nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
This class should have a `toString()` method that describes what's required, so some string like: > Comma-separated header rules, where each header rule is of the form '[action] [header name]:[header value]' and optionally surrounded by double quotes if any part of a header rule contains a comma
Wouldn't it be much easier to do the following: ``` public Connector createConnector(String listener, String name) { ... String hostname = ... int port = ... ... if (name == null || name.trim().isEmpty()) { name = String.format("%s_%s%d", PROTOCOL_HTTPS, hostname, port); } connector.setName(name); ... ```
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
This logic is repeated in a couple of places. I'm wondering if we could change `MaterializedPeek` to take the `InternalSteamsBuilder` as an additional constructor param and have the logic inside the class, and this block of code could be replaced with `new MaterializedPeek<>(materialized, builder).maybeIncrementTopologyCount()` or something like that.
Sorry for that -- You are of course right. `final` only for iterator loops...
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
It seems that both loginContext and mode can just be a local variable.
It seems that both loginContext and mode can just be a local variable.
nit: final int `activeTaskAssignmentLength`.
Please remove empty line.
> At the moment, I am leaning toward the latter. In any case, I suggest we let the errors propagate for now and file a jira to reconsider once we are closer to integration. Does that sound fair? Sounds fair to create a Jira and revisit this later.
See above: we shouldn't rely on `previousRightWindow` here. Actually I don't think we need it at all? (assuming we move the check in it to the condition above where we use the combined window agg)
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Also not clear why "numSegments - 1" here.
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
This should be done in the SSL class. The base class should not be aware of SSL and just use configurations from the concrete classes
See above: we shouldn't rely on `previousRightWindow` here. Actually I don't think we need it at all? (assuming we move the check in it to the condition above where we use the combined window agg)
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
@ijuma Sorry, I don't know of a standard way of doing this,
We shouldn't use `<br>`; instead, use a `<pre>` section around the lines.
We should read the metadata inside the while loop since it could change.
nit: some extra newlines here.
Also not clear why "numSegments - 1" here.
We shouldn't use `<br>`; instead, use a `<pre>` section around the lines.
Seems to be the exact same test as above (both don't use grace). Seem the difference is if window size enlarged retention time setting or not, but it's not reflected in the names of the tests.
Seems to be the exact same test as above (both don't use grace). Seem the difference is if window size enlarged retention time setting or not, but it's not reflected in the names of the tests.
typo: The title of the last column should be `DELETE_SEGMENT_FINISHED`.
typo: The title of the last column should be `DELETE_SEGMENT_FINISHED`.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
Seems to be the exact same test as above (both don't use grace). Seem the difference is if window size enlarged retention time setting or not, but it's not reflected in the names of the tests.
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
All methods only used once should be explicitly inlined.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
All methods only used once should be explicitly inlined.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
This name seems backwards.
Seems like a no-op
The compiler uses `MustacheResourceTemplateLoader` internally and that one is configured to use the configured charset.
I think it's because of: ``` * <p> On some systems, closing a channel releases all locks held by the Java * virtual machine on the underlying file regardless of whether the locks were * acquired via that channel or via another channel open on the same file. It * is strongly recommended that, within a program, a unique channel be used to * acquire all locks on any given file. ```
This doesn't seem to be used.
Why is serviceName a property inside JaaS config? Could this be made one of the Kafka Sasl configuration properties instead? Presumably it is used only by Kafka code and hence doesn't belong in jaas.conf? IBM JDK Kerberos module throws an exception because it doesn't recognize this property.
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
This was probably left by mistake.
This was probably left by mistake.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
The sentence "Note that the order of the tags..." is not applicable because there is no set in this case. It's just the order of the varargs.
nit: personal preference so feel free to ignore. But i'd ditch the `else` in this case. I don't think it adds anything
This is the default.
nit: personal preference so feel free to ignore. But i'd ditch the `else` in this case. I don't think it adds anything
It seems I also could approve it. I will read all code tomorrow and work with you to get this approved.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
I know this is a bit picky, but we (mostly @mjsax and i) are trying to encourage everyone to use `final` where possible
That was my other thought. We might wrap one DataException into another but that's not a big deal. In this code `Decimal.toLogical` is now used, and if you follow the refs, there's a `new BigInteger(value)` in there that might throw `NumberFormatException`. Improbable, but thought we could be on the safe side with the more general catch block.
Nit: somehow I don't like `blah`. Otherwise LGTM
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
It looks like there is an extra whitespace after return.
Sounds interesting, cc @kkonstantine
`keySerde` -> `valueSerde`
`keySerde` -> `valueSerde`
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
Same as above: need to check `clientResponse.hasResponse()`
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: seems we could move this to the caller and remove the `requestTimeoutMs` parameter.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
It seems that both loginContext and mode can just be a local variable.
We could perhaps add a `leaderId` in `PartitionMetadata`
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
`setNeedsCommit` -> `{@link #setNeedsCommit}`
`setNeedsCommit` -> `{@link #setNeedsCommit}`
`setNeedsCommit` -> `{@link #setNeedsCommit}`
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
`setNeedsCommit` -> `{@link #setNeedsCommit}`
Maybe we can just a better name for `path` since it makes this code look suspicious.
It seems that both loginContext and mode can just be a local variable.
This name seems backwards.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
The functionality of process() now is completely covered by transform: users can define a transform function with return type R be "Void" and add a dummy "return null" in the end of the function. And then in KStream we can add public void transform(TransformerSupplier<K, V, Void>) to replace the "process()" call. Having both process() and transform() might be confusing to users, so I would suggest we just remove process() here.
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
debug line should be removed.
depending on the decision regarding naming sources for `builder.table` we'll need to update this test.
nit: braces unneeded
Another name might be `seek()`.
base -> based progress -> progressed
What about client security related properties? It's weird that we pick up "bootstrap.servers" from one prefix, but the corresponding security properties under a different prefix. If we do provide the security related properties in the same prefix, they seem to be duplicated from those under prefix REMOTE_LOG_METADATA_COMMON_CLIENT_PREFIX, REMOTE_LOG_METADATA_COMMON_CLIENT_PREFIX or REMOTE_LOG_METADATA_CONSUMER_PREFIX.
It seems that both loginContext and mode can just be a local variable.
either move `this` to next line, or fix indention.
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
This type is not parameterized. It's generally better to list the parameters when you reference a parameterized type.
to me it seems like we can't possibly know what the constraints of all reporters would be and they don't provide an interface for validation, so it should be up to them to figure out how to substitute. but i've also asked some other folks to maybe chime in here who may have better context on how we've handled this elsewhere.
Nit: why not use `boolean`
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
It seems that both loginContext and mode can just be a local variable.
This is synchronized and will await on the produceFuture. `await()` is called by `awaitFlushCompletion()` which is called when a user calls `flush()`. I am concerned that a user can call `flush()` and end up effectively dead locking other operations on the ProducerBatch, as getChildrenProducerBatch and addChildrenProducerBatch will not be able to be called by other threads - my concern is that the sender thread may become deadlocked in splitAndReenqueue in this state.
So if we were going to be strict about var naming, then technically `ipv4_addr` _could_ be an ipv6 addr. Little things like this are usually better to clean up because you never know what may happen to this code in the future. Maybe let Felixx or Carlton have the final say but imho it would be cleaner to move the logic away from the dictionary literal: ```suggestion if self.addr == "0": addr = "0.0.0.0" elif self._raw_ipv6: addr = "[%s]" % self.addr else: addr = self.addr ```
```suggestion - Minute when the job should run (C(0-59), C(*), C(*/2), etc.). ``` Same for the others.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
nit: blank missing :P
nit: blank missing :P
The variable name doesn't need to be / shouldn't be changed, IMO. (My suggestion in the ticket for a variable name was for the string argument, if that was going to be tested separately.)
I really like the fact that we are separating Resources from ResourcePatterns! Great job.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Another name might be `seek()`.
base -> based progress -> progressed
nit: we can do without the curly braces here and above. However, these will soon be replaced by the actual impl
We should log an error that prints out what the two configs actually are
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
Here you should test if the stream thread has the name of the stream thread that was removed before.
Here you should test if the stream thread has the name of the stream thread that was removed before.
Here you should test if the stream thread has the name of the stream thread that was removed before.
Also mention that this returns by topic name if the request used topic names. otherwise returns null.
nit: braces unneeded
Looks good. I like the additional checking that you're doing here.
We can use `new ProducerRecord<>(topic, "value");` to simplify it a tiny bit
Thinking about it, this may be the root of the problem. We are removing from the head of the ArrayList, one at a time. For each removal, we cause all the elements to be shifted in the underlying array, which is very inefficient if n is not small.
Thinking about it, this may be the root of the problem. We are removing from the head of the ArrayList, one at a time. For each removal, we cause all the elements to be shifted in the underlying array, which is very inefficient if n is not small.
Thinking about it, this may be the root of the problem. We are removing from the head of the ArrayList, one at a time. For each removal, we cause all the elements to be shifted in the underlying array, which is very inefficient if n is not small.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
To clarify, what I was suggesting is this: ``` if (buffer.hasRemaining()) { objects[i] = fields[i].def.type.read(buffer); } else if (tolerateMissingWithDefaults && fields[i].def.hasDefaultValue) { objects[i] = fields[i].def.defaultValue; } else { throw new SchemaException("Missing value for field '" + fields[i].def.name + "' which has no default value"); } ``` I was just trying to consolidate the logic, but it's not a big deal. By the way, since you drew my attention to it, it might be worth catching the `SchemaException` that we throw here and and raising directly rather than wrapping it in another SchemaException.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
Or https://github.com/google/guava/blob/master/guava/src/com/google/common/math/IntMath.java#L56-L72 It is safe to look as it is Apache License 2.0.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
I think we should call `deserializer.configure(...)` here
This is added in #986 as well. The later patch to go in will have to rebase, or we can extract out the common code as a separate PR. I am fine with either way. FYI @becketqin.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Is this constructor used at all? If not, I'd not include it one should generally provide a message explaining more.
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
nit: we can do without the curly braces here and above. However, these will soon be replaced by the actual impl
nit: we can do without the curly braces here and above. However, these will soon be replaced by the actual impl
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
@becketqin is right-- you should handle this case. Perhaps the server sent back bad data. The way to handle it is not to throw an exception, but to complete the relevant future(s) with an error. There are a few other cases where we handle bad server data by completing a future with failure in AdminClient.
How about returning a Set instead of List? ``` return topics .stream() .filter(topic -> !topic.isEmpty()) .collect(Collectors.toSet()); ```
I see. I do not have a strong preference actually. But I remember we use singulars not plurals in many other classes and just wanted to be consistent. If it is actually the opposite case I'm happy to have them all to be plural.
Preferred leader election is an optimization. If we can't move the leader to the preferred one, it seems there is no need to do anything extra.
nit `getMetadata` -> get`
nit `getMetadata` -> get`
nit: mentioning the time unit seems redundant.
for headers, we need to do the same as for `recordValue` ? (I think you c&p from `compareValueTimestamp` -- there it's different because timestamp is a `long` and cannot be `null`.
for headers, we need to do the same as for `recordValue` ? (I think you c&p from `compareValueTimestamp` -- there it's different because timestamp is a `long` and cannot be `null`.
@becketqin is right-- you should handle this case. Perhaps the server sent back bad data. The way to handle it is not to throw an exception, but to complete the relevant future(s) with an error. There are a few other cases where we handle bad server data by completing a future with failure in AdminClient.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
nit: line too long
nit: extra line
nit: break line
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
req: I think we want to introduce some `acceptableLag` config within which a task is considered caught-up, otherwise this is way too strict. ie the condition should be `lag <= acceptableLag`
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
This will close the `ServerSocketChannel` before it can be used by the `ServerThread`. The channel is eventually closed when the thread is closed so this change is unnecessary. I'll address this when merging.
you should note that the default changes in 2.4 and why
Dropped this unnecessary duplicate code, as discussed.
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
@ijuma Sorry, I don't know of a standard way of doing this,
The one we are keen on is PLAIN. We will be using SASL with SSL, so PLAIN gives us the simplest secure authentication without having to distribute certificates for mutual client auth. Yes, a separate PR makes sense so that this one can be committed soon. I will raise another JIRA.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
formatting: no need to curly braces
Please get rid of this volatile. There is no longer a circular dependency here.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Nitpick: I'd call this `getOrCreateFileChannel`.
Now that we have separate `Plugins::sinkConnectors` and `Plugins::sourceConnectors` methods, we can abstract this a little, which should improve readability a bit and make it easier to extend for other plugin types in the future: ```suggestion static final List<Class<? extends SinkConnector>> SINK_CONNECTOR_EXCLUDES = Arrays.asList( VerifiableSinkConnector.class, MockSinkConnector.class ); static final List<Class<? extends SourceConnector>> SOURCE_CONNECTOR_EXCLUDES = Arrays.asList( VerifiableSourceConnector.class, MockSourceConnector.class, SchemaSourceConnector.class ); @SuppressWarnings({"unchecked", "rawtypes"}) static final List<Class<? extends Transformation<?>>> TRANSFORM_EXCLUDES = Collections.singletonList( (Class) PredicatedTransformation.class ); public ConnectorPluginsResource(Herder herder) { this.herder = herder; this.connectorPlugins = new ArrayList<>(); // TODO: improve once plugins are allowed to be added/removed during runtime. addConnectorPlugins(herder.plugins().sinkConnectors(), SINK_CONNECTOR_EXCLUDES); addConnectorPlugins(herder.plugins().sourceConnectors(), SOURCE_CONNECTOR_EXCLUDES); addConnectorPlugins(herder.plugins().transformations(), TRANSFORM_EXCLUDES); addConnectorPlugins(herder.plugins().predicates(), Collections.emptySet()); addConnectorPlugins(herder.plugins().converters(), Collections.emptySet()); addConnectorPlugins(herder.plugins().headerConverters(), Collections.emptySet()); } private <T> void addConnectorPlugins(Collection<PluginDesc<T>> plugins, Collection<Class<? extends T>> excludes) { plugins.stream() .filter(p -> !excludes.contains(p.pluginClass())) .map(ConnectorPluginInfo::new) .forEach(connectorPlugins::add); ```
It'd be more powerful to do an assertion on the complete set of returned plugins, since that will only require one test run to discover all differences between the expected plugins and the actual ones: ```suggestion Set<Class<?>> excludes = Stream.of(ConnectorPluginsResource.SINK_CONNECTOR_EXCLUDES, ConnectorPluginsResource.SOURCE_CONNECTOR_EXCLUDES) .flatMap(Collection::stream) .collect(Collectors.toSet()); Set<ConnectorPluginInfo> expectedConnectorPlugins = Stream.of(SINK_CONNECTOR_PLUGINS, SOURCE_CONNECTOR_PLUGINS) .flatMap(Collection::stream) .filter(p -> !excludes.contains(p.pluginClass())) .map(ConnectorPluginsResourceTest::newInfo) .collect(Collectors.toSet()); Set<ConnectorPluginInfo> actualConnectorPlugins = new HashSet<>(connectorPluginsResource.listConnectorPlugins(true)); assertEquals(expectedConnectorPlugins, actualConnectorPlugins); verify(herder, atLeastOnce()).plugins(); ``` (This assumes we split out `CONNECTOR_EXCLUDES`, but the same general strategy should apply even if we don't).
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
...right, we're already in netcommon. Carry on, then.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
SGTM. If we find it flooding the logs and not helpful we can reconsider
...right, we're already in netcommon. Carry on, then.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
Why is serviceName a property inside JaaS config? Could this be made one of the Kafka Sasl configuration properties instead? Presumably it is used only by Kafka code and hence doesn't belong in jaas.conf? IBM JDK Kerberos module throws an exception because it doesn't recognize this property.
prop: make the value a `SortedSet` so we can just insert clients as we build the map and use a custom comparator to automatically sort the clients based on lag
I think we are guaranteed to have the listener present, but perhaps it's worth checking explicitly and throwing if it is not the case.
Nit: we typically just say `partition` in these cases. Same for the other `log.debug`.
Also not clear why "numSegments - 1" here.
Nit: we typically just say `partition` in these cases. Same for the other `log.debug`.
It should be 'false' by default
ditto on removing before/after.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
This is added in #986 as well. The later patch to go in will have to rebase, or we can extract out the common code as a separate PR. I am fine with either way. FYI @becketqin.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
It should be 'false' by default
Also not clear why "numSegments - 1" here.
nit: parameters on a separate line
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
It seems that both loginContext and mode can just be a local variable.
@tomazfernandes this PR targets the `2.7.x` branch and we've switched to snapshot there https://github.com/spring-projects/spring-boot/blob/f96efa72abbc8ab4abd6f5378ebc9574a84c30b1/spring-boot-project/spring-boot-dependencies/build.gradle#L1783-L1787
This is public API meant to be used by users. I don't mind if our tests are a bit more verbose but we should aim to have succinct public APIs
ok, potentially reduces allocations for the user, thanks
I think this would never happen now since the passed in `recordPerTopicPerPartition` is always initialized.
nit: do we need the `numTasks` argument since the only caller is passing MIN_TASKS? Alternatively, we could replace `info.tasks().size() >= numTasks` with `!info.tasks().isEmpty()` and get rid of `MIN_TASKS`.
I'd move the `ERROR_HEADER_PREFIX` here since it really is more of an implementation detail. And as @kkonstantine suggested, I'd change the prefix to be `__connect.errors.` (with the trailing period) so that the above lines can be like: public static final String ERROR_HEADER_PREFIX = HEADER_PREFIX + "errors";
This is good, but it may be more consistent to move the remaining lines in this method to another static method. That would make this `masked(Object)` method a bit easier to understand, too. If you add a new static method right after this method and use `value` for the parameter, the next few lines will remain unchanged (other than moving into a new static method).
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Since it's tied to the deprecated name, the error message should probably include both the deprecated and new name. Otherwise it'll be more difficult to track down the source of the conflict.
Minor nit, but I think something like this would be more accurate/complete. Applies to this and the broker config. What do you think? If the `MAX_COMPACTION_LAG_MS_CONFIG` or the `MIN_COMPACTION_LAG_MS_CONFIG` configurations are also specified, then the log compactor considers the log eligible for compaction as soon as either: (i) the dirty ratio threshold has been met and the log has had dirty (uncompacted) records for at least the `MIN_COMPACTION_LAG_MS_CONFIG` duration, or (ii) if the log has had dirty (uncompacted) records for at most the `MAX_COMPACTION_LAG_MS_CONFIG` period.
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
Hmm, I'm having trouble reasoning about the shutdown in this case. In the existing cases, we'd have `WorkerSinkTask.stop()`/`WorkerSinkTask.awaitStop()` handle invoking these, which also tries to ensure this thread has exited and calls `SinkTask.stop()`. But in this case, this thread calls `WorkerSinkTask.abort()`, which only calls `SinkTask.stop()`. How would we manage a case where, e.g., work is rebalanced by the DistributedHerder, which would trigger the Worker to stop a task (from the Herder's thread)? Then we'd potentially have `SinkTask.stop()` called multiple times if it hit this `catch` block, right? I think the responsibility of which thread invokes certain methods might be getting confused here. (Admittedly, it is tough to get this right since the responsibilities of different threads is confusing in this code.)
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
Nice tidy up of this test class :-)
Is there a reason why you had to add this code? `clientSaslMechanism` should already have been set to inter-broker SASL mechanim by the broker for that case. We rely on that in `clientCallbackHandlerClass` for example.
Given that we have both `ConnectorFactory` and `PluginDiscovery` which should be able to give you the full set of both canonical and short names, couldn't we just do a look up both on `connType` and `includedConnType` and validate that they are the same? It might require a bit of reworking (e.g. making `Map<String, Class<? extends Connector>>` available instead of `List<Class<? extends Connector>>` in PluginDiscovery), but it seems like a better solution since it'll address all the cases afaict. re: BadRequestException, we needed something in the 400 range and nothing else seemed appropriate.
This should go away. `@ConditionalOnClass` already does that.
This should go away. `@ConditionalOnClass` already does that.
This should go away. `@ConditionalOnClass` already does that.
I think the message needs to be updated.
We should use try-with-resources here (for `DataInputStream`).
Nit, to improve readability and precision, especially around how many Kafka transactions would be used: > Whether to enable exactly-once support for source connectors in the cluster by using transactions to write source records and their source offsets, and by proactively fencing out old task generations before bringing up new ones.
nit: braces unneeded
nit: braces unneeded
nit: should be `ConnectHeaders`. *probably* would be easy to figure out, but better to just get it right :)
SGTM. If we find it flooding the logs and not helpful we can reconsider
nit: should be `ConnectHeaders`. *probably* would be easy to figure out, but better to just get it right :)
SGTM. If we find it flooding the logs and not helpful we can reconsider
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
Nit: somehow I don't like `blah`. Otherwise LGTM
indentation issue here, if this is passing checkstyle i would be surprised
This should be ``` return new Subscriber<T>(child); ``` to chain the unsubscription properly.
The map is not used.
The map is not used.
https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/log/LogConfig.scala#L150 can reference to this new field.
Nit: somehow I don't like `blah`. Otherwise LGTM
Maybe we can just a better name for `path` since it makes this code look suspicious.
Thank you for pointing this out! I will have a look at this in the next days.
The type in Collections.<String, String> is unnecessary.
Thank you for pointing this out! I will have a look at this in the next days.
It seems that the checkstyle failed but all unit tests have passed. I can modify the code slightly to fix the checkstyle failure before merging it.
The map is not used.
There is a built-in for this `Function.identity()`
Can this be a `byte`.
"*" is considered "LITERAL" for compatibility reasons
I think we should assert that the "predicate" and "negate" config were the implicit ones and not the ones defined by `HasDuplicateConfigTransformation`. I guess we could do this by having `HasDuplicateConfigTransformation`'s configs use different types ("negate is `BOOLEAN` in both) and then asserting the expected types.
Please remove empty line.
Shouldn't the workers discover that the coordinator is unavailable while it is down? I'm imagining this test going like this: 1. steady-state workers are running 2. brokers stop 3. workers discover the coordinator is unavailable 4. workers stop their tasks 5. brokers start 6. workers discover the next coordinator 7. workers start their tasks 8. workers are running unaffected
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
ok, potentially reduces allocations for the user, thanks
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
+1 - And the use of such expression for the JMX stuff always bugged me.
I might be missing something, but in both cases, you just want to use regular expressions, right? There is no need to mess around with predicate functions.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
`schemaType` is null means that the value type is not supported by the Connect's Data API. May be we should throw an exception with a message indicating this.
nit: move parameter to it's own line (same below)
nit: add `final`
nit. I think there is `.` missing `since 3.0[.] Use`
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
All these regexes should be relaxed.
All these regexes should be relaxed.
I was using this test to print the topology and it shows two sub topologies while it should be one (seems the reason is that you use the same `StreamsBuilder` as in `setup()` method. Also, the naming of the operators seems to be incorrect. Also wondering if `KGroupedStream#cogroup()` needs on overload that takes a `Named` parameter? Maybe not, but the specified `Named` from `aggregate()` would need to be used for other processors, too. Atm there is this weird `COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test` ``` Topologies: Sub-topology: 0 Source: KSTREAM-SOURCE-0000000000 (topics: [topic]) --> none Sub-topology: 1 Source: KSTREAM-SOURCE-0000000001 (topics: [one]) --> COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test Processor: COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test (stores: [COGROUPKSTREAM-AGGREGATE-STATE-STORE-0000000002]) --> test <-- KSTREAM-SOURCE-0000000001 Processor: test (stores: [COGROUPKSTREAM-AGGREGATE-STATE-STORE-0000000002]) --> KTABLE-TOSTREAM-0000000005 <-- COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test Processor: KTABLE-TOSTREAM-0000000005 (stores: []) --> KSTREAM-SINK-0000000006 <-- test Sink: KSTREAM-SINK-0000000006 (topic: output) <-- KTABLE-TOSTREAM-0000000005 ```
I was using this test to print the topology and it shows two sub topologies while it should be one (seems the reason is that you use the same `StreamsBuilder` as in `setup()` method. Also, the naming of the operators seems to be incorrect. Also wondering if `KGroupedStream#cogroup()` needs on overload that takes a `Named` parameter? Maybe not, but the specified `Named` from `aggregate()` would need to be used for other processors, too. Atm there is this weird `COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test` ``` Topologies: Sub-topology: 0 Source: KSTREAM-SOURCE-0000000000 (topics: [topic]) --> none Sub-topology: 1 Source: KSTREAM-SOURCE-0000000001 (topics: [one]) --> COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test Processor: COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test (stores: [COGROUPKSTREAM-AGGREGATE-STATE-STORE-0000000002]) --> test <-- KSTREAM-SOURCE-0000000001 Processor: test (stores: [COGROUPKSTREAM-AGGREGATE-STATE-STORE-0000000002]) --> KTABLE-TOSTREAM-0000000005 <-- COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test Processor: KTABLE-TOSTREAM-0000000005 (stores: []) --> KSTREAM-SINK-0000000006 <-- test Sink: KSTREAM-SINK-0000000006 (topic: output) <-- KTABLE-TOSTREAM-0000000005 ```
nit: unneeded newline
Thanks @vvcephei -- that is convincing.
Thanks @vvcephei -- that is convincing.
nit: unneeded newline
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
Ack. Overlooked this change :)
add `final` twice
nit - "once once"
nit: add `final`
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
Also not clear why "numSegments - 1" here.
If we start from scratch then maybe these would be better be in `state`, but they have been added to `processor` and moving them would be incompatible changes. So I'm more concerning about the newly added classes.
Also not clear why "numSegments - 1" here.
Also not clear why "numSegments - 1" here.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
`This module takes a script and a hash of values...`
nit: the ternary operator can be used (`?:`) as below, unless you're not a fan. ```suggestion AbstractStatus.State connectorState = request.shouldRestartConnector(connectorStatus) ? AbstractStatus.State.RESTARTING : connectorStatus.state(); ```
Both `GZipInputStream` and `SnappyInputStream` read the header in the constructor, so it would make sense to me to remain consistent in that respect.
We tend to use different `node` value when multiple connections are created by a test. You could just replace `node` here with "1" and a couple of lines below with "2".
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
nit: we usually do not use unnecessary numbers as part of the parameter; rename to `streamImpl` instead.
getter and setter should be removed
nit: extra blank line ```suggestion ```
Maybe add an `addSubtopology` method? I don't really like the idea of a) exposing, and b) mutating an internal collection.
The code isn't huge, so by no means a blocker, but @kkonstantine pointed out that the entire block before configuration (and most of config modulo the conditional) is identical between header and "normal" converters. The main difference in the header blocks are just the class referenced (`Converter.class` vs `HeaderConverter.class`). Consolidation would be nice if it's easy to do, but at the same time I'd rather get a fix to the immediate problem in, so definitely wouldn't block on saving 10 lines of duplicated code.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Tiny nitpick: you can declare error in this line too as it's not used outside the loop anymore
Cheating the compiler, woohoo!
Tiny nitpick: you can declare error in this line too as it's not used outside the loop anymore
nit: could be useful to log the type of exception in the assertion message.
Nitpick: space missing before `conditionDetails`.
So we basically do 10 re-tries? Is this intended? Or should be just sleep for a hard-coded "backup time"
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Remove double blank.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
Could we have a separate test case which covers the `forceClose()` path. We can assert that we do not wait for the producerId and all pending sends are aborted.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
I fixed this one to use the constant before merging.
Could we reuse ```mechanismName``` (https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java#L79) so we don't need this duplicate replacement.
I think in general we shouldn't call this `toString`. People would confuse it for the actual `toString` method and would suppose the same or similar behavior. For instance `toString` methods aren't expected to throw exceptions. So in my opinion we should call this something like `readAll` or `readAllBytes`.
Could we reuse ```mechanismName``` (https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/ScramMechanism.java#L79) so we don't need this duplicate replacement.
This empty class seems suspicious.
This doesn't seem to be used.
Can remove if initialize above
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Technically this sets the proper value for `url` but it's doing so twice. s/url = url/url/
Alternatively, we could make this method idempotent. Seems like we only call it from `ensureHasBookkeeperEntry` anyway.
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
formatting: no need to curly braces
formatting: no need to curly braces
I think we should call `deserializer.configure(...)` here
nit: add `final`
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
Could store `entry.getKey()` in a local variable since it is used several times
It seems that the checkstyle failed but all unit tests have passed. I can modify the code slightly to fix the checkstyle failure before merging it.
Could store `entry.getKey()` in a local variable since it is used several times
`ConfigProvider` was introduced in AK 2.0, so this change can't be backported to earlier branches.
This was the checkstyle error that was failing your build.
We shouldn't return `null`, but instead return a "unknown query" result.
We shouldn't return `null`, but instead return a "unknown query" result.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Nit: why not use `boolean`
Style convention is to separate words by underscore.
nit: unneeded newline
Mentioned offline, but it would be good to understand the need for these fields to be `volatile`. It seems that the use of the latch is sufficient to ensure visibility from the memory model perspective.
We recently "fixed" `listAllTaskDirectories` to guarantee that it never returns null. We just missed to update all the null checks when we did that
We recently "fixed" `listAllTaskDirectories` to guarantee that it never returns null. We just missed to update all the null checks when we did that
The compiler uses `MustacheResourceTemplateLoader` internally and that one is configured to use the configured charset.
I hope we can get rid of those conversion in the future :)
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
Yeah, I can't think of a strong reason for either option, so I guess we can leave it here.
Use `File.separator` instead of `/`
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
may be use Objects.requireNonNull
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
Should we produce the input before we start the KS instances? If there is no input, it's clear that Standbys won't restore as there is not data for restoring.
Should we produce the input before we start the KS instances? If there is no input, it's clear that Standbys won't restore as there is not data for restoring.
Not sure what has changed here.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
I think `update the index` could be made clearer since the `DataInput` interface doesn't mention an index. Same for other similar cases.
I think `update the index` could be made clearer since the `DataInput` interface doesn't mention an index. Same for other similar cases.
I think `update the index` could be made clearer since the `DataInput` interface doesn't mention an index. Same for other similar cases.
Same as above mentioned, the validation didn't get handled in new API.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Nit: we don't need this tag before the parameter list.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
As above: add more "randomness"
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Shouldn't this be a config exception? It is not really invalid partitions.
Is this constructor used at all? If not, I'd not include it one should generally provide a message explaining more.
Shouldn't this be a config exception? It is not really invalid partitions.
When I suggested it, I thought we could do a bit better, maybe something like `(id: 5, www.example.com:9123)`, but maybe that's actually worse.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
formatting: no need to curly braces
I think we should call `deserializer.close()` here
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
nit: some extra newlines here.
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
Please remove empty lines here and in the other test methods.
Same question here about just using a static ConfigDef instead of a static method.
nit: move parameter to it's own line (same below)
Also not clear why "numSegments - 1" here.
I think we should call `deserializer.close()` here
Also not clear why "numSegments - 1" here.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I think we should call `deserializer.close()` here
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
I think we should call `deserializer.close()` here
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
This should go away. `@ConditionalOnClass` already does that.
Did you plan to implement this? If you not, you can use the trick you are doing in other places. E.g. ```java static ConfigurationValidator NOOP_VALIDATOR = (_, __) -> {}; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
"with a read-only key"
Just for reference: fixed via https://github.com/apache/kafka/pull/5588
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
We should test that delete twice in a row fails with `IllegalStateException`
We should test that delete twice in a row fails with `IllegalStateException`
We should test that delete twice in a row fails with `IllegalStateException`
Why is the order of these methods different than in `ConnectorStatusListener`? Also, the `TaskStatusListener` methods always forward the method to the delegate _last_, whereas the methods of the `ConnectorStatusListener` use a mixture. Let's make them consistent.
Why is the order of these methods different than in `ConnectorStatusListener`? Also, the `TaskStatusListener` methods always forward the method to the delegate _last_, whereas the methods of the `ConnectorStatusListener` use a mixture. Let's make them consistent.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
Can this be a `byte`.
I think we should call `deserializer.close()` here
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Can this be a `byte`.
I think we should call `deserializer.close()` here
Can this be a `byte`.
I think we should call `deserializer.close()` here
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
I think we should call `deserializer.close()` here
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
Can this be a `byte`.
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Looks good. I like the additional checking that you're doing here.
do we really need that we matched it? Can't we do all all of this is a single log statement? We can include size of credentials map and authenticated boolean. This will help keep the old structure.
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
This is what @guozhangwang was asking for.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
This is the same code as in `KTableFilter` -- we should refactor and share code.
This is the same code as in `KTableFilter` -- we should refactor and share code.
Hey @dguy , actually after thinking about it again, I realized that the `selectKey` can be used before either aggregates, or joins, but it could also before any other operators. So enforce removing nulls at this stage is not safe (similarly for `map`, which could also change the key to null). Instead, we should filter nulls in 1) `repartitionIfRequired`, as if the key is null, it is meaningless for repartitioning since it can go to any partitions anyways, and 2) in `KStreamAggregate / Reduce / Joins`, that if the received record key is null, ignore them (instead of throwing exceptions), since repartitioning may not necessarily happen before the aggregation or joins. Thoughts? Sorry for the back-and-forth opinions btw.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
may be use Objects.requireNonNull
may be use Objects.requireNonNull
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
single line is fine
I'd suggest moving this static method after the non-static methods.
We should test that delete twice in a row fails with `IllegalStateException`
We should test that delete twice in a row fails with `IllegalStateException`
There is a built-in for this `Function.identity()`
nit: remove `this`
Hey @dguy , actually after thinking about it again, I realized that the `selectKey` can be used before either aggregates, or joins, but it could also before any other operators. So enforce removing nulls at this stage is not safe (similarly for `map`, which could also change the key to null). Instead, we should filter nulls in 1) `repartitionIfRequired`, as if the key is null, it is meaningless for repartitioning since it can go to any partitions anyways, and 2) in `KStreamAggregate / Reduce / Joins`, that if the received record key is null, ignore them (instead of throwing exceptions), since repartitioning may not necessarily happen before the aggregation or joins. Thoughts? Sorry for the back-and-forth opinions btw.
```suggestion "The desired Unix precision for the timestamp. Used to generate the output when type=unix " + ```
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
This is done above in `before()` so it's probably not behind the flakiness, unfortunately. Not sure why we purge the local state twice but you're right, we should at least be consistent when we do and purge the state for all three Streams. Good catch
I am must wondering, if this should go into it's own test class `KStreamGlobalKTableJoinTest.java` ? Similar below.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Ditto on removing before/after
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
Configuration properties must be JavaBean properties (the type must match) and we don't support `Optional` here.
Configuration properties must be JavaBean properties (the type must match) and we don't support `Optional` here.
lib/ansible/modules/network/aos/aos_ip_pool.py:191:1: M511 - mutable default arg of type List There is only one caller of create_new_ip_pool() and it provides all three args, so subnets doesnt need to be keyword arg or optional.
Map.Entry<String, String> to avoid the check below
typo in the test name.
req: typo unknown Pid
I'm not too keen on the structure of the JSON, both because the keys vary and because it's not very extensible. I'd prefer something like this: ``` json { "status": "UP", "nodes": [ { "address": "127.0.0.1:7001", "version": "3.0.7" }, { "address": "127.0.0.1:7002", "version": "3.0.7" }, { "address": "127.0.0.1:7003", "version": "3.0.7" } ] } ``` The keys are the same for every node and we can also easily add extra information about a node.
It's not any more JDK dependent than running a loop is JDK dependent (JIT optimizations vary more than this method that changes less often). Anyway, if it's 4 bytes, it doesn't matter.
It's not any more JDK dependent than running a loop is JDK dependent (JIT optimizations vary more than this method that changes less often). Anyway, if it's 4 bytes, it doesn't matter.
Sorry, missed this earlier: We are creating a new `selector` in `checkAuthentiationFailed`, so we should ensure that the previous selector is closed. You could call `selector.close()` just before calling `checkAuthenticationFailed` here and also a couple of lines below.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
the norm (ideally) for AK is to only use `this.` as needed to handle masking. i'm sure there are exceptions, but almost universally the use case is for constructors to avoid awkward parameter naming in order to avoid conflicting with a convenient member variable name.
may be use Objects.requireNonNull
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
While I'm in favor of code re-use, in this case, the code in `Topic.validate` is not too large and could be easily ported to a `Named.validate` method. By doing so, Kafka Streams can change naming rules as needed. I realize that `Materialized.as` uses`Topic.validate` to validate the name of the store, but I'd suggest updating to use `Named.validate` there as well. NOTE: If we do this, we'd need to update the KIP EDIT: Actually I'm not sure we'd need to update the KIP as most likely this method would not be publicly accessible.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
Minor simplification we can do below: ```java if (targetNode == null || !awaitReady(client, targetNode, time, requestTimeoutMs)) { transactionManager.lookupCoordinator(nextRequestHandler); break; } ```
validateStoreOpen() can be outside of lock block.
Since we don't do coordinator discovery in this loop, do we need to reinitialize the `coordinator` variable? If the connection fails, then pending request count should drop to 0 already.
We don't usually assert on exception messages as it makes tests a bit brittle. This applies to a few other tests too.
That's a broken `equals` implementation and not this library's problem.
the naming used above seems better here ```suggestion Throwable exception = null; ```
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
We should close the producer.
We should close the producer.
We should close the producer.
We should close the producer.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
We usually avoid writing to standard out in test cases. A few more of these.
That's a good idea. Note: Kafka does not use this JUnit functionality yet (i.e. no use of ExternalResource, ClassRule, Rule as far as I can tell). @ijuma: Would it ok for us to introduce this? There's no additional dependency etc., it's just using a new JUnit feature that was introduced in 4.7 (we're on 4.12).
If only Java made it possible to declare immutable local variables and method parameters in a more concise way!
Nice tidy up of this test class :-)
`.toString()` unnecessary here are other similar logs.
nit: some extra newlines here.
I believe a null-pointer check is necessary here.
Another name might be `seek()`.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
We should read the metadata inside the while loop since it could change.
I recommend to add special handling for JsonParseException - just log it instead of rethrowing. If such an exception is not handled properly, consuming may be blocked with any non-json message - just text, for example. I got this while playing with Kafka locally: just one simple "dummy" message from console client brought tons of exceptions to my log.
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
We should add a `null` check to allow closing a deserializer that was not properly setup
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Another name might be `seek()`.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
Nit: go with single parameter per line.
nit: newline after if condition, also space before and after `!=`, and space after `if`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
This should go away. `@ConditionalOnClass` already does that.
Hmm, so previously (and also with this change) we are assuming that we will get different resolved IPs for each connection to apache.kafka.org? This seems to rely on round-robbin DNS resolution that we can't really control. I think these assertions will always be prone to failure unless we can control the DNS server like @dajac suggested. I guess we can commit this to unblock the tests, but we should definitely prioritize a better fix.
@eliaslevy Since this part is covered in other unit test case, we want to remove redundant coverage to leave the unit test as succinct as possible.
Not sure you need to initialize the factory every time there.
Same as above mentioned, the validation didn't get handled in new API.
I would call this one `topics()` as you did already in the request.
Why use the delegate? Why not just call the methods on the `WorkerConnector`'s fields from within the `SourceConnectorContext` and `SinkConnectorContext` methods? E.g., @Override public void requestTaskReconfiguration() { ctx.requestTaskReconfiguration(); }
It's easier to follow these tests when they are broken down into smaller cases. That also gives us an opportunity to provide an opportunity to give a good name to the case we're verifying. For example, `testCreatePartitionsWithInvalidReplicaAssignment` or `testCreatePartitionsWithSmallerPartitionCount`.
This should be outside the try block
Ok. Thanks for clarifying.
BackpressureUtils didn't exist at that point, so I am considering how to consolidate this type of logic as we keep repeating this type of non-trivial code and it is easy to get wrong. I'm okay with merging ... we really should spend some time figuring out the core patterns so we can encode the state machine, similar to what BackpressureUtils and AbstractOnSubscribe have started formalizing.
BackpressureUtils didn't exist at that point, so I am considering how to consolidate this type of logic as we keep repeating this type of non-trivial code and it is easy to get wrong. I'm okay with merging ... we really should spend some time figuring out the core patterns so we can encode the state machine, similar to what BackpressureUtils and AbstractOnSubscribe have started formalizing.
BackpressureUtils didn't exist at that point, so I am considering how to consolidate this type of logic as we keep repeating this type of non-trivial code and it is easy to get wrong. I'm okay with merging ... we really should spend some time figuring out the core patterns so we can encode the state machine, similar to what BackpressureUtils and AbstractOnSubscribe have started formalizing.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
As discussed in the JIRA, I still think we should use `FileChannel.open`.
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
I believe the goal is to use constant-time comparison to prevent timing attacks, hence the walk through the arrays.
> At the moment, I am leaning toward the latter. In any case, I suggest we let the errors propagate for now and file a jira to reconsider once we are closer to integration. Does that sound fair? Sounds fair to create a Jira and revisit this later.
`endOffsets.get(topicPartition)` can be replaced by `offset`
Rather than having `try{...} finally` everywhere it might be better to keep track of the locked `TaskId` and unlock them in the `cleanup` method.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
`endOffsets.get(topicPartition)` can be replaced by `offset`
How about this? ```java // The consumer fetch position needs to be restored to the committed offset before the transaction started ```
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
```suggestion @Evolving public class WindowRangeQuery<K, V> implements Query<KeyValueIterator<Windowed<K>, V>> { ```
```suggestion @Evolving public class WindowRangeQuery<K, V> implements Query<KeyValueIterator<Windowed<K>, V>> { ```
nit: could be set to final and refactor as: ``` final Integer partition; if (partitioner != null) { final List<PartitionInfo> partitions = producer.partitionsFor(topic); if (partitions.size() > 0) { partition = partitioner.partition(topic, key, value, partitions.size()); } else { throw new StreamsException("Could not get partition information for topic '" + topic + "' for task " + taskId + ". This can happen if the topic does not exist."); } } else { partition = null; }
nit: could be set to final and refactor as: ``` final Integer partition; if (partitioner != null) { final List<PartitionInfo> partitions = producer.partitionsFor(topic); if (partitions.size() > 0) { partition = partitioner.partition(topic, key, value, partitions.size()); } else { throw new StreamsException("Could not get partition information for topic '" + topic + "' for task " + taskId + ". This can happen if the topic does not exist."); } } else { partition = null; }
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Do we want this to be `error` or `warn`? Maybe `error` is right, so take this as a question. :)
It's a bit unconventional to have abort logic at the start of the loop. I think what users would expect is something like this: ```java try { producer.beginTransaction() producer.send(...) producer.sendOffsetsToTransaction(...) producer.commitTransaction() } catch (Exception ) { producer.abortTransaction() } ```
nit `getMetadata` -> get`
nit: add a size? There are a few cases in here where we could do this.
will break if `item` is `None`.
Nit: var should be named `deserializeValue`
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Also not clear why "numSegments - 1" here.
We need to keep the old method as before and deprecate.
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
ð fair enough
I think this way of triggering the exception is not only complicated but it even might be a source of flakiness. Could we have some more straightforward? I think the original solution (overriding getResponse) was better than this.
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
`os.chmod` should be before the `try`. It doesn't make a big difference but that's the common pattern in general.
Would `isUnknown` be clearer? I find that boolean methods without any prefix feel a bit ambiguous when reading them.
Would `isUnknown` be clearer? I find that boolean methods without any prefix feel a bit ambiguous when reading them.
nit: would be nice to be consistent on the pattern we use here
would `RECORD_TRANSFER_MAX_DURATION` be a better name here? `RECORD_MAX_DURATION_MS` seemed to indicate that we are recording the max duration.
Also not clear why "numSegments - 1" here.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
This should go away. `@ConditionalOnClass` already does that.
nit: style seems to be to not include braces when there is only one if or else statement
the `try{...} finally` has been removed
I guess both are acceptable solutions (ie, creating two repartition topics or throwing an exception). Your proposal is more user friendly but results in a more expensive deployment. The question might be, what do we try to optimize for? \cc @vvcephei @guozhangwang
I guess both are acceptable solutions (ie, creating two repartition topics or throwing an exception). Your proposal is more user friendly but results in a more expensive deployment. The question might be, what do we try to optimize for? \cc @vvcephei @guozhangwang
We no longer need `DEFAULT_OUTPUT_TOPIC_NAME` if all caller will use `createTopic` now
Maybe a cleaner approach is to provide two separate `Logger` implementations.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
Can you please fix this output too -- the tool does "seek to beginning" and does not set offsets to zero.
Can you please fix this output too -- the tool does "seek to beginning" and does not set offsets to zero.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Also, it seems like using a default of `PluginType.UNKNOWN` here might be suboptimal. If someone wants to the view the config for a REST extension, for example, they'll end up seeing an error message later on (in `AbstractHerder::connectorPluginConfig`) that says something like "Invalid plugin type unknown. Valid types are..." I think it'd be clearer to users if we could differentiate between these two cases: 1. User requests config for a plugin that does exist on the worker, but which we don't expose config information via the REST API for (such as a REST extension or a config provider) 2. User requests config for a plugin that doesn't exist on the worker Status-wise, In the case of 1, a 400 response probably makes sense, but for 2, a 404 response might be more applicable.
Could we try to avoid this copying if we assume it always wraps an array? I.e. ``` if (data.hasArray) return data.array(); ``` My syntax may not be perfect, and we need to double check the starting and offset in the backed array, but the general idea is as above.
Same question here about just using a static ConfigDef instead of a static method.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Same question here about just using a static ConfigDef instead of a static method.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
IMO the representation of session should be modeled with more care considering the needs of potential consumer: - `creationTime` and `lastAccessedTime` should be converted to `Date` - is `maxInactiveIntervalInSeconds` really needed here? - consider providing at least _some_ info about session attributes
nit: use `assertThrows` instead of try-fail-catch construct.
It should be public as it will be used in `producer` APIs.
I just mean, why not inline that? I'm just imagining coming back to this code in a few months and wondering why we need to suspend a task before recycling, or why we call `prepareCommit` but don't then actually commit, etc
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
Technically this sets the proper value for `url` but it's doing so twice. s/url = url/url/
Technically this sets the proper value for `url` but it's doing so twice. s/url = url/url/
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think this way of triggering the exception is not only complicated but it even might be a source of flakiness. Could we have some more straightforward? I think the original solution (overriding getResponse) was better than this.
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
This seems to be safely handling unsubscribe by doing it in the right thread so 'unsubscribeOn' is not needed.
This seems to be safely handling unsubscribe by doing it in the right thread so 'unsubscribeOn' is not needed.
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
Same question here as earlier about the `Locale`
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
It'd be better to not change these lines, because we don't intend to change the logic -- yet doing so adds risk and increases the size of this PR.
Remove double blank.
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
I'm wondering if we should use `CommitFailedException`. In the consumer, we do not expose illegal generation and unknown member id errors directly to the user.
It's intentional to avoid build warnings about importing deprecated classes.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
we should not use Java keyword `assert` but Junit `assertXXX` methods (`assertEquals` for this test)
Not sure we need the while loop since it waits for a day at least.
I think for calling methods single line is fine. But for defining method, we should always go with one parameter per line.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Seems like we should use `3L` instead. The leader would not have been able to advance the high watermark past the fetch offset of `3L`.
We only applied for `ElementType.METHOD`, so `ElementType.ANNOTATION_TYPE` can be removed.
Nit: the method is `Transformation.close()`, not "stop". The log message should probably reflect that.
Nit: the method is `Transformation.close()`, not "stop". The log message should probably reflect that.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
We only applied for `ElementType.METHOD`, so `ElementType.ANNOTATION_TYPE` can be removed.
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
nit: if you use `Utils.mkSet`, then you won't need the conversion below.
I was mostly trying to get rid of the word `Node` because it's a bit redundant when you look at the log messages.
Should we restrict the values for name and version? Maybe we can just test that they are non empty? nit: the non-capture group isn't really necessary and this regex matches stuff like `"."` and `"---"`.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
As above: add more "randomness"
Do we need the if/else? Since this is a unit test, it seems OK to just assert that the first element is the rate and the second is the total.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
This should be done in the SSL class. The base class should not be aware of SSL and just use configurations from the concrete classes
`hasItem(task01)` -> `equalTo(Collections.singleton(task01))`
You can just do i+=2 in the for loop.
Ack. Was not sure if it's an intentional change. Thanks for clarifying that it's an actual fix.
It would be nice to have a unit test for this.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
Is calling `c_uint()` redundant as well? https://github.com/django/django/blob/b0d16d0129b7cc5978a8d55d2331a34cb369e6c7/django/contrib/gis/geos/polygon.py#L93
nit: add a space before the `:`.
i.e., add `fail` after this line
Wrong signature of `aggregate(...)`.
nit: There is an extra space before `+`.
```suggestion content = to_text(response.read(), errors='surrogate_or_strict') ```
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: unneeded newline
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
This should go away. `@ConditionalOnClass` already does that.
nit: add a size? There are a few cases in here where we could do this.
Do we need this methods? Maybe I'm missing sth but thread's database connections should already by overridden, and we don't pass `connections_override` to the `_create_server()` anywhere in Django :thinking:
There is a race here. If `run()` gets here and `onNext` is fired, throttling will be disposed and the `onNext` value gets emitted. Here then the cached value gets emitted as well and now there are two tasks delayed for the subsequent interactions.
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
There is a race here. If `run()` gets here and `onNext` is fired, throttling will be disposed and the `onNext` value gets emitted. Here then the cached value gets emitted as well and now there are two tasks delayed for the subsequent interactions.
We can use `new ProducerRecord<>(topic, "value");` to simplify it a tiny bit
Should be more precise. See discussion about `HoppingWindow` and `TumblindWindow` in #1250
Should be more precise. See discussion about `HoppingWindow` and `TumblindWindow` in #1250
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
I think we should call `deserializer.close()` here
Nit: remove unnecessary `this`.
Dropped this unnecessary duplicate code, as we discussed.
Dropped this unnecessary duplicate code, as we discussed.
If we reuse shared streams instance do we still need try-catch here as the `cleanup()` should close streams.
Hmm, seems like you forgot to remove the `remainingMs` in the `while` condition.
There is already a property in `MustacheProperties` (in the parent class, actually).
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
@junrao, that's an interesting suggestion. If we do that, various `if (buf.hasRemaining())` checks in some of the callers no longer make sense.
typo: byteArrray -> byteArray
nit: Indicate that this needs shallow iterations on the entries.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
You need to close the `Connection`.
remove try-catch and replace with: ``` final StreamsException s = assertThrows(StreamsException.class, () -> testDriver.pipeInput(consumerRecord)); ``` assert afterwards and don't re-throw.
There is already a property in `MustacheProperties` (in the parent class, actually).
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
nit: if you use `Utils.mkSet`, then you won't need the conversion below.
nit: if you use `Utils.mkSet`, then you won't need the conversion below.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Hmm.. I think the original logic made more sense. Even if `completeExceptionally` returns false, it's still an error, right? We would not want to then proceed to `future.complete` or the next operation.
This ignores the input `value` and always returns the value of the `spring.mustache.formatter.value` property.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
You need to close the `Connection`.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
This ignores the input `value` and always returns the value of the `spring.mustache.formatter.value` property.
Instead of doing this, we can simply override `toString` in each enum. However, if we go with my suggestion of renaming the enum values, the `toString` will be the right one by default, I think.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
s/Consumer/The verifying consumer
As above: add more "randomness"
nit: add a size? There are a few cases in here where we could do this.
Can we also rename `StreamsGraphNode` to `GraphNode`? The `Streams` prefix is a bit confusing, IMO, because `StreamSourceNode` and `StreamsGraphNode` seem really similar although they are quite different.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
prop: Could we pass into `getMovements()` the number of warm-up replicas and only compute as many movements as needed instead of computing all movements and then using just the first couple of movements.
This won't log the error. We want to use the `public void error(String msg, Throwable t);` overload, so we need to change `e.getMessage()` -> `e`
There is a race here. If `run()` gets here and `onNext` is fired, throttling will be disposed and the `onNext` value gets emitted. Here then the cached value gets emitted as well and now there are two tasks delayed for the subsequent interactions.
Did you mean: ```suggestion setBrokerId(2). setBrokerEpoch(100). ```
If you only have `file.setWritable(true, true)` then the directory will still be writeable by non-users, I assume? I actually don't know the details of the `File#setXXX` methods -- but we don't want it to be writeable by just anyone. Should we instead do something like ```suggestion set &= file.setWritable(false) && file.setWritable(true, true); ```
You should use `assertThrows` instead. Otherwise we need a `fail` after `close()` to make sure we actually raise an exception.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
If you only have `file.setWritable(true, true)` then the directory will still be writeable by non-users, I assume? I actually don't know the details of the `File#setXXX` methods -- but we don't want it to be writeable by just anyone. Should we instead do something like ```suggestion set &= file.setWritable(false) && file.setWritable(true, true); ```
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Yes, this should on an internal package (eg `common.internals`).
Do we really want anything related to internal topics to be client side? This could change in brokers from version to version and the clients should still work. I understand that for now we have no way to get that information, but we will soon (KAFKA-3306). I imagine removing the client side list would be part of the cleanup once thats available. So whatever exists in the mean time should be private so we don't need a deprecation cycle.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Exception message doesn't look right (the word "list").
I said it incorrectly before, and I actually meant that you can use `org.apache.kafka.test.NoOpKeyValueMapper` in this case as we do not really care about what aggregate key / value to use. Your proposal is also fine, while I was just trying to reduce duplicated code :)
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
`2` -> `entries.size() - 1`
Alternatively, we could make this method idempotent. Seems like we only call it from `ensureHasBookkeeperEntry` anyway.
`2` -> `entries.size() - 1`
Please use static imports to make this more readable.
This is the default.
It's a sample application so I don't think the performance argument applies here.
No, what I was suggesting is to add synchronization to the methods inside `Heartbeat` itself. For example: ``` public synchronized long timeToNextHeartbeat(long now); ```
nit: move to line above.
nit: There is an extra space before `+`.
We can pass the serializers in the constructor and it's a bit more concise.
We can pass the serializers in the constructor and it's a bit more concise.
the ```length``` is neglected
nit: add `final`
Just wanted to say I really like the way this unit test is written! With the right usage of mocks we would avoid having any time-dependent flakiness.
nit: curious why `storeType` is not enum but raw string. Typo in `in_memory` could make it `ROCKS_DB` type. e.g. `in_memry`. Maybe it's register in `in(ROCKS_DB, IN_MEMORY),` when defining and checked there
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
This is a weird line break. It would be better to shorten the line by assigning the result of `mapper.apply` to a variable.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
rewrite test as above using `assertThrows()`.
Better to use `determine_ext` instead of `.endswith`
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
I think it is better to throw if the passed in exception handler is `null` and set the default uncaught exception handler in the `StreamThread` constructor.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
nit: remove `this` (not required)
SGTM. If we find it flooding the logs and not helpful we can reconsider
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
OK, will remove before merging.
This is a very confusing method. There is a risk that it may be invoked inadvertently when making changes, even though it is meant to be only for tests.
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
always what? I can't even :)
The number has changed and 5 is no longer relevant.
always what? I can't even :)
always what? I can't even :)
always what? I can't even :)
Here too it seems like we can use the generic version of `prepareOffsetCommitResponse`.
@cmccabe Looks like the log entry hasn't been updated.
This is also an existing issue. We set the ISR here, but it can be overridden to targetIsr in tobuild() later.
@cmccabe Looks like the log entry hasn't been updated.
@cmccabe Looks like the log entry hasn't been updated.
We can use a separate ticket to centralize these helper functions into `org.apache.kafka.test.TestUtils`, would you mind filing a JIRA? Example functions like `getProducer/Consumer/StreamsConfig`, etc.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
We can use a separate ticket to centralize these helper functions into `org.apache.kafka.test.TestUtils`, would you mind filing a JIRA? Example functions like `getProducer/Consumer/StreamsConfig`, etc.
Can we use something like `TestUtils.waitUntilTrue`? This approach will make tests unnecessarily slow.
Can we use something like `TestUtils.waitUntilTrue`? This approach will make tests unnecessarily slow.
@cmccabe Looks like the log entry hasn't been updated.
Can we use something like `TestUtils.waitUntilTrue`? This approach will make tests unnecessarily slow.
Remove double blank.
nit: remove empty line
Code convention nitpick: there should be a space before the colon.
Code convention nitpick: there should be a space before the colon.
same here. let's make all method params as `final`
nit: `null` -> {@code null}`
Also not clear why "numSegments - 1" here.
same here. let's make all method params as `final`
I'd also consider removing this one too if we are not using it.
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
nit: some extra newlines here.
Updated this when merging.
I know we're violating this a few places (due to the initial code import), but I think we want to avoid converting to `*` imports.
Updated this when merging.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Sorry, a typo here. The return value should be parent.
```suggestion // TODO K9113: this is used from StreamThread only for a hack to collect metrics from the record collectors inside of StreamTasks ``` Just marking this for later follow-up.
Can we also assert that the state gets to `RUNNING` after the new thread has joined
We can use the `replace` overload that takes a `char`.
We can use the `replace` overload that takes a `char`.
I don't know what has changed here.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
I don't know what has changed here.
What's the purpose of this warning? It doesn't seem needed.
Ditto here, we should retain some version of this test and any others that are specifically intending to test the behavior of the old API (until the deprecation period has elapsed and we can remove it)
i.e., add `fail` after this line
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
nit: 'else' can be dropped
nit: braces unneeded
Why did you change this to a `Set`? It seems unrelated to the ticket.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
Technically this sets the proper value for `url` but it's doing so twice. s/url = url/url/
Think you might have forgotten to remove some debugging here
We should add a `null` check to allow closing a deserializer that was not properly setup
nit: braces unneeded
Hmm.. It just doesn't seem worth optimizing for. Processing the partition data means what? Looping over it and checking if error is NONE? Does it matter if we do that twice? We could also just leave off the `hasPartitionErrors` and do a single iteration and raise the error on the first exception.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
I see. There may not be a nice way to wire in the thread id from a static context. If we can't get the thread id, I'd suggest accepting the change here so that at least the message points to the right file.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
I don't think this will work, will it? You should specify the topics that you want metadata about. If you specify an empty list, no topic info will be returned.
Should we also check that ``` final long start = SessionKeySerde.extractStart(bytes.get()); final long end = SessionKeySerde.extractEnd(bytes.get()); return end >= from && start <= to; ``` Although the current impl of RocksDBWIndowStore naturally checked that for us, it does not guarantee all underlying store impls guarantee that.
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
Maybe we can use `setIfExists`.
should this be null? perhaps throw an IllegalArgException
should this be null? perhaps throw an IllegalArgException
You might consider using `OptionalDouble`.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
This should go away. `@ConditionalOnClass` already does that.
This should go away. `@ConditionalOnClass` already does that.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
This isn't a REST extension necessarily, right? It's also used by Kafka via JMX. I think mentioning `worker restarts` and `rest extension` might be confusing
If we start from scratch then maybe these would be better be in `state`, but they have been added to `processor` and moving them would be incompatible changes. So I'm more concerning about the newly added classes.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
```suggestion /** * Metadata of a task. */ ```
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Do we need the if/else? Since this is a unit test, it seems OK to just assert that the first element is the rate and the second is the total.
typo: byteArrray -> byteArray
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
`name()` -> `wrapped.name()`
We can use `new ProducerRecord<>(topic, "value");` to simplify it a tiny bit
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
nit: There is an extra space before `+`.
we can use `TestUtils.assertFutureThrows()` here too
This is unnecessary.
This should also use UTC now. The test should used a fixed year and find a way to mock `parse_http_date`'s way of obtaining a current year.
I fixed this one to use the constant before merging.
I fixed this one to use the constant before merging.
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
We shouldn't return `null`, but instead return a "unknown query" result.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
We shouldn't return `null`, but instead return a "unknown query" result.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
// It shouldn't affect the comparison though since loop is present in both Flowable and Observable benchmarks
If there are multiple FatalExitError thrown, do we want call `System.exit()` only once instead of creating a thread for each of them? Maybe we can just log the error and return.
Nice coverage with different num.partitions, thanks!
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
Is this constructor used at all? If not, I'd not include it one should generally provide a message explaining more.
Is this constructor used at all? If not, I'd not include it one should generally provide a message explaining more.
No need to talk to a mocked observer, TestObserver.assertEmpty() already verifies these.
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
nit: We could use `singletonMap` here.
IMO, this string should give details when the condition is not met, like `stream thread has not been added`. Same applies to the other wait conditions.
nit: We could use `singletonMap` here.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
If the whole module was added starting from v2.4, you do not have to add that to every option. The options only required a specific `version_added` when the options have been added in a newer release.
Maybe there is an easier way, but I found the following: Set the config to: ``` final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.singletonMap("test", "property")); ``` and then check it: ``` internalTopologyBuilder.buildSubtopology(0); assertThat(internalTopologyBuilder.stateStores().get("store-this-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.stateStores().get("store-other-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); for (final InternalTopicConfig config : internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.values()) { assertThat( config.getProperties(Collections.emptyMap(), 0).get("test"), equalTo("property") ); } ``` Without ``` assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); ``` the test would pass without checking the config if `buildSubtopology()` is not called because no changelog topics would be registered in the topology. So it basically checks that `buildSubtopology()` is called.
This exception is no longer possible since the constructor is taking `ObjectName`.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: add `final` (same below)
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
Also, I think in the exception thrown if `configEntries == null` should mention whether the system property is set or not as this would be helpful for people who thought it was set.
Sorry, I thought the URL could be used to provide the username and password.
Nit: too many blank lines.
Ah, my bad. I think the variable I had in mind is actually called `Double.BYTES`. Not 100% sure it's defined for all possible primitive types, but I would hope so
You actually do not need `this` here, right? The values are the default initialization values in Java. And `super` is also called in the default constructor. So actually, you could remove this constructor completely.
`info.getProperty(â¦)` can return `null` when using `redisNode.asString()` because of the execution of the `INFO` command. `INFO` is executed only on master nodes, not on slaves. `clusterGetNodes()` returns all nodes. Passing `null` into `withDetail(key, value)` leads to an `IllegalArgumentException`. I'd not put too much knowledge about cluster execution in here but rather iterate over the `info` keys (e.g. filter on suffix `"." + VERSION`) and use the keys from `info` to retrieve data. I'd also propose adding nodes as list to the Redis info as topology details are valuable in a health indicator.
We don't need to delay the error ... just emit it and skip everything else. We confirmed this behavior in `observeOn`: https://github.com/ReactiveX/RxJava/issues/1680
Thanks for double checking this! Then it lgtm.
We don't need to delay the error ... just emit it and skip everything else. We confirmed this behavior in `observeOn`: https://github.com/ReactiveX/RxJava/issues/1680
I just read through `MemoryLRUCache`. It is not thread-safe and will corrupt itself because a read causes a mutation of the LRU history. (I made the same mistake early in my career when fixing performance problems leading to exploring caching in-depth, so its an easy oversight to make) A read/write lock is a very expensive mechanism and most often the incorrect lock type to use. For short critical sections it is more expensive than an exclusive lock. By using a `ReentrantLock` or `synchronized` you'll have both correctness and higher performance. As is, I strongly urge you to correct this before merging. You don't have to use a caching library, but the code is very broken.
nit: "failed on partition being lost {}" -> "failed on invocation of `onPartitionsLost` for partitions {}"
What happens if `millisRemaining` is, say, 2 and `retryBackoffMs` is 1000? If `millisRemaining` is positive, then shouldn't we sleep for the smaller of `millisRemaining` or `retryBackoffMs`? IOW: ```suggestion Utils.sleep(Math.min(retryBackoffMs, millisRemaining)); ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
Just use ` and ...` instead of nesting. Less indentation == better readable.
`downstream` is a bit confusing: Found the child node of the key changer {} from the repartition {}.
SGTM. If we find it flooding the logs and not helpful we can reconsider
I think we should call `deserializer.configure(...)` here
There a two independent configs for the list-type and inner-type, hence it might be better to handle both independently: ``` if (listClass == null) { String listTypePropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_DESERIALIZER_TYPE_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_DESERIALIZER_TYPE_CLASS; listClass = (Class<List<Inner>>) configs.get(listTypePropertyName); if (listClass == null) { throw new ConfigException("Not able to determine the list class because it was neither passed via the constructor nor set in the config"); } } if (inner == null) { String innerDeserializerPropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_SERIALIZER_INNER_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_SERIALIZER_INNER_CLASS; Class<Deserializer<Inner>> innerDeserializerClass = (Class<Deserializer<Inner>>) configs.get(innerDeserializerPropertyName); inner = Utils.newInstance(innerDeserializerClass); inner.configure(configs, isKey); } ```
I think we should call `deserializer.close()` here
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
We need to remove this too, right? We shouldn't forward anything regardless of whether it's a left join, if the mapped key is null then there's nothing to map it to
Private and call from the constructor? We only ever call this immediately after instantiating the class.
The logic here is a bit over-complicated to me, can we simplify to sth like standard sort-merge here? We have e.g. `AbstractMergedSortedCacheStoreIterator` for a similar pattern.
Hmm.. is this correct? If `forward(kv)` is called without childName or childIndex, it means sending to all children. So should this be `capture.childName == null || ...` ? Ditto above in line 414.
Here too it seems like we can use the generic version of `prepareOffsetCommitResponse`.
Here too it seems like we can use the generic version of `prepareOffsetCommitResponse`.
Hmm, it was moved outside of the `stateLock` for this reason: https://github.com/apache/kafka/pull/3622#discussion_r131438053
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
Shouldn't this be a config exception? It is not really invalid partitions.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
It looks like we don't support mixed mode testing. That seems worth a follow-up JIRA. It is definitely an interesting case from the perspective of the raft implementation since it involves two listeners.
@wicknicks would be useful to have some unit test for this class.
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Ditto about `no_color=True`
`before or after`
Yeah this is observed in another PR review, and should be fixed by now. cc @dguy
nit: add `final` (2x)
@SinghAsDev Since KafkaConsumer has only one thread, even scheduled tasks have to be executed in that thread, which means the user has to wait for them. Since you can't really control when the tasks will be executed, in the worst case, it could turn a non-blocking call into a blocking one. And I don't see why error handling can't be handled asynchronously. For updating regex subscriptions, I wouldn't think it too much of a big deal even if we just ignored failures and waited for the next metadata update, though it would be easy to implement retries with backoff (I think we do this for heartbeats already).
nit: braces unneeded
req: I think we want to introduce some `acceptableLag` config within which a task is considered caught-up, otherwise this is way too strict. ie the condition should be `lag <= acceptableLag`
Maybe we could use a different value here.
We should limit this suppression to the method for which we really need it instead of the whole class
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Nit: please add `final` to all local vars and method parameters
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
This is assuming that `totalTopics` is always a multiple of `MAX_BATCH_SIZE. Is that always true? Perhaps it is better not to make that assumption in any case.
I fixed this one to use the constant before merging.
That's not needed, it's automatically detected.
Maybe we can have a numRecords variable for the `100`.
I think we should call `deserializer.close()` here
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
This is not part of the KIP any longer
I think we should call `deserializer.close()` here
nit: add `final` (same below)
Good point! @vpapavas , can you handle stuff like this in a follow-on PR? I'm doing a final pass to try and get this one merged.
Not something we have to do here, but one way we could improve this in the future is by taking into account leader epoch information from individual partitions. We can ensure that epochs increase monotonically in order to prevent using stale information during retry. Another thing we could do is reduce the topics we are fetching metadata for as the ListOffsets requests complete. Ideally we'd only be refetching metadata for topics with metadata errors.
It would be good to have constants instead of hardcoding the fields in many places.
AK convention is to not use `set` setters or `get` getters.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
nit: drop reference to consumer groups
nit: drop reference to consumer groups
Good point! @vpapavas , can you handle stuff like this in a follow-on PR? I'm doing a final pass to try and get this one merged.
AK convention is to not use `set` setters or `get` getters.
Not something we have to do here, but one way we could improve this in the future is by taking into account leader epoch information from individual partitions. We can ensure that epochs increase monotonically in order to prevent using stale information during retry. Another thing we could do is reduce the topics we are fetching metadata for as the ListOffsets requests complete. Ideally we'd only be refetching metadata for topics with metadata errors.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I was looking up the format in more detail and understand now what going on. The code does not seem to be ideal IMHO, but no need to change it in this PR.
nit: no need to hyphenate unrecognized.
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Let's remove the brace changes please.
Is ignoring the right answer? Would it be better to fail fast? If not, at least a warning should be logged.
It'd be better to not change these lines, because we don't intend to change the logic -- yet doing so adds risk and increases the size of this PR.
nit: it was correct before
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
In line 126 above, maybe we can just call `e.toString` which will include the message string if it contains? otherwise LGTM
May as well cull the sysout to reduce test noise
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Not sure you need to initialize the factory every time there.
I don't think this is necessary. The overriden method does this: ```java public URI getURI() { try { return getURL().toURI(); } catch(Exception e) { throw new RuntimeException(e); } } ```
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
A `if (clean)` should be sufficient now
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Nit: var should be named `deserializeValue`
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I think this says, "we are looking for a parent node that is among my parent nodes". It seems like we can generalize this logic by not assuming there's a single parent node at all.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
Same question here as earlier about the `Locale`
Why do we need to update the configs? By using seeks we can simply ignore the underlying configed value right? More specifically, as done below we can check if `consumer.committed` returns anything or not, and if no AND the reset policy is specified, we just use seeks to the specified positions.
Yea, my suggestion would be to reuse the existing constructor as the construction of the `AlterConfigsResponseData` seems non trivial for a caller to do, compared with passing a map of errors.
I was going to ask why we're using the `test` prefix for a benchmark, but then I realized that many of the kafka benchmarks do that and I somehow didn't notice. :) Given that, it seems fine to leave it like this for now.
set the type to list then
set the type to list then
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
nit: remove empty line
base -> based progress -> progressed
and -> a
base -> based progress -> progressed
Good point! @vpapavas , can you handle stuff like this in a follow-on PR? I'm doing a final pass to try and get this one merged.
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
Seems that this class is a bit redundant, i.e, we could just construct an `AssignedTasks` with the `logContext` and `"standby task"`
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
nit: unneeded newline
I vote yes for this. I think if we use this for writing snapshot from the state machine, then minimum size is a more interesting metrics for flushing to disk vs lingerMs. If we implement this so that either one has to be true then the client can set the `lingerMs` or `minSize` to MAX_VALUE if it wants to ignore those values.
nit: we can do without the curly braces here and above. However, these will soon be replaced by the actual impl
Can this be a `byte`.
Can this be a `byte`.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
nit: add `final` (same below)
nit: add `final` (same below)
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
nit: What about extracting the construction in a small helper method `prepareDescribeLogDirsResponse` that create a response for one LogDir and TopicPartition? It seems that the same block of code is used in many tests.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
"*" is considered "LITERAL" for compatibility reasons
We should wait for the new stream thread with a timeout, otherwise we risk that this test may become flaky.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
This changes behaviour as any exception from the `close()` call will no longer be caught and logged as a warning.
As an alternative, which might align better with Kafka in general, would be to set the timeout via `StreamsConfig`. This keeps the API clean. @enothereska argument that `close()` should not have any arguments is quite valid to keep APIs consistent within Kafka.
We can try that -- but we need to reduce `HEARTBEAT_INTERVAL_MS_CONFIG`, too, for this case -- its default is 3 seconds and it must be smaller than session timeout. Checking some existing tests, we have some that set them to 500ms / 1sec. Some other test reduce session timeout to 2 or 5 seconds...
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Not introduced in this patch: "is non" => "as non"
Not introduced in this patch: "is non" => "as non"
Do we want a `ConnectException` here instead? Not sure.
Do we want a `ConnectException` here instead? Not sure.
Do we want a `ConnectException` here instead? Not sure.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
remove empty line
I think, we should use three different values to make sure that the different prefixes overwrite the configs for the corresponding clients. Looking into the test below, they seem to be redundant with this one? We can also remove this test and keep the other three (that would avoid redundancy, too)
unnecessary type in constructor, can use `new HashMap<>()`
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
This line fails in the build and needs a fix.
We use to log all leader and isr changes in info even for clean leader election.
I believe the messages is in correct - it is the whole partitions for which any offsets are not committed. `log.warn("Synchronous auto-commit of offsets for partitions {} will be abandoned", toGiveUpTopicPartitions);`
I think, we should use three different values to make sure that the different prefixes overwrite the configs for the corresponding clients. Looking into the test below, they seem to be redundant with this one? We can also remove this test and keep the other three (that would avoid redundancy, too)
We use to log all leader and isr changes in info even for clean leader election.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
We use to log all leader and isr changes in info even for clean leader election.
We should probably change the exception class here since `ConfigException` takes a config name and value while this one is passing in the exception message and cause like other exception constructors. Then existing log entry would be sufficient as well.
Could we also move this only to the `StreamTask`? Doesn't have to be in this PR.
It seems ```exitProcedure``` and ```haltProcedure``` can be local variable
Yeah, sounds good. And as we discussed offline, maybe we could even go as far as constructing the taskIds inside the ConfigBackingStore: ``` java public void putTaskConfigs(String connector, List<Map<String, String>> configs); ``` This would save the need to do the taskId verification step, though I'm not sure if there was a good reason to keep taskId generation within the Herder implementations.
I would keep this public method -- it can just create a consumer and call `private readValues`. Same for `readKeyValues()`
Isn't it true that most of the time this method will get only supported `Callback` implementations? In those cases, we'll never need the `unsupportedCallbacks`. I originally thought it might be worth making this more efficient, but I don't think it's worth it since the default constructor for `ArrayList` is pretty efficient in recent JVMs (with lazy allocation of the underlying array when the first element is added to the list).
Note that the `getPort(url)` call a few lines above can fail with a `NumberFormatException`, so we probably need to put that inside the `try`.
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
nit: ... suspended task is not reassigned
This changes behaviour as any exception from the `close()` call will no longer be caught and logged as a warning.
Good catch. It's probably too late to change that though.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
I think this should only be done after the store is in a valid state, i.e, after restore. Otherwise there is a chance we can try and query or write to the store before it is ready
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
I've found that avoiding using anything related to the type of a variable in its name is usually for the best. It takes a few more seconds to come up with an appropriate name, but it definitely pays off when reading, and even in generic uses as this one here it's still better IMO. E.g. I'd call this at least `chain` or something.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: add a size? There are a few cases in here where we could do this.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Do we want to always enforce "latest" for AUTO_OFFSET_RESET_CONFIG? I think there are some cases where a user may want to consume from earliest.
This line fails in the build and needs a fix.
Instead of adding headers each time, maybe we can pre-create the headers list and pass to ProducerRecord() constructor.
ditto on removing before/after.
Can we move the whole `data` setup into `items`? 🤔 ```suggestion def items(self): o1 = TestModel() o1.lastmod = datetime(2013, 3, 13, 10, 0, 0) o2 = TestModel() o2.lastmod = datetime(2014, 3, 13, 10, 0, 0) return [o1, o2] def lastmod(self, obj): return obj.lastmod ``` (Getting rid of the dict lookup step.) (🤷‍♀️)
Please get rid of this volatile. There is no longer a circular dependency here.
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
Please get rid of this volatile. There is no longer a circular dependency here.
Seems to be covered by `shouldAssignMultipleReplicasOfStandbyTask()` already
nit: add `final`
> it doesn't seem particularly beneficial It seems to me the benefit is the error happens from runtime/test_runtime to build time (generate message code).
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
```suggestion * is {@code null}, no records are emitted. ``` Please also fix this on the original method
At a high level, our store ecosystem looks like an onion. On the outside, we have a <K,V> store, and on the inside, we have a <bytes,bytes> store. All the layers in between have different responsibilities, like changelogging, caching, add metrics, etc. The nice thing about this PR is that it gives us one clean layer that's responsible for the transition `<K,V> <=> <bytes, bytes>`. When we need to look at the de/serialization into/out-of the stores, we have exactly one place to look. The prior code did mostly this, but to accommodate cache flushing in conjunction with the fact that the cache layer is below the transition from objects to bytes, we had to poke a hole in the onion and tell the caching layer (a bytes layer) how to deserialize. So, then there were two layers that independently know how to de/serialize, and the onion had a hole in it. This idea to move the serialization out to the TupleForwarder is basically the same, but in the opposite direction. Again, there are two components that need to perform serialization (the serialization layer and the tuple forwarder), and again, we need to poke a hole in the onion so that the tuple forwarder can communicate directly with an inner layer. It's not always practical to go for a "pure" design, but if readability is the goal, then it seems like we should try to avoid mixing layers, unwrapping layers, etc. as much as possible. To be fair, this is just my take on the situation.
nit: should be `Deserializer<?>` to avoid warnings about using a raw type
Seems as if this refactor hasn't been updated on the PR
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
I could not find any unit tests for this method.
we are not using getters and setters. I think this should be named as serviceName
We can use `TestUtils.assertFutureThrows()` here too
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: should be removed (similar below)
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Should be AtomicInteger (see explanation below)
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Nit: somehow I don't like `blah`. Otherwise LGTM
Nit: somehow I don't like `blah`. Otherwise LGTM
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
What's the purpose of this warning? It doesn't seem needed.
What's the purpose of this warning? It doesn't seem needed.
Hmm, why did we do this? I thought we'd have a try/catch block.
What's the purpose of this warning? It doesn't seem needed.
+1 for consistency
The implication here is that wakeup won't work if you've fetched data and keep calling poll() when you have max records set small, right? This seems like it could be a problem for anything that takes a long time to process messages since the wakeup may be an indicator that the application needs to shutdown...
It's not really clear to me why we need a test case with two consumers.
Let's check that `previouslyAllocated`'s capacity is `batchSize` else `buffer.limit(sizeBytes)` is going to throw with a less useful stacktrace.
Missing newline character.
nit: add `final` (same below)
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
req: drop the `!caughtUpClients.isEmpty()` check here, if it's in the map it should have at least 1 caught-up client
nit: 'else' can be dropped
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Nit: somehow I don't like `blah`. Otherwise LGTM
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
We don't need this for files, right? Just for directories (because of `file.deleteOnExit`)
We should update the Scala `TestUtils` to call this method.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
This was probably left by mistake.
Do we need to do this for so many stores? i think 2 would be sufficient as the test becomes quite noisy and it is difficult to see the intent
debug line should be removed.
This shouldn't be possible, right? It wouldn't make much sense to put a topic in the result if it didn't have a corresponding `TopicListing`.
This shouldn't be possible, right? It wouldn't make much sense to put a topic in the result if it didn't have a corresponding `TopicListing`.
nit (sorry): seems ungrammatical when the error message is appended. How about this? ``` "Expiring " + recordCount + " record(s) for " + topicPartition + ": " + expiryErrorMessage) ```
nit (sorry): seems ungrammatical when the error message is appended. How about this? ``` "Expiring " + recordCount + " record(s) for " + topicPartition + ": " + expiryErrorMessage) ```
Opened a minor PR: https://github.com/apache/kafka/pull/8250 (let me know what you think)
Just one minor point, if we don't have EOS enabled, we could end up pulling duplicates in some tests like the `StreamsUpgradeTest::upgrade_downgrade_brokers`
Do you want to pass in `autoAdvanceMs` for record creation? Default is zero.
Nit: every conditional needs to have braces (per the code style) not nit: I find this logic a little difficult to follow. Contrary to what @mjsax suggested, wouldn't it be pretty straightforward to map the old semantics on to the new ones like this: * negative numbers => 0 * 0 => Long.MAX_VALUE * all other arguments stay the same ? Then, the old close method could just transform its arguments and call the new method, with no need to have this "new semantics" flag and an early return in the middle of the loop.
req: This is unnecessary
req: This is unnecessary
Just one minor point, if we don't have EOS enabled, we could end up pulling duplicates in some tests like the `StreamsUpgradeTest::upgrade_downgrade_brokers`
Nit: every conditional needs to have braces (per the code style) not nit: I find this logic a little difficult to follow. Contrary to what @mjsax suggested, wouldn't it be pretty straightforward to map the old semantics on to the new ones like this: * negative numbers => 0 * 0 => Long.MAX_VALUE * all other arguments stay the same ? Then, the old close method could just transform its arguments and call the new method, with no need to have this "new semantics" flag and an early return in the middle of the loop.
Is it safe to call this multiple times? If not, we would not want to do it if `state == STOPPED`.
Not sure you need to initialize the factory every time there.
Why don't we need this check anymore? It's still done for `globalThread`.
`toString` is not required.
nit: move to line above.
name seems unused.
the naming used above seems better here ```suggestion Throwable exception = null; ```
You might want to use another variable name.
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
I'd suggest copying and using what we've been using elsewhere to assert that a connector and its tasks are up and running: https://github.com/apache/kafka/blob/trunk/connect/runtime/src/test/java/org/apache/kafka/connect/integration/RebalanceSourceConnectorsIntegrationTest.java#L324-L337 It works fine with the `waitForCondition` method that accepts a timeout. Eventually (maybe soon) this type of assertion will go to `EmbeddedConnectCluster` and will be made available for every Connect integration test. However, I suggest we don't take on this refactoring now and we just copy the method from the test above.
Just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. Would you mind to not move configs that get deprecate and add the new config at the "right" place. Thanks a lot. :)
Is this used anywhere? I see we have changed client code to use the other C'tor.
Nit: please add `final` to all local vars and method parameters
`Integer.toString` is a slightly more concise way of doing this.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
`? extends` should be removed as covariant return types are usually inconvenience to the consumer.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
We should use try-with-resources here (for `DataInputStream`).
ditto on removing before/after.
nit: I would move this block up, before calling `listOffsets`, in order to have the response ready. Same for other tests.
Did we want to use `valueAndSchema.value()` for the last parameter? Same for the message below.
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
I think we should call `deserializer.close()` here
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
`fail` is not required. Maybe, it would be better though to have a try-catch around this (and use `fail`) and remove `expected` annoation (using `expected` should only be done for single-line tests).
Hmm, we're using a raw type here and a few other places. This is discouraged (type checking is disabled in these cases). If we don't want to propagate the generics when we use the superclass, we should probably drop them.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
we should not hard-code version 3, but programmatically find the highest supported version and send something higher , so that this code doesn't have to be revisited if there is a new version
I know you just moved these lines around, but while you're doing that it probably would be worthwhile to combine these 2 statements into one. If the log is busy, these might not appear next to each other.
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
Same question here as earlier about the `Locale`
nice fix! this has been bothering me.
Thinking about it, this may be the root of the problem. We are removing from the head of the ArrayList, one at a time. For each removal, we cause all the elements to be shifted in the underlying array, which is very inefficient if n is not small.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Same question here as earlier about the `Locale`
nice fix! this has been bothering me.
nice fix! this has been bothering me.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
name seems unused.
Nit: the method is `Transformation.close()`, not "stop". The log message should probably reflect that.
Nit: the method is `Transformation.close()`, not "stop". The log message should probably reflect that.
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
We should use try-with-resources here (for `DataInputStream`).
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
```suggestion import org.apache.kafka.common.MetricName; import org.apache.kafka.common.metrics.Metrics; import org.apache.kafka.common.metrics.Sensor; import org.apache.kafka.common.metrics.stats.CumulativeSum; import java.util.Map; ```
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Nit: please add `final` to all local vars and method parameters
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
super nit: taskCreationLock --> taskDirCreationLock
Ditto on removing before/after
Might be better to use an `Exception` variable `firstException` and rethrow at the end if not `null` -- IIRC, behavior is undefined if we throw a second exception (ie, `finally` would executed after the first (outer) `catch` block.
the method ```clean``` catches ```Exception``` already. Could we get rid of those try-catch statements? the code ```log.error("{} Failed to release the state directory lock.", logPrefix());``` can be moved to ```clean```. For example: ```java public synchronized void clean() { // remove task dirs try { cleanRemovedTasksCalledByUser(); } catch (final Exception e) { log.error("{} Failed to release the state directory lock.", logPrefix()); throw new StreamsException(e); } ``` ```java private void cleanRemovedTasksCalledByUser() throws Exception { for (final File taskDir : listAllTaskDirectories()) { final String dirName = taskDir.getName(); final TaskId id = TaskId.parse(dirName); if (!locks.containsKey(id) && lock(id)) { try { log.info("{} Deleting state directory {} for task {} as user calling cleanup.", logPrefix(), dirName, id); Utils.delete(taskDir, Collections.singletonList(new File(taskDir, LOCK_FILE_NAME))); } finally { unlock(id); // for manual user call, stream threads are not running so it is safe to delete // the whole directory Utils.delete(taskDir); } ```
Nitpick: I'd call this `getOrCreateFileChannel`.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Same for generation and member.id. We could just call `request.data().generationId()`
super nit: extra blank line
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
I've seen alternative solutions floating around that use a configurable source here. Basically, the configuration passed to configure() is consulted to find the "source cluster", rather than looking at the topic name. That approach lets you return an actual source here, which obviates the new canTrackSource() method etc.
Are these 3 lines an artifact of code reformatting? They don't seem to correspond to changes other than the reordering itself. The previous order matches the variable declaration order, so maybe we want to leave this as-is.
nit: usually we write this like this: ```java this.groupInstanceId = requireNonNull(groupInstanceId, "group.instance.id can't be null"); ```
again, naming of the test
That has its own complications because if my provider is only providing TrustManagerFacotry.PKIX then it can't provider other services+algorithms that might be expected in calls like SSLContext.getInstance(String protocol, String provider). SSLContext.getInstance might look for TLSv1.1 or TLSv1.2 etc which my provider doesn't really have and I don't have a way to fallback anymore once I go route of specifying "provider" in getInstance() calls. In short - once we have a Provider providing a Standard service+algorithm we may have to implement other services+algorithm also otherwise it may not work (like I mentioned for SSLContext)
Could store `entry.getKey()` in a local variable since it is used several times
That has its own complications because if my provider is only providing TrustManagerFacotry.PKIX then it can't provider other services+algorithms that might be expected in calls like SSLContext.getInstance(String protocol, String provider). SSLContext.getInstance might look for TLSv1.1 or TLSv1.2 etc which my provider doesn't really have and I don't have a way to fallback anymore once I go route of specifying "provider" in getInstance() calls. In short - once we have a Provider providing a Standard service+algorithm we may have to implement other services+algorithm also otherwise it may not work (like I mentioned for SSLContext)
That has its own complications because if my provider is only providing TrustManagerFacotry.PKIX then it can't provider other services+algorithms that might be expected in calls like SSLContext.getInstance(String protocol, String provider). SSLContext.getInstance might look for TLSv1.1 or TLSv1.2 etc which my provider doesn't really have and I don't have a way to fallback anymore once I go route of specifying "provider" in getInstance() calls. In short - once we have a Provider providing a Standard service+algorithm we may have to implement other services+algorithm also otherwise it may not work (like I mentioned for SSLContext)
So we basically do 10 re-tries? Is this intended? Or should be just sleep for a hard-coded "backup time"
nit: 'else' can be dropped
I think this should only be done after the store is in a valid state, i.e, after restore. Otherwise there is a chance we can try and query or write to the store before it is ready
nit: remove `this` (not required)
Just wanted to say I really like the way this unit test is written! With the right usage of mocks we would avoid having any time-dependent flakiness.
This should go away. `@ConditionalOnClass` already does that.
He means that you don't need an `else` in this case.
We should read the metadata inside the while loop since it could change.
"Mixin for combining with a lookup"
Do we want this to be `error` or `warn`? Maybe `error` is right, so take this as a question. :)
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
I think this would never happen now since the passed in `recordPerTopicPerPartition` is always initialized.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
Nit: I think we can simply say `Idempotence will be disabled...` (instead of `enable.idempotence` will be disabled...`)
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
nit: make the parameters final, and if you could put them on separate lines, similar to the `process` method on 327. Ditto for `assertNextOutputRecord` on lines 330 and 334 above.
I'm wondering if we should use `CommitFailedException`. In the consumer, we do not expose illegal generation and unknown member id errors directly to the user.
This would be less mysterious if this method were inlined into `updateLimitOffsets`. Right now, it's not terribly clear why it's ok to set the "last update offset time" in a method that doesn't update the offsets.
I think we should call `deserializer.close()` here
There should never be multiple requests, right? If there were, a second request might arrive between 168 and 169, violating the desired property. In that case, we should grab a lock instead. As long as there's only one requesting thread, and it always waits for the commit right after requesting, then we should be good.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
Nitpick: if you pass the deserializers via the constructor, it's a bit more concise. This applies to all tests.
Nitpick: if you move the fail inside the `try`, then you no longer need the `return` in the catch. This applies to a few other tests too.
Nit: add `{}` to block
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
Do we need this? Can't we just use the Time we pass into the constructor in tests? Not a big deal really, just wondering
nit: break line
On my PR, I had copied `awaitForComplete` into into `BlockingSingle`. This is obviously cleaner :p
Hmm, why did we do this? I thought we'd have a try/catch block.
nit: remove `this`
Seems like this is the same in `testReadFullyOrFailWithMultiReads`. Maybe we can extract it to a helper method.
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
Ah, I see. Thanks for the explanation
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
We should log an error that prints out what the two configs actually are
By catching Throwable, aren't we silencing the error and not immediately failing the test? Also we should not be catching Throwable, if the JVM throws an Error we want it to fail the test and never want to handle it. There're a bunch of them in these files
We should log an error that prints out what the two configs actually are
Shouldn't this be a config exception? It is not really invalid partitions.
nit: add a size? There are a few cases in here where we could do this.
This doesn't seem to be used.
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
nit: could you try to deduplicate code here and in the other unit tests? Here for example, you could have one method like this: ``` private void shouldThrowIfNoPeekNextKey(final Supplier<MemoryLRUCacheBytesIterator> methodUnderTest) { final ThreadCache.MemoryLRUCacheBytesIterator iterator = methodUnderTest.get(); assertThrows(NoSuchElementException.class, iterator::peekNextKey); } ``` and then two public tests ``` @Test public void shouldThrowIfNoPeekNextKeyRange() { final ThreadCache cache = new ThreadCache(logContext, 10000L, new MockStreamsMetrics(new Metrics())); shouldThrowIfNoPeekNextKey(() -> cache.range(namespace, Bytes.wrap(new byte[]{0}), Bytes.wrap(new byte[]{1}))); } @Test public void shouldThrowIfNoPeekNextKeyReverseRange() { final ThreadCache cache = new ThreadCache(logContext, 10000L, new MockStreamsMetrics(new Metrics())); shouldThrowIfNoPeekNextKey(() -> cache.reverseRange(namespace, Bytes.wrap(new byte[]{0}), Bytes.wrap(new byte[]{1}))); } ``` Admittedly, in this specific case, we would not win much but for other unit tests in this test class it may be worth. Try and then decide if it is worth or not.
we only need the lock for setting the seed and calling `random.nextInt`, right? for the rest of the function we can avoid holding the lock since we're just iterating over an immutable list that can't change and calling stuff that is threadsafe anyway
As above for this and the next ctor
we only need the lock for setting the seed and calling `random.nextInt`, right? for the rest of the function we can avoid holding the lock since we're just iterating over an immutable list that can't change and calling stuff that is threadsafe anyway
To be realistic, the second parameter should be `Collections.singleton(topic)` rather than `emptySet`.
nit - "once once"
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
I don't think we need this `null` check either.
`doWork` is just one iteration. `ShutdownableThread` has the loop. I'm ok with the change, but we probably will need to copy over some of the shutdown logic.
Nit: fix line break
`doWork` is just one iteration. `ShutdownableThread` has the loop. I'm ok with the change, but we probably will need to copy over some of the shutdown logic.
why use `topicName` here? Should it not be `failed: key=X actual=A expected=B...` instead of `failed: key=X <topicName>=A expected=B...`
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
the method ```clean``` catches ```Exception``` already. Could we get rid of those try-catch statements? the code ```log.error("{} Failed to release the state directory lock.", logPrefix());``` can be moved to ```clean```. For example: ```java public synchronized void clean() { // remove task dirs try { cleanRemovedTasksCalledByUser(); } catch (final Exception e) { log.error("{} Failed to release the state directory lock.", logPrefix()); throw new StreamsException(e); } ``` ```java private void cleanRemovedTasksCalledByUser() throws Exception { for (final File taskDir : listAllTaskDirectories()) { final String dirName = taskDir.getName(); final TaskId id = TaskId.parse(dirName); if (!locks.containsKey(id) && lock(id)) { try { log.info("{} Deleting state directory {} for task {} as user calling cleanup.", logPrefix(), dirName, id); Utils.delete(taskDir, Collections.singletonList(new File(taskDir, LOCK_FILE_NAME))); } finally { unlock(id); // for manual user call, stream threads are not running so it is safe to delete // the whole directory Utils.delete(taskDir); } ```
Not something we have to do here, but one way we could improve this in the future is by taking into account leader epoch information from individual partitions. We can ensure that epochs increase monotonically in order to prevent using stale information during retry. Another thing we could do is reduce the topics we are fetching metadata for as the ListOffsets requests complete. Ideally we'd only be refetching metadata for topics with metadata errors.
nit: parameter/line formatting
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
visibility could be restricted to be package-level (i.e remove keyword `protected`)
Hmm.. Do we know how this is getting propagated in all cases? Some of the responses are handled using a `RequestCompletionHandler`, but NetworkClient currently eats any exception raised from this callback.
Can't you use `createClient`? This call confused me... (same below)
Also: should only call onPartitionsLost on owned partitions that no longer exist
Can't you use `createClient`? This call confused me... (same below)
Also: should only call onPartitionsLost on owned partitions that no longer exist
here it might work better to use `TestUtils.waitForCondition` instead of an arbitrary sleep call
here it might work better to use `TestUtils.waitForCondition` instead of an arbitrary sleep call
We should read the metadata inside the while loop since it could change.
This was probably left by mistake.
`Map::put` returns the previous value.
here it might work better to use `TestUtils.waitForCondition` instead of an arbitrary sleep call
ok - same thing three times. Maybe extract it to a method `verifyTransactionInflight`
nit: add `final`
We should read the metadata inside the while loop since it could change.
I think we should be consistent and use double-quotes.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
nit: can we make this debug level? Otherwise it will make this test a little spammy.
I'd suggest moving this static method after the non-static methods.
I am confused. If we change `store.range(hello, "zooom");` should `hasNext()` not return `true` (start and end are inclusive). Thus, to me it seems the test is wrong and there must be a bug in the iterator code.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
What's our plan for the global thread? I didn't think of this during the KIP discussion, and sorry if it was brought up there and I just forgot about it. But it seems like we should still give users a non-deprecated way to set a handler for the global thread.
We use to log all leader and isr changes in info even for clean leader election.
We don't even start the Executor so there is nothing that would start it. We have used that approach in Hystrix for years, and there we used the `reset` model rather than shutdown/start: https://github.com/Netflix/Hystrix/blob/master/hystrix-core/src/main/java/com/netflix/hystrix/Hystrix.java#L42 If we completely shutdown the Executor, and then lazily recreate it, there is nothing to start threads, so it would be safe.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
What's our plan for the global thread? I didn't think of this during the KIP discussion, and sorry if it was brought up there and I just forgot about it. But it seems like we should still give users a non-deprecated way to set a handler for the global thread.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
Private and call from the constructor? We only ever call this immediately after instantiating the class.
What if it is a file? We didn't really talk about this, but it could potentially be a list of uberjars. Even if we don't want to support this here, at least log something if the entire path is going to be ignored due to not being a directory.
We should limit this suppression to the method for which we really need it instead of the whole class
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
Nitpick: I'd call this `getOrCreateFileChannel`.
I'd be tempted to rename this `getJobName()`
Nitpick: I'd call this `getOrCreateFileChannel`.
Testing against log message is error-prone and hard to maintain, I think just making sure the thrown exception type is expected should be sufficient.
@jeffchao traditionally Kafka used key,value pairs in properties and pass it everywhere and each implementation takes look at this config and pulls their interested key,value pairs. Example, authorizer interface https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/security/auth/Authorizer.scala#L35 . The pluggable class when it gets instantiated a configure method will be called and all the key,value in server.properties will be passed and it will pick whats relevant to the class. We can do the same here instead of asking users append key,values into the a config which is hard to configure and hard to get it right.
Same here, for verifying the thrown cause
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
What's the purpose of this warning? It doesn't seem needed.
Perhaps we should continue to test the simpler case where we don't provide a `name` or `condition`.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Nitpick: I'd call this `getOrCreateFileChannel`.
Should we finer-handling different error cases here? ``` /** * Possible error codes: * * REQUEST_TIMED_OUT(7) * INVALID_TOPIC_EXCEPTION(17) * CLUSTER_AUTHORIZATION_FAILED(31) * TOPIC_ALREADY_EXISTS(36) * INVALID_PARTITIONS(37) * INVALID_REPLICATION_FACTOR(38) * INVALID_REPLICA_ASSIGNMENT(39) * INVALID_CONFIG(40) * NOT_CONTROLLER(41) * INVALID_REQUEST(42) */ ```
I'd be tempted to rename this `getJobName()`
I think it is better to throw if the passed in exception handler is `null` and set the default uncaught exception handler in the `StreamThread` constructor.
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
Nitpick: I'd call this `getOrCreateFileChannel`.
typo: byteArrray -> byteArray
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
The order is not really that important here, either way works
This will close the `ServerSocketChannel` before it can be used by the `ServerThread`. The channel is eventually closed when the thread is closed so this change is unnecessary. I'll address this when merging.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Don't you think that being explicit improve readability? `boolean first = false;`
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
What if it is a file? We didn't really talk about this, but it could potentially be a list of uberjars. Even if we don't want to support this here, at least log something if the entire path is going to be ignored due to not being a directory.
This will close the `ServerSocketChannel` before it can be used by the `ServerThread`. The channel is eventually closed when the thread is closed so this change is unnecessary. I'll address this when merging.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
Maybe we can just a better name for `path` since it makes this code look suspicious.
This should go away. `@ConditionalOnClass` already does that.
nit: would be nice to be consistent on the pattern we use here
Nitpick: if you move the fail inside the `try`, then you no longer need the `return` in the catch. This applies to a few other tests too.
Nitpick: if you move the fail inside the `try`, then you no longer need the `return` in the catch. This applies to a few other tests too.
I now saw that in the consumer tests you use `Duration.ofSeconds(1).toMillis()` and `Duration.ofMillis(999).toNanos()`. This makes it already clearer. I think a variable with a meaningful name for the lower bound would make it even clearer.
I'd consider making this extend org.junit.rules.ExternalResource - it can then be used as a JUnit ClassRule or Rule. The benefits being that the JUnit framework takes care of startup and shutdown
Nit: space before `:`.
Nit: space before `:`.
Since we have three threads for this test, there can be multiple rebalances before the streams instance stabilize and start processing...
nit: We could instantiate a new `ListTransactionsOptions` here instead of using `null`. This would remove the `null` check below.
The order is not really that important here, either way works
Here too it seems like we can use the generic version of `prepareOffsetCommitResponse`.
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
Ditto on removing before/after
Please remove empty line.
I don't know what has changed here.
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
Ditto on removing before/after
nit: personal preference so feel free to ignore. But i'd ditch the `else` in this case. I don't think it adds anything
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
why bother with this? `NodeFactory` is private in `TopologyBuilder` so it is not going to be anything else. Plus it wouldn't matter if we used the interface rather than `instanceof`
nit: personal preference so feel free to ignore. But i'd ditch the `else` in this case. I don't think it adds anything
I think the name of the function is better defined as `interleaveTasksByConsumers`
base -> based progress -> progressed
the naming used above seems better here ```suggestion Throwable exception = null; ```
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
validateStoreOpen() can be outside of lock block.
Private and call from the constructor? We only ever call this immediately after instantiating the class.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
I was asking more for a semantic one -- as long as this is not expected then I'm happy for this piece as is :)
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
ok. Just curious what is target date when all implementation for this will be merged? cc@saisandeep
ok. Just curious what is target date when all implementation for this will be merged? cc@saisandeep
`replayObserverFromIndex` always access `index` first. Actually, if I swap these two statement, ``` java int index = h.index.get(); int size = h.list.size(); ``` I can pass this test. I think `index` can guarantee "l < index.get() <= list.size()". So I feel this is not the cause of the concurrency issue.
Maybe we should add one case where `position > 0`.
Hmm, we seem to be sanity checking a) that we are assigned this partition and b) the user code is not jumping ahead of the current position without actually performing a seek. Is this right? If so, these seem like things we should warn about if a connector is trying to do that since it indicates the connector is almost definitely broken.
Do we need to lock here? I think the lock has already been taken out from the callers of this method
Do we need to lock here? I think the lock has already been taken out from the callers of this method
Doesn't seem to be used for anything? Why not just log a message saying that it didn't contain any plugins? In fact, even if we save this here, it seems like we'd still want that error message since the lack of any plugins probably indicates an incorrect configuration.
the `try{...} finally` has been removed
I know we need both `File` and `Path` instance to complete the permission setting. What I meant is that: 1. We already had the `File` instances, i.e. baseDir, stateDir 2. `Paths.get(stateDir.getPath())` --> what happened behind the scene, is we created a Path instance from the path string in the file instance (i.e.`stateDir.getPath()`) ```java public final Path getPath(String var1, String... var2) { ... return new UnixPath(this, var3); } ``` 3. `path.toFile()` --> what happened behind the scene, is we created a File instance from the path string ```java public final File toFile() { return new File(this.toString()); } ``` So, currently, we will created an additional File instance via `path.toFile()`. If we pass the File instance into `configurePermissions()` directly, it'll only created a `Path` instance. ex: ```java configurePermissions(stateDir); // pass the file instance directly ``` ```java private void configurePermissions(final File file) { final Path path = Paths.get(file.getPath()); // created path instance if (path.getFileSystem().supportedFileAttributeViews().contains("posix")) { .... } else { boolean set = file.setReadable(true, true); // won't create additional File instance here .... } } ```
formatting: no need to curly braces
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
Maybe we should add one case where `position > 0`.
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
That's what Bruno originally did, but the original `cleanRemovedTasks` method branched on the `manualUserCall` flag in several places and was pretty difficult to follow (imo). So (also imo) it's cleaner to split it up into two methods that make it clear what the expected behavior is in each case. Just my 2 cents
Maybe we should add one case where `position > 0`.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Same for generation and member.id. We could just call `request.data().generationId()`
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
Okay. We do similar synchronization for `append`. The `LeaderState` has an `epoch` and it is final. The part that may be tricky to implement is the `epoch < currentEpoch` case.
No `else` needed since we used `return` for both other cases. For the exception, I think we can just throw `ClassCastException` since `IllegalStateException` doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more `Records` subtypes. For example: ```java "The record type is " + partition.records().getClass().getSimpleName() + ", which is not a subtype of " + Records.class.getSimpleName() + ". This method is only safe to call if the `FetchResponse` was deserialized from bytes."
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
I believe the goal is to use constant-time comparison to prevent timing attacks, hence the walk through the arrays.
Same as above mentioned, the validation didn't get handled in new API.
Rather than a copy/paste, this should call the other constructor you've created with `SpringBootConfiguration.class`
This should disappear with my suggestion.
I think we can be more concise and simply say `// Single writer thread, multiple reader threads`
I think we can be more concise and simply say `// Single writer thread, multiple reader threads`
ditto here, please add a separate check and exception
Nitpick: I'd call this `getOrCreateFileChannel`.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Private and call from the constructor? We only ever call this immediately after instantiating the class.
Add a log saying that internal strings are used since inputValues.txt is absent.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
I think this'll break up-to-date checking for the jar. Creating a text resource from a string results in the creation of a temporary file with a random name. As that random name varies from build-to-build, the jar tasks will never be considered up-to-date as it'll look like its inputs have changed. We had this problem when adding the classpath index support to `BootJar`. The solution was to get the text resource's file and rename it before adding it to the copy spec rather than as part of the spec.
Similar here, we can cache the result in case to be reused.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
I don't think we need the `null` checks.
Nitpick: I'd call this `getOrCreateFileChannel`.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Ditto on removing before/after
What if it is a file? We didn't really talk about this, but it could potentially be a list of uberjars. Even if we don't want to support this here, at least log something if the entire path is going to be ignored due to not being a directory.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
If we swallow the exception here, and the test always throws an IO exception, we will never notice. I guess it would be better to use `fail()` with a message.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
nit: the name is a bit awkward. How about `maybeInvokeOnPartitionsLost`? We can change the others similarly.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
If we swallow the exception here, and the test always throws an IO exception, we will never notice. I guess it would be better to use `fail()` with a message.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
Also not clear why "numSegments - 1" here.
Maybe this looks better? ```suggestion // we're at the end of the input. if (queryResult.getResult().value() == batch1NumMessages - 1) return; ```
Nitpick: I'd call this `deserialize`.
cosmetic: extra space at the start
There is a race here. If `run()` gets here and `onNext` is fired, throttling will be disposed and the `onNext` value gets emitted. Here then the cached value gets emitted as well and now there are two tasks delayed for the subsequent interactions.
`endOffsets.get(topicPartition)` can be replaced by `offset`
prop: - Remove `Target` - `thread` -> `stream thread`
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
debug line should be removed.
Why do we need a `try` for this case? The `close()` is a no-op anyway. (Similar below)
typo: Woth -> With
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
We should limit this suppression to the method for which we really need it instead of the whole class
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
add `final` twice
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
Maybe we can just a better name for `path` since it makes this code look suspicious.
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Let's remove on both side: I think in J8 it is not really a big difference.
Could we just add a toString function to ProcessorNode / SourceNode / SinkNode so that this code just becomes: ``` print(node) { // node.toString // also include listing children names foreach(child <- children) print(child). } ``` And also you do not to maintain the mapping as well.
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
"*" is considered "LITERAL" for compatibility reasons
Got it. May be we could have something like SchemaAndValueUtils to include such utils for it. Just didn't feel great seeing this method in the ConnectHeaders class.
nit: I would rather use the full name instead of using acronyms.
This could be: ``` .reduce( (value1, value2) -> Math.max(Integer.parseInt(value1), Integer.parseInt(value2)) ) ```
`instantiateConfigProviders` since this is potentially creating multiple providers
I believe a null-pointer check is necessary here.
nit: extra line
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
We don't usually assert on exception messages as it makes tests a bit brittle. This applies to a few other tests too.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
There are some request header tests in `RequestResponseTest`, we should move them here so that we can find them all in one place.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
`while` seems to be missing
This exception can't be thrown by DeleteTopics.
Fair enough. If we think it's the right thing to do, then making the change in `Utils` seems like a good idea to me.
Thanks for double checking this! Then it lgtm.
I'd go for underlining.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
debug line should be removed.
Shouldn't this be `timeoutMs - (time.milliseconds() - startTimeMs)`? Also, it's not too big of a deal, but the checks for `Long.MAX_VALUE` seem like overkill.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
Adding a parameter `version` for `encodeVersionThree` is very confusing to other readers. I'd suggest completely duplicate the code in `encodeVersionFour` and remove this parameter in `encodeVersionThree`.
I've been thinking about this function a little bit and the savings we are trying to achieve. From a high level, I think we are trying to minimize the number of reads and the number of allocations. I am considering whether we can pull the `skipBytes` approach up to this level. So first thing we do is allocate a buffer of size `min(sizeInBytes, FIXED_BUFFER_SIZE)`. Then we turn the parsing into a state machine. The logic would look something like this: ``` buffer = allocate() needMore = true state = READ_METADATA while (true) { if (needMore) input.read(buffer) switch (state) { case READ_METADATA: // read offset and timestamp // transition to READ_KEY_SIZE case READ_KEY_SIZE: // read key size // transition to SKIP_KEY_BYTES case SKIP_KEY_BYTES: // skip until key is consumed // transition to READ_VALUE_SIZE case READ_VALUE_SIZE: // read value size // transition to SKIP_VALUE_BYTES case SKIP_VALUE_BYTES: // skip bytes until value is consumed // transition to READ_HEADERS case READ_NUM_HEADERS: // read num headers // transition to READ_HEADER case READ_HEADER: // read one header // return when all expected headers are consumed } } ``` The basic idea is to always use the same buffer and never have any trivial reads. In fact, this would allow us to reuse the same buffer across multiple calls to `readPartially` which would improve GC even further.
Just realized, that the method does use `synchronized` keyword anyway... it's guarded against this already. Same for `start()`.
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
Suggestion on above function addConfiguredSecurityProviders: 1. I think using following format for security.providers: security.providers=provider1_classname,provider2_generator_classname key1:val1 key2:val2,... 2. So when parsing above config, if there is no parameters following provider1_classname, then we can think provider1_classname is java Provider, then insert it; if there are key:value pair parameters following provider2_generator_classname, we can think provider2_generator_classname is SecurityProviderGenerator, then create "Map<String, ?> config" from key:value pair parameters, then call configure and getProvider of instance of SecurityProviderGenerator. This way we can handle all different scenarios in the future.
nit: The callers of this iterate the committed offsets twice. Once in order to check partition ownership and then a second time to invoke `updateLastSeenEpochIfNewer`. I wonder if we could consolidate these two loops.
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
you don't need this. Junit gives you a new instance of the test class for every test method
nit: The callers of this iterate the committed offsets twice. Once in order to check partition ownership and then a second time to invoke `updateLastSeenEpochIfNewer`. I wonder if we could consolidate these two loops.
If you allocate this as a direct buffer here, you need to force it to be deallocated in `SslTransportLayer#close`. Otherwise these off-heap buffers will build up over time and starve the system of memory. The garbage collector doesn't "see" direct buffers and in at least a few versions of Java, they never get cleaned up until a full GC.
nit: align parameters.
nit: align parameters.
Same here: not only CREATED, but also RESTORING and SUSPENDED tasks should not be included in `consumedOffsetsAndMetadataPerTask` and we should not let the task-manager to peek its state.
Why was replace('\n', '') removed? If that was required before I don't see anything that would replace it now.
Ah - you are not doubling the elapsed time because you are actually doing a modulo on the window size. That said, I think the current code should still be correct. Note that in your test you haven't actually created three samples because you didn't call record at the 60 second or later mark. i.e., if you debug through you will find only two samples. So the "current" time is taken off now minus the `lastWindowMs` of the "current" sample which is the second sample and that ends up being 105 seconds for me (which is correct because the current sample has not rolled over due to the absence of a record).
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
A better way is to first call `this.mockTime.milliseconds()`, then `this.mockTime.sleep(1000)` then call the `milliseconds` again with the second batch.
A better way is to first call `this.mockTime.milliseconds()`, then `this.mockTime.sleep(1000)` then call the `milliseconds` again with the second batch.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
I think we can call the one-parameter `produce()` in line 144 above as well
Should we really catch NPE here? It seems like if the user wants to return a non-null mapped key from a null key, then they should handle the null case specifically in their `keyMapper` and not just throw an NPE. In general, an NPE is a sign that something has gone wrong. I would be pretty surprised if I threw an NPE explicitly in my user code and it just got swallowed and interpreted as if I had actually returned null.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
There's still a usage as `applicationId + "-" + topic` in the `SinkNodeFactory` subclass. The structure of that class is now a bit odd as the `applicationId` is passed as a parameter, but it's a non-static so it captures the parent reference and actually uses it for at least one other member of the parent class (`internalTopicNames`). I'm fine committing as is if this is consistent with trunk since then a clean up could easily be cherry picked if that was desired. But it looks like this patch and what's on trunk differ significantly. This method name doesn't even seem to exist on trunk? Are you sure you want to diverge so wildly? It's going to make any more backports/cherrypicks really annoying...
unnecessary type in constructor, can use `new HashMap<>()`
There's still a usage as `applicationId + "-" + topic` in the `SinkNodeFactory` subclass. The structure of that class is now a bit odd as the `applicationId` is passed as a parameter, but it's a non-static so it captures the parent reference and actually uses it for at least one other member of the parent class (`internalTopicNames`). I'm fine committing as is if this is consistent with trunk since then a clean up could easily be cherry picked if that was desired. But it looks like this patch and what's on trunk differ significantly. This method name doesn't even seem to exist on trunk? Are you sure you want to diverge so wildly? It's going to make any more backports/cherrypicks really annoying...
Maybe call RxJavaPlugins.onError() or however that api is called in 1.x? I believe people won't like stacktrace popping up in their logs without ability to swallow it
unnecessary type in constructor, can use `new HashMap<>()`
should it be `putIfAbsent` (cf `cleanUpTaskProducer()`)
should it be `putIfAbsent` (cf `cleanUpTaskProducer()`)
Is the change in behavior intentional? `SecurityException`, which was previously caught and logged, is an instance of `RuntimeException`.
Yeah, that would be the closest for primitive types.
That sounds good to me ð
By the way, I wonder if we should just say it should be idempotent? Seems redundant to mention KafkaProducer.
Do we need this? Can't we just use the Time we pass into the constructor in tests? Not a big deal really, just wondering
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
`as defined by the arguments` is not really telling me anything. I would either add a longer more descriptive doc string or none.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
nit: add `final`
Can you please fix this output too -- the tool does "seek to beginning" and does not set offsets to zero.
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
Yeah it makes sense. Sorry for not getting back to you sooner
Nit: please add `final` to all local vars and method parameters
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
nit: Could we add a error reason in this assertion, so that when the exception message is not one of these 2 messages, we can know what happened. Ex: "Unexpected exception thrown while getting the value from store."
A couple of things (applies to the same code a few lines below): - Is there a reason you changed `Map<String, String>` to `HashMap<String, String>`? - We can pass `1` to the `HashMap` constructor to avoid allocating a 16 entries array when we `put` `topic`.
Traditional how? That it's in 1.x? I don't see why that should stop us from removing it. Doing something like this is wrong: ``` java timer(1, SECONDS, Schedulers.test()) ``` yet it's how you'd use every other static method in this class.
We should also create a client connection with one of the newly disabled protocols like TLSv1.1 and verify that the client connection fails.
Couldn't we simply wait for the current state to become `RUNNING`? ```suggestion private void waitForRunning() throws Exception { waitForCondition( () -> kafkaStreams.state() == KafkaStreams.State.RUNNING, DEFAULT_DURATION.toMillis(), () -> String.format("Client did not transit to state %s in %d seconds", expected, DEFAULT_DURATION.toMillis() / 1000) ); } ```
This is also the default, I think.
No we don't have that rule. Personally i think it is fine as long as it fits on a single line, i.e., less than 100 characters.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Thanks for the discussion, all. One thing to note is that this config has "no" impact on high availability. Anyone who wants HA would configure num.standby.replicas, and this config applies on top of that one (for this reason, I like the name you picked. It is "extra".) I think you can make a case for per-node or per-cluster, but if we assume we only want to add one config, I think per-cluster is more valuable, since it lets you protect the brokers from overload, which a per-node config may not. Regarding whether we set the default limit low or high, I'd advocate for low. Some clusters are undoubtedly running close to the limits of their disk space or broker capacity, so suddenly letting every node double its traffic would result in serious operational consequences. On the other hand, if we start out low, then the probability of a crash becomes much lower, and the only problem is that the overall balancing process takes a long time. But, since the config is set low, there's a low impact on processing capacity while it's happening, so maybe there's no real impact over that long time. If you buy the argument that a low default is good, then the obvious choice is "1", but that would take a _really_ long time to complete balancing. The default of "2" is basically a compromise. It lets you balance twice as fast, and it's "probably" still low enough to cause a problem for no one. "5" also seems fine-ish, but the farther from "1" you move, the riskier the choice is. One final thought, when you say that some people would "need to change" the config, say from the default (2) to MAX_VALUE... It seems like this population is restricted to the people who really need to make sure that balancing happens absolutely as fast as possible (maybe because their application can't keep up unless the whole cluster is processing, or because they're scaling up to cope with a spike in input data). Hopefully, these people know that they need extra horsepower and are motivated to read the docs and locate the config they need to change. Also, hopefullly, this isn't the common case.
"do nothing" is probably the right thing here.
Was just thinking about how long a. transaction might possibly be open. 1 minute SGTM
Fine with me to keep the guard. Was just double checking.
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Also: should only call onPartitionsLost on owned partitions that no longer exist
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
A more reliable way to check if a user explicitly sets the config is to check from config.originals(). Ditto for configureRetries().
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Same question here about just using a static ConfigDef instead of a static method.
Same question here about just using a static ConfigDef instead of a static method.
Same question here about just using a static ConfigDef instead of a static method.
Same question here about just using a static ConfigDef instead of a static method.
Yes, it makes sense to return a range for an ApiKey instead of a single version. I was just wondering if this method is redundant given NodeVersions.apiVersionRange(ApiKey api). Also, it feels a bit weird for a public facing class to reference Protocol, which is not a public facing one.
nit: 'else' can be dropped
I feel INFO level is fine as in many cases people will keep alerting on warn / error logs.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
If we swallow the exception here, and the test always throws an IO exception, we will never notice. I guess it would be better to use `fail()` with a message.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Admittedly, this is a random time to bring this up, but a pattern that I like for this is: ```java final long seed = providedSeed != null ? providedSeed : new Random().nextLong(); System.out.println("Seed is: " + seed); final Random rand = new Random(seed); ``` where `providedSeed` comes from an env variable, command-line arg, whatever... This way you get the same default behavior (pseudorandomly generated sequence of test values), but you also have the option to deterministically reproduce a previous pseudorandom sequence from a prior run. This can be helpful in diagnosing flaky tests. Not saying this is needed here; I just wanted to share the pattern.
Hmm, if we convert arrays to bytes, we need to be careful. If the arrays have different sizes, then the operation is not constant time.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
`hasItem(task01)` -> `equalTo(Collections.singleton(task01))`
Recently, we prefer to use `assertThat()` instead of `assertEquals()`.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
If we swallow the exception here, and the test always throws an IO exception, we will never notice. I guess it would be better to use `fail()` with a message.
OK. Sorry, I looked at this first before I saw the update to `TaskStateType.`
Recently, we prefer to use `assertThat()` instead of `assertEquals()`.
Nit: var should be named `deserializeValue`
I fixed this one to use the constant before merging.
Hmm, if we convert arrays to bytes, we need to be careful. If the arrays have different sizes, then the operation is not constant time.
OK. Sorry, I looked at this first before I saw the update to `TaskStateType.`
OK. Sorry, I looked at this first before I saw the update to `TaskStateType.`
Hmm, if we convert arrays to bytes, we need to be careful. If the arrays have different sizes, then the operation is not constant time.
Why is this needed? This is worse than the previous approach as it opens, closes and reopens the file.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
Recently, we prefer to use `assertThat()` instead of `assertEquals()`.
typo: Woth -> With
This was probably left by mistake.
Sounds good. I just want to avoid someone trying to simplify the tests in the future without understanding that this test is verifying both features work together.
nit: add `final`
nit: can we make this debug level? Otherwise it will make this test a little spammy.
nit: can we make this debug level? Otherwise it will make this test a little spammy.
Why not check `context.timestamp`? Checking the message of the exception is very brittle.
We should verify the actual timestamp.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Hmm.. `first` and `last` of RocksDBStore are not used anywhere, I think it is a leftover of the code clean up introduced in KAFKA-4499 (cc @RichardYuSTUG ). Maybe we can just remove these two functions from RocksDBStore.
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
Nit: param alignment.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
don't need variables here
Looks like you can do these 7 lines in a `@Before` method and not repeat it in all of your tests
Looks like you can do these 7 lines in a `@Before` method and not repeat it in all of your tests
Nitpick: in Kafka, we generally set the field where it's first used unless it's an if/else where the field could be set in either.
The parameters can be `final`.
This should go away. `@ConditionalOnClass` already does that.
Is the change in behavior intentional? `SecurityException`, which was previously caught and logged, is an instance of `RuntimeException`.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Same thing here with the `connectorProps` vs the `config`.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
I think it would be better to wait until the Kafka Streams client id in state `RUNNING` and then verify if the history of the states transitions after adding the stream thread is first `REBALANCING` and then `RUNNING`. Currently, the order is not verified as far as I can see.
Here you should test if the stream thread has the name of the stream thread that was removed before.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
Hmm, I'm having trouble reasoning about the shutdown in this case. In the existing cases, we'd have `WorkerSinkTask.stop()`/`WorkerSinkTask.awaitStop()` handle invoking these, which also tries to ensure this thread has exited and calls `SinkTask.stop()`. But in this case, this thread calls `WorkerSinkTask.abort()`, which only calls `SinkTask.stop()`. How would we manage a case where, e.g., work is rebalanced by the DistributedHerder, which would trigger the Worker to stop a task (from the Herder's thread)? Then we'd potentially have `SinkTask.stop()` called multiple times if it hit this `catch` block, right? I think the responsibility of which thread invokes certain methods might be getting confused here. (Admittedly, it is tough to get this right since the responsibilities of different threads is confusing in this code.)
prop: I would use `taskId01.toString()` here, since you are not testing the `taskId01.toString()` method. Our assumption is that the folder has a name that is equal to the result of `taskId01.toString()` and not `0_1`.
prop: I would use `taskId01.toString()` here, since you are not testing the `taskId01.toString()` method. Our assumption is that the folder has a name that is equal to the result of `taskId01.toString()` and not `0_1`.
Will that ever happen, though? In `maybeSetRunning` we only call `setState(RUNNING)` if all other threads are in the `RUNNING` state. So i guess it is more to stop moving to `REBALANCING` or `ERROR`
Suggestion on above function addConfiguredSecurityProviders: 1. I think using following format for security.providers: security.providers=provider1_classname,provider2_generator_classname key1:val1 key2:val2,... 2. So when parsing above config, if there is no parameters following provider1_classname, then we can think provider1_classname is java Provider, then insert it; if there are key:value pair parameters following provider2_generator_classname, we can think provider2_generator_classname is SecurityProviderGenerator, then create "Map<String, ?> config" from key:value pair parameters, then call configure and getProvider of instance of SecurityProviderGenerator. This way we can handle all different scenarios in the future.
Doesn't seem to be used for anything? Why not just log a message saying that it didn't contain any plugins? In fact, even if we save this here, it seems like we'd still want that error message since the lack of any plugins probably indicates an incorrect configuration.
typo: we want to test the **case** that poll() returns no records.
`Integer.toString` is a slightly more concise way of doing this.
Not sure you need to initialize the factory every time there.
nit: This check seems superfluous (and is inconsistent with the collection of connector callables).
Thinking about it a bit more, it seems struct's toString is the way to go. It's harder to mess up by using the underlying request struct. Builder toStrings are updated manually while struct toString just traverses the underlying struct so it will automatically pick up wire format changes.
Thinking about it a bit more, it seems struct's toString is the way to go. It's harder to mess up by using the underlying request struct. Builder toStrings are updated manually while struct toString just traverses the underlying struct so it will automatically pick up wire format changes.
Seems this `fail` did not work as expected? Otherwise the test would have failed all the time? Maybe we should rather set a boolean flag that we evaluate outside of the callback to let the test fail? Also, we have one run with zero exceptions and one run with 2 exception (one exception type each) -- not 4. Thus, we need to handle this differently for the error-injection and the "clean run" differently depending on the boolean test flag.
But `ProcessorStateManager` doesn't handle global tasks
It's mostly the flushing that concerns me, not really the offset commit. I don't think we need to make it synchronous, just that it seems silly to block that shared scheduler to complete it. My thought instead was to let the scheduler trigger the flush, but then let the task be responsible for waiting for its completion. While waiting, of course, it can continue writing to `outstandingMessagesBacklog`. So I don't think there should be any issue from a throughput perspective.
I think it would be preferrable to call this "globalPartitionCount" and call the gauge "globalPartitionCountGauge" or something similar.
again, naming of the test
same here as what i said below. You can use a `assertThat`
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Check TROGDOR.md. > All Trogdor RPCs are idempotent except the shutdown requests. Sending an idempotent RPC twice in a row has the same effect as sending the RPC once. Because the request is idempotent, sending it twice has the same effect, including the same result code.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
I concern that by stripping off just the first byte for base key and index key, we would be paying too much byte array copies which would be much slower than other stores (for which we just blindly copy-paste the bytes). Maybe we can have some optimization in-place for the first draft? E.g.: 1) for index key, we know we just need to add the first byte and strip the last four byte of seq (? is that right, need to double check). 2) for base key, we can just do a swap-copy from the index key to switch the position of timestamp and key.
Is this line intentional? Unit tests normally don't need to print out to console.
Well, won't we end up deleting the topics before closing it if we never reach the first `streams.close` ? Or does it not really matter in that case since something has already gone wrong (just curious, I'm fine with it as-is btw)
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Can this be a `byte`.
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
Is this line intentional? Unit tests normally don't need to print out to console.
Nitpick: I'd call this `getOrCreateFileChannel`.
Nitpick: I'd call this `getOrCreateFileChannel`.
Nitpick: I'd call this `getOrCreateFileChannel`.
Can this be a `byte`.
ok, potentially reduces allocations for the user, thanks
Is this line intentional? Unit tests normally don't need to print out to console.
You should deviate from the service's default here otherwise you're not testing anything.
I'm not too worried about it. We might try some "extract variable/method" refactoring when we merge.
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
It would be more helpful if the name were included, e.g. "Setting 'foo' must be uppercase."
typo in the test name.
Java 7 method. Not available in Java 6.
this overwrite of mm2config should go in the setup method, IMHO
nit: 'else' can be dropped
this overwrite of mm2config should go in the setup method, IMHO
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
`endOffsets.get(topicPartition)` can be replaced by `offset`
looks like this condition is only actual for `resubscribeBeforeTimeout` test
Same question here as earlier about the `Locale`
Same question here as earlier about the `Locale`
Similarly, everything up to the fetch (i.e. coordinator lookup, join group, and sync group) are pretty much the same in all of these methods. Maybe we turn it into a function (e.g. `prepareRebalance`).
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
Minor: it seems like this test would be a little simpler if you start subscribed to topic1 and then switch to topic2.
Thanks for the explanation. Make sense.
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
Same for all such calls.
Do we lose anything if we use `Set` instead of `Collection`? Seems like set is the right semantics.
Do we lose anything if we use `Set` instead of `Collection`? Seems like set is the right semantics.
The implication here is that wakeup won't work if you've fetched data and keep calling poll() when you have max records set small, right? This seems like it could be a problem for anything that takes a long time to process messages since the wakeup may be an indicator that the application needs to shutdown...
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
This doesn't seem to be used.
Please remove empty lines here and in the other test methods.
Please remove empty lines here and in the other test methods.
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
`advanceMs` is not the same as provided input parameter `advance` -- this would make the error message miss leading.
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
This would be less mysterious if this method were inlined into `updateLimitOffsets`. Right now, it's not terribly clear why it's ok to set the "last update offset time" in a method that doesn't update the offsets.
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
It can sometimes be hard to get the logs for failing tests, so it might be nice to get the failure reason in the actual test output. Check out `Matchers`: there should be a way to compose the checks you're doing here manually. It'll be something like: ``` assertThat( message, is( oneOf( containsString("Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING"), containsString("The state store, source-table, may have migrated to another instance") ) ) ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
There's no need to copy entry.getValue().sourceTopics into a HashSet just to iterate it. Later down you put individual soureTopic into a topicToTaskMap which already eliminates possible duplicate keys...
Can we use `assertThat(node.name, equalTo("source1")` or `assertEquals("source1", node.name)` instead of `assertTrue` for assertions like this? Elsewhere in this test, too
isFull is no longer used.
The change makes sense to me. I don't think anything would stop the auto-commits from going through. Even if there was such a mechanism, it seems better to explicitly disable it.
Seems just as efficient to me, especially since we only throw the first error.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
On second thought, I'm fine with keeping the predicate.
This should return `-1` as old `BadValueTransformer`
What's the purpose of this warning? It doesn't seem needed.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
This seems to be a "hack" -- IMHO, as task should be only in either one set/list, but never in both... Can we change the first loop to use an explicit iterator and remove a task from `tasksToCloseClean` when we add it to `tasksToCloseDirty`
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
Hmm.. Might not be too important, but it doesn't seem necessary to include the retry backoff in this check. If the user sets retries=0, then the backoff shouldn't matter.
Hmm.. Might not be too important, but it doesn't seem necessary to include the retry backoff in this check. If the user sets retries=0, then the backoff shouldn't matter.
Hmm.. Might not be too important, but it doesn't seem necessary to include the retry backoff in this check. If the user sets retries=0, then the backoff shouldn't matter.
Nit: somehow I don't like `blah`. Otherwise LGTM
nit (optional): Since a variable is used as a shorthand for the return value of this method, maybe a more intuitive name would convey the meaning better. E.g. `hasErrors` makes more obvious it's a boolean (`result` can be anything).
We should use interpolation instead of string concat here.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Thanks for double checking this! Then it lgtm.
Hmm, I'd just generate the randoms during set-up and add them to an array.
I am must wondering, if this should go into it's own test class `KStreamGlobalKTableJoinTest.java` ? Similar below.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
i think this would be better off as a test rather than in `setUp`
i think this would be better off as a test rather than in `setUp`
nit: this loop is a little unconventional. Maybe we could use `pollFirstEntry` instead of the iterator? Similarly in `setNumKip500BrokerNodes`.
from the KIP, I think this is supposed to be `source-task-metrics`
Was trying to save one short lived object, but maybe I was too paranoid.
Was trying to save one short lived object, but maybe I was too paranoid.
typo: moreq -> more
Maybe we can just a better name for `path` since it makes this code look suspicious.
Hmm, if there is any exception from here, we probably want to bubble it up to the caller. For example, in SocketServer.processNewResponses(), if send() hits any exception, we want to call updateRequestMetrics(() and avoid updating inflightResponses, and move on to the next response in the queue in the same loop.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
add `final` wherever possible
We tend to use different `node` value when multiple connections are created by a test. You could just replace `node` here with "1" and a couple of lines below with "2".
Could we use ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG etc instead of hand-coded strings? It is less error-prone for possible future changes.
Second parameter should be `serverConfigs`
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
can we just return here to make it clear that we are baling out? We then don't need the further `if(!initializable.isEmpty())` checks below
Since this is a fairly complex assignment process, I wonder if it would help to break it down into smaller functions (maybe one for each step?). Otherwise, this is going to be a pretty intimidating chunk of code for newcomers.
Can remove if initialize above
Since this is a fairly complex assignment process, I wonder if it would help to break it down into smaller functions (maybe one for each step?). Otherwise, this is going to be a pretty intimidating chunk of code for newcomers.
Hmm, normally `IllegalArgumentException` indicates that the argument to a function is bogus, right? That's not really the case here-- the function argument was fine, but the topic wasn't set up correctly. This can probably just be a generic `RuntimeException`, since we don't have a need to make it something fancier.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
I'd suggest moving this static method after the non-static methods.
I'd suggest moving this static method after the non-static methods.
You might consider using `OptionalDouble`.
I think this way of triggering the exception is not only complicated but it even might be a source of flakiness. Could we have some more straightforward? I think the original solution (overriding getResponse) was better than this.
iiuc, this is actually the bug that we are fixing here. On the current trunk, if flush or cache.close throws, we do _not_ close the wrapped store. Now, with this change, we still call flush, cache.close, and wrapped().close, regardless if some of them throw.
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
@ijuma Sorry, I don't know of a standard way of doing this,
@ijuma Sorry, I don't know of a standard way of doing this,
nit: unneeded parenthesis
nit: after.. what? I think you can drop "in time after." Here is the assertion that is used: ``` assertThat("Condition not met within timeout " + maxWaitMs + ". " + conditionDetails, testCondition.conditionMet()); ```
There should never be multiple requests, right? If there were, a second request might arrive between 168 and 169, violating the desired property. In that case, we should grab a lock instead. As long as there's only one requesting thread, and it always waits for the commit right after requesting, then we should be good.
nit: add `final` nit: add space `entry : writeBatchMap.entrySet()` (I thought this was a checkstyle rule? Wondering if my memory is wrong because build passed)
nit: could avoid the last space after `is correct.`
This can be static
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
This can be static
nit: add `final` nit: add space `entry : writeBatchMap.entrySet()` (I thought this was a checkstyle rule? Wondering if my memory is wrong because build passed)
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
nit: add `final` nit: add space `entry : writeBatchMap.entrySet()` (I thought this was a checkstyle rule? Wondering if my memory is wrong because build passed)
nit: could avoid the last space after `is correct.`
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
We should test that delete twice in a row fails with `IllegalStateException`
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
as above mentioned, the `listStore.all()` is not closed here.
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
```suggestion put(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, "/tmp/foo"); ```
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
nit: style seems to be to not include braces when there is only one if or else statement
You might consider using `OptionalDouble`.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Should this be included here, or should it refer to a dedicated section in the connect docs? I guess there's two cases: bootstrapping a whole new connect cluster, or upgrading an existing one. For the bootstrapping case it's not completely clear whether the "preparing" round is required.
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
nit: `toString` can be used implicitly
Is this just to prevent it from processing anything until you're ready to proceed? It seems like you can/are doing that just by controlling when to produce input messages and doing so one at a time (if that's accurate, then WDYT about renaming `process` to `processed` and flipping the boolean so it more clearly serves the purpose of indicating whether a record has yet been processed)
could move line 368 above this and then declare this as: `String [] parentNames = {this.name, streamImpl.name}`
Ah, yes, the magic is hardcoded here.
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
Maybe we can just a better name for `path` since it makes this code look suspicious.
The parameters can be `final`.
The parameters can be `final`.
We should test that delete twice in a row fails with `IllegalStateException`
Maybe we can just a better name for `path` since it makes this code look suspicious.
Hmm.. I am not sure this is sufficient. Any of the responses could return from the heartbeat thread.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
If we do not expect this to happen. Shouldn't we throwI IllegalStateException? In this case, if the broker returned a replica that is not in the request, the broker may have somehow misplaced a replica. We should probably alert in this case.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
Please, let's not. The other functions in AdminClient do not rely on metadata caching-- they use the latest metadata that is available. Deleting records shouldn't be a common operation. If it is, we can have a metadata cache with a configurable expiration time. I think it's also really bad to set an exception based on possibly stale information. You give the user no way out if the cache is stale (besides creating an entirely new admin client object, I suppose).
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
Should be more precise. See discussion about `HoppingWindow` and `TumblindWindow` in #1250
Should be more precise. See discussion about `HoppingWindow` and `TumblindWindow` in #1250
See if you can refactor this code which is similar to what beginningOffsets has (apart from the condition between pos1 and pos2)
nit: rename `byt` to `defaultValue`
Ok. Then the KIP wiki needs to be updated.
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
nit: We could use `singletonMap` here.
> Why does it do this? Maybe it's a translation layer for other stores? In which case, is it correct for Streams to second-guess the implementation and break its own contract by ignoring the marker interface and delivering non-timestamped binary data? I don't think that would work. Note, on restore, we always get the most inner store and would not call this "translation layer wrapper store" (and thus it would break as we would insert our converter and hand timestamped-bytes to the store that does not understand them). If one want to implement a translation wrapper like this, she need to "hide" it from Kafka Streams and not implement `WrappingStore` (ie, the translation wrapper must be the most inner store).
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: after.. what? I think you can drop "in time after." Here is the assertion that is used: ``` assertThat("Condition not met within timeout " + maxWaitMs + ". " + conditionDetails, testCondition.conditionMet()); ```
nit: I would move this block up, before calling `listOffsets`, in order to have the response ready. Same for other tests.
nit: break line
This is neat, but we shouldn't use it. There's an IntegrationTestUtil for getting a temporary folder, which is hooked in to support for different testing environments to set their desired temporary file location.
nit: break line
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
We should use try-with-resources here (for `DataInputStream`).
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
I think we should call `deserializer.configure(...)` here
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
I think we should call `deserializer.close()` here
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
It's a little confusing that this is named newValue, but is sometimes actually priorValue
I think we should call `deserializer.close()` here
Maybe we can also add sth. like `possibly because an older versioned client is used to send input topic messages to Kafka that do not have timestamps encoded` ..
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
nit: add `final`
I think you can just use `partition < partitionsCount` instead of using `compareTo`. Similar in line 558.
nit: I would move this block up, before calling `listOffsets`, in order to have the response ready. Same for other tests.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
nit: 'else' can be dropped
the naming used above seems better here ```suggestion Throwable exception = null; ```
the naming used above seems better here ```suggestion Throwable exception = null; ```
`Failed to flush accumulated records` -> `Failed to flush all accumulated records...` Also, it would be much more useful if we could say `%d of %d` batches although I see we would have to expose a `size()` method in `IncompleteBatches`
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
"given a read-only key"
I wonder if we ought to just assume that the error goes at the top-level. It's a little weird to receive a partition-specific error code here and then assume that it should be used for _all_ partitions.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
This is why the test was failing for you. The query is for a range of window start times, not record times. Since the window size is five minutes, the range `[now - 1 minute, now]` wasn't going to contain the actual window start time of `now - 5 minutes`. In other words, just a simple oversight :/ Sorry for the trouble.
as above: avoid `/` Update to ``` log.warn("Unable to read '{}{}{}'. Using default inputValues list", "resources", File.seperator, fileName); ```
e.getMessage will be more accurate.
@jeffchao traditionally Kafka used key,value pairs in properties and pass it everywhere and each implementation takes look at this config and pulls their interested key,value pairs. Example, authorizer interface https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/security/auth/Authorizer.scala#L35 . The pluggable class when it gets instantiated a configure method will be called and all the key,value in server.properties will be passed and it will pick whats relevant to the class. We can do the same here instead of asking users append key,values into the a config which is hard to configure and hard to get it right.
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
Yea, my suggestion would be to reuse the existing constructor as the construction of the `AlterConfigsResponseData` seems non trivial for a caller to do, compared with passing a map of errors.
nit `getMetadata` -> get`
Yea, my suggestion would be to reuse the existing constructor as the construction of the `AlterConfigsResponseData` seems non trivial for a caller to do, compared with passing a map of errors.
nit: the ternary operator can be used (`?:`) as below, unless you're not a fan. ```suggestion AbstractStatus.State connectorState = request.shouldRestartConnector(connectorStatus) ? AbstractStatus.State.RESTARTING : connectorStatus.state(); ```
I think we should probably move this log statement since this method doesn't actually reset offsets.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
I don't think we need the `null` checks.
Since these string literals are now relevant elsewhere, we should make them reusable constants. Perhaps they should be enums? I realize now that perhaps the class names should have also been enums but ð¤·.
Are these 3 lines an artifact of code reformatting? They don't seem to correspond to changes other than the reordering itself. The previous order matches the variable declaration order, so maybe we want to leave this as-is.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
I think we should have a `log.info()` here to show the error. I'm afraid users might miss some error statuses once they get overridden, so it's good to have it persisted somewhere
```suggestion if (this.streamsUncaughtExceptionHandler.handle(e) = StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) { log.warn("Exception in global stream thread cause the application to attempt to shutdown." + " This action will succeed only if there is at least one StreamThread running on ths client"); } ``` This looked a bit off...
@cmccabe is right about the race condition I think. we should probably check that `controlChannel` is initialized here
We can use `new ProducerRecord<>(topic, "value");` to simplify it a tiny bit
We can use `new ProducerRecord<>(topic, "value");` to simplify it a tiny bit
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
I think we ditch the before/after methods as I previously recommended.
I think we ditch the before/after methods as I previously recommended.
This is also the default, I think.
We should include `startPosition` in the message.
We should include `startPosition` in the message.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
```suggestion log.warn("{}.config() has returned a null ConfigDef; no further preflight config validation for this converter will be performed", headerConverterClass); ```
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
I don't think that's what I had in mind. What we need to do here is check if "NONE" is active and change the description accordingly.
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
Maybe a cleaner approach is to provide two separate `Logger` implementations.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
Is this just to prevent it from processing anything until you're ready to proceed? It seems like you can/are doing that just by controlling when to produce input messages and doing so one at a time (if that's accurate, then WDYT about renaming `process` to `processed` and flipping the boolean so it more clearly serves the purpose of indicating whether a record has yet been processed)
@amethystic I believe Jun is suggesting that it is abnormal for `readFully` (i.e. if you can't fill the buffer, then something is wrong). I think a case can be made for that. I think the downside is that the error messages may not be as good as if the callers do the check themselves. The upside is that we avoid the situation where the caller forgets to check. We'd have to verify that these semantics are right for `FileRecords.readInto` since it doesn't perform any checking atm.
nit: 'else' can be dropped
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
nit: Indicate that this needs shallow iterations on the entries.
@amethystic I believe Jun is suggesting that it is abnormal for `readFully` (i.e. if you can't fill the buffer, then something is wrong). I think a case can be made for that. I think the downside is that the error messages may not be as good as if the callers do the check themselves. The upside is that we avoid the situation where the caller forgets to check. We'd have to verify that these semantics are right for `FileRecords.readInto` since it doesn't perform any checking atm.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
Yeah, builders are nice for the reasons you mention. However, since it wasn't discussed in KIP-222, I think keeping it package private for now might be better.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
Nit: somehow I don't like `blah`. Otherwise LGTM
super nit: the message should explain what happened if the condition fails, ie it should be the opposite, something like ```suggestion TestUtils.waitForCondition(() -> !process.get(), "The record was not processed"); ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
It would be more helpful if the name were included, e.g. "Setting 'foo' must be uppercase."
Maybe we can just a better name for `path` since it makes this code look suspicious.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Maybe we can just a better name for `path` since it makes this code look suspicious.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
It seems I also could approve it. I will read all code tomorrow and work with you to get this approved.
I would change this to `# Prevent logging from appearing in test output.`
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
hm.. maybe I just did not notice `config.timeWindowMs`. All good now.
Same as before, parameters of `assertEquals` should be the other way round.
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
nit: no need newline of 104 below.
nit: no need newline of 104 below.
The second newline should be left for the caller, as it otherwise causes an extra line before 'Dependents' in the enriched RST
Private and call from the constructor? We only ever call this immediately after instantiating the class.
Private and call from the constructor? We only ever call this immediately after instantiating the class.
nit: parameters on a separate line
Ah that's good to know, I've polished that in https://github.com/spring-projects/spring-boot/commit/04544f98428cae4c3083f0ee58410eea3591f066
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Should we really catch NPE here? It seems like if the user wants to return a non-null mapped key from a null key, then they should handle the null case specifically in their `keyMapper` and not just throw an NPE. In general, an NPE is a sign that something has gone wrong. I would be pretty surprised if I threw an NPE explicitly in my user code and it just got swallowed and interpreted as if I had actually returned null.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
typo: CompleteableFuture -> CompletableFuture
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
`replicaing` -> `replicating`
as above. Name of the test can be more descriptive. `shouldRequireBrokerVersion0101OrHigherWhenEosDisabled`
as above. Name of the test can be more descriptive. `shouldRequireBrokerVersion0101OrHigherWhenEosDisabled`
I believe a null-pointer check is necessary here.
On my PR, I had copied `awaitForComplete` into into `BlockingSingle`. This is obviously cleaner :p
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
I just read through `MemoryLRUCache`. It is not thread-safe and will corrupt itself because a read causes a mutation of the LRU history. (I made the same mistake early in my career when fixing performance problems leading to exploring caching in-depth, so its an easy oversight to make) A read/write lock is a very expensive mechanism and most often the incorrect lock type to use. For short critical sections it is more expensive than an exclusive lock. By using a `ReentrantLock` or `synchronized` you'll have both correctness and higher performance. As is, I strongly urge you to correct this before merging. You don't have to use a caching library, but the code is very broken.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
Seems we're missing the second purpose.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
Private and call from the constructor? We only ever call this immediately after instantiating the class.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Nit: seems like the interrupted check should be done before we compute the remaining time (from a clarity point of view).
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
I don't think we really need this function any more... we can just submit to the executor from the other function.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
This looks unintentional.
nit: add `final`
nit: Indicate that this needs deep iterations on the entries.
I don't think we need this `null` check either.
```Calling flush() from callback is not allowed since it makes deadlock.```
the naming used above seems better here ```suggestion Throwable exception = null; ```
```Calling flush() from callback is not allowed since it makes deadlock.```
nit: `err` is not used elsewhere. You may choose to iterate directly over the collection that is returned.
There are a couple of checkstyle failures in these two lines because of missing spaces
Recently, we prefer to use `assertThat()` instead of `assertEquals()`.
nit: if you want a new paragraph you need to add `<p>`
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
nit: `err` is not used elsewhere. You may choose to iterate directly over the collection that is returned.
Would this be better as an `nc -z` test? Grepping logs was always kind of a half-assed solution, and the real test we care about seems to be whether anything is actually listening on the port. We have this now for at least jmx (thanks to yours truly) and ZK (thanks to @kkonstantine) and I'd like to continue the trend elsewhere as it is far less brittle than grepping logs.
We don't need tags in this function, I think.
Personally, I prefer (3) because the others provide redundant information.
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
nit: if you want a new paragraph you need to add `<p>`
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
Why using StopWatch? this create many short live objects for not resean.
Why using StopWatch? this create many short live objects for not resean.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
This statement is a bit misleading, how about "to the format indicated by the given magic value".
super nit: taskCreationLock --> taskDirCreationLock
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
I don't think we need this `null` check either.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
How is this better than a method that returns the map? Is it because we pass the map with a lock held? Could we expose a map get method instead? Calling callbacks with locks held tends to cause problems and I'm a bit concerned that someone will see this method and use it outside of tests.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
This name seems backwards.
Private and call from the constructor? We only ever call this immediately after instantiating the class.
What's the purpose of this warning? It doesn't seem needed.
There is https://github.com/ben-manes/concurrentlinkedhashmap. Guava and Caffeine (Java 8 required) also have Cache implementations with the same underlying behaviour.
How is this better than a method that returns the map? Is it because we pass the map with a lock held? Could we expose a map get method instead? Calling callbacks with locks held tends to cause problems and I'm a bit concerned that someone will see this method and use it outside of tests.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
```suggestion pk_setting = getattr(self.app_config, 'default_auto_field', settings.DEFAULT_AUTO_FIELD) pk_class = import_string(pk_setting) if not issubclass(pk_class, AutoField): raise ValueError("Configured default auto field '%s' is not a subclass of AutoField." % pk_class) auto = pk_class(verbose_name='ID', primary_key=True, auto_created=True) ```
next() samples the sequence, it's not supposed to buffer the entire sequence so it can't be used for forEach which must be applied to every onNext call in an Observable. It could be done with toIterable/toEnumerable, but I wouldn't want that since that would first buffer the entire thing in a list and then call forEach over it. forEach should be invoked as each element is emitted to onNext in without buffering.
I've seen alternative solutions floating around that use a configurable source here. Basically, the configuration passed to configure() is consulted to find the "source cluster", rather than looking at the topic name. That approach lets you return an actual source here, which obviates the new canTrackSource() method etc.
I think it'd be better to include the whole exception by using `warn(String, Throwable)` rather than just the message, particularly as the message is already part of the health's detail
I'd suggest moving this static method after the non-static methods.
I really like the fact that we are separating Resources from ResourcePatterns! Great job.
You might consider using `OptionalDouble`.
I'd suggest moving this static method after the non-static methods.
I think this should ensure it preserves the order of the tags.
I really like the fact that we are separating Resources from ResourcePatterns! Great job.
This should go away. `@ConditionalOnClass` already does that.
I believe a null-pointer check is necessary here.
Style convention: this should be called `value()`.
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
To be consistent with the rest of the code, this.flg can just be flg.
To be consistent with the rest of the code, this.flg can just be flg.
Ah got it, I'm still think about it as the string template and was overlooking that. SG.
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
nit: we can do without the curly braces here and above. However, these will soon be replaced by the actual impl
nit: add `final
At the moment, within `ForeachAction` the `context` is not accessible. Even if we have some plans to change this it does not help you, as we don't have any timeline for the change.
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
This change appears to be unrelated.
This formatting change is not related with a bug fix, please revert.
How about "runs an external command for the worker."
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
In the task constructor we already created a bunch of modules, like the metrics and the producer object. We need to make sure these modules still get cleared even when the task was not initialized.
Thanks for bringing this up @dguy @enothereska , thinking about this more I feel it is Okay to state that users should not call any public APIs of the `KafkaStreams` object inside this callback, if they do then undefined behavior.
In the task constructor we already created a bunch of modules, like the metrics and the producer object. We need to make sure these modules still get cleared even when the task was not initialized.
given that the previous messages say "Reading to ..." maybe it would make sense to say: ```suggestion log.trace("Read to end offset {} for {}", endOffset, topicPartition); ```
remove var -- only used once.
I am must wondering, if this should go into it's own test class `KStreamGlobalKTableJoinTest.java` ? Similar below.
nit: add a size? There are a few cases in here where we could do this.
offtopic: I'm wondering if we should drop `SubscriptionHelper.isCancelled()`
we're in Java8 now... I think you can do: `(key,value,context) -> { ... }`
we're in Java8 now... I think you can do: `(key,value,context) -> { ... }`
`apiKey` is of type `ApiKeys` while `requestHeader.apiKey()` returns a `short`.
Making timeouts configurable could be a good idea, but it's better done in a general way in its own PR.
Sorry for the confusion. I thought `hasRemaining` made sense initially, but then I realized that the name should be more suggestive of its usage. I'd prefer something like `ensureNoneRemaining`, but it's not a dealbreaker for me.
nit: creating restoredPosition is not required if !constinceyEnabled
nit: creating restoredPosition is not required if !constinceyEnabled
This function isn't used, and when you implement the same functionality in `eric_eccli_command` you probably shouldn't be doing it yourself anyway.
The map is not used.
Thanks @guozhangwang I was just checking, and we also define `"stream-processor-node-metrics"` in `ProcessorNode` -- should we unify both, to have one constant only? Think, we can also simplify `ProcessorNode#createTaskAndNodeLatencyAndThroughputSensors` and remove the `group` parameter.
The map is not used.
The map is not used.
The map is not used.
need a check for null on `obj` here as well
need a check for null on `obj` here as well
```suggestion @Evolving public class WindowKeyQuery<K, V> implements Query<WindowStoreIterator<V>> { ```
```suggestion @Evolving public class WindowKeyQuery<K, V> implements Query<WindowStoreIterator<V>> { ```
```suggestion "The desired Unix precision for the timestamp. Used to generate the output when type=unix " + ```
It seems like the `weights` argument for `preprocess_weights_for_loading` is not really a list of numpy arrays. It's a list of `HDF5 dataset`. When I call `print(weights)` on my machine, I saw something like: ``` [<HDF5 dataset "kernel:0": shape (100, 96), type "<f4">, <HDF5 dataset "recurrent_kernel:0": shape (32, 96), type "<f4">, <HDF5 dataset "bias:0": shape (192,), type "<f4">] ``` Hence there would be some metadata attached to the weights. Specifically, with `print([x.name for x in weights])`, the output is: ``` ['/model_weights/cu_dnngru_1/cu_dnngru_1/kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/recurrent_kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/bias:0'] ``` However, I'm really not sure if this is a behavior that we could rely on (i.e., is it a consistent behavior for different versions of h5py, different versions of Keras, python, OS, ...). Also, it might not pass some existing tests since the tests are written under the assumption that the input is a list of arrays.
nit: add a space before the `:`.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
@original-brownbear I understand that part, but IMHO it's best if we stick to some basic guidelines for our tests/benchmarks. To reduce the GC impact how about we decrease the cache size to 5, and the number of records to insert 25 or so? Or just create an array inline with the keys and declare as a private variable? Either way, we should be able to do the work in the `setUp` method.
@original-brownbear I understand that part, but IMHO it's best if we stick to some basic guidelines for our tests/benchmarks. To reduce the GC impact how about we decrease the cache size to 5, and the number of records to insert 25 or so? Or just create an array inline with the keys and declare as a private variable? Either way, we should be able to do the work in the `setUp` method.
Nice solution to this problem.
Did you plan to implement this? If you not, you can use the trick you are doing in other places. E.g. ```java static ConfigurationValidator NOOP_VALIDATOR = (_, __) -> {}; ```
Might be worth changing this so when there is only one exception, it doesn't wrap and lenghten the stacktrace unnecessarily.
I think we can avoid this alignment style. It leaves us with significantly less space to write lambdas, etc. (another indicator is that this style is not applied elsewhere in the file). Two tab stops in the line below should be fine, even if the declaration above is where it is now.
Might be worth changing this so when there is only one exception, it doesn't wrap and lenghten the stacktrace unnecessarily.
prop: I find the `assignment.` prefix a bit clumsy and I think we do not really need it. Other configs do also not have its context prepended like for instance `built.in.metrics.version`.
You can't expose such thing in an exception.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
I fixed this one to use the constant before merging.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
My approach is shared here: https://github.com/stepio/kafka-json/blob/master/src/main/java/org/stepio/kafka/common/serialization/JsonDeserializer.java
What value does this test provide? Seems it verifies that `setup()` method is correct? Seems unnecessary to me.
@guozhangwang **Forgive me if I misunderstood this method, really**. But if the list is composed of key-value pairs, wouldn't this for loop goes up to the the middle of the array? Plus, if `tags` is `"a","1","b","2"` the final map will be `"a" -> "1", "1" -> "b"`. Is this the right intend? Besides not reaching "b" -> "2", it will make the previous value a key in the next iteration. If not, I suppose we could rewrite it as ``` for (int i = 0; i < tags.length; ) { tagMap.put(tags[i], tags[i+1]); i += 2; } ``` Again, forgive me if I understood everything wrong.
prop: I would use `taskId01.toString()` here, since you are not testing the `taskId01.toString()` method. Our assumption is that the folder has a name that is equal to the result of `taskId01.toString()` and not `0_1`.
prop: I would use `taskId01.toString()` here, since you are not testing the `taskId01.toString()` method. Our assumption is that the folder has a name that is equal to the result of `taskId01.toString()` and not `0_1`.
This is added in #986 as well. The later patch to go in will have to rebase, or we can extract out the common code as a separate PR. I am fine with either way. FYI @becketqin.
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
Can you re-warp this block to 79 chars? (First line is too short.)
nit: creating restoredPosition is not required if !constinceyEnabled
Good point! @vpapavas , can you handle stuff like this in a follow-on PR? I'm doing a final pass to try and get this one merged.
whenever referring to Connect as the framework (as opposed to the verb) I'd use `Connect`. Same as `Kafka cluster` and `Connect framework` a few words after. It's easy to miss that you are referring to the framework if it's not capitalized.
whenever referring to Connect as the framework (as opposed to the verb) I'd use `Connect`. Same as `Kafka cluster` and `Connect framework` a few words after. It's easy to miss that you are referring to the framework if it's not capitalized.
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Actually let me put in this way: `restoredPartitions` could just be local to this function? It's only usage outside is in `clear` so it seems we can keep it local or just use `restored` directly and remove it from `clear`.
I'd consider making this extend org.junit.rules.ExternalResource - it can then be used as a JUnit ClassRule or Rule. The benefits being that the JUnit framework takes care of startup and shutdown
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Shouldn't this be in the contract of `Utils.newInstance` to not return some other class that doesn't match? I think this is pulled from `AbstractConfig` which makes sense for consistency, but I don't get why `Utils.newInstance` would ever return a value with an invalid type.
I am wondering why this is not an assertion. Would the broker ever be expected to return only a subset of the partitions in a full fetch request? To be honest, I think it would be fine to skip these checks and just assume the broker gives us the right thing.
I am wondering why this is not an assertion. Would the broker ever be expected to return only a subset of the partitions in a full fetch request? To be honest, I think it would be fine to skip these checks and just assume the broker gives us the right thing.
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
Ah, yes, the magic is hardcoded here.
Still don't need these 2 lines.
I think this would be clearer if called `isSendToPartitionAllowed`. At first I thought this method was sending to a partition. :)
nit: you could just specify one `String` variable at the top of the method and set it accordingly if `topics` is `null` or not then have a single `return` statement. Just a personal preference though.
Not sure about this test the title says `shouldUseSpecifiedNameForGlobalTableSourceProcessor` but it's asserting the names of state-stores. But we can fix this in one of the following PRs.
Maybe use Objects.requireNonNull
Maybe use Objects.requireNonNull
I think we should call `deserializer.close()` here
and -> a
This statement is a bit misleading, how about "to the format indicated by the given magic value".
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
nit: unneeded parenthesis
Throwing `IllegalStateException` is served as the purpose that "this should never happen, and if it does it is a bug and hence it is ok to fail and stop the world".
nit: parameters on a separate line
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Same minor nitpick about whether or not we need to check for an empty group ID.
nit: use `private static` ordering (for consistency with the rest of the code base)
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
nit: use `private static` ordering (for consistency with the rest of the code base)
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
I don't think we consider `SslFactory` a public API, so I think we are probably good here.
@ijuma Sorry, I don't know of a standard way of doing this,
nit: add `final`
nit: add `final`
Hmm this would fail for the old schema. I think we have to use `getOrElse`.
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
nit: we are not "overriding" them, but duplicate them with the prefixed props right? If the user has already applied the prefix then this function would mostly be a no-op.
nit: braces unneeded
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
I see what you intended. Thanks for the response.
I see what you intended. Thanks for the response.
Personally I would prefer not special handling this case with the different schedule time, as this could change the commit interval unexpectedly for users; instead we can just move forward with the regular commit interval, and if the next commit fails again it may be fine still.
The functionality of process() now is completely covered by transform: users can define a transform function with return type R be "Void" and add a dummy "return null" in the end of the function. And then in KStream we can add public void transform(TransformerSupplier<K, V, Void>) to replace the "process()" call. Having both process() and transform() might be confusing to users, so I would suggest we just remove process() here.
The functionality of process() now is completely covered by transform: users can define a transform function with return type R be "Void" and add a dummy "return null" in the end of the function. And then in KStream we can add public void transform(TransformerSupplier<K, V, Void>) to replace the "process()" call. Having both process() and transform() might be confusing to users, so I would suggest we just remove process() here.
Clever. Quite timely for you to have fixed this as I came across this problem just last night.
This would require a separate KStreamVoidTransformProcessor, but I feel it worth the internal cost for simpler public APIs.
Clever. Quite timely for you to have fixed this as I came across this problem just last night.
Clever. Quite timely for you to have fixed this as I came across this problem just last night.
This TODO should be removed
nit: Indicate that this needs shallow iterations on the entries.
we just generally try to avoid the mess if the code isn't ready to be committed yet. it can always be held onto in a branch, wip pr, etc
we just generally try to avoid the mess if the code isn't ready to be committed yet. it can always be held onto in a branch, wip pr, etc
What if it is a file? We didn't really talk about this, but it could potentially be a list of uberjars. Even if we don't want to support this here, at least log something if the entire path is going to be ignored due to not being a directory.
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
This doesn't seem to be used.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
This should go away. `@ConditionalOnClass` already does that.
we only need the lock for setting the seed and calling `random.nextInt`, right? for the rest of the function we can avoid holding the lock since we're just iterating over an immutable list that can't change and calling stuff that is threadsafe anyway
Same question here about just using a static ConfigDef instead of a static method.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
typo: byteArrray -> byteArray
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
This should go away. `@ConditionalOnClass` already does that.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
we only need the lock for setting the seed and calling `random.nextInt`, right? for the rest of the function we can avoid holding the lock since we're just iterating over an immutable list that can't change and calling stuff that is threadsafe anyway
we only need the lock for setting the seed and calling `random.nextInt`, right? for the rest of the function we can avoid holding the lock since we're just iterating over an immutable list that can't change and calling stuff that is threadsafe anyway
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
Actually there are a few places like this. Maybe we can figure out how to let jmx_tool always be set even if we're not scraping any JMX objects? I think that's how the mixin worked before.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I'd prefer that we use `TimeUnit.SECONDS.toMillis(10)` and `TimeUnit.SECONDS.toMillis(1)` here. It avoids having to do any math when looking at the code.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
nit: add `final` (same below)
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Then we wouldn't have caught this bug ð . The most dangerous aspect of the generated protocols is the down-conversion to older formats since it gets poor test coverage.
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
add `final` (also all other methods below)
This was probably left by mistake.
`endOffsets.get(topicPartition)` can be replaced by `offset`
nit: you could just specify one `String` variable at the top of the method and set it accordingly if `topics` is `null` or not then have a single `return` statement. Just a personal preference though.
`endOffsets.get(topicPartition)` can be replaced by `offset`
This was probably left by mistake.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
nit: you could just specify one `String` variable at the top of the method and set it accordingly if `topics` is `null` or not then have a single `return` statement. Just a personal preference though.
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
This was probably left by mistake.
Side improvement: I think we should skip late record directly and also record it in `TaskMetrics.droppedRecordsSensorOrExpiredWindowRecordDropSensor`
This was probably left by mistake.
Is this really worth it? It seems like a `forMagic` without a transactional id gives you most of the benefit.
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
It seems that this is an internal request and is never throttled.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
Hmm, I guess fewer moving pieces does make sense for this, OTOH if you can't load a file off disk you're pretty broken :-) On Sun, May 18, 2014 at 4:04 PM, Markus Amalthea Magnuson < notifications@github.com> wrote: > In django/views/debug.py: > > > @@ -1121,7 +1135,7 @@ def default_urlconf(request): > > <!DOCTYPE html> > > <html lang="en"><head> > > <meta http-equiv="content-type" content="text/html; charset=utf-8"> > > - <meta name="robots" content="NONE,NOARCHIVE"><title>Welcome to Django</title> > > - <meta name="robots" content="NONE,NOARCHIVE"><title>{{ window_title }}</title> > > I figured all of these are in strings to be able to serve error pages even > if the template engine has failed. But that's just a theory :) > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/2682/files#r12776836 > . ## "I disapprove of what you say, but I will defend to the death your right to say it." -- Evelyn Beatrice Hall (summarizing Voltaire) "The people's good is the highest law." -- Cicero GPG Key fingerprint: 125F 5C67 DFE9 4084
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Should we consider including the error message of `e` in to the exception as well? also nit: capitalized `Fatal`.
Good point, I think we should add `this.nano += TimeUnit.NANOSECONDS.convert(autoTickMs, TimeUnit.MILLISECONDS)` in `nanoseconds()` as well.
Seems as if this refactor hasn't been updated on the PR
This should be a private method, I believe
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
This was probably left by mistake.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: we can throw AssertionError here to indicate this should not happen.
nit: we can throw AssertionError here to indicate this should not happen.
This line is failing checkstyle.
nit: extra blank line ```suggestion ```
Can we also rename `StreamsGraphNode` to `GraphNode`? The `Streams` prefix is a bit confusing, IMO, because `StreamSourceNode` and `StreamsGraphNode` seem really similar although they are quite different.
This line is failing checkstyle.
Yes, it seems that -1 means that we are trying to read beyond the end of the channel, which probably should be treated as abnormal.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
nit: this loop is a little unconventional. Maybe we could use `pollFirstEntry` instead of the iterator? Similarly in `setNumKip500BrokerNodes`.
Yeah, builders are nice for the reasons you mention. However, since it wasn't discussed in KIP-222, I think keeping it package private for now might be better.
Are both host groups really needed? Does the one that contains ':' handle both? We have regex in other places in the project that do similar parsing we may want to keep in sync: - https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/utils/Utils.java#L53 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/BrokerEndPoint.scala#L27 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/EndPoint.scala#L29
Are both host groups really needed? Does the one that contains ':' handle both? We have regex in other places in the project that do similar parsing we may want to keep in sync: - https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/utils/Utils.java#L53 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/BrokerEndPoint.scala#L27 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/EndPoint.scala#L29
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
I think this would never happen now since the passed in `recordPerTopicPerPartition` is always initialized.
I think this would never happen now since the passed in `recordPerTopicPerPartition` is always initialized.
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
I would prefer `advanceBy(long advance)`
You can just do i+=2 in the for loop.
We we improve this test class further (this method is ok I guess). Methods below for example: ``` @Test public void shouldBuildKeyValueStore() { final KeyValueStore<String, String> store = Stores.keyValueStoreBuilder( Stores.persistentKeyValueStore("name"), Serdes.String(), Serdes.String() ).build(); assertThat(store, not(nullValue())); } ``` Only check for not-`null` what seems to be a poor verification. (Maybe others can be improved, too).
Nit: please add `final` to all local vars and method parameters
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
nit: 'else' can be dropped
I think we can just have one function between `values` and `groups` here. I'd suggest we use ``` public Map<TopicPartition, KafkaFuture<Void>> deletedGroups() ```
-> `storeName()` (without `get`)
I see. `MaterializedInternals` must be `public` and cannot enlarge the scope if `Materialized` constructor is `protected`... What about adding a public static method `MaterializedInternals#fromMaterialized(Materialized)` that calls the copy constructor? This way, we could make it protected IMHO.
Just thinking about is once more: why do we need to make this interface public? We have `Named` as public method to use `NamedOperation` and other public control objects (`Consumed` etc) that implement it -- but I actually think, users don't need to know about this interface? \cc @fhussonnois @bbejeck @guozhangwang @vvcephei @ableegoldman
Just thinking about is once more: why do we need to make this interface public? We have `Named` as public method to use `NamedOperation` and other public control objects (`Consumed` etc) that implement it -- but I actually think, users don't need to know about this interface? \cc @fhussonnois @bbejeck @guozhangwang @vvcephei @ableegoldman
I guess we could also get an auth error for the groupId.
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Yes, this should on an internal package (eg `common.internals`).
Nit: I think the state transition should be done before the INFO log.
should this be null? perhaps throw an IllegalArgException
as above `final` and one parameter per line
The "Swallowing the exception" is a bit alarming at first. It's true that if this method returns false then `TestUtils.waitForCondition` (which is using this method as the test condition) will fail at line 137. Pretty minor, but how about the following? ``` // Log the exception and return that the partitions were not assigned log.error("Could not check connector state info.", e); return false; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
nit: insert space `String... expected`
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
If we were to use a epsilon here... it should be abstracted as a globally configured epsilon. Also, I think this value is too low and would cause issues with GPUs (float32). But anyway: we shouldn't. If the sum of the weights is zero, then the problem is ill-defined and a loss cannot be computed. We should throw an exception in that case.
Ok. We also have a check in `subscribe` to ensure that the set of assignors is not empty. There might be a way to remove the redundant checking. By the way, there's a typo above: `confingure`.
Ok. We also have a check in `subscribe` to ensure that the set of assignors is not empty. There might be a way to remove the redundant checking. By the way, there's a typo above: `confingure`.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
Since equality is measured by comparing timestamps something like `return Objects.hash(timestamp);` should be used instead.
You'll hate me, but I see a tiny chance for `ClassCastException` that we can avoid.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
You'll hate me, but I see a tiny chance for `ClassCastException` that we can avoid.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
That check should be reversed: we assert that it's not null, the `else` part dealing with the case when it is.
same for tests below as well
+1 -- also below in other tests.
This is the essential line of the test that verifies the change in #7097. Without the fix in #7097, the listener will get an update with *all 3 task IDs*, and to pass this line would then need to be changed to: ``` configUpdateListener.onTaskConfigUpdate(Arrays.asList(TASK_IDS.get(2), TASK_IDS.get(0), TASK_IDS.get(1))); ``` However, we don't want *all* task IDs to be updated. Instead only want only the task ID(s) for the tasks that were indeed updated. That's why this test case expects that the task config update only includes the one ID of the task that is actually updated (i.e., `TASK_IDS.get(2)`). So as is, this test method will fail unless the fix for #7097 is actually applied.
I'm assuming it's worth keeping this 2nd loop separate from the first one for performance reasons. At first glance it looks strange to iterate over the same collection twice in a row
rewrite test as above using `assertThrows()`.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
Nit: can be `final`
`windowSize` should be `Duration`
Don't concern yourself with dots. If they aren't an acceptable character for a particular monitoring system, it is the responsibility of Micrometer's `NamingConvention` for that registry to strip or escape them.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
same for the store
We shouldn't return `null`, but instead return a "unknown query" result.
Can we simplify the patch by not having this method? We pause a partition after putting it in `recentlyUnPausedTopicPartitions`, we can still use `fetcher.subscriptions` to check whether the partition is unpaused while going over the partition in `recentlyUnPausedTopicPartitions`.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
Nit: param alignment.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
Here too it seems like we can use the generic version of `prepareOffsetCommitResponse`.
Setter methods again.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
Setter methods again.
nit: extra line
nit: unneeded newline
Nit: var should be named `deserializeValue`
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
the `try{...} finally` has been removed
nit: unneeded newline
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
You should use try with resources here too.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
We can return `false` on the first mismatch no need to check the rest of the arrays.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
Why is `completed` count being tracked? It doesn't seem to be used anywhere.
nit: move `windowBy()` to it's own line -- also `count()` (similar below)
There's a heck of a lot of code inside the resource block of this `try`. The only thing that really needs to be there is the `new KafkaStreams`. Can we assign the config to a variable prior to the try block? I don't feel strongly about this, but it just seems a little harder to parse visually when there is so much code separating the `try` from the actual block.
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
I think upon close(), we can also use `maybeAutoCommitOffsetsAsync` and then we can remove the whole function fo `maybeAutoCommitOffsetsSync`.
Nit: use `java.nio.charset.StandardCharsets.UTF_8` here rather than `Charset.forName(...)`. The latter has to do a lookup every time.
nit: I don't spot any, but safer to avoid typos by just having constants for these
Tiny nitpick: `TopicPartition.toString` does what you are doing manually here, so you could simplify it by just saying: ``` java "Batch containing " + recordCount + " record(s) expired due to timeout while requesting metadata from brokers for " + topicPartition ```
We recently "fixed" `listAllTaskDirectories` to guarantee that it never returns null. We just missed to update all the null checks when we did that
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
Please add spaces around the equal sign.
Should this call be governed by !dryRun
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Please add spaces around the equal sign.
Please add spaces around the equal sign.
nit: add a space before the `:`.
nit: add a space before the `:`.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
A common pattern for classes like this without any state is to create a static instance. ```java public static final UnknownAddressSpec INSTANCE = new UnknownAddressSpec(); ```
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Thanks very much. I'll mark this as a draft for now so that we know it's not quite ready to be merged.
Perhaps this can be private and we can expose a `buildUnsafe` method that sets `validate` to false. Then we will be less tempted to accidentally use the API.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
Perhaps this can be private and we can expose a `buildUnsafe` method that sets `validate` to false. Then we will be less tempted to accidentally use the API.
This could also potentially be simplified to iterate over their fields together, which is probably cheaper than than the map lookups by field name. (In fact, *strictly* speaking it should be safe to just use the field from the original in the copy since they are supposed to be exactly identical anyway.)
NPE: ![image](https://user-images.githubusercontent.com/925755/55269396-d55f3480-5292-11e9-9c29-78c524d63c65.png) I'm not using a topic pattern, equality should still work.
I think this and following usages around `latestSupportedVersion` are related to the upcoming version probing code. It's a little mysterious to have a "latest supported version" always equal to the "current version" in this PR in isolation, but I don' think it's actually problematic.
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
Same thought w/r/t performing assertions on the complete set of returned plugins: ```suggestion Set<Class<?>> excludes = Stream.of( ConnectorPluginsResource.SINK_CONNECTOR_EXCLUDES, ConnectorPluginsResource.SOURCE_CONNECTOR_EXCLUDES, ConnectorPluginsResource.TRANSFORM_EXCLUDES ).flatMap(Collection::stream) .collect(Collectors.toSet()); Set<ConnectorPluginInfo> expectedConnectorPlugins = Stream.of( SINK_CONNECTOR_PLUGINS, SOURCE_CONNECTOR_PLUGINS, CONVERTER_PLUGINS, HEADER_CONVERTER_PLUGINS, TRANSFORMATION_PLUGINS, PREDICATE_PLUGINS ).flatMap(Collection::stream) .filter(p -> !excludes.contains(p.pluginClass())) .map(ConnectorPluginsResourceTest::newInfo) .collect(Collectors.toSet()); Set<ConnectorPluginInfo> actualConnectorPlugins = new HashSet<>(connectorPluginsResource.listConnectorPlugins(false)); assertEquals(expectedConnectorPlugins, actualConnectorPlugins); verify(herder, atLeastOnce()).plugins(); ```
@dajac just to clarify, are you concerning that the `generation()` may change between the check and the error-log? If yes maybe we do not need to synchronize the whole function, instead we just get a reference of the returned `generation()` call and use that in the error-log, since the generation object is immutable.
Log this kind of stuff at `debug`, it's useful info to have
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
nit: add `final`
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
I probably would have these 12 lines in a `consumerProps` method and also reuse it from `getConsumerConfigs`. But if you think it's better this way, then that's OK.
nit: add `final`
I probably would have these 12 lines in a `consumerProps` method and also reuse it from `getConsumerConfigs`. But if you think it's better this way, then that's OK.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. Would you mind to not move configs that get deprecate and add the new config at the "right" place. Thanks a lot. :)
Just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. Would you mind to not move configs that get deprecate and add the new config at the "right" place. Thanks a lot. :)
https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/log/LogConfig.scala#L150 can reference to this new field.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Ditto on removing before/after
Ditto on removing before/after
Can we call this `toHtml` to go along with the generically named `toRst`? If we want to change the output in the future, we won't need to add a new API.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
We shouldn't return `null`, but instead return a "unknown query" result.
Seems like a no-op
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
`InternalProcessorContext` is already public interface but it's in `internals` package, so I figured it is okay? Anyways, this is not much blocking this PR, so feel free to merge it anyways and we can keep discussing here while you merge.
Ouch! Sorry about that!
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
nit: unneeded newline
A common pattern for classes like this without any state is to create a static instance. ```java public static final UnknownAddressSpec INSTANCE = new UnknownAddressSpec(); ```
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we do the timeTaken check immediately after L270 assertion to indicate that we are testing on the back-off triggered for group authorization failure? The current flow looks a bit weird as the second `ensureCoordinatorReady` doesn't do any back-off.
Should we do the timeTaken check immediately after L270 assertion to indicate that we are testing on the back-off triggered for group authorization failure? The current flow looks a bit weird as the second `ensureCoordinatorReady` doesn't do any back-off.
Add a reference to KIP-511 here
This can be final.
I recommend to add special handling for JsonParseException - just log it instead of rethrowing. If such an exception is not handled properly, consuming may be blocked with any non-json message - just text, for example. I got this while playing with Kafka locally: just one simple "dummy" message from console client brought tons of exceptions to my log.
I now saw that in the consumer tests you use `Duration.ofSeconds(1).toMillis()` and `Duration.ofMillis(999).toNanos()`. This makes it already clearer. I think a variable with a meaningful name for the lower bound would make it even clearer.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: add `final`
the method name changed to `windowedTable` and `windowSize` parameter is missing
I said it incorrectly before, and I actually meant that you can use `org.apache.kafka.test.NoOpKeyValueMapper` in this case as we do not really care about what aggregate key / value to use. Your proposal is also fine, while I was just trying to reduce duplicated code :)
I said it incorrectly before, and I actually meant that you can use `org.apache.kafka.test.NoOpKeyValueMapper` in this case as we do not really care about what aggregate key / value to use. Your proposal is also fine, while I was just trying to reduce duplicated code :)
the method name changed to `windowedTable` and `windowSize` parameter is missing
the method name changed to `windowedTable` and `windowSize` parameter is missing
the method name changed to `windowedTable` and `windowSize` parameter is missing
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
the method name changed to `windowedTable` and `windowSize` parameter is missing
I said it incorrectly before, and I actually meant that you can use `org.apache.kafka.test.NoOpKeyValueMapper` in this case as we do not really care about what aggregate key / value to use. Your proposal is also fine, while I was just trying to reduce duplicated code :)
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
I don't think that complexity is warranted. Just keep constructor injection please.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Dropped this unnecessary duplicate code, as discussed.
I don't think that complexity is warranted. Just keep constructor injection please.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
We can use `assertThrows` for this kind of pattern: ```java RecordDeserializationException rde = assertThrows(RecordDeserializationException.class, () -> consumer.poll(Duration.ZERO)); assertEquals(invalidRecordOffset, rde.offset()); assertEquals(tp0, rde.partition()); ```
the method name changed to `windowedTable` and `windowSize` parameter is missing
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
prop: change `stateStoreNames` -> `stateStoreName` here.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
prop: change `stateStoreNames` -> `stateStoreName` here.
The `KeyValue` class allows null values for `key` and `value` (at least I didn't see input validations such as throwing IAE in its constructor when either key or value are null). So we must guard against nulls / NPEs here.
This is ok in terms of the test, but `LOCAL_CLOSE` is the state used for client-side disconnection. For server-side disconnections, the state would be whatever the client state was at the time the disconnection was detected. Could just use `ChannelState.READY`.
please fix this: `use {@link } instead`
prop: change `stateStoreNames` -> `stateStoreName` here.
Or we make each test create task instead of creating task in ```setup```
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: I know it was already like that, but since we are now passing the actual class object, you might want to refer to the class object as `klass` (I like the keystrokes on this one) or `clazz`, which are common naming conventions when using class objects. Then call the String field `className` or similar. Of course JsonProperty will continue to be called `class`. Up to you.
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
Did you mean: ```suggestion setBrokerId(2). setBrokerEpoch(100). ```
the `try{...} finally` has been removed
@vahidhashemian, yes, that's what I mean.
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
Did you mean: ```suggestion setBrokerId(2). setBrokerEpoch(100). ```
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
Did you mean: ```suggestion setBrokerId(2). setBrokerEpoch(100). ```
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
Maybe something like "call_command() received unrecognized option(s) for the <foo> command: .... " I think listing all the options in the message might not be a bad idea either if it doesn't look too cluttered.
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
`info.getProperty(â¦)` can return `null` when using `redisNode.asString()` because of the execution of the `INFO` command. `INFO` is executed only on master nodes, not on slaves. `clusterGetNodes()` returns all nodes. Passing `null` into `withDetail(key, value)` leads to an `IllegalArgumentException`. I'd not put too much knowledge about cluster execution in here but rather iterate over the `info` keys (e.g. filter on suffix `"." + VERSION`) and use the keys from `info` to retrieve data. I'd also propose adding nodes as list to the Redis info as topology details are valuable in a health indicator.
Ditto on removing before/after
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Should we really catch NPE here? It seems like if the user wants to return a non-null mapped key from a null key, then they should handle the null case specifically in their `keyMapper` and not just throw an NPE. In general, an NPE is a sign that something has gone wrong. I would be pretty surprised if I threw an NPE explicitly in my user code and it just got swallowed and interpreted as if I had actually returned null.
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Dropped this unnecessary duplicate code, as we discussed.
Ditto on removing before/after
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
It should be 'false' by default
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
the `try{...} finally` has been removed
nit: usually we would write this is `this.state = requireNonNull(state);`
nit: usually we would write this is `this.state = requireNonNull(state);`
the `try{...} finally` has been removed
There's no need to copy entry.getValue().sourceTopics into a HashSet just to iterate it. Later down you put individual soureTopic into a topicToTaskMap which already eliminates possible duplicate keys...
Let me know if you plan to address or ignore this -- I am fine either way.
Let me know if you plan to address or ignore this -- I am fine either way.
Is the change in behavior intentional? `SecurityException`, which was previously caught and logged, is an instance of `RuntimeException`.
Capitalize 't' Also, died _due_ to
It can sometimes be hard to get the logs for failing tests, so it might be nice to get the failure reason in the actual test output. Check out `Matchers`: there should be a way to compose the checks you're doing here manually. It'll be something like: ``` assertThat( message, is( oneOf( containsString("Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING"), containsString("The state store, source-table, may have migrated to another instance") ) ) ```
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
Thanks for the cleanup! Really appreciated!
Hmm, why did we do this? I thought we'd have a try/catch block.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
This should return `-1` as old `BadValueTransformer`
Ah got it, I'm still think about it as the string template and was overlooking that. SG.
We can remove the extra call in the variable here. ```suggestion CallRetryContext failedCallRetryContext = failedCall.callRetryContext(); ```
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
rewrite test as above using `assertThrows()`.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Is the current implementation vulnerable to the following race condition? 1. thread1 grabs `CHANNELS` lock, get the channel object from the map; and then exists the `CHANNELS` lock; 2. thread2 grabs the lock, release the lock on it, close the channel, remove from the map. 3. thread1 now calls `channel.tryLock`, which throws `ClosedChannelException`.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
You need to close the `Connection`.
nit: 4 space indention only
Maybe we can just a better name for `path` since it makes this code look suspicious.
Add the `@Overrride` annotation to this method.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
This is still missing in the KIP wiki page.
This is still missing in the KIP wiki page.
Another nitpick: to use 0 as the base store prefix, and 1 as indices and so on; the main thinking is that in the future we may extend it to have multiple indices with a single base.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Not sure why it's the case? I think the previous pending txn should have aborted in step 4.
It might be more robust to use "contains" instead of "startsWith", but I won't insist on it.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
I'm not convinced we gain anything by adding another level of inheritance here. It removes one method that doesn't do much anyway. My preference would be to leave it as it was. If we are going to use inheritance then i think we should keep the hierarchy as shallow as possible.
@ijuma I looked into this in more detail. We don't need a new type `R` -- instead, we should update to ``` public class KTableKTableJoinNode<K, V1, V2, VR> extends BaseJoinProcessorNode<K, Change<V1>, Change<V2>, Change<VR>> ``` and use `private final MaterializedInternal<K, VR, KeyValueStore<Bytes, byte[]>> materializedInternal;` (ie, `VR` instead of `R`. (Note, the you always pass `<..., Change<X>, X>` in the current PR, what is redundant and can be avoided.)
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
I don't think that's what I had in mind. What we need to do here is check if "NONE" is active and change the description accordingly.
Hmm.. I think the original logic made more sense. Even if `completeExceptionally` returns false, it's still an error, right? We would not want to then proceed to `future.complete` or the next operation.
Do we really want anything related to internal topics to be client side? This could change in brokers from version to version and the clients should still work. I understand that for now we have no way to get that information, but we will soon (KAFKA-3306). I imagine removing the client side list would be part of the cleanup once thats available. So whatever exists in the mean time should be private so we don't need a deprecation cycle.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Add a reference to KIP-511 here
Ditto on removing before/after
ditto on removing before/after.
Nit: var should be named `deserializeValue`
ditto on removing before/after.
Maybe we can just a better name for `path` since it makes this code look suspicious.
ditto on removing before/after.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Add a reference to KIP-511 here
Yes, this should on an internal package (eg `common.internals`).
The additional validation doesn't hurt, but it might be more natural to move this check into the `if` below since we don't actually cast unless the condition is true.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
Perhaps we should not change the return type here unless we decide to make the more extensive `LinkedHashSet` change across all APIs (and corresponding KIP).
How about the following to simplify the string construction below: ```java String clientEnabled = System.getProperty(ZK_SASL_CLIENT, "default:" + DEFAULT_ZK_SASL_CLIENT); String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, "default:" + DEFAULT_ZK_LOGIN_CONTEXT_NAME); ```
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
Cleaner to just check if `tasks.isEmpty` after the loop is over.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
`will be returned` -> `will be queried`
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
```suggestion @Evolving public class WindowKeyQuery<K, V> implements Query<WindowStoreIterator<V>> { ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
```suggestion @Evolving public class WindowKeyQuery<K, V> implements Query<WindowStoreIterator<V>> { ```
```suggestion @Evolving public class WindowKeyQuery<K, V> implements Query<WindowStoreIterator<V>> { ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
nit: move parameter to it's own line (same below)
i think this would be better off as a test rather than in `setUp`
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
I'm against the sprinkling of `final` keyword everywhere. But more than that, I'm in favor of consistency w.r.t. the surrounding code. A few lines above, you may observe that `close` has a similar loop without `final`. Every project has its idiosyncrasies and Connect is not dogmatic w.r.t to `final` for local variables.
I'm against the sprinkling of `final` keyword everywhere. But more than that, I'm in favor of consistency w.r.t. the surrounding code. A few lines above, you may observe that `close` has a similar loop without `final`. Every project has its idiosyncrasies and Connect is not dogmatic w.r.t to `final` for local variables.
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
```suggestion @Evolving public class WindowRangeQuery<K, V> implements Query<KeyValueIterator<Windowed<K>, V>> { ```
```suggestion @Evolving public class WindowRangeQuery<K, V> implements Query<KeyValueIterator<Windowed<K>, V>> { ```
i think this would be better off as a test rather than in `setUp`
i think leaving as is should be fine atm, and tbh at least they are both close enough together to be easily modified together. if we think this is useful enough, i'd file a jira dependent on the jdk8 update so we can follow up.
```suggestion @Evolving public class WindowRangeQuery<K, V> implements Query<KeyValueIterator<Windowed<K>, V>> { ```
same for the store
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
I said it incorrectly before, and I actually meant that you can use `org.apache.kafka.test.NoOpKeyValueMapper` in this case as we do not really care about what aggregate key / value to use. Your proposal is also fine, while I was just trying to reduce duplicated code :)
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
nit: unneeded newline
Also not clear why "numSegments - 1" here.
Seems like a no-op
This method is also deprecated. We should throw same exception as for `childIndex`.
nit: unneeded newline
I had the same question. It appears better to just duplicate the properties.
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
nit: unneeded newline
Seems like a no-op
I think the result does not need to include anything here if we organize the top-level future as a map of members -> the corresponding futures of `Void`.
I had the same question. It appears better to just duplicate the properties.
I think the result does not need to include anything here if we organize the top-level future as a map of members -> the corresponding futures of `Void`.
I think we should call `deserializer.close()` here
Mainly I was just trying to ensure we do not abuse the sentinel, but it sounds like you have thought through its usage.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
I had the same question. It appears better to just duplicate the properties.
I think we should call `deserializer.close()` here
Also not clear why "numSegments - 1" here.
I had the same question. It appears better to just duplicate the properties.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
I think the result does not need to include anything here if we organize the top-level future as a map of members -> the corresponding futures of `Void`.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
I'd suggest moving this static method after the non-static methods.
Do we need this? It seems that it's easier to just duplicate the property for producer and consumer.
Seems like a no-op
Seems like a no-op
nit: unneeded newline
nit: unneeded newline
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
nit: unneeded newline
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Left this out of my previous review. This needs to change as well as it will return false for two `Segment` instances with the same `id`. Also, this statement will always evaluate to false as `Long.compare(x, y)` only returns `-1`, `0`, or `1`.
I had the same question. It appears better to just duplicate the properties.
nit: unneeded newline
Configuration properties must be JavaBean properties (the type must match) and we don't support `Optional` here.
Seems like a no-op
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
nit. Add `{ }` to block (we always use them). Same below.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
I might be missing something, but in both cases, you just want to use regular expressions, right? There is no need to mess around with predicate functions.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
Note to future me: I didn't get this far in the PR.
i think this would be better off as a test rather than in `setUp`
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Seems like a no-op
nit: unneeded newline
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
I submitted a PR for KAFKA-2711. I think we do need clientPrincipalName, and I hope this is clearer with the changes in that PR: https://github.com/apache/kafka/pull/390
nit: unneeded newline
nit: unneeded newline
Would this not be slightly better if we used `Errors.forCode` and then did a switch on the enum? Also, we should not compare to `0`, we should use `Errors.NONE`.
nit: unneeded newline
Seems like a no-op
Might be worth noting what needs synchronization (accessed by heartbeat thread and user thread) and what is safe. I was having trouble sorting out which methods need synchronization and which ones don't. Seems like the shared state is `heartbeat`, `state`, `client`, `time`, `groupId`, `retryBackoffMs` (where `time`, `groupId`, `retryBackoffMs` are threadsafe)
Same idea here, if we support multiple connection factories, there should be a way to identify them.
nit: unneeded newline
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
nit. Add `{ }` to block (we always use them). Same below.
I'd suggest moving this static method after the non-static methods.
I'd suggest moving this static method after the non-static methods.
It's not critical, but you might want to catch any exceptions from this `project` call and wrap them in another `SchemaProjectorException` so you can include info about which field failed projection.
nit. Add `{ }` to block (we always use them). Same below.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
i think this would be better off as a test rather than in `setUp`
Nit: var should be named `deserializeValue`
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Same idea here, if we support multiple connection factories, there should be a way to identify them.
Same idea here, if we support multiple connection factories, there should be a way to identify them.
Do we need this? It seems that it's easier to just duplicate the property for producer and consumer.
Also not clear why "numSegments - 1" here.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
nit: unneeded newline
we are not using getters and setters. I think this should be named as serviceName
I think we should call `deserializer.close()` here
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
Hmm, not sure if this is being inherited from other tests in this class, but this isn't the behavior we'd expect. The logic is now somewhat confusingly split between `ConnectorPluginsResource.validateConfigs()` and `AbstractHerder.validateConnectorConfig()`, but since `connector.class` is missing, we expect a `BadRequestException`. This test only works because this answer doesn't match what would actually happen in `AbstractHerder`.
createMetadataTopic() is no longer used.
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
`name()` -> `wrapped.name()`
I'd suggest moving this static method after the non-static methods.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
No captures for groups you don't use.
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
As above for this and next ctor
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
`2` -> `entries.size() - 1`
nit: move parameter to it's own line (same below)
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
Hmm.. `first` and `last` of RocksDBStore are not used anywhere, I think it is a leftover of the code clean up introduced in KAFKA-4499 (cc @RichardYuSTUG ). Maybe we can just remove these two functions from RocksDBStore.
formatting: no need to curly braces
`"Script {} does not exist.".format(py_script)` -> `'Script %s does not exist.' % py_script`
Haha, I'm not sure whether we're saying the same thing. My suggestion was to blindly treat the exception as a top-level error. In other words, take the error code from the exception and use it as the top-level error code for new versions, and as the partition-level error code for old versions.
Haha, I'm not sure whether we're saying the same thing. My suggestion was to blindly treat the exception as a top-level error. In other words, take the error code from the exception and use it as the top-level error code for new versions, and as the partition-level error code for old versions.
Let's use `Map` on the left side instead of `HashMap`
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
I feel INFO level is fine as in many cases people will keep alerting on warn / error logs.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
I feel INFO level is fine as in many cases people will keep alerting on warn / error logs.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
This doesn't seem to be used.
I fixed this one to use the constant before merging.
If this method is used *only* for informational purposes, maybe we should just call `toString` on the topicNameExtractor and make sure that the `StaticTopicNameExtractor` includes the topic name in its output. Better yet, we could just change the method to return the `topicNameExtractor` itself, since it really doesn't *have* a topic anymore. If it's used for any other not-strictly-informational purpose, it seems risky to return some other string, claiming it's the "topic". It seems like it could become a bug in the future...
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
Nit: var should be named `deserializeValue`
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
This is also not introduced in this PR, but: inside `close()` the right ordering should be call `closeState` first then `context.close()` since the former will access the latter as well. Currently it does not introduce any issues since `context.close()` only shuts down the metrics, but moving forward we may modify it to make the later access failed.
This is not part of the KIP any longer
We can also get here if handshake has already failed (state == `State.HANDSHAKE_FAILED`) and there are still bytes to be flushed in `netWriteBuffer`.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
Maybe something like "call_command() received unrecognized option(s) for the <foo> command: .... " I think listing all the options in the message might not be a bad idea either if it doesn't look too cluttered.
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
nit: 'else' can be dropped
I'm not sure I see a good use case for it. In any case, this check could be relaxed (or moved to the outer `get_response`, outside the middleware chain) later as a separate change (maybe after the old middleware system is gone, which would reduce the complexity of the change).
Thanks! Will push this shortly.
Thanks! Will push this shortly.
Thanks! Will push this shortly.
That change in `ExecuteListenerProvider` is unrelated to the purpose of this PR. Please revert it so that this change is properly focused.
To make it more rigid: we can pass a valid end point string, and then check that the field is still `null` below.
Constructor should be at the top.
Constructor should be at the top.
As above: add more "randomness"
You should use try with resources here too.
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
nit: I don't spot any, but safer to avoid typos by just having constants for these
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
The number has changed and 5 is no longer relevant.
How about returning a Set instead of List? ``` return topics .stream() .filter(topic -> !topic.isEmpty()) .collect(Collectors.toSet()); ```
We could make this field access `public`
nit: We should use `groupId.idValue` here and in the others.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
nit: it is naming a source node, not a processor node. -> `"source"`
Should we include the config source instead for compatibility? Also, just double-checking that it is intentional to leave the synonyms out of `equals`.
Can we make this method return `OptimizableRepartitionNode` just for symmetry? I.e., you can see that we're replacing a bunch of `OptimizableRepartitionNode`s with a new `OptimizableRepartitionNode` instead of replacing them with a generic `StreamsGraphNode`.
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
This is a really nice touch ð Although without attempting some degree of stickiness in the standby task assignment it seems unlikely to actually find a standby on a caught-up client..
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
nit: add a size? There are a few cases in here where we could do this.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
nit: both lines missing . at end
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
i think this would be better off as a test rather than in `setUp`
i think this would be better off as a test rather than in `setUp`
nit: can we make this debug level? Otherwise it will make this test a little spammy.
`PrintForEachAction<>` to remove warning. Also in the `print` method
nit: `log.error("Exception caught while post-committing task: {}", task.id(), e);`
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Probably a good idea to check if SASL_SSL for the second case and throw an exception otherwise (in case we ever add another SASL_\* protocol).
We can return `false` on the first mismatch no need to check the rest of the arrays.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Okay I think this makes sense, let's just follow this pattern then.
I think this is going to end up throwing an exception if it executes on a worker that isn't running the connector. `reconfigureConnectorTasksWithRetry` needs to only be executed on the worker actually running the connector since the first check it does to check if the connector is running throws an exception if the connector doesn't exist. I think you want to call `worker.setTargetState` without the check, but still maintain the check around this call. The current tests miss this for two reasons. First, they exercise pausing but not resuming. Second, the result is not a crash, but log noise and rescheduling the next attempt to reconfigure the connector.
The test name is not self describing: what about `shouldAlllowToSpecifyRocksDBConfigSetterClassAsString`
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
The test name is not self describing: what about `shouldAlllowToSpecifyRocksDBConfigSetterClassAsString`
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Yes, it seems that -1 means that we are trying to read beyond the end of the channel, which probably should be treated as abnormal.
Could we still keep the log entry? `log.info("Unable to decode subscription data: used version: {}; latest supported version: {}", usedVersion, latestSupportedVersion);`
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
req: rename to `tasksToPreviousClients` or something similar that works "previous" into it
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
Oh, I guess I missed `shouldNotReportOffsetSumsForTaskWeCantLock()`. No, I did not have something different in mind.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
`ConsumerRecordFactory` is deprecated via KIP-470 (merge recently) -- please update the code to use `TestInputTopic` -- we cannot merge as-is, because the build would fail if we use deprecated classes.
super nit: the delta really doesn't matter in this case I'm wondering if `assertEquals(i, (int) totalMetric.measurable().measure(config, time.milliseconds()));` would be more clear, but this is subjective so feel free to ignore.
Seems to be covered by `shouldAssignMultipleReplicasOfStandbyTask()` already
Can't you use `createClient`? This call confused me... (same below)
`setNeedsCommit` -> `{@link #setNeedsCommit}`
`setNeedsCommit` -> `{@link #setNeedsCommit}`
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
Can this be a `byte`.
I think we're testing `testDir` Occupied here, not `AppDir`.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
We shouldn't return `null`, but instead return a "unknown query" result.
It's not critical, but you might want to catch any exceptions from this `project` call and wrap them in another `SchemaProjectorException` so you can include info about which field failed projection.
It reads a bit strange to fall through to `lookupCoordinator` if we know the request doesn't need the coordinator. Maybe clearer with a slight restructure: ```java transactionManager.retry(nextRequestHandler); if (nextRequestHandler.needsCoordinator()) { transactionManager.lookupCoordinator(nextRequestHandler); } else { // For non-coordinator requests, sleep here to prevent a tight loop when no node is available time.sleep(retryBackoffMs); metadata.requestUpdate(); } ```
It reads a bit strange to fall through to `lookupCoordinator` if we know the request doesn't need the coordinator. Maybe clearer with a slight restructure: ```java transactionManager.retry(nextRequestHandler); if (nextRequestHandler.needsCoordinator()) { transactionManager.lookupCoordinator(nextRequestHandler); } else { // For non-coordinator requests, sleep here to prevent a tight loop when no node is available time.sleep(retryBackoffMs); metadata.requestUpdate(); } ```
It reads a bit strange to fall through to `lookupCoordinator` if we know the request doesn't need the coordinator. Maybe clearer with a slight restructure: ```java transactionManager.retry(nextRequestHandler); if (nextRequestHandler.needsCoordinator()) { transactionManager.lookupCoordinator(nextRequestHandler); } else { // For non-coordinator requests, sleep here to prevent a tight loop when no node is available time.sleep(retryBackoffMs); metadata.requestUpdate(); } ```
Updated this when merging.
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
Updated this when merging.
You are right, this is fine. I was confused about the checkpointedOffsets in standbyTasks before.
As above for this and the next ctor
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Let's use `Map` on the left side instead of `HashMap`
Let's use `Map` on the left side instead of `HashMap`
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
base -> based progress -> progressed
Is this code based on an existing implementation? If that's the case, we should specify it / link to it.
This seems to overlap with #4095 -- should not be part of this PR IMHO.
Thanks for cleaning up the code duplication.
Let's use `Map` on the left side instead of `HashMap`
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
I submitted a PR for KAFKA-2711. I think we do need clientPrincipalName, and I hope this is clearer with the changes in that PR: https://github.com/apache/kafka/pull/390
As above for this and the next ctor
base -> based progress -> progressed
You are right, this is fine. I was confused about the checkpointedOffsets in standbyTasks before.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
nit: remove `this`
Dropped this unnecessary duplicate code, as we discussed.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
same here as what i said below. You can use a `assertThat`
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
the `try{...} finally` has been removed
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Sorry for the confusion. I thought `hasRemaining` made sense initially, but then I realized that the name should be more suggestive of its usage. I'd prefer something like `ensureNoneRemaining`, but it's not a dealbreaker for me.
nit: just simplify to `throws Exception`
Let's use `Map` on the left side instead of `HashMap`
That change in `ExecuteListenerProvider` is unrelated to the purpose of this PR. Please revert it so that this change is properly focused.
Just let the Exception flow, that will automatically fail the test
offtopic: I'm wondering if we should drop `SubscriptionHelper.isCancelled()`
I think it would be preferrable to call this "globalPartitionCount" and call the gauge "globalPartitionCountGauge" or something similar.
add `final` twice
add `final` twice
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
At this point we have a lot of repeated code with `toRst()`. Would probably make sense to refactor to share the majority of the code for each config's main set of fields.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
Let's remove the brace changes please.
to_text and prefix the string with u.
same for the store
The code isn't huge, so by no means a blocker, but @kkonstantine pointed out that the entire block before configuration (and most of config modulo the conditional) is identical between header and "normal" converters. The main difference in the header blocks are just the class referenced (`Converter.class` vs `HeaderConverter.class`). Consolidation would be nice if it's easy to do, but at the same time I'd rather get a fix to the immediate problem in, so definitely wouldn't block on saving 10 lines of duplicated code.
Can remove if initialize above
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
This still doesn't seem correct. We're only invoking configuration if the plugin implements `Configurable` afaict. This does not work for `Converter`s implemented against the new API and assuming the "forward" configuration. We *must* always invoke the "old" `configure(Map, boolean)`, and only invoke the `Configurable` version as a backup. Possibly it would make sense to indicate on the `HeaderConverter` that the `Configurable` methods should be idempotent if we need to be able to implement both. Not sure if we can test this easily with unit tests, but I think we might want a plain old `Converter` (that does not implement `HeaderConverter`) in tests to validate compatibility... but it's possible we'd need either integration or system tests to properly validate.
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
The dependent key name should be in backticks. And perhaps comma-delimited rather than tabs.
Discussed offline with @ijuma. This actually isn't quite enough to fix the example he brought up earlier in all cases. For example, it still doesn't work if you construct `Config` with a `Set` for the entries. Given that we can't guarantee equality in this way generally, I'd probably suggest we just revert to using `Collections.unmodifiableCollection` like you had before.
typo: FOLLOW_REPLICATION_THROTTLED_REPLICAS -> FOLLOWER_REPLICATION_THROTTLED_REPLICAS
I just read through `MemoryLRUCache`. It is not thread-safe and will corrupt itself because a read causes a mutation of the LRU history. (I made the same mistake early in my career when fixing performance problems leading to exploring caching in-depth, so its an easy oversight to make) A read/write lock is a very expensive mechanism and most often the incorrect lock type to use. For short critical sections it is more expensive than an exclusive lock. By using a `ReentrantLock` or `synchronized` you'll have both correctness and higher performance. As is, I strongly urge you to correct this before merging. You don't have to use a caching library, but the code is very broken.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
I think parameterize this class with `eos-alpha` and `eos-beta` is a better idea --- for some tests that do not rely on the flag and hence would be a duplicated one, we can move it to a separate non-parameterized class.
Could use Collections.emptySet() if reduced to Set
This is because we are inheriting a Scala class, and moving forward we should remove this with the Java version `org.apache.kafka.copycat.util.ShutdownableThread` that can be moved into `o.a.k.common.utils`. We can leave it as is for now.
By using an extra `continue` we reduce the indentation. I also propose that we change the hint message when depending on whether the cache path matches, is inside, or contains one of the other paths: ```suggestion if not setting: continue if name == 'STATICFILES_DIRS': paths = {pathlib.Path(dir).resolve() for dir in setting} else: paths = {pathlib.Path(setting).resolve()} for alias in settings.CACHES: cache = caches[alias] if not isinstance(cache, FileBasedCache): continue cache_path = pathlib.Path(cache._dir).resolve() if any(path == cache_path for path in paths): hint = f"Your '{alias}' cache path matches your {name}." elif any(path in cache_path.parents for path in paths): hint = f"Your '{alias}' cache path is inside your {name}." elif any(cache_path in path.parents for path in paths): hint = f"Your '{alias}' cache path contains your {name}." else: continue errors.append(Warning( 'Your configuration might expose your cache or lead to corruption of your data.', hint=hint, id='cache.W002', )) ```
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
Let's use try with resources here and the other test so that the file is closed after it's used.
This still doesn't seem correct. We're only invoking configuration if the plugin implements `Configurable` afaict. This does not work for `Converter`s implemented against the new API and assuming the "forward" configuration. We *must* always invoke the "old" `configure(Map, boolean)`, and only invoke the `Configurable` version as a backup. Possibly it would make sense to indicate on the `HeaderConverter` that the `Configurable` methods should be idempotent if we need to be able to implement both. Not sure if we can test this easily with unit tests, but I think we might want a plain old `Converter` (that does not implement `HeaderConverter`) in tests to validate compatibility... but it's possible we'd need either integration or system tests to properly validate.
Nitpick: we typically do this like: ``` java return "KerberosShortNamer(principalToLocalRules = " + principalToLocalRules + ")"; ```
We should include `startPosition` in the message.
We should include `startPosition` in the message.
We should include `startPosition` in the message.
We should include `startPosition` in the message.
We should include `startPosition` in the message.
We should include `startPosition` in the message.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Same here, we can cache the result of `Builder.getPartitions(data)` for re-use.
do we really need that we matched it? Can't we do all all of this is a single log statement? We can include size of credentials map and authenticated boolean. This will help keep the old structure.
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
This would require a separate KStreamVoidTransformProcessor, but I feel it worth the internal cost for simpler public APIs.
I'd move the `ERROR_HEADER_PREFIX` here since it really is more of an implementation detail. And as @kkonstantine suggested, I'd change the prefix to be `__connect.errors.` (with the trailing period) so that the above lines can be like: public static final String ERROR_HEADER_PREFIX = HEADER_PREFIX + "errors";
I'd move the `ERROR_HEADER_PREFIX` here since it really is more of an implementation detail. And as @kkonstantine suggested, I'd change the prefix to be `__connect.errors.` (with the trailing period) so that the above lines can be like: public static final String ERROR_HEADER_PREFIX = HEADER_PREFIX + "errors";
nit: remove empty line
nit: remove empty line
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
nit: add `final`
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
original was better
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
I think we are guaranteed to have the listener present, but perhaps it's worth checking explicitly and throwing if it is not the case.
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
I know we need both `File` and `Path` instance to complete the permission setting. What I meant is that: 1. We already had the `File` instances, i.e. baseDir, stateDir 2. `Paths.get(stateDir.getPath())` --> what happened behind the scene, is we created a Path instance from the path string in the file instance (i.e.`stateDir.getPath()`) ```java public final Path getPath(String var1, String... var2) { ... return new UnixPath(this, var3); } ``` 3. `path.toFile()` --> what happened behind the scene, is we created a File instance from the path string ```java public final File toFile() { return new File(this.toString()); } ``` So, currently, we will created an additional File instance via `path.toFile()`. If we pass the File instance into `configurePermissions()` directly, it'll only created a `Path` instance. ex: ```java configurePermissions(stateDir); // pass the file instance directly ``` ```java private void configurePermissions(final File file) { final Path path = Paths.get(file.getPath()); // created path instance if (path.getFileSystem().supportedFileAttributeViews().contains("posix")) { .... } else { boolean set = file.setReadable(true, true); // won't create additional File instance here .... } } ```
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
I know we need both `File` and `Path` instance to complete the permission setting. What I meant is that: 1. We already had the `File` instances, i.e. baseDir, stateDir 2. `Paths.get(stateDir.getPath())` --> what happened behind the scene, is we created a Path instance from the path string in the file instance (i.e.`stateDir.getPath()`) ```java public final Path getPath(String var1, String... var2) { ... return new UnixPath(this, var3); } ``` 3. `path.toFile()` --> what happened behind the scene, is we created a File instance from the path string ```java public final File toFile() { return new File(this.toString()); } ``` So, currently, we will created an additional File instance via `path.toFile()`. If we pass the File instance into `configurePermissions()` directly, it'll only created a `Path` instance. ex: ```java configurePermissions(stateDir); // pass the file instance directly ``` ```java private void configurePermissions(final File file) { final Path path = Paths.get(file.getPath()); // created path instance if (path.getFileSystem().supportedFileAttributeViews().contains("posix")) { .... } else { boolean set = file.setReadable(true, true); // won't create additional File instance here .... } } ```
:thinking: ```suggestion collector = Collector(using=del_query.db, origin=self) ```
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
nit: not a big deal here, but for unit tests I think given the very low overhead it is better to separate out each of the cases into their own test as it can help make it more quickly obvious if issues are with a specific case or if it affects multiple cases.
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
Cleaner to just check if `tasks.isEmpty` after the loop is over.
Yeah, Java's type system makes this stuff a pain. I think you can fix it with: ``` final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(new KStreamBranch<>((Predicate<K, V>[]) predicates.clone(), childNames), branchName); ``` which should be safe If you want to also get rid of the cast, you can do it by coercing each of the predicates to a Predicate<K,V> when you loop over them at the beginning: ``` Predicate<K, V>[] kvPredicates = new Predicate[predicates.length]; for (int i = 0; i < predicates.length; i++) { final Predicate<? super K, ? super V> predicate = predicates[i]; Objects.requireNonNull(predicate, "predicates can't be null"); kvPredicates[i] = predicate::test; } ```
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
I think we should call `deserializer.close()` here
I think we should make the `MetricsReporter` interface itself extend `Reconfigurable`, rather than just `JmxReporter`. We might want to reconfigure other metrics reporters at runtime, and there is no reason to special-case just this one.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
Let's use `Map` on the left side instead of `HashMap`
Hmm, this doesn't need to block merging this, but we should think carefully about doing delay this way. The rest of Connect avoids trying to rely on Java's `interrupt` behavior because it's not really a reliable way to *actually* interrupt threads, and in a system where there are pluggable components that are allowed to block indefinitely, relying on functionality that most Java developers don't understand well probably isn't going to work all that well. It may not have actually gotten to a KIP, but there was at least some discussion on a JIRA somewhere about making connect perform interrupts in addition to the basic task `stop()` calls it already does, but it doesn't currently do this. For anything that can end up with pretty long sleep periods, we should try to make sure there's a good way of interrupting it and moving on (e.g. so rebalances wouldn't get delayed because there's a connector that's encountering errors). At a minimum, since we don't do interrupts currently, I think we wouldn't interrupt this code currently. The other approach we use elsewhere is to `wait` on a monitor so we can set a flag and interrupt with `notify` and have it bail out immediately.
Let's use `Map` on the left side instead of `HashMap`
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
we're in Java8 now... I think you can do: `(key,value,context) -> { ... }`
It seems like we're duplicating some of the logic contained in `Plugins` into this class by tracking class alias names and pre-computing plugin type based on them. Did you consider a `Herder` method that only accepted the name of the plugin, and took on the responsibility of deducing the plugin type itself? ```java List<ConfigKeyInfo> connectorPluginConfig(String pluginName); ``` In `AbstractHerder`, we could do something like this: ```java @Override public List<ConfigKeyInfo> connectorPluginConfig(String pluginName) { try { Object plugin = Plugins.newPlugin(pluginName); PluginType pluginType = PluginType.from(plugin.class); List<ConfigKeyInfo> results = new ArrayList<>(); ConfigDef configDefs; switch (pluginType) { case SINK: case SOURCE: configDefs = ((Connector) plugin).config(); break; case CONVERTER: configDefs = ((Converter) plugin).config(); break; // ... Rest of switch statement follows same pattern, and rest of the method remains unchanged } ``` And in `Plugins` we could do this: ```java public Object newPlugin(String classOrAlias) throws ClassNotFoundException { Class<? extends Object> klass = pluginClass(delegatingLoader, classOrAlias, Object.class); return newPlugin(klass); } ``` Or alternatively, we could introduce a common interface for plugins that expose a `ConfigDef`: ```java interface DefinedConfigPlugin { ConfigDef config(); } ``` Which could really simplify some of the `AbstractHerder` logic: ```java @Override public List<ConfigKeyInfo> connectorPluginConfig(String pluginName) { try { DefinedConfigPlugin plugin = Plugins.newDefinedConfigPlugin(pluginName); ConfigDef configDefs = plugin.config(); // No switch statement on plugin type necessary // ... Rest of the method remains unchanged } ``` And the change to `Plugins` would be lightweight as well: ```java public DefinedConfigPlugin newDefinedConfigPlugin(String classOrAlias) throws ClassNotFoundException { Class<? extends DefinedConfigPlugin> klass = pluginClass(delegatingLoader, classOrAlias, DefinedConfigPlugin.class); return newPlugin(klass); } ``` Worth noting that if we want to differentiate to users between "this plugin is not on the worker" and "we don't expose config information for this type of plugin", we'd have to make a few further tweaks.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Maybe we can just a better name for `path` since it makes this code look suspicious.
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
change `duration` to `period`
change `duration` to `period`
change `duration` to `period`
Admittedly, this is a random time to bring this up, but a pattern that I like for this is: ```java final long seed = providedSeed != null ? providedSeed : new Random().nextLong(); System.out.println("Seed is: " + seed); final Random rand = new Random(seed); ``` where `providedSeed` comes from an env variable, command-line arg, whatever... This way you get the same default behavior (pseudorandomly generated sequence of test values), but you also have the option to deterministically reproduce a previous pseudorandom sequence from a prior run. This can be helpful in diagnosing flaky tests. Not saying this is needed here; I just wanted to share the pattern.
Since this isn't implemented, perhaps lets not mention it? I found it confusing
Since this isn't implemented, perhaps lets not mention it? I found it confusing
Since this isn't implemented, perhaps lets not mention it? I found it confusing
Somewhat more idiomatic to do: `print(json.dumps({"status": "running"}))`
Somewhat more idiomatic to do: `print(json.dumps({"status": "running"}))`
Since this isn't implemented, perhaps lets not mention it? I found it confusing
The second param seems redundant.
As discussed in the JIRA, I still think we should use `FileChannel.open`.
the condition is always false if you don't add brackets. ``` throw new IllegalArgumentException("Topic pattern to subscribe to cannot be " + (pattern == null ? "null" : "empty")); ```
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Ah, I see. Thanks for the explanation
If you only have `file.setWritable(true, true)` then the directory will still be writeable by non-users, I assume? I actually don't know the details of the `File#setXXX` methods -- but we don't want it to be writeable by just anyone. Should we instead do something like ```suggestion set &= file.setWritable(false) && file.setWritable(true, true); ```
If you only have `file.setWritable(true, true)` then the directory will still be writeable by non-users, I assume? I actually don't know the details of the `File#setXXX` methods -- but we don't want it to be writeable by just anyone. Should we instead do something like ```suggestion set &= file.setWritable(false) && file.setWritable(true, true); ```
Nit: rename to `shouldThrowOnInvalidTopicNames`
Nit: rename to `shouldThrowOnInvalidTopicNames`
Nit: rename to `shouldThrowOnInvalidTopicNames`
Nit: rename to `shouldThrowOnInvalidTopicNames`
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
If the tests work without it, I think it should be fine to remove.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
this overwrite of mm2config should go in the setup method, IMHO
Here we can further refactor a bit: ``` if (config.idempotenceEnabled()) { // read out the acks string value if (string value is null) // just log an info saying we are gonna override it to -1 else if (string value is not "all") // throw exception } ```
this overwrite of mm2config should go in the setup method, IMHO
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
generally in assertEquals, the thing being tested comes second. If there is an error message, the first thing appears as the "expected value"
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
generally in assertEquals, the thing being tested comes second. If there is an error message, the first thing appears as the "expected value"
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
This is the default.
this overwrite of mm2config should go in the setup method, IMHO
this overwrite of mm2config should go in the setup method, IMHO
Can you enclose the body of if block with curly braces ? Same with else block. It is easier to read.
nit: 'else' can be dropped
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
I see. Thanks.
In the previous version, we didn't delay the onCompleted event.
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
Somewhat more idiomatic to do: `print(json.dumps({"status": "running"}))`
I think `file_exists` is duplicated from `test_console_consumer.py` We should probably put this into something like `remoteaccount_utils.py` and reuse
shoulc => should
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
He means that you don't need an `else` in this case.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
@rajinisivaram Thanks for the detailed explanation. Yeah, I was basically wondering if topic expiration was a "good enough" fix for all of these cases. You may have some unnecessary logging until a deleted topic is expired (for example), but it seems like it wouldn't be too bad since the expiration timeout is 5 minutes, which also matches the default metadata refresh interval. Since we're not attempting to fix the problem of log spam while a message for a deleted topic is queued (which seems like the most likely source of excessive metadata error logging to me), do you think the early removal still makes a big difference in practice? If so, then it may be worth keeping.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Nit: somehow I don't like `blah`. Otherwise LGTM
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
As above: add more "randomness"
As above: add more "randomness"
As above: add more "randomness"
Seems like a no-op
I think we actually want it to be readable _only_ by the user, and explicitly restrict permissions for all other users. The patch which originally broke things for Windows users was trying to tighten up the security in exactly this way
Need null-check since `remoteAddress` is null on the server-side since we are currently only setting for client connectons.
You'll hate me, but I see a tiny chance for `ClassCastException` that we can avoid.
Can we move the whole `data` setup into `items`? 🤔 ```suggestion def items(self): o1 = TestModel() o1.lastmod = datetime(2013, 3, 13, 10, 0, 0) o2 = TestModel() o2.lastmod = datetime(2014, 3, 13, 10, 0, 0) return [o1, o2] def lastmod(self, obj): return obj.lastmod ``` (Getting rid of the dict lookup step.) (🤷‍♀️)
Can we move the whole `data` setup into `items`? 🤔 ```suggestion def items(self): o1 = TestModel() o1.lastmod = datetime(2013, 3, 13, 10, 0, 0) o2 = TestModel() o2.lastmod = datetime(2014, 3, 13, 10, 0, 0) return [o1, o2] def lastmod(self, obj): return obj.lastmod ``` (Getting rid of the dict lookup step.) (🤷‍♀️)
You should use try with resources here too.
Also not clear why "numSegments - 1" here.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Maybe use Objects.requireNonNull
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
maybe use "a", "b", "c" as values, as the transformer counts the number of calls to `process` (for better distinction with next test)
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
`toString` of `FileChannel` doesn't seem to be useful: ```text scala> FileChannel.open(new File("/Users/ijuma/Downloads/trace.log").toPath) res5: java.nio.channels.FileChannel = sun.nio.ch.FileChannelImpl@591e5fd4 ```
Maybe use Objects.requireNonNull
Maybe use Objects.requireNonNull
Maybe use Objects.requireNonNull
add `final` twice
add `final` twice
add `final` twice
Need to fix indentation below.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
The protocol behavior is that `null` is valid while we use a default empty string so that it's never seen by users. The generated protocol classes definitely change behavior here as it caused a previously passing test to fail with a NPE. I'll share the details with you offline.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
I would say it's important _not_ to be able to create bogus requests. ;) We can introduce specific mechanisms for testing, but a public constructor for a request should do its own validation.
We should add a `null` check to allow closing a deserializer that was not properly setup
We should add a `null` check to allow closing a deserializer that was not properly setup
We can ditch this logic block since it is not relevant to your test - it was a very specific check on the correctness of the ConsoleConsumer start command to ensure the log4j settings were correct.
We can ditch this logic block since it is not relevant to your test - it was a very specific check on the correctness of the ConsoleConsumer start command to ensure the log4j settings were correct.
again, naming of the test
prop: Please use `assertThat()` since it makes verifications a bit better readable.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
We should include `startPosition` in the message.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
`advanceMs` is not the same as provided input parameter `advance` -- this would make the error message miss leading.
Also not clear why "numSegments - 1" here.
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
Do we want this to be `error` or `warn`? Maybe `error` is right, so take this as a question. :)
Is this change intentional? Ditto below.
Is this change intentional? Ditto below.
Right, sorry I misread that line.
Is this intentional? cc @enothereska
Nit: `late enough version` reads a bit funny. Maybe we can say "Could not validate fetch offsets for partitions {} since the broker does not support the required protocol version (introduced in Kafka 2.3)" or something.
Just one minor point, if we don't have EOS enabled, we could end up pulling duplicates in some tests like the `StreamsUpgradeTest::upgrade_downgrade_brokers`
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
"*" is considered "LITERAL" for compatibility reasons
"*" is considered "LITERAL" for compatibility reasons
I think we just want to get rid of the special handling for logical types, but if it stays, the handling here needs to change. Any user defined schema can have a name too.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
Nit: var should be named `deserializeValue`
There are some request header tests in `RequestResponseTest`, we should move them here so that we can find them all in one place.
This list is small anyway, so I'm not too worried about the cost, but this seems wasteful. Seems like this promotion check should be a simple lookup in a precomputed table.
I think the requirement should be stronger, we should check the subject has a KerberosPrincipal to skip the kerberos login. Else we can run into a situation that there is an alternate login context that has nothing to do with Kerberos and we'll fail.
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Exception message doesn't look right (the word "list").
Nit: somehow I don't like `blah`. Otherwise LGTM
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
Be careful about changing this -- it should probably be a LinkedHashMap or some similar order-preserving Map if we do this. Depending on the serialization format, they may be sensitive to field ordering so being able to preserve the ordering will be important. Even within a single process a converter could end up randomizing schema field orders and breaking equivalence if an order randomizing map was used. The alternative would be to add an extra Set to SchemaBuilder, which requires extra allocations but doesn't require jumping through hoops to preserve the behavior of the `fields()` method.
Got it. May be we could have something like SchemaAndValueUtils to include such utils for it. Just didn't feel great seeing this method in the ConnectHeaders class.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
Let's check that `previouslyAllocated`'s capacity is `batchSize` else `buffer.limit(sizeBytes)` is going to throw with a less useful stacktrace.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
nit: unneeded newline
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
I'd suggest to use a more descriptive test name, e.g. in the form of `shouldDoXYZ`.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
Not really necessary, `worker.dispose()` will dispose any outstanding timer action.
Not really necessary, `worker.dispose()` will dispose any outstanding timer action.
There are no ..
`ObjectMapper` instances should be created once and cached, normally.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Why using StopWatch? this create many short live objects for not resean.
Can we also rename `StreamsGraphNode` to `GraphNode`? The `Streams` prefix is a bit confusing, IMO, because `StreamSourceNode` and `StreamsGraphNode` seem really similar although they are quite different.
How about the following to simplify the string construction below: ```java String clientEnabled = System.getProperty(ZK_SASL_CLIENT, "default:" + DEFAULT_ZK_SASL_CLIENT); String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, "default:" + DEFAULT_ZK_LOGIN_CONTEXT_NAME); ```
We can remove `requireNonNull` here, because `getter.keySerde()` would already throw a `ConfigException` if the default serde is null.
Ditto on removing before/after
nit: can we make this debug level? Otherwise it will make this test a little spammy.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
We can remove `requireNonNull` here, because `getter.keySerde()` would already throw a `ConfigException` if the default serde is null.
Ditto on removing before/after
Ditto on removing before/after
We can remove `requireNonNull` here, because `getter.keySerde()` would already throw a `ConfigException` if the default serde is null.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
This appears to be untested
This appears to be untested
Not sure you need to initialize the factory every time there.
Not sure you need to initialize the factory every time there.
I think we should provide some context on the exception here.
Nit: I was thinking that the variable name should be `batchHeader` and this string seems to confirm that.
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Some fields might be safe to just shallow copy, but I think a number of these need to be deep copied to avoid accidentally modifying the original schema. I think `parameters and `defaultValue` at a minimum need to change. Schemas seem like they should be fine since they'd just be fully replaced, not modified, anyway.
Nit: please add `final` to all local vars and method parameters
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Some fields might be safe to just shallow copy, but I think a number of these need to be deep copied to avoid accidentally modifying the original schema. I think `parameters and `defaultValue` at a minimum need to change. Schemas seem like they should be fine since they'd just be fully replaced, not modified, anyway.
`.toString()` unnecessary here are other similar logs.
typo: FOLLOW_REPLICATION_THROTTLED_REPLICAS -> FOLLOWER_REPLICATION_THROTTLED_REPLICAS
This is not correct, it should be `buffer.remaining`. It seems simpler to just do `while (buffer.remaining())` with an early exit in the case read returns `-1`.
Nit: "The file channel position..."
Ditto on the properties and the driver.
Some fields might be safe to just shallow copy, but I think a number of these need to be deep copied to avoid accidentally modifying the original schema. I think `parameters and `defaultValue` at a minimum need to change. Schemas seem like they should be fine since they'd just be fully replaced, not modified, anyway.
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
Lines 45 and 46 should use the static constants in this class for the name of the topics: `TOPICS_REGEX_CONFIG ` rather than `SinkTask.TOPICS_REGEX_CONFIG`, and `TOPICS_CONFIG` rather than `SinkTask. TOPICS_CONFIG`.
Some fields might be safe to just shallow copy, but I think a number of these need to be deep copied to avoid accidentally modifying the original schema. I think `parameters and `defaultValue` at a minimum need to change. Schemas seem like they should be fine since they'd just be fully replaced, not modified, anyway.
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
nit: unneeded newline
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
The boolean makes it easier to do the check, but doesn't help with cases where the caller forgets. So the exception is better from that perspective.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: unneeded newline
If we want the burst to be more similar to original behavior, it seems like this should be `#samples`. With the current implementation, we can do 1 unit of work in the oldest window and then accept a burst right at the end of the last (not full yet) sample. Which means that the max burst size is almost at #samples * quota (if sample = 1 sec, quota is in units/second). Does this sound right to you? Also, I think we should take into account `config.timeWindowMs`, because it could be something other than 1 second.
Same question here about just using a static ConfigDef instead of a static method.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Let's remove the brace changes please.
Not sure you need to initialize the factory every time there.
The functionality of process() now is completely covered by transform: users can define a transform function with return type R be "Void" and add a dummy "return null" in the end of the function. And then in KStream we can add public void transform(TransformerSupplier<K, V, Void>) to replace the "process()" call. Having both process() and transform() might be confusing to users, so I would suggest we just remove process() here.
Missed whimsy: if Black didn't normalize it to 'rf', this could be a 'fr', or French string.
I thought it was unintentional. Never mind. See this style for the first time :)
I thought it was unintentional. Never mind. See this style for the first time :)
I thought it was unintentional. Never mind. See this style for the first time :)
As above for this and the next ctor
I think this should probably be an `info` or `warn`.
Hmm.. I was looking into how the producer handles various operations after the call to close(). Unsurprisingly, there is a bunch of inconsistency. For send(), as far as I can tell, the logic looks like this: 1. Check whether the sender thread is closed and raise an error if it is 2. Refresh metadata if needed 3. Check if the accumulator is closed To be honest, I don't know why we don't just check if the sender thread has begun shutdown, but perhaps that's a separate issue. For transactional requests, it seems we don't currently do any checking to see whether the producer has been shutdown. At least I couldn't find any checks in `commitTransaction()`. To make this solution work, I think we should have those checks. Basically the user should see some kind of error indicating that the producer has already begun shutdown and the operation is no longer allowed. As it is, they would probably see an illegal state error indicating the transaction already began aborting or something. This could be a simple check in `TransactionManager` if we add a `close()` method as suggested elsewhere.
nit: braces unneeded
nit: braces unneeded
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
It has the MAX_DRAIN_ITERATION which trades the potential event delay (1) with effectively continuous draining (MAX_VALUE). I can't think of any adaptive adjustment method, only a parameterized serialize() operator.
nit: add `final` and put single parameter per line
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
nit. I think there is `.` missing `since 3.0[.] Use`
I think we should call `deserializer.close()` here
Looks good. I like the additional checking that you're doing here.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
We should read the metadata inside the while loop since it could change.
Looks good. I like the additional checking that you're doing here.
Looks good. I like the additional checking that you're doing here.
Looks good. I like the additional checking that you're doing here.
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
@vahidhashemian, yes, that's what I mean.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
This doesn't seem to be used.
We should read the metadata inside the while loop since it could change.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
The message doesn't seem to match the condition above.
Two tests are missing here. One that assert what happens when the library is not on the classpath, as I've indicated in [my previous review](https://github.com/spring-projects/spring-boot/pull/24340#discussion_r546777503). One that assert that a custom `Sniffer` instance is used rather creating one here. This custom instance should probably have a dependency on the high level client we auto-configure to make this a bit more realistic.
Good point! @vpapavas , can you handle stuff like this in a follow-on PR? I'm doing a final pass to try and get this one merged.
Update return type to `L` (if we introduce `L`)
nit: add a size? There are a few cases in here where we could do this.
Update return type to `L` (if we introduce `L`)
formatting: no need to curly braces
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
Update return type to `L` (if we introduce `L`)
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
nit: add `final`
There is a corner case in regarding the listener here: say a ListenerA class was previously used in the consumer, and now it wants to subscribe with another ListenerB class, after calling subscribe(), before sending a join-group request, a rebalance could be triggered upon, for example partition change, which will then use the new ListenerB class already. Not sure if it will be an issue though.
super nit: extra blank line
This seems to have the same issue as in SaslClient in that we need the logic to turn off OP_WRITE here too. Suppose that the server tries to send a token, but couldn't completely flush the writes. We get in here and completely flush the output buffer. Now, if the OP_WRITE is not turned off, the selector will be woken up all the time before the server receives the next token from the client.
the `try{...} finally` has been removed
This seems to have the same issue as in SaslClient in that we need the logic to turn off OP_WRITE here too. Suppose that the server tries to send a token, but couldn't completely flush the writes. We get in here and completely flush the output buffer. Now, if the OP_WRITE is not turned off, the selector will be woken up all the time before the server receives the next token from the client.
@jeffchao traditionally Kafka used key,value pairs in properties and pass it everywhere and each implementation takes look at this config and pulls their interested key,value pairs. Example, authorizer interface https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/security/auth/Authorizer.scala#L35 . The pluggable class when it gets instantiated a configure method will be called and all the key,value in server.properties will be passed and it will pick whats relevant to the class. We can do the same here instead of asking users append key,values into the a config which is hard to configure and hard to get it right.
Here we rely on insertProviderAt() programatic way BUT if in the application's context somebody else calls Security.insertProviderAt(provider,1) that provider will be given the priority for any conflicting Provider services+algorithms. This code works well if you have exclusive services+algorithms example SPIFFE but if you are writing a provider for Standard algorithms example TrustManagerFactory.PKIX then you may run into trouble since your insertProviderAt() call got overridden by somebody else in the application context/startup. When that happens I don't know easy way to fix it. I think It is important to call this out.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
It looks like there is an extra whitespace after return.
Given that we have both `ConnectorFactory` and `PluginDiscovery` which should be able to give you the full set of both canonical and short names, couldn't we just do a look up both on `connType` and `includedConnType` and validate that they are the same? It might require a bit of reworking (e.g. making `Map<String, Class<? extends Connector>>` available instead of `List<Class<? extends Connector>>` in PluginDiscovery), but it seems like a better solution since it'll address all the cases afaict. re: BadRequestException, we needed something in the 400 range and nothing else seemed appropriate.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Ah, you are right. Sorry.
Given that we have both `ConnectorFactory` and `PluginDiscovery` which should be able to give you the full set of both canonical and short names, couldn't we just do a look up both on `connType` and `includedConnType` and validate that they are the same? It might require a bit of reworking (e.g. making `Map<String, Class<? extends Connector>>` available instead of `List<Class<? extends Connector>>` in PluginDiscovery), but it seems like a better solution since it'll address all the cases afaict. re: BadRequestException, we needed something in the 400 range and nothing else seemed appropriate.
It was removed from the other versions of `group` but not from here.
How about returning a Set instead of List? ``` return topics .stream() .filter(topic -> !topic.isEmpty()) .collect(Collectors.toSet()); ```
Yeah, I have a slight preference to just lock `SubscriptionState` every time since it is the simplest option. I don't think contention is a major problem since there's only the heartbeat thread which is sleeping most of the time. Unless there's some reason to think the cost of lock acquisition itself is a concern.
There is a corner case in regarding the listener here: say a ListenerA class was previously used in the consumer, and now it wants to subscribe with another ListenerB class, after calling subscribe(), before sending a join-group request, a rebalance could be triggered upon, for example partition change, which will then use the new ListenerB class already. Not sure if it will be an issue though.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Reading again, maybe you mean that an exception will be thrown back to the user although it may not be from the method one would necessarily expect. For example, `send` won't throw an exception due to a failed batch, but `commitTransaction` will. Instead of explaining in detail here, we should probably refer to the actual methods (which need to be updated as well).
rcvr -> receiver (no need to obfuscate it)
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
Add a reference to KIP-511 here
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
We should limit this suppression to the method for which we really need it instead of the whole class
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
I think we probably should clean these up so they are more useful for users, but won't block merging this on that. I was thinking something more along the lines of: ``` UUIDDeserializer deserializes UUIDs in standard 36-byte hexidecimal string representation. ``` then followed by the encoding details, i.e. the stuff a user wants to know. Many users won't even think about the fact that what's going into the deserializer (or out of the serializer) is actually a `byte[]`.
I'd consider making this extend org.junit.rules.ExternalResource - it can then be used as a JUnit ClassRule or Rule. The benefits being that the JUnit framework takes care of startup and shutdown
Thanks for clarifying this... Maybe we should update the Producer docs, since this is enormously subtle, but also important for handling correctly.
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
No `else` needed since we used `return` for both other cases. For the exception, I think we can just throw `ClassCastException` since `IllegalStateException` doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more `Records` subtypes. For example: ```java "The record type is " + partition.records().getClass().getSimpleName() + ", which is not a subtype of " + Records.class.getSimpleName() + ". This method is only safe to call if the `FetchResponse` was deserialized from bytes."
Nit: "For instance, the transactional APIs require brokers with version 0.11.0 or newer."
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
So it seems the only reason for this method is to optimize iterator.remove (by using keysHandled .clear())? If so, I am not sure if it's worth doing this optimization since this makes the code a bit harder to read.
Preferred leader election is an optimization. If we can't move the leader to the preferred one, it seems there is no need to do anything extra.
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
createMetadataTopic() is no longer used.
Why was `FileNotFoundException` removed from the signature? It can be useful to list specific subclasses that may be worth handling separately from the general `IOException`.
It's unusual to hold a reference to an abstract class like this. I believe the intent is to be able to transparently handle either `KeyValueSegments` or (I'm guessing) `KeyValueTimestampSegments`. The full expression would be to have a `Segments` interface implemented by `AbstractSegments`, which is then extended by your two implementations. Then this line would reference `Segments<S>`. It's fine to collapse this into just the abstract class (although questionable in the presence of package-protected fields). But to maintain transparency, I'd name the abstract class `Segments` instead of `AbstractSegments`. That way, to an outsider class (like this one), you're still just interacting with the interface (i.e., the public interface of the class), rather than specifically an abstract class. Adhering to this pattern leaves the door open in the future to extract `Segments` into a full interface without having to change any outside code (which is what I meant by maintain transparency).
But I wouldn't be afraid to just use a full if/else block, either. ```suggestion final WindowBytesStoreSupplier storeSupplier; if (inOrderIterator) { storeSupplier = new InOrderMemoryWindowStoreSupplier("InOrder", 50000L, 10L, false); } else { storeSupplier = Stores.inMemoryWindowStore("Reverse", ofMillis(50000), ofMillis(10), false); } ```
But I wouldn't be afraid to just use a full if/else block, either. ```suggestion final WindowBytesStoreSupplier storeSupplier; if (inOrderIterator) { storeSupplier = new InOrderMemoryWindowStoreSupplier("InOrder", 50000L, 10L, false); } else { storeSupplier = Stores.inMemoryWindowStore("Reverse", ofMillis(50000), ofMillis(10), false); } ```
How about setting initial size of `records`? `new ArrayList<>(ids.size())`
Why do we need to call `build()` here? (similar below)
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
Private and call from the constructor? We only ever call this immediately after instantiating the class.
Seems like this is the same in `testReadFullyOrFailWithMultiReads`. Maybe we can extract it to a helper method.
Can this be a `byte`.
I can see two reasons that this might be set up this way. One is that the author didn't feel confident that they could distinguish EOF from other errors. I'm not entirely sure that checking for EOFException is enough. Another reason is because if an exception is thrown, whatever data has already been transferred will not be acknowledged to the caller, which would result in an inaccurate count at the upper layer.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
I can see two reasons that this might be set up this way. One is that the author didn't feel confident that they could distinguish EOF from other errors. I'm not entirely sure that checking for EOFException is enough. Another reason is because if an exception is thrown, whatever data has already been transferred will not be acknowledged to the caller, which would result in an inaccurate count at the upper layer.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Can this be a `byte`.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Include the exception in the log so there is an indication of what went wrong? Looks like it was previously included.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
Not sure about the terminology here. Reader and writer don't make sense in this context since nothing is being read or written. Maybe source and target? Also, it's possible the intent might be clearer if `writer` and `record` were next to each other in the argument list since `record` should be in the `writer` format and being converted to `reader` format.
Could we expose this like the following instead? ``` public KafkaFuture<ListOffsetResultInfo> partitionResult(TopicPartition partition); ``` Then we can keep the map internal.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Could we expose this like the following instead? ``` public KafkaFuture<ListOffsetResultInfo> partitionResult(TopicPartition partition); ``` Then we can keep the map internal.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Code convention nitpick: there should be a space before the colon.
Could we expose this like the following instead? ``` public KafkaFuture<ListOffsetResultInfo> partitionResult(TopicPartition partition); ``` Then we can keep the map internal.
Could we expose this like the following instead? ``` public KafkaFuture<ListOffsetResultInfo> partitionResult(TopicPartition partition); ``` Then we can keep the map internal.
Could we expose this like the following instead? ``` public KafkaFuture<ListOffsetResultInfo> partitionResult(TopicPartition partition); ``` Then we can keep the map internal.
Code convention nitpick: there should be a space before the colon.
Yes, this should on an internal package (eg `common.internals`).
We should use try-with-resources here (for `DataInputStream`).
I think so, changed it locally.
Nitpick: if you move the fail inside the `try`, then you no longer need the `return` in the catch. This applies to a few other tests too.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
Changed it locally.
I'm suspicious of summing the various latencies, rather than just measuring the time from the start of the method until now, since it would hide any unexpected sources of overhead.
I think so, changed it locally.
newuntil => newUntil
quote names of objects (`'CREATE INDEX "%(index)s"...'` etc). These parameters are spliced into the statement, not passed as arguments.
Is this intentional? cc @enothereska
quote names of objects (`'CREATE INDEX "%(index)s"...'` etc). These parameters are spliced into the statement, not passed as arguments.
quote names of objects (`'CREATE INDEX "%(index)s"...'` etc). These parameters are spliced into the statement, not passed as arguments.
Instead of adding headers each time, maybe we can pre-create the headers list and pass to ProducerRecord() constructor.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
can you please also check that the partition id gets set to -1
`null` check is redundant as `null instanceof StringDeserializer` will return false anyway.
can you please also check that the partition id gets set to -1
`NEO4J` is not needed. `neo4j` entry will be inferred from `Neo4jHealthIndicator`, can be replaced by `nodes`? Additionally, all entries in the result shouldn't be added to the detail.
nit: alignment looks a little off
`NEO4J` is not needed. `neo4j` entry will be inferred from `Neo4jHealthIndicator`, can be replaced by `nodes`? Additionally, all entries in the result shouldn't be added to the detail.
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
nit: alignment looks a little off
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
This should go away. `@ConditionalOnClass` already does that.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Yeah, that would be the closest for primitive types.
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Can we also assert that the state gets to `RUNNING` after the new thread has joined
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
While I think it would be fine, it would be "new" -- if we think `instance` is better, we might want to migrate all other code lazily to use `instance`, too. It's always best to have the same naming conventions throughout the whole codebase IMHO.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
Hmm, we want to check inter.broker.protocol.version >= 0.10.0. This is easier if we can use the case object in core. Since we only need to use the old protocol when SaslClientAuthethicator is used at the broker side. Perhaps, we can check inter.broker.protocol.version in the broker code and pass a flag into inter.broker.protocol.version. The places where we use SaslClientAuthethicator are in ReplicaFetcherThread, ControllerChannelManager, and KafkaServer (for controlled shutdown). When used in clients (producer/consumer), SaslClientAuthethicator will always use the new protocol.
need a check for null on `obj` here as well
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
It will be worth mentioning that it includes the root cause since this is in `Utils`.
It will be worth mentioning that it includes the root cause since this is in `Utils`.
It will be worth mentioning that it includes the root cause since this is in `Utils`.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
In most cases we don't have any message, so should be fine to remove. I see your point about `assert that bla` -- however, I think if the assertion hits, the error message reads different (ie, with reversed logic) and hence rephrasing would make it easier to read the error message if it fails (please correct me if I am wrong).
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
We should fix right away -- otherwise it might slip.
We should fix right away -- otherwise it might slip.
We should fix right away -- otherwise it might slip.
nit: newline for better IDE debugging.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
I think we just want to get rid of the special handling for logical types, but if it stays, the handling here needs to change. Any user defined schema can have a name too.
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
I think we're testing `testDir` Occupied here, not `AppDir`.
```suggestion if (stateDir.exists() && !stateDir.delete()) { ``` Do we need to check `hasPersistentStores` here? It seems sufficient just to check if the directory exists.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
nit: add `final`
We should read the metadata inside the while loop since it could change.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Do we really want anything related to internal topics to be client side? This could change in brokers from version to version and the clients should still work. I understand that for now we have no way to get that information, but we will soon (KAFKA-3306). I imagine removing the client side list would be part of the cleanup once thats available. So whatever exists in the mean time should be private so we don't need a deprecation cycle.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
`info.getProperty(â¦)` can return `null` when using `redisNode.asString()` because of the execution of the `INFO` command. `INFO` is executed only on master nodes, not on slaves. `clusterGetNodes()` returns all nodes. Passing `null` into `withDetail(key, value)` leads to an `IllegalArgumentException`. I'd not put too much knowledge about cluster execution in here but rather iterate over the `info` keys (e.g. filter on suffix `"." + VERSION`) and use the keys from `info` to retrieve data. I'd also propose adding nodes as list to the Redis info as topology details are valuable in a health indicator.
We should limit this suppression to the method for which we really need it instead of the whole class
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Function calls are complex. For example: ``` from youtube_dl.jsinterp import JSInterpreter jsi = JSInterpreter(''' function a(x) { return x; } function b(x) { return x; } function c() { return [a, b][0](0); } ''') print(jsi.call_function('c')) ```
`info.getProperty(â¦)` can return `null` when using `redisNode.asString()` because of the execution of the `INFO` command. `INFO` is executed only on master nodes, not on slaves. `clusterGetNodes()` returns all nodes. Passing `null` into `withDetail(key, value)` leads to an `IllegalArgumentException`. I'd not put too much knowledge about cluster execution in here but rather iterate over the `info` keys (e.g. filter on suffix `"." + VERSION`) and use the keys from `info` to retrieve data. I'd also propose adding nodes as list to the Redis info as topology details are valuable in a health indicator.
We should read the metadata inside the while loop since it could change.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
Do we really want anything related to internal topics to be client side? This could change in brokers from version to version and the clients should still work. I understand that for now we have no way to get that information, but we will soon (KAFKA-3306). I imagine removing the client side list would be part of the cleanup once thats available. So whatever exists in the mean time should be private so we don't need a deprecation cycle.
Static import for `SECONDS` will make code little nicer!
In fact, even the producer code is pretty similar, so you could have a methods like the following which is called by both `getBaseConsumerConfigs` and `getProducerConfigs`: ``` java private Map<String, Object> clientProps(Set<String> configNames, Map<String, Object> originals, Map<String, Object> overrides) { Map<String, Object> props = filter(configNames, originals); // enforce streams overrides if not specified by user for (String keyName : overrides.keySet()) { if (!props.containsKey(keyName)) props.put(keyName, overrides.get(keyName)); } } ```
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
Yes, reading can be done from multiple threads. `volatile` would probably be enough for this use case.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
Should we just assertTrue result.readyNodes.size() > 0? Ditto in line 348.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
I feel INFO level is fine as in many cases people will keep alerting on warn / error logs.
We shouldn't return `null`, but instead return a "unknown query" result.
SGTM. If we find it flooding the logs and not helpful we can reconsider
SGTM. If we find it flooding the logs and not helpful we can reconsider
SGTM. If we find it flooding the logs and not helpful we can reconsider
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
Might be useful to mention the serialized representation is JSON, and to say that this only affects deserialization when `schemas.enable=false`.
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
ok, potentially reduces allocations for the user, thanks
Also not clear why "numSegments - 1" here.
I think the assertion on 219 would pass even if the 1st mocked interaction never happened. Do we need something to tighten up the expected behaviour? Maybe something like: ```java verify(kafkaBasedLog, times(2)).send(any(), any(), any()); ```
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
Can we change the naming to use `ALL_CAPS`? For example, compare with the definition of `RemotePartitionDeleteState` in this PR.
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Typo -- or is that Italian? :-)
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Typo -- or is that Italian? :-)
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
A common pattern for classes like this without any state is to create a static instance. ```java public static final UnknownAddressSpec INSTANCE = new UnknownAddressSpec(); ```
By catching Throwable, aren't we silencing the error and not immediately failing the test? Also we should not be catching Throwable, if the JVM throws an Error we want it to fail the test and never want to handle it. There're a bunch of them in these files
typo in the test name.
A common pattern for classes like this without any state is to create a static instance. ```java public static final UnknownAddressSpec INSTANCE = new UnknownAddressSpec(); ```
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
This should be done in the SSL class. The base class should not be aware of SSL and just use configurations from the concrete classes
Ah, yes, it's `org.apache.kafka.test.TestUtils#tempDirectory()`. My mistake. The protocol is for all temporary state in Kafka tests to use that method. The change I made in `QueryableStateIntegrationTest` is basically what we should do here as well.
A common pattern for classes like this without any state is to create a static instance. ```java public static final UnknownAddressSpec INSTANCE = new UnknownAddressSpec(); ```
typo in the test name.
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
Hmm.. This method is invoked from `unsubscribe`. It seems like we might want to use `onPartitionsRevoked` in that case because it can still be a graceful handoff.
Also: should only call onPartitionsLost on owned partitions that no longer exist
Also: should only call onPartitionsLost on owned partitions that no longer exist
typo: moreq -> more
Maybe get the value of this expression on the line above. IMHO it will make it easier to see what the `assertThat` is doing.
Actually, it's not just older requests, the default was always `""` whereas I am seeing `null` after this PR. It looks like there are two issues: 1. We didn't set a default of `""` for clientId in the json schema. 2. The generated protocol code behaves differently with regards to default values. It only uses the default if the field is not present. The `Struct` code uses it if `value == null`. ```java Object value = this.values[field.index]; if (value != null) return value; else if (field.def.hasDefaultValue) return field.def.defaultValue; else if (field.def.type.isNullable()) return null; else throw new SchemaException("Missing value for field '" + field.def.name + "' which has no default value."); ``` This is the generated code _after_ I add the `""` default for `clientId`. ```java public void read(Readable readable, short version) { this.requestApiKey = readable.readShort(); this.requestApiVersion = readable.readShort(); this.correlationId = readable.readInt(); if (version >= 1) { this.clientId = readable.readNullableString(); } else { this.clientId = ""; } } ```
Hey @junrao, It was discussed on the dev channel that we shouldn't store or pass around the '*' the end as this then requires places to validate the resource name ends in a '*' on API calls and when loading from ZK. Also, with the rebrand of this from 'wildcard-suffixed' to simply 'prefixed' then I think we can drop the '*' completely. e.g. the user would add an ACL to any topic resource the has the prefix 'foo'. Look mum, no asterisks! This also helps separate this from the current 'wildcard' support i.e. '*'.
Maybe get the value of this expression on the line above. IMHO it will make it easier to see what the `assertThat` is doing.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Is there a reason not to include support for casting `DECIMAL` to other primitives? Yes, this might be lossy, but it also would help in cases where there would be no loss of precision.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
```suggestion "The desired Unix precision for the timestamp. Used to generate the output when type=unix " + ```
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Maybe get the value of this expression on the line above. IMHO it will make it easier to see what the `assertThat` is doing.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
yeah, other stuff from `RuntimeMXBean` was just a suggestion, obviously i wouldn't limit to that. classpath was the main one i saw that is useful. i don't think that it's too confusing since it is also alongside a bunch of other general system info. also, we still support the classpath approach, we just won't fix conflicts. we've definitely had cases on the mailing list that ended up being classpath issues that we probably could have spotted the likely root cause more quickly if we had had access to the classpath info.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
nit: It seems clearer to use `ConsumerPartitionAssignor.class` directly below.
nit: It seems clearer to use `ConsumerPartitionAssignor.class` directly below.
We should use try-with-resources here (for `DataInputStream`).
Seems like a no-op
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
It's not critical, but you might want to catch any exceptions from this `project` call and wrap them in another `SchemaProjectorException` so you can include info about which field failed projection.
We shouldn't return `null`, but instead return a "unknown query" result.
I wish `mock` has a less verbose interface to count the number of calls while keeping a function around.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
We shouldn't return `null`, but instead return a "unknown query" result.
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
We should not use wildcard imports. Check your IDE setting to disable this auto-rewrite.
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
I think in general we shouldn't call this `toString`. People would confuse it for the actual `toString` method and would suppose the same or similar behavior. For instance `toString` methods aren't expected to throw exceptions. So in my opinion we should call this something like `readAll` or `readAllBytes`.
getter and setter should be removed
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
We should not use wildcard imports. Check your IDE setting to disable this auto-rewrite.
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's a minor thing, but I would move the acquire/release to the public subscribe method.
nit: add `final`
Good call-- thanks for the correction.
Not for this PR: we can clean up the task-manager code to not pass in the checkpoint at all.
Good call-- thanks for the correction.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
Don't you think that being explicit improve readability? `boolean first = false;`
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
But `ProcessorStateManager` doesn't handle global tasks
Any reason you change to import all classes under `java.util`? I think we should import what we used in this class only.
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
this will never be called if one of the assertions fails
nit: remove `this` (not required)
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
Just wanted to say I really like the way this unit test is written! With the right usage of mocks we would avoid having any time-dependent flakiness.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Maybe we should update `MAX_PARTITION_FETCH_BYTES_DOC` as well.
Just wanted to say I really like the way this unit test is written! With the right usage of mocks we would avoid having any time-dependent flakiness.
Please revert all unrelated changes from single to double quotes.
Please revert all unrelated changes from single to double quotes.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
You can now use Java8 if you want! ``` static { CODE_TO_VALUE = Collections.unmodifiableMap(Arrays.stream(ResourceNameType.values()) .collect(Collectors.toMap(t -> t.code, Function.identity()))); } ```
we only need the lock for setting the seed and calling `random.nextInt`, right? for the rest of the function we can avoid holding the lock since we're just iterating over an immutable list that can't change and calling stuff that is threadsafe anyway
You can now use Java8 if you want! ``` static { CODE_TO_VALUE = Collections.unmodifiableMap(Arrays.stream(ResourceNameType.values()) .collect(Collectors.toMap(t -> t.code, Function.identity()))); } ```
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
This should go away. `@ConditionalOnClass` already does that.
nit: There is an extra space before `+`.
typo: we want to test the **case** that poll() returns no records.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
I like to include a trailing comma in cases like this so if more args are later edited it doesn't require editing this line again (keeps git blame cleaner)
This could also potentially be simplified to iterate over their fields together, which is probably cheaper than than the map lookups by field name. (In fact, *strictly* speaking it should be safe to just use the field from the original in the copy since they are supposed to be exactly identical anyway.)
Other module haved aliased `oauth_token` to `api_token` since `api_token` is what's actually used in the code I think it makes sense to add the alias here.
I think it should be just fine to check `if snapshot.vm is not None` because you are already using `snapshots_service` of that vm, so you don't need to check if names are same.
This line can be reverted now that the JUnit 4/5 split is gone.
I think it should be just fine to check `if snapshot.vm is not None` because you are already using `snapshots_service` of that vm, so you don't need to check if names are same.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
I don't understand what this test is doing. Why do we need background clients instead of producing upfront and consuming the data mirrorred at the end of the test? It looks like we are testing the primary->backup scenario but we are restarting the backup cluster. The source connector should not interact with the backup cluster.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Yeah it makes sense. Sorry for not getting back to you sooner
Nit: would generally prefer to see this made explicit (i.e., `drain` twice) as opposed to loop (which in case of some bug could in the worst case be non-terminating).
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
This doesn't seem to be used.
Yeah, we're still feeling out the best patterns for handling older versions.
"*" is considered "LITERAL" for compatibility reasons
prop: I would use `taskId01.toString()` here, since you are not testing the `taskId01.toString()` method. Our assumption is that the folder has a name that is equal to the result of `taskId01.toString()` and not `0_1`.
nit: remove empty line
You can't expose such thing in an exception.
You can't expose such thing in an exception.
You can't expose such thing in an exception.
Suggestion: I am not sure which terminology we use elsewhere, but "changelogConfig" may suggest to the average reader that there's a separate "changelog" concept that they may have never heard of. It's simply a topic configuration. I'd suggest to rename `changelogConfig` to `changelogTopicConfig` or the shorter `topicConfig`.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
You might consider using `OptionalDouble`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
You might consider using `OptionalDouble`.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
Hmm, why did we do this? I thought we'd have a try/catch block.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
nit: remove `this`
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
Hmm, why did we do this? I thought we'd have a try/catch block.
`NEO4J` is not needed. `neo4j` entry will be inferred from `Neo4jHealthIndicator`, can be replaced by `nodes`? Additionally, all entries in the result shouldn't be added to the detail.
nit: it is naming a source node, not a processor node. -> `"source"`
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
depending on the decision regarding naming sources for `builder.table` we'll need to update this test.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
I think it would be better to wait until the Kafka Streams client id in state `RUNNING` and then verify if the history of the states transitions after adding the stream thread is first `REBALANCING` and then `RUNNING`. Currently, the order is not verified as far as I can see.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
This should go away. `@ConditionalOnClass` already does that.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
Ditto on removing before/after
Yeah, I don't know if we do (depends on whether locking is a bottleneck here). And even if we did, it makes sense to do that separately instead of this PR.
This would be less mysterious if this method were inlined into `updateLimitOffsets`. Right now, it's not terribly clear why it's ok to set the "last update offset time" in a method that doesn't update the offsets.
This would be less mysterious if this method were inlined into `updateLimitOffsets`. Right now, it's not terribly clear why it's ok to set the "last update offset time" in a method that doesn't update the offsets.
we just generally try to avoid the mess if the code isn't ready to be committed yet. it can always be held onto in a branch, wip pr, etc
This will close the `InputStream` before it can be retrieved from the `ConfigurationSource` and used. Log4j2 makes it the responsibility of the user of the `ConfigurationSource` to retrieve the `InputStream` and close it so this change is unnecessary.
This will close the `InputStream` before it can be retrieved from the `ConfigurationSource` and used. Log4j2 makes it the responsibility of the user of the `ConfigurationSource` to retrieve the `InputStream` and close it so this change is unnecessary.
Nit: somehow I don't like `blah`. Otherwise LGTM
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
`.toString()` unnecessary here are other similar logs.
It seems I also could approve it. I will read all code tomorrow and work with you to get this approved.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: can we make this `if startTime == 0` ? That seems slightly easier to understand, and then all the conditionals can be in terms of startTime which is a bit more intuitive since that's what we're iterating over. Context switching between startTime and endTime kind of makes me lose my train of thought
I think we probably should clean these up so they are more useful for users, but won't block merging this on that. I was thinking something more along the lines of: ``` UUIDDeserializer deserializes UUIDs in standard 36-byte hexidecimal string representation. ``` then followed by the encoding details, i.e. the stuff a user wants to know. Many users won't even think about the fact that what's going into the deserializer (or out of the serializer) is actually a `byte[]`.
I think we probably should clean these up so they are more useful for users, but won't block merging this on that. I was thinking something more along the lines of: ``` UUIDDeserializer deserializes UUIDs in standard 36-byte hexidecimal string representation. ``` then followed by the encoding details, i.e. the stuff a user wants to know. Many users won't even think about the fact that what's going into the deserializer (or out of the serializer) is actually a `byte[]`.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
My reasoning is that the tests that expect the clock to auto-tick would be affected if the code under test changed from `milliseconds` to `nanoseconds`. Am I missing something? And is there a reason to only auto-tick `milliseconds`? `FastClock` is an interesting idea, it seems to depend less on how often `milliseconds` is invoked by the code under test. It seems more realistic too (in a sense, it's like reducing all timeout values by a multiplier).
I changed the cast to `Long.valueOf`.
From String#compareTo() ``` while (k < lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) { return c1 - c2; ``` Should the size comparison follow the same ordering ? i.e. size1 - size2
`.toString()` unnecessary here are other similar logs.
From String#compareTo() ``` while (k < lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) { return c1 - c2; ``` Should the size comparison follow the same ordering ? i.e. size1 - size2
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
Unfortunately, the fact the database is embedded is not exactly the same as us replacing the database with an embedded database. In theory, I'd very surprised if an embedded database would require different credentials for schema initialization so that approach would work but not really semantically correct IMO.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
I think we should drop the space after "function" through this file (can be a separate commit).
Ok. Then the KIP wiki needs to be updated.
This seems overly complicated. An easier structure to follow would be something like this: ```java String expectedType = "KafkaController"; Set<String> expectedMetricNames = Utils.mkSet( "ActiveControllerCount", "GlobalTopicCount", "GlobalPartitionCount", "OfflinePartitionsCount", "PreferredReplicaImbalanceCount" ); MetricsRegistry registry = new MetricsRegistry(); try (QuorumControllerMetrics quorumControllerMetrics = new QuorumControllerMetrics(registry)) { assertMetricsCreated(registry, expectedMetricNames); } assertMetricsRemoved(registry, expectedMetricNames); ```
Again, lines L#118 to L#123 can be replaced by: ``` assignment.keySet().retainAll(userAssignment); ``` same effect, as we want the intersection of `assignment` and `userAssignment`
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Ouch! Sorry about that!
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
I think this config property key seems a misfit, and probably reflects an earlier incantation of the design before KIP acceptance. It might be worth - in a separate PR - renaming this to something like `errors.tolerance` to better align with its purpose.
nit: could be useful to log the type of exception in the assertion message.
No, we have to fix it before AK 2.0. Once it is in a released API, we canât change it.
It's not obvious to me that the template approach is the best solution for readability as opposed to just creating another test settings file.
I think debug logging would be sufficient for this one as well as the log entry below for normal disconnect.
Nit: remove `this`
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
No need to repeat the choices.
I'd suggest moving this static method after the non-static methods.
Could you test `maybeRecordE2ELatency()` through `process()` and `forward()`? Although you test `maybeRecordE2ELatency()`, you do not test if the recording is done during processing, but that is the crucial thing, IMO.
We should update the Scala `TestUtils` to call this method.
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Yup, exactly, deserves a `throw` in my opinion, to prevent leaking that `null` into user's code. Also ![1454550686518](https://cloud.githubusercontent.com/assets/967132/12830813/453683d8-cba2-11e5-97f8-b820117907e1.jpg)
Yup, exactly, deserves a `throw` in my opinion, to prevent leaking that `null` into user's code. Also ![1454550686518](https://cloud.githubusercontent.com/assets/967132/12830813/453683d8-cba2-11e5-97f8-b820117907e1.jpg)
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Nit: the method is `Transformation.close()`, not "stop". The log message should probably reflect that.
I think we do not need to reset here since we are throwing the `InterruptException` again, which will set the flag as well.
It's a bit better if you move this inside the `try` and remove the `return` from the catch.
I think we do not need to reset here since we are throwing the `InterruptException` again, which will set the flag as well.
It's a bit better if you move this inside the `try` and remove the `return` from the catch.
I think we do not need to reset here since we are throwing the `InterruptException` again, which will set the flag as well.
It's a bit better if you move this inside the `try` and remove the `return` from the catch.
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
nit: 'else' can be dropped
Do we really want to do this? Might it be better to have a config for this? Or just run it with a fixed number of threads
When moving to boto3, we usually try to minimize the amount of code change to just altering the API calls/parameter names that are different between boto/boto3. Moving code into a class makes it very hard to review while also checking the boto3 compatibility.
When moving to boto3, we usually try to minimize the amount of code change to just altering the API calls/parameter names that are different between boto/boto3. Moving code into a class makes it very hard to review while also checking the boto3 compatibility.
I changed the cast to `Long.valueOf`.
I changed the cast to `Long.valueOf`.
Fixed via https://issues.apache.org/jira/browse/KAFKA-13699
I have no clue about this. \cc @enothereska @dguy
I changed the cast to `Long.valueOf`.
The typo is still there.
This is also related to the following PR https://github.com/apache/kafka/pull/1015 that uses sentinels in a number of places. It would be nice to be consistent on -1 versus null.
Not sure about this. I'd suggest using NO_TIMESTAMP and similar sentinels for the compatibility case.
Similar to above we should rename this.
I changed the cast to `Long.valueOf`.
nit: 'else' can be dropped
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
I changed the cast to `Long.valueOf`.
`before or after`
Fixed via https://issues.apache.org/jira/browse/KAFKA-13699
Nitpick: space missing before `conditionDetails`.
`before or after`
`long` -> `Long` is a binary incompatible change.
nit: add `final`
Think you might have forgotten to remove some debugging here
chop "one of" add comma before "or"
Think you might have forgotten to remove some debugging here
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
This may match across several `meta`s.
Shouldn't this be a config exception? It is not really invalid partitions.
Code convention nitpick: there should be a space before the colon.
Shouldn't this be a config exception? It is not really invalid partitions.
Code convention nitpick: there should be a space before the colon.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
Nit: ```suggestion * @return list of {@link ConfigValue} instances that describe each client configuration in the request and includes an {@link ConfigValue#errorMessages error} if the configuration is not allowed by the policy; never null ```
Shouldn't this be a config exception? It is not really invalid partitions.
createMetadataTopic() is no longer used.
Seems to be covered by `shouldAssignMultipleReplicasOfStandbyTask()` already
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
createMetadataTopic() is no longer used.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
While I think it would be fine, it would be "new" -- if we think `instance` is better, we might want to migrate all other code lazily to use `instance`, too. It's always best to have the same naming conventions throughout the whole codebase IMHO.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
nit: we can combine these two `try` blocks: ```java try (LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty()); QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> b.setConfigDefs(CONFIGS), Optional.of(sessionTimeoutSec))) { ... ```
Code convention nitpick: there should be a space before the colon.
Shouldn't this be a config exception? It is not really invalid partitions.
Code convention nitpick: there should be a space before the colon.
Code convention nitpick: there should be a space before the colon.
Nit: ```suggestion * @return list of {@link ConfigValue} instances that describe each client configuration in the request and includes an {@link ConfigValue#errorMessages error} if the configuration is not allowed by the policy; never null ```
please see my earlier remark about localizing as much as possible and adding a tear-down.
please see my earlier remark about localizing as much as possible and adding a tear-down.
please see my earlier remark about localizing as much as possible and adding a tear-down.
please see my earlier remark about localizing as much as possible and adding a tear-down.
please see my earlier remark about localizing as much as possible and adding a tear-down.
nit: remove `this`
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
This could move to `ListOffsetResponse` as a helper, and maybe name as `singletonListOffsetTopicResponse`
This could move to `ListOffsetResponse` as a helper, and maybe name as `singletonListOffsetTopicResponse`
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
This could move to `ListOffsetResponse` as a helper, and maybe name as `singletonListOffsetTopicResponse`
nit: could be useful to log the type of exception in the assertion message.
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
nit: 'else' can be dropped
It seems a little harsh to set a fatal error condition because the process logged something on stderr. A lot of applications use stderr as an output. Maybe we should just log this with `log.error`.
nit: As said in the other PR, this is a good idea but I would only do it if we do it for all exceptions.
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
I believe a null-pointer check is necessary here.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
nit: extra space, ditto below.
`.toString()` unnecessary here are other similar logs.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
`.toString()` unnecessary here are other similar logs.
I feel INFO level is fine as in many cases people will keep alerting on warn / error logs.
`.toString()` unnecessary here are other similar logs.
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
nit: could be set to final and refactor as: ``` final Integer partition; if (partitioner != null) { final List<PartitionInfo> partitions = producer.partitionsFor(topic); if (partitions.size() > 0) { partition = partitioner.partition(topic, key, value, partitions.size()); } else { throw new StreamsException("Could not get partition information for topic '" + topic + "' for task " + taskId + ". This can happen if the topic does not exist."); } } else { partition = null; }
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
These two cases don't seem to be different. I'd recommend just always wrapping the exception and throwing (currently the else block). If we just re-throw the first exception, reading the stack trace becomes very confusing. Especially since a lot of those exceptions don't even include the stack trace.
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
We don't need to delay the error ... just emit it and skip everything else. We confirmed this behavior in `observeOn`: https://github.com/ReactiveX/RxJava/issues/1680
nit: 'else' can be dropped
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
This lock is unnecessary since the onNext call is not supposed to be invoked concurrently.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Idem as above with a `ServerRequest`
Nitpick: we typically do this like: ``` java return "KerberosShortNamer(principalToLocalRules = " + principalToLocalRules + ")"; ```
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
It's useful to have a toString in any case, but I'd probably include the name of the class `KerberosShortNamer` in the `toString`.
Adding a parameter `version` for `encodeVersionThree` is very confusing to other readers. I'd suggest completely duplicate the code in `encodeVersionFour` and remove this parameter in `encodeVersionThree`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
By the way, `kafka.metrics.reporters` is a horrible config key name because it suggests that it is configuring the "Kafka metrics" system (which, as you know, is separate and different from the Yammer metrics system), but actually no, it configures Yammer. :disappointed:
By the way, `kafka.metrics.reporters` is a horrible config key name because it suggests that it is configuring the "Kafka metrics" system (which, as you know, is separate and different from the Yammer metrics system), but actually no, it configures Yammer. :disappointed:
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Second parameter should be `serverConfigs`
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Style convention: this should be called `value()`.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
Remove double blank.
nit: add `final`
nit: add `final`
Remove double blank.
nit: add `final`
This change appears to be unrelated.
If we start from scratch then maybe these would be better be in `state`, but they have been added to `processor` and moving them would be incompatible changes. So I'm more concerning about the newly added classes.
There is a corner case in regarding the listener here: say a ListenerA class was previously used in the consumer, and now it wants to subscribe with another ListenerB class, after calling subscribe(), before sending a join-group request, a rebalance could be triggered upon, for example partition change, which will then use the new ListenerB class already. Not sure if it will be an issue though.
`@EnableWebSecurity` will have switched off Boot's web security configuration so I don't think the order matters. I think we need either `@EnableWebSecurity` or `@Order`.
the norm (ideally) for AK is to only use `this.` as needed to handle masking. i'm sure there are exceptions, but almost universally the use case is for constructors to avoid awkward parameter naming in order to avoid conflicting with a convenient member variable name.
We could get away with a single `*`
We could get away with a single `*`
We don't need any of the 3 lines above right? We do it all inside the finally.
Hmm.. would we ever have customized error message that are not from `Errors` map? E.g. if pluggable modules record some non-ak errors.
we just generally try to avoid the mess if the code isn't ready to be committed yet. it can always be held onto in a branch, wip pr, etc
@akarnokd I wonder if this loop affects benchmark in positive or negative way, it consumes single core to max Should `cdl.await()` be used instead? it parks the thread I see this pattern in few other benchmarks but idk if it's intentional
nit: unneeded newline
I would say it's important _not_ to be able to create bogus requests. ;) We can introduce specific mechanisms for testing, but a public constructor for a request should do its own validation.
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
Hmm, if standbyTask does not ever call `init()` then why do we want it to be an abstract class? I felt that we can either just remove abstract `init` and just let `StreamTask` has its own `init` function that is also called in `resume`; or if we do want to have a `init` abstract logic, we can also move ``` log.info("standby-task [{}] Initializing state stores", id()); initializeStateStores(); checkpointedOffsets = Collections.unmodifiableMap(stateMgr.checkpointed()); processorContext.initialized(); ``` At let constructor call this `init`. Personally I like the first option since we are already overriding the constructors anyways which always covers the `init` part, and just the stream task needs a reusable `init` part that is to be used in `resume`. But it's your call.
Not clear why we want to use a separate thread to call `joinGroupIfNeeded`? In unit test we would try to avoid any unnecessary multi-threading as it can easily cause flaky tests.
A common pattern for classes like this without any state is to create a static instance. ```java public static final UnknownAddressSpec INSTANCE = new UnknownAddressSpec(); ```
"with a read-only key"
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: fix indention (similar below)
nit: fix indention (similar below)
nit: add `final` (same below)
We should use try-with-resources here (for `DataInputStream`).
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
We should use try-with-resources here (for `DataInputStream`).
Nit: the method is `Producer.close()`, not "stop". The log message should probably reflect that.
Yes that's right, but code-wise if the current restore consumer only contains partitions of standby tasks then the `updatedAssignment.removeAll(closedTaskChangelogs);` below would be a no-op since the `updatedAssignment` would not contain any of the `closedTaskChangelogs` (well, unless we assign the active and the standby of the same task to the same thread, which is even worse).
nit: add `final`
nit: add `final`
nit: I think we can remove `synchronized` here as well
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Ideally, we'd always use brackets on control flow operators.
nit: remove blank line
Ideally, we'd always use brackets on control flow operators.
nit: move `topology.globalStateStores(),` to next line.
nit: why not `k2` ? Should we use `A`, `B`, `C`, `D` for the values to make it easier to understand the expected result? It's unclear which A is which below.
nit `getMetadata` -> get`
this line is still a bit long... You could try a static import for `singletonList`.
Hmm. I think we're just following the same pattern used elsewhere, but I think the version check is redundant. We already know it's a valid version because the request constructor verifies it.
Hmm. I think we're just following the same pattern used elsewhere, but I think the version check is redundant. We already know it's a valid version because the request constructor verifies it.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
Add the `@Overrride` annotation to this method.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
Add the `@Overrride` annotation to this method.
`name()` -> `wrapped.name()`
Looks good. I like the additional checking that you're doing here.
Could store `entry.getKey()` in a local variable since it is used several times
Can you just do `name.startswith('__') and not name.endswith('__')`? Simpler is better
nit: This check seems superfluous (and is inconsistent with the collection of connector callables).
Copy/paste bug: should be "source."
You basically specified the `differentName` check twice, in this and in the previous method. I would specify the following tests into separate methods: - same - different names - different topics - different patterns Makes the test better readable and avoids repetitions of checks.
Yes that's right, but code-wise if the current restore consumer only contains partitions of standby tasks then the `updatedAssignment.removeAll(closedTaskChangelogs);` below would be a no-op since the `updatedAssignment` would not contain any of the `closedTaskChangelogs` (well, unless we assign the active and the standby of the same task to the same thread, which is even worse).
Why not check `context.timestamp`? Checking the message of the exception is very brittle.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Why not check `context.timestamp`? Checking the message of the exception is very brittle.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
I'm wondering if we should log this exception in case `thread_dump` raises an unexpected error. We don't want to lose the original error.
I'm wondering if we should log this exception in case `thread_dump` raises an unexpected error. We don't want to lose the original error.
```{@link org.apache.kafka.common.KafkaFuture#get}``` => ```{@link org.apache.kafka.common.KafkaFuture#get()}```
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
I don't see the point here, both errors are identical, so why do this ? If it fails you wouldn't even know which one actually failed.
I think this can be written as a for loop over `requests` followed by `requests.clear()`.
`.toString()` unnecessary here are other similar logs.
It seems that the checkstyle failed but all unit tests have passed. I can modify the code slightly to fix the checkstyle failure before merging it.
What about promotion? We need to actually perform the type promotion. It isn't valid, for example, to use an `int8` field's `Byte` value directly for a `float32` field.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
Same question here about just using a static ConfigDef instead of a static method.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I was thinking: ``` if (tries > 0) Thread.sleep(tries > 1 ? 10 : 2); ```
Maybe: Include in the log the Connect key, value, and other details of records that resulted in errors and failures.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
This would require a separate KStreamVoidTransformProcessor, but I feel it worth the internal cost for simpler public APIs.
nit: we usually do not use unnecessary numbers as part of the parameter; rename to `streamImpl` instead.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
nit: we usually do not use unnecessary numbers as part of the parameter; rename to `streamImpl` instead.
This will close the `ServerSocketChannel` before it can be used by the `ServerThread`. The channel is eventually closed when the thread is closed so this change is unnecessary. I'll address this when merging.
Ah got it, my bad :)
It seems I also could approve it. I will read all code tomorrow and work with you to get this approved.
You might consider using `OptionalDouble`.
Probably not, and since sensor names are only used for internal bookkeeping there should be no compatibility issues with the change.
I like this parity check. :+1:
Probably not, and since sensor names are only used for internal bookkeeping there should be no compatibility issues with the change.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: add `final`
`HeaderConverter` and this method don't exist prior to AK 1.1.
This method is called from within `newConverter`, `newHeaderConverter`, and `newConfigProvider`, so mentioning "converters" and getting the available converter implementation classes is actually wrong when used to find the config provider implementation class. One way to address that would be to pass in additional parameters to the method, but since we want to backport this to branches before `2.0` we have to make that work without method references. So one simple option is to rename the method to `converterClassFromConfig` and add a new method for `configProviderClassFromConfig` that does essentially the same thing but is tailored for config providers. Perhaps a better alternative is to dynamically determine the name and the `pluginNames(...)` based upon whether `klass` is a subtype of `Converter` or `ConfigProvider`. This keeps a single method, but is a bit more dynamic.
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
This method is called from within `newConverter`, `newHeaderConverter`, and `newConfigProvider`, so mentioning "converters" and getting the available converter implementation classes is actually wrong when used to find the config provider implementation class. One way to address that would be to pass in additional parameters to the method, but since we want to backport this to branches before `2.0` we have to make that work without method references. So one simple option is to rename the method to `converterClassFromConfig` and add a new method for `configProviderClassFromConfig` that does essentially the same thing but is tailored for config providers. Perhaps a better alternative is to dynamically determine the name and the `pluginNames(...)` based upon whether `klass` is a subtype of `Converter` or `ConfigProvider`. This keeps a single method, but is a bit more dynamic.
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
Maybe `Producer epoch...`. Also, not sure the exception message adds anything given what's already logged. Maybe we should remove that.
Definitely don't add an abstract class! Let's leave it as is for now, then.
I think a better test scenario is to move the logic in `close()` call, i.e. when the stream thread is being shutdown, and topology is closing, we call `processorNode.close()` in which we wait for a while and then tries to access the global store. It mimics the case where in closing the store cache is flushed and hence tries to access the global store again.
I think a better test scenario is to move the logic in `close()` call, i.e. when the stream thread is being shutdown, and topology is closing, we call `processorNode.close()` in which we wait for a while and then tries to access the global store. It mimics the case where in closing the store cache is flushed and hence tries to access the global store again.
I'm not too worried about it. We might try some "extract variable/method" refactoring when we merge.
I'm not too worried about it. We might try some "extract variable/method" refactoring when we merge.
nit: line too long
Is this used anywhere? I see we have changed client code to use the other C'tor.
Got it but I think the reason why a `Supplier` was added is wrong.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
nit: line too long
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Maybe we can just a better name for `path` since it makes this code look suspicious.
please see my earlier remark about localizing as much as possible and adding a tear-down.
please see my earlier remark about localizing as much as possible and adding a tear-down.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
I don't think we really need this function any more... we can just submit to the executor from the other function.
I think we should call `deserializer.close()` here
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Indentation doesn't look right here.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Shouldn't this be a config exception? It is not really invalid partitions.
Yes. But if we add some more parameters later on, it would simplify the diff. But it's also ok to keep as it.
Maybe we could make this assertion precise? I think we expect the request count to be 0.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
Nit: we don't normally use exclamation marks in Kafka log messages.
nit: remove empty line
nit: remove empty line
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
If not, we should move the exception capturing logic inside the dbAccessor as well.
The second param seems redundant.
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
Please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style)
I'm not too keen on the structure of the JSON, both because the keys vary and because it's not very extensible. I'd prefer something like this: ``` json { "status": "UP", "nodes": [ { "address": "127.0.0.1:7001", "version": "3.0.7" }, { "address": "127.0.0.1:7002", "version": "3.0.7" }, { "address": "127.0.0.1:7003", "version": "3.0.7" } ] } ``` The keys are the same for every node and we can also easily add extra information about a node.
Seems to be covered by `shouldAssignMultipleReplicasOfStandbyTask()` already
We can pass the serializers in the constructor and it's a bit more concise.
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
The two cases are differ that one throwing KafkaException (fatal) and the other throwing ProducerFencedException (task-migrated).
Seems to be covered by `shouldAssignMultipleReplicasOfStandbyTask()` already
nit: move below the shortcut return below.
The number has changed and 5 is no longer relevant.
This is using the "try-with-resources statement" so it will take care of the close.
The two cases are differ that one throwing KafkaException (fatal) and the other throwing ProducerFencedException (task-migrated).
This seems overly complicated. An easier structure to follow would be something like this: ```java String expectedType = "KafkaController"; Set<String> expectedMetricNames = Utils.mkSet( "ActiveControllerCount", "GlobalTopicCount", "GlobalPartitionCount", "OfflinePartitionsCount", "PreferredReplicaImbalanceCount" ); MetricsRegistry registry = new MetricsRegistry(); try (QuorumControllerMetrics quorumControllerMetrics = new QuorumControllerMetrics(registry)) { assertMetricsCreated(registry, expectedMetricNames); } assertMetricsRemoved(registry, expectedMetricNames); ```
Merge deliberately doesn't limit the source observable of observables; this is what `MergeMaxConcurrent` is for. Besides, I can't rule out a race for `requested`.
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
I think we should have a `log.info()` here to show the error. I'm afraid users might miss some error statuses once they get overridden, so it's good to have it persisted somewhere
I think we should have a `log.info()` here to show the error. I'm afraid users might miss some error statuses once they get overridden, so it's good to have it persisted somewhere
I think we should have a `log.info()` here to show the error. I'm afraid users might miss some error statuses once they get overridden, so it's good to have it persisted somewhere
There is a race condition here. `ExternalCommandWorker#process` is used by the `ProcessMonitor` thread, and also here in a different thread. Similarly, `controlChannel` is accessed by multiple threads and could be be used before it is initialized. I think `process` and `controlChannel` need to be initialized and accessed under a lock. I would suggest something like: 1. take lock 2. check if process is null. if so then EXIT 3. create ControlCommand 4. release lock 5. call executor#awaitTermination for 1 minute 6. if the executor did not finish all tasks, then take the lock again, invoke process#destroy, release lock, call awaitTermination again
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
We should initialize `TopologyTestDriver` with a fixed mock-timestamp and use this below instead of calling `System. currentTimeMillis()`
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
"*" is considered "LITERAL" for compatibility reasons
"*" is considered "LITERAL" for compatibility reasons
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
@ijuma Sorry, I don't know of a standard way of doing this,
@ijuma Sorry, I don't know of a standard way of doing this,
this method is unused but it maybe useful in the future.
There's really no reason to remove that.
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
We should initialize `TopologyTestDriver` with a fixed mock-timestamp and use this below instead of calling `System. currentTimeMillis()`
We should initialize `TopologyTestDriver` with a fixed mock-timestamp and use this below instead of calling `System. currentTimeMillis()`
"*" is considered "LITERAL" for compatibility reasons
We should initialize `TopologyTestDriver` with a fixed mock-timestamp and use this below instead of calling `System. currentTimeMillis()`
one parameter per line
"*" is considered "LITERAL" for compatibility reasons
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
perhaps a better name is `getConfigKeyRst()`
perhaps a better name is `getConfigKeyRst()`
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Thanks for cleaning up the code duplication.
`apiKey` is of type `ApiKeys` while `requestHeader.apiKey()` returns a `short`.
nit: fix indention: should only be 4 spaces (same below)
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Couldn't we simply wait for the current state to become `RUNNING`? ```suggestion private void waitForRunning() throws Exception { waitForCondition( () -> kafkaStreams.state() == KafkaStreams.State.RUNNING, DEFAULT_DURATION.toMillis(), () -> String.format("Client did not transit to state %s in %d seconds", expected, DEFAULT_DURATION.toMillis() / 1000) ); } ```
A 404 feels right to me. That's what we do in the `env` endpoint for a property that doesn't exist. It too can match multiple entries as the same property may be defined in multiple property sources.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
nit: could avoid the last space after `is correct.`
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
Use `KafkaException` instead of `RuntimeException`
nit: add a size? There are a few cases in here where we could do this.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
Is it intentional that there's a space before the colon? Also, is the stacktrace useful here? Or do we just want to print the error message. I haven't looked in detail, so a genuine question.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
This is a no op.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
I think we should call `deserializer.close()` here
nit: add a size? There are a few cases in here where we could do this.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
Cleaner to just check if `tasks.isEmpty` after the loop is over.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
nit: add a size? There are a few cases in here where we could do this.
I was thinking: ``` if (tries > 0) Thread.sleep(tries > 1 ? 10 : 2); ```
nit: extra blank line ```suggestion ```
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
nit: you could just specify one `String` variable at the top of the method and set it accordingly if `topics` is `null` or not then have a single `return` statement. Just a personal preference though.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
I would consider something other than just `...`. It took me some time to figure out why we were even adding this. `non-null` or something like that, or changing the format so it isn't `keySchema=` which implies (to me at least) that we're putting the actual value. Alternatively, you can include the actual schema, currently it's `toString()` just returns name & type, not a full, nested representation of the schema.
nit: this can be final
nit: extra blank line ```suggestion ```
Nit: go with single parameter per line.
Nit: go with single parameter per line.
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
I think we should call `deserializer.close()` here
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
nit: extra line
Could you add the returned `Subscription` to `innerSubscription`? `innerSubscription` also needs to be a `CompositeSubscription`
I guess the trick is to use a separate configuration class, take a look: https://github.com/spring-projects/spring-boot/blob/main/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/DataSourceAutoConfiguration.java#L66-L72
I guess the trick is to use a separate configuration class, take a look: https://github.com/spring-projects/spring-boot/blob/main/spring-boot-project/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/DataSourceAutoConfiguration.java#L66-L72
Can we use `assertThat(node.name, equalTo("source1")` or `assertEquals("source1", node.name)` instead of `assertTrue` for assertions like this? Elsewhere in this test, too
Is it possible to trigger infinite loop: raiseError -> reconfig -> raiseError -> reconfig ...
Is it possible to trigger infinite loop: raiseError -> reconfig -> raiseError -> reconfig ...
Is it possible to trigger infinite loop: raiseError -> reconfig -> raiseError -> reconfig ...
Is it possible to trigger infinite loop: raiseError -> reconfig -> raiseError -> reconfig ...
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
```suggestion if redirect_fqcr1 := routing_entry.get('redirect', None) ``` Also, it would be good to use a better name than redirect_fqcr1.
Cleaner to just check if `tasks.isEmpty` after the loop is over.
```suggestion if redirect_fqcr1 := routing_entry.get('redirect', None) ``` Also, it would be good to use a better name than redirect_fqcr1.
This seems like it's a kind of weird restriction. I guess it'd be odd to use the same name for an internal topic and another, though if you know its going to be prefixed it might not be great to not be able to use that same name.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
Should be more precise. See discussion about `HoppingWindow` and `TumblindWindow` in #1250
Why is the order non-deterministic... a set somewhere? I think we should try to avoid that if possible.
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
Hmm.. I'm wondering how did we succeed in this test case, since in the above code `send()` call is only captured with `TimeoutException`? Note that we only set the KafkaException in the callback while here we throw exception directly. And in fact, you changed the expected exception from StreamsException to KafkaException in line 128 above.
I'm thinking of the case where the broker doesn't support v1 of ListOffsets. For this case, I think we currently raise `ObsoleteBrokerException`. I am questioning whether it would be more consistent to return a null entry in this case in the result of `offsetsForTimes`. Currently it is possible for the broker to support the new api version, but not the message format version which is needed to answer the query. In this case, we return a null entry.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
again, naming of the test
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Seems like a no-op
There's no need for that. If the pool is not available, then no pool should be configured as before.
nit: remove `this`
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
Should we add some more stuff to round this out (and make use of all the support for reporting more than one value...), e.g. some other `RuntimeMXBean` info? For example, classpath info seems like it'd be useful (probably more so before `plugin.path`, but still probably handy from time to time).
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
nit: remove `this`
To close out the earlier thread.. This test is okay, since `NOT_RUNNING` will make that instance go to DEAD state (or some non functional state like that) where the store cannot be obtained.. the lines below check that we can stil retrieve the keys from the other replica
I'd suggest to use a more descriptive test name, e.g. in the form of `shouldDoXYZ`.
```suggestion public void shouldInstantiateAssignor() { ```
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
nit: should be `Deserializer<?>` to avoid warnings about using a raw type
The test name is not self describing: what about `shouldAlllowToSpecifyRocksDBConfigSetterClassAsString`
The test name is not self describing: what about `shouldAlllowToSpecifyRocksDBConfigSetterClassAsString`
It would be better to do the assertion in the test rather than here. It will make the test clearer.
I'd suggest to use a more descriptive test name, e.g. in the form of `shouldDoXYZ`.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
IMO, this string should give details when the condition is not met, like `stream thread has not been added`. Same applies to the other wait conditions.
we can make method this public in `EmbeddedConnectCluster`.
we can make method this public in `EmbeddedConnectCluster`.
we can make method this public in `EmbeddedConnectCluster`.
we can make method this public in `EmbeddedConnectCluster`.
we can make method this public in `EmbeddedConnectCluster`.
we can make method this public in `EmbeddedConnectCluster`.
we can make method this public in `EmbeddedConnectCluster`.
we can make method this public in `EmbeddedConnectCluster`.
Seems that this class is a bit redundant, i.e, we could just construct an `AssignedTasks` with the `logContext` and `"standby task"`
Rather than having `try{...} finally` everywhere it might be better to keep track of the locked `TaskId` and unlock them in the `cleanup` method.
Rather than having `try{...} finally` everywhere it might be better to keep track of the locked `TaskId` and unlock them in the `cleanup` method.
Rather than having `try{...} finally` everywhere it might be better to keep track of the locked `TaskId` and unlock them in the `cleanup` method.
same for functions below
Maybe we could make this assertion precise? I think we expect the request count to be 0.
This should go away. `@ConditionalOnClass` already does that.
@bbejeck @guozhangwang Oops, looks like I missed this. Bill has a point here. I will probably log a JIRA to get this done.
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
again, naming of the test
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
Oh, I just noticed. Then `synchronized` is not needed anymore.
Did you mean: ```suggestion setBrokerId(2). setBrokerEpoch(100). ```
The primary functionality of this method is to _set_ the partition... I am confused by `with stale(standby, restoring) stores added via fetching the stores` -- what does this mean? Maybe just simplify to: ``` Set a specific partition that should be queries exclusively. ```
The primary functionality of this method is to _set_ the partition... I am confused by `with stale(standby, restoring) stores added via fetching the stores` -- what does this mean? Maybe just simplify to: ``` Set a specific partition that should be queries exclusively. ```
Can remove if initialize above
Can remove if initialize above
It should be 'false' by default
nit: remove `which is`
The primary functionality of this method is to _set_ the partition... I am confused by `with stale(standby, restoring) stores added via fetching the stores` -- what does this mean? Maybe just simplify to: ``` Set a specific partition that should be queries exclusively. ```
`it is` -> `they are` (we user is a person :))
The reason why `ConcurrentSkipListMap` did not implement it in this way is because it is designed to be async, and we need it that way to support IQ / stream thread concurrency. But since only stream thread would put / delete into the map (assuming we forbid iterator.remove from the other PR so it is not allowed from IQ), then it is okay to have this field as non-volatile.
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
nit: can we make this debug level? Otherwise it will make this test a little spammy.
What's our plan for the global thread? I didn't think of this during the KIP discussion, and sorry if it was brought up there and I just forgot about it. But it seems like we should still give users a non-deprecated way to set a handler for the global thread.
What's our plan for the global thread? I didn't think of this during the KIP discussion, and sorry if it was brought up there and I just forgot about it. But it seems like we should still give users a non-deprecated way to set a handler for the global thread.
nit: move `topology.globalStateStores(),` to next line.
prop: I would use `taskId01.toString()` here, since you are not testing the `taskId01.toString()` method. Our assumption is that the folder has a name that is equal to the result of `taskId01.toString()` and not `0_1`.
prop: I would use `taskId01.toString()` here, since you are not testing the `taskId01.toString()` method. Our assumption is that the folder has a name that is equal to the result of `taskId01.toString()` and not `0_1`.
Indeed merge is the main reason, however every time people use split-merge and **don't find out** about this behavior they introduce a potential hard-to-find bug. It still seems to me that `merge` should by default behave like `mergeFirstErrorOnly` from #5779 discussion, but I'm definitely not pushing.
Nit: remove `this`
Nit: remove `this`
nit: "failed on partition being lost {}" -> "failed on invocation of `onPartitionsLost` for partitions {}"
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Thinking about this, I guess we could improve `StickyTaskAssinger`. If I am not off, load balancing on stream basis is not optimal -- but I am also not sure if the effort to improve it is worth it... If we extend this test to assign more tasks, let's say 12, client `p2` will get 7 tasks assigned and `p1` get 5 tasks assigned (while it would be better to assign 8 tasks to `p2` such that all 3 thread get 4 tasks each). The problem is, that the capacity factors are not considered: `p2` should get twice as many tasks assigned as `p1` -- but the algorithm says only "more" -- and this more is determined be the diff of the capacity (ie. in this case `p2` will get at most 2 more tasks assigned than `p1`. Or maybe my analysis is wrong (I did not run the code and step through it.)
same here. let's make all method params as `final`
same here. let's make all method params as `final`
Nit: please add `final` to all local vars and method parameters
Nit: var should be named `deserializeValue`
All the `null` checks at each layer of the call stack make me think that particular issue might be better handled with an exception. Not critical since this is all internal code, but seems like then we'd only need to check version compatibility in one or two places.
I find the curent version more readable.
I find the curent version more readable.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
Should this be included here, or should it refer to a dedicated section in the connect docs? I guess there's two cases: bootstrapping a whole new connect cluster, or upgrading an existing one. For the bootstrapping case it's not completely clear whether the "preparing" round is required.
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
Since log.error(.. ex) will print the stack trace already, may be we can save re-throwing the exception again. EDIT: if we want to stop the whole process by throwing the exception, we can then save log.error().
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Seems like this might occur only in a programming error, which we could test for in a unit test.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
nit: We could use `singletonMap` here.
This definitely doesn't cover the full space of errors that are possible here -- `asSubclass` could throw a `ClassCastException`, `newInstance` could also throw `SecurityException`. I think the `catch` was broad because this ensures that except for extreme cases like other `Throwables` or `Errors` we get everything converted to `KafkaExceptions`.
Consider naming the topic "topic2" since there are only two topics in the test
Consider naming the topic "topic2" since there are only two topics in the test
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
I think this description makes it more confusing. You already explain this above. Please remove this edit.
Even though the config is invalid, the passwords may be valid, so it seems safer not to include them. It would be nice if the sensitive entries in the JAAS config would be communicated in some way to improve debuggability (in the future). Btw, a nit: we seem to use inconsistent capitalisation of the word JAAS in our messages. It would be nice to make that consistent.
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
same as above for parameters
same as above for parameters
Update return type to `L` (if we introduce `L`)
Update return type to `L` (if we introduce `L`)
Update return type to `L` (if we introduce `L`)
Ah, sorry I didn't think of this/mention it before, but I think we actually need to wait for a _transition_ to RUNNING, and not just for it to be in the state itself. It probably takes a little while after removing a thread for the rebalance to occur, so it's probably already in RUNNING. Pretty sure there's some other integration test util that watches for the REBALANCING -> RUNNING transition, though
This is the default.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
This doesn't seem to be used.
nit: avoid `this` if not required.
Update return type to `L` (if we introduce `L`)
Can you add here that patterns support full Python regex? I see that you straight `re.compile` them later.
nit: remove `this`
Passing in the current listener seems a little weird. I wonder if we're trying a little too hard to reuse the subscribeTopics method in SubscriptionState. If instead we had a method like SubscriptionState.subscribeMatchingTopic (or something like that), then we wouldn't need the flag and we wouldn't need to pass a listener. You could change this line to this: ``` subscription.subscribeMatchingTopics(topicsToSubscribe); metadata.setTopics(topicsToSubscribe) ```
This is because we are inheriting a Scala class, and moving forward we should remove this with the Java version `org.apache.kafka.copycat.util.ShutdownableThread` that can be moved into `o.a.k.common.utils`. We can leave it as is for now.
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
nit: parameter/line formatting
Yes, it seems that -1 means that we are trying to read beyond the end of the channel, which probably should be treated as abnormal.
@amethystic I believe Jun is suggesting that it is abnormal for `readFully` (i.e. if you can't fill the buffer, then something is wrong). I think a case can be made for that. I think the downside is that the error messages may not be as good as if the callers do the check themselves. The upside is that we avoid the situation where the caller forgets to check. We'd have to verify that these semantics are right for `FileRecords.readInto` since it doesn't perform any checking atm.
`endOffsets.get(topicPartition)` can be replaced by `offset`
nit: We could use `singletonMap` here.
nit: We could use `singletonMap` here.
Please remove empty line.
I think it would be better to wait until the Kafka Streams client id in state `RUNNING` and then verify if the history of the states transitions after adding the stream thread is first `REBALANCING` and then `RUNNING`. Currently, the order is not verified as far as I can see.
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
The restore consumer needs to override one param: `consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");`
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
We should rename this when merging. Something like `ExplicitDataSourceTypeOrUrlCondition`.
The restore consumer needs to override one param: `consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");`
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
Could store `entry.getKey()` in a local variable since it is used several times
One extra line.
Changing to `List<List<FlywayMigration>>` breaks backwards compatibility without any benefit. I think we should either keep the old format, or change to a Map<String, List<FlywayMigration>> where the string somehow indicates which DataSource the migrations were run against. The JDBC URL of the DB would be ideal, but I'm not sure we can get that.
Could store `entry.getKey()` in a local variable since it is used several times
Personally I would prefer not special handling this case with the different schedule time, as this could change the commit interval unexpectedly for users; instead we can just move forward with the regular commit interval, and if the next commit fails again it may be fine still.
Ok - yes makes sense. Thanks for the clarification
nit: extra line
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Nit: long line.
I'd suggest keeping the format slightly closer to what we had before. Specifically: `Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted`
I mean the `ProductionExceptionHandlerResponse` class itself
I'd suggest keeping the format slightly closer to what we had before. Specifically: `Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted`
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
Sorry for that -- You are of course right. `final` only for iterator loops...
Perhaps we should not change the return type here unless we decide to make the more extensive `LinkedHashSet` change across all APIs (and corresponding KIP).
So the net effect of UnsafeFunc0 is that it forces us to catch the declared Exception on resourceFactory.call() and think about what might happen. I'm not sure it's worth it.
I remember some of the metrics were lazily registered, i.e. they would only be registered if the corresponding action is called for the first time. Have we refactored it to always register all metrics up starting the task / process-node etc? Otherwise waiting for the stream state to transit to RUNNING may not guarantee all metrics should be already registered.
Thanks for double checking this! Then it lgtm.
Nit: seems like the interrupted check should be done before we compute the remaining time (from a clarity point of view).
nit: 'else' can be dropped
I think upon close(), we can also use `maybeAutoCommitOffsetsAsync` and then we can remove the whole function fo `maybeAutoCommitOffsetsSync`.
prop: - Remove `Target` - `thread` -> `stream thread`
Unlike in the standalone, it's a bit more difficult to check how the connector configuration has changed. This `startConnector(...)` method seems to be called in two places: from `restartConnector(...)` and `processConnectorConfigUpdates`, which IIRC happens whenever the connector configuration has changed in some way. I'm wondering how often a connector might not change it's task configs when the connector config has changed. What do you think about just always restarting the tasks even if the generated task configs have not changed? WDYT? @kkonstantine, the `processConnectorConfigUpdates(...)` method is called during rebalances, and maybe I'm missing cases where the recent rebalance improvements handle the task configs more frequently than I recall.
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
We usually avoid writing to standard out in test cases. A few more of these.
The `java.util.concurrent.Callable` would be a more friendly class instead.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
I thought about this when tightening the FSM before but the unit tests reminds me of one thing: our current contract is that we only transit to PARTITIONS_REVOKED when calling onPartitionsRevoked, which is called only once at the beginning of the rebalance today, so keeping it strict is better just in case we have incorrect partial rebalance procedure. With KIP-429 this may be violated so we need to revisit our FSM once Streams adopt cooperative protocols. cc @ableegoldman who's working on this.
typo: Woth -> With
I think we may be able to simplify this and just use `canSendRequest`. If a metadata update is due (which is a rare case), we will still be prevented from sending. It doesn't seem like we get any benefit from having `leastLoadedNode` choose a different node which may have in-flight requests.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
I think this is what the below TODO (191) was added for, Thanks :) Please feel free to remove that TODO marker then.
Is this key for the purpose of renaming an existing block? Usually how this works is some key is global (maybe name) and then if other parameters are changed (like description) the module will detect that the resource description is out of date and change it, so users don't have to manually tell the module what fields to update.
While I think it would be fine, it would be "new" -- if we think `instance` is better, we might want to migrate all other code lazily to use `instance`, too. It's always best to have the same naming conventions throughout the whole codebase IMHO.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
nit: add a size? There are a few cases in here where we could do this.
I'd be tempted to rename this `getJobName()`
Looks good. I like the additional checking that you're doing here.
nit: add a size? There are a few cases in here where we could do this.
`instantiateConfigProviders` since this is potentially creating multiple providers
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
remove var -- only used once.
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
`instantiateConfigProviders` since this is potentially creating multiple providers
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
It can sometimes be hard to get the logs for failing tests, so it might be nice to get the failure reason in the actual test output. Check out `Matchers`: there should be a way to compose the checks you're doing here manually. It'll be something like: ``` assertThat( message, is( oneOf( containsString("Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING"), containsString("The state store, source-table, may have migrated to another instance") ) ) ```
This could be just "Classes shared between Wavefront tracing and metrics."
This could be just "Classes shared between Wavefront tracing and metrics."
Maybe we could use a different value here.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
It's unusual to hold a reference to an abstract class like this. I believe the intent is to be able to transparently handle either `KeyValueSegments` or (I'm guessing) `KeyValueTimestampSegments`. The full expression would be to have a `Segments` interface implemented by `AbstractSegments`, which is then extended by your two implementations. Then this line would reference `Segments<S>`. It's fine to collapse this into just the abstract class (although questionable in the presence of package-protected fields). But to maintain transparency, I'd name the abstract class `Segments` instead of `AbstractSegments`. That way, to an outsider class (like this one), you're still just interacting with the interface (i.e., the public interface of the class), rather than specifically an abstract class. Adhering to this pattern leaves the door open in the future to extract `Segments` into a full interface without having to change any outside code (which is what I meant by maintain transparency).
I know this line hasn't been changed, but the `this` variable refers to the `ConnectorContext` that does not have a `toString()` method. Might be better to refer to `WorkerConnector.this` instead, so that it behaves like old line 87.
Is there a case when updateQuota() can return false? Ditto for removeQuota().
I know this line hasn't been changed, but the `this` variable refers to the `ConnectorContext` that does not have a `toString()` method. Might be better to refer to `WorkerConnector.this` instead, so that it behaves like old line 87.
I know this line hasn't been changed, but the `this` variable refers to the `ConnectorContext` that does not have a `toString()` method. Might be better to refer to `WorkerConnector.this` instead, so that it behaves like old line 87.
I know this line hasn't been changed, but the `this` variable refers to the `ConnectorContext` that does not have a `toString()` method. Might be better to refer to `WorkerConnector.this` instead, so that it behaves like old line 87.
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
I know this line hasn't been changed, but the `this` variable refers to the `ConnectorContext` that does not have a `toString()` method. Might be better to refer to `WorkerConnector.this` instead, so that it behaves like old line 87.
It should be 'false' by default
nit: line too long
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
does always apply -> always applies
Hmm, this doesn't seem great.
Hmm, this doesn't seem great.
Hmm, this doesn't seem great.
We could perhaps include the available processors check too: ```java private static final boolean ENABLED; static { ENABLED = System.getProperty("org.graalvm.nativeimage.imagecode") == null && !Boolean.getBoolean(IGNORE_BACKGROUNDPREINITIALIZER_PROPERTY_NAME) && Runtime.getRuntime().availableProcessors() > 1; } ```
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
same here. let's make all method params as `final`
The test name is not self describing: what about `shouldAlllowToSpecifyRocksDBConfigSetterClassAsString`
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
It isn't about blocking vs non-blocking. It is about how a Kafka broker behaves to a non-authenticated request on SASL ports... we need to test it (since it is the requirement of this JIRA). We hope that SASL behaves exactly the same as PLAINTEXT, but we don't know that it does without a test.
It isn't about blocking vs non-blocking. It is about how a Kafka broker behaves to a non-authenticated request on SASL ports... we need to test it (since it is the requirement of this JIRA). We hope that SASL behaves exactly the same as PLAINTEXT, but we don't know that it does without a test.
`isServer` is not used
It isn't about blocking vs non-blocking. It is about how a Kafka broker behaves to a non-authenticated request on SASL ports... we need to test it (since it is the requirement of this JIRA). We hope that SASL behaves exactly the same as PLAINTEXT, but we don't know that it does without a test.
It seems that we can just use one level of if/else.
It seems that we can just use one level of if/else.
Let's remove the brace changes please.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
To match the old code this should be: ``` if (zoneinfo_root.exists() and not zoneinfo_root.joinpath(*self.TIME_ZONE.split('/')).exists()): ``` You are missed the second `.exists()`.
We should also check to make sure there are no invalid empty task IDs. In that case we should throw an exception and not try to create anything, similar to the above exception...
`endOffsets.get(topicPartition)` can be replaced by `offset`
We should also check to make sure there are no invalid empty task IDs. In that case we should throw an exception and not try to create anything, similar to the above exception...
I said it incorrectly before, and I actually meant that you can use `org.apache.kafka.test.NoOpKeyValueMapper` in this case as we do not really care about what aggregate key / value to use. Your proposal is also fine, while I was just trying to reduce duplicated code :)
Does it make sense to do this check for all types on read? INT64, INT32, etc
as above. Name of the test can be more descriptive. `shouldRequireBrokerVersion0101OrHigherWhenEosDisabled`
as above. Name of the test can be more descriptive. `shouldRequireBrokerVersion0101OrHigherWhenEosDisabled`
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
I would say it's important _not_ to be able to create bogus requests. ;) We can introduce specific mechanisms for testing, but a public constructor for a request should do its own validation.
This block may be a bit easier to follow if the if-else block sets up the Map of properties that will be used for the config provider properties, and then instantiate them in one place. Something like: ``` Map<String, String> providerConfig; if (configProviders == null || configProviders.isEmpty()) { providerConfigs = indirectVariables; } else { providerConfigs = mapValuesToStrings(configProviders); } Map<String, ConfigProvider providers = instantiateConfigProvider(providerConfigs, originals); if (!providers.isEmpty()) { ... ``` I know the if-else could be simplified further, but I think this is simple to follow.
nit: can remove type arguments
This should go away. `@ConditionalOnClass` already does that.
Yeah, Java's type system makes this stuff a pain. I think you can fix it with: ``` final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(new KStreamBranch<>((Predicate<K, V>[]) predicates.clone(), childNames), branchName); ``` which should be safe If you want to also get rid of the cast, you can do it by coercing each of the predicates to a Predicate<K,V> when you loop over them at the beginning: ``` Predicate<K, V>[] kvPredicates = new Predicate[predicates.length]; for (int i = 0; i < predicates.length; i++) { final Predicate<? super K, ? super V> predicate = predicates[i]; Objects.requireNonNull(predicate, "predicates can't be null"); kvPredicates[i] = predicate::test; } ```
What do we do if there's an exception? If it's expected, let's make it clear
What do we do if there's an exception? If it's expected, let's make it clear
I was thinking: ``` if (tries > 0) Thread.sleep(tries > 1 ? 10 : 2); ```
Is this intentional? cc @enothereska
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
Or have one that takes a lambda so that the caller can do the `close`. Similar to what we have for Scala.
Hmm.. Do we know how this is getting propagated in all cases? Some of the responses are handled using a `RequestCompletionHandler`, but NetworkClient currently eats any exception raised from this callback.
Are both host groups really needed? Does the one that contains ':' handle both? We have regex in other places in the project that do similar parsing we may want to keep in sync: - https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/utils/Utils.java#L53 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/BrokerEndPoint.scala#L27 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/EndPoint.scala#L29
Should we restrict the values for name and version? Maybe we can just test that they are non empty? nit: the non-capture group isn't really necessary and this regex matches stuff like `"."` and `"---"`.
nit: unneeded newline
We should actually remove the reference to `KTable` as we don't currently support it
Probably a good idea to check if SASL_SSL for the second case and throw an exception otherwise (in case we ever add another SASL_\* protocol).
Is this just to prevent it from processing anything until you're ready to proceed? It seems like you can/are doing that just by controlling when to produce input messages and doing so one at a time (if that's accurate, then WDYT about renaming `process` to `processed` and flipping the boolean so it more clearly serves the purpose of indicating whether a record has yet been processed)
Got it. May be we could have something like SchemaAndValueUtils to include such utils for it. Just didn't feel great seeing this method in the ConnectHeaders class.
Perhaps we should not change the return type here unless we decide to make the more extensive `LinkedHashSet` change across all APIs (and corresponding KIP).
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
We need to choose at least a live replica.
```suggestion return completeOrForwardRequest(cb, path, method, headers, body, resultType, new IdentityTranslator<>(), forward); ```
nit: unneeded newline
nit: unneeded newline
Maybe use Objects.requireNonNull
Got it. May be we could have something like SchemaAndValueUtils to include such utils for it. Just didn't feel great seeing this method in the ConnectHeaders class.
Maybe use Objects.requireNonNull
nit: unneeded newline
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
@amethystic I believe Jun is suggesting that it is abnormal for `readFully` (i.e. if you can't fill the buffer, then something is wrong). I think a case can be made for that. I think the downside is that the error messages may not be as good as if the callers do the check themselves. The upside is that we avoid the situation where the caller forgets to check. We'd have to verify that these semantics are right for `FileRecords.readInto` since it doesn't perform any checking atm.
Do we want this to be `error` or `warn`? Maybe `error` is right, so take this as a question. :)
The `connectorStatus(connector)` call might fail with a `NotFoundException` if the connector was removed after the `configState.connector()` method is called but before the status for the removed connector is asked for. Although this shouldn't happen within the process (since requests are handled sequentially by a single thread), it may be possible that this herder is not the leader, that the leader performed the change, and that this herder's config state backing store read that change after the `configState.connector()` method was called but before the `connectorStatus(connector)` method is called for that connector. Should be easily handled with a try-catch, and if the connector with the specified name is not found then simply continue to the next connector name. Something like: ```suggestion try { out.put(connector, connectorStatus(connector)); } catch (NotFoundException e) { // do nothing with connectors that were just removed } ``` Note that if a connector is *added* with similar timing, the new connector name will not be returned from `configState.connectors()` and the new connector will not be included in the results. I think that's fine, considering the result of this method call would still be consistent with the state at the time the `configState.connectors()` call is made. Call it again, and you'd see the new connector.
The `connectorStatus(connector)` call might fail with a `NotFoundException` if the connector was removed after the `configState.connector()` method is called but before the status for the removed connector is asked for. Although this shouldn't happen within the process (since requests are handled sequentially by a single thread), it may be possible that this herder is not the leader, that the leader performed the change, and that this herder's config state backing store read that change after the `configState.connector()` method was called but before the `connectorStatus(connector)` method is called for that connector. Should be easily handled with a try-catch, and if the connector with the specified name is not found then simply continue to the next connector name. Something like: ```suggestion try { out.put(connector, connectorStatus(connector)); } catch (NotFoundException e) { // do nothing with connectors that were just removed } ``` Note that if a connector is *added* with similar timing, the new connector name will not be returned from `configState.connectors()` and the new connector will not be included in the results. I think that's fine, considering the result of this method call would still be consistent with the state at the time the `configState.connectors()` call is made. Call it again, and you'd see the new connector.
Wouldn't you also need to handle default values? Presumably you're also assuming that there's only one version of a schema referenced anywhere in the schema? And that the schema parameters (e.g. the scale used by Decimal) don't matter? I realize that Decimal isn't a good example of where this could come into play, I'm just trying to highlight that I'm not sure the current API really addresses the full problem.
Perhaps we should not change the return type here unless we decide to make the more extensive `LinkedHashSet` change across all APIs (and corresponding KIP).
same for the store
nit: should be `ConnectHeaders`. *probably* would be easy to figure out, but better to just get it right :)
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
nit: we can use `map#compute` to replace getOrDefault + put.
same for the store
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
the `try{...} finally` has been removed
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
We should deprecate this one too I believe.
We can still set `final` -- note, that `final` implies that the parameter `config` cannot be reassigned to a different `Map` -- the `Map` itself is still mutable though and thus it can be altered within `KafkaConsumer` later on. (Adding `final` is more a question of style here.)
The `KeyValue` class allows null values for `key` and `value` (at least I didn't see input validations such as throwing IAE in its constructor when either key or value are null). So we must guard against nulls / NPEs here.
thinking aloud: guess there is nt much value in wrapping a single provider.. so +1
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
thinking aloud: guess there is nt much value in wrapping a single provider.. so +1
nit: braces unneeded
nit: braces unneeded
Yes, I was suggesting separate methods. Something like this: ``` private void resetGeneration() { this.generation = Generation.NO_GENERATION; this.state = MemberState.UNJOINED; this.rejoinNeeded = true; } public synchronized void resetGenerationOnLeaveGroup(String causeMessage) { log.debug("Resetting generation due to consumer pro-actively leaving the group"); resetGeneration(); } protected synchronized void resetGenerationOnResponseError(ApiKeys api, Errors error) { log.debug("Resetting generation after encountering " + error + " from " + api + response); resetGeneration(); } ```
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Also not clear why "numSegments - 1" here.
We can make this a little clearer and save some duplication with a signature like this: ```java protected synchronized void resetGenerationOnError(Errors error, ApiKeys api) ```
req: Actually deleting topics after test is critical for some tests: I've encountered some cases where the same topics are reused mistakenly across different test cases within the single class. But I feel that it is better to put the topic deletion in the `@after` function while leaving `cleanUp()` as part of the test function itself.
Nice tidy up of this test class :-)
Ah! I misread this as turning `logAll` *on* instead of *off*. Now I get it :)
Lines 45 and 46 should use the static constants in this class for the name of the topics: `TOPICS_REGEX_CONFIG ` rather than `SinkTask.TOPICS_REGEX_CONFIG`, and `TOPICS_CONFIG` rather than `SinkTask. TOPICS_CONFIG`.
To make it more rigid: we can pass a valid end point string, and then check that the field is still `null` below.
spelling -> recrord -> record
not sure about the purpose of this test. I don't really like using `assertNotEqual` since there are an infinite number of "not expected" strings that will cause the test to pass.
Admittedly, this is a random time to bring this up, but a pattern that I like for this is: ```java final long seed = providedSeed != null ? providedSeed : new Random().nextLong(); System.out.println("Seed is: " + seed); final Random rand = new Random(seed); ``` where `providedSeed` comes from an env variable, command-line arg, whatever... This way you get the same default behavior (pseudorandomly generated sequence of test values), but you also have the option to deterministically reproduce a previous pseudorandom sequence from a prior run. This can be helpful in diagnosing flaky tests. Not saying this is needed here; I just wanted to share the pattern.
If only Java made it possible to declare immutable local variables and method parameters in a more concise way!
nit: use "{}.x." vs. string concatenation
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
Remove unnecessary `toString()` once the Entry type is set above. Other similar cases below too.
Remove unnecessary `toString()` once the Entry type is set above. Other similar cases below too.
Remove unnecessary `toString()` once the Entry type is set above. Other similar cases below too.
I think we should call `deserializer.close()` here
Add missing `null` check for `materialized`
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: add `final`
Perhaps: `With the COOPERATIVE protocol, owned partitions cannot be reassigned...`
nit: add `final`
Can we just call the overloads with two parameters here? Ditto above.
nit: we can use `map#compute` to replace getOrDefault + put.
@dajac just to clarify, are you concerning that the `generation()` may change between the check and the error-log? If yes maybe we do not need to synchronize the whole function, instead we just get a reference of the returned `generation()` call and use that in the error-log, since the generation object is immutable.
Same for generation and member.id. We could just call `request.data().generationId()`
This is probably just my style bias, but I wonder if it would be easier (and more readable) to use static factories for atomic vs non-atomic ControllerResult. Something like: ```java ControllerResult.newAtomicResult(records, response) // and ControllerResult.newResult(records, response) ``` Boolean flags as such a pain and easy to mess up. I actually think it might be nice if there are no public constructors for ControllerResult and we use factories for everything. However, this would be a bigger change, so I'm fine if we defer it (if we even decide we need it).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
If case of failure, we detect the failure only after `session.timeout.ms` (default 10 seconds) hit -- to speed up the test, we could decrease the session timeout via `StreamsConfig`
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
A bit confusing that a second assignment follows if the `if` statement is true. I'd also call the variable `taskState` (as opposed to `connectorState` above) Ternary can be used here as well: ```suggestion AbstractStatus.State state = request.shouldRestartTask(taskStatus) ? AbstractStatus.State.RESTARTING : taskStatus.state(); ``` (as with any suggestion from github, please check it compiles and conforms to the style)
Minor but I'm not sure if we'd prefer the builder's toString or the underlying request struct's toString as was formerly the case.
There's now a `Utils.mkProperties` method you can use (in conjunction with `mkMap`) to set these at the declaration site instead of setting them (redundantly) before every test. Then you won't need the `@Before` at all.
Is this line intentional? Unit tests normally don't need to print out to console.
We don't usually assert on exception messages as it makes tests a bit brittle. This applies to a few other tests too.
nit: we are not "overriding" them, but duplicate them with the prefixed props right? If the user has already applied the prefix then this function would mostly be a no-op.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
Currently this is reverse order. Probably better to just do `return Integer.compare(k1.orderInGroup, k2.orderInGroup)` here.
prop: change `stateStoreNames` -> `stateStoreName` here.
I might be missing something, but in both cases, you just want to use regular expressions, right? There is no need to mess around with predicate functions.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
nit: add a size? There are a few cases in here where we could do this.
This was probably left by mistake.
nit: add a size? There are a few cases in here where we could do this.
extension name must not be empty
You could just do `values()[version]` after the appropriate bounds check at the start of the method. So that this doesn't have to change as we add versions. One downside is that `values` causes a copy. So we could save a copy as a private field instead (this is sadly a common pattern with enums).
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
```suggestion log.debug("New average number of tasks per worker rounded down (floor) {} and rounded up (ceil) {}", floorTasks, ceilTasks); ```
Hmm.. We have an `UNKNOWN` state in `ConsumerGroupState` in case the group coordinator adds a new state that the client isn't aware of. Currently we're going to pass this through the request, which is a bit odd. Furthermore, if the coordinator _does_ add new states, we will be unable to see them using this API. I think it might be better to use a `null` list of states in the request to indicate that any state is needed.
Nice tidy up of this test class :-)
`needCommit` -> `needsCommit`
I might be missing something, but in both cases, you just want to use regular expressions, right? There is no need to mess around with predicate functions.
as above. `requireNotNull` not necessary any longer
@amethystic I believe Jun is suggesting that it is abnormal for `readFully` (i.e. if you can't fill the buffer, then something is wrong). I think a case can be made for that. I think the downside is that the error messages may not be as good as if the callers do the check themselves. The upside is that we avoid the situation where the caller forgets to check. We'd have to verify that these semantics are right for `FileRecords.readInto` since it doesn't perform any checking atm.
This wording could be improved: "Batch splitting cannot be used with non-compressed messages, NOR with message format versions v0 and v1"
nit: this can be a single line.
Nit: "The file channel position..."
This logic is repeated in a couple of places. I'm wondering if we could change `MaterializedPeek` to take the `InternalSteamsBuilder` as an additional constructor param and have the logic inside the class, and this block of code could be replaced with `new MaterializedPeek<>(materialized, builder).maybeIncrementTopologyCount()` or something like that.
`needCommit` -> `needsCommit`
The message doesn't seem to match the condition above.
same here as what i said below. You can use a `assertThat`
Or we make each test create task instead of creating task in ```setup```
do we really need that we matched it? Can't we do all all of this is a single log statement? We can include size of credentials map and authenticated boolean. This will help keep the old structure.
same here as what i said below. You can use a `assertThat`
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
You might consider using `OptionalDouble`.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
That's a good idea. Note: Kafka does not use this JUnit functionality yet (i.e. no use of ExternalResource, ClassRule, Rule as far as I can tell). @ijuma: Would it ok for us to introduce this? There's no additional dependency etc., it's just using a new JUnit feature that was introduced in 4.7 (we're on 4.12).
Cleaner to just check if `tasks.isEmpty` after the loop is over.
Same here: not only CREATED, but also RESTORING and SUSPENDED tasks should not be included in `consumedOffsetsAndMetadataPerTask` and we should not let the task-manager to peek its state.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
nit: add a size? There are a few cases in here where we could do this.
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
whenever referring to Connect as the framework (as opposed to the verb) I'd use `Connect`. Same as `Kafka cluster` and `Connect framework` a few words after. It's easy to miss that you are referring to the framework if it's not capitalized.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Thanks. I had this on my mind when I was working on the tests for the framework PR. It occurred to me that another approach would be to simply run a dummy query and check the returned position. But I guess that doesn't really count as a "unit" test, since the intervening store layers could in theory be changing the position as well, so that approach might not be testing what it thinks it's testing. This is more direct, and to be honest, I don't think it's that bad in the context of a unit test.
`marker` must be capitalized here per http://boto3.readthedocs.io/en/latest/reference/services/iam.html#IAM.Client.list_policies, so line 140 has to call `get_policy_by_name(module, iam, name, Marker=response['Marker'])`
This should go away. `@ConditionalOnClass` already does that.
It would be more helpful if the name were included, e.g. "Setting 'foo' must be uppercase."
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
I see. Thank you.
As above for this and the next ctor
This is why the test was failing for you. The query is for a range of window start times, not record times. Since the window size is five minutes, the range `[now - 1 minute, now]` wasn't going to contain the actual window start time of `now - 5 minutes`. In other words, just a simple oversight :/ Sorry for the trouble.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
I don't think we need extra `toGiveUpTopicPartitions` to store the partitions to be deleted. We can log the warning message in L1103 here directly
OK, make sense.
I don't think we need extra `toGiveUpTopicPartitions` to store the partitions to be deleted. We can log the warning message in L1103 here directly
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Cool, never mind.
This should go away. `@ConditionalOnClass` already does that.
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Can this be made polymorphic instead of actually checking the `PASSWORD` type here? e.g., could we simply always do `newConfig.put(key, entry.getValue().toString())` since `Password.toString()` always hides the value (in contrast to the `value()` method? I don't see a use atm, but keeping this generalizable seems potentially valuable. wouldn't block on this, but it doesn't seem great to have to bake details of the config type into code in the `AbstractHerder` that otherwise doesn't care about it.
Can this be made polymorphic instead of actually checking the `PASSWORD` type here? e.g., could we simply always do `newConfig.put(key, entry.getValue().toString())` since `Password.toString()` always hides the value (in contrast to the `value()` method? I don't see a use atm, but keeping this generalizable seems potentially valuable. wouldn't block on this, but it doesn't seem great to have to bake details of the config type into code in the `AbstractHerder` that otherwise doesn't care about it.
This should be `synchronized` too as you could have other started threads updating the map at the same time. Perhaps just wrap the map with `Collections.synchronizedMap(...)` and then remove `synchronized` from `StreamStateListener.onChange(..)` Sorry for the back-and-forth.
This should be `synchronized` too as you could have other started threads updating the map at the same time. Perhaps just wrap the map with `Collections.synchronizedMap(...)` and then remove `synchronized` from `StreamStateListener.onChange(..)` Sorry for the back-and-forth.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I'd really like to discourage passing `null`. We can have a `KeyValueMapper` instance that we pass here and also throw an exception in the method that is delegated to if the `KeyValueMapper` is `null`. Same elsewhere
I'd really like to discourage passing `null`. We can have a `KeyValueMapper` instance that we pass here and also throw an exception in the method that is delegated to if the `KeyValueMapper` is `null`. Same elsewhere
Nit: why not use `boolean`
I think that's a bit fragile. I think the plan is more to stop binding the property as a String[] but rather introduce another one that we would map to the command-line property. Existing plugins use a space-delimited feature and I haven't checked how they skip spaces within valuesL
nit: `Arrays.asList` a bit more concise.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
I haven't been able to convince myself that this is correct or completely safe. I'm concerned it's just reducing the time gap to the point that the non-determinism is very hard to trigger. This should only affect the `create`/`subscribe` boundaries, not intermediate operators using `lift`. The issue I see is that it triggers the `countDown` right before `f.call(s)` which is the actual `subscribe` step. We have no idea at that point whether `f.call(s)` is going to be synchronous or async. The async case should not call before `f.call(s)`, but after ... which do were in `OperatorSubscribeOn` like this: ``` java o.subscribe(innerSubscriber); onSubscribeLatch.countDown(); ``` This code however will trigger at the origin of the `Observable` right before `OnSubscribe` is invoked. Interestingly, both locations need to exist to cover the sync and async flows. Despite having written the code my mind is not fully connecting the dots on this ... hence my apprehension with this code.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
ok - same thing three times. Maybe extract it to a method `verifyTransactionInflight`
Can we actually just get rid of "test only" constructors? It couldn't be used by _that_ many different tests...
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
We don't allow a third option [elsewhere](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java#L1288-L1292) in the code, so probably we shouldn't here either.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
It's a sample application so I don't think the performance argument applies here.
It's a sample application so I don't think the performance argument applies here.
It's a sample application so I don't think the performance argument applies here.
I would say it's important _not_ to be able to create bogus requests. ;) We can introduce specific mechanisms for testing, but a public constructor for a request should do its own validation.
can we just return here to make it clear that we are baling out? We then don't need the further `if(!initializable.isEmpty())` checks below
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
I dont remember why I did that. Looks like `future.get` would be better.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
Similarly, better to declare `throws IOException, ReflectiveOperationException`.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
That's correct. The implementation becomes a bit tricky, as we can't just use `Arrays.asList` and be done.
nit: maybe we can separate AbstractTaskCreator and its two impls into separate classes once we are finalizing the refactoring in a follow-up PR (this PR can stay as is to keep it from exploding LOC)
i.e., add `fail` after this line
Use fail_json_aws for AWS exceptions as the messages contain a lot more info
Same for all such calls.
nit: we can use `map#compute` to replace getOrDefault + put.
Mode getstr also returns `contents` in addition to msg.
Let's use `Map` on the left side instead of `HashMap`
nit: add `final`
nit: add `final`
nit: add `final`
nit: add `final`
What do we do if there's an exception? If it's expected, let's make it clear
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
What do we do if there's an exception? If it's expected, let's make it clear
What do we do if there's an exception? If it's expected, let's make it clear
What do we do if there's an exception? If it's expected, let's make it clear
What do we do if there's an exception? If it's expected, let's make it clear
Why is the order of these methods different than in `ConnectorStatusListener`? Also, the `TaskStatusListener` methods always forward the method to the delegate _last_, whereas the methods of the `ConnectorStatusListener` use a mixture. Let's make them consistent.
What do we do if there's an exception? If it's expected, let's make it clear
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
Idem as above with a `ServerRequest`
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
Maybe we could use a different value here.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
What do we do if there's an exception? If it's expected, let's make it clear
Do we _know_ that it will resolve the problem? Maybe better: ``` Changing the location of state.dir may resolve the problem ```
Maybe we could use a different value here.
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
@SinghAsDev Haha, I can understand why this is a little confusing, but the network layer considers the request a "success" if it gets a response. However, that doesn't mean that there wasn't an error code in that response. It might be nice to handle this at the network layer, but it seems to me that there wasn't a generic way to check for errors. Each response object had the error code at a different location in its schema, so the only thing we could do is pass the response back and let the application determine if there was an error. The one case where we might be able to infer errors generically is by checking ClientResponse.wasDisconnected(), but I don't think we do this either (I've forgotten if there's a good reason for that).
"InMemoryKeyValueIterator" -> `getClass().getName()
nit: parameters on a separate line
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
something like `inferredInternalTopics.containsAll(specifiedInternalTopics)` might be easier to understand here
Maybe we could make this assertion precise? I think we expect the request count to be 0.
rewrite test as above using `assertThrows()`.
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
This line is a bit misleading, as it is referring subject and object to the same class. I'd suggest just remove this line.
@granthenke Ahh, great point! I guess that is both nice to enforce and also annoying in this particular case.... Seems like we did some significant reformatting under the initial checkstyle addition as well, which unfortunately messes up git-blame, but I guess it's a one-time cost.
```{@link org.apache.kafka.common.KafkaFuture#get}``` => ```{@link org.apache.kafka.common.KafkaFuture#get()}```
Technically, this is `numDrainedRecords`.
WDYT? ```suggestion log.warn("RetriableException caught on attempt {}, retrying automatically up to {} more times. " + "Reason: {}", attempt, maxAttempts - attempt, e.getMessage()); ```
WDYT? ```suggestion log.warn("RetriableException caught on attempt {}, retrying automatically up to {} more times. " + "Reason: {}", attempt, maxAttempts - attempt, e.getMessage()); ```
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
We also need to update `equals()` to include `topicPattern`
This doesn't seem to be used.
Ack. Was not sure if it's an intentional change. Thanks for clarifying that it's an actual fix.
Maybe we can just a better name for `path` since it makes this code look suspicious.
we can make method this public in `EmbeddedConnectCluster`.
nit: it was correct before
It'd be better to not change these lines, because we don't intend to change the logic -- yet doing so adds risk and increases the size of this PR.
Wouldn't it be much easier to do the following: ``` public Connector createConnector(String listener, String name) { ... String hostname = ... int port = ... ... if (name == null || name.trim().isEmpty()) { name = String.format("%s_%s%d", PROTOCOL_HTTPS, hostname, port); } connector.setName(name); ... ```
```suggestion put(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, "/tmp/foo"); ```
not critical since it's not a ton of logic, but since this logic is repeated, it might be better to turn it into a utility method on `SinkConnectorConfig` and use it both in that class's validate method and here.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
nit: I don't spot any, but safer to avoid typos by just having constants for these
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
`We have specified <code>retries</code> default as Integer.MAX_VALUE, and` -> `The <code>retries</code> setting defaults to <code>Integer.MAX_VALUE</code>, and`
I said it incorrectly before, and I actually meant that you can use `org.apache.kafka.test.NoOpKeyValueMapper` in this case as we do not really care about what aggregate key / value to use. Your proposal is also fine, while I was just trying to reduce duplicated code :)
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
Looks like you can do these 7 lines in a `@Before` method and not repeat it in all of your tests
`info_dict['formats'] = formats`.
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
This doesn't seem to be used.
Kinda, but it had a TreeMap before, so it used the "natural ordering" of the Strings which means... something. Anyway, are we okay with the fact that the ordering may change according to the person who built the docs? The kafka.apache.org webpage will then show whatever order the site-builder's JVM used? Or is it Jenkins? We don't really have any other choice, other than making everyone use LinkedHashSets, right? And we decided we don't want that.
Might be better to use an `Exception` variable `firstException` and rethrow at the end if not `null` -- IIRC, behavior is undefined if we throw a second exception (ie, `finally` would executed after the first (outer) `catch` block.
Ah, I see. Thanks for the explanation
Drop "The .. the .. " -> "Topics consumer is subscribing to" or "Consumer's topic subscription" Same for rest..
do we really need that we matched it? Can't we do all all of this is a single log statement? We can include size of credentials map and authenticated boolean. This will help keep the old structure.
do we really need that we matched it? Can't we do all all of this is a single log statement? We can include size of credentials map and authenticated boolean. This will help keep the old structure.
I don't have a problem with _check_type_bytes simply calling the toplevel string_to_bytes(); no need for this method. (Wish we could do the same with pretty_bytes() but backwards compat... )
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
Maybe we can set this to `false` in the `shouldDisableIdempotence` block? Seems a bit more natural.
We can remove this
sss :snake: ```suggestion password_help_text = form.fields["password"].help_text ```
This one is still not using a tab.
I moved this test to the `tests/messages_tests/tests.py`.
"*" is considered "LITERAL" for compatibility reasons
Since we use this check mutliple times, could you please extract `!streamThread.getName().equals(Thread.currentThread().getName()` to a variable named `callingThreadIsNotCurrentStreamThread` or similar.
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
We'll need a separate AK issue, then.
We'll need a separate AK issue, then.
We typically don't use java serialization. Is Serializable needed? Ditto in a few other classes.
We typically don't use java serialization. Is Serializable needed? Ditto in a few other classes.
The parameters can be `final`.
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Let's use `Map` on the left side instead of `HashMap`
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
This still doesn't seem correct. We're only invoking configuration if the plugin implements `Configurable` afaict. This does not work for `Converter`s implemented against the new API and assuming the "forward" configuration. We *must* always invoke the "old" `configure(Map, boolean)`, and only invoke the `Configurable` version as a backup. Possibly it would make sense to indicate on the `HeaderConverter` that the `Configurable` methods should be idempotent if we need to be able to implement both. Not sure if we can test this easily with unit tests, but I think we might want a plain old `Converter` (that does not implement `HeaderConverter`) in tests to validate compatibility... but it's possible we'd need either integration or system tests to properly validate.
The functionality of process() now is completely covered by transform: users can define a transform function with return type R be "Void" and add a dummy "return null" in the end of the function. And then in KStream we can add public void transform(TransformerSupplier<K, V, Void>) to replace the "process()" call. Having both process() and transform() might be confusing to users, so I would suggest we just remove process() here.
Shouldn't this be in the contract of `Utils.newInstance` to not return some other class that doesn't match? I think this is pulled from `AbstractConfig` which makes sense for consistency, but I don't get why `Utils.newInstance` would ever return a value with an invalid type.
Shouldn't this be in the contract of `Utils.newInstance` to not return some other class that doesn't match? I think this is pulled from `AbstractConfig` which makes sense for consistency, but I don't get why `Utils.newInstance` would ever return a value with an invalid type.
request "got" re-sent to the control
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
I'm not too worried about it. We might try some "extract variable/method" refactoring when we merge.
"with a read-only key"
We should use try-with-resources here (for `DataInputStream`).
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
We should deprecate this one too I believe.
We should deprecate this one too I believe.
same as above for parameters
There is no check on user/password there so perhaps we could rationalize the check altogether? (i.e. remove the first if)
req: I think we want to introduce some `acceptableLag` config within which a task is considered caught-up, otherwise this is way too strict. ie the condition should be `lag <= acceptableLag`
Nit: line too long
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
same for functions below
I think we probably want a `do/while` loop here. There should be no difference in behaviour, but it seems to model the problem better (i.e. we first do a read and then we check if there is still space remaining in the buffer. Maybe: ```java long currentPosition = position; int bytesRead; do { bytesRead = channel.read(destinationBuffer, currentPosition); currentPosition += bytesRead; } while (bytesRead != -1 && destinationBuffer.hasRemaining()); ```
nit: Please fix code style.
nit: remove empty lines
@agavra instead of adding the `CachedConfigs` class could we perform the parsing at instation time in the `JsonConverterConfig` class and store results there, exposing them through getters? For example: ```java public class JsonConverterConfig extends AbstractConfig { private final DecimalFormat decimalFormat; // ... public JsonConverterConfig(Map<String, ?> props) { super(CONFIG, props); this.decimalFormat = DecimalFormat.valueOf(getString(DECIMAL_FORMAT_CONFIG).toUpperCase(Locale.ROOT)); } // ... public DecimalFormat decimalFormat() { return decimalFormat; } } ``` The `CachedConfigs` class adds a bit of cognitive overhead to this part of the code base; if we can avoid adding another utility class to have to track it'd be nice.
nit: line too long
Add a reference to KIP-511 here
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
On second thought, I'm fine with keeping the predicate.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Not sure you need to initialize the factory every time there.
Not sure you need to initialize the factory every time there.
nit: this loop is a little unconventional. Maybe we could use `pollFirstEntry` instead of the iterator? Similarly in `setNumKip500BrokerNodes`.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
nit: -> `shouldThrowForInvalidSocketReceiveBufferSize()`
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
Not sure you need to initialize the factory every time there.
On second though, using `describeConsumerGroups()` may be more predictable in terms on work to do, as you describe only the groups assgined to this task
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
method name changes
Is the transactional part really intended? Is it supported at all? In any case, there's no `@Transactional` on this annotation.
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
Can you re-warp this block to 79 chars? (First line is too short.)
Can you re-warp this block to 79 chars? (First line is too short.)
Can you re-warp this block to 79 chars? (First line is too short.)
Can you re-warp this block to 79 chars? (First line is too short.)
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
That was my other thought. We might wrap one DataException into another but that's not a big deal. In this code `Decimal.toLogical` is now used, and if you follow the refs, there's a `new BigInteger(value)` in there that might throw `NumberFormatException`. Improbable, but thought we could be on the safe side with the more general catch block.
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
It looks like we always run with effectively infinite timeout since we rely on the timeout for individual connectors/tasks. We can probably just remove the timeout values and in `bulkRun` use the `invokeAll` variant that doesn't have a timeout.
It looks like we always run with effectively infinite timeout since we rely on the timeout for individual connectors/tasks. We can probably just remove the timeout values and in `bulkRun` use the `invokeAll` variant that doesn't have a timeout.
It looks like we always run with effectively infinite timeout since we rely on the timeout for individual connectors/tasks. We can probably just remove the timeout values and in `bulkRun` use the `invokeAll` variant that doesn't have a timeout.
Thanks! Will push this shortly.
It looks like we always run with effectively infinite timeout since we rely on the timeout for individual connectors/tasks. We can probably just remove the timeout values and in `bulkRun` use the `invokeAll` variant that doesn't have a timeout.
So the net effect of UnsafeFunc0 is that it forces us to catch the declared Exception on resourceFactory.call() and think about what might happen. I'm not sure it's worth it.
Thanks! Will push this shortly.
Like I wrote earlier, this should just be a map, so duplicates should not be a problem. I think it would be good to do all the validation here. There's no reason not to do it and it makes things more robust if the code is re-arranged in the future.
Thanks! Will push this shortly.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Nit: you can call `Thread.enumerate` directly. Also, it would be good to assert that `threadCount` is < than `threads.length`.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
I think we should call `deserializer.close()` here
```suggestion processed = new AtomicBoolean(true); ```
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
Also set the store name in this test.
Fair enough. If we think it's the right thing to do, then making the change in `Utils` seems like a good idea to me.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
...if sending old values
It's sent by the (admin) client to the leader for the topics partitions included in the request
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
This change appears to be unrelated.
I think we should call `deserializer.configure(...)` here
I think we should call `deserializer.configure(...)` here
I think we should call `deserializer.configure(...)` here
I think we should call `deserializer.configure(...)` here
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
I think we should call `deserializer.configure(...)` here
The producer in the `WorkerSourceTask` automatically resends records, but if the producer fails to resend the [WorkerSourceTask enqueues the unsent records in `toSend`](https://github.com/apache/kafka/blob/08e8facdc9fce3a9195f5f646b49f55ffa043c73/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java#L343-L348) and send them again. It is true that this happens after each call to `poll()`, but if the send fails then `toSend` is non-null and upon the next iteration of the loop it will not call `poll()` and will then try resending whatever is in `toSend`. This will continue to happen as long as `toSend` is not null. However, in the current PR, even though this might happen, the loop may still ask for the source partitions and offsets and will synchronously commit them using the `offsetWriter`. So it is possible that a record with a particular offset `o1`, for a source partition `p1` fails to send and is retried, but then a connector then sets a later offset `o2` for the same partition and the connector commits offset `o2`. If the connector were to fail at exactly that point (which is possible), the `o2` offset may have been committed without the `o1` record being written. I understand that in your particular use case, you probably would only set the offsets for a particular partition if records were not written recently, but that doesn't change the fact that the `WorkerSourceTask` might be attempting to resend the previous records for quite some time. What if your new block of code were only performed if `sendRecords()` succeeded? I think there are a couple of issues with that as well. First, the offset writer is called synchronously, whereas other calls to commit offsets are sent a separate commit thread that calls multiple tasks. Now there are multiple threads committing offsets with potential race conditions and concurrency issues. Second, it still is a complicated API, and will developers truly understand when and how they use `getSourcePartitionAndOffset()`? Can I call it to read the last offset committed for a particular source partition? The worker doesn't ever set the offsets there. The WorkerSourceTask has a single, ordered pipeline for all records that each have their offsets. I still believe the best and most reliable and deterministic way to solve this is to use that same pipeline.
It might still be nice to see the stacktrace here (even if it also gets logged elsewhere). If you want to do it, don't forget you have to change to using `String.format` for the variable substitution. I don't feel strongly in this case, so I'll defer to you whether you want to do this or not.
It might still be nice to see the stacktrace here (even if it also gets logged elsewhere). If you want to do it, don't forget you have to change to using `String.format` for the variable substitution. I don't feel strongly in this case, so I'll defer to you whether you want to do this or not.
We seem to have lost the `info` message from the original.
Perhaps something like "Represents a pattern that is used by ACLs to match zero or more Resources"
I think we should probably move this log statement since this method doesn't actually reset offsets.
The advantage of using `ConfigDef.validator` on the `response.http.headers.config` config key is that this constructor call would throw an exception if any invalid value is used, and much sooner, too.
The advantage of using `ConfigDef.validator` on the `response.http.headers.config` config key is that this constructor call would throw an exception if any invalid value is used, and much sooner, too.
The advantage of using `ConfigDef.validator` on the `response.http.headers.config` config key is that this constructor call would throw an exception if any invalid value is used, and much sooner, too.
Yeah this is observed in another PR review, and should be fixed by now. cc @dguy
Yeah this is observed in another PR review, and should be fixed by now. cc @dguy
Yeah this is observed in another PR review, and should be fixed by now. cc @dguy
I think we're testing `testDir` Occupied here, not `AppDir`.
I think we're testing `testDir` Occupied here, not `AppDir`.
I think we're testing `testDir` Occupied here, not `AppDir`.
This could be final.
nit: add `final`
nit: add `final`
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
nit: remove blank line
Okay, thanks! I have limited time at the moment. I'll try to look at it this week.
Can we use `assertThat(node.name, equalTo("source1")` or `assertEquals("source1", node.name)` instead of `assertTrue` for assertions like this? Elsewhere in this test, too
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Can we use `assertThat(node.name, equalTo("source1")` or `assertEquals("source1", node.name)` instead of `assertTrue` for assertions like this? Elsewhere in this test, too
Can we use `assertThat(node.name, equalTo("source1")` or `assertEquals("source1", node.name)` instead of `assertTrue` for assertions like this? Elsewhere in this test, too
Nit: remove unnecessary `this`.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Maybe call RxJavaPlugins.onError() or however that api is called in 1.x? I believe people won't like stacktrace popping up in their logs without ability to swallow it
mhm, I see, ok
nit: Starting a message with lower case feels a little unusual.
@jeffchao traditionally Kafka used key,value pairs in properties and pass it everywhere and each implementation takes look at this config and pulls their interested key,value pairs. Example, authorizer interface https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/security/auth/Authorizer.scala#L35 . The pluggable class when it gets instantiated a configure method will be called and all the key,value in server.properties will be passed and it will pick whats relevant to the class. We can do the same here instead of asking users append key,values into the a config which is hard to configure and hard to get it right.
Maybe this looks better? ```suggestion // we're at the end of the input. if (queryResult.getResult().value() == batch1NumMessages - 1) return; ```
Suggestion on above function addConfiguredSecurityProviders: 1. I think using following format for security.providers: security.providers=provider1_classname,provider2_generator_classname key1:val1 key2:val2,... 2. So when parsing above config, if there is no parameters following provider1_classname, then we can think provider1_classname is java Provider, then insert it; if there are key:value pair parameters following provider2_generator_classname, we can think provider2_generator_classname is SecurityProviderGenerator, then create "Map<String, ?> config" from key:value pair parameters, then call configure and getProvider of instance of SecurityProviderGenerator. This way we can handle all different scenarios in the future.
I wonder if this message and the one in `doCommitSync` is overkill. Maybe we could change the first log message in `doCommit` to include whether it is async or sync. For example? ```java boolean syncCommit = closing; log.info("{} Committing {} offsets: {}", this, isSyncCommit? "sync" : "async", offsets); ```
SGTM. If we find it flooding the logs and not helpful we can reconsider
You need to close the `Connection`.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
I think we should also log the error in `failed && isRetriable()` case
mhm, I see, ok
I think we should also log the error in `failed && isRetriable()` case
Probably not the best choice of error type, `InternalError` indicates JVM error, combined with "Null check on a primitive" message might mislead the developer into thinking that something is wrong with bytecode/VM hehe
Using the enum as suggested: ```suggestion def insert_statement(self, on_conflict=None): if on_conflict == OnConflict.IGNORE: return 'INSERT IGNORE INTO' return super().insert_statement(on_conflict) ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
ditto on removing before/after.
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
This is also an existing issue. We set the ISR here, but it can be overridden to targetIsr in tobuild() later.
Should be final
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
You're right. I prepared separate PR #7787.
Ack. Overlooked this change :)
nit: 'else' can be dropped
Nit: please use single parameter per line formatting
"implements ProcessorSupplier<K, V>" with the generic types.
Groups in particular may not make sense in some cases. Some connectors have only a handful of options so grouping them isn't particularly useful.
Groups in particular may not make sense in some cases. Some connectors have only a handful of options so grouping them isn't particularly useful.
`setNeedsCommit` -> `{@link #setNeedsCommit}`
nit `getMetadata` -> get`
You need to close the `Connection`.
`setNeedsCommit` -> `{@link #setNeedsCommit}`
`setNeedsCommit` -> `{@link #setNeedsCommit}`
I find having a method specific for SSL strange. Callers should not have to know, this should be retrieved automatically based on the cluster being targeted
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
What do we do if there's an exception? If it's expected, let's make it clear
Suggestion on above function addConfiguredSecurityProviders: 1. I think using following format for security.providers: security.providers=provider1_classname,provider2_generator_classname key1:val1 key2:val2,... 2. So when parsing above config, if there is no parameters following provider1_classname, then we can think provider1_classname is java Provider, then insert it; if there are key:value pair parameters following provider2_generator_classname, we can think provider2_generator_classname is SecurityProviderGenerator, then create "Map<String, ?> config" from key:value pair parameters, then call configure and getProvider of instance of SecurityProviderGenerator. This way we can handle all different scenarios in the future.
What's the purpose of this warning? It doesn't seem needed.
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
nit: remove `which is`
nit: maybe iterate over `entrySet()` instead.
The "Swallowing the exception" is a bit alarming at first. It's true that if this method returns false then `TestUtils.waitForCondition` (which is using this method as the test condition) will fail at line 137. Pretty minor, but how about the following? ``` // Log the exception and return that the partitions were not assigned log.error("Could not check connector state info.", e); return false; ```
"the event will be prepended to the queue" : This is no longer true in the implementation.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
`localIdOrSentinel` would be more accurate, I think.
`downstream` is a bit confusing: Found the child node of the key changer {} from the repartition {}.
This loop only needs to happen once, so it seems like you can move it outsize the enclosing loop.
Since we have three threads for this test, there can be multiple rebalances before the streams instance stabilize and start processing...
base -> based progress -> progressed
Remove double blank.
nit. I think there is `.` missing `since 3.0[.] Use`
maybe rename this to `setUp` and put the loop populating the array in this method
maybe rename this to `setUp` and put the loop populating the array in this method
Since we have three threads for this test, there can be multiple rebalances before the streams instance stabilize and start processing...
We don't need to delay the error ... just emit it and skip everything else. We confirmed this behavior in `observeOn`: https://github.com/ReactiveX/RxJava/issues/1680
the entry will be something like ``` { "neo4j" : { "neo4j" : 8 } } ``` IMHO, the name should be `nodes` for this proprosal.
The "Swallowing the exception" is a bit alarming at first. It's true that if this method returns false then `TestUtils.waitForCondition` (which is using this method as the test condition) will fail at line 137. Pretty minor, but how about the following? ``` // Log the exception and return that the partitions were not assigned log.error("Could not check connector state info.", e); return false; ```
The "Swallowing the exception" is a bit alarming at first. It's true that if this method returns false then `TestUtils.waitForCondition` (which is using this method as the test condition) will fail at line 137. Pretty minor, but how about the following? ``` // Log the exception and return that the partitions were not assigned log.error("Could not check connector state info.", e); return false; ```
The "Swallowing the exception" is a bit alarming at first. It's true that if this method returns false then `TestUtils.waitForCondition` (which is using this method as the test condition) will fail at line 137. Pretty minor, but how about the following? ``` // Log the exception and return that the partitions were not assigned log.error("Could not check connector state info.", e); return false; ```
The map is not used.
Is this key for the purpose of renaming an existing block? Usually how this works is some key is global (maybe name) and then if other parameters are changed (like description) the module will detect that the resource description is out of date and change it, so users don't have to manually tell the module what fields to update.
We are slightly changing the behavior here: if the metric does not exist, previously it is just an no-op, while now we will create the metric first then deletes it.
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
With regard to naming: we should also check that the store in only queryable is a name is specified via `Materialized`.
Suggestion on above function addConfiguredSecurityProviders: 1. I think using following format for security.providers: security.providers=provider1_classname,provider2_generator_classname key1:val1 key2:val2,... 2. So when parsing above config, if there is no parameters following provider1_classname, then we can think provider1_classname is java Provider, then insert it; if there are key:value pair parameters following provider2_generator_classname, we can think provider2_generator_classname is SecurityProviderGenerator, then create "Map<String, ?> config" from key:value pair parameters, then call configure and getProvider of instance of SecurityProviderGenerator. This way we can handle all different scenarios in the future.
nit: how about just put these two in one line? We usually only use multi-lines if there are 3+ parameters.
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
Do we want a `ConnectException` here instead? Not sure.
Do we want a `ConnectException` here instead? Not sure.
Doesn't matter much, but I don't think it's common practice to include a trailing comma on single line tuples of length > 1.
OK, will remove before merging.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
same as above for parameters
same as above for parameters
You could do `Assert.fail(...)` here rather than tracking it in a boolean etc
You could do `Assert.fail(...)` here rather than tracking it in a boolean etc
We have multiple null check for `childrenProducerBatch` which is not necessary, instead we could just reject here if the given `childrenProducerBatch` is null to ensure it's non-null.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
Maybe we can just a better name for `path` since it makes this code look suspicious.
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
Hmm, if there is any exception from here, we probably want to bubble it up to the caller. For example, in SocketServer.processNewResponses(), if send() hits any exception, we want to call updateRequestMetrics(() and avoid updating inflightResponses, and move on to the next response in the queue in the same loop.
Looks like there are some checkstyle violations in the commit. It's probably choking on not having a space between the `catch` and open parenthesis. ```suggestion } catch (ConnectRestException e) { ```
Since all stores will be at least wrapped with `MeteredXXStore` we can add the error handling only at the metered store layer to be consistent. Besides, the inner `RocksDBSessionStore` would actually be `<Bytes, byte[]>` typed always, so this would not help. Same for the RocksDBWindowStorebelow.
Hmm, if there is any exception from here, we probably want to bubble it up to the caller. For example, in SocketServer.processNewResponses(), if send() hits any exception, we want to call updateRequestMetrics(() and avoid updating inflightResponses, and move on to the next response in the queue in the same loop.
Hmm, if there is any exception from here, we probably want to bubble it up to the caller. For example, in SocketServer.processNewResponses(), if send() hits any exception, we want to call updateRequestMetrics(() and avoid updating inflightResponses, and move on to the next response in the queue in the same loop.
nit: let's keep calling this `savedLoader` as in the other places where we call this method because: a) naming consistency might pay off here more than elsewhere, b) calling it old might be misleading because you are keeping the reference because you want to restore it somewhere (rather than replace it as "old" would imply)
Looks like there are some checkstyle violations in the commit. It's probably choking on not having a space between the `catch` and open parenthesis. ```suggestion } catch (ConnectRestException e) { ```
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
nit: it is naming a source node, not a processor node. -> `"source"`
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Hmm, if there is any exception from here, we probably want to bubble it up to the caller. For example, in SocketServer.processNewResponses(), if send() hits any exception, we want to call updateRequestMetrics(() and avoid updating inflightResponses, and move on to the next response in the queue in the same loop.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Nit: fix line break
this will never be called if one of the assertions fails
Nit: fix line break
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
It would be more helpful if the name were included, e.g. "Setting 'foo' must be uppercase."
It would be more helpful if the name were included, e.g. "Setting 'foo' must be uppercase."
It would be more helpful if the name were included, e.g. "Setting 'foo' must be uppercase."
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I think this is OK without the "by".
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
I believe a null-pointer check is necessary here.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
I believe a null-pointer check is necessary here.
I feel INFO level is fine as in many cases people will keep alerting on warn / error logs.
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Yeah, we're still feeling out the best patterns for handling older versions.
This always scheduled in the future with `timeout`. Shouldn't it be the time until next timeout? Let's say timeout is 1000ms and I get an onNext call every 50ms. This code seems to schedule each action to execute 1000ms in the future even if it comes in 950ms since the last onNext was permitted through.
nit: 'else' can be dropped
typo: CompleteableFuture -> CompletableFuture
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
I think we should call `deserializer.close()` here
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
I think we should call `deserializer.close()` here
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
I think we should call `deserializer.close()` here
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
Also not clear why "numSegments - 1" here.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
Not something we have to do here, but one way we could improve this in the future is by taking into account leader epoch information from individual partitions. We can ensure that epochs increase monotonically in order to prevent using stale information during retry. Another thing we could do is reduce the topics we are fetching metadata for as the ListOffsets requests complete. Ideally we'd only be refetching metadata for topics with metadata errors.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Hopefully, there's no danger of these counters overflowing, but regardless, I think the math would still work out if we did reset them here.
By catching Throwable, aren't we silencing the error and not immediately failing the test? Also we should not be catching Throwable, if the JVM throws an Error we want it to fail the test and never want to handle it. There're a bunch of them in these files
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
You can completely drop this conditional, since iterating over empty iterable produces the same effect.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Seems you can replace this with this: ``` java topicPartitions.addAll(partitionsForTask.get(id)); ``` Same below.
SGTM. If we find it flooding the logs and not helpful we can reconsider
Nit: somehow I don't like `blah`. Otherwise LGTM
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
Seems you can replace this with this: ``` java topicPartitions.addAll(partitionsForTask.get(id)); ``` Same below.
You can completely drop this conditional, since iterating over empty iterable produces the same effect.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Add the `@Overrride` annotation to this method.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
`Constructor<List<T>>` (or `Constructor<L>` if we introduce `L`)
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
`Constructor<List<T>>` (or `Constructor<L>` if we introduce `L`)
For anything below `internal.*` I don't think annotations are necessary.
This is the wrong format for this log message. The exception won't be logged. You have to format the string first: ```suggestion log.debug( String.format("Timeout exception. Remaining time to deadline %d; retrying.", deadlineMs - currentWallClockMs), timeoutException ); ```
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
Thinking about it, this may be the root of the problem. We are removing from the head of the ArrayList, one at a time. For each removal, we cause all the elements to be shifted in the underlying array, which is very inefficient if n is not small.
nit: add a size? There are a few cases in here where we could do this.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
It can sometimes be hard to get the logs for failing tests, so it might be nice to get the failure reason in the actual test output. Check out `Matchers`: there should be a way to compose the checks you're doing here manually. It'll be something like: ``` assertThat( message, is( oneOf( containsString("Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING"), containsString("The state store, source-table, may have migrated to another instance") ) ) ```
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
nit: some extra newlines here.
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
nit: typo `snapshoId`
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
i think this would be better off as a test rather than in `setUp`
I think we should call `deserializer.close()` here
nit: add a size? There are a few cases in here where we could do this.
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
spelling -> recrord -> record
I would say it's important _not_ to be able to create bogus requests. ;) We can introduce specific mechanisms for testing, but a public constructor for a request should do its own validation.
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
nit: add `final`
nit: add `final`
i.e., add `fail` after this line
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
We should update the Scala `TestUtils` to call this method.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
The purpose of this change was to highlight that the data structure is required to be concurrent. Of course if a method that existed in `ConcurrentMap` and not in `Map` was used, that would be a hard requirement. `putIfAbsent` used to be such a method but that's not the case after 1.8. In any case, the use of the more accurate interface is valid even if we don't explicitly use methods that don't exist in the parent. That's because the need for this implementation to be thread safe is a requirement here.
req: drop the `!caughtUpClients.isEmpty()` check here, if it's in the map it should have at least 1 caught-up client
req: I think we want to introduce some `acceptableLag` config within which a task is considered caught-up, otherwise this is way too strict. ie the condition should be `lag <= acceptableLag`
req: drop the `!caughtUpClients.isEmpty()` check here, if it's in the map it should have at least 1 caught-up client
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
Is this a valid restriction for the broker? Would there be cases where multiple mechanisms may be required? In the original Kafka Security proposal, there was mention of one port supporting multiple SASL mechanisms. I don't know how common that is though. Probably not for this release, but it may be worth thinking about how we would do that in a compatible manner if we decide to do it.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Can remove if initialize above
Is this a valid restriction for the broker? Would there be cases where multiple mechanisms may be required? In the original Kafka Security proposal, there was mention of one port supporting multiple SASL mechanisms. I don't know how common that is though. Probably not for this release, but it may be worth thinking about how we would do that in a compatible manner if we decide to do it.
typo: byteArrray -> byteArray
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
No need to check null. We always have to forward oldAgg and newAgg, anyway.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think we're testing `testDir` Occupied here, not `AppDir`.
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
nit: add `final
with 10 messages and a commit marker at 5, we need a second commit marker at 11: `0...4,C,6,...11,C` thus, endOffset should be 12. Having say this, I think a simpler setup `0...,9,C` and endOffset `11` would be sufficient for this test case.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
We should deprecate this one too I believe.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
We should deprecate this one too I believe.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Add a reference to KIP-511 here
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
nit: braces unneeded
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
That makes sense. But what I don't know is, why we only consider `partitions` in the first place...
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
`instantiateConfigProviders` since this is potentially creating multiple providers
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Nit: add `Cannot be {@code null}.` (maybe somewhere else, too)
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
So the net effect of UnsafeFunc0 is that it forces us to catch the declared Exception on resourceFactory.call() and think about what might happen. I'm not sure it's worth it.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
So the net effect of UnsafeFunc0 is that it forces us to catch the declared Exception on resourceFactory.call() and think about what might happen. I'm not sure it's worth it.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
getter and setter should be removed
This should call `configState.rawConnectorConfig(connector)`, which returns the _user-supplied_ configuration _with variables not resolved_. The `connectorConfig(connector)` call returns the configuration _with variables already replaced_, which means we might be leaking passwords and other secrets specified using variables.
If this test passes then this assertion isn't quite right as `TomcatContextCustomizerConfiguration` doesn't define a `TomcatContextCustomizer`. The assertions needs to be written such that if you remove `.withUserConfiguration(TomcatContextCustomizerConfiguration.class)` the test will fail.
You actually do not need `this` here, right? The values are the default initialization values in Java. And `super` is also called in the default constructor. So actually, you could remove this constructor completely.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
> At the moment, I am leaning toward the latter. In any case, I suggest we let the errors propagate for now and file a jira to reconsider once we are closer to integration. Does that sound fair? Sounds fair to create a Jira and revisit this later.
> At the moment, I am leaning toward the latter. In any case, I suggest we let the errors propagate for now and file a jira to reconsider once we are closer to integration. Does that sound fair? Sounds fair to create a Jira and revisit this later.
Not sure you need to initialize the factory every time there.
Not sure you need to initialize the factory every time there.
I think we are guaranteed to have the listener present, but perhaps it's worth checking explicitly and throwing if it is not the case.
I think we are guaranteed to have the listener present, but perhaps it's worth checking explicitly and throwing if it is not the case.
The protocol behavior is that `null` is valid while we use a default empty string so that it's never seen by users. The generated protocol classes definitely change behavior here as it caused a previously passing test to fail with a NPE. I'll share the details with you offline.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
For this case, the input `KStream` key was not changed, and thus no repartition topic should be created. We should only get a single sub-topology.
For this case, the input `KStream` key was not changed, and thus no repartition topic should be created. We should only get a single sub-topology.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Nit: var should be named `deserializeValue`
Nit: var should be named `deserializeValue`
cosmetic: extra space at the start
For this case, the input `KStream` key was not changed, and thus no repartition topic should be created. We should only get a single sub-topology.
Nit: var should be named `deserializeValue`
Nit: var should be named `deserializeValue`
Why call it `now` and not `then` (or `previous`); `time.milliseconds()` give the current timestmap, ie, "now"
We don't need any of the 3 lines above right? We do it all inside the finally.
nit: remove the redundant line. Same as below.
Shouldn't this be a config exception? It is not really invalid partitions.
Shouldn't this be a config exception? It is not really invalid partitions.
Shouldn't this be a config exception? It is not really invalid partitions.
max timeDifferenceMs later than -> at most ...
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
nit: break line
Personally I would prefer not special handling this case with the different schedule time, as this could change the commit interval unexpectedly for users; instead we can just move forward with the regular commit interval, and if the next commit fails again it may be fine still.
nit: remove the redundant line. Same as below.
nit: new line
nit: remove the redundant line. Same as below.
Schema? It's Field class...
Schema? It's Field class...
Schema? It's Field class...
Schema? It's Field class...
Schema? It's Field class...
nit: remove empty line
This may be overkill but classes and resources predicates are being applied to both use cases with no way for an implementation to know what type of "resource" needs to be filtered.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
You basically specified the `differentName` check twice, in this and in the previous method. I would specify the following tests into separate methods: - same - different names - different topics - different patterns Makes the test better readable and avoids repetitions of checks.
You basically specified the `differentName` check twice, in this and in the previous method. I would specify the following tests into separate methods: - same - different names - different topics - different patterns Makes the test better readable and avoids repetitions of checks.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
base -> based progress -> progressed
base -> based progress -> progressed
The two cases are differ that one throwing KafkaException (fatal) and the other throwing ProducerFencedException (task-migrated).
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
nit: style seems to be to not include braces when there is only one if or else statement
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Again minor, but maybe IllegalArgumentException
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
There are a couple of checkstyle failures in these two lines because of missing spaces
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
Interesting. In that case it doesn't seem to important in the short term, it's only relevant once the exceptions become user facing.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
The reason I ask is that I was expecting this would be implemented with a `ConfigDef` validator, but I didn't see one defined.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Use URL instead of Url. ```suggestion - The URL of the Gitlab server, with protocol (i.e. http or https). ```
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
I think we ditch the before/after methods as I previously recommended.
Can this be a `byte`.
Can this be a `byte`.
I think we ditch the before/after methods as I previously recommended.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
By catching Throwable, aren't we silencing the error and not immediately failing the test? Also we should not be catching Throwable, if the JVM throws an Error we want it to fail the test and never want to handle it. There're a bunch of them in these files
nit: We could use `singletonMap` here.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
nit: add a size? There are a few cases in here where we could do this.
We usually avoid writing to standard out in test cases. A few more of these.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
Hmm, why did we do this? I thought we'd have a try/catch block.
Hmm, why did we do this? I thought we'd have a try/catch block.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
The better API is to take a list for other_args and a dict for kwargs so that we never have conflicts between the two but I see why you went the **kwargs route (since other_args was already using the unpakcing idiom). This is an internal function so we have the freedom to change the function's signature At first glance there's a bunch of options: ``` python def _build_command(self, binary, command, *other_args): [...] def _build_command(self, binary, command, other_args=None): if other_args is None: other_args = [] def _build_command(self, binary, command='ssh', other_args=None): if other_args is None: other_args = [] ``` Looking at what the code does, though, I think this would be even better: ``` python def _build_command(self, command, other_args=None): if other_args is None: other_args = [] if command == 'ssh': binary = self.play_context.ssh_executable else: binary = self.get_option('{0}_executable'.format(command)) ``` Here's my thinking: * If we're limiting the possible commands to the set of ssh, scp, and sftp, then the correct command is really the primary piece of information that this function needs. Therefore, command should both be mandatory and the first argument. * Since command is limited to a few specific values, we can choose the proper value of binary based on the value of command. Therefore we don't need to pass in binary; we can set it inside of this function. My glance at all the callers of _build_command(), this looks like it's the correct way to default binary for all three of the possible commands but you'll probably want to hceck my eyesight ;-) * We need to change the signature of the function and then update the callers so we might as well correct all the deficiencies in the function's signature. (Hence, changing other_args into a kwarg taking a list of arguments). Hope that makes sense.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
That is a good point. I think adding a boolean flag in addition to the `future` result indicating if it may be incomplete is better than exposing the node map. I.e. we could have two fields inside `ListConsumerGroupsResult`, a `boolean` and a `KafkaFuture<Collection<ConsumerGroupListing>>` (I think we do not need to have nested KafkaFutures so I did not have that inside `Collection`, but correct me if I overlook anything).
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Could we combine the finally block with L45-46? Also I was thinking whether we should close the producer thread as well.
Good point! @vpapavas , can you handle stuff like this in a follow-on PR? I'm doing a final pass to try and get this one merged.
OK, will remove before merging.
yeah, the existing `IllegalStateException` is confusing and we should fix it.
yeah, the existing `IllegalStateException` is confusing and we should fix it.
nit: all the other collections are initialized in the constructor.
How do you feel about dropping `Number` from these names? This would be consistent with the methods we expose from `TransactionManager` itself (e.g. `lastAckedSequence()`).
This isn't since 0.17
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
maybe also add a `lastAssignedTask(List<TaskId>)` helper to clean up `source.get(source.size() - 1)` used here and below
Ditto on the properties and the driver.
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
We'll need to fix this in a follow-up so that followers send the right replicaId.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
base -> based progress -> progressed
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
The test is fine -- but what's the value in testing overwrite the default extractor two times.
typo: byteArrray -> byteArray
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
This test fails on the mac on this line as the path is not `/tmp` but starts with `/var/folders...` by changing the assertion to `startsWith("process-state-manager-test Failed to write offset checkpoint file to [` then the test passes
I don't think this is necessary. The overriden method does this: ```java public URI getURI() { try { return getURL().toURI(); } catch(Exception e) { throw new RuntimeException(e); } } ```
`Indicate[s] that Kafka Streams is in state {@link org.apache.kafka.streams.KafkaStreams.State#CREATED CREATED} and thus state stores cannot be queries yet.`
nit: add `final`
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
Maybe there is an easier way, but I found the following: Set the config to: ``` final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.singletonMap("test", "property")); ``` and then check it: ``` internalTopologyBuilder.buildSubtopology(0); assertThat(internalTopologyBuilder.stateStores().get("store-this-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.stateStores().get("store-other-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); for (final InternalTopicConfig config : internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.values()) { assertThat( config.getProperties(Collections.emptyMap(), 0).get("test"), equalTo("property") ); } ``` Without ``` assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); ``` the test would pass without checking the config if `buildSubtopology()` is not called because no changelog topics would be registered in the topology. So it basically checks that `buildSubtopology()` is called.
ditto here and others below
Maybe there is an easier way, but I found the following: Set the config to: ``` final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.singletonMap("test", "property")); ``` and then check it: ``` internalTopologyBuilder.buildSubtopology(0); assertThat(internalTopologyBuilder.stateStores().get("store-this-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.stateStores().get("store-other-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); for (final InternalTopicConfig config : internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.values()) { assertThat( config.getProperties(Collections.emptyMap(), 0).get("test"), equalTo("property") ); } ``` Without ``` assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); ``` the test would pass without checking the config if `buildSubtopology()` is not called because no changelog topics would be registered in the topology. So it basically checks that `buildSubtopology()` is called.
You need to close the `Connection`.
You need to close the `Connection`.
maybe also add a `lastAssignedTask(List<TaskId>)` helper to clean up `source.get(source.size() - 1)` used here and below
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
The `KeyValue` class allows null values for `key` and `value` (at least I didn't see input validations such as throwing IAE in its constructor when either key or value are null). So we must guard against nulls / NPEs here.
```suggestion Utils.closeQuietly(retryWithToleranceOperator, "retry operator"); ```
```suggestion Utils.closeQuietly(retryWithToleranceOperator, "retry operator"); ```
@guozhangwang Yes, keeping the reference is fine. I was concerned by the check itself because we were calling `generation()` twice in the previous implementation thus we could get two different instances. ``` generation() != Generation.NO_GENERATION && !protocolName.equals(generation().protocolName) ``` I haven't thought about the error-log but it is also a good point.
The `KeyValue` class allows null values for `key` and `value` (at least I didn't see input validations such as throwing IAE in its constructor when either key or value are null). So we must guard against nulls / NPEs here.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
I think it's better to test a "normal" function instead of `lambda`, e.g. ```python with self.assertRaisesMessage(TypeError, msg). @sensitive_variables def test_func(self, password): pass ```
I think it's better to test a "normal" function instead of `lambda`, e.g. ```python with self.assertRaisesMessage(TypeError, msg). @sensitive_variables def test_func(self, password): pass ```
Is the intention to allow termination to happen from other threads even if still running a test? i.e. do we want this test to pass as well? ```scala @Test def exitWithoutSettingUpHooks(): Unit = { val t = new Thread { override def run { try { Exit.exit(1, None) } catch { case e: RuntimeException => assertEquals("Attempted to terminate the VM in a junit test.", e.getMessage) } } } t.start() t.join() } ``` It's also maybe slightly nicer to not have to check the stack frames ```suggestion private static final boolean IN_JUNIT_TEST = Stream.of( "org.junit.platform.commons.util.ReflectionUtils", "org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor" ).anyMatch(clazz -> { try { Class.forName(clazz); return true; } catch (ClassNotFoundException ignored) { return false; } }); static void throwIfInJunitTest() { if (IN_JUNIT_TEST) { throw new RuntimeException("Attempted to terminate the VM in a junit test."); } } ```
Is the intention to allow termination to happen from other threads even if still running a test? i.e. do we want this test to pass as well? ```scala @Test def exitWithoutSettingUpHooks(): Unit = { val t = new Thread { override def run { try { Exit.exit(1, None) } catch { case e: RuntimeException => assertEquals("Attempted to terminate the VM in a junit test.", e.getMessage) } } } t.start() t.join() } ``` It's also maybe slightly nicer to not have to check the stack frames ```suggestion private static final boolean IN_JUNIT_TEST = Stream.of( "org.junit.platform.commons.util.ReflectionUtils", "org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor" ).anyMatch(clazz -> { try { Class.forName(clazz); return true; } catch (ClassNotFoundException ignored) { return false; } }); static void throwIfInJunitTest() { if (IN_JUNIT_TEST) { throw new RuntimeException("Attempted to terminate the VM in a junit test."); } } ```
Is the intention to allow termination to happen from other threads even if still running a test? i.e. do we want this test to pass as well? ```scala @Test def exitWithoutSettingUpHooks(): Unit = { val t = new Thread { override def run { try { Exit.exit(1, None) } catch { case e: RuntimeException => assertEquals("Attempted to terminate the VM in a junit test.", e.getMessage) } } } t.start() t.join() } ``` It's also maybe slightly nicer to not have to check the stack frames ```suggestion private static final boolean IN_JUNIT_TEST = Stream.of( "org.junit.platform.commons.util.ReflectionUtils", "org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor" ).anyMatch(clazz -> { try { Class.forName(clazz); return true; } catch (ClassNotFoundException ignored) { return false; } }); static void throwIfInJunitTest() { if (IN_JUNIT_TEST) { throw new RuntimeException("Attempted to terminate the VM in a junit test."); } } ```
Is the intention to allow termination to happen from other threads even if still running a test? i.e. do we want this test to pass as well? ```scala @Test def exitWithoutSettingUpHooks(): Unit = { val t = new Thread { override def run { try { Exit.exit(1, None) } catch { case e: RuntimeException => assertEquals("Attempted to terminate the VM in a junit test.", e.getMessage) } } } t.start() t.join() } ``` It's also maybe slightly nicer to not have to check the stack frames ```suggestion private static final boolean IN_JUNIT_TEST = Stream.of( "org.junit.platform.commons.util.ReflectionUtils", "org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor" ).anyMatch(clazz -> { try { Class.forName(clazz); return true; } catch (ClassNotFoundException ignored) { return false; } }); static void throwIfInJunitTest() { if (IN_JUNIT_TEST) { throw new RuntimeException("Attempted to terminate the VM in a junit test."); } } ```
Is the intention to allow termination to happen from other threads even if still running a test? i.e. do we want this test to pass as well? ```scala @Test def exitWithoutSettingUpHooks(): Unit = { val t = new Thread { override def run { try { Exit.exit(1, None) } catch { case e: RuntimeException => assertEquals("Attempted to terminate the VM in a junit test.", e.getMessage) } } } t.start() t.join() } ``` It's also maybe slightly nicer to not have to check the stack frames ```suggestion private static final boolean IN_JUNIT_TEST = Stream.of( "org.junit.platform.commons.util.ReflectionUtils", "org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor" ).anyMatch(clazz -> { try { Class.forName(clazz); return true; } catch (ClassNotFoundException ignored) { return false; } }); static void throwIfInJunitTest() { if (IN_JUNIT_TEST) { throw new RuntimeException("Attempted to terminate the VM in a junit test."); } } ```
Is the intention to allow termination to happen from other threads even if still running a test? i.e. do we want this test to pass as well? ```scala @Test def exitWithoutSettingUpHooks(): Unit = { val t = new Thread { override def run { try { Exit.exit(1, None) } catch { case e: RuntimeException => assertEquals("Attempted to terminate the VM in a junit test.", e.getMessage) } } } t.start() t.join() } ``` It's also maybe slightly nicer to not have to check the stack frames ```suggestion private static final boolean IN_JUNIT_TEST = Stream.of( "org.junit.platform.commons.util.ReflectionUtils", "org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor" ).anyMatch(clazz -> { try { Class.forName(clazz); return true; } catch (ClassNotFoundException ignored) { return false; } }); static void throwIfInJunitTest() { if (IN_JUNIT_TEST) { throw new RuntimeException("Attempted to terminate the VM in a junit test."); } } ```
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
Can remove if initialize above
`replicaing` -> `replicating`
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
`instantiateConfigProviders` since this is potentially creating multiple providers
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
Nit: add `final` to both parameters -- please follow a "one parameter per line" formatting.
This block may be a bit easier to follow if the if-else block sets up the Map of properties that will be used for the config provider properties, and then instantiate them in one place. Something like: ``` Map<String, String> providerConfig; if (configProviders == null || configProviders.isEmpty()) { providerConfigs = indirectVariables; } else { providerConfigs = mapValuesToStrings(configProviders); } Map<String, ConfigProvider providers = instantiateConfigProvider(providerConfigs, originals); if (!providers.isEmpty()) { ... ``` I know the if-else could be simplified further, but I think this is simple to follow.
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
Hmm, why did we do this? I thought we'd have a try/catch block.
Can remove if initialize above
Can remove if initialize above
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
This could be final.
While we're at it, we may as well use another `{}` substitution for the parameter and remove the unneeded `toString()`.
Are you implying cache efficiency? I'd imagine the order to matter if one of the fields had more chances to return `false` than the others. But I don't think it's worth thinking about this here. Feel free to leave this as you have it. When I saw it, I just thought your editor performed the reordering.
It includes the partition-level error. It seems to me it follows the docs. ` The number of each type of error in the response, including {@link Errors#NONE} and top-level errors as well as more specifically scoped errors (such as topic or partition-level errors). `
getter and setter should be removed
We also need to update `equals()` to include `topicPattern`
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
Suggestion: ```text Returns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`. If this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire). ``` ```
We also need to update `equals()` to include `topicPattern`
You could return Optional[String] probably where defined string would be the rejection reason. This would mean renaming the methods slightly though.
wow, I don't think we actually catch the case where the replica set is empty. Let me open a separate PR for this
Just wanted to say I really like the way this unit test is written! With the right usage of mocks we would avoid having any time-dependent flakiness.
Sure, that would work. Maybe `getFirstPartitionError` is a clearer name? Or you could bundle the exception throwing as well into a single `maybeThrowFirstPartitionError`? Either way is fine with me, but I'd prefer not to additional fields without a clear case that they're needed.
This will close the `SocketChannel` before it can be used by `TimeoutAwareChannel`. It's eventually closed when the `TimeoutAwareChannel` is closed so this is change isn't needed. I'll address this while merging.
you can just return from inside these cases and avoid the local var / null initializer problem.
`.toString()` unnecessary here are other similar logs.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
unnecessary type in constructor, can use `new HashMap<>()`
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
The `connectorStatus(connector)` call might fail with a `NotFoundException` if the connector was removed after the `configState.connector()` method is called but before the status for the removed connector is asked for. Although this shouldn't happen within the process (since requests are handled sequentially by a single thread), it may be possible that this herder is not the leader, that the leader performed the change, and that this herder's config state backing store read that change after the `configState.connector()` method was called but before the `connectorStatus(connector)` method is called for that connector. Should be easily handled with a try-catch, and if the connector with the specified name is not found then simply continue to the next connector name. Something like: ```suggestion try { out.put(connector, connectorStatus(connector)); } catch (NotFoundException e) { // do nothing with connectors that were just removed } ``` Note that if a connector is *added* with similar timing, the new connector name will not be returned from `configState.connectors()` and the new connector will not be included in the results. I think that's fine, considering the result of this method call would still be consistent with the state at the time the `configState.connectors()` call is made. Call it again, and you'd see the new connector.
I think we're testing `testDir` Occupied here, not `AppDir`.
Ditto on removing before/after
I'd keep `FileNotFoundException` in the signature as it indicates a specific error as opposed to the more general IOException
I think we're testing `testDir` Occupied here, not `AppDir`.
nit: Indicate that this needs shallow iterations on the entries.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Recently, we prefer to use `assertThat()` instead of `assertEquals()`.
I know we need both `File` and `Path` instance to complete the permission setting. What I meant is that: 1. We already had the `File` instances, i.e. baseDir, stateDir 2. `Paths.get(stateDir.getPath())` --> what happened behind the scene, is we created a Path instance from the path string in the file instance (i.e.`stateDir.getPath()`) ```java public final Path getPath(String var1, String... var2) { ... return new UnixPath(this, var3); } ``` 3. `path.toFile()` --> what happened behind the scene, is we created a File instance from the path string ```java public final File toFile() { return new File(this.toString()); } ``` So, currently, we will created an additional File instance via `path.toFile()`. If we pass the File instance into `configurePermissions()` directly, it'll only created a `Path` instance. ex: ```java configurePermissions(stateDir); // pass the file instance directly ``` ```java private void configurePermissions(final File file) { final Path path = Paths.get(file.getPath()); // created path instance if (path.getFileSystem().supportedFileAttributeViews().contains("posix")) { .... } else { boolean set = file.setReadable(true, true); // won't create additional File instance here .... } } ```
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
firstException wouldn't be null at this point - see call on line 510 It seems call on line 510 can be removed
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
That class is different because it doesn't actually `define` the config, it's just an undeclared "extra" config that gets passed around to be interpreted inside the serde. Actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.
I think this test condition is unnecessary. The `poll` in the line above completes only when the future is done. Same below.
At this point, it's not clear if all bytes from src have been read. So, it might be useful to loop through the writes to sslEngine until flush() can't write all bytes to sockets and then return. This can potentially avoid the caller from re-populating the same bytes from fileChannel again.
I think I'm convinced :) Let's keep them as removed.
Nit: go with single parameter per line.
firstException wouldn't be null at this point - see call on line 510 It seems call on line 510 can be removed
Seems like a no-op
nit: add `final`
What's the purpose of this warning? It doesn't seem needed.
What's the purpose of this warning? It doesn't seem needed.
`validateStoreOpen()` can be outside of lock block.
`validateStoreOpen()` can be outside of lock block.
This may throw a `SecurityException`. I think we should set the TCCL on a best-effort basis so any `SecurityException` that's thrown should be caught (and logged) and we should then proceed with the `invoke`.
Move that below the `csrf_processing_done` -- we do not need to do extra work in that case.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
same for functions below
same for functions below
same for functions below
same for functions below
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
nit: Indicate that this needs deep iterations on the entries.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
and -> a
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
Could this result in NPE? May be we can directly throw an IllegalArgumentException here.
It is probably good to always have ms in the name variable name that represents time in ms. Probably not a big deal here since this is local variable.
Could this result in NPE? May be we can directly throw an IllegalArgumentException here.
Could this result in NPE? May be we can directly throw an IllegalArgumentException here.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
This statement is a bit misleading, how about "to the format indicated by the given magic value".
nit: add a size? There are a few cases in here where we could do this.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
This statement is a bit misleading, how about "to the format indicated by the given magic value".
Could this result in NPE? May be we can directly throw an IllegalArgumentException here.
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
It is probably good to always have ms in the name variable name that represents time in ms. Probably not a big deal here since this is local variable.
This statement is a bit misleading, how about "to the format indicated by the given magic value".
This statement is a bit misleading, how about "to the format indicated by the given magic value".
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
Use: ``` self.assertSequenceEqual( Article.objects.order_by(F("author").desc(nulls_last=True)), [self.a4, ...] ) ```
Maybe this looks better? ```suggestion // we're at the end of the input. if (queryResult.getResult().value() == batch1NumMessages - 1) return; ```
nit: add a size? There are a few cases in here where we could do this.
`.configure()` is called within `getConfiguredInstance()` already -- you can remove this line (I know this pattern was there before, but it's wrong -- can you please fit it :)) this can be a single liner within try-catch-block: `return getConfiguredInstance(DEFAULT_KEY_SERDE_CLASS_CONFIG, Serde.class);`
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
@dajac Won't this create a list regardless of whether there are timed out entries? Let's see whether this addresses @ijuma 's concern on the other PR.
same here. let's make all method params as `final`
Good point. Btw, this particular class (the default SASL/PLAIN server-side callback handler) is not recommended for production use, so perhaps not that critical.
Good point. Btw, this particular class (the default SASL/PLAIN server-side callback handler) is not recommended for production use, so perhaps not that critical.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Is this used anywhere? I see we have changed client code to use the other C'tor.
It's a little confusing that this is named newValue, but is sometimes actually priorValue
same here. let's make all method params as `final`
with 10 messages and a commit marker at 5, we need a second commit marker at 11: `0...4,C,6,...11,C` thus, endOffset should be 12. Having say this, I think a simpler setup `0...,9,C` and endOffset `11` would be sufficient for this test case.
we just generally try to avoid the mess if the code isn't ready to be committed yet. it can always be held onto in a branch, wip pr, etc
Maybe it's worth not including this constructor. It's only used in tests and it's generally a good idea to provide a message with the exception.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: could be useful to log the type of exception in the assertion message.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Maybe it's worth not including this constructor. It's only used in tests and it's generally a good idea to provide a message with the exception.
with 10 messages and a commit marker at 5, we need a second commit marker at 11: `0...4,C,6,...11,C` thus, endOffset should be 12. Having say this, I think a simpler setup `0...,9,C` and endOffset `11` would be sufficient for this test case.
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
Nit: somehow I don't like `blah`. Otherwise LGTM
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
`instantiateConfigProviders` since this is potentially creating multiple providers
This seems like it's a kind of weird restriction. I guess it'd be odd to use the same name for an internal topic and another, though if you know its going to be prefixed it might not be great to not be able to use that same name.
It's not critical, but you might want to catch any exceptions from this `project` call and wrap them in another `SchemaProjectorException` so you can include info about which field failed projection.
`instantiateConfigProviders` since this is potentially creating multiple providers
This seems like it's a kind of weird restriction. I guess it'd be odd to use the same name for an internal topic and another, though if you know its going to be prefixed it might not be great to not be able to use that same name.
This seems like it's a kind of weird restriction. I guess it'd be odd to use the same name for an internal topic and another, though if you know its going to be prefixed it might not be great to not be able to use that same name.
prop: Would it make sense to also have an overload with just a flat list, i.e., ``` void runTestWithDriver(final List<TestRecord<Long, String>> expectedResult) ``` Maybe it would simplify the code of some of the tests. Hopefully, you can share some of the code in the overloads.
It's not critical, but you might want to catch any exceptions from this `project` call and wrap them in another `SchemaProjectorException` so you can include info about which field failed projection.
`instantiateConfigProviders` since this is potentially creating multiple providers
`Value` wrapping and `output_field` is unnecessary on the main branch ```suggestion annotated_field=2, ).filter(order__gte=6) qs2 = ReservedName.objects.annotate( annotated_field=1, ``` or ```suggestion annotated_field=Value(2), ).filter(order__gte=6) qs2 = ReservedName.objects.annotate( annotated_field=Value(1), ``` both work
This logic is not exactly the most straightforward. What about something like this? ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { Versioned versioned; if (pluginImpl != null) { versioned = (Versioned) pluginImpl; } else { versioned = (Versioned) pluginKlass.newInstance(); } return versioned.version(); } return "undefined"; ``` or ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { if (pluginImpl == null) { pluginImpl = pluginKlass.newInstance(); } return ((Versioned) pluginImpl).version(); } return "undefined"; ```
Something to consider for a future PR: it's a bit odd that `MockClientSupplier` always returns the same producer when the contract is that `getProducer` returns a new producer. If we changed it so that it had the specified behaviour we would not need this class.
same here as what i said below. You can use a `assertThat`
nit: We could use `TestUtils.assertFutureThrows` here.
same here as what i said below. You can use a `assertThat`
@mimaison It is true that the test would check only one class depending on the JRE. But it checks that the relationship between `java.vendor` and Kerberos classes matches the expectation in the code (for that JRE). The other unit test is checking if String comparison works, which is fine as a unit test, but it doesn't really test the actual System property based on the JRE.
Style-wise, I like to make the thing being tested the last import and visually separate from the other imports (a blank line between them and the import for the thing(s) being tested.
nit: We could use `TestUtils.assertFutureThrows` here.
Could we use `TestUtils.waitForCondition`? That will time out if it takes too long for the condition to become true.
@rajinisivaram Just for curiosity I tried the IBM MacOS SDK. It has both classes. And neither work ð with our test harness! Anyway that JDK is not our priority
we can use `TestUtils.assertFutureThrows()` here too
This does not really align with the name of the test. Is it intentional to have it? The test basically verifies that the first request is failed with an `UnsupportedVersionResponse` error and that the second request does not get any response.
Could we use `TestUtils.waitForCondition`? That will time out if it takes too long for the condition to become true.
Alternatively, now that we enforce checkpoint during suspension, we could just remove the `pre/postCommit` for active tasks in `handleAssignment`. It just seems nice to be able to assert that we never call `pre/postCommit` after a task is suspended
Nitpick: if you move the fail inside the `try`, then you no longer need the `return` in the catch. This applies to a few other tests too.
Nitpick: if you move the fail inside the `try`, then you no longer need the `return` in the catch. This applies to a few other tests too.
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Definitely don't add an abstract class! Let's leave it as is for now, then.
Nit: `assertThat` take expected result as first parameter IIRC (otherwise error message on failing test is "reversed")
Is this change actually needed? The intent currently is to let `BoundField` be constructed only within the scope of a given Schema and to use `Schema.get` in order to get an instance. We do not expect a `BoundField` constructed in the context of one schema to be used for another schema. Note also that the includes test case does not cover this change, so we are probably missing another test case if we think this fix is important.
This could be moved outside the `try` and handled in the `if` above: ```java if (this.jarFile == null || this.jarEntryName.isEmpty()) ```
This could be moved outside the `try` and handled in the `if` above: ```java if (this.jarFile == null || this.jarEntryName.isEmpty()) ```
This could be moved outside the `try` and handled in the `if` above: ```java if (this.jarFile == null || this.jarEntryName.isEmpty()) ```
`ObjectMapper` instances should be created once and cached, normally.
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
We tend to use different `node` value when multiple connections are created by a test. You could just replace `node` here with "1" and a couple of lines below with "2".
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
nit: This last check is not needed, since it verifies functionality of the `Map` returned by `Collections.unmodifiableMap()` and not of the code under test.
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
@ijuma @original-brownbear Yes. It's an array because it's passed into `TopologyBuilder#connectProcessorAndStateStores(String processorName, String... stateStoreNames)`
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
unnecessary type in constructor, can use `new HashMap<>()`
Would it be a lot easier to do the following? ``` Map<String, Object> prefixedOriginals = connectorConfig.originalsWithPrefix(prefix); Map<String, Object> clientConfigs = configDef.parse(prefixedOriginals); ``` This does check a few more things (dependencies are set and validators are run), so maybe that's not really want we want to do here.
Would it be a lot easier to do the following? ``` Map<String, Object> prefixedOriginals = connectorConfig.originalsWithPrefix(prefix); Map<String, Object> clientConfigs = configDef.parse(prefixedOriginals); ``` This does check a few more things (dependencies are set and validators are run), so maybe that's not really want we want to do here.
I'd suggest moving this static method after the non-static methods.
I'd suggest moving this static method after the non-static methods.
I'd suggest moving this static method after the non-static methods.
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
I'd suggest moving this static method after the non-static methods.
`WrappedStore` should have a method `root()` (or similar name) that returns the most inner store.
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
I don't think this is necessary. The SecurityFileChangeListener thread may not yet have started, but the watch services are already registered after `factory.configure(configs)`. The file change below should queue a change even if the thread hasn't started.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
All `description:` (apart from `short_description:`) must be full sentences (capital letters & fullstops)
Maybe we could use a different value here.
I'd suggest moving this static method after the non-static methods.
That class is different because it doesn't actually `define` the config, it's just an undeclared "extra" config that gets passed around to be interpreted inside the serde. Actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
Is there a reason not to include support for casting `DECIMAL` to other primitives? Yes, this might be lossy, but it also would help in cases where there would be no loss of precision.
@xin-au good idea with the timeouts, but I think we can simplify lines 310-329 down to a single `waitForCondition`. Something along the lines of: ```java TestUtils.waitForCondition(() -> !globalStreamThread.isAlive(), "Failed to shutdown a global stream thread,the global stream thread is still alive"); ```
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
Nit: move into the `if` block where it is used. (also add `final`)
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
This should call `configState.rawConnectorConfig(connector)`, which returns the _user-supplied_ configuration _with variables not resolved_. The `connectorConfig(connector)` call returns the configuration _with variables already replaced_, which means we might be leaking passwords and other secrets specified using variables.
Add the `@Overrride` annotation to this method.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Nit: remove `this`
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Add the `@Overrride` annotation to this method.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Add the `@Overrride` annotation to this method.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Do we really need to set a fatal error for every consumer, or could we just remove the problem partition from the assignment and set NEEDS_REJOIN? Or is it better to just fail fast
nice fix! this has been bothering me.
Add the `@Overrride` annotation to this method.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
Nit: move into the `if` block where it is used. (also add `final`)
While I think it would be fine, it would be "new" -- if we think `instance` is better, we might want to migrate all other code lazily to use `instance`, too. It's always best to have the same naming conventions throughout the whole codebase IMHO.
Should the error message not point out what went wrong, ie, "messages in the first batch were [not] processed in a timely manner" -- same below
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
Maybe "to specify callbacks for producer.send() or to call .get() on the returned Future:..."
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Add the `@Overrride` annotation to this method.
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
+1 for fixing the api. I would prefer a traditional api (either make C'tor private and `of` as a builder pattern w/o returning Optional or provide C'tors to create objects).
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
Ideally, we'd always use brackets on control flow operators.
I think this is because this function is only for init the getters, which requires the state stores is connected, hence accessible in `init` to the node.
Maybe we can just a better name for `path` since it makes this code look suspicious.
NPE: ![image](https://user-images.githubusercontent.com/925755/55269396-d55f3480-5292-11e9-9c29-78c524d63c65.png) I'm not using a topic pattern, equality should still work.
I vote yes for this. I think if we use this for writing snapshot from the state machine, then minimum size is a more interesting metrics for flushing to disk vs lingerMs. If we implement this so that either one has to be true then the client can set the `lingerMs` or `minSize` to MAX_VALUE if it wants to ignore those values.
Maybe we can just a better name for `path` since it makes this code look suspicious.
This name seems backwards.
Hello and thanks for reviewing! The callout about record ordering was originally requested within Confluent; the same is mentioned at this page: https://developer.confluent.io/tutorials/message-ordering/kafka.html. We think this would also benefit AK docs.
This name seems backwards.
formatting: no need to curly braces
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
formatting: no need to curly braces
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
It would be nice to have a unit test for this.
formatting: no need to curly braces
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Suggestion on above function addConfiguredSecurityProviders: 1. I think using following format for security.providers: security.providers=provider1_classname,provider2_generator_classname key1:val1 key2:val2,... 2. So when parsing above config, if there is no parameters following provider1_classname, then we can think provider1_classname is java Provider, then insert it; if there are key:value pair parameters following provider2_generator_classname, we can think provider2_generator_classname is SecurityProviderGenerator, then create "Map<String, ?> config" from key:value pair parameters, then call configure and getProvider of instance of SecurityProviderGenerator. This way we can handle all different scenarios in the future.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
I think this should be `protected` to avoid calls to `wrappedStore()` in all child classes
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
This still needs to be addressed
This still needs to be addressed
I don't think we need these prevTasks and standbyTasks for this test. You can just pass `Collections.emptySet()` to the `Subscription`
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
This lock is unnecessary since the onNext call is not supposed to be invoked concurrently.
This TODO should be removed
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
depending on the decision regarding naming sources for `builder.table` we'll need to update this test.
This lock is unnecessary since the onNext call is not supposed to be invoked concurrently.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
Preferred leader election is an optimization. If we can't move the leader to the preferred one, it seems there is no need to do anything extra.
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
Same for all such calls.
Shouldn't this be a config exception? It is not really invalid partitions.
nit: 'else' can be dropped
In order to reproduce this issue, we need to reset the generation via `maybeLeaveGroup` before the `onJoinComplete(gen.generationId, gen.memberId, gen.protocol, memberAssignment);` is triggered, but after the join-group response handler is exercised to set the generation id. I think this can still be doable with a single thread, to execute in the following ordering: 1. we only prepare the join-group response in the mock network client, but not the sync-group response, and we also make the MockTime to be able to advance time automatically, then by calling `joinGroupIfNeeded` with a small timeout instead of Long.MAX_VALUE, it should be able to finish the join-group round trip, trigger the handling logic to set the generation id, and then send the sync-group request, but then time out on https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java#L400 waiting for the sync-group response and return false. 2. Then we call `maybeLeaveGroup` within the same thread. 3. Then we prepare the sync-group response in the mock network client, and call `joinGroupIfNeeded` again, this time the response would be received, and the rest of the logic https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java#L406-L415 would be executed.
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
> Why does it do this? Maybe it's a translation layer for other stores? In which case, is it correct for Streams to second-guess the implementation and break its own contract by ignoring the marker interface and delivering non-timestamped binary data? I don't think that would work. Note, on restore, we always get the most inner store and would not call this "translation layer wrapper store" (and thus it would break as we would insert our converter and hand timestamped-bytes to the store that does not understand them). If one want to implement a translation wrapper like this, she need to "hide" it from Kafka Streams and not implement `WrappingStore` (ie, the translation wrapper must be the most inner store).
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
This is also the default, I think.
This is also the default, I think.
This is the default.
again, naming of the test
again, naming of the test
nit: add `final`
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
This might be instable in Jenkins.
Can we make this method return `OptimizableRepartitionNode` just for symmetry? I.e., you can see that we're replacing a bunch of `OptimizableRepartitionNode`s with a new `OptimizableRepartitionNode` instead of replacing them with a generic `StreamsGraphNode`.
nit: add `final`
I think this says, "we are looking for a parent node that is among my parent nodes". It seems like we can generalize this logic by not assuming there's a single parent node at all.
Can we make this method return `OptimizableRepartitionNode` just for symmetry? I.e., you can see that we're replacing a bunch of `OptimizableRepartitionNode`s with a new `OptimizableRepartitionNode` instead of replacing them with a generic `StreamsGraphNode`.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
nit: extra blank line
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
Nit: Can we change the wording of this to the following ```suggestion log.debug("{} attempting protocol downgrade and retrying.", this); ```
nit: add `final`
Hmm, normally `IllegalArgumentException` indicates that the argument to a function is bogus, right? That's not really the case here-- the function argument was fine, but the topic wasn't set up correctly. This can probably just be a generic `RuntimeException`, since we don't have a need to make it something fancier.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
I think it would be good to include a message giving context before we start listing unresolved issues.
Why the second client will have two pending transactions? Upon migrated the task the initTxn should cause the pending transaction failed.
Thanks! Will push this shortly.
ah, you are right.
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
OK, will remove before merging.
Is there precisely one time you can specify this? It sounds to me like this should be allowed to repeat multiple times. So this should be a `list`. Or maybe even better a `dict`, so people can specify things like ``` blkio_weight_device: /dev/sda: 100 /dev/sdb: 200 ```
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Shouldn't this be a config exception? It is not really invalid partitions.
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
add `final` twice
I'm not sure this is a good idea. If we're unlucky, the partition we're interested in may not be listed. Since this is an exceptional case anyway, I would suggest using the more verbose message.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
Shouldn't this be a config exception? It is not really invalid partitions.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
I believe this will inject non-determinism ... notifications will be capable of interleaving and being out of order. I think we need to combine this with `ScheduledObserver` which maintains a queue and event loop for handling each notification sequentially on the given scheduler.
It would be nice to have a unit test for this.
I know you just moved these lines around, but while you're doing that it probably would be worthwhile to combine these 2 statements into one. If the log is busy, these might not appear next to each other.
Shouldn't this be a config exception? It is not really invalid partitions.
Shouldn't this be a config exception? It is not really invalid partitions.
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
That sounds good to me ð
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
There may be a couple validations we have in `ZkAdminManager.describeClientQuotas` that do not appear here. For example, we detect invalid mixes of ip and user searches: ``` if ((userComponent.isDefined || clientIdComponent.isDefined) && ipComponent.isDefined) throw new InvalidRequestException(s"Invalid entity filter component combination, IP filter component should not be used with " + s"user or clientId filter component.") ```
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
debug line should be removed.
debug line should be removed.
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
Yeah, either way works for me. Seems unlikely someone using a bleeding edge library like streams would be on an ancient Slf4j ð
nit: 'else' can be dropped
This does not really align with the name of the test. Is it intentional to have it? The test basically verifies that the first request is failed with an `UnsupportedVersionResponse` error and that the second request does not get any response.
Unlike in the standalone, it's a bit more difficult to check how the connector configuration has changed. This `startConnector(...)` method seems to be called in two places: from `restartConnector(...)` and `processConnectorConfigUpdates`, which IIRC happens whenever the connector configuration has changed in some way. I'm wondering how often a connector might not change it's task configs when the connector config has changed. What do you think about just always restarting the tasks even if the generated task configs have not changed? WDYT? @kkonstantine, the `processConnectorConfigUpdates(...)` method is called during rebalances, and maybe I'm missing cases where the recent rebalance improvements handle the task configs more frequently than I recall.
Could this be completely fixed by ``` int startIdx = Utils.abs(this.randOffset.nextInt(Integer.MAX_VALUE)) % nodes.size(); ... for (int i = 0; i < nodes.size; i++) { int idx = (startIdx + i) % nodes.size(); } ```
Dropped this unnecessary duplicate code, as we discussed.
My only suggestion is that I think it could be easier in the long run to do the following instead of duplicating the transaction logic, but at the same time the current code is saving cycle by not evaluating the `if module.check_mode` conditional multiple times so it's purely preference and I don't care to block the PR on it. ð ```python if state == "present": if not shard_find(client, shard): if not module.check_mode: shard_add(client, shard) changed = True else: changed = False elif state == "absent": if shard_find(client, shard): if not module.check_mode: shard_remove(client, shard) changed = True else: changed = False ```
This is pointless message since you don't support login.
Increase the timeout makes sense to me.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
This is pointless message since you don't support login.
I think these need to be `volatile` if we want them to work cross threads. I was thinking we should consider using `AtomicInteger` to avoid the need to increment these variables inside synchronized variables. I know it has a smaller cap (INT_MAX) but I imagine that should be enough for such a test
I think these need to be `volatile` if we want them to work cross threads. I was thinking we should consider using `AtomicInteger` to avoid the need to increment these variables inside synchronized variables. I know it has a smaller cap (INT_MAX) but I imagine that should be enough for such a test
Hmm, why did we do this? I thought we'd have a try/catch block.
Hmm, why did we do this? I thought we'd have a try/catch block.
Check TROGDOR.md. > All Trogdor RPCs are idempotent except the shutdown requests. Sending an idempotent RPC twice in a row has the same effect as sending the RPC once. Because the request is idempotent, sending it twice has the same effect, including the same result code.
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
It seems a little harsh to set a fatal error condition because the process logged something on stderr. A lot of applications use stderr as an output. Maybe we should just log this with `log.error`.
Nit: ```suggestion * executed exactly once. If {@code maxRetries} is set to {@code n}, the callable will be executed at ```
Sound like it uses `Properties` class (while it doesn't) -- but maybe I am overthinking this... Should be fine.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Sound like it uses `Properties` class (while it doesn't) -- but maybe I am overthinking this... Should be fine.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
```suggestion put(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, "/tmp/foo"); ```
Nit: please add `final` to all local vars and method parameters
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
why use `topicName` here? Should it not be `failed: key=X actual=A expected=B...` instead of `failed: key=X <topicName>=A expected=B...`
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
I submitted a PR for KAFKA-2711. I think we do need clientPrincipalName, and I hope this is clearer with the changes in that PR: https://github.com/apache/kafka/pull/390
Hmm.. I am not sure this is sufficient. Any of the responses could return from the heartbeat thread.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
Also: should only call onPartitionsLost on owned partitions that no longer exist
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
just noticed this - I think we want `clean_shutdown=False` here to ensure we really kill the process if the normal attempt to gracefully shut it down failed
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
nit: 'else' can be dropped
Nit: var should be named `deserializeValue`
This won't log the error. We want to use the `public void error(String msg, Throwable t);` overload, so we need to change `e.getMessage()` -> `e`
nit: maybe we can separate AbstractTaskCreator and its two impls into separate classes once we are finalizing the refactoring in a follow-up PR (this PR can stay as is to keep it from exploding LOC)
Let's use `Map` on the left side instead of `HashMap`
This won't log the error. We want to use the `public void error(String msg, Throwable t);` overload, so we need to change `e.getMessage()` -> `e`
nit: maybe we can separate AbstractTaskCreator and its two impls into separate classes once we are finalizing the refactoring in a follow-up PR (this PR can stay as is to keep it from exploding LOC)
nit: maybe we can separate AbstractTaskCreator and its two impls into separate classes once we are finalizing the refactoring in a follow-up PR (this PR can stay as is to keep it from exploding LOC)
Kafka doesn't mandate braces in `if` statements.
Let's remove the brace changes please.
Nit: somehow I don't like `blah`. Otherwise LGTM
Let's remove the brace changes please.
Same here, we can cache the result of `Builder.getPartitions(data)` for re-use.
FYI https://twitter.com/joshbloch/status/583813919019573248 :)
FYI https://twitter.com/joshbloch/status/583813919019573248 :)
FYI https://twitter.com/joshbloch/status/583813919019573248 :)
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
This check `records.size() < offset` seems a bit sketchy to me. Basically we are assuming that the input topic `data`'s starting offset is always 0, and there is no "holes" in the topic partitions so that the `offset` indicates the number of records we can read from the input topic. Maybe a more robust way to do that would be 1) read the input topics `data` and optionally `repartition` based on `withRepartitioning`, stop when the current record's offset is equal to or larger than the committed offset, and remember the number of records; 2) read the output topics (again optionally `repartition`) from the beginning to the end (use `seekTo`), and check that the number of records are the same as the number of records read from the input. Then we do not need to truncate, and also in verification we do not need to check list size again since they are already checked here.
I would also try to uniformize the logs and would use debug all the time except for the unexpected errors.
Ouch! Sorry about that!
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
Wouldn't you also need to handle default values? Presumably you're also assuming that there's only one version of a schema referenced anywhere in the schema? And that the schema parameters (e.g. the scale used by Decimal) don't matter? I realize that Decimal isn't a good example of where this could come into play, I'm just trying to highlight that I'm not sure the current API really addresses the full problem.
Might be simpler to use the mock deserializer only for values.
Maybe add one more sentence: > .. underlying fetch behavior. The consumer will cache the records from each Fetch request and return them incrementally from each `poll`.
Maybe add one more sentence: > .. underlying fetch behavior. The consumer will cache the records from each Fetch request and return them incrementally from each `poll`.
@ijuma For me it seems `isJava8Compatible()` could also be removed (with all its test usages)
This condition seems unnecessary complex. Should it not just be: ``` if (mappedKey == null || value == null) { ```
One extra line.
Oh, and a typo which I would like to make KNOWN (or UNKNOWN?! ... I would pick a pun over clarity any day :) )
Yes, this should on an internal package (eg `common.internals`).
Yes, this should on an internal package (eg `common.internals`).
we can get rid of the else block here and save some indentation. if we threw an exception then we're out of the function
we only need the lock for setting the seed and calling `random.nextInt`, right? for the rest of the function we can avoid holding the lock since we're just iterating over an immutable list that can't change and calling stuff that is threadsafe anyway
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
We only applied for `ElementType.METHOD`, so `ElementType.ANNOTATION_TYPE` can be removed.
We could port this function when it is actually needed.
```suggestion // If a task's previous host client was not caught-up or no longer exists, assign it to the caught-up client with the least tasks ```
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
```suggestion // If a task's previous host client was not caught-up or no longer exists, assign it to the caught-up client with the least tasks ```
`.toString()` unnecessary here are other similar logs.
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
This is because we are inheriting a Scala class, and moving forward we should remove this with the Java version `org.apache.kafka.copycat.util.ShutdownableThread` that can be moved into `o.a.k.common.utils`. We can leave it as is for now.
This should go away. `@ConditionalOnClass` already does that.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
This is not covered by tests, also raising an exceptions in user-defined functions is not really helpful for users: ```python django.db.utils.OperationalError: user-defined function raised exception ``` I think we should return `None` instead.
It depends, but it can be public. You can solve metaclass conflicts manually creating class inhertiting from all of your metaclasses, or automatically by using this function (`metaclassmaker` or `six_with_metaclassmaker`), that would do exactly the same new metaclass for you.
Actually, WDYT about adding this class in the "add configs" PR and then rebasing this PR on top of that? Then I could do the same (since I need this class in my next PR as well)
Actually, WDYT about adding this class in the "add configs" PR and then rebasing this PR on top of that? Then I could do the same (since I need this class in my next PR as well)
You might consider using `OptionalDouble`.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
How about this transport configuration that we se to `NettyConnectionFactory`? @wilkinsona mentioned that on the original issue and we'd like some feedback on that.
Fair enough. Let's leave it as-is.
nit: add `final`
Aha, good point.
Nit: go with single parameter per line.
Check TROGDOR.md. > All Trogdor RPCs are idempotent except the shutdown requests. Sending an idempotent RPC twice in a row has the same effect as sending the RPC once. Because the request is idempotent, sending it twice has the same effect, including the same result code.
Use `self._search_regex` and `utils.unified_strdate` instead.
Use `self._search_regex` and `utils.unified_strdate` instead.
Use `self._search_regex` and `utils.unified_strdate` instead.
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
Are we sure we want to make them required config for `KerberosLogin`? I noticed that we have actually defined default value for these configs in `SaslConfigs.addClientSaslSupport()`. These default values are used by producer and consumer. And if these configs should be explicitly provided by user, should we have a class that extends `AbstractConfig`, define these configs as required, and use this class in KerberosLogin to handle user-provided properties, in the same way that ConsumerConfig is used? This would allow us to throw exception in case of missing config using a unified mechanism.
Thanks for adding coverage for sliding windows.
This looks better than what I did, go for it! My original hotfix PR is just to unblock the JDK11 jenkins job.
nit: ```suggestion final KafkaMetric metric = metric("prefix-scan-rate"); ```
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
This doesn't seem to be used.
What about inlining `transformations` and having something like: ``` when(plugins.transformations()).thenReturn(Collections.singleton(transformationPluginDesc())); ```
Same as before, parameters of `assertEquals` should be the other way round.
Nit: somehow I don't like `blah`. Otherwise LGTM
Nit: somehow I don't like `blah`. Otherwise LGTM
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
Nit: line too long
we just generally try to avoid the mess if the code isn't ready to be committed yet. it can always be held onto in a branch, wip pr, etc
This is probably just my style bias, but I wonder if it would be easier (and more readable) to use static factories for atomic vs non-atomic ControllerResult. Something like: ```java ControllerResult.newAtomicResult(records, response) // and ControllerResult.newResult(records, response) ``` Boolean flags as such a pain and easy to mess up. I actually think it might be nice if there are no public constructors for ControllerResult and we use factories for everything. However, this would be a bigger change, so I'm fine if we defer it (if we even decide we need it).
Nit: fix line break
This statement is a bit misleading, how about "to the format indicated by the given magic value".
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Nit: fix line break
It's probably worth while to mention that this method starts the task for a source connector with older behavior (without exactly once support).
It's probably worth while to mention that this method starts the task for a source connector with older behavior (without exactly once support).
Do we still need `needsJoinPrepare` now? It seems to me that we need to call `onJoinPrepare` whenever `needRejoin` is true.
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
nit: parameters on a separate line
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
```suggestion put(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, "/tmp/foo"); ```
Just let the Exception flow, that will automatically fail the test
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
Nit: since we require a non-null `Duration`, we should state that here: ```suggestion * @param timeoutDuration timeout duration; may not be null ```
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
This is also the default, I think.
How about adding a `coordinators` method to `FindCoordinatorResponse` which would either return the list of coordinators (`data.coordinators()`) if not empty or would return a list containing a `Coordinator` created from the top level information. That would remove all the `batch` checks below.
Better be `cooperative-sticky`? `cooperative` is too general I think.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Use `KafkaException` instead of `RuntimeException`
Use `KafkaException` instead of `RuntimeException`
nit: add a size? There are a few cases in here where we could do this.
do we need this invalid config step here
That probably wasn't what I was talking about. I meant the fact you remove the `PushGateway` variable and therefore changed this constructor. I see no good reason for doing so.
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
nit: parameters on a separate line
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
Well, won't we end up deleting the topics before closing it if we never reach the first `streams.close` ? Or does it not really matter in that case since something has already gone wrong (just curious, I'm fine with it as-is btw)
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
We should log an error that prints out what the two configs actually are
Well, won't we end up deleting the topics before closing it if we never reach the first `streams.close` ? Or does it not really matter in that case since something has already gone wrong (just curious, I'm fine with it as-is btw)
nit: new line
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
nit: Could just to `new ArrayList<>();`
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
I guess by preventing the unwrapping, the error keeps propagating up, therefore, this change is essential. However, there could be code out there that depended on the original behavior (since Exceptions is part of the public API).
From my understanding, this must either be without the last `{}` or using `e.toString()`? (Cf. https://stackoverflow.com/questions/6371638/slf4j-how-to-log-formatted-message-object-array-exception)
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
`Failed to flush accumulated records` -> `Failed to flush all accumulated records...` Also, it would be much more useful if we could say `%d of %d` batches although I see we would have to expose a `size()` method in `IncompleteBatches`
result isn't defined if check_mode but is still being used below in the call to await_resource()
nit: we can do without the curly braces here and above. However, these will soon be replaced by the actual impl
Shouldn't this be a config exception? It is not really invalid partitions.
nit: Could just to `new ArrayList<>();`
Why using StopWatch? this create many short live objects for not resean.
I guess by preventing the unwrapping, the error keeps propagating up, therefore, this change is essential. However, there could be code out there that depended on the original behavior (since Exceptions is part of the public API).
Maybe we could use a different value here.
Shouldn't this be a config exception? It is not really invalid partitions.
I think this config property key seems a misfit, and probably reflects an earlier incantation of the design before KIP acceptance. It might be worth - in a separate PR - renaming this to something like `errors.tolerance` to better align with its purpose.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
Yeah, we're still feeling out the best patterns for handling older versions.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
The code isn't huge, so by no means a blocker, but @kkonstantine pointed out that the entire block before configuration (and most of config modulo the conditional) is identical between header and "normal" converters. The main difference in the header blocks are just the class referenced (`Converter.class` vs `HeaderConverter.class`). Consolidation would be nice if it's easy to do, but at the same time I'd rather get a fix to the immediate problem in, so definitely wouldn't block on saving 10 lines of duplicated code.
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
Thanks. Not a blocker.
As above: add more "randomness"
Let's keep the `L`
Can we also assert that the state gets to `RUNNING` after the new thread has joined
the naming used above seems better here ```suggestion Throwable exception = null; ```
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Can we also assert that the state gets to `RUNNING` after the new thread has joined
What's our plan for the global thread? I didn't think of this during the KIP discussion, and sorry if it was brought up there and I just forgot about it. But it seems like we should still give users a non-deprecated way to set a handler for the global thread.
Do we need to lock here? I think the lock has already been taken out from the callers of this method
Could you test `maybeRecordE2ELatency()` through `process()` and `forward()`? Although you test `maybeRecordE2ELatency()`, you do not test if the recording is done during processing, but that is the crucial thing, IMO.
What about inlining `transformations` and having something like: ``` when(plugins.transformations()).thenReturn(Collections.singleton(transformationPluginDesc())); ```
What about inlining `transformations` and having something like: ``` when(plugins.transformations()).thenReturn(Collections.singleton(transformationPluginDesc())); ```
You are right. Checking ```Error reading field 'field2'``` should be enough for this test case.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
Is it intentional to swallow this exception? At a minimum, we should probably log the exception at DEBUG level.
mhm, I see, ok
mhm, I see, ok
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: could you try to deduplicate code here and in the other unit tests? Here for example, you could have one method like this: ``` private void shouldThrowIfNoPeekNextKey(final Supplier<MemoryLRUCacheBytesIterator> methodUnderTest) { final ThreadCache.MemoryLRUCacheBytesIterator iterator = methodUnderTest.get(); assertThrows(NoSuchElementException.class, iterator::peekNextKey); } ``` and then two public tests ``` @Test public void shouldThrowIfNoPeekNextKeyRange() { final ThreadCache cache = new ThreadCache(logContext, 10000L, new MockStreamsMetrics(new Metrics())); shouldThrowIfNoPeekNextKey(() -> cache.range(namespace, Bytes.wrap(new byte[]{0}), Bytes.wrap(new byte[]{1}))); } @Test public void shouldThrowIfNoPeekNextKeyReverseRange() { final ThreadCache cache = new ThreadCache(logContext, 10000L, new MockStreamsMetrics(new Metrics())); shouldThrowIfNoPeekNextKey(() -> cache.reverseRange(namespace, Bytes.wrap(new byte[]{0}), Bytes.wrap(new byte[]{1}))); } ``` Admittedly, in this specific case, we would not win much but for other unit tests in this test class it may be worth. Try and then decide if it is worth or not.
I think we should call `deserializer.configure(...)` here
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
May be better to use a limited size rather than `Integer.MAX_VALUE`. That would make it easier to test the limit.
May be better to use a limited size rather than `Integer.MAX_VALUE`. That would make it easier to test the limit.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
rewrite test as above using `assertThrows()`.
Yes, this should on an internal package (eg `common.internals`).
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
Yes, this should on an internal package (eg `common.internals`).
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
Right, sorry I misread that line.
The usual style is to put the closing parenthesis on the next line and include a trailing comma on this line.
If we reuse shared streams instance do we still need try-catch here as the `cleanup()` should close streams.
nit: We use singular verbs in other functions (e.g. line 54 above), would be better to be consistent.
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
We only applied for `ElementType.METHOD`, so `ElementType.ANNOTATION_TYPE` can be removed.
We only applied for `ElementType.METHOD`, so `ElementType.ANNOTATION_TYPE` can be removed.
Basic patch looks fine, but this code formatting won't pass checkstyle. After cleaning up you can verify it passes with `./gradlew clients:checkstyleMain`.
Nitpick: we typically do this like: ``` java return "KerberosShortNamer(principalToLocalRules = " + principalToLocalRules + ")"; ```
Basic patch looks fine, but this code formatting won't pass checkstyle. After cleaning up you can verify it passes with `./gradlew clients:checkstyleMain`.
SGTM. If we find it flooding the logs and not helpful we can reconsider
We only applied for `ElementType.METHOD`, so `ElementType.ANNOTATION_TYPE` can be removed.
as per previous `assertThat(..., instanceOf(...))` would be better
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
It will be worth mentioning that it includes the root cause since this is in `Utils`.
It will be worth mentioning that it includes the root cause since this is in `Utils`.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
what about `assertEquals("consumer record size is not zero", 0, records.count());`? It can also be applied in a few other places
The channel is not being passed to `log.debug`.
nit: add `final` and put single parameter per line
same question as other pr -- this is `sink-task-metrics` instead of `sink-tasks-metrics` in the KIP
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
This isn't a REST extension necessarily, right? It's also used by Kafka via JMX. I think mentioning `worker restarts` and `rest extension` might be confusing
I'd consider making this extend org.junit.rules.ExternalResource - it can then be used as a JUnit ClassRule or Rule. The benefits being that the JUnit framework takes care of startup and shutdown
Nitpick: I'd call this `getOrCreateFileChannel`.
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
Nitpick: I'd call this `getOrCreateFileChannel`.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Nitpick: I'd call this `getOrCreateFileChannel`.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
add `final` twice
formatting: no need to curly braces
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
We cannot rely on the rebalance protocol from `setRebalanceProtocol` in task manager to determine the logic, since during a rebalance, one can send with two supported protocol but the `EAGER` protocol is still used --- only the leader knows which protocol is used when doing the assignment. At the moment it is almost impossible to let the listener know which protocol was exactly used (not what protocol was supported); but on the other hand I feel may be it is not necessary as well: If the COOPERATIVE protocol is used, then we are effectively suspend tasks in onPartitionRevoked, and then immediately close those suspended tasks in onPartitionsAssigned since they are called consecutively in `onJoinComplete`, and no one would ever be resumed at all (i.e. that `resumeSuspended` call would always be no-op with no passed in task parameters). So I'd suggest we make the listener to also be agnostic to the rebalance protocol, and just follow the current logic of suspending resuming, and we can even see if we could in later releases remove the whole suspending/resuming all together regardless of the protocols.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
We should test that delete twice in a row fails with `IllegalStateException`
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
I think we should call `deserializer.configure(...)` here
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
This should go away. `@ConditionalOnClass` already does that.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
The reason why `ConcurrentSkipListMap` did not implement it in this way is because it is designed to be async, and we need it that way to support IQ / stream thread concurrency. But since only stream thread would put / delete into the map (assuming we forbid iterator.remove from the other PR so it is not allowed from IQ), then it is okay to have this field as non-volatile.
The reason why `ConcurrentSkipListMap` did not implement it in this way is because it is designed to be async, and we need it that way to support IQ / stream thread concurrency. But since only stream thread would put / delete into the map (assuming we forbid iterator.remove from the other PR so it is not allowed from IQ), then it is okay to have this field as non-volatile.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
The reason why `ConcurrentSkipListMap` did not implement it in this way is because it is designed to be async, and we need it that way to support IQ / stream thread concurrency. But since only stream thread would put / delete into the map (assuming we forbid iterator.remove from the other PR so it is not allowed from IQ), then it is okay to have this field as non-volatile.
as above (more often below -- please fit all)
Maybe we can just a better name for `path` since it makes this code look suspicious.
```{@link org.apache.kafka.common.KafkaFuture#get}``` => ```{@link org.apache.kafka.common.KafkaFuture#get()}```
```{@link org.apache.kafka.common.KafkaFuture#get}``` => ```{@link org.apache.kafka.common.KafkaFuture#get()}```
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
Remove double blank.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
nit: could be useful to log the type of exception in the assertion message.
We can use `assertThrows()` here. Same below
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
nit: move to line above.
@cmccabe is right about the race condition I think. we should probably check that `controlChannel` is initialized here
@cmccabe is right about the race condition I think. we should probably check that `controlChannel` is initialized here
It seems like the race conditions for `process` won't turn into any errors. It maybe is better to be explicit about the race conditions and have locks as to ease future maintainability of this task (especially by other contributors)
@cmccabe is right about the race condition I think. we should probably check that `controlChannel` is initialized here
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
nit: remove `this`
nit: remove `this`
Second parameter should be `serverConfigs`
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
I think it is better to throw if the passed in exception handler is `null` and set the default uncaught exception handler in the `StreamThread` constructor.
Sorry for the delay, I suggest we revert this part to properly scope this PR.
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
`windowSize` should be `Duration`
nit: add a space before the `:`.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
nit: add a space before the `:`.
the `try{...} finally` has been removed
Think you might have forgotten to remove some debugging here
Think you might have forgotten to remove some debugging here
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
How about keeping this `private` and adding a protected `isCancelled()` method? Currently, the `cancelled` field is encapsulated entirely within the `WorkerTask` class, and modified only via the public `cancel()` method. We can just as easily keep the encapsulation. OTOH, if we were to make `cancelled` protected, we'd lose that encapsulation and make it a bit more complicated if a future developer did want to add logic upon cancellation.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
and -> a
Looking a little bit closer what `throttler` does, it seems that it uses its own condition variable internally for throttling. That explains the call to `throttler.wakeup()` below (that was expected to wake up the throttler). The problem (bug) of course is that this call to wait() here is not waiting on the same object as the throttler (one object is the `SchemaSourceTask` and the other one is the `ThroughputThrottler`). There are two alternative solutions to introducing a new condition (here `stopped`). 1. Just keep on calling throttler.throttle(): - if target throughput is <= 0, it will practically wait indefinitely until a thread calls `stop` -> `throttler.wakeup()`. - if target throughput is > 0, is will still wait for approximately 1/throughput time. 2. Since you can't reset the target throughput for a specific throttler (it's a constructor argument), discard the old throttler and create a new one with target throughput 0. Here that'd be: ```java throttler = new ThroughputThrottler(0, 0) ``` (the 2nd argument doesn't matter if the 1st one is 0). This new instantiation would still need to be wrapped with `synchronized (this)`. Now, all that needs to happen is to wrap `throttler.wakeup();` within a `synchronized (this)` block, in order to make visible to every thread the switch between throttlers. The implementation is far smaller than the explanation (3 lines if I can count well). Your call.
To make it more rigid: we can pass a valid end point string, and then check that the field is still `null` below.
To make it more rigid: we can pass a valid end point string, and then check that the field is still `null` below.
To make it more rigid: we can pass a valid end point string, and then check that the field is still `null` below.
Ah, yes, the magic is hardcoded here.
Ah, yes, the magic is hardcoded here.
Thanks for the explanation. It seems like `purgeLocalStreamsState` should really be using `java.io.tmpdir` instead of `/tmp` if it wants to have that safety net.
Could we use `TestUtils.waitForCondition`? That will time out if it takes too long for the condition to become true.
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
I don't understand what this test is doing. Why do we need background clients instead of producing upfront and consuming the data mirrorred at the end of the test? It looks like we are testing the primary->backup scenario but we are restarting the backup cluster. The source connector should not interact with the backup cluster.
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: 'else' can be dropped
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
Is this used anywhere? I see we have changed client code to use the other C'tor.
Is this used anywhere? I see we have changed client code to use the other C'tor.
Is the `myCommittedToken == null` check unnecessary here since it can never be the case when there are extensions? I think we make sure of this since we only call `identifyExtensions()` when there is a token.
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
Nitpick: I'd call this `deserialize`.
He means that you don't need an `else` in this case.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Since this is usually the entry point where users would call `toString`, the indent is used for wrapping it. For example, `toString()` prints ``` Kafka Streams Thread Tasks Topology States ``` `toString(">")` prints ``` >Kafka Streams > Thread > Tasks > Topology > States ``` We do not need to let users override the internal ones, only the entry point of nested prints.
To make it more rigid: we can pass a valid end point string, and then check that the field is still `null` below.
What do we do if there's an exception? If it's expected, let's make it clear
`self.routing` is potentially `None`.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
I deliberately used byte-based checks when I wrote this as the archive is predominantly binary data. I think I'd prefer to keep it that way here and in the cases below as well.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
we can make method this public in `EmbeddedConnectCluster`.
`self.routing` is potentially `None`.
If the user is able to make the server sign arbitrary data of their choosing, using the same salt and key will yield the same signature. However, if we slightly modify the key, they can't. This makes chosen plaintext attacks less vulnerable.
Was the boundary check wrong? You changed `>=` to `>`.
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
And same question for the other uses of `TestUtils.tempDirectory` in this PR.
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
This should be 2.7 please.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
And same question for the other uses of `TestUtils.tempDirectory` in this PR.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
I think we should call `deserializer.configure(...)` here
`.toString()` unnecessary here are other similar logs.
This is really inefficient if `buffer` is a `DirectByteBuffer` and it's not small. The bulk `put` method performs better by doing a JNI array copy if it's larger than 6 elements. It's also less code.
This is really inefficient if `buffer` is a `DirectByteBuffer` and it's not small. The bulk `put` method performs better by doing a JNI array copy if it's larger than 6 elements. It's also less code.
Remove double blank.
nit: remove empty line
Wildcard imports should be caught by checkstyle, and should fail the build. In any case, please replace with non-wildcard imports.
Nit: every conditional needs to have braces (per the code style) not nit: I find this logic a little difficult to follow. Contrary to what @mjsax suggested, wouldn't it be pretty straightforward to map the old semantics on to the new ones like this: * negative numbers => 0 * 0 => Long.MAX_VALUE * all other arguments stay the same ? Then, the old close method could just transform its arguments and call the new method, with no need to have this "new semantics" flag and an early return in the middle of the loop.
Thanks for cleaning this up. I still can't read the old code without taking notes...
nit: remove empty line
We should pass in `record.topic()` instead of `""` into `deserialize`.
Oh yeah, duh. Nevermind this ð
Remove double blank.
nit: add a space before the `:`.
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
`advanceMs` is not the same as provided input parameter `advance` -- this would make the error message miss leading.
Actually, it's not just older requests, the default was always `""` whereas I am seeing `null` after this PR. It looks like there are two issues: 1. We didn't set a default of `""` for clientId in the json schema. 2. The generated protocol code behaves differently with regards to default values. It only uses the default if the field is not present. The `Struct` code uses it if `value == null`. ```java Object value = this.values[field.index]; if (value != null) return value; else if (field.def.hasDefaultValue) return field.def.defaultValue; else if (field.def.type.isNullable()) return null; else throw new SchemaException("Missing value for field '" + field.def.name + "' which has no default value."); ``` This is the generated code _after_ I add the `""` default for `clientId`. ```java public void read(Readable readable, short version) { this.requestApiKey = readable.readShort(); this.requestApiVersion = readable.readShort(); this.correlationId = readable.readInt(); if (version >= 1) { this.clientId = readable.readNullableString(); } else { this.clientId = ""; } } ```
`advanceMs` is not the same as provided input parameter `advance` -- this would make the error message miss leading.
"with a read-only key"
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
May be better to use a limited size rather than `Integer.MAX_VALUE`. That would make it easier to test the limit.
`advanceMs` is not the same as provided input parameter `advance` -- this would make the error message miss leading.
same for the store
Actually, it's not just older requests, the default was always `""` whereas I am seeing `null` after this PR. It looks like there are two issues: 1. We didn't set a default of `""` for clientId in the json schema. 2. The generated protocol code behaves differently with regards to default values. It only uses the default if the field is not present. The `Struct` code uses it if `value == null`. ```java Object value = this.values[field.index]; if (value != null) return value; else if (field.def.hasDefaultValue) return field.def.defaultValue; else if (field.def.type.isNullable()) return null; else throw new SchemaException("Missing value for field '" + field.def.name + "' which has no default value."); ``` This is the generated code _after_ I add the `""` default for `clientId`. ```java public void read(Readable readable, short version) { this.requestApiKey = readable.readShort(); this.requestApiVersion = readable.readShort(); this.correlationId = readable.readInt(); if (version >= 1) { this.clientId = readable.readNullableString(); } else { this.clientId = ""; } } ```
This is fragile and should be avoided. It looks like that this auto-configuration should expose a `CouchbaseConfiguration` rather than augmenting the Environment so late in the game. If we opened `CouchbaseConfiguration` a bit (make that its own class with the necessary parameters that you need), then we could expose one here and leave the original auto-configuration unchanged (it would simply backoff as it does already prior to this change).
nit: add a size? There are a few cases in here where we could do this.
nit: empty line.
Nit: `new Runnable()` not required, you can just override `run()` from `Thread`.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
GitLab authentication should not be inside this class. It should be in the main function and then you init your class with the gitlab_instance object in parameter. Look at other GitLab module
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
`shouldRecord`? `maybeRecord` sounds like it would record it for you.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
topics is a Set. What's your intention for the second parameter ? If you want the number of topics logged, you should use topics.size().
Can we actually just get rid of "test only" constructors? It couldn't be used by _that_ many different tests...
a 4 byte size, an 8 byte offset => an 8 byte offset, a 4 byte size of the record
Hmm, if standbyTask does not ever call `init()` then why do we want it to be an abstract class? I felt that we can either just remove abstract `init` and just let `StreamTask` has its own `init` function that is also called in `resume`; or if we do want to have a `init` abstract logic, we can also move ``` log.info("standby-task [{}] Initializing state stores", id()); initializeStateStores(); checkpointedOffsets = Collections.unmodifiableMap(stateMgr.checkpointed()); processorContext.initialized(); ``` At let constructor call this `init`. Personally I like the first option since we are already overriding the constructors anyways which always covers the `init` part, and just the stream task needs a reusable `init` part that is to be used in `resume`. But it's your call.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Can we actually just get rid of "test only" constructors? It couldn't be used by _that_ many different tests...
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
topics is a Set. What's your intention for the second parameter ? If you want the number of topics logged, you should use topics.size().
we can maintain `context`, `actions` as class variables initialized in setup().
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
I think you might want to rollback at this point.
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
req: we'll never hit this, as `taskToCaughtUpClients` only contains tasks _with_ caught-up clients IIUC. Can we just construct `unassignedTasksWithoutCaughtUpClients` as the set `totalTasks - taskToCaughtUpClients.keySet`? We can do that in `assignTasksWithoutCaughtUpClients` and remove `unassignedTasksWithoutCaughtUpClients` from `assignTasksWithCaughtUpClients` entirely
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
`final` and initialize in constructor instead? Doesn't seem to depend on the config at all.
Same as above: need to check `clientResponse.hasResponse()`
Same as above: need to check `clientResponse.hasResponse()`
Some of the internal awkwardness seems to be the result of not having a clear "list of classes" type. Not something we have to do here, but potential room for improvement.
This intermediate `List` is not really useful. We could just change the loop below to iterate over the connector classes and call `getSimpleName()` on each of them
Right now I think we should keep the (high) sleep times as is. But in general we may want to lower the sleep times in this PR. I don't know what a "good" value would be (preferably we'd be able to use `TestUtils.waitUntilTrue` eventually) -- using sleep just s*cks -- but I think Jenkins should be running a bit faster than Travis. Perhaps we should give it a try with `5s` rather than `10s`? That said, we perhaps don't want another iteration on this code, given that the 0.10 vote already started.
I don't understand what this test is doing. Why do we need background clients instead of producing upfront and consuming the data mirrorred at the end of the test? It looks like we are testing the primary->backup scenario but we are restarting the backup cluster. The source connector should not interact with the backup cluster.
Minor: it seems like this test would be a little simpler if you start subscribed to topic1 and then switch to topic2.
Can we use something like `TestUtils.waitUntilTrue`? This approach will make tests unnecessarily slow.
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
nit ```suggestion expectedSensor, StreamsMetricsImpl.CACHE_LEVEL_GROUP, tagMap, hitRatio, HIT_RATIO_AVG_DESCRIPTION, HIT_RATIO_MIN_DESCRIPTION, HIT_RATIO_MAX_DESCRIPTION ); ```
nit ```suggestion expectedSensor, StreamsMetricsImpl.CACHE_LEVEL_GROUP, tagMap, hitRatio, HIT_RATIO_AVG_DESCRIPTION, HIT_RATIO_MIN_DESCRIPTION, HIT_RATIO_MAX_DESCRIPTION ); ```
This approach will be useful sometimes but other times I will want an error on close to be suppressed. This is a common pattern for reading from an InputStream. Once we call close() we have finished our reading and just want to clean up and if the resource has already been closed or invalidated we don't really care. I'm unaware what behaviour results when unsubscribe itself throws an exception and can't write a test at the moment.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
Nice tidy up of this test class :-)
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
typo `operaate` -> `operate`
Ditto on removing before/after
Please remove `, no_log=True` from the username line
Nitpick: space missing before `conditionDetails`.
Please remove `, no_log=True` from the username line
why use `topicName` here? Should it not be `failed: key=X actual=A expected=B...` instead of `failed: key=X <topicName>=A expected=B...`
max timeDifferenceMs later than -> at most ...
Like I wrote earlier, this should just be a map, so duplicates should not be a problem. I think it would be good to do all the validation here. There's no reason not to do it and it makes things more robust if the code is re-arranged in the future.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
max timeDifferenceMs later than -> at most ...
max timeDifferenceMs later than -> at most ...
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
Same here, we can cache the result of `Builder.getPartitions(data)` for re-use.
Thanks @vvcephei -- that is convincing.
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
Hmm. This still has the problem where things can be partially applied, because we have a bunch of `CreateTask` runnables being processed separately. It would be easier to just have a single `CreateTasks` runnable and pass it the map. Then the whole thing could fail with a `RequestConflictException` if any task had a conflict.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
I don't see the point of this.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
Nit: Can we change the wording of this to the following ```suggestion log.debug("{} attempting protocol downgrade and retrying.", this); ```
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Hmm.. Do we know how this is getting propagated in all cases? Some of the responses are handled using a `RequestCompletionHandler`, but NetworkClient currently eats any exception raised from this callback.
Hmm.. Do we know how this is getting propagated in all cases? Some of the responses are handled using a `RequestCompletionHandler`, but NetworkClient currently eats any exception raised from this callback.
It looks like there is an extra whitespace after return.
For this case, we should not get a state store.
For this case, we should not get a state store.
formatting: no need to curly braces
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
I was going to ask why we're using the `test` prefix for a benchmark, but then I realized that many of the kafka benchmarks do that and I somehow didn't notice. :) Given that, it seems fine to leave it like this for now.
This data construction seems better to be put in the `AlterConfigsResponse` constructor.
`start` is not used.
We don't really care about the stack trace here or below, just the message. We know the `StreamsException` is generated from this class and the message is enough to identify the problem. Further, these are done in a retry loop so can become quite verbose if failed multiple times
Thanks for adding coverage for sliding windows.
Nit: would generally prefer to see this made explicit (i.e., `drain` twice) as opposed to loop (which in case of some bug could in the worst case be non-terminating).
nit: can we make this debug level? Otherwise it will make this test a little spammy.
A better test case would be to return the MEMBER_ID_REQUIRED error code. We could then skip SyncGroup and call maybeLeaveGroup. This is the scenario that this patch is trying to fix.
I've removed the Supplier in my polish commit. I didn't found a single use of it and would argue that it is something you can determine when you build the template
nit: line too long
nit: line too long
Nitpick: space missing before `conditionDetails`.
Nitpick: space missing before `conditionDetails`.
Nitpick: space missing before `conditionDetails`.
Can this be made polymorphic instead of actually checking the `PASSWORD` type here? e.g., could we simply always do `newConfig.put(key, entry.getValue().toString())` since `Password.toString()` always hides the value (in contrast to the `value()` method? I don't see a use atm, but keeping this generalizable seems potentially valuable. wouldn't block on this, but it doesn't seem great to have to bake details of the config type into code in the `AbstractHerder` that otherwise doesn't care about it.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
`toString` of `FileChannel` doesn't seem to be useful: ```text scala> FileChannel.open(new File("/Users/ijuma/Downloads/trace.log").toPath) res5: java.nio.channels.FileChannel = sun.nio.ch.FileChannelImpl@591e5fd4 ```
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
"*" is considered "LITERAL" for compatibility reasons
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
We can still set `final` -- note, that `final` implies that the parameter `config` cannot be reassigned to a different `Map` -- the `Map` itself is still mutable though and thus it can be altered within `KafkaConsumer` later on. (Adding `final` is more a question of style here.)
Hmm.. I was looking into how the producer handles various operations after the call to close(). Unsurprisingly, there is a bunch of inconsistency. For send(), as far as I can tell, the logic looks like this: 1. Check whether the sender thread is closed and raise an error if it is 2. Refresh metadata if needed 3. Check if the accumulator is closed To be honest, I don't know why we don't just check if the sender thread has begun shutdown, but perhaps that's a separate issue. For transactional requests, it seems we don't currently do any checking to see whether the producer has been shutdown. At least I couldn't find any checks in `commitTransaction()`. To make this solution work, I think we should have those checks. Basically the user should see some kind of error indicating that the producer has already begun shutdown and the operation is no longer allowed. As it is, they would probably see an illegal state error indicating the transaction already began aborting or something. This could be a simple check in `TransactionManager` if we add a `close()` method as suggested elsewhere.
nit: "didn't went" -> "didn't go"
Can we also include the cause when we throw exceptions? It's not always helpful, but it has been invaluable for debugging many times since we started to include the cause.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
Can we also include the cause when we throw exceptions? It's not always helpful, but it has been invaluable for debugging many times since we started to include the cause.
nit: There is an extra space before `+`.
nit: There is an extra space before `+`.
`long` -> `Long` is a binary incompatible change.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Unify "create task" code with `shouldThrowExceptionIfAnyExceptionsRaisedDuringCloseTopology` -- it's almost the same and both test cases can use the same topology structure.
It seems like we don't need to mention 0.11 here since the requirement for 2.5 is stricter.
I think it would be better to have a test that shows that a new thread that replaced a failed one, actually is able to process records. So, I would let the new thread process some records and then shutdown the client with a normal close. Maybe similar applies to the shutdown tests. First let the client/application process some records and then throw an exception that shuts down the client/application. I guess, this last paragraph is something for a separate PR.
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
Yes that's right, but code-wise if the current restore consumer only contains partitions of standby tasks then the `updatedAssignment.removeAll(closedTaskChangelogs);` below would be a no-op since the `updatedAssignment` would not contain any of the `closedTaskChangelogs` (well, unless we assign the active and the standby of the same task to the same thread, which is even worse).
@dguy you'll need a lock for `putIfAbsent` too since the individual locks in put/get are not sufficient (e.g., value could change in between get and put).
Similarly for `closeDirty` and `prepareCloseDirty`
as above: avoid `/` Update to ``` log.warn("Unable to read '{}{}{}'. Using default inputValues list", "resources", File.seperator, fileName); ```
as above: avoid `/` Update to ``` log.warn("Unable to read '{}{}{}'. Using default inputValues list", "resources", File.seperator, fileName); ```
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
This should go away. `@ConditionalOnClass` already does that.
```suggestion possible_names.extend([context.redirect_list[-1], context.plugin_resolved_name]) ```
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
You can use `EnumMap`, which is a lot more efficient.
As above: add more "randomness"
As above: add more "randomness"
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
I think we should call `deserializer.configure(...)` here
nit: might be better to set end to another timestamp.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
super nit: taskCreationLock --> taskDirCreationLock
The `CachingKeyValueStore` doesn't throw an NPE here, rather `org.apache.kafka.common.utils.Bytes.LexicographicByteArrayComparator.compare` does. We probably should add `Objects.requireNonNull(...)` to `CachingKeyValueStore#put(..)` etc
I now saw that in the consumer tests you use `Duration.ofSeconds(1).toMillis()` and `Duration.ofMillis(999).toNanos()`. This makes it already clearer. I think a variable with a meaningful name for the lower bound would make it even clearer.
I now saw that in the consumer tests you use `Duration.ofSeconds(1).toMillis()` and `Duration.ofMillis(999).toNanos()`. This makes it already clearer. I think a variable with a meaningful name for the lower bound would make it even clearer.
nit: `anf` -> `and`
nit: `anf` -> `and`
again, naming of the test
That's where I'm referring to: `String fieldName = targetField.name();` but I didn't follow too many levels of redirection ...
again, naming of the test
You might want change IntelliJ to use the `java.util.Objects.equals and hashCode (java 7+)` setting when generating `equals` and `hashCode` implementations -- it generates nicer, tighter code that plays better with our checkstyle.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
nit: extra blank line ```suggestion ```
The number has changed and 5 is no longer relevant.
I'm suspicious of summing the various latencies, rather than just measuring the time from the start of the method until now, since it would hide any unexpected sources of overhead.
I'm not too keen on the structure of the JSON, both because the keys vary and because it's not very extensible. I'd prefer something like this: ``` json { "status": "UP", "nodes": [ { "address": "127.0.0.1:7001", "version": "3.0.7" }, { "address": "127.0.0.1:7002", "version": "3.0.7" }, { "address": "127.0.0.1:7003", "version": "3.0.7" } ] } ``` The keys are the same for every node and we can also easily add extra information about a node.
i and uid order inverted
You might consider using `OptionalDouble`.
Makes sense, we can do that later.
Sorry, I found we already log the error in `autoCommitOffsetsAsync`. We should remove the logging here. And make the if condition simpler as: ``` if (future == null || future.succeeded() || (future.failed() && !future.isRetriable())) { onJoinPrepareAsyncCommitCompleted = true; }
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
nit: since the error message says "the elements" shouldn't this check all elements? ```suggestion if not all(val): ``` alternatively, we can leave the if-statement as-is and instead change the error to something like "the first key in the list must not be empty"
nit: add `final` and line too long
Maybe `Producer epoch...`. Also, not sure the exception message adds anything given what's already logged. Maybe we should remove that.
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
nit: We should use `groupId.idValue` here and in the others.
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
I think it would be better to wait until the Kafka Streams client id in state `RUNNING` and then verify if the history of the states transitions after adding the stream thread is first `REBALANCING` and then `RUNNING`. Currently, the order is not verified as far as I can see.
I think it would be better to wait until the Kafka Streams client id in state `RUNNING` and then verify if the history of the states transitions after adding the stream thread is first `REBALANCING` and then `RUNNING`. Currently, the order is not verified as far as I can see.
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
Please remove empty line.
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
Same minor nitpick about whether or not we need to check for an empty group ID.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
If we expect no warmups, we can assert it here with: ```suggestion assertValidAssignment(0, allTaskIds, emptySet(), clientStates, new StringBuilder()); ```
nit: avoid unnecessary reformatting (similar below)
This test fails on the mac on this line as the path is not `/tmp` but starts with `/var/folders...` by changing the assertion to `startsWith("process-state-manager-test Failed to write offset checkpoint file to [` then the test passes
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
`.toString()` unnecessary here are other similar logs.
It seems a bit ad-hoc to have this environmental variable for one test only.
nit: unneeded newline
It seems a bit ad-hoc to have this environmental variable for one test only.
It seems a bit ad-hoc to have this environmental variable for one test only.
Nit, to improve readability and precision, especially around how many Kafka transactions would be used: > Whether to enable exactly-once support for source connectors in the cluster by using transactions to write source records and their source offsets, and by proactively fencing out old task generations before bringing up new ones.
I feel like you're just testing argparse here, and this test can be removed. We don't test parsing any other arguments, since we can assume argparse works as advertised.
nit: extra blank line ```suggestion ```
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
nit: braces unneeded
Is this intentional? cc @enothereska
request1 and request 2 are not used.
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
Ok. Thanks for clarifying.
nit: empty line.
This should be `synchronized` too as you could have other started threads updating the map at the same time. Perhaps just wrap the map with `Collections.synchronizedMap(...)` and then remove `synchronized` from `StreamStateListener.onChange(..)` Sorry for the back-and-forth.
`toString` of `FileChannel` doesn't seem to be useful: ```text scala> FileChannel.open(new File("/Users/ijuma/Downloads/trace.log").toPath) res5: java.nio.channels.FileChannel = sun.nio.ch.FileChannelImpl@591e5fd4 ```
Is this a valid restriction for the broker? Would there be cases where multiple mechanisms may be required? In the original Kafka Security proposal, there was mention of one port supporting multiple SASL mechanisms. I don't know how common that is though. Probably not for this release, but it may be worth thinking about how we would do that in a compatible manner if we decide to do it.
spelling -> recrord -> record
spelling -> recrord -> record
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: move this `if` statement below/above version check on line 62
We should also verify the thrown cause
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
typo: byteArrray -> byteArray
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
nit: single parameter per line
nit: single parameter per line
nit: single parameter per line
ditto on removing before/after.
We should double-check that it's safe to remove this. The [original change](https://github.com/spring-projects/spring-boot/commit/333bc3e8425b0cd36bc93224e6fb2ab810ffe141) suggests that the problem exists with Java 7 and later.
This formatting change is not related with a bug fix, please revert.
req: I think we want to introduce some `acceptableLag` config within which a task is considered caught-up, otherwise this is way too strict. ie the condition should be `lag <= acceptableLag`
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
Ideally, we'd always use brackets on control flow operators.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
Yeah, that would be the closest for primitive types.
nit: remove empty line
`'required': False` is the default so you can omit that. Same for any of the following.
`'required': False` is the default so you can omit that. Same for any of the following.
`removeSensor()` would remove its associated metrics as well, I think we do not need the second call below.
This is a very confusing method. There is a risk that it may be invoked inadvertently when making changes, even though it is meant to be only for tests.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
This is a very confusing method. There is a risk that it may be invoked inadvertently when making changes, even though it is meant to be only for tests.
`removeSensor()` would remove its associated metrics as well, I think we do not need the second call below.
nit: we can use `map#compute` to replace getOrDefault + put.
This is a very confusing method. There is a risk that it may be invoked inadvertently when making changes, even though it is meant to be only for tests.
We should read the metadata inside the while loop since it could change.
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
nit: add a size? There are a few cases in here where we could do this.
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
Why do we have SSL specific methods here? Could we move all the SSL bits into the SSL class? We have fields for the configurations. So we could set them accordingly (without or without SSL) in each concrete class. Then in the base class, we just use the fields to create the clusters without having to know if it's SSL or not.
Why do we have SSL specific methods here? Could we move all the SSL bits into the SSL class? We have fields for the configurations. So we could set them accordingly (without or without SSL) in each concrete class. Then in the base class, we just use the fields to create the clusters without having to know if it's SSL or not.
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
should this be null? perhaps throw an IllegalArgException
I think we're testing `testDir` Occupied here, not `AppDir`.
Extra "for" in "milliseconds for that"
remove try-fail-catch and rewrite to ``` final StreamsException expected = assertThrows(StreamsException.class, () -> collector.flush()); assertTrue(expected.getCause() instanceof TimeoutException); assertTrue(expected.getMessage().endsWith(topic1TimeoutHint)); ```
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Why not check `context.timestamp`? Checking the message of the exception is very brittle.
Thanks for cleaning this up. I still can't read the old code without taking notes...
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
We can use `List<Class<? extends Connector>` to avoid the warning
should be final
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
`<byte[]>` this explicit type is unnecessary
Harmonise with yt-dlp pt2: ```suggestion 'age_limit': 18, ```
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
nit: add `final`
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
This isn't a REST extension necessarily, right? It's also used by Kafka via JMX. I think mentioning `worker restarts` and `rest extension` might be confusing
This isn't a REST extension necessarily, right? It's also used by Kafka via JMX. I think mentioning `worker restarts` and `rest extension` might be confusing
**Do not remove** `_search_regex` part.
Please use hanging indent: ``` self.assertEqual( set(request.META.keys()), {'PATH_INFO', 'REQUEST_METHOD', 'SCRIPT_NAME', 'CONTENT_TYPE', 'wsgi.input'} ) ```
nit: list the members list here would help trouble shoot.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Catching `Throwable` will also catch errors which I don't think we want to do. But I don't even think we want to catch all exceptions and rethrow them as unchecked. The `deleteAllTopics` method is already marked as throwing `Exception`. If anything is thrown, we can let it bubble up and fail the test.
Catching `Throwable` will also catch errors which I don't think we want to do. But I don't even think we want to catch all exceptions and rethrow them as unchecked. The `deleteAllTopics` method is already marked as throwing `Exception`. If anything is thrown, we can let it bubble up and fail the test.
nit: add a size? There are a few cases in here where we could do this.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
nit: There is an extra space before `+`.
nit: could avoid the last space after `is correct.`
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
I think we just want to get rid of the special handling for logical types, but if it stays, the handling here needs to change. Any user defined schema can have a name too.
I think we just want to get rid of the special handling for logical types, but if it stays, the handling here needs to change. Any user defined schema can have a name too.
We typically don't use java serialization. Is Serializable needed? Ditto in a few other classes.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
recommend renaming to `save` with alias to `save_config` for consistency
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
Oh, and a typo which I would like to make KNOWN (or UNKNOWN?! ... I would pick a pun over clarity any day :) )
I fixed this one to use the constant before merging.
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Nice tidy up of this test class :-)
The typo is still there.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
This will cause `TEXT` frames to be unexpected when debug logging isn't available.
This will cause `TEXT` frames to be unexpected when debug logging isn't available.
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
nit: style seems to be to not include braces when there is only one if or else statement
Can you add a period at the end, please.
Can you add a period at the end, please.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
For this specific API, I suspect it is ever commonly used in PAPI, so I'm fine with not supporting it right away, also as a way to encourage users to change code sooner than later, if there's anyone.
Gotcha, I misunderstood the docs and thought it was ~1. Let's keep it as-is
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
We should fix right away -- otherwise it might slip.
I'm unclear with the purpose of this line is -- the "statements" local variable isn't used
We don't want to be converting from int to string in the benchmark code.
We don't want to be converting from int to string in the benchmark code.
Should this ever happen? If it does happen should we consider it a bug? Ditto for the other `hasNextCondition`.
hm.. maybe I just did not notice `config.timeWindowMs`. All good now.
hm.. maybe I just did not notice `config.timeWindowMs`. All good now.
Right, sorry I misread that line.
hm.. maybe I just did not notice `config.timeWindowMs`. All good now.
We don't want to be converting from int to string in the benchmark code.
hm.. maybe I just did not notice `config.timeWindowMs`. All good now.
Right, sorry I misread that line.
~~Maybe a list comprehension here too.~~ EDIT: Forget it, I misread the double for-loop.
Would be better to describe what `cases` are referring to.
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
`long` -> `Long` is a binary incompatible change.
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
That's a good point that the same taskID may change with different partitions. I think what I'm trying to explore is whether we can make the logic a bit clearer to read while being protocol agnostic. That is, we can either 1) reason about the source-of-truth for added / revoked / remained tasks for both active and standby in `assignor#onAssignment`, and then we do not need to rely on the parameters passed in the `listener#onPartitionsRevoked / Assigned` at all. 2) rely on the `listener#onPartitionsRevoked / Assigned` to get the list of revoked / remained / added tasks.
I don't think that will work, because the metadata object that is maintained in AdminClientRunnable does not fetch information about any topics. In general the way the Metadata object works is a very poor fit for AdminClient-- it was designed for producers and consumers, where you have long-running subscriptions and so forth. It is much simpler and better just to make the metadata call here-- we can always optimize this later with a cache if needed.
Just one minor point, if we don't have EOS enabled, we could end up pulling duplicates in some tests like the `StreamsUpgradeTest::upgrade_downgrade_brokers`
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
We don't provide the error message in any other case. Should we remove this one for the time being? I think that it is a good idea but only if we do it across the board.
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
I think this says, "we are looking for a parent node that is among my parent nodes". It seems like we can generalize this logic by not assuming there's a single parent node at all.
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
Not sure you need to initialize the factory every time there.
use `try-catch` instead of `expected` annotation -- not a single line test.
Minor: it seems like this test would be a little simpler if you start subscribed to topic1 and then switch to topic2.
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
Minor: it seems like this test would be a little simpler if you start subscribed to topic1 and then switch to topic2.
We probably want another constructor `ChannelState(State state, String remoteAddress)` for non-authentication-failure states where we store `remoteAddress`.
This causes a checkstyle failure
nit: `lastCommitMs + commitTimeMs < now` -> `now - lastCommitMs > commitTimeMs` IMHO, easier to read this way.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Looks good. I like the additional checking that you're doing here.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
We should pass in `record.topic()` instead of `""` into `deserialize`.
Same minor nitpick about whether or not we need to check for an empty group ID.
nit: we tend to have a new line at the end of files
We could make this field access `public`
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
`Metadata.add` should also not allow a null `topic` either. Also, we provide an error message if a user provides a null `topic` here.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
nit: naming -> `shouldAcceptDefaultBufferSizes()` Also, I am wondering why we check for default buffer size? The ticket was about the issue, that `-1` was not accepted. Thus, while having this test is ok, we should actually test for `-1` to have a test that covers the reported issue.
I'm fine with these as is, but you could also change the methods to be `static` in `Worker` and accept the `WorkerConfig` as a parameter since that's the only class member they use. Would get rid of all the distracting mocks and expect calls and focus the tests on the key functionality of those methods.
nit: 'else' can be dropped
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
Since this is usually the entry point where users would call `toString`, the indent is used for wrapping it. For example, `toString()` prints ``` Kafka Streams Thread Tasks Topology States ``` `toString(">")` prints ``` >Kafka Streams > Thread > Tasks > Topology > States ``` We do not need to let users override the internal ones, only the entry point of nested prints.
`needCommit` -> `needsCommit`
Actually I'm not sure why we need this additional block if we are already holding the lock. The predicate wouldn't be used after this method returns.
Actually I'm not sure why we need this additional block if we are already holding the lock. The predicate wouldn't be used after this method returns.
Actually I'm not sure why we need this additional block if we are already holding the lock. The predicate wouldn't be used after this method returns.
Actually I'm not sure why we need this additional block if we are already holding the lock. The predicate wouldn't be used after this method returns.
This could be final.
nit: Please fix code style.
Nit: somehow I don't like `blah`. Otherwise LGTM
I think this would be clearer if called `isSendToPartitionAllowed`. At first I thought this method was sending to a partition. :)
I think this would be clearer if called `isSendToPartitionAllowed`. At first I thought this method was sending to a partition. :)
nit: unneeded newline
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Same question here as earlier about the `Locale`
This field is not used, we can remove it.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
Well, that's bad. The `Transport` instance is never closed. `JavaMailSenderImpl#connectTransport` looks like a good fit for what you're doing (relying on the plain `connect` does not seem such a great idea either). Unfortunately it's protected but not rocket science either. I guess you need a `Transport#close()` class in a guarded finally block code.
This may double-notify the child in case a predicate returned false in onNext, breaking the event semantics. In the previous version the if check on status.get() was correct as in case it was set to false, it means a previous onNext call was already sent out the false value and completion signal.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
If I change the name of the property source to be something else than this, the test fails. The `PropertySource` implementation and its name are irrelevant for this, it could be anything.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
The advantage of using `ConfigDef.validator` on the `response.http.headers.config` config key is that this constructor call would throw an exception if any invalid value is used, and much sooner, too.
If we swallow the exception here, and the test always throws an IO exception, we will never notice. I guess it would be better to use `fail()` with a message.
If we swallow the exception here, and the test always throws an IO exception, we will never notice. I guess it would be better to use `fail()` with a message.
This is an internal class -- no need to mark as deprecated.
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
@original-brownbear I understand that part, but IMHO it's best if we stick to some basic guidelines for our tests/benchmarks. To reduce the GC impact how about we decrease the cache size to 5, and the number of records to insert 25 or so? Or just create an array inline with the keys and declare as a private variable? Either way, we should be able to do the work in the `setUp` method.
I fixed this one to use the constant before merging.
I fixed this one to use the constant before merging.
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
nit: should be `ConnectHeaders`. *probably* would be easy to figure out, but better to just get it right :)
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
The protocol behavior is that `null` is valid while we use a default empty string so that it's never seen by users. The generated protocol classes definitely change behavior here as it caused a previously passing test to fail with a NPE. I'll share the details with you offline.
retainLatest() and this method have a lot in common. We could potentially refactor it, but not too concerned if its left as-is.
This doesn't seem to be used.
Ditto on removing before/after
Not sure. PENDING_SHUTDOWN indicates a clean shutdown while this lets the thread fail.
Same question here about just using a static ConfigDef instead of a static method.
nit: should be `ConnectHeaders`. *probably* would be easy to figure out, but better to just get it right :)
nit: braces unneeded
It would be nice to have a unit test for this.
Not mandatory, but a good practice: a trailing comma here too ;-) ```suggestion ), ```
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
req: The names of this method and the previous method should be switched.
Nit: "For instance, the transactional APIs require brokers with version 0.11.0 or newer."
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
`self.routing` is potentially `None`.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Should we get a `seed` value and log it (to allow reproducing if the test fails)? ``` final long seed = new Random(System.currentTimeMs).nextLong(); log(seed); final Random rand = new Random(seed); ```
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
I see the problem with original approach after looking your test case. Now I think the new approach is correct.
nit: move parameter to it's own line (same below)
I see the problem with original approach after looking your test case. Now I think the new approach is correct.
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
what about `assertEquals("consumer record size is not zero", 0, records.count());`? It can also be applied in a few other places
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
Let's check that `previouslyAllocated`'s capacity is `batchSize` else `buffer.limit(sizeBytes)` is going to throw with a less useful stacktrace.
Sorry, missed this earlier: We are creating a new `selector` in `checkAuthentiationFailed`, so we should ensure that the previous selector is closed. You could call `selector.close()` just before calling `checkAuthenticationFailed` here and also a couple of lines below.
Nit: would generally prefer to see this made explicit (i.e., `drain` twice) as opposed to loop (which in case of some bug could in the worst case be non-terminating).
Let's check that `previouslyAllocated`'s capacity is `batchSize` else `buffer.limit(sizeBytes)` is going to throw with a less useful stacktrace.
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Also? ```suggestion assertEmptyRecords(); assertNoEmptyDeques(); ```
This name seems backwards.
Do we need `invalidData`? Seems like we can just do this: ``` if (i == recordIndex) { throw new SerializationException(); } else { i++; return super.deserialize(topic, data); } ```
Do we need `invalidData`? Seems like we can just do this: ``` if (i == recordIndex) { throw new SerializationException(); } else { i++; return super.deserialize(topic, data); } ```
I vote yes for this. I think if we use this for writing snapshot from the state machine, then minimum size is a more interesting metrics for flushing to disk vs lingerMs. If we implement this so that either one has to be true then the client can set the `lingerMs` or `minSize` to MAX_VALUE if it wants to ignore those values.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
`endOffsets.get(topicPartition)` can be replaced by `offset`
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Nit: If we do fix up the above example of this it makes sense to fix this up too.
For this case, we should not get a state store.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
`info.getProperty(â¦)` can return `null` when using `redisNode.asString()` because of the execution of the `INFO` command. `INFO` is executed only on master nodes, not on slaves. `clusterGetNodes()` returns all nodes. Passing `null` into `withDetail(key, value)` leads to an `IllegalArgumentException`. I'd not put too much knowledge about cluster execution in here but rather iterate over the `info` keys (e.g. filter on suffix `"." + VERSION`) and use the keys from `info` to retrieve data. I'd also propose adding nodes as list to the Redis info as topology details are valuable in a health indicator.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Nitpick: if you pass the deserializers via the constructor, it's a bit more concise. This applies to all tests.
I think it would be better to wait until the Kafka Streams client id in state `RUNNING` and then verify if the history of the states transitions after adding the stream thread is first `REBALANCING` and then `RUNNING`. Currently, the order is not verified as far as I can see.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
bit-nitpick :) ``` // modulo 2 operation if ((keyValue.length & 1) != 0) ``` most definitely optimized out by JIT because the divisor is known (`2`). Is it too hard to read? Sometimes it's good to train ppl who read the code by example. Can't be more nitpicking than that and if you want to keep uniformity with other versions of `getTags` elsewhere never mind. Not 100% sure either, leaving here to ask what you think in general for such optimizations that are JIT optimizable too.
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Instead of `new MetricName("batch-size-avg", "producer-metrics", "", tags)`, I think we should use `metrics.metricName("batch-size-avg", "producer-metrics")`, right? The doc says `Please create MetricName by method {@link org.apache.kafka.common.metrics.Metrics#metricName(String, String, String, Map)}`. Same for other MetricName instantiation.
That test does nothing. Verify that the repository was called with the right argument would be in order: ``` verify(this.repository).deleteById(session.getId()); ```
That test does nothing. Verify that the repository was called with the right argument would be in order: ``` verify(this.repository).deleteById(session.getId()); ```
Also mention that this returns by topic name if the request used topic names. otherwise returns null.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Same question here as earlier about the `Locale`
super nit: extra blank line
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
super nit: extra blank line
`InternalProcessorContext` is already public interface but it's in `internals` package, so I figured it is okay? Anyways, this is not much blocking this PR, so feel free to merge it anyways and we can keep discussing here while you merge.
bit-nitpick :) ``` // modulo 2 operation if ((keyValue.length & 1) != 0) ``` most definitely optimized out by JIT because the divisor is known (`2`). Is it too hard to read? Sometimes it's good to train ppl who read the code by example. Can't be more nitpicking than that and if you want to keep uniformity with other versions of `getTags` elsewhere never mind. Not 100% sure either, leaving here to ask what you think in general for such optimizations that are JIT optimizable too.
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
typo: we want to test the **case** that poll() returns no records.
this overwrite of mm2config should go in the setup method, IMHO
Colorize is not tested currently: http://ci.djangoproject.com/job/Django%20Coverage/HTML_Coverage_Report/_var_lib_jenkins_jobs_Django%20Coverage_workspace_django_utils_termcolors.html#n43 So testing the return value makes sense for me.
nit: ```suggestion log.warn("Thread " + streamThread.getName() + " did not shutdown in the allotted time"); ```
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
`To query state stores, it's required to first start Kafka Streams via {@link KafkaStreams#start()}. You can retry to query the state after the state transitioned to ...`
The parameters can be `final`.
I don't know what has changed here.
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
again, naming of the test
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
nit: maybe iterate over `entrySet()` instead.
Looks good. I like the additional checking that you're doing here.
`windowSize` should be `Duration`
Right, sorry I misread that line.
Nit: why not use `boolean`
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
We can probably output the error instead of the error code (the field name should be changed appropriately.
Use single quotes.
Map.Entry<String, String> to avoid the check below
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
this could be: `assertThat(serializer.serialize(topic, null), nullValue())`
Also not clear why "numSegments - 1" here.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
This code doesn't is not equivalent right? `RabbitListenerRetryTemplateConfigurer()` does more than what you removed as far as I see.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Add a check to verify, whether the iterator has no more elements.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
spelling -> recrord -> record
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
I am must wondering, if this should go into it's own test class `KStreamGlobalKTableJoinTest.java` ? Similar below.
I am must wondering, if this should go into it's own test class `KStreamGlobalKTableJoinTest.java` ? Similar below.
This was probably left by mistake.
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
I think this category can be dropped
I think this category can be dropped
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
"*" is considered "LITERAL" for compatibility reasons
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
Still not sure about the name since this already includes more than just `cipher`. But since it is an internal class, it should be ok to leave it as is for now.
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
Thanks. Not a blocker.
I think we should call `deserializer.configure(...)` here
Thanks. Not a blocker.
How about "runs an external command for the worker."
Yes, this should on an internal package (eg `common.internals`).
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
nit: parameter/line formatting
nit: parameter/line formatting
`needCommit` -> `needsCommit`
This check `records.size() < offset` seems a bit sketchy to me. Basically we are assuming that the input topic `data`'s starting offset is always 0, and there is no "holes" in the topic partitions so that the `offset` indicates the number of records we can read from the input topic. Maybe a more robust way to do that would be 1) read the input topics `data` and optionally `repartition` based on `withRepartitioning`, stop when the current record's offset is equal to or larger than the committed offset, and remember the number of records; 2) read the output topics (again optionally `repartition`) from the beginning to the end (use `seekTo`), and check that the number of records are the same as the number of records read from the input. Then we do not need to truncate, and also in verification we do not need to check list size again since they are already checked here.
`needCommit` -> `needsCommit`
More specifically, during `onPartitionsRevoked` the restore-consumer is assigned either: 1) with active restoring task partitions, or 2) with standby task partitions With 1), upon `onPartitionsAssigned` we would continue restoring active tasks while no standby tasks would be processed yet, hence we could update restore-consumer with revoked partitions and newly added task partitions that needs restoring; With 2), upon `onPartitionsAssigned` there are two cases: 1) if there are newly added task partitions that needs restoring, we should "revoke" all standby tasks since we need to first go to restore those active tasks; 2) no new active tasks need restoring, we should only "revoke" those standby tasks that are re-assigned.
Yea, my suggestion would be to reuse the existing constructor as the construction of the `AlterConfigsResponseData` seems non trivial for a caller to do, compared with passing a map of errors.
@sutambe I also think we should mention the scenario that a Record is added to a batch that is about to expire.
We can keep them together ```suggestion with self.subTest(DEBUG=debug), self.settings(DEBUG=debug): ```
We don't even start the Executor so there is nothing that would start it. We have used that approach in Hystrix for years, and there we used the `reset` model rather than shutdown/start: https://github.com/Netflix/Hystrix/blob/master/hystrix-core/src/main/java/com/netflix/hystrix/Hystrix.java#L42 If we completely shutdown the Executor, and then lazily recreate it, there is nothing to start threads, so it would be safe.
same for functions below
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
This should return `-1` as old `BadValueTransformer`
I wonder if we ought to just assume that the error goes at the top-level. It's a little weird to receive a partition-specific error code here and then assume that it should be used for _all_ partitions.
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
This should return `-1` as old `BadValueTransformer`
This should return `-1` as old `BadValueTransformer`
I hope we can get rid of those conversion in the future :)
the `try{...} finally` has been removed
The protocol behavior is that `null` is valid while we use a default empty string so that it's never seen by users. The generated protocol classes definitely change behavior here as it caused a previously passing test to fail with a NPE. I'll share the details with you offline.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
May be None.
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
the `try{...} finally` has been removed
Got it, thanks for the explanation.
OK, let's keep the change to that one field for now.
to me it seems like we can't possibly know what the constraints of all reporters would be and they don't provide an interface for validation, so it should be up to them to figure out how to substitute. but i've also asked some other folks to maybe chime in here who may have better context on how we've handled this elsewhere.
Hmm, this doesn't need to block merging this, but we should think carefully about doing delay this way. The rest of Connect avoids trying to rely on Java's `interrupt` behavior because it's not really a reliable way to *actually* interrupt threads, and in a system where there are pluggable components that are allowed to block indefinitely, relying on functionality that most Java developers don't understand well probably isn't going to work all that well. It may not have actually gotten to a KIP, but there was at least some discussion on a JIRA somewhere about making connect perform interrupts in addition to the basic task `stop()` calls it already does, but it doesn't currently do this. For anything that can end up with pretty long sleep periods, we should try to make sure there's a good way of interrupting it and moving on (e.g. so rebalances wouldn't get delayed because there's a connector that's encountering errors). At a minimum, since we don't do interrupts currently, I think we wouldn't interrupt this code currently. The other approach we use elsewhere is to `wait` on a monitor so we can set a flag and interrupt with `notify` and have it bail out immediately.
I know the naming thing has bit us in the past, is this same approach used elsewhere and/or how was it decided on? Specifically, metric name constraints really shouldn't be JMX specific if that is the case here, despite the fact that the metrics is so obviously JMX-inspired. I can easily find https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/metrics/KafkaMetricsGroup.scala#L46 but nothing else. Have we not had the same problems because metrics w/ topic names in them already have constraints on the naming? If I am remembering correctly, I think maybe both @gwenshap and @junrao were involved in some discussions, I think `-` vs `_` was a problem at some point? Maybe one of them could chime in here.
I know the naming thing has bit us in the past, is this same approach used elsewhere and/or how was it decided on? Specifically, metric name constraints really shouldn't be JMX specific if that is the case here, despite the fact that the metrics is so obviously JMX-inspired. I can easily find https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/metrics/KafkaMetricsGroup.scala#L46 but nothing else. Have we not had the same problems because metrics w/ topic names in them already have constraints on the naming? If I am remembering correctly, I think maybe both @gwenshap and @junrao were involved in some discussions, I think `-` vs `_` was a problem at some point? Maybe one of them could chime in here.
nit: we can throw illegal-state if the state() == RESTORING since it should never happen.
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
nit: conventional in Kafka to drop `get`. Same in `getLastAckedSequenceNumber`
nit: conventional in Kafka to drop `get`. Same in `getLastAckedSequenceNumber`
reordering (chop dash)
Use single quotes consistently.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
prop: Should we use `MockTime` here? prop: Could you use a more meaningful name for `ts`? The above is also valid for the overload.
nit: Indicate that this needs deep iterations on the entries.
Lookup plugins run on the controller. The minimum python version for the controller is python 2.6. So str.format() can't use "{}". The easy workaround is to use "{0}" and "{1}" instead.
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
reordering (chop dash)
Use single quotes consistently.
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
The importance of the topic name depends on the serializer being used. For example, if you are using an Avro Serde with the Schema Registry, then the topic might be the subject name. So in this case it is quite important.
nit: could be set to final and refactor as: ``` final Integer partition; if (partitioner != null) { final List<PartitionInfo> partitions = producer.partitionsFor(topic); if (partitions.size() > 0) { partition = partitioner.partition(topic, key, value, partitions.size()); } else { throw new StreamsException("Could not get partition information for topic '" + topic + "' for task " + taskId + ". This can happen if the topic does not exist."); } } else { partition = null; }
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
Hopefully, there's no danger of these counters overflowing, but regardless, I think the math would still work out if we did reset them here.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Thanks for the explanation. Make sense.
format: ``` if (exception != null) throw exception; ```
Why we need to call `streams.close()` inside the function given they are always called in `tearDown`? Ditto below.
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
Why we need to call `streams.close()` inside the function given they are always called in `tearDown`? Ditto below.
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
Sorry ... I'm not shipping code with `Thread.stop` in it.
Maybe it's worth not including this constructor. It's only used in tests and it's generally a good idea to provide a message with the exception.
nit: I don't spot any, but safer to avoid typos by just having constants for these
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
Hmm, I think I'd prefer two separate maps with two separate fields in `LoginManager`. It makes things more explicit and easy to understand in my opinion (even though it's a bit more code).
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Do we _know_ that it will resolve the problem? Maybe better: ``` Changing the location of state.dir may resolve the problem ```
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
nit: These are the same descriptions as above. How about creating a static `Field` instances or at least extracting the message.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
just noticed this - I think we want `clean_shutdown=False` here to ensure we really kill the process if the normal attempt to gracefully shut it down failed
Thanks for that note ewen. I learned something!
IMO a single test with custom `too_many_forms` and `too_few_forms` is enough.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
Shouldn't this be in the contract of `Utils.newInstance` to not return some other class that doesn't match? I think this is pulled from `AbstractConfig` which makes sense for consistency, but I don't get why `Utils.newInstance` would ever return a value with an invalid type.
Shouldn't this be in the contract of `Utils.newInstance` to not return some other class that doesn't match? I think this is pulled from `AbstractConfig` which makes sense for consistency, but I don't get why `Utils.newInstance` would ever return a value with an invalid type.
`expireMs` should probably be a `long` since we use it as if it's never null a few lines below.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
Same as before, `new Integer[]{}' not required for `Arrays.asList`.
Same as before, `new Integer[]{}' not required for `Arrays.asList`.
Catching `Throwable` will also catch errors which I don't think we want to do. But I don't even think we want to catch all exceptions and rethrow them as unchecked. The `deleteAllTopics` method is already marked as throwing `Exception`. If anything is thrown, we can let it bubble up and fail the test.
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
nit: add `final` and put single parameter per line
Do you want to prevent NPE? Maybe easier to rewrite to ``` if (props != null && StreamsConfig.OPTIMIZE.equals(props.getProperty(StreamsConfig.TOPOLOGY_OPTIMIZATION))) { ```
Do we need to use AtomicReference here? Seems we only call `maybeInvokePartitionsRevoked` once per branch
It seems you can move this line after line422.
```suggestion * A byte array comparator used on lexicographic ordering, but only comparing prefixes. ```
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
This seems random and can lead to flaky tests. So there is no way to measure latency while Trogdor task is running? For the rate limit test below we do wait for task to run.
Seems like we don't really need inheritance here. Can just have an "if" statement that checks if we have a group or not
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
I fixed this one to use the constant before merging.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Suggestion: I am not sure which terminology we use elsewhere, but "changelogConfig" may suggest to the average reader that there's a separate "changelog" concept that they may have never heard of. It's simply a topic configuration. I'd suggest to rename `changelogConfig` to `changelogTopicConfig` or the shorter `topicConfig`.
`HeaderConverter` and this method don't exist prior to AK 1.1.
Maybe this looks better? ```suggestion // we're at the end of the input. if (queryResult.getResult().value() == batch1NumMessages - 1) return; ```
This field is not used, we can remove it.
Same as above: need to check `clientResponse.hasResponse()`
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
variable exception unnecessary
```suggestion // TODO K9113: this is used from StreamThread only for a hack to collect metrics from the record collectors inside of StreamTasks ``` Just marking this for later follow-up.
Yeah, we're still feeling out the best patterns for handling older versions.
Nit: ```suggestion throw new ConfigException(String.format("Invalid header name '%s'. " + "The '[header name]' cannot contain whitespace", headerName)); ```
Longer explanation from before: https://github.com/apache/kafka/pull/645#discussion_r47489229
SG, thanks for the explanation!
SG, thanks for the explanation!
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
Add a reference to KIP-511 here
Ahhhh damn, I think you've mentioned that problem before What if JMH would be event/callback based so we could benchmark async code like RxJava in a reactive manner? ie: ```java @Benchmark public void flowable(BenchmarkObserver benchmarkObserver) { flowable.subscribe(this, Functions.emptyConsumer(), new Action() { @Override public void run() throws Exception { benchmarkObserver.onComplete(); } }); } ```
Using generic types instead of raw types for collections is preferable (we can fix elsewhere in the file too) ```suggestion List<?> items = (List<?>) value; ```
req: drop the `!caughtUpClients.isEmpty()` check here, if it's in the map it should have at least 1 caught-up client
I thought `formset = ChoiceFormSet(self.data, auto_id=False, prefix='choices')` could go in `setUp()` also.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
IIUC, spotbugs complained if these were not here.
Any reason you change to import all classes under `java.util`? I think we should import what we used in this class only.
As above for this and the next ctor
Thanks for the explanation. It seems like `purgeLocalStreamsState` should really be using `java.io.tmpdir` instead of `/tmp` if it wants to have that safety net.
It would be nice to have a unit test for this.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
We should probably check that `clientId` is still null.
Looks good. I like the additional checking that you're doing here.
Ditto here, we can use AssertionError
nit: ```suggestion final KafkaMetric metric = metric("prefix-scan-rate"); ```
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
Could we just add one more boolean condition into the filter and check whether `changelogsWithLimitOffsets` is empty or not.
Could we just add one more boolean condition into the filter and check whether `changelogsWithLimitOffsets` is empty or not.
To be clear, according to `StreamsConfig`, we do NOT allow `max.warmup.replicas = 0`. It must at least be 1. Or was your statement hypothetical, that it would be OK to allow it? Anyway, I am in favour of keeping the `> 0` check here.
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
If we do not expect this to happen. Shouldn't we throwI IllegalStateException? In this case, if the broker returned a replica that is not in the request, the broker may have somehow misplaced a replica. We should probably alert in this case.
If we do not expect this to happen. Shouldn't we throwI IllegalStateException? In this case, if the broker returned a replica that is not in the request, the broker may have somehow misplaced a replica. We should probably alert in this case.
Thanks for the discussion, all. One thing to note is that this config has "no" impact on high availability. Anyone who wants HA would configure num.standby.replicas, and this config applies on top of that one (for this reason, I like the name you picked. It is "extra".) I think you can make a case for per-node or per-cluster, but if we assume we only want to add one config, I think per-cluster is more valuable, since it lets you protect the brokers from overload, which a per-node config may not. Regarding whether we set the default limit low or high, I'd advocate for low. Some clusters are undoubtedly running close to the limits of their disk space or broker capacity, so suddenly letting every node double its traffic would result in serious operational consequences. On the other hand, if we start out low, then the probability of a crash becomes much lower, and the only problem is that the overall balancing process takes a long time. But, since the config is set low, there's a low impact on processing capacity while it's happening, so maybe there's no real impact over that long time. If you buy the argument that a low default is good, then the obvious choice is "1", but that would take a _really_ long time to complete balancing. The default of "2" is basically a compromise. It lets you balance twice as fast, and it's "probably" still low enough to cause a problem for no one. "5" also seems fine-ish, but the farther from "1" you move, the riskier the choice is. One final thought, when you say that some people would "need to change" the config, say from the default (2) to MAX_VALUE... It seems like this population is restricted to the people who really need to make sure that balancing happens absolutely as fast as possible (maybe because their application can't keep up unless the whole cluster is processing, or because they're scaling up to cope with a spike in input data). Hopefully, these people know that they need extra horsepower and are motivated to read the docs and locate the config they need to change. Also, hopefullly, this isn't the common case.
Maybe we could use a different value here.
Maybe we could use a different value here.
There are some request header tests in `RequestResponseTest`, we should move them here so that we can find them all in one place.
There should never be multiple requests, right? If there were, a second request might arrive between 168 and 169, violating the desired property. In that case, we should grab a lock instead. As long as there's only one requesting thread, and it always waits for the commit right after requesting, then we should be good.
ok - leave it as is i guess
You should use try with resources here too.
Do we need to check if it is null here? I think it is probably ok if it doesn't throw any exceptions? Obviously it would be better if we could check that `loginManger.release()` was only called on the first invocation, but i appreciate that involves further refactoring
Sorry for that -- You are of course right. `final` only for iterator loops...
Sorry for that -- You are of course right. `final` only for iterator loops...
You should use try with resources here too.
You should use try with resources here too.
Sorry for that -- You are of course right. `final` only for iterator loops...
You basically specified the `differentName` check twice, in this and in the previous method. I would specify the following tests into separate methods: - same - different names - different topics - different patterns Makes the test better readable and avoids repetitions of checks.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: Indicate that this needs deep iterations on the entries.
@ijuma Sorry, I don't know of a standard way of doing this,
I have the same thoughts as above for commit time.
`doWork` is just one iteration. `ShutdownableThread` has the loop. I'm ok with the change, but we probably will need to copy over some of the shutdown logic.
There are two issues I see with this: In terms of code, the `elif key=='TEST'`executed for every key that isn't TEST_\* is a little funny. In terms of semantics, you assume that not including a value in the dict is the same as setting it to None, which isn't true (e.g. `TEST['CREATE_DB']` is a Boolean which defaults to True ). I think it is better to do something like (untested) ``` python test_settings = conn.setdefault('TEST', {}) old_test_settings = {} for key, value in six.iteritems(conn): if key.startswith('TEST_'): new_key = key[5:] new_key = self.TEST_SETTING_RENAMES.get(new_key, new_key) old_test_settings[new_key] = value if old_test_settings: if test_settings: if test_settings!=old_test_settings: raise ImproperlyConfigured(...) else: #not test_settings test_settings = old_test_settings warnings.warn(...) # now test_settings can be used ``` This doesn't pin exactly any mismatch, but that can be done only when an error has been detected (and then TEST_SETTING_RENAMES_REVERSE may still be useful)
There are two issues I see with this: In terms of code, the `elif key=='TEST'`executed for every key that isn't TEST_\* is a little funny. In terms of semantics, you assume that not including a value in the dict is the same as setting it to None, which isn't true (e.g. `TEST['CREATE_DB']` is a Boolean which defaults to True ). I think it is better to do something like (untested) ``` python test_settings = conn.setdefault('TEST', {}) old_test_settings = {} for key, value in six.iteritems(conn): if key.startswith('TEST_'): new_key = key[5:] new_key = self.TEST_SETTING_RENAMES.get(new_key, new_key) old_test_settings[new_key] = value if old_test_settings: if test_settings: if test_settings!=old_test_settings: raise ImproperlyConfigured(...) else: #not test_settings test_settings = old_test_settings warnings.warn(...) # now test_settings can be used ``` This doesn't pin exactly any mismatch, but that can be done only when an error has been detected (and then TEST_SETTING_RENAMES_REVERSE may still be useful)
I think what you have here works fine. Thanks @umesh9794 for your PR.
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
Could also do the following to be a bit more succinct: ```suggestion assertEquals(Schema.Type.INT32, transformedSchema.field("date").schema().type()); ```
Is the change in behavior intentional? `SecurityException`, which was previously caught and logged, is an instance of `RuntimeException`.
previous message => previous receive
I submitted a PR for KAFKA-2711. I think we do need clientPrincipalName, and I hope this is clearer with the changes in that PR: https://github.com/apache/kafka/pull/390
What's the purpose of this warning? It doesn't seem needed.
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
```suggestion * Options for {@link Admin#electLeaders(ElectionType, Set, ElectLeadersOptions)}. ```
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
Could store `entry.getKey()` in a local variable since it is used several times
This is the default.
```suggestion /** * The value of {@link StreamsConfig#APPLICATION_SERVER_CONFIG} configured for the Streams * client. * * @return {@link HostInfo} corresponding to the Streams client */ ```
```suggestion /** * Task ID of the task. * * @return task ID consisting of subtopology and partition ID */ ```
Yes, we could add `ignoredExtensions` and include that in the log in the server.
The restore consumer needs to override one param: `consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");`
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
I think the basic idea makes sense and is what I was expecting. It might not feel too elegant, but I think a simple approach is best initially. An interesting point to consider is what would happen if an offset fetch is in-flight while a rebalance is in progress. When it returns, the offsets may be stale. I am wondering if it makes sense to fence the response using the group generation. In other words, we record the generation at the time of the request and then verify when we receive the response that it matches the current group generation.
What's the purpose of this warning? It doesn't seem needed.
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
Not really necessary here to check isUnsubscribed. If the child unsubscribes, it is propagated to the upstream anyway up to the producer (i.e., from, subject, etc.) which will check isUnsubscribed.
Nitpick: if you move the fail inside the `try`, then you no longer need the `return` in the catch. This applies to a few other tests too.
> I felt the same, but I picked this approach to make less changes in the code, since I am beginner here. That's fair. However, we should not "optimize" for fewer changes but for better code. :) > But, I need to give a thought on kind of prefixes we should use to make it unique for various fail cases. `validateMillisecondDuration()` will just add the prefix. Each called can pass in whatever prefix is suitable for it.
I think we're testing `testDir` Occupied here, not `AppDir`.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Ah, you are right. Sorry.
Ah, you are right. Sorry.
Similarly, I think the password in the URI should win so it should be `password`.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
nit: There is an extra space before `+`.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
nit: move `process()` to next line (easier to read)
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
Should we really catch NPE here? It seems like if the user wants to return a non-null mapped key from a null key, then they should handle the null case specifically in their `keyMapper` and not just throw an NPE. In general, an NPE is a sign that something has gone wrong. I would be pretty surprised if I threw an NPE explicitly in my user code and it just got swallowed and interpreted as if I had actually returned null.
I think `update the index` could be made clearer since the `DataInput` interface doesn't mention an index. Same for other similar cases.
It seems that the checkstyle failed but all unit tests have passed. I can modify the code slightly to fix the checkstyle failure before merging it.
Pls use caps :) (see your `ErrorReporter` above).
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
`NEO4J` is not needed. `neo4j` entry will be inferred from `Neo4jHealthIndicator`, can be replaced by `nodes`? Additionally, all entries in the result shouldn't be added to the detail.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
`NEO4J` is not needed. `neo4j` entry will be inferred from `Neo4jHealthIndicator`, can be replaced by `nodes`? Additionally, all entries in the result shouldn't be added to the detail.
rewrite test as above using `assertThrows()`.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
There are two issues I see with this: In terms of code, the `elif key=='TEST'`executed for every key that isn't TEST_\* is a little funny. In terms of semantics, you assume that not including a value in the dict is the same as setting it to None, which isn't true (e.g. `TEST['CREATE_DB']` is a Boolean which defaults to True ). I think it is better to do something like (untested) ``` python test_settings = conn.setdefault('TEST', {}) old_test_settings = {} for key, value in six.iteritems(conn): if key.startswith('TEST_'): new_key = key[5:] new_key = self.TEST_SETTING_RENAMES.get(new_key, new_key) old_test_settings[new_key] = value if old_test_settings: if test_settings: if test_settings!=old_test_settings: raise ImproperlyConfigured(...) else: #not test_settings test_settings = old_test_settings warnings.warn(...) # now test_settings can be used ``` This doesn't pin exactly any mismatch, but that can be done only when an error has been detected (and then TEST_SETTING_RENAMES_REVERSE may still be useful)
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
nit: add a size? There are a few cases in here where we could do this.
I think we should call `deserializer.close()` here
"InMemoryKeyValueIterator" -> `getClass().getName()
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
`.toString()` unnecessary here are other similar logs.
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
Again, lines L#118 to L#123 can be replaced by: ``` assignment.keySet().retainAll(userAssignment); ``` same effect, as we want the intersection of `assignment` and `userAssignment`
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
`.toString()` unnecessary here are other similar logs.
This line is failing checkstyle. I think we need a space after the first semicolon.
Same thing about the copyright.
@garyrussell and I had a little chat offline and I shared having two properties for the same feature was a bit odd. Gary said he'd add an enum in Spring AMQP instead so we'll have to rework this PR to use that. Wondering if switching a property's type in a feature release is acceptable so flagging for team attention.
A common pattern for classes like this without any state is to create a static instance. ```java public static final UnknownAddressSpec INSTANCE = new UnknownAddressSpec(); ```
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
nit: remove empty line
Matching empty string is senseless.
Why do you remove this check? A `TimeWindow` should not allow this case.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
As discussed in the JIRA, I still think we should use `FileChannel.open`.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
We should use try-with-resources here (for `DataInputStream`).
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
I would move all of these apart from the first two to the declaration of the fields themselves.
Not really necessary here to check isUnsubscribed. If the child unsubscribes, it is propagated to the upstream anyway up to the producer (i.e., from, subject, etc.) which will check isUnsubscribed.
Yeah, you can use a volatile field and synchronize on the assignment if still null. And then file a separate Jira to remove it from the class in a separate PR.
`Note when the windowed serde class is used, one needs...`
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
`of` -> `or`
`of` -> `or`
I think we should call `deserializer.configure(...)` here
Rather than doing that, could you please inject an `ObjectProvider` and use its API. That would prevent from calling the `BeanFactory` directly.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
nit: can remove type arguments
I know I need to change for the rest of them.
I hope we can get rid of those conversion in the future :)
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
You need to close the `Connection`.
rewrite test as above using `assertThrows()`.
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
same as above for parameters
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Sorry for that -- You are of course right. `final` only for iterator loops...
Sorry for that -- You are of course right. `final` only for iterator loops...
There's no need for that. If the pool is not available, then no pool should be configured as before.
It seems that both loginContext and mode can just be a local variable.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Can we also include the cause when we throw exceptions? It's not always helpful, but it has been invaluable for debugging many times since we started to include the cause.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Can we also include the cause when we throw exceptions? It's not always helpful, but it has been invaluable for debugging many times since we started to include the cause.
Looks good. I like the additional checking that you're doing here.
Looks good. I like the additional checking that you're doing here.
Looks good. I like the additional checking that you're doing here.
Ack. Was not sure if it's an intentional change. Thanks for clarifying that it's an actual fix.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
Maybe we should simply pass the `ProducerRecord` in the constructor? We could then also just use the `ProducerRecord.toString` in the error so that we don't have similar issues in the future.
As discussed in the JIRA, I still think we should use `FileChannel.open`.
Nit: "The file channel position..."
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Is the change in behavior intentional? `SecurityException`, which was previously caught and logged, is an instance of `RuntimeException`.
OK, let's keep the change to that one field for now.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
I like this parity check. :+1:
Would it be cleaner to just close/remove the task producer inside `tryCloseCleanAllActiveTasks`? Could we just close/remove the task producers before closing clean or do we specifically need to close them first? I don't remember...
There's still a usage as `applicationId + "-" + topic` in the `SinkNodeFactory` subclass. The structure of that class is now a bit odd as the `applicationId` is passed as a parameter, but it's a non-static so it captures the parent reference and actually uses it for at least one other member of the parent class (`internalTopicNames`). I'm fine committing as is if this is consistent with trunk since then a clean up could easily be cherry picked if that was desired. But it looks like this patch and what's on trunk differ significantly. This method name doesn't even seem to exist on trunk? Are you sure you want to diverge so wildly? It's going to make any more backports/cherrypicks really annoying...
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
same as above for parameters
same as above for parameters
Same question here as earlier about the `Locale`
nit: `anf` -> `and`
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
I'm not sure it is ever good for this to be a global default. Haven't we learned that it causes nasty issues in places like event loops? It seems only appropriate for separate threads, like the IO or NewThread schedulers.
No worries, let's keep the scope small for now. Just wanted to raise the question
The flake8/test failure is because the above `help` is missing a closing parenthesis, hence a `SyntaxError`. You can always repush to the branch to rerun the tests.
I think it's better to omit the try/except and instead say `Settings(settings_module) # should not raise an exception`. See 071801ccff970682a799ce754431a3c3ce3d6902
like trailing commas in the last item in a dictionary as stated above
How about we reset the offsets between tests? I think that may be what you're suggesting. It would be cleaner not to accumulate metadata over time.
How about we reset the offsets between tests? I think that may be what you're suggesting. It would be cleaner not to accumulate metadata over time.
`instantiateConfigProviders` since this is potentially creating multiple providers
`name()` -> `wrapped.name()`
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
nit: I don't think we should bother checking the string messages as it is quite brittle. The important thing is that the exception is thrown
This should go away. `@ConditionalOnClass` already does that.
Can we just call the overloads with two parameters here? Ditto above.
Can we just call the overloads with two parameters here? Ditto above.
I think most (all?) of these assertions are very obvious and the long text is just repeating the code. Does the text add value of is it just noise? Also, the lines should not be longer than the GitHub review window.
I think most (all?) of these assertions are very obvious and the long text is just repeating the code. Does the text add value of is it just noise? Also, the lines should not be longer than the GitHub review window.
`MetadataResponse` allows us to get the `Cluster` directly, so we can do something simpler: ``` Node oldLeader = initialUpdateResponse.cluster().leaderFor(tp1); Node newLeader = updatedMetadata.cluster().leaderFor(tp1); assertNotEquals(oldLeader, newLeader); ``` Since the metadata doesn't change, we can just do this check once.
Not sure you need to initialize the factory every time there.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Use `StringBuilder`? Possibly also change the name of the method since it is not a getter.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Is the change in behavior intentional? `SecurityException`, which was previously caught and logged, is an instance of `RuntimeException`.
We should use try-with-resources here (for `DataInputStream`).
nit: We could use `TestUtils.assertFutureThrows` here.
what about `assertEquals("consumer record size is not zero", 0, records.count());`? It can also be applied in a few other places
Should we restrict the values for name and version? Maybe we can just test that they are non empty? nit: the non-capture group isn't really necessary and this regex matches stuff like `"."` and `"---"`.
Are both host groups really needed? Does the one that contains ':' handle both? We have regex in other places in the project that do similar parsing we may want to keep in sync: - https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/utils/Utils.java#L53 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/BrokerEndPoint.scala#L27 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/EndPoint.scala#L29
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
How about "runs an external command for the worker."
How about "runs an external command for the worker."
I think we are guaranteed to have the listener present, but perhaps it's worth checking explicitly and throwing if it is not the case.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
Nit: somehow I don't like `blah`. Otherwise LGTM
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
rewrite test as above using `assertThrows()`.
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
`start` is not used.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Instead of `new MetricName("batch-size-avg", "producer-metrics", "", tags)`, I think we should use `metrics.metricName("batch-size-avg", "producer-metrics")`, right? The doc says `Please create MetricName by method {@link org.apache.kafka.common.metrics.Metrics#metricName(String, String, String, Map)}`. Same for other MetricName instantiation.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
rewrite test as above using `assertThrows()`.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
```suggestion "consumer is not part of an active group yet. You can try completing the rebalance " + ```
Looks good. I like the additional checking that you're doing here.
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
I do not think we need to emulate the behavior of the java uncaught exception handler here. I do not see why a user should try to reset the uncaught exception handler. If we receive this requirement, we can still add it. I have the impression the "reset" makes this code unnecessarily complex.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
That's a good idea. Note: Kafka does not use this JUnit functionality yet (i.e. no use of ExternalResource, ClassRule, Rule as far as I can tell). @ijuma: Would it ok for us to introduce this? There's no additional dependency etc., it's just using a new JUnit feature that was introduced in 4.7 (we're on 4.12).
nit: Empty line could be removed.
ð fair enough
ð fair enough
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
Should we restrict the values for name and version? Maybe we can just test that they are non empty? nit: the non-capture group isn't really necessary and this regex matches stuff like `"."` and `"---"`.
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
well, i thought a method reference would work here for the hash map, but I tried it and it doesn't seem to work. ð¤
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
It is probably good to always have ms in the name variable name that represents time in ms. Probably not a big deal here since this is local variable.
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
There's no need for that. If the pool is not available, then no pool should be configured as before.
Is there a reason to change the signature of this method? This is unrelated to this PR so I'd like this to be reverted.
rewrite test as above using `assertThrows()`.
`shouldRecord`? `maybeRecord` sounds like it would record it for you.
@becketqin is right-- you should handle this case. Perhaps the server sent back bad data. The way to handle it is not to throw an exception, but to complete the relevant future(s) with an error. There are a few other cases where we handle bad server data by completing a future with failure in AdminClient.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
and -> a
Add the stream task id prefix here as well for both exception message and the warning log entry.
I might have missed something here. I don't see that the UnsafeFunc0 adds much. After all every Func0 is potentially unsafe inasmuch as it can throw a RuntimeException for instance.
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
and -> a
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
nit: usually we drop the `get` prefix on getters.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
Shouldn't this look for other whitespace characters, per the exception message? Something like: ```suggestion if (headerName.isEmpty() || headerName.matches("\\s")) { ```
We may be able to save all this hassle by defining alias group as a map of `target` to a list of `deprecated` configs? We defined this as a 2-dim array but we always convert it to lists...
OK, will remove before merging.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
We can use `TestUtils.assertFutureThrows()` here too
We can use `TestUtils.assertFutureThrows()` here too
We can use `TestUtils.assertFutureThrows()` here too
We can use `TestUtils.assertFutureThrows()` here too
Same for generation and member.id. We could just call `request.data().generationId()`
Same for generation and member.id. We could just call `request.data().generationId()`
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
We should update the Scala `TestUtils` to call this method.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Tiny nitpick: you can declare error in this line too as it's not used outside the loop anymore
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
Is this line intentional? Unit tests normally don't need to print out to console.
Is this line intentional? Unit tests normally don't need to print out to console.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
No `u` prefix (python3.2 compatibility)
No `u` prefix (python3.2 compatibility)
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
should we wrap the processing etc in `try{..}finally{..}` so we ensure that we do `streams.close()`? Also maybe close with a timeout? Same elsewhere
`apiKey` is of type `ApiKeys` while `requestHeader.apiKey()` returns a `short`.
requestHeader.apiKey() can just be apiKey.
Do you think it would be clearer if we don't rely on the defaults, but just explicitly include both branches? Oh, also, this isn't an immutable builder, so you can just do: ```suggestion if (cachingEnabled) { stateStoreConfig.withCachingEnabled(); } else { stateStoreConfig.withCachingDisabled(); } if (loggingEnabled) { stateStoreConfig.withLoggingEnabled(new HashMap()); } else { stateStoreConfig.withLoggingDisabled(); } ```
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
Nit: we don't normally use exclamation marks in Kafka log messages.
as above (similar elsewhere)
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
nit: add a space before the `:`.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
nit: add a space before the `:`.
nit: add a space before the `:`.
nit: add a space before the `:`.
nit: add a space before the `:`.
nit: add a space before the `:`.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
Maybe we can just a better name for `path` since it makes this code look suspicious.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Might it be simpler to just do: ``` topicCounterMap.put(topic, prevPartition -1); ```
the condition is always false if you don't add brackets. ``` throw new IllegalArgumentException("Topic pattern to subscribe to cannot be " + (pattern == null ? "null" : "empty")); ```
I think we should call `deserializer.configure(...)` here
Same question here as earlier about the `Locale`
I think the basic idea makes sense and is what I was expecting. It might not feel too elegant, but I think a simple approach is best initially. An interesting point to consider is what would happen if an offset fetch is in-flight while a rebalance is in progress. When it returns, the offsets may be stale. I am wondering if it makes sense to fence the response using the group generation. In other words, we record the generation at the time of the request and then verify when we receive the response that it matches the current group generation.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
We should limit this suppression to the method for which we really need it instead of the whole class
@lpmi-13 thanks for the PR. This looks correct to me - `fail_json` will exit the code.
remove var -- only used once.
This was probably left by mistake.
The dependent key name should be in backticks. And perhaps comma-delimited rather than tabs.
You are right, this is fine. I was confused about the checkpointedOffsets in standbyTasks before.
nit: we usually do not use unnecessary numbers as part of the parameter; rename to `streamImpl` instead.
This was probably left by mistake.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
nit: we can use `threadAssignment.size()` to replace the `threadTaskCount` variable. Same as below.
Wouldn't it be much easier to do the following: ``` public Connector createConnector(String listener, String name) { ... String hostname = ... int port = ... ... if (name == null || name.trim().isEmpty()) { name = String.format("%s_%s%d", PROTOCOL_HTTPS, hostname, port); } connector.setName(name); ... ```
This could move to `ListOffsetResponse` as a helper, and maybe name as `singletonListOffsetTopicResponse`
Is this negative check necessary? long has 2^63 -1 capacity and let's assume that we will accumulate 10^9 every second we would still need 106 752 days to overflow (roughly 292 years).
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
`asList` -> `Collections.singletonList`
Should we call close in the `finally` block? Here and elsewhere
Some fields might be safe to just shallow copy, but I think a number of these need to be deep copied to avoid accidentally modifying the original schema. I think `parameters and `defaultValue` at a minimum need to change. Schemas seem like they should be fine since they'd just be fully replaced, not modified, anyway.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
nit: As said in the other PR, this is a good idea but I would only do it if we do it for all exceptions.
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
This exception is no longer possible since the constructor is taking `ObjectName`.
nit: remove (was tested already)
We should check the keys too in every case in this test.
That's a good idea. Note: Kafka does not use this JUnit functionality yet (i.e. no use of ExternalResource, ClassRule, Rule as far as I can tell). @ijuma: Would it ok for us to introduce this? There's no additional dependency etc., it's just using a new JUnit feature that was introduced in 4.7 (we're on 4.12).
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Same question here as earlier about the `Locale`
Same question here as earlier about the `Locale`
Same question here as earlier about the `Locale`
request "got" re-sent to the control
oops, you right, my fault. :( I glanced over really quickly, but with the prospect of doing a more comprehensive review/reading (incl. compilation, etc) on Monday. :) Well, so we can rewrite it as: ``` for (Iterator<TopicPartition> it = assignment.keySet(); it.hasNext(); ) { TopicPartition tp = it.next(); if (!subscription.contains(tp.topic())) it.remove(); } ``` This simplifies the code a tidy bit, at least. No need to get `entrySet` as we are only interested on the keys. ;)
There is a corner case in regarding the listener here: say a ListenerA class was previously used in the consumer, and now it wants to subscribe with another ListenerB class, after calling subscribe(), before sending a join-group request, a rebalance could be triggered upon, for example partition change, which will then use the new ListenerB class already. Not sure if it will be an issue though.
Nit: we don't need the `<p>` tag because there is only one paragraph.
Nit: remove `this`
There is a corner case in regarding the listener here: say a ListenerA class was previously used in the consumer, and now it wants to subscribe with another ListenerB class, after calling subscribe(), before sending a join-group request, a rebalance could be triggered upon, for example partition change, which will then use the new ListenerB class already. Not sure if it will be an issue though.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
There is a corner case in regarding the listener here: say a ListenerA class was previously used in the consumer, and now it wants to subscribe with another ListenerB class, after calling subscribe(), before sending a join-group request, a rebalance could be triggered upon, for example partition change, which will then use the new ListenerB class already. Not sure if it will be an issue though.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
`KafkaStreams` is AutoCloseable now so you can include its construction inside the `try` block. Ditto elsewhere.
`KafkaStreams` is AutoCloseable now so you can include its construction inside the `try` block. Ditto elsewhere.
`KafkaStreams` is AutoCloseable now so you can include its construction inside the `try` block. Ditto elsewhere.
I think we should call `deserializer.configure(...)` here
Nit: "For instance, the transactional APIs require brokers with version 0.11.0 or newer."
Nit: "For instance, the transactional APIs require brokers with version 0.11.0 or newer."
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
Hmm, but we're not actually calling the listener here. We do that separately.
`before or after`
+1 -- also below in other tests.
Please get rid of this volatile. There is no longer a circular dependency here.
Please get rid of this volatile. There is no longer a circular dependency here.
Okay I think this makes sense, let's just follow this pattern then.
@sutambe I also think we should mention the scenario that a Record is added to a batch that is about to expire.
I think we should call `deserializer.close()` here
Interesting! I guess we could implement it at some point, but that seems like a fair amount of work.
ditto for the rest of the test
There's no benefit in using `StringBuilder` for something like this. Using `+` will have the same effect (the case where `StringBuilder` helps is when there's a loop.
you don't need this. Junit gives you a new instance of the test class for every test method
Let's check that `previouslyAllocated`'s capacity is `batchSize` else `buffer.limit(sizeBytes)` is going to throw with a less useful stacktrace.
```suggestion /** * Task ID of the task. * * @return task ID consisting of subtopology and partition ID */ ```
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
This seems to have the same issue as in SaslClient in that we need the logic to turn off OP_WRITE here too. Suppose that the server tries to send a token, but couldn't completely flush the writes. We get in here and completely flush the output buffer. Now, if the OP_WRITE is not turned off, the selector will be woken up all the time before the server receives the next token from the client.
I believe this is fixed in my next PR.
It seems I also could approve it. I will read all code tomorrow and work with you to get this approved.
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
use `try-catch` instead of `expected` annotation -- not a single line test.
@vahidhashemian, yes, that's what I mean.
It would be good to have constants instead of hardcoding the fields in many places.
Nit: var should be named `deserializeValue`
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
You didn't want to capture the response content and assert that here? (Just wondering your thoughts...)
You didn't want to capture the response content and assert that here? (Just wondering your thoughts...)
This seems to defeat the purpose... If we really want to skip this test in this environment, we should rather put it in the beginning and do ``` if (isUnix) { return; } ```
Is this used anywhere? I see we have changed client code to use the other C'tor.
> Is there any backwards compatibility issue with doing this? I.e. is the availability of this import part of Django's public API? Theoretically yes, we should add a reverse import for backward compatibility, or at least a small release notes.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
nit: There is an extra space before `+`.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
What's the purpose of this warning? It doesn't seem needed.
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
It might still be nice to see the stacktrace here (even if it also gets logged elsewhere). If you want to do it, don't forget you have to change to using `String.format` for the variable substitution. I don't feel strongly in this case, so I'll defer to you whether you want to do this or not.
We can probably output the error instead of the error code (the field name should be changed appropriately.
What's the purpose of this warning? It doesn't seem needed.
not critical since it's not a ton of logic, but since this logic is repeated, it might be better to turn it into a utility method on `SinkConnectorConfig` and use it both in that class's validate method and here.
nit: use `{}` instead of string concat for `retries`
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
```suggestion /** * Metadata of a task. */ ```
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Let's try to be consistent to use `copartition` instead of `coPartition`
`assertNull`s shouldn't be here but few lines bellow.
nit: add `a {@link Named} config`
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
This still doesn't seem correct. We're only invoking configuration if the plugin implements `Configurable` afaict. This does not work for `Converter`s implemented against the new API and assuming the "forward" configuration. We *must* always invoke the "old" `configure(Map, boolean)`, and only invoke the `Configurable` version as a backup. Possibly it would make sense to indicate on the `HeaderConverter` that the `Configurable` methods should be idempotent if we need to be able to implement both. Not sure if we can test this easily with unit tests, but I think we might want a plain old `Converter` (that does not implement `HeaderConverter`) in tests to validate compatibility... but it's possible we'd need either integration or system tests to properly validate.
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
No, it's been here since 2.3, just not usable as a connection on its own.
`assertNull`s shouldn't be here but few lines bellow.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
This is repeating what `SafeObserver` does. A `Notification` doesn't need to do anything different and thus we shouldn't be replicating that logic.
@miguno Actually, we do not enforce this guarantee. For many UDFs, we just hand in a reference to key and/or value and if the user would alter the object, we would not notice...
`assertNull`s shouldn't be here but few lines bellow.
We should also validate (in our tests) that the user cannot modify the underlying stream because, as I understand the proposed semantics, "an unchanged stream" is an invariant we want to guarantee as part of the contract.
We should also validate (in our tests) that the user cannot modify the underlying stream because, as I understand the proposed semantics, "an unchanged stream" is an invariant we want to guarantee as part of the contract.
Ah, right. I didn't look carefully at the type, sorry.
This has been fixed by: https://github.com/apache/kafka/pull/8291 Please omit and rebase to get the latest changes.
nit: This check seems superfluous (and is inconsistent with the collection of connector callables).
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Nit: long line.
nit: 'else' can be dropped
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
nit: add a size? There are a few cases in here where we could do this.
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
nit: remove `this` (not required)
There may be a couple validations we have in `ZkAdminManager.describeClientQuotas` that do not appear here. For example, we detect invalid mixes of ip and user searches: ``` if ((userComponent.isDefined || clientIdComponent.isDefined) && ipComponent.isDefined) throw new InvalidRequestException(s"Invalid entity filter component combination, IP filter component should not be used with " + s"user or clientId filter component.") ```
Do we still need `needsJoinPrepare` now? It seems to me that we need to call `onJoinPrepare` whenever `needRejoin` is true.
I'd suggest moving this static method after the non-static methods.
Please remove empty line.
nit: add `final` (same below)
Not sure if it really matters, but this is not a uniform distribution (because MAX_VALUE and MIN_VALUE are not integer multiples of 1000 days. If you wanted a uniform distribution, it looks like you can use the bounded `nextInt` and cast to `long`. Also, FYI, `Math.abs(Long.MIN_VALUE) == Long.MIN_VALUE` (which is a negative number), due to overflow.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
Use `StringBuilder`? Possibly also change the name of the method since it is not a getter.
This probably shouldn't be called "prepare", right? It is the main Callable here and we expect to stay in it for a while.
This probably shouldn't be called "prepare", right? It is the main Callable here and we expect to stay in it for a while.
Is this constructor used at all? If not, I'd not include it one should generally provide a message explaining more.
This probably shouldn't be called "prepare", right? It is the main Callable here and we expect to stay in it for a while.
Yeah might as well change it I think, it results in shorter code
We should limit this suppression to the method for which we really need it instead of the whole class
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
What do you think about this accepting `Notification` instead of `Action0`? The reason is that we now have 2 wrappers ... the `Notification` and `Action0` around a type `T` and 2 object allocations for each `onNext`. The use of `Action0` is definitely more generic, but as we've seen by your `CompositeSubscription` changes, we're at the point where we're moving away from generic to achieve performance and memory gains, and this class will be involved in very high throughput scenarios.
i think this would be better off as a test rather than in `setUp`
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
There are some bugs here: * If you call remove twice in a row, it should fail. Remember: > Note that the remove() and set(Object) methods are not defined in terms of the cursor position; they are defined to operate on the last element returned by a call to next() or previous(). So you can't `remove` twice in a row-- you have to call `next` or `previous` again before you can call `remove`. Since lastReturned can be non-null here after we call `remove`, something bad will happen if we call it twice. * If you get to the end of the list and then call `previous`, it should work. It fails here because we check `cur` against `head` * Indices (`nextIndex` / `previousIndex`) get screwed up after calling `remove` * In general, there seems to be no value in having both a `cur` and a `next`. We can always follow the doubly-linked list backwards, so having an extra field doesn't add any efficiency. We also have `lastReturned` to track what was last returned, and `cursor` to track whether we're at the end or the beginning of the list (which is implemented as a circular linked list, as you've no doubt noted) If you choose to have both of these fields, you need to keep them properly updated when you remove an element. Sounds like a pain.
We should limit this suppression to the method for which we really need it instead of the whole class
Definitely don't add an abstract class! Let's leave it as is for now, then.
This probably shouldn't be called "prepare", right? It is the main Callable here and we expect to stay in it for a while.
This doesn't seem to be used.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
Is this constructor used at all? If not, I'd not include it one should generally provide a message explaining more.
This probably shouldn't be called "prepare", right? It is the main Callable here and we expect to stay in it for a while.
What's the purpose of this warning? It doesn't seem needed.
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
There are some bugs here: * If you call remove twice in a row, it should fail. Remember: > Note that the remove() and set(Object) methods are not defined in terms of the cursor position; they are defined to operate on the last element returned by a call to next() or previous(). So you can't `remove` twice in a row-- you have to call `next` or `previous` again before you can call `remove`. Since lastReturned can be non-null here after we call `remove`, something bad will happen if we call it twice. * If you get to the end of the list and then call `previous`, it should work. It fails here because we check `cur` against `head` * Indices (`nextIndex` / `previousIndex`) get screwed up after calling `remove` * In general, there seems to be no value in having both a `cur` and a `next`. We can always follow the doubly-linked list backwards, so having an extra field doesn't add any efficiency. We also have `lastReturned` to track what was last returned, and `cursor` to track whether we're at the end or the beginning of the list (which is implemented as a circular linked list, as you've no doubt noted) If you choose to have both of these fields, you need to keep them properly updated when you remove an element. Sounds like a pain.
This isn't a REST extension necessarily, right? It's also used by Kafka via JMX. I think mentioning `worker restarts` and `rest extension` might be confusing
What's the purpose of this warning? It doesn't seem needed.
I don't think we need a synchronized block here since `start()` is always called once at the very start
Nit: move these two static factory methods above the non-static member variables, so all static and non-static members are together.
nit: this doesn't throw IOException. You can remove all of these all the way up to `MetadataImage.write`.
Could use `equalsIgnoreCase` directly.
```suggestion put(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, "/tmp/foo"); ```
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
Can you re-warp this block to 79 chars? (First line is too short.)
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
nit: add `final`
Seems like a no-op
Seems like a no-op
method name changes
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
@vahidhashemian, yes, that's what I mean.
Yes, this should on an internal package (eg `common.internals`).
Yes, this should on an internal package (eg `common.internals`).
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
`Constructor<List<T>>` (or `Constructor<L>` if we introduce `L`)
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Alternatively, we could ditch the `driver` field and just make it a local variable in every test. Having it as a field made more sense when it was `setUp` in each methods, but now that it's instantiated in each test, it would be simpler to limit the scope to a local variable. Each test would need to call close at the end, but that's fine with me. If anything, it demonstrates proper use of the driver.
Might be better to add a proper POJO maybe `StreamsMetadata` or something that wraps the `streamTime` Long plus `ProcessorMetadata` instead of using `KeyValue` ? We might add new fields later on what is easier to do for a new POJO.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
nit: remove empty line
Another way to write this, that reduces a couple lines of code would be: ```java if (allTopics.remove(topicName) == null) { future.completeExceptionally(new UnknownTopicOrPartitionException(String.format("Topic %s does not exist.", topicName))); } else { future.complete(null); } deleteTopicsResult.put(topicName, future); ```
nit `getMetadata` -> get`
nit: remove empty line
Nit: somehow I don't like `blah`. Otherwise LGTM
I suggest `for x_shape, y_shape, axes, z_shape in test_cases:` to improve readability.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
This was probably left by mistake.
redundant parens `% (names)`
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Nit: somehow I don't like `blah`. Otherwise LGTM
Yes, we should remove `sleep` in the tests and ensure they work without them.
Instead of adding headers each time, maybe we can pre-create the headers list and pass to ProducerRecord() constructor.
nit: I do think a short message would be helpful here, even if it's just "Failed to deserialize record with type {type}"
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
Kinda, but it had a TreeMap before, so it used the "natural ordering" of the Strings which means... something. Anyway, are we okay with the fact that the ordering may change according to the person who built the docs? The kafka.apache.org webpage will then show whatever order the site-builder's JVM used? Or is it Jenkins? We don't really have any other choice, other than making everyone use LinkedHashSets, right? And we decided we don't want that.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
remove this line -- not required.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Kinda, but it had a TreeMap before, so it used the "natural ordering" of the Strings which means... something. Anyway, are we okay with the fact that the ordering may change according to the person who built the docs? The kafka.apache.org webpage will then show whatever order the site-builder's JVM used? Or is it Jenkins? We don't really have any other choice, other than making everyone use LinkedHashSets, right? And we decided we don't want that.
Kinda, but it had a TreeMap before, so it used the "natural ordering" of the Strings which means... something. Anyway, are we okay with the fact that the ordering may change according to the person who built the docs? The kafka.apache.org webpage will then show whatever order the site-builder's JVM used? Or is it Jenkins? We don't really have any other choice, other than making everyone use LinkedHashSets, right? And we decided we don't want that.
Should be final
Thanks! Will push this shortly.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
Why do we have SSL specific methods here? Could we move all the SSL bits into the SSL class? We have fields for the configurations. So we could set them accordingly (without or without SSL) in each concrete class. Then in the base class, we just use the fields to create the clusters without having to know if it's SSL or not.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
nit: add `final`
nit: add `final`
nit: add `final`
nit: add `final`
This is because we are inheriting a Scala class, and moving forward we should remove this with the Java version `org.apache.kafka.copycat.util.ShutdownableThread` that can be moved into `o.a.k.common.utils`. We can leave it as is for now.
nit: I would rather use the full name instead of using acronyms.
You can drop `final` from here, we generally don't use it for local variables.
Isn't it more clear that method names start with a verb? like`evaluatePoolingFailureAnalyzer()`
Ditto on removing before/after
debug line should be removed.
Sorry for that -- You are of course right. `final` only for iterator loops...
Sorry for that -- You are of course right. `final` only for iterator loops...
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
```suggestion processed = new AtomicBoolean(true); ```
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
Typo -- or is that Italian? :-)
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
nit: typo `snapshoId`
Yes, it seems that -1 means that we are trying to read beyond the end of the channel, which probably should be treated as abnormal.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
I think this should be synchronized.
I was talking about the delayed interrupt time. Ideally, the shorter it is, the faster the test terminates. So I thought we could use 1s instead of 2s.
I was talking about the delayed interrupt time. Ideally, the shorter it is, the faster the test terminates. So I thought we could use 1s instead of 2s.
We should deprecate this one too I believe.
We should deprecate this one too I believe.
We should deprecate this one too I believe.
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
Nit: somehow I don't like `blah`. Otherwise LGTM
Ouch! Sorry about that!
You might consider using `OptionalDouble`.
This doesn't seem to be used.
Can replace the three lines with: ``` assertEquals(Utils.mkSet("TLSv1.2"), Utils.mkSet(engine.getEnabledProtocols())); ```
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I think we should call `deserializer.configure(...)` here
I think we should call `deserializer.configure(...)` here
This seems suspicious... * Shouldn't all blocking operations have timeouts? * Should we be swallowing and ignoring InterruptedExceptions? It seems like a recipe for Streams to hang forever un-killably. But I feel like I'm missing something.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
nit: add a size? There are a few cases in here where we could do this.
Ditto on removing before/after
nit: one line per parameter for method call when statement is long acceptable.
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
I think we should call `deserializer.close()` here
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
Even though the config is invalid, the passwords may be valid, so it seems safer not to include them. It would be nice if the sensitive entries in the JAAS config would be communicated in some way to improve debuggability (in the future). Btw, a nit: we seem to use inconsistent capitalisation of the word JAAS in our messages. It would be nice to make that consistent.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Nit: let's not add an unnecessary extra line.
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
This test is highly overlapping with `testOldBrokerAbortTransaction`, could be good to refactor out a common flow.
This test is highly overlapping with `testOldBrokerAbortTransaction`, could be good to refactor out a common flow.
this could be: `assertThat(serializer.serialize(topic, null), nullValue())`
This test is highly overlapping with `testOldBrokerAbortTransaction`, could be good to refactor out a common flow.
This test is highly overlapping with `testOldBrokerAbortTransaction`, could be good to refactor out a common flow.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
and -> a
nit: line too long
I don't have a better suggestion, but targetTopicPartitionsUpstream is a kinda confusing name.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
For even distribution, it would be useful to verify 2 things. (1) The leaders are distributed evenly when all brokers are unfenced. (2) If any broker is fenced, the new leaders are still distributed evenly.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
Maybe we can just a better name for `path` since it makes this code look suspicious.
I vote yes for this. I think if we use this for writing snapshot from the state machine, then minimum size is a more interesting metrics for flushing to disk vs lingerMs. If we implement this so that either one has to be true then the client can set the `lingerMs` or `minSize` to MAX_VALUE if it wants to ignore those values.
I vote yes for this. I think if we use this for writing snapshot from the state machine, then minimum size is a more interesting metrics for flushing to disk vs lingerMs. If we implement this so that either one has to be true then the client can set the `lingerMs` or `minSize` to MAX_VALUE if it wants to ignore those values.
Maybe we can just a better name for `path` since it makes this code look suspicious.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Please change it to `only one thread should call`, remove `be allowed to`.
I think you want to null out these fields after you call `dispose` because using them after this will lead to undefined behaviour (a NPE is preferable in case of misuse).
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Same as before, `new Integer[]{}' not required for `Arrays.asList`.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
AclAuthorizer is not a public class, so it may be ok to make this class public in AclAuthorizer instead of duplicating it here.
Was the boundary check wrong? You changed `>=` to `>`.
I think, we should use three different values to make sure that the different prefixes overwrite the configs for the corresponding clients. Looking into the test below, they seem to be redundant with this one? We can also remove this test and keep the other three (that would avoid redundancy, too)
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
Can we do two passes instead (`\r\n` then `\n`)? Technically speaking that would replace `\r`
prop: - Remove `Target` - `thread` -> `stream thread`
prop: - Remove `Target` - `thread` -> `stream thread`
Ah, yeah, you'd need to do something more like what actually happens in the actual KafkaConsumer/`getAssignorInstances` code. eg ``` @Test @SuppressWarnings("unchecked") public void shouldInstantiateAssignorClass() { Object classTypes = Collections.singletonList(StickyAssignor.class); List<ConsumerPartitionAssignor> assignors = getAssignorInstances((List<String>) classTypes, Collections.emptyMap()); assertTrue(assignors.get(0) instanceof StickyAssignor); } ```
Ah, yeah, you'd need to do something more like what actually happens in the actual KafkaConsumer/`getAssignorInstances` code. eg ``` @Test @SuppressWarnings("unchecked") public void shouldInstantiateAssignorClass() { Object classTypes = Collections.singletonList(StickyAssignor.class); List<ConsumerPartitionAssignor> assignors = getAssignorInstances((List<String>) classTypes, Collections.emptyMap()); assertTrue(assignors.get(0) instanceof StickyAssignor); } ```
Since log.error(.. ex) will print the stack trace already, may be we can save re-throwing the exception again. EDIT: if we want to stop the whole process by throwing the exception, we can then save log.error().
I'm not sure returning `true` is valid. We don't actually know if all the threads have shutdown. Though, i'm not entirely sure what to do about it. Perhaps we need to extract the shutdown Thread as a field and then we can check if it is still running. If it isn't running then we can return true, otherwise we should try and join on the thread with the provided timeout
Nit: remove `this`
```suggestion put(StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, "/tmp/foo"); ```
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
base -> based progress -> progressed
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
We need to think about how we can avoid this. The package structure appears to be working against us.
This approach will be useful sometimes but other times I will want an error on close to be suppressed. This is a common pattern for reading from an InputStream. Once we call close() we have finished our reading and just want to clean up and if the resource has already been closed or invalidated we don't really care. I'm unaware what behaviour results when unsubscribe itself throws an exception and can't write a test at the moment.
This approach will be useful sometimes but other times I will want an error on close to be suppressed. This is a common pattern for reading from an InputStream. Once we call close() we have finished our reading and just want to clean up and if the resource has already been closed or invalidated we don't really care. I'm unaware what behaviour results when unsubscribe itself throws an exception and can't write a test at the moment.
Nitpick: space missing before `conditionDetails`.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
You can simply md5 the description and set the content to `u'md5:_md5_goes_here'`.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Nit: `.` missing at end of sentence
nit: add a size? There are a few cases in here where we could do this.
Nit: `.` missing at end of sentence
Nit: `.` missing at end of sentence
formatting: no need to curly braces
Nit: no need newline. Also I think we do not need the `TimeFirstWindowKeySchema.` since it is within this class right? Ditto below.
We should limit this suppression to the method for which we really need it instead of the whole class
Nit: no need newline. Also I think we do not need the `TimeFirstWindowKeySchema.` since it is within this class right? Ditto below.
Nit: no need newline. Also I think we do not need the `TimeFirstWindowKeySchema.` since it is within this class right? Ditto below.
formatting: no need to curly braces
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
AK convention is to not use `set` setters or `get` getters.
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
Nit: no need newline. Also I think we do not need the `TimeFirstWindowKeySchema.` since it is within this class right? Ditto below.
nit: creating restoredPosition is not required if !constinceyEnabled
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
Hmm, so previously (and also with this change) we are assuming that we will get different resolved IPs for each connection to apache.kafka.org? This seems to rely on round-robbin DNS resolution that we can't really control. I think these assertions will always be prone to failure unless we can control the DNS server like @dajac suggested. I guess we can commit this to unblock the tests, but we should definitely prioritize a better fix.
"InMemoryKeyValueIterator" -> `getClass().getName()
OK, let's keep the change to that one field for now.
Should we log INFO if we are indeed enforcing processing? I.e. there are some empty partitions.
nit: 'else' can be dropped
Maybe this looks better? ```suggestion // we're at the end of the input. if (queryResult.getResult().value() == batch1NumMessages - 1) return; ```
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Maybe this looks better? ```suggestion // we're at the end of the input. if (queryResult.getResult().value() == batch1NumMessages - 1) return; ```
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
nit: 'else' can be dropped
nit: 'else' can be dropped
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: remove empty line
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
Maybe we can create a JIRA for tracking, but it's not that important for now. Since the common parts that can be consolidated may be not much: in the actual topology building process we need to set the internal topic names, set copartition topics etc which are not needed for the topology description building at all. What I was originally thinking is the the topology building process may be extending from the topology description building process with its additional functionalities like I mentioned above, but I am all hand-wavy on the devil details now.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
This should call `configState.rawConnectorConfig(connector)`, which returns the _user-supplied_ configuration _with variables not resolved_. The `connectorConfig(connector)` call returns the configuration _with variables already replaced_, which means we might be leaking passwords and other secrets specified using variables.
I think we should call `deserializer.close()` here
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
I think we're testing `testDir` Occupied here, not `AppDir`.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Should be final.
nit: add a size? There are a few cases in here where we could do this.
Did you mean: ```suggestion setBrokerId(3). setBrokerEpoch(100). ```
I'm not sure it is ever good for this to be a global default. Haven't we learned that it causes nasty issues in places like event loops? It seems only appropriate for separate threads, like the IO or NewThread schedulers.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
Even though I think this is a bit off, I'm going to go ahead and merge it, so we can fix forward. The overall feature isn't fully implemented yet anyway, so this will have no negative effects if we release the branch right now.
nit: add a size? There are a few cases in here where we could do this.
Nit: add `Cannot be {@code null}.` (maybe somewhere else, too)
Nit: add `Cannot be {@code null}.` (maybe somewhere else, too)
nit: Shutting down -> Complete shutdown .. Also in the verification we can change accordingly.
rewrite test as above using `assertThrows()`.
`innerDeserializer` could be null; we should handle to case to avoid a NPE calling `getClass()`
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
Small typo here: Guage -> Gauge.
It's not required to protect the await, but is to get the logging.
The above suggestion would also us to avoid having to pass the `requestVersion` down here.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Nit: I was thinking that the variable name should be `batchHeader` and this string seems to confirm that.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
This doesn't seem to be used.
Why not check `context.timestamp`? Checking the message of the exception is very brittle.
nit: the name is a bit awkward. How about `maybeInvokeOnPartitionsLost`? We can change the others similarly.
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
I'm not too keen on the structure of the JSON, both because the keys vary and because it's not very extensible. I'd prefer something like this: ``` json { "status": "UP", "nodes": [ { "address": "127.0.0.1:7001", "version": "3.0.7" }, { "address": "127.0.0.1:7002", "version": "3.0.7" }, { "address": "127.0.0.1:7003", "version": "3.0.7" } ] } ``` The keys are the same for every node and we can also easily add extra information about a node.
we should not use Java keyword `assert` but Junit `assertXXX` methods (`assertEquals` for this test)
Should we close the task first before re-initialize it to another StreamTask? Ditto below.
prop: Please use `assertThat()` since it makes verifications a bit better readable.
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
Admittedly, this is a random time to bring this up, but a pattern that I like for this is: ```java final long seed = providedSeed != null ? providedSeed : new Random().nextLong(); System.out.println("Seed is: " + seed); final Random rand = new Random(seed); ``` where `providedSeed` comes from an env variable, command-line arg, whatever... This way you get the same default behavior (pseudorandomly generated sequence of test values), but you also have the option to deterministically reproduce a previous pseudorandom sequence from a prior run. This can be helpful in diagnosing flaky tests. Not saying this is needed here; I just wanted to share the pattern.
This formatting is going to fail checkstyle. There seem to be other failures as well. For the changes in this patch, run `./gradlew clean clients:test` to make sure everything will pass.
Is this line intentional? Unit tests normally don't need to print out to console.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
I think you need `to_native` here.
We also need a test to validate that some extensions can be ignored (neither valid nor error).
We also need a test to validate that some extensions can be ignored (neither valid nor error).
We also need a test to validate that some extensions can be ignored (neither valid nor error).
I think we should call `deserializer.configure(...)` here
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Isn't this cheating? You're modifying behavior in the compliance tests but the runtime actually behaves differently.
Could store `entry.getKey()` in a local variable since it is used several times
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
`instantiateConfigProviders` since this is potentially creating multiple providers
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
as above: we need to remove adminPrefix configs
We should use try-with-resources here (for `DataInputStream`).
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
nit: some extra newlines here.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
How is the `path` value handled? I don't think this will support relaxed binding, e.g. if someone sets `spring.integration.graphControllerPath` or `SPRING_INTEGRATION_GRAPH_CONTROLLER_PATH` the configuration will be ignored.
How is the `path` value handled? I don't think this will support relaxed binding, e.g. if someone sets `spring.integration.graphControllerPath` or `SPRING_INTEGRATION_GRAPH_CONTROLLER_PATH` the configuration will be ignored.
How is the `path` value handled? I don't think this will support relaxed binding, e.g. if someone sets `spring.integration.graphControllerPath` or `SPRING_INTEGRATION_GRAPH_CONTROLLER_PATH` the configuration will be ignored.
nit: add a space before the `:`.
nit: not a big deal here, but for unit tests I think given the very low overhead it is better to separate out each of the cases into their own test as it can help make it more quickly obvious if issues are with a specific case or if it affects multiple cases.
nit: add a space before the `:`.
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
Since log.error(.. ex) will print the stack trace already, may be we can save re-throwing the exception again. EDIT: if we want to stop the whole process by throwing the exception, we can then save log.error().
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
nit: add a size? There are a few cases in here where we could do this.
this doesn't seem to be used
Kafka doesn't mandate braces in `if` statements.
Let's remove the brace changes please.
Let's remove the brace changes please.
We should probably check that `clientId` is still null.
nit: we can just throw a `TopologyException` exception here.
Let's remove the brace changes please.
I feel INFO level is fine as in many cases people will keep alerting on warn / error logs.
ditto on the properties and the driver.
ditto on the properties and the driver.
nit: remove the redundant line. Same as below.
nit: add `final` (2x)
Could we combine the finally block with L45-46? Also I was thinking whether we should close the producer thread as well.
Is it actually useful for `metadata.awaitUpdate` to throw an exception? Maybe it should simply return a `boolean`.
The log level is a tricky one. In the producer, messages for errors are all at debug level (for instance when we transition to error state in the transaction manager). So having this higher than debug may not add much value.
`instantiateConfigProviders` since this is potentially creating multiple providers
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
next() samples the sequence, it's not supposed to buffer the entire sequence so it can't be used for forEach which must be applied to every onNext call in an Observable. It could be done with toIterable/toEnumerable, but I wouldn't want that since that would first buffer the entire thing in a list and then call forEach over it. forEach should be invoked as each element is emitted to onNext in without buffering.
I'd _guess_ is that this was automatically performed by `black` because you had a trailing comma within the list (i.e. `[my_operation,]` rather than `[my_operation]`) which [black will treat as a rule to make the expression multi-line](https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#trailing-commas) > A pre-existing trailing comma informs Black to always explode contents of the current bracket pair into one item per line.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
state.isRunning() is as below ``` public boolean isRunning() { return equals(RUNNING) || equals(STARTING) || equals(PARTITIONS_REVOKED) || equals(PARTITIONS_ASSIGNED); } ``` if its not too much work, we can rename to something like `state.isAlive()` , that captures what we want to check .. your call.
nit: Indicate that this needs deep iterations on the entries.
I changed the cast to `Long.valueOf`.
This field is not used, we can remove it.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
Unrelated to your change, but the bitwise OR is a little surprising. Maybe we can rewrite this to be more explicit? Glancing through our code, I don't see any other usages of this operator besides actual bitwise operations.
This method is also deprecated. We should throw same exception as for `childIndex`.
Nitpick: space missing before `conditionDetails`.
I have no strong opinion on close-parameter vs streams config. So ok with me.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
As an alternative, which might align better with Kafka in general, would be to set the timeout via `StreamsConfig`. This keeps the API clean. @enothereska argument that `close()` should not have any arguments is quite valid to keep APIs consistent within Kafka.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
We should emphasize that this partitioner should be stateless as it can be shared across topics / sink nodes.
Parameters that are not required, don't need a `required: False`. This is implied.
Parameters that are not required, don't need a `required: False`. This is implied.
Parameters that are not required, don't need a `required: False`. This is implied.
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
It is not particularly critical, but my suggestion was to keep the same `for` loop, but add something like > while (!metadata.updateRequested()) Thread.yield() > metadata.update(...) or `Thread.sleep(1)` instead of `yield()`. Now each update corresponds to a request to update metadata from the `partitionsFor`. like it does in the real scenario. You need to make sure that the thread terminates in this case.
To be realistic, the second parameter should be `Collections.singleton(topic)` rather than `emptySet`.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
the `try{...} finally` has been removed
Do you think it would be clearer if we don't rely on the defaults, but just explicitly include both branches? Oh, also, this isn't an immutable builder, so you can just do: ```suggestion if (cachingEnabled) { stateStoreConfig.withCachingEnabled(); } else { stateStoreConfig.withCachingDisabled(); } if (loggingEnabled) { stateStoreConfig.withLoggingEnabled(new HashMap()); } else { stateStoreConfig.withLoggingDisabled(); } ```
nit: We could use `singletonMap` here.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
I've seen this a few places -- `SchemaAndValue` already has `SchemaAndValue.NULL` field which does the same thing -- no need to repeat a bunch of times in a bunch of classes.
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
I've seen alternative solutions floating around that use a configurable source here. Basically, the configuration passed to configure() is consulted to find the "source cluster", rather than looking at the topic name. That approach lets you return an actual source here, which obviates the new canTrackSource() method etc.
Think you might have forgotten to remove some debugging here
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
formatting: no need to curly braces
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
formatting: no need to curly braces
Ouch! Sorry about that!
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
`asList` -> `Collections.singletonList`
I think we don't need this method if we apply my other suggestions
Think you might have forgotten to remove some debugging here
Check TROGDOR.md. > All Trogdor RPCs are idempotent except the shutdown requests. Sending an idempotent RPC twice in a row has the same effect as sending the RPC once. Because the request is idempotent, sending it twice has the same effect, including the same result code.
nit: move below the shortcut return below.
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
to avoid extra memory taken by toArray() (it does copy array to new array object), we could create primitive array like: ```java String[] argsWithoutDebugFlags = new String[args.length]; ``` and then copy values in proper index by maintaining running index e.g. ```java int index = 0; for (String arg : args) { ... argsWithoutDebugFlags[index++] = arg; ... } ... return argsWithoutDebugFlags; ```
We'll need to fix this in a follow-up so that followers send the right replicaId.
nit: fix indention (we usually use 4 spaces, not 8)
nit: add `final`
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
Left this out of my previous review. This needs to change as well as it will return false for two `Segment` instances with the same `id`. Also, this statement will always evaluate to false as `Long.compare(x, y)` only returns `-1`, `0`, or `1`.
Typo: > or use the default RocksDB backend[] by providing ...
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
nit: add a size? There are a few cases in here where we could do this.
Why we need to call `streams.close()` inside the function given they are always called in `tearDown`? Ditto below.
OK, will remove before merging.
Is this intentional? cc @enothereska
Is this intentional? cc @enothereska
Why we need to call `streams.close()` inside the function given they are always called in `tearDown`? Ditto below.
nit: add a size? There are a few cases in here where we could do this.
It is more common in ansible modules to use: `domain=dict(required=True)`
That sounds good to me ð
@carljm, yes, I was a little confused, `bool()` will be enough.
It is more common in ansible modules to use: `domain=dict(required=True)`
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
This doesn't seem to be used.
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
prop: Please use `assertThat()` since it makes verifications a bit better readable.
prop: Please use `assertThat()` since it makes verifications a bit better readable.
prop: Please use `assertThat()` since it makes verifications a bit better readable.
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
I think it might be better to move this check into `ConsumerNetworkClient.RequestFutureCompletionHandler` to ensure that we don't forget any checks. Also `onFailure` seems like a more appropriate callback for that case,
nit: We could use `singletonMap` here.
`asList` -> `Collections.singletonList`
`asList` -> `Collections.singletonList`
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
nit ```suggestion expectedSensor, StreamsMetricsImpl.CACHE_LEVEL_GROUP, tagMap, hitRatio, HIT_RATIO_AVG_DESCRIPTION, HIT_RATIO_MIN_DESCRIPTION, HIT_RATIO_MAX_DESCRIPTION ); ```
nit ```suggestion expectedSensor, StreamsMetricsImpl.CACHE_LEVEL_GROUP, tagMap, hitRatio, HIT_RATIO_AVG_DESCRIPTION, HIT_RATIO_MIN_DESCRIPTION, HIT_RATIO_MAX_DESCRIPTION ); ```
We need to think about how we can avoid this. The package structure appears to be working against us.
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
Sorry, I thought the URL could be used to provide the username and password.
We should log an error that prints out what the two configs actually are
Nit: we don't normally use exclamation marks in Kafka log messages.
nit: 'else' can be dropped
```suggestion @override_settings( CSRF_FAILURE_VIEW=f'{__name__}.failure_view_with_invalid_signature', ) ```
Sorry for being late on this. Populating static variables from a non-static method is generally not a good practice since it's generally not thread-safe. Given how JMH works, it's fine for those fields to be non-static right? Also, it seems more realistic since the data is isolated per run.
nit: move to line above.
super nit: the message should explain what happened if the condition fails, ie it should be the opposite, something like ```suggestion TestUtils.waitForCondition(() -> !process.get(), "The record was not processed"); ```
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
This formatting is going to fail checkstyle. There seem to be other failures as well. For the changes in this patch, run `./gradlew clean clients:test` to make sure everything will pass.
Can we remove the `AndHighAvailabiltiyEnabled` suffix from the test name? And/or just generally shorten it if you have a better idea
Can we remove the `AndHighAvailabiltiyEnabled` suffix from the test name? And/or just generally shorten it if you have a better idea
nit: add a size? There are a few cases in here where we could do this.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Can we remove the `AndHighAvailabiltiyEnabled` suffix from the test name? And/or just generally shorten it if you have a better idea
How about the following to simplify the string construction below: ```java String clientEnabled = System.getProperty(ZK_SASL_CLIENT, "default:" + DEFAULT_ZK_SASL_CLIENT); String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, "default:" + DEFAULT_ZK_LOGIN_CONTEXT_NAME); ```
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
Just let the Exception flow, that will automatically fail the test
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
the condition is always false if you don't add brackets. ``` throw new IllegalArgumentException("Topic pattern to subscribe to cannot be " + (pattern == null ? "null" : "empty")); ```
the condition is always false if you don't add brackets. ``` throw new IllegalArgumentException("Topic pattern to subscribe to cannot be " + (pattern == null ? "null" : "empty")); ```
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Yeah, thinking about it more, I think either approach makes sense.
This would require a separate KStreamVoidTransformProcessor, but I feel it worth the internal cost for simpler public APIs.
Got it. Thanks. The patch LGTM.
I don't understand what this test is doing. Why do we need background clients instead of producing upfront and consuming the data mirrorred at the end of the test? It looks like we are testing the primary->backup scenario but we are restarting the backup cluster. The source connector should not interact with the backup cluster.
Admittedly, this is a random time to bring this up, but a pattern that I like for this is: ```java final long seed = providedSeed != null ? providedSeed : new Random().nextLong(); System.out.println("Seed is: " + seed); final Random rand = new Random(seed); ``` where `providedSeed` comes from an env variable, command-line arg, whatever... This way you get the same default behavior (pseudorandomly generated sequence of test values), but you also have the option to deterministically reproduce a previous pseudorandom sequence from a prior run. This can be helpful in diagnosing flaky tests. Not saying this is needed here; I just wanted to share the pattern.
Maybe we can close the first group here and verify that the sensors/metrics are no longer registered? A similar check for the sink would be good.
Maybe we can close the first group here and verify that the sensors/metrics are no longer registered? A similar check for the sink would be good.
Maybe we can close the first group here and verify that the sensors/metrics are no longer registered? A similar check for the sink would be good.
Admittedly, this is a random time to bring this up, but a pattern that I like for this is: ```java final long seed = providedSeed != null ? providedSeed : new Random().nextLong(); System.out.println("Seed is: " + seed); final Random rand = new Random(seed); ``` where `providedSeed` comes from an env variable, command-line arg, whatever... This way you get the same default behavior (pseudorandomly generated sequence of test values), but you also have the option to deterministically reproduce a previous pseudorandom sequence from a prior run. This can be helpful in diagnosing flaky tests. Not saying this is needed here; I just wanted to share the pattern.
```suggestion }, "The number of active tasks returned in the allotted time was not one."); ```
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
Single quotes. `item` is already a string.
Single quotes. `item` is already a string.
I think we can.
@ijuma For me it seems `isJava8Compatible()` could also be removed (with all its test usages)
Adding here these lines fixes the failures: ``` python if connection.features.interprets_empty_strings_as_nulls: self_converters.append(lambda val,*args: None if isinstance(val, six.string_types) and not val else val) ``` but this is getting uglier and uglier
You can't expose such thing in an exception.
nit: make the parameters final, and if you could put them on separate lines, similar to the `process` method on 327. Ditto for `assertNextOutputRecord` on lines 330 and 334 above.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
no need to use `this.` outside the constructor. Here and below
Unlike in the standalone, it's a bit more difficult to check how the connector configuration has changed. This `startConnector(...)` method seems to be called in two places: from `restartConnector(...)` and `processConnectorConfigUpdates`, which IIRC happens whenever the connector configuration has changed in some way. I'm wondering how often a connector might not change it's task configs when the connector config has changed. What do you think about just always restarting the tasks even if the generated task configs have not changed? WDYT? @kkonstantine, the `processConnectorConfigUpdates(...)` method is called during rebalances, and maybe I'm missing cases where the recent rebalance improvements handle the task configs more frequently than I recall.
Perhaps clarify to: "by transforming the value of each element in this stream into a new value in the new stream"
Perhaps clarify to: "by transforming the value of each element in this stream into a new value in the new stream"
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
You might consider using `OptionalDouble`.
nit. I think there is `.` missing `since 3.0[.] Use`
`endOffsets.get(topicPartition)` can be replaced by `offset`
`endOffsets.get(topicPartition)` can be replaced by `offset`
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
We can try that -- but we need to reduce `HEARTBEAT_INTERVAL_MS_CONFIG`, too, for this case -- its default is 3 seconds and it must be smaller than session timeout. Checking some existing tests, we have some that set them to 500ms / 1sec. Some other test reduce session timeout to 2 or 5 seconds...
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
I think we can.
We should limit this suppression to the method for which we really need it instead of the whole class
Something does not work as expected in this algorithm. According to this doc, the assignor should fall back to distributing tasks on least-loaded clients. However, the following test case fails: ``` @Test public void shouldDistributeTasksOnLeastLoadedClientsWhenThereAreNoEnoughUniqueTagDimensions() { final Map<UUID, ClientState> clientStates = mkMap( mkEntry(UUID_1, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_1), mkEntry(ZONE_TAG, ZONE_1)), TASK_0_0)), mkEntry(UUID_2, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_2), mkEntry(ZONE_TAG, ZONE_2)), TASK_0_1)), mkEntry(UUID_3, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_2), mkEntry(ZONE_TAG, ZONE_1)), TASK_0_2)), mkEntry(UUID_4, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_2), mkEntry(ZONE_TAG, ZONE_1)), TASK_1_0)) ); final Set<TaskId> allActiveTasks = findAllActiveTasks(clientStates); final AssignmentConfigs assignmentConfigs = newAssignmentConfigs(1, CLUSTER_TAG, ZONE_TAG); new ClientTagAwareStandbyTaskAssignor().assign(clientStates, allActiveTasks, allActiveTasks, assignmentConfigs); assertEquals(1, clientStates.get(UUID_1).standbyTaskCount()); assertEquals(1, clientStates.get(UUID_2).standbyTaskCount()); assertEquals(1, clientStates.get(UUID_3).standbyTaskCount()); assertEquals(1, clientStates.get(UUID_4).standbyTaskCount()); } ``` The standby task for active task 0_0 can be put on client UUID_2 and the standby task for active task 0_1 can be put on client UUID_1 without breaking rack awareness constraints. Standby tasks for active tasks 0_2 and 1_0 cannot be put on any client without breaking rack awareness, so they should be distributed on least-loaded clients. However, that does apparently not happen, because client UUID_3 and UUID_4 are not assigned any standby.
I think we can.
I think we can.
nit: Indicate that this needs deep iterations on the entries.
Ditto on removing before/after
Could use `equalsIgnoreCase` directly.
This was probably left by mistake.
How about adding a `coordinators` method to `FindCoordinatorResponse` which would either return the list of coordinators (`data.coordinators()`) if not empty or would return a list containing a `Coordinator` created from the top level information. That would remove all the `batch` checks below.
How about adding a `coordinators` method to `FindCoordinatorResponse` which would either return the list of coordinators (`data.coordinators()`) if not empty or would return a list containing a `Coordinator` created from the top level information. That would remove all the `batch` checks below.
Do we still need `needsJoinPrepare` now? It seems to me that we need to call `onJoinPrepare` whenever `needRejoin` is true.
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
As above: add a `topologyDescription` verification step -- we should see a repartition topic. We should also not get a state store when reading the data from the repartition topic into the `KTable` for this case.
We'll need to think carefully about this. The proposed change could break some tests that had multiple DataSources. Previously, if there was no primary DataSource, no DataSources would be replaced and if there was a primary DataSource, only that DataSource would be replaced. This change will result in all DataSources being replaced which may not be what someone wants. Perhaps we need another mode for `replace`, I'm not sure yet.
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
Also not clear why "numSegments - 1" here.
Also not clear why "numSegments - 1" here.
nit: some extra newlines here.
nit: some extra newlines here.
we can make method this public in `EmbeddedConnectCluster`.
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
> Hmm, for production, do we ever restart a thread even for illegal-state or illegal-argument? If the user decides to restart a stream thread in its exception handler it is possible.
See #1353 for a suggestion for consistent naming of parameters that indicate a count of items to be emitted across operators with such parameters.
There's really no reason to remove that.
Thanks for the explanation. Make sense.
The second param seems redundant.
```suggestion - number of functions to activate on interface. ```
Looks good. I like the additional checking that you're doing here.
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
// and if auto-commit disable or the coordinatorUnknown is true, the future will be // the asynchronous commit operation will not do. --> // null future means no offset commit request sent, so it is still considered completed
Mode getstr also returns `contents` in addition to msg.
Looks good. I like the additional checking that you're doing here.
Add a log saying that internal strings are used since inputValues.txt is absent.
Let's rename `headers1` and `headers2` here too
Add a log saying that internal strings are used since inputValues.txt is absent.
We shouldn't return `null`, but instead return a "unknown query" result.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
Other classes implement this as: ``` this.processorName = name; return this; ``` Why the difference? I we think that using this pattern to guaranteed immutability is better (what might be a good idea), we should consider to rewrite _all_ code -- of course, if a separate PR). I cannot remember atm, why we did not implement similar method immutable? Can you remember @bbejeck? We introduced this pattern with KIP-182.
nit: add `final` and put single parameter per line
We shouldn't return `null`, but instead return a "unknown query" result.
nit: `addMetadata` -> `put`
ð I "have a friend" who sometimes puts new classes in the same package so that they can use package private methods. This friend understands that such code is brittle.
"InMemoryKeyValueIterator" -> `getClass().getName()
nit: add `final`
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: use `IntegrationTestUtils#safeUniqueTestName` for the name
nit: add `final`
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
This was probably left by mistake.
We should include `startPosition` in the message.
Is this check correct? A `Coalesce` can still result in a null value (if all of its arguments are null), so even if the expression is already a `Coalesce` ISTM it needs to be wrapped again (or have `Value('')` added to the end of its `source_expressions`, but just wrapping in another `Coalesce` seems cleaner).
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
We typically avoid the `get` prefix in Kafka, so `objectName` seems fine.
Nit, to improve readability and precision, especially around how many Kafka transactions would be used: > Whether to enable exactly-once support for source connectors in the cluster by using transactions to write source records and their source offsets, and by proactively fencing out old task generations before bringing up new ones.
I think this and following usages around `latestSupportedVersion` are related to the upcoming version probing code. It's a little mysterious to have a "latest supported version" always equal to the "current version" in this PR in isolation, but I don' think it's actually problematic.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
we're in Java8 now... I think you can do: `(key,value,context) -> { ... }`
we're in Java8 now... I think you can do: `(key,value,context) -> { ... }`
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
I meant to have all "singulars" for consistency, i.e * Creates a * Starts the * Shuts down this * Does a clean up I'm OK with imperative style.
Is it really worth having this catch here? I think it's best to just let the exception propagate. Any method under test can throw an unknown exception after all.
I meant to have all "singulars" for consistency, i.e * Creates a * Starts the * Shuts down this * Does a clean up I'm OK with imperative style.
This always scheduled in the future with `timeout`. Shouldn't it be the time until next timeout? Let's say timeout is 1000ms and I get an onNext call every 50ms. This code seems to schedule each action to execute 1000ms in the future even if it comes in 950ms since the last onNext was permitted through.
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
Let's rename the method to be more explicit about what we're updating here. ```suggestion public void updateCallRetryContext(CallRetryContext failedCallRetryContext) { ```
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
Please introduce line breaks in the docstring to avoid very long lines.
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
What is the value in separating the `set` and `done` methods? The one place where I can see that they are separated by some other code it looks like moving the `set` next to the `done` doesn't affect the tests at all.
typo: we want to test the **case** that poll() returns no records.
This should return `-1` as old `BadValueTransformer`
Shouldn't this look for other whitespace characters, per the exception message? Something like: ```suggestion if (headerName.isEmpty() || headerName.matches("\\s")) { ```
Shouldn't this look for other whitespace characters, per the exception message? Something like: ```suggestion if (headerName.isEmpty() || headerName.matches("\\s")) { ```
Is it valid to have a blank string as the replacement value? If not, then the `replacement` config should have a validator that prevents using invalid values, and it probably would be good to succinctly describe the limitations in the doc string. And it may be better to only set `this.replacement` to a non-null string that should always be used. This would centralize the logic of determining whether it should be used in one place, and line 135 becomes a lot simpler and more efficient: ```suggestion if (replacement != null) { ```
Is it valid to have a blank string as the replacement value? If not, then the `replacement` config should have a validator that prevents using invalid values, and it probably would be good to succinctly describe the limitations in the doc string. And it may be better to only set `this.replacement` to a non-null string that should always be used. This would centralize the logic of determining whether it should be used in one place, and line 135 becomes a lot simpler and more efficient: ```suggestion if (replacement != null) { ```
Is it valid to have a blank string as the replacement value? If not, then the `replacement` config should have a validator that prevents using invalid values, and it probably would be good to succinctly describe the limitations in the doc string. And it may be better to only set `this.replacement` to a non-null string that should always be used. This would centralize the logic of determining whether it should be used in one place, and line 135 becomes a lot simpler and more efficient: ```suggestion if (replacement != null) { ```
Shouldn't this look for other whitespace characters, per the exception message? Something like: ```suggestion if (headerName.isEmpty() || headerName.matches("\\s")) { ```
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
We should limit this suppression to the method for which we really need it instead of the whole class
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
That was my other thought. We might wrap one DataException into another but that's not a big deal. In this code `Decimal.toLogical` is now used, and if you follow the refs, there's a `new BigInteger(value)` in there that might throw `NumberFormatException`. Improbable, but thought we could be on the safe side with the more general catch block.
```suggestion return Collections.emptyList(); ```
This will close the `SocketChannel` before it can be used by `TimeoutAwareChannel`. It's eventually closed when the `TimeoutAwareChannel` is closed so this is change isn't needed. I'll address this while merging.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
This should be new `ValueMapperWithKey`
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
That's a good point.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
This is assuming that `totalTopics` is always a multiple of `MAX_BATCH_SIZE. Is that always true? Perhaps it is better not to make that assumption in any case.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
generics can be inferred here.
Most tests end up calling this method twice, once explicitly and once via `teardown()`. Let's pick one way and stick with it.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
generics can be inferred here.
generics can be inferred here.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
recommend sticking with T, U, V (or A, B, C for higher-kinded) type parameters
nit add `a {@link Named} config`
using a builder and string concat? maybe just `append("blah").append(var).append("\n");
redundant type arguments `<ProducerRecord<byte[], byte[]`
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Seems like a no-op
There's really no reason to remove that.
Nit: might be worth adding a simple assertion on the result just to make sure.
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
Could we rename this to something like "remainingPartitions"
Could we rename this to something like "remainingPartitions"
I think we may be able to remove this if we just initialize `nextSequenceNumber` to 0. Then we wouldn't need `hasSequenceNumber` as well.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
Same for generation and member.id. We could just call `request.data().generationId()`
Looks good. I like the additional checking that you're doing here.
It should be public as it will be used in `producer` APIs.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
@Ishiihara Do we still need this check? Based on the usage above and since the method is private, it seems safe to assume that the tasks all match the connector.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
To get rid of the test failure, you need to change this: ```suggestion final KafkaMetric metric = metrics.metric(new MetricName("prefix-scan-rate", STORE_LEVEL_GROUP, "", tags)); ``` Sorry, the failure of the test is my bad. I missed the issue with the different metrics versions when I requested to change this in a previous review.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Looks good. I like the additional checking that you're doing here.
nitpick: it's a little weird to use `Boolean.TRUE` instead of just `true`.
The additional validation doesn't hurt, but it might be more natural to move this check into the `if` below since we don't actually cast unless the condition is true.
It's a little unclear as to how we are removing things from the cache here. If I understand correctly, we stick an empty Optional in the cache to represent removal. And here by _not_ handling the empty optional case, we exclude the broker from the new image. But if that's the case, why do we need the Optional in the first place? Can we directly remove the broker from "changedBrokers" when handling UnregisterBrokerRecord? This question applies to some other Delta classes that are using Optional as well
The additional validation doesn't hurt, but it might be more natural to move this check into the `if` below since we don't actually cast unless the condition is true.
The additional validation doesn't hurt, but it might be more natural to move this check into the `if` below since we don't actually cast unless the condition is true.
`PrintForEachAction<>` to remove warning. Also in the `print` method
Could we fail the test right here? It doesn't seem like there is much benefit to returning the missing metrics from the method. That would let us simplify this a little. Instead of this: ```java Set<String> missingMetrics = getMissingMetricNames(expectedMetricNames, expectedGroup, expectedType); assertEquals(Collections.emptySet(), missingMetrics, "Expected metrics did not exist"); ``` we could have: ```java assertRegisteredMetrics(expectedMetricNames, expectedGroup, expectedType); ``` We could probably also drop `expectedGroup` since we only have `kafka.controller`.
It would be nice to have a unit test for this.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
rewrite test as above using `assertThrows()`.
The issue with using a real file is that you can't test the scenario that we are trying to fix: `FileChannel.read` returns before the buffer is full. See `FileRecordsTest.testTruncateNotCalledIfSizeIsBiggerThanTargetSize` for an example of a mocked fine channel.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
I think `kafkaOffset` was incorrectly changed to `Long`. We'll always have a Kafka offset, so it should be `long`. Also, the current version breaks compatibility since the old signature constructor is no longer available.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Alright, let's revert that part then please. Thanks!
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
the `try{...} finally` has been removed
I might be missing something, but in both cases, you just want to use regular expressions, right? There is no need to mess around with predicate functions.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
nit: add a size? There are a few cases in here where we could do this.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Suggestion: ```text Returns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`. If this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire). ``` ```
Hmm, why did we do this? I thought we'd have a try/catch block.
Nit: why not use `boolean`
Nit: why not use `boolean`
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
It seems like these calls could be updated to use the `Record` itself instead of the key, value, and `InternalProcesorContext#recordContext`.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Should we produce the input before we start the KS instances? If there is no input, it's clear that Standbys won't restore as there is not data for restoring.
Should we produce the input before we start the KS instances? If there is no input, it's clear that Standbys won't restore as there is not data for restoring.
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
While I think it would be fine, it would be "new" -- if we think `instance` is better, we might want to migrate all other code lazily to use `instance`, too. It's always best to have the same naming conventions throughout the whole codebase IMHO.
nit: add a space before the `:`.
Is this necessary? The leader epoch is -1 by default.
I think we can remove the mention of the rebalance listener since it is not invoked in this context.
IN `CommonClientConfigs`, it seems like we use `DEFAULT_...` instead of `..._DEFAULT`.
Let's use `epoch` instead of `currentEpoch`. Since we are using `currentEpoch`, the `endOffsetForEpoch.offset` will equal the LEO. If you instead use `epoch` then the `endOffsetForEpoch.offset`. will be `4` which is less than the LEO (`5`).
It seems relevant to the implementer whether the configs have been validated or not. If they're not guaranteed by the contract to have been validated then the implementer might need to duplicate some of the validation logic in this method.
nit: style seems to be to not include braces when there is only one if or else statement
nit: style seems to be to not include braces when there is only one if or else statement
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Ahhhh damn, I think you've mentioned that problem before What if JMH would be event/callback based so we could benchmark async code like RxJava in a reactive manner? ie: ```java @Benchmark public void flowable(BenchmarkObserver benchmarkObserver) { flowable.subscribe(this, Functions.emptyConsumer(), new Action() { @Override public void run() throws Exception { benchmarkObserver.onComplete(); } }); } ```
This line is failing checkstyle.
This line is failing checkstyle.
This line is failing checkstyle.
I think we're testing `testDir` Occupied here, not `AppDir`.
```suggestion public void shouldIgnoreIrrelevantLoadedCheckpoints() throws IOException { ```
I think key-pairs of strings as list is brittle. But we inherited that.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
@davispw I think this was just done defensively since the ExecutorService means some state will be mutated in another thread (you'll notice the Kafka*BackingStore implementations aren't synchronized). Since we're only touching the `executor` field here and it should be thread safe anyway, I think we can drop the synchronization.
@davispw I think this was just done defensively since the ExecutorService means some state will be mutated in another thread (you'll notice the Kafka*BackingStore implementations aren't synchronized). Since we're only touching the `executor` field here and it should be thread safe anyway, I think we can drop the synchronization.
typo: byteArrray -> byteArray
rewrite test as above using `assertThrows()`.
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Maybe we can just a better name for `path` since it makes this code look suspicious.
This message is a little strange. We can certainly represent the topic id, but it is invalid. I wonder if it would make sense to raise `IllegalArgumentException` directly instead of through the result since this is likely a logical error of some kind.
Could we use `TestUtils.waitForCondition`? That will time out if it takes too long for the condition to become true.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
Indeed, we would want to verify that. It didn't look like it was when I originally checked, but I may have missed something.
Right, sorry I misread that line.
Right, sorry I misread that line.
Right, sorry I misread that line.
req: I think we want to introduce some `acceptableLag` config within which a task is considered caught-up, otherwise this is way too strict. ie the condition should be `lag <= acceptableLag`
Since this is a fairly complex assignment process, I wonder if it would help to break it down into smaller functions (maybe one for each step?). Otherwise, this is going to be a pretty intimidating chunk of code for newcomers.
Right, sorry I misread that line.
Since this is a fairly complex assignment process, I wonder if it would help to break it down into smaller functions (maybe one for each step?). Otherwise, this is going to be a pretty intimidating chunk of code for newcomers.
Ah, I see that the state directory is being purged here. But I think this @After-approach may not work if the test crashes or the JVM terminates before `shutdown` is being called, right? (e.g. due to Jenkins woes) I think it would be safer to purge the state dir prior to the run.
Ah, I see that the state directory is being purged here. But I think this @After-approach may not work if the test crashes or the JVM terminates before `shutdown` is being called, right? (e.g. due to Jenkins woes) I think it would be safer to purge the state dir prior to the run.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
How about using `e.toString()`? It shows the class name of exception. I feel it is useful also.
Nit: why not use `boolean`
How about using `e.toString()`? It shows the class name of exception. I feel it is useful also.
Should we produce the input before we start the KS instances? If there is no input, it's clear that Standbys won't restore as there is not data for restoring.
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
Possibly my favorite aspect of this PR is that you have reminded me that `SchemaBuilderException` is even a thing that exists...
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
There should never be multiple requests, right? If there were, a second request might arrive between 168 and 169, violating the desired property. In that case, we should grab a lock instead. As long as there's only one requesting thread, and it always waits for the commit right after requesting, then we should be good.
I think key-pairs of strings as list is brittle. But we inherited that.
Good call-- thanks for the correction.
nit: add `final` (same line below)
I think we ditch the before/after methods as I previously recommended.
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
nit: parameters on a separate line
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
`2` -> `entries.size() - 1`
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
It can sometimes be hard to get the logs for failing tests, so it might be nice to get the failure reason in the actual test output. Check out `Matchers`: there should be a way to compose the checks you're doing here manually. It'll be something like: ``` assertThat( message, is( oneOf( containsString("Cannot get state store source-table because the stream thread is PARTITIONS_ASSIGNED, not RUNNING"), containsString("The state store, source-table, may have migrated to another instance") ) ) ```
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
Maybe we can just a better name for `path` since it makes this code look suspicious.
well, i thought a method reference would work here for the hash map, but I tried it and it doesn't seem to work. ð¤
Need to fix indentation below.
getter and setter should be removed
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
Sounds good. I just want to avoid someone trying to simplify the tests in the future without understanding that this test is verifying both features work together.
It seems this test is always using `Cluster.empty()`, which means it never tests state transitions from a topic that is in use to a topic that falls out of use and gets `UNKNOWN_TOPIC_OR_PARTITION` errors.
It seems this test is always using `Cluster.empty()`, which means it never tests state transitions from a topic that is in use to a topic that falls out of use and gets `UNKNOWN_TOPIC_OR_PARTITION` errors.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
Can we also rename `StreamsGraphNode` to `GraphNode`? The `Streams` prefix is a bit confusing, IMO, because `StreamSourceNode` and `StreamsGraphNode` seem really similar although they are quite different.
Can we also rename `StreamsGraphNode` to `GraphNode`? The `Streams` prefix is a bit confusing, IMO, because `StreamSourceNode` and `StreamsGraphNode` seem really similar although they are quite different.
If I read the source correctly, this can be simplified to ```suggestion monkeypatch.setitem(C.config._base_defs, 'GALAXY_CACHE_DIR', cache_dir) ```
the message will be `Checking None URL` if `format_id` is not available, provide a fallback for `format_id`.
the message will be `Checking None URL` if `format_id` is not available, provide a fallback for `format_id`.
There is nothing yet for Spring AMQP 2.1. More over we only talk about a compatible dependency. So, if you don't use Spring Boot but only Spring AMQP, you should override dependency manually. That's all. Otherwise with the Spring Boot everything is transparent for you. And yes: that is really too much to support...
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
`log` not used
should it be `putIfAbsent` (cf `cleanUpTaskProducer()`)
typo: we want to test the **case** that poll() returns no records.
This seems to be a "hack" -- IMHO, as task should be only in either one set/list, but never in both... Can we change the first loop to use an explicit iterator and remove a task from `tasksToCloseClean` when we add it to `tasksToCloseDirty`
This seems to be a "hack" -- IMHO, as task should be only in either one set/list, but never in both... Can we change the first loop to use an explicit iterator and remove a task from `tasksToCloseClean` when we add it to `tasksToCloseDirty`
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Fair enough. Let's leave it as-is.
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
Nice tidy up of this test class :-)
Nice tidy up of this test class :-)
New tests pass without this change.
I really like the fact that we are separating Resources from ResourcePatterns! Great job.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
may be use Objects.requireNonNull
We should limit this suppression to the method for which we really need it instead of the whole class
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
We should limit this suppression to the method for which we really need it instead of the whole class
We should limit this suppression to the method for which we really need it instead of the whole class
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
nit: add a size? There are a few cases in here where we could do this.
Nothing, it is just my personal preferences and it was just a suggestion.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
This list is small anyway, so I'm not too worried about the cost, but this seems wasteful. Seems like this promotion check should be a simple lookup in a precomputed table.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
nit: should be `Deserializer<?>` to avoid warnings about using a raw type
nit: unneeded newline
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
same as above for parameters
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
```suggestion // TODO K9113: this is used from StreamThread only for a hack to collect metrics from the record collectors inside of StreamTasks ``` Just marking this for later follow-up.
nit: space after `try`.
nit: add `final`
Just want to check my understanding. The user may attempt to commit offsets while the broker has a JoinGroup in purgatory. In this case, we would send the older generation which would be doomed to fail with `ILLEGAL_GENERATION` once the join completes. In this case, should we still reset the generation as we do below? I am wondering if it is useful to remember the generation that an offset commit was sent with (perhaps inside `OffsetCommitCompletion`) so that we only reset if necessary.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Rather than using a `String` there you could use a `Resource`. That way the binder will do the work of making sure that resource is valid (if set).
Rather than using a `String` there you could use a `Resource`. That way the binder will do the work of making sure that resource is valid (if set).
Rather than using a `String` there you could use a `Resource`. That way the binder will do the work of making sure that resource is valid (if set).
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Good point, thanks!
The second param seems redundant.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
nit: simpler or not? ```java Map<String, Uuid> newTopicIds = topicIds.entrySet().stream() .filter(entry -> shouldRetainTopic.test(entry.getKey())) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue)); ```
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
Maybe we could use a different value here.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
I think this may race with the termination of the generated `Observables` if they are async.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
@lindong28 I think the 12 wait for updates in the loop may be too many since max.block.ms=10min? It will be good to ensure that the test doesn't leave the thread running even if the test fails.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
Not clear why we want to use a separate thread to call `joinGroupIfNeeded`? In unit test we would try to avoid any unnecessary multi-threading as it can easily cause flaky tests.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
It is not particularly critical, but my suggestion was to keep the same `for` loop, but add something like > while (!metadata.updateRequested()) Thread.yield() > metadata.update(...) or `Thread.sleep(1)` instead of `yield()`. Now each update corresponds to a request to update metadata from the `partitionsFor`. like it does in the real scenario. You need to make sure that the thread terminates in this case.
Sorry for that -- You are of course right. `final` only for iterator loops...
Could we fail the test right here? It doesn't seem like there is much benefit to returning the missing metrics from the method. That would let us simplify this a little. Instead of this: ```java Set<String> missingMetrics = getMissingMetricNames(expectedMetricNames, expectedGroup, expectedType); assertEquals(Collections.emptySet(), missingMetrics, "Expected metrics did not exist"); ``` we could have: ```java assertRegisteredMetrics(expectedMetricNames, expectedGroup, expectedType); ``` We could probably also drop `expectedGroup` since we only have `kafka.controller`.
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
Let's use try with resources here and the other test so that the file is closed after it's used.
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
Ah, my bad. I think the variable I had in mind is actually called `Double.BYTES`. Not 100% sure it's defined for all possible primitive types, but I would hope so
Even though the config is invalid, the passwords may be valid, so it seems safer not to include them. It would be nice if the sensitive entries in the JAAS config would be communicated in some way to improve debuggability (in the future). Btw, a nit: we seem to use inconsistent capitalisation of the word JAAS in our messages. It would be nice to make that consistent.
Sorry for that -- You are of course right. `final` only for iterator loops...
Even though the config is invalid, the passwords may be valid, so it seems safer not to include them. It would be nice if the sensitive entries in the JAAS config would be communicated in some way to improve debuggability (in the future). Btw, a nit: we seem to use inconsistent capitalisation of the word JAAS in our messages. It would be nice to make that consistent.
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
nit: add a size? There are a few cases in here where we could do this.
Sorry for that -- You are of course right. `final` only for iterator loops...
nit: add a size? There are a few cases in here where we could do this.
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
Could we just add a toString function to ProcessorNode / SourceNode / SinkNode so that this code just becomes: ``` print(node) { // node.toString // also include listing children names foreach(child <- children) print(child). } ``` And also you do not to maintain the mapping as well.
nit: add a size? There are a few cases in here where we could do this.
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
I think we should call `deserializer.close()` here
nit: if you want a new paragraph you need to add `<p>`
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
formatting: no need to curly braces
formatting: no need to curly braces
nit: ```suggestion final Set<String> logMessages = appender.getEvents().stream() .filter(e -> e.getLevel().equals("WARN")) .map(LogCaptureAppender.Event::getMessage) .collect(Collectors.toSet()); ```
formatting: no need to curly braces
typo in the test name.
typo in the test name.
Other classes implement this as: ``` this.processorName = name; return this; ``` Why the difference? I we think that using this pattern to guaranteed immutability is better (what might be a good idea), we should consider to rewrite _all_ code -- of course, if a separate PR). I cannot remember atm, why we did not implement similar method immutable? Can you remember @bbejeck? We introduced this pattern with KIP-182.
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: avoid `this` if not required.
nit: avoid `this` if not required.
nit: avoid `this` if not required.
nit: move parameter to it's own line (same below)
Seems to fit in one line
This should go away. `@ConditionalOnClass` already does that.
nit: I don't spot any, but safer to avoid typos by just having constants for these
nit: There is an extra space before `+`.
nit: I don't spot any, but safer to avoid typos by just having constants for these
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
Instead of doing this, we can simply override `toString` in each enum. However, if we go with my suggestion of renaming the enum values, the `toString` will be the right one by default, I think.
nit: if you want a new paragraph you need to add `<p>`
i think this would be better off as a test rather than in `setUp`
typo: byteArrray -> byteArray
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
As above: use `assertThrows` and verify error message
It may also be useful to assert that the current consumer position is equal to `rde.offset`.
Might be simpler to use the mock deserializer only for values.
Maybe this should be trace level. I can imagine it being very spammy when you have a lot of partitions. Also, we usually capitalize the first word.
Maybe we can just a better name for `path` since it makes this code look suspicious.
It should be 'false' by default
Since asserts are not enabled in any environment at the moment, can we just do plain checks? Also, it's a bit nicer if we include a brief error message.
I think we should call `deserializer.close()` here
Another name might be `seek()`.
Nit: go with single parameter per line.
Seems like it would be better to add a `toString` to the segment or superclass.
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
I still miss the overload `observeOn(Scheduler, boolean delayError, int bufferSize)`
may be use Objects.requireNonNull
Oh, I guess I missed `shouldNotReportOffsetSumsForTaskWeCantLock()`. No, I did not have something different in mind.
Look like a ProcessingContext builder method while it is not. Wouldn't it be better to keep this void
Use single quotes.
Use single quotes.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
Sound like it uses `Properties` class (while it doesn't) -- but maybe I am overthinking this... Should be fine.
We cannot pass `connection` in the `__init__()` because it breaks e.g. `deepcopy()`. I decided to add a separate hook `set_wrapper_classes()`, it is not the cleanest solution, but it's not the end of the world :globe_with_meridians: , and we don't have much time before the feature freeze :clock1: .
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
Yeah, you can use a volatile field and synchronize on the assignment if still null. And then file a separate Jira to remove it from the class in a separate PR.
Ah, I didn't knew there was a template :) Well, in that case, keep it. It doesn't really hurt.
`.toString()` unnecessary here are other similar logs.
```suggestion // Value `null` is valid for an optional field, even though the field has a default value. ```
```suggestion // Value `null` is valid for an optional field, even though the field has a default value. ```
We could make this field access `public`
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
Maybe something like "No command specified" would be more descriptive
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Maybe something like "No command specified" would be more descriptive
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
Seems the only thing we really care about is offset commits when shutting down. As long as we send the LeaveGroup, it's probably fine not to await its response (because of one of your previous patches). Because we now have the check for `pendingAsyncCommits`, I'm wondering if it's actually necessary to await all pending requests from the coordinator? At least if we keep the check, maybe we could ensure that we are not in the middle of a rebalance since that would unnecessarily delay shutdown.
We can inline this like you've done for the byte[] case below
I think we should have a `log.info()` here to show the error. I'm afraid users might miss some error statuses once they get overridden, so it's good to have it persisted somewhere
I think we should have a `log.info()` here to show the error. I'm afraid users might miss some error statuses once they get overridden, so it's good to have it persisted somewhere
nit: Could we add some java doc here to explain why we need this? Thanks.
I was looking up the format in more detail and understand now what going on. The code does not seem to be ideal IMHO, but no need to change it in this PR.
Thanks for cleaning up the code duplication.
There is a built-in for this `Function.identity()`
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
why use `topicName` here? Should it not be `failed: key=X actual=A expected=B...` instead of `failed: key=X <topicName>=A expected=B...`
This can be removed
Both `GZipInputStream` and `SnappyInputStream` read the header in the constructor, so it would make sense to me to remain consistent in that respect.
```suggestion response, info = fetch_url(module=module, url=base_url, headers=json.loads(headers), method='GET') ```
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
We will return an empty assignment while the group is rebalancing. Rebalances can sometimes take a little while to complete, and we have found it useful to still be able to show the members when the group is in this state.
I was mostly trying to get rid of the word `Node` because it's a bit redundant when you look at the log messages.
Also set the store name in this test.
@hachikuji Yes, that sounds good to me. It should reduce heap usage when there are lots of requests requiring down-conversions while still avoiding blocking the network thread.
debug line should be removed.
Could also use `Collections.singletonList`, which would also make this immutable
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Not sure why it's the case? I think the previous pending txn should have aborted in step 4.
We didn't have it before, but maybe we should add a null check here for more resilience in the future.
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Copy/paste bug: should be "source."
If I change the name of the property source to be something else than this, the test fails. The `PropertySource` implementation and its name are irrelevant for this, it could be anything.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Might be simpler to just update the Jira and do all at once? > Any thought about how the prefix text should look like? The suggestion you made via wrapping one `IllegalArgumentException` with the other, was good. Just you proposed "outer" error message could be used to be passed in as prefix.
I think this `if` block can be written this way too so we can avoid the extra nesting (since Java performs short-circuit evaluation for `&&` and `||`): ``` if (subscriptions.isAssigned(tp) && subscriptions.isOffsetResetNeeded(tp) && !resetOffset(tp)) failedPartitions.add(tp); ```
SGTM. If we find it flooding the logs and not helpful we can reconsider
nit: `log.error("Exception caught while post-committing task: {}", task.id(), e);`
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
this _technically_ changes the public interface and would require a KIP if we're being pedantic about the process. I personally think we can go by without a KIP but we obviously need a committer to say what they think
No, we have to fix it before AK 2.0. Once it is in a released API, we canât change it.
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
I don't think this is necessary. The SecurityFileChangeListener thread may not yet have started, but the watch services are already registered after `factory.configure(configs)`. The file change below should queue a change even if the thread hasn't started.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Much appreciated. I probably should have done this when I created the first of these test cases, but thanks for helping to clean things up.
I think we should consider add a byte for indicating versions so that we can have better upgrade patch in the future in case we are evolving the serialization format. Similar rationales for versioning RocksDB state files and subscription metadata, or anything that involves serdes.
typo: moreq -> more
Nit: var should be named `deserializeValue`
Can't you use `createClient`? This call confused me... (same below)
Can't you use `createClient`? This call confused me... (same below)
Nit: var should be named `deserializeValue`
Nit: If we do fix up the above example of this it makes sense to fix this up too.
nit: 'else' can be dropped
Sorry, ignore this. I'd missed that there are two URIs being configured, one with credentials and one without.
Can we actually just get rid of "test only" constructors? It couldn't be used by _that_ many different tests...
This will end with a comma after the last transformation.
using a builder and string concat? maybe just `append("blah").append(var).append("\n");
How about keeping this `private` and adding a protected `isCancelled()` method? Currently, the `cancelled` field is encapsulated entirely within the `WorkerTask` class, and modified only via the public `cancel()` method. We can just as easily keep the encapsulation. OTOH, if we were to make `cancelled` protected, we'd lose that encapsulation and make it a bit more complicated if a future developer did want to add logic upon cancellation.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
Ah got it, I'm still think about it as the string template and was overlooking that. SG.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
While we're at it, we may as well use another `{}` substitution for the parameter and remove the unneeded `toString()`.
Preexisting, but should this be an error log? (seems to be implied by the text of the log)
While we're at it, we may as well use another `{}` substitution for the parameter and remove the unneeded `toString()`.
This also changes behaviour as any exception thrown from `close(context)` will no longer be caught.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
Perhaps: `With the COOPERATIVE protocol, owned partitions cannot be reassigned...`
Perhaps: `With the COOPERATIVE protocol, owned partitions cannot be reassigned...`
@mimaison It is true that the test would check only one class depending on the JRE. But it checks that the relationship between `java.vendor` and Kerberos classes matches the expectation in the code (for that JRE). The other unit test is checking if String comparison works, which is fine as a unit test, but it doesn't really test the actual System property based on the JRE.
`instantiateConfigProviders` since this is potentially creating multiple providers
`instantiateConfigProviders` since this is potentially creating multiple providers
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Look like a ProcessingContext builder method while it is not. Wouldn't it be better to keep this void
Look like a ProcessingContext builder method while it is not. Wouldn't it be better to keep this void
nit: 'else' can be dropped
I don't have a good place to put this... on line 208, if commitSync was succesfull, we still need to call workerThread.onCommit().
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
nit: parameters on a separate line
This was probably left by mistake.
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
nit: this loop is a little unconventional. Maybe we could use `pollFirstEntry` instead of the iterator? Similarly in `setNumKip500BrokerNodes`.
We should limit this suppression to the method for which we really need it instead of the whole class
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
This approach will be useful sometimes but other times I will want an error on close to be suppressed. This is a common pattern for reading from an InputStream. Once we call close() we have finished our reading and just want to clean up and if the resource has already been closed or invalidated we don't really care. I'm unaware what behaviour results when unsubscribe itself throws an exception and can't write a test at the moment.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
I think I would move the method to a test utility so that tests can use that instead.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Updated this when merging.
Can you enclose the body of if block with curly braces ? Same with else block. It is easier to read.
`.toString()` unnecessary here are other similar logs.
nit: "topic name to limit search to. REQUIRED if --partition is specified."
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
I think the name of the function is better defined as `interleaveTasksByConsumers`
I think the name of the function is better defined as `interleaveTasksByConsumers`
I think the name of the function is better defined as `interleaveTasksByConsumers`
nit: -> `shouldThrowForInvalidSocketReceiveBufferSize()`
nit: -> `shouldThrowForInvalidSocketReceiveBufferSize()`
Looks good. I like the additional checking that you're doing here.
nit: -> `shouldThrowForInvalidSocketReceiveBufferSize()`
Looks good. I like the additional checking that you're doing here.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
I think the name of the function is better defined as `interleaveTasksByConsumers`
Looks good. I like the additional checking that you're doing here.
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
Nit: `assertThat` take expected result as first parameter IIRC (otherwise error message on failing test is "reversed")
one parameter per line
An unhandled `SuspiciousOperation` will result in a `400 Bad Request` response which is ok since it is a client error. However, `413 Request Entity Too Large` would be the correct status code for this error.
nit: `addMetadata` -> `put`
as above `final` and one parameter per line
nit: break line
nit: could be useful to log the type of exception in the assertion message.
nit: could be useful to log the type of exception in the assertion message.
nit: could be useful to log the type of exception in the assertion message.
nit: ... suspended task is not reassigned
I like the extra-detailed error messages, thank you.
The restore consumer needs to override one param: `consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");`
This appears to be untested
This is using the "try-with-resources statement" so it will take care of the close.
nit: add `final` -- same next line
Nit: can be `final`
Nit: can be `final`
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
The "Swallowing the exception" is a bit alarming at first. It's true that if this method returns false then `TestUtils.waitForCondition` (which is using this method as the test condition) will fail at line 137. Pretty minor, but how about the following? ``` // Log the exception and return that the partitions were not assigned log.error("Could not check connector state info.", e); return false; ```
Instead of moving this check internally to the loop, can we add an `else` call after the original if condition that, if `topicToTaskIds` is not empty, log a single warning entry that `Topics {} do not exist but ...` with `topicToTaskIds.keySet().toList()`. This will not swamp multiple warning log entries.
Instead of moving this check internally to the loop, can we add an `else` call after the original if condition that, if `topicToTaskIds` is not empty, log a single warning entry that `Topics {} do not exist but ...` with `topicToTaskIds.keySet().toList()`. This will not swamp multiple warning log entries.
Nit: space before `:`.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
No worries. I was only recommending to change the name if you stopped using it to gate the processing and just relied on producing messages to control when they could be processed, if you did want to do that. Either way is fine with me so you can just leave it as is
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
I think we should call `deserializer.close()` here
Do we need this? Can't we just use the Time we pass into the constructor in tests? Not a big deal really, just wondering
Ditto on removing before/after
Ditto on removing before/after
need a newline after the group before the underline, and a double newline after the underline
same here as what i said below. You can use a `assertThat`
Ouch! Sorry about that!
This is not correct, it should be `buffer.remaining`. It seems simpler to just do `while (buffer.remaining())` with an early exit in the case read returns `-1`.
nit: What about extracting the construction in a small helper method `prepareDescribeLogDirsResponse` that create a response for one LogDir and TopicPartition? It seems that the same block of code is used in many tests.
I know we need both `File` and `Path` instance to complete the permission setting. What I meant is that: 1. We already had the `File` instances, i.e. baseDir, stateDir 2. `Paths.get(stateDir.getPath())` --> what happened behind the scene, is we created a Path instance from the path string in the file instance (i.e.`stateDir.getPath()`) ```java public final Path getPath(String var1, String... var2) { ... return new UnixPath(this, var3); } ``` 3. `path.toFile()` --> what happened behind the scene, is we created a File instance from the path string ```java public final File toFile() { return new File(this.toString()); } ``` So, currently, we will created an additional File instance via `path.toFile()`. If we pass the File instance into `configurePermissions()` directly, it'll only created a `Path` instance. ex: ```java configurePermissions(stateDir); // pass the file instance directly ``` ```java private void configurePermissions(final File file) { final Path path = Paths.get(file.getPath()); // created path instance if (path.getFileSystem().supportedFileAttributeViews().contains("posix")) { .... } else { boolean set = file.setReadable(true, true); // won't create additional File instance here .... } } ```
I know we need both `File` and `Path` instance to complete the permission setting. What I meant is that: 1. We already had the `File` instances, i.e. baseDir, stateDir 2. `Paths.get(stateDir.getPath())` --> what happened behind the scene, is we created a Path instance from the path string in the file instance (i.e.`stateDir.getPath()`) ```java public final Path getPath(String var1, String... var2) { ... return new UnixPath(this, var3); } ``` 3. `path.toFile()` --> what happened behind the scene, is we created a File instance from the path string ```java public final File toFile() { return new File(this.toString()); } ``` So, currently, we will created an additional File instance via `path.toFile()`. If we pass the File instance into `configurePermissions()` directly, it'll only created a `Path` instance. ex: ```java configurePermissions(stateDir); // pass the file instance directly ``` ```java private void configurePermissions(final File file) { final Path path = Paths.get(file.getPath()); // created path instance if (path.getFileSystem().supportedFileAttributeViews().contains("posix")) { .... } else { boolean set = file.setReadable(true, true); // won't create additional File instance here .... } } ```
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
I think it would be cleaner to pass `cacheSizePerThread` to `resizeThreadCache()` instead of the number of stream threads. We would then just call `getCacheSizePerThread()` once instead of once in `addStreamThread()` and once in `resizeThreadCache()`. We would also just need to compute `threads.size() + 1` once.
Since it looks like we expect numRecords to always be set, should we error out here if record is null? That would seem to indicate that our source topic was under-sized or some other issue (GC pause?) caused poll to timeout.
Ouch! Sorry about that!
I think it would be cleaner to pass `cacheSizePerThread` to `resizeThreadCache()` instead of the number of stream threads. We would then just call `getCacheSizePerThread()` once instead of once in `addStreamThread()` and once in `resizeThreadCache()`. We would also just need to compute `threads.size() + 1` once.
Probably not worth it. The tricky thing is that we have to factor the remaining bytes in fileChannelBuffer into TransportLayers.hasPendingWrites(), which requires more work.
Good point, I think we should add `this.nano += TimeUnit.NANOSECONDS.convert(autoTickMs, TimeUnit.MILLISECONDS)` in `nanoseconds()` as well.
I think it would be cleaner to pass `cacheSizePerThread` to `resizeThreadCache()` instead of the number of stream threads. We would then just call `getCacheSizePerThread()` once instead of once in `addStreamThread()` and once in `resizeThreadCache()`. We would also just need to compute `threads.size() + 1` once.
Hmm. I feel the `final` would be worth capitalizing the var name.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Hmm. I feel the `final` would be worth capitalizing the var name.
We should read the metadata inside the while loop since it could change.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
I think maybe ```py dummy = object() def get(self, key, default=None, version=None, acquire_lock=dummy): if acquire_lock is not dummy: warnings.warn( ``` I still think this arg fits in the grey area for deprecation timeline, would like someone to weigh in e.g. @jarshwah
Do you mean it should NOT be included...
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
@rajinisivaram Just for curiosity I tried the IBM MacOS SDK. It has both classes. And neither work ð with our test harness! Anyway that JDK is not our priority
the `try{...} finally` has been removed
`WindowStore` is public API -- we need a KIP if we want to deprecate something. Thus, this is not a `MINOR` PR.
I am not entirely sure about this. I think that `SASL_JAAS_CONFIG` should be prefixed with the SASL mechanism otherwise we ignore it. In this case, we log a warning in `loadServerContext`. I suppose this is the reason why we don't use a generic message for both cases here. It does not make sense to say that `SASL_JAAS_CONFIG` is not set if we don't use it without the prefix.
Nit: ```suggestion public void testValidCustomizedHttpResponseHeaders() throws IOException { ```
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
Nit: might be a bit clearer to add "WithoutSchema": ```suggestion public void insertConfiguredFieldsIntoTombstoneEventWithoutSchema() { ```
No batch should have been drained.
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
No batch should have been drained.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
This is also an existing issue. We set the ISR here, but it can be overridden to targetIsr in tobuild() later.
This is because we are inheriting a Scala class, and moving forward we should remove this with the Java version `org.apache.kafka.copycat.util.ShutdownableThread` that can be moved into `o.a.k.common.utils`. We can leave it as is for now.
This is also an existing issue. We set the ISR here, but it can be overridden to targetIsr in tobuild() later.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
This is neat, but we shouldn't use it. There's an IntegrationTestUtil for getting a temporary folder, which is hooked in to support for different testing environments to set their desired temporary file location.
This is neat, but we shouldn't use it. There's an IntegrationTestUtil for getting a temporary folder, which is hooked in to support for different testing environments to set their desired temporary file location.
Seems to be covered by `shouldAssignMultipleReplicasOfStandbyTask()` already
should we wrap the processing etc in `try{..}finally{..}` so we ensure that we do `streams.close()`? Also maybe close with a timeout? Same elsewhere
should we wrap the processing etc in `try{..}finally{..}` so we ensure that we do `streams.close()`? Also maybe close with a timeout? Same elsewhere
We should log an error that prints out what the two configs actually are
nit (sorry): seems ungrammatical when the error message is appended. How about this? ``` "Expiring " + recordCount + " record(s) for " + topicPartition + ": " + expiryErrorMessage) ```
@dajac just to clarify, are you concerning that the `generation()` may change between the check and the error-log? If yes maybe we do not need to synchronize the whole function, instead we just get a reference of the returned `generation()` call and use that in the error-log, since the generation object is immutable.
nit: insert space `String... expected`
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
This name seems backwards.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
This should go away. `@ConditionalOnClass` already does that.
OK, let's keep the change to that one field for now.
Update return type to `L` (if we introduce `L`)
Nit: use `java.nio.charset.StandardCharsets.UTF_8` here rather than `Charset.forName(...)`. The latter has to do a lookup every time.
I think we should provide some context on the exception here.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
I think we should provide some context on the exception here.
But `ProcessorStateManager` doesn't handle global tasks
I guess this method no longer throws at all? (also applies to close)
This only needs to be set when we first create the `OffsetCommitRequestTopic`, right? So it can be set inside the `getOrDefault` block.
style nit: normally we'd use braces around blocks unless they're a single line
Please use hanging indent: ``` self.assertEqual( set(request.META.keys()), {'PATH_INFO', 'REQUEST_METHOD', 'SCRIPT_NAME', 'CONTENT_TYPE', 'wsgi.input'} ) ```
`asList` -> `Collections.singletonList`
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
nit: simpler or not? ```java Map<String, Uuid> newTopicIds = topicIds.entrySet().stream() .filter(entry -> shouldRetainTopic.test(entry.getKey())) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue)); ```
nit: simpler or not? ```java Map<String, Uuid> newTopicIds = topicIds.entrySet().stream() .filter(entry -> shouldRetainTopic.test(entry.getKey())) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue)); ```
nit: simpler or not? ```java Map<String, Uuid> newTopicIds = topicIds.entrySet().stream() .filter(entry -> shouldRetainTopic.test(entry.getKey())) .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue)); ```
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
At a high level, our store ecosystem looks like an onion. On the outside, we have a <K,V> store, and on the inside, we have a <bytes,bytes> store. All the layers in between have different responsibilities, like changelogging, caching, add metrics, etc. The nice thing about this PR is that it gives us one clean layer that's responsible for the transition `<K,V> <=> <bytes, bytes>`. When we need to look at the de/serialization into/out-of the stores, we have exactly one place to look. The prior code did mostly this, but to accommodate cache flushing in conjunction with the fact that the cache layer is below the transition from objects to bytes, we had to poke a hole in the onion and tell the caching layer (a bytes layer) how to deserialize. So, then there were two layers that independently know how to de/serialize, and the onion had a hole in it. This idea to move the serialization out to the TupleForwarder is basically the same, but in the opposite direction. Again, there are two components that need to perform serialization (the serialization layer and the tuple forwarder), and again, we need to poke a hole in the onion so that the tuple forwarder can communicate directly with an inner layer. It's not always practical to go for a "pure" design, but if readability is the goal, then it seems like we should try to avoid mixing layers, unwrapping layers, etc. as much as possible. To be fair, this is just my take on the situation.
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
Nit: the method is `Producer.close()`, not "stop". The log message should probably reflect that.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
nit: some extra newlines here.
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
We should test that delete twice in a row fails with `IllegalStateException`
Even though I think this is a bit off, I'm going to go ahead and merge it, so we can fix forward. The overall feature isn't fully implemented yet anyway, so this will have no negative effects if we release the branch right now.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Instead of `new MetricName("batch-size-avg", "producer-metrics", "", tags)`, I think we should use `metrics.metricName("batch-size-avg", "producer-metrics")`, right? The doc says `Please create MetricName by method {@link org.apache.kafka.common.metrics.Metrics#metricName(String, String, String, Map)}`. Same for other MetricName instantiation.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
req: rename `clientHostingTask` -> `previousHostingClient` (or similar)
Minor: it seems like this test would be a little simpler if you start subscribed to topic1 and then switch to topic2.
In the meantime I've seen we're doing that with `RestTemplateBuilder` and I see you're using a separate collection. Retrospectively, it's not that bad at all.
nit: add a size? There are a few cases in here where we could do this.
We should have a constant rather than using '262' directly
req: rename `clientHostingTask` -> `previousHostingClient` (or similar)
no need to use `this.` outside the constructor. Here and below
In the meantime I've seen we're doing that with `RestTemplateBuilder` and I see you're using a separate collection. Retrospectively, it's not that bad at all.
no need to use `this.` outside the constructor. Here and below
I think we should not say that the commit can be retried. I would just say that the rebalance needs to be completed by calling `poll()` and that offsets to commit can be reconsidered after the group is rejoined.
no need to use `this.` outside the constructor. Here and below
nit: We could use `singletonMap` here.
nit: We could use `singletonMap` here.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
req: rename `clientHostingTask` -> `previousHostingClient` (or similar)
req: rename `clientHostingTask` -> `previousHostingClient` (or similar)
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Wouldn't "application.port" be a better default? There's already "application.pid", "application.properties", "application.yml" etc.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
Would it be possible to extract test code in this class and `RocksDBRangeIteratorTest` that actually tests code in class `RocksDbIterator` to a test class `RocksDbIteratorTest`. I think that would make the code more maintainable.
Would it be possible to extract test code in this class and `RocksDBRangeIteratorTest` that actually tests code in class `RocksDbIterator` to a test class `RocksDbIteratorTest`. I think that would make the code more maintainable.
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
Search should use the default settings: most popular sort, no duration preference, no upload date preference.
volatile is not needed here, since this is only accessed under the lock.
Nit: why not use `boolean`
Nit: why not use `boolean`
Search should use the default settings: most popular sort, no duration preference, no upload date preference.
request1 and request 2 are not used.
I never knew about that double underscore trick. Thanks!
Yeah, I have a slight preference to just lock `SubscriptionState` every time since it is the simplest option. I don't think contention is a major problem since there's only the heartbeat thread which is sleeping most of the time. Unless there's some reason to think the cost of lock acquisition itself is a concern.
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
Since we can handle the case in the restoration phase above, I think we do not need to use a separate globalNonPersistentStoresTopics here anymore. Instead, we can do the following inside this function: 1. Filter the entry of the pass-in `offsets` map if `!store.persistent() || storeToChangelogTopic.containsKey(store.name())`. 2. checkpointableOffsets.putAll(filteredOffsets); 2.a. In line 245 above, we can still only heck if `checkpoint != null`. 3. if (!filteredOffsets.isEmpty()) filteredOffsets Note that after the restoration is done, we will fill in the restored offset in line 287: ``` checkpointableOffsets.put(topicPartition, offset); ``` So after the restoration phase we should have the checkpointableOffsets map populated already.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
The serialization package is open to everyone (it's public API and at the lowest layer). So I don't think we should worry about that. It's not like we're avoiding a dependency here, we are just hiding it via a string based config (that still requires the default constructor to be present).
Map.Entry<String, String> to avoid the check below
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
This should be `@NonNull`.
I think key-pairs of strings as list is brittle. But we inherited that.
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: o2[%s] was **equal** to o1[%s]
IMO, this string should give details when the condition is not met, like `stream thread has not been added`. Same applies to the other wait conditions.
IMO, this string should give details when the condition is not met, like `stream thread has not been added`. Same applies to the other wait conditions.
nit: move parameter to it's own line (same below)
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
We tend to use different `node` value when multiple connections are created by a test. You could just replace `node` here with "1" and a couple of lines below with "2".
Yes, it seems that -1 means that we are trying to read beyond the end of the channel, which probably should be treated as abnormal.
Should we include the config source instead for compatibility? Also, just double-checking that it is intentional to leave the synonyms out of `equals`.
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
Is this right? I thought it should be `position += limit`.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
nit: Indicate that this needs deep iterations on the entries.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
I think this would never happen now since the passed in `recordPerTopicPerPartition` is always initialized.
Since these string literals are now relevant elsewhere, we should make them reusable constants. Perhaps they should be enums? I realize now that perhaps the class names should have also been enums but ð¤·.
@cmccabe to clarify my point: if you have 3 futures and you want to use all of them, you need to a way to combine the 3 futures into 1 and handle the fact that each may fail separately. So, imagine that someone wants to use these 3 fields somewhere in their code after handling errors. I'll use Scala Future terminology next. The typical way to do these things in a non-blocking API is to map/flatMap over the future and pass the unwrapped value to other code. The code, in turn, may return a `Future` if it needs to perform some computation that is expensive, involves IO, etc or simply return a normal value. In the former case, `flatMap` is needed why in the latter `map` will do. If you have 3 `Future`s instead of `1`, you need to do 3 nested `flatMap`/`map` calls and pass the individual values to a method or create a class containing these values before passing them around. So, in general, it's easier if this is done for you. We can always introduce separate futures in the future if there's a case for handling errors separately. I can't think of a good reason to do that here though.
I see, the assumption is that existing implementations will have overriden it.
Do we _know_ that it will resolve the problem? Maybe better: ``` Changing the location of state.dir may resolve the problem ```
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
OK, will remove before merging.
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
could be named as `processingMode`
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
```suggestion module.deprecate("Alias \'{aliase}\' is deprecated".format(aliase=aliase), "2.10") ```
Input parameter `partitionTimes` should always contain the correct partition time, hence, we can just get it: ``` final long partitionTime = partitionTimes.get(partition); ```
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Can we actually just get rid of "test only" constructors? It couldn't be used by _that_ many different tests...
We should update the Scala `TestUtils` to call this method.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: some extra newlines here.
Maybe we can just a better name for `path` since it makes this code look suspicious.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Maybe we can just a better name for `path` since it makes this code look suspicious.
nit: some extra newlines here.
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
same here as what i said below. You can use a `assertThat`
Cleaner to just check if `tasks.isEmpty` after the loop is over.
It doesn't trigger an extra migration in my testing.
It doesn't trigger an extra migration in my testing.
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
Should we finer-handling different error cases here? ``` /** * Possible error codes: * * REQUEST_TIMED_OUT(7) * INVALID_TOPIC_EXCEPTION(17) * CLUSTER_AUTHORIZATION_FAILED(31) * TOPIC_ALREADY_EXISTS(36) * INVALID_PARTITIONS(37) * INVALID_REPLICATION_FACTOR(38) * INVALID_REPLICA_ASSIGNMENT(39) * INVALID_CONFIG(40) * NOT_CONTROLLER(41) * INVALID_REQUEST(42) */ ```
same here as what i said below. You can use a `assertThat`
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
same here as what i said below. You can use a `assertThat`
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
same here as what i said below. You can use a `assertThat`
nit: I think we could use a more convenient type, such as `Map<Integer, InetAddressSpec>`. Ultimately this just needs to make it down to `KafkaNetworkChannel.updateEndpoint` so the conversion to the config value is unnecessary.
How about "runs an external command for the worker."
Well, my point is, that the check can be simplified. I don't think that `record.headers() == null` can be true; it's guaranteed that there is a headers object. Not sure if we can simplify the second check. It iterators over the headers map and does String comparison to find a header with key `v` -- seems to be rather heavy.
When you make `initializeSnapshotWithHeader` private, you may need to slightly change this implementation. E.g.: ```java return supplier.get().map(snapshot -> { RecordsSnapshotWriter<T> writer = new RecordsSnapshotWriter<>( snapshot, maxBatchSize, memoryPool, snapshotTime, lastContainedLogTimestamp, CompressionType.NONE, serde); writer.initializeSnapshotWithHeader(); return writer; }); ```
nit: move below the shortcut return below.
We need to keep the old method as before and deprecate.
Probably a good idea to check if SASL_SSL for the second case and throw an exception otherwise (in case we ever add another SASL_\* protocol).
`replicaing` -> `replicating`
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
nit: We should use `groupId.idValue` here and in the others.
If not, we should move the exception capturing logic inside the dbAccessor as well.
This can be initialized here and be `final`
The one we are keen on is PLAIN. We will be using SASL with SSL, so PLAIN gives us the simplest secure authentication without having to distribute certificates for mutual client auth. Yes, a separate PR makes sense so that this one can be committed soon. I will raise another JIRA.
@pierremahot we'll need a test for this
This lock is unnecessary since the onNext call is not supposed to be invoked concurrently.
Why do you remove this check? A `TimeWindow` should not allow this case.
Nit: we don't normally use exclamation marks in Kafka log messages.
Nit: we don't normally use exclamation marks in Kafka log messages.
Nit: we don't normally use exclamation marks in Kafka log messages.
As now we only perform `commitSync` during closing, we do not need to update the `lastCommittedOffsets` here.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Actually, it's not just older requests, the default was always `""` whereas I am seeing `null` after this PR. It looks like there are two issues: 1. We didn't set a default of `""` for clientId in the json schema. 2. The generated protocol code behaves differently with regards to default values. It only uses the default if the field is not present. The `Struct` code uses it if `value == null`. ```java Object value = this.values[field.index]; if (value != null) return value; else if (field.def.hasDefaultValue) return field.def.defaultValue; else if (field.def.type.isNullable()) return null; else throw new SchemaException("Missing value for field '" + field.def.name + "' which has no default value."); ``` This is the generated code _after_ I add the `""` default for `clientId`. ```java public void read(Readable readable, short version) { this.requestApiKey = readable.readShort(); this.requestApiVersion = readable.readShort(); this.correlationId = readable.readInt(); if (version >= 1) { this.clientId = readable.readNullableString(); } else { this.clientId = ""; } } ```
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
Is this a valid restriction for the broker? Would there be cases where multiple mechanisms may be required? In the original Kafka Security proposal, there was mention of one port supporting multiple SASL mechanisms. I don't know how common that is though. Probably not for this release, but it may be worth thinking about how we would do that in a compatible manner if we decide to do it.
Actually, it's not just older requests, the default was always `""` whereas I am seeing `null` after this PR. It looks like there are two issues: 1. We didn't set a default of `""` for clientId in the json schema. 2. The generated protocol code behaves differently with regards to default values. It only uses the default if the field is not present. The `Struct` code uses it if `value == null`. ```java Object value = this.values[field.index]; if (value != null) return value; else if (field.def.hasDefaultValue) return field.def.defaultValue; else if (field.def.type.isNullable()) return null; else throw new SchemaException("Missing value for field '" + field.def.name + "' which has no default value."); ``` This is the generated code _after_ I add the `""` default for `clientId`. ```java public void read(Readable readable, short version) { this.requestApiKey = readable.readShort(); this.requestApiVersion = readable.readShort(); this.correlationId = readable.readInt(); if (version >= 1) { this.clientId = readable.readNullableString(); } else { this.clientId = ""; } } ```
Is this just to prevent it from processing anything until you're ready to proceed? It seems like you can/are doing that just by controlling when to produce input messages and doing so one at a time (if that's accurate, then WDYT about renaming `process` to `processed` and flipping the boolean so it more clearly serves the purpose of indicating whether a record has yet been processed)
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
SGTM. If we find it flooding the logs and not helpful we can reconsider
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
This is more than just a URI, it can be a local path (and potentially other types I'm not aware of)
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
another ideaa: add an assertion here? so that we are guaranteed that this method is called.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
add `final` twice
i think it would be better to add support for this embed urls and return a url result instead of inline handling of the embed url.
i think it would be better to add support for this embed urls and return a url result instead of inline handling of the embed url.
i think it would be better to add support for this embed urls and return a url result instead of inline handling of the embed url.
This is good, but it may be more consistent to move the remaining lines in this method to another static method. That would make this `masked(Object)` method a bit easier to understand, too. If you add a new static method right after this method and use `value` for the parameter, the next few lines will remain unchanged (other than moving into a new static method).
This is good, but it may be more consistent to move the remaining lines in this method to another static method. That would make this `masked(Object)` method a bit easier to understand, too. If you add a new static method right after this method and use `value` for the parameter, the next few lines will remain unchanged (other than moving into a new static method).
This is good, but it may be more consistent to move the remaining lines in this method to another static method. That would make this `masked(Object)` method a bit easier to understand, too. If you add a new static method right after this method and use `value` for the parameter, the next few lines will remain unchanged (other than moving into a new static method).
How about "runs an external command for the worker."
formatting: no need to curly braces
This isn't a REST extension necessarily, right? It's also used by Kafka via JMX. I think mentioning `worker restarts` and `rest extension` might be confusing
You can drop `final` from here, we generally don't use it for local variables.
formatting: no need to curly braces
Since we have several things that all need to be closed, perhaps we could use `ClientUtils.closeQuietly`? Maybe something like this ```java try { for (String id : connections) close(id); } finally { AtomicReference<Throwable> firstException = new AtomicReference<>(); closeQuietly(nioSelector, firstException); closeQuietly(sensors, firstException); closeQuietly(channelBuilder, firstException) if (firstException.get() != null) throw firstException.get() } ```
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
with in => within
again, naming of the test
Nit: line too long
prop: `suspend` and `closeSuspended` could cause confusions as the meaning was very close. Maybe name `closeSuspended` to `closeSuspendedIntervalState`
SGTM. If we find it flooding the logs and not helpful we can reconsider
After thinking about this more, it's probably more reliable and easier to maintain if we just default to always using our version of `ismount()` rather that trying to evaluate the Python version. Ideally we could probe somehow and fallback to this version rather than doing a version comparison, but it's really hard to probe for a bugfix. ```suggestion ```
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
So we basically do 10 re-tries? Is this intended? Or should be just sleep for a hard-coded "backup time"
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
Probably not the best choice of error type, `InternalError` indicates JVM error, combined with "Null check on a primitive" message might mislead the developer into thinking that something is wrong with bytecode/VM hehe
nit: We should use `groupId.idValue` here and in the others.
nit: We should use `groupId.idValue` here and in the others.
nit: We should use `groupId.idValue` here and in the others.
Similar here, maybe we could leverage `transitionTo` to help throw the exception.
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
nit: extra blank line ```suggestion ```
I think this way of triggering the exception is not only complicated but it even might be a source of flakiness. Could we have some more straightforward? I think the original solution (overriding getResponse) was better than this.
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Sounds interesting, cc @kkonstantine
```suggestion // Value `null` is valid for an optional field, even though the field has a default value. ```
We can pass the serializers in the constructor and it's a bit more concise.
We can pass the serializers in the constructor and it's a bit more concise.
We can pass the serializers in the constructor and it's a bit more concise.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
All these tests could also be parameterized - would be a lot less code, but would likely need reflection to look up the constructor.
So we basically do 10 re-tries? Is this intended? Or should be just sleep for a hard-coded "backup time"
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
This could become a `Map<String, String>` and remain as `SHUTDOWN_MESSAGE`
This could become a `Map<String, String>` and remain as `SHUTDOWN_MESSAGE`
remove try-catch and replace with: ``` final StreamsException s = assertThrows(StreamsException.class, () -> testDriver.pipeInput(consumerRecord)); ``` assert afterwards and don't re-throw.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
I still miss the overload `observeOn(Scheduler, boolean delayError, int bufferSize)`
No worries, let's keep the scope small for now. Just wanted to raise the question
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Looks good. I like the additional checking that you're doing here.
`scheduler` has no effect here...
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
This should go away. `@ConditionalOnClass` already does that.
This should go away. `@ConditionalOnClass` already does that.
nit: 'else' can be dropped
nit: 'else' can be dropped
nit: could be useful to log the type of exception in the assertion message.
nit: use `"table-source"` ? It's naming a source node, not a processor node.
Okay. We do similar synchronization for `append`. The `LeaderState` has an `epoch` and it is final. The part that may be tricky to implement is the `epoch < currentEpoch` case.
Ditto on removing these before/after methods.
ditto on removing before/after.
nit: 'else' can be dropped
request "got" re-sent to the control
I think the name of the function is better defined as `interleaveTasksByConsumers`
Nit: var should be named `deserializeValue`
I think we should call `deserializer.close()` here
There are some request header tests in `RequestResponseTest`, we should move them here so that we can find them all in one place.
There are some request header tests in `RequestResponseTest`, we should move them here so that we can find them all in one place.
Nit: var should be named `deserializeValue`
Nit: var should be named `deserializeValue`
nit: add `final`
Could we collapse the code path for having a queryable store name or not into the same function? For example: ``` filter(.. /*nothing*/) calls filter(.. (String) null); filter(.. "storeName") calls filter(.. storeSupplier); // if storeName is not null, otherwise pass null as well filter(.. supplier) do the actual impl, which checks if supplier is null or not ```
Thanks for the background @rajinisivaram. By the way, I noticed one of the checks is defined inconsistently: https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/network/SslTransportLayer.java#L344.
Minor: if the test fails, the value of `basic.has_journal` won't be restored. This probably doesn't matter.
So in my updated PR I change this line to line up with CompletableFuture.
`instantiateConfigProviders` since this is potentially creating multiple providers
There's really no reason to remove that.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
Should we produce the input before we start the KS instances? If there is no input, it's clear that Standbys won't restore as there is not data for restoring.
"*" is considered "LITERAL" for compatibility reasons
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
"*" is considered "LITERAL" for compatibility reasons
"*" is considered "LITERAL" for compatibility reasons
"*" is considered "LITERAL" for compatibility reasons
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
nit: line too long
Can remove if initialize above
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
I didn't think of that before, but now that you mention it, the change makes sense to me.
Use markdown format for links
One extra line.
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
Nit: we don't normally use exclamation marks in Kafka log messages.
The issue mentioned `Single` as return type.
this won't work with ipv6 addresses, I think there are some helper methods for this is org.apache.kafka.common.utils.Utils
nit: use `"table-source"` ? It's naming a source node, not a processor node.
We may be able to save all this hassle by defining alias group as a map of `target` to a list of `deprecated` configs? We defined this as a 2-dim array but we always convert it to lists...
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
I don't think this logic is quite right...when we call maybeRevokePartitions we calculate revokedPartitions = assignedPartitions.filter(tp -> !assignedPartitions.contains(tp)) which is an empty list.
I don't think this logic is quite right...when we call maybeRevokePartitions we calculate revokedPartitions = assignedPartitions.filter(tp -> !assignedPartitions.contains(tp)) which is an empty list.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Don't bother, that was FYI. We can do that with the merge commit ;)
a list of dictionaries
Update return type to `L` (if we introduce `L`)
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
Update return type to `L` (if we introduce `L`)
Update return type to `L` (if we introduce `L`)
Update return type to `L` (if we introduce `L`)
Update return type to `L` (if we introduce `L`)
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
This method had me worried at first because it doesn't seem to do anything to guarantee there's only one connector's tasks in the map. We might be able to switch the internal representation here to also be a list, although the way we collect them makes it natural to maintain as a map and then convert to the list (especially given a compacted topic). Maybe a good solution is an assertion here that the connector name matches as expected? I think we're sort of covered by the unit tests that test that compacted topics work even if random sets of task configs get cleaned up, but right now I'm not certain we test the possibility that we have two connectors with tasks that have been compacted and are in an inconsistent state.
`InternalProcessorContext` is already public interface but it's in `internals` package, so I figured it is okay? Anyways, this is not much blocking this PR, so feel free to merge it anyways and we can keep discussing here while you merge.
This doesn't seem to be used.
typo: byteArrray -> byteArray
I am must wondering, if this should go into it's own test class `KStreamGlobalKTableJoinTest.java` ? Similar below.
Because `Named#name` is not `final`, it is not guaranteed that `EMPTY` will have an `null` name (one might call `#empty()` and modify it) -- seems to be a potential source of bugs. Can we instead remove `EMPTY` and return `new NamedInternal()` in `empty()` each time? It's not on the critical code path, so should be fine.
fair enough - we still don't need the assertion though as it is already true as of line 69
No need to compile explicitly, `re` will hold compiled cache internally anyway.
Ditto on removing before/after
super nit: taskCreationLock --> taskDirCreationLock
nit: ```suggestion throw new ConfigException(DLQ_TOPIC_NAME_CONFIG + " has a topic name which matches the regex in " + SinkTask.TOPICS_REGEX_CONFIG); ```
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
There's really no reason to remove that.
There's really no reason to remove that.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Could we collapse the code path for having a queryable store name or not into the same function? For example: ``` filter(.. /*nothing*/) calls filter(.. (String) null); filter(.. "storeName") calls filter(.. storeSupplier); // if storeName is not null, otherwise pass null as well filter(.. supplier) do the actual impl, which checks if supplier is null or not ```
If we change the `localEntityIdTemplate` property to have a default value of `{baseUrl}/saml2/service-provider-metadata/{registrationId}` this assertion will have to change to match. I would also be good to test that the default in the properties matches the default in the builder. That could be done with something like this: ``` assertThat(RelyingPartyRegistration.withRegistrationId("id")).extracting("localEntityIdTemplate") .isEqualTo(new Saml2RelyingPartyProperties.Registration().getLocalEntityIdTemplate()); ```
Nit: ```suggestion * executed exactly once. If {@code maxRetries} is set to {@code n}, the callable will be executed at ```
Can remove if initialize above
Nit: we don't normally use exclamation marks in Kafka log messages.
Nit: we don't normally use exclamation marks in Kafka log messages.
Nit: we don't normally use exclamation marks in Kafka log messages.
Nit: we don't normally use exclamation marks in Kafka log messages.
Nit: we don't normally use exclamation marks in Kafka log messages.
Nit: we don't normally use exclamation marks in Kafka log messages.
Can you enclose the body of if block with curly braces ? Same with else block. It is easier to read.
Could you please add some line breaks? This and some of the other verifications are too long.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
none from what I can see, but I'm not sure it's worth holding up the PR for it.
nit: we can throw AssertionError here to indicate this should not happen.
Second argument should be `video_id`.
Please use hanging indent: ``` self.assertEqual( set(request.META.keys()), {'PATH_INFO', 'REQUEST_METHOD', 'SCRIPT_NAME', 'CONTENT_TYPE', 'wsgi.input'} ) ```
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
We should log an error that prints out what the two configs actually are
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
We'll need to think carefully about this. The proposed change could break some tests that had multiple DataSources. Previously, if there was no primary DataSource, no DataSources would be replaced and if there was a primary DataSource, only that DataSource would be replaced. This change will result in all DataSources being replaced which may not be what someone wants. Perhaps we need another mode for `replace`, I'm not sure yet.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
add `final` twice
nit: npe is possible here, though state overall won't be ok, but npe is still seems possibe
The other benefit is the way we are loading converters it could technically be loaded in a different plugin loader that what are keyed in the map since we're loading the ConnectConfig after swapping the class loader in `startTask`. If we prefer to keep it the way it is here, we need to revert that change.
In this case `quality` is determined from other attributes, like the bitrate or the resolution. There's no need to specify `quality` values explicitly.
In this case `quality` is determined from other attributes, like the bitrate or the resolution. There's no need to specify `quality` values explicitly.
The other benefit is the way we are loading converters it could technically be loaded in a different plugin loader that what are keyed in the map since we're loading the ConnectConfig after swapping the class loader in `startTask`. If we prefer to keep it the way it is here, we need to revert that change.
While we're at it, we may as well use another `{}` substitution for the parameter and remove the unneeded `toString()`.
can we change the test, to include a "pass" over the next schedule? atm, "stream-time == next-punctuation-time" but we should cover "stream-time > next-punctuation-time" (with jumping over a whole schedule)
can we change the test, to include a "pass" over the next schedule? atm, "stream-time == next-punctuation-time" but we should cover "stream-time > next-punctuation-time" (with jumping over a whole schedule)
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
@akarnokd I wonder if this loop affects benchmark in positive or negative way, it consumes single core to max Should `cdl.await()` be used instead? it parks the thread I see this pattern in few other benchmarks but idk if it's intentional
`instantiateConfigProviders` since this is potentially creating multiple providers
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
super nit: extra blank line
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
Would it be possible to extract test code in this class and `RocksDBRangeIteratorTest` that actually tests code in class `RocksDbIterator` to a test class `RocksDbIteratorTest`. I think that would make the code more maintainable.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
Nit: var should be named `deserializeValue`
Nit: please add `final` to all local vars and method parameters
Nit: var should be named `deserializeValue`
Please remove empty lines here and in the other test methods.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
`Failed to flush accumulated records` -> `Failed to flush all accumulated records...` Also, it would be much more useful if we could say `%d of %d` batches although I see we would have to expose a `size()` method in `IncompleteBatches`
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
That was my other thought. We might wrap one DataException into another but that's not a big deal. In this code `Decimal.toLogical` is now used, and if you follow the refs, there's a `new BigInteger(value)` in there that might throw `NumberFormatException`. Improbable, but thought we could be on the safe side with the more general catch block.
Tiny nitpick: you can declare error in this line too as it's not used outside the loop anymore
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
`Failed to flush accumulated records` -> `Failed to flush all accumulated records...` Also, it would be much more useful if we could say `%d of %d` batches although I see we would have to expose a `size()` method in `IncompleteBatches`
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
ok - same thing three times. Maybe extract it to a method `verifyTransactionInflight`
@akarnokd I wonder if this loop affects benchmark in positive or negative way, it consumes single core to max Should `cdl.await()` be used instead? it parks the thread I see this pattern in few other benchmarks but idk if it's intentional
as above. Name of the test can be more descriptive. `shouldRequireBrokerVersion0101OrHigherWhenEosDisabled`
Do we really want anything related to internal topics to be client side? This could change in brokers from version to version and the clients should still work. I understand that for now we have no way to get that information, but we will soon (KAFKA-3306). I imagine removing the client side list would be part of the cleanup once thats available. So whatever exists in the mean time should be private so we don't need a deprecation cycle.
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
I like the extra-detailed error messages, thank you.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Nit: might be worth adding a simple assertion on the result just to make sure.
spelling -> recrord -> record
"*" is considered "LITERAL" for compatibility reasons
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
nit: add `final`
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
It seems that both loginContext and mode can just be a local variable.
Seems like this is the same in `testReadFullyOrFailWithMultiReads`. Maybe we can extract it to a helper method.
Seems like this is the same in `testReadFullyOrFailWithMultiReads`. Maybe we can extract it to a helper method.
This variable needs to be `final` says checkstyle.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Setter methods again.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Setter methods again.
should we wrap the processing etc in `try{..}finally{..}` so we ensure that we do `streams.close()`? Also maybe close with a timeout? Same elsewhere
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
We can use `Collections.singletonMap()`
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Setter methods again.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Setter methods again.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Setter methods again.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
Setter methods again.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Setter methods again.
Setter methods again.
Setter methods again.
Setter methods again.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Allow me to begin by saying that I admit and like the simplicity of this pattern. Still, if this method is frequently used, and if the `gets` >> `creates` (are expected to be way more), then an alternative would be: ```java private final ConcurrentMap<String, MetricGroup> groupsByName = new ConcurrentHashMap<>(); ... public MetricGroup group(String groupName, boolean includeWorkerId, String... tagKeyValues) { MetricGroup group = groupsByName.get(groupName); if (group == null) { Map<String, String> tags = tags(includeWorkerId ? workerId : null, tagKeyValues); group = new MetricGroup(groupName, tags); groupsByName.putIfAbsent(groupName, group); } return group; } ``` which is almost identical in terms of code. This pattern might waste a few objects on initialization, but otherwise it relieves the map from global synchronization on `gets`. If both `gets` and `creates` are expected to be just a few it doesn't worth it probably. Can't say because the use of `group` in this PR is not demonstrated.
Only do the regular expression check if `schemes == '__all__'`.
Only do the regular expression check if `schemes == '__all__'`.
I don't feel strongly about it. If we enforce the "no null keys" invariant, then they are equivalent. It seems mildly confusing that we essentially have two different methods of determining when the iterator has run out of data. I leave it up to you.
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
Nit: the method is `Producer.close()`, not "stop". The log message should probably reflect that.
Nit: the method is `Producer.close()`, not "stop". The log message should probably reflect that.
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Nit: the method is `Producer.close()`, not "stop". The log message should probably reflect that.
I'm not convinced we gain anything by adding another level of inheritance here. It removes one method that doesn't do much anyway. My preference would be to leave it as it was. If we are going to use inheritance then i think we should keep the hierarchy as shallow as possible.
Nit: the method is `Producer.close()`, not "stop". The log message should probably reflect that.
Nit: every conditional needs to have braces (per the code style) not nit: I find this logic a little difficult to follow. Contrary to what @mjsax suggested, wouldn't it be pretty straightforward to map the old semantics on to the new ones like this: * negative numbers => 0 * 0 => Long.MAX_VALUE * all other arguments stay the same ? Then, the old close method could just transform its arguments and call the new method, with no need to have this "new semantics" flag and an early return in the middle of the loop.
Nit: every conditional needs to have braces (per the code style) not nit: I find this logic a little difficult to follow. Contrary to what @mjsax suggested, wouldn't it be pretty straightforward to map the old semantics on to the new ones like this: * negative numbers => 0 * 0 => Long.MAX_VALUE * all other arguments stay the same ? Then, the old close method could just transform its arguments and call the new method, with no need to have this "new semantics" flag and an early return in the middle of the loop.
This is also the default, I think.
Nit: the method is `Producer.close()`, not "stop". The log message should probably reflect that.
Not sure what has changed here.
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Can you re-warp this block to 79 chars? (First line is too short.)
@rajinisivaram I guess so. I was trying to come up with an excuse to keep shutdown fast and eliminate some bookkeeping ð . By the way, I'm not sure it makes sense to distinguish between async and sync commits since `wakeup` can interrupt a synchronous commit before returning.
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
Is it possible to trigger infinite loop: raiseError -> reconfig -> raiseError -> reconfig ...
@rajinisivaram I guess so. I was trying to come up with an excuse to keep shutdown fast and eliminate some bookkeeping ð . By the way, I'm not sure it makes sense to distinguish between async and sync commits since `wakeup` can interrupt a synchronous commit before returning.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
as above. Name of the test can be more descriptive. `shouldRequireBrokerVersion0101OrHigherWhenEosDisabled`
The test should describe what it is doing, i.e., `shouldThrowStreamsExceptionWhenBrokerCompatibilityResponseInconsisent`
The test should describe what it is doing, i.e., `shouldThrowStreamsExceptionWhenBrokerCompatibilityResponseInconsisent`
Can replace the three lines with: ``` assertEquals(Utils.mkSet("TLSv1.2"), Utils.mkSet(engine.getEnabledProtocols())); ```
Can replace the three lines with: ``` assertEquals(Utils.mkSet("TLSv1.2"), Utils.mkSet(engine.getEnabledProtocols())); ```
I think we're testing `testDir` Occupied here, not `AppDir`.
Personally, I prefer (3) because the others provide redundant information.
nit: make final
Personally, I prefer (3) because the others provide redundant information.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
nit: I don't spot any, but safer to avoid typos by just having constants for these
Here we rely on insertProviderAt() programatic way BUT if in the application's context somebody else calls Security.insertProviderAt(provider,1) that provider will be given the priority for any conflicting Provider services+algorithms. This code works well if you have exclusive services+algorithms example SPIFFE but if you are writing a provider for Standard algorithms example TrustManagerFactory.PKIX then you may run into trouble since your insertProviderAt() call got overridden by somebody else in the application context/startup. When that happens I don't know easy way to fix it. I think It is important to call this out.
Here we rely on insertProviderAt() programatic way BUT if in the application's context somebody else calls Security.insertProviderAt(provider,1) that provider will be given the priority for any conflicting Provider services+algorithms. This code works well if you have exclusive services+algorithms example SPIFFE but if you are writing a provider for Standard algorithms example TrustManagerFactory.PKIX then you may run into trouble since your insertProviderAt() call got overridden by somebody else in the application context/startup. When that happens I don't know easy way to fix it. I think It is important to call this out.
Here we rely on insertProviderAt() programatic way BUT if in the application's context somebody else calls Security.insertProviderAt(provider,1) that provider will be given the priority for any conflicting Provider services+algorithms. This code works well if you have exclusive services+algorithms example SPIFFE but if you are writing a provider for Standard algorithms example TrustManagerFactory.PKIX then you may run into trouble since your insertProviderAt() call got overridden by somebody else in the application context/startup. When that happens I don't know easy way to fix it. I think It is important to call this out.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
I think it is probably worth adding as even if it is deprecated it is still supported
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
nit: add `final`
Maybe use Objects.requireNonNull
`VALID_TYPES` can now be removed too
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
`VALID_TYPES` can now be removed too
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
We should log an error that prints out what the two configs actually are
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
This method is usually called `setUp()`.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
This is because we are inheriting a Scala class, and moving forward we should remove this with the Java version `org.apache.kafka.copycat.util.ShutdownableThread` that can be moved into `o.a.k.common.utils`. We can leave it as is for now.
The primary functionality of this method is to _set_ the partition... I am confused by `with stale(standby, restoring) stores added via fetching the stores` -- what does this mean? Maybe just simplify to: ``` Set a specific partition that should be queries exclusively. ```
Hmm, when is prevMetadata ever set to INCREMENTAL? From the code, it seems that prevMetadata is only set to response.metadata(), which always starts with FULL.
The primary functionality of this method is to _set_ the partition... I am confused by `with stale(standby, restoring) stores added via fetching the stores` -- what does this mean? Maybe just simplify to: ``` Set a specific partition that should be queries exclusively. ```
The primary functionality of this method is to _set_ the partition... I am confused by `with stale(standby, restoring) stores added via fetching the stores` -- what does this mean? Maybe just simplify to: ``` Set a specific partition that should be queries exclusively. ```
Hmm, this doesn't need to block merging this, but we should think carefully about doing delay this way. The rest of Connect avoids trying to rely on Java's `interrupt` behavior because it's not really a reliable way to *actually* interrupt threads, and in a system where there are pluggable components that are allowed to block indefinitely, relying on functionality that most Java developers don't understand well probably isn't going to work all that well. It may not have actually gotten to a KIP, but there was at least some discussion on a JIRA somewhere about making connect perform interrupts in addition to the basic task `stop()` calls it already does, but it doesn't currently do this. For anything that can end up with pretty long sleep periods, we should try to make sure there's a good way of interrupting it and moving on (e.g. so rebalances wouldn't get delayed because there's a connector that's encountering errors). At a minimum, since we don't do interrupts currently, I think we wouldn't interrupt this code currently. The other approach we use elsewhere is to `wait` on a monitor so we can set a flag and interrupt with `notify` and have it bail out immediately.
Hmm, this doesn't need to block merging this, but we should think carefully about doing delay this way. The rest of Connect avoids trying to rely on Java's `interrupt` behavior because it's not really a reliable way to *actually* interrupt threads, and in a system where there are pluggable components that are allowed to block indefinitely, relying on functionality that most Java developers don't understand well probably isn't going to work all that well. It may not have actually gotten to a KIP, but there was at least some discussion on a JIRA somewhere about making connect perform interrupts in addition to the basic task `stop()` calls it already does, but it doesn't currently do this. For anything that can end up with pretty long sleep periods, we should try to make sure there's a good way of interrupting it and moving on (e.g. so rebalances wouldn't get delayed because there's a connector that's encountering errors). At a minimum, since we don't do interrupts currently, I think we wouldn't interrupt this code currently. The other approach we use elsewhere is to `wait` on a monitor so we can set a flag and interrupt with `notify` and have it bail out immediately.
Hmm, when is prevMetadata ever set to INCREMENTAL? From the code, it seems that prevMetadata is only set to response.metadata(), which always starts with FULL.
The additional validation doesn't hurt, but it might be more natural to move this check into the `if` below since we don't actually cast unless the condition is true.
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
```suggestion @Evolving public class WindowRangeQuery<K, V> implements Query<KeyValueIterator<Windowed<K>, V>> { ```
What are your thoughts regarding returning the same `"No such logger"` value? It might be more informative to JMX users
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Unfortunately that's not very consistent with what we want in the metadata. The default should be in code rather. Let's go with a `ClientRequest` that hardcodes the value as it used to in the field.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Ah, you are right: `valueOf()` `Throws: IllegalArgumentException - if the specified enum type has no constant with the specified name, or the specified class object does not represent an enum type.` Thanks for catching/testing for/fixing it.
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
Another name might be `seek()`.
Sorry if this basically seems like code-golfing, but I'm wondering if this would be equivalent and a little more robust? ```suggestion return samples.isEmpty() ? Double.NaN : max; ``` Then, we could leave the initial values at negative infinity (not sure if it matters).
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
```suggestion if redirect_fqcr1 := routing_entry.get('redirect', None) ``` Also, it would be good to use a better name than redirect_fqcr1.
```suggestion if redirect_fqcr1 := routing_entry.get('redirect', None) ``` Also, it would be good to use a better name than redirect_fqcr1.
nit: java style
Nit: somehow I don't like `blah`. Otherwise LGTM
nit: move below the shortcut return below.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
could move line 368 above this and then declare this as: `String [] parentNames = {this.name, streamImpl.name}`
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Maybe this looks better? ```suggestion // we're at the end of the input. if (queryResult.getResult().value() == batch1NumMessages - 1) return; ```
nit: add `final`
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
nit: insert space `String... expected`
Actually, do we even need the `endTime >= timestamp` part of the condition? We're really just iterating over the single dimension of the `startTime` from 0 to `timestamp + 1`
nit: if unused, remove the variable instead of suppressing a warning.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
instead of creating a new set, thoughts on just returning an empty collection? (`Collections.emptyNavigableSet()`)
instead of creating a new set, thoughts on just returning an empty collection? (`Collections.emptyNavigableSet()`)
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
This class is surprisingly similar to org.apache.zookeeper.Login, have we copied from the same source? ;-)
Checked with Jun and this is fine.
@wicknicks would be useful to have some unit test for this class.
I find having a method specific for SSL strange. Callers should not have to know, this should be retrieved automatically based on the cluster being targeted
We can use `putIfAbstent()`
nit: add a size? There are a few cases in here where we could do this.
Could also do the following to be a bit more succinct: ```suggestion assertEquals(Schema.Type.INT32, transformedSchema.field("date").schema().type()); ```
Perhaps we can use a better name for keysWithBytesFromSocket since selectedKeys() include keys ready for writes too.
nit: the name is a bit awkward. How about `maybeInvokeOnPartitionsLost`? We can change the others similarly.
looks like this condition is only actual for `resubscribeBeforeTimeout` test
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
This could be final.
nit: add `final` (same below)
nit: add `final` (same below)
Instead of having an `else` with a nested `if/else`, we could keep it flat: ```scala if (fileAlreadyExists) ... else if (preallocate) ... else ... ```
These should be constant values or an enum since they are used in multiple places
These should be constant values or an enum since they are used in multiple places
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
We can use a separate ticket to centralize these helper functions into `org.apache.kafka.test.TestUtils`, would you mind filing a JIRA? Example functions like `getProducer/Consumer/StreamsConfig`, etc.
Is this just to prevent it from processing anything until you're ready to proceed? It seems like you can/are doing that just by controlling when to produce input messages and doing so one at a time (if that's accurate, then WDYT about renaming `process` to `processed` and flipping the boolean so it more clearly serves the purpose of indicating whether a record has yet been processed)
Nit: every conditional needs to have braces (per the code style) not nit: I find this logic a little difficult to follow. Contrary to what @mjsax suggested, wouldn't it be pretty straightforward to map the old semantics on to the new ones like this: * negative numbers => 0 * 0 => Long.MAX_VALUE * all other arguments stay the same ? Then, the old close method could just transform its arguments and call the new method, with no need to have this "new semantics" flag and an early return in the middle of the loop.
No worries. I was only recommending to change the name if you stopped using it to gate the processing and just relied on producing messages to control when they could be processed, if you did want to do that. Either way is fine with me so you can just leave it as is
Same for all such calls.
Are these 3 lines an artifact of code reformatting? They don't seem to correspond to changes other than the reordering itself. The previous order matches the variable declaration order, so maybe we want to leave this as-is.
@sir-sigurd Is there any reason to change a regex? :thinking: You added `:`.
empty line needed
You're right. You know I both saw that and missed it too...
empty line needed
empty line needed
Instead of doing this, we can simply override `toString` in each enum. However, if we go with my suggestion of renaming the enum values, the `toString` will be the right one by default, I think.
If we reuse shared streams instance do we still need try-catch here as the `cleanup()` should close streams.
If we reuse shared streams instance do we still need try-catch here as the `cleanup()` should close streams.
If we reuse shared streams instance do we still need try-catch here as the `cleanup()` should close streams.
`<byte[]>` this explicit type is unnecessary
The reason of this function is that we'd reply on the overridden `Object.toString` function to print it, and if the received key-value happen to be `byte[]` we'd like to deserialize it otherwise `byte[].toString` will just print user-unreadable stuff.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
I'd consider making this extend org.junit.rules.ExternalResource - it can then be used as a JUnit ClassRule or Rule. The benefits being that the JUnit framework takes care of startup and shutdown
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
typo: The title of the last column should be `DELETE_SEGMENT_FINISHED`.
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
nit: remove extra line
Why is `completed` count being tracked? It doesn't seem to be used anywhere.
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
Thanks for the explanation. Make sense.
`advanceMs` is not the same as provided input parameter `advance` -- this would make the error message miss leading.
Another way to put this is that maybe we should make sure our built-in converters can handle calls to both `configure(Map, boolean isKey)` followed by `configure(Map)` with the `TYPE_CONFIG`. then, only things that are `Configurable` see the second one. old implementations wouldn't see it as they would not have implemented `Configurable` (except in unusual circumstances). New implementations could be warned by docs in `HeaderConverer` that they should take care to handle that sequence of calls.
We we improve this test class further (this method is ok I guess). Methods below for example: ``` @Test public void shouldBuildKeyValueStore() { final KeyValueStore<String, String> store = Stores.keyValueStoreBuilder( Stores.persistentKeyValueStore("name"), Serdes.String(), Serdes.String() ).build(); assertThat(store, not(nullValue())); } ``` Only check for not-`null` what seems to be a poor verification. (Maybe others can be improved, too).
nit: move to line above.
nit: move to line above.
What's the purpose of this warning? It doesn't seem needed.
or at least remove "by akarnokd on â¦", we have git history for that
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
spelling -> recrord -> record
if this method terminates in line 278 there will be no `self._requirement` in class instance, which would break things.
Technically, this is `numDrainedRecords`.
Nitpick: I'd call this `getOrCreateFileChannel`.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Could we combine the finally block with L45-46? Also I was thinking whether we should close the producer thread as well.
The flake8/test failure is because the above `help` is missing a closing parenthesis, hence a `SyntaxError`. You can always repush to the branch to rerun the tests.
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
The order is not really that important here, either way works
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
`long` -> `Long` is a binary incompatible change.
Mentioned offline, but it would be good to understand the need for these fields to be `volatile`. It seems that the use of the latch is sufficient to ensure visibility from the memory model perspective.
nit: add a size? There are a few cases in here where we could do this.
nit: add a size? There are a few cases in here where we could do this.
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Could you also verify that the stream thread was not replaced? You could use `KafkaStreams#metadataForLocalThreads()` for that.
Could you also verify that the stream thread was not replaced? You could use `KafkaStreams#metadataForLocalThreads()` for that.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
It might be simpler to just use `int transactionTimeout` -- Java will auto-cast to long in ``` if (transactionTimeout < commitInterval) { ```
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
Unify "create task" code with `shouldThrowExceptionIfAnyExceptionsRaisedDuringCloseTopology` -- it's almost the same and both test cases can use the same topology structure.
Nit: "The file channel position..."
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
nit: simplify -> `throws Exception` (also above)
nit: we could use `else if` here.
nit: we could use `else if` here.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
There should be an `id` group.
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
Ditto on removing these before/after methods.
I'm not sure these add value since TransformationChain has log messages with the records, which should be sufficient to know whether the schemas are null.
Can we call this `toHtml` to go along with the generically named `toRst`? If we want to change the output in the future, we won't need to add a new API.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
nit: we can use `map#compute` to replace getOrDefault + put.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
Let's keep the `L`
extension name must not be empty
Not sure you need to initialize the factory every time there.
Admittedly, this is a random time to bring this up, but a pattern that I like for this is: ```java final long seed = providedSeed != null ? providedSeed : new Random().nextLong(); System.out.println("Seed is: " + seed); final Random rand = new Random(seed); ``` where `providedSeed` comes from an env variable, command-line arg, whatever... This way you get the same default behavior (pseudorandomly generated sequence of test values), but you also have the option to deterministically reproduce a previous pseudorandom sequence from a prior run. This can be helpful in diagnosing flaky tests. Not saying this is needed here; I just wanted to share the pattern.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
nit: extra line
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
Would it be worthwhile to also add an empty collection at the end of the map as well to make sure that case is covered? You could use LinkedHashMap to ensure order.
the norm (ideally) for AK is to only use `this.` as needed to handle masking. i'm sure there are exceptions, but almost universally the use case is for constructors to avoid awkward parameter naming in order to avoid conflicting with a convenient member variable name.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
Would it be worthwhile to also add an empty collection at the end of the map as well to make sure that case is covered? You could use LinkedHashMap to ensure order.
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
Would it be worthwhile to also add an empty collection at the end of the map as well to make sure that case is covered? You could use LinkedHashMap to ensure order.
I will move all early returns to a separate commit.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
We dropped `sequence_reset_by_name_sql()` intentionally in d28396f5268f1974ef1e84d13bcf1ac107005ced. It's redundant after `TRUNCATE`, we should call it only in `DELETE FROM` branch.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
This should go away. `@ConditionalOnClass` already does that.
This should go away. `@ConditionalOnClass` already does that.
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
nit: Indicate that this needs shallow iterations on the entries.
this global variable isn't great. Can't we hit some rest endpoint that can return this internal values out of the extension? probably makes for a better end to end test too.
Yes, this should on an internal package (eg `common.internals`).
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
This doesn't seem to be used.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
nit: creating restoredPosition is not required if !constinceyEnabled
Yes, this should on an internal package (eg `common.internals`).
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Yes, this should on an internal package (eg `common.internals`).
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
This doesn't seem to be used.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
nit: 'else' can be dropped
There is a built-in for this `Function.identity()`
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Thanks for changing this. A couple more minor suggestions: - We can use this `Random` in the assignment of this.nodeIndexOffset (creating a `Random` without a seed involves a `System.nanoTime` and an atomic update of a JVM global variable). - All the fields that are assigned in the constructor should be made `final`.
Let's tweak this API to Throwable: ```suggestion StreamsUncaughtExceptionHandler.StreamsUncaughtExceptionHandlerResponse handle(final Throwable exception); ``` Here's a good explanation of why: https://stackoverflow.com/questions/2274102/difference-between-using-throwable-and-exception-in-a-try-catch The benefit is that we could handle `Error`s as well as `Exception`s. However, this comes with the obligation that we should not continue to use the thread after an Error occurs. I think we can deal with this restriction reasonably.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
You should also compare `expectedValues`.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
This doesn't seem to be used.
You might consider: ```suggestion try (final KeyValueIterator<String, String> scanIterator = forward ? stateStore.range(null, null) : stateStore.reverseRange(null, null)) { TestUtils.checkEquals(scanIterator, dataIterator); } ```
This doesn't seem to be used.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
`<byte[]>` this explicit type is unnecessary
`<byte[]>` this explicit type is unnecessary
`<byte[]>` this explicit type is unnecessary
These methods look like they are identical to those in the previous test class above
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
Thanks. Not a blocker.
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
This doesn't seem to be used.
This might be instable in Jenkins.
What typo ? ð Yes, it should be public -- it's meant to be a utility method (even if we don't use it atm).
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
To close out the earlier thread.. This test is okay, since `NOT_RUNNING` will make that instance go to DEAD state (or some non functional state like that) where the store cannot be obtained.. the lines below check that we can stil retrieve the keys from the other replica
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
Tripe `"""` for a docstring. Missing period at the end.
We should log an error that prints out what the two configs actually are
To close out the earlier thread.. This test is okay, since `NOT_RUNNING` will make that instance go to DEAD state (or some non functional state like that) where the store cannot be obtained.. the lines below check that we can stil retrieve the keys from the other replica
We should log an error that prints out what the two configs actually are
To close out the earlier thread.. This test is okay, since `NOT_RUNNING` will make that instance go to DEAD state (or some non functional state like that) where the store cannot be obtained.. the lines below check that we can stil retrieve the keys from the other replica
Nit: why not `failIfNotReadyForSend`? One character longer, but reads a bit better. :)
nit: 'else' can be dropped
Thanks for double checking this! Then it lgtm.
How about using `e.toString()`? It shows the class name of exception. I feel it is useful also.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
Same here, we can cache the result of `Builder.getPartitions(data)` for re-use.
Same here, we can cache the result of `Builder.getPartitions(data)` for re-use.
Thanks for the explanation. It seems like `purgeLocalStreamsState` should really be using `java.io.tmpdir` instead of `/tmp` if it wants to have that safety net.
```suggestion }, "The number of active tasks returned in the allotted time was not one."); ```
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Hey, I'm sorry, but can you explain what's going on here? `Sensor` doesn't override `equals`, so I'm not seeing how this assertion works.
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
As above -- incorrect return type description
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
This method could be replaced with the use of a Junit Rule and TemporaryFolder, i.e., `@Rule public final TemporaryFolder folder = new TemporaryFolder() ... logDir = folder.newFolder() `
well, i thought a method reference would work here for the hash map, but I tried it and it doesn't seem to work. ð¤
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
I don't think we need this `null` check either.
I don't think we need this `null` check either.
Nit: somehow I don't like `blah`. Otherwise LGTM
nit: add `final`
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
This is why the test was failing for you. The query is for a range of window start times, not record times. Since the window size is five minutes, the range `[now - 1 minute, now]` wasn't going to contain the actual window start time of `now - 5 minutes`. In other words, just a simple oversight :/ Sorry for the trouble.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
This is why the test was failing for you. The query is for a range of window start times, not record times. Since the window size is five minutes, the range `[now - 1 minute, now]` wasn't going to contain the actual window start time of `now - 5 minutes`. In other words, just a simple oversight :/ Sorry for the trouble.
```suggestion // when the interval has elapsed we should try to update the limit offset for standbys reading from // a source changelog with the new committed offset, unless there are no buffered records since // we only need the limit when processing new records ```
Also not clear why "numSegments - 1" here.
Also not clear why "numSegments - 1" here.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
Also not clear why "numSegments - 1" here.
We should read the metadata inside the while loop since it could change.
Also not clear why "numSegments - 1" here.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Also not clear why "numSegments - 1" here.
nit: add a size? There are a few cases in here where we could do this.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: add a size? There are a few cases in here where we could do this.
may be use Objects.requireNonNull
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
nit: add a size? There are a few cases in here where we could do this.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Same thought as above.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
nit: add a size? There are a few cases in here where we could do this.
Why not replace the `initialized` check with a null check? In that case, `value` needs to be volatile and `initialized` can be removed.
We can use `assertThrows` for this kind of pattern: ```java RecordDeserializationException rde = assertThrows(RecordDeserializationException.class, () -> consumer.poll(Duration.ZERO)); assertEquals(invalidRecordOffset, rde.offset()); assertEquals(tp0, rde.partition()); ```
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
the norm (ideally) for AK is to only use `this.` as needed to handle masking. i'm sure there are exceptions, but almost universally the use case is for constructors to avoid awkward parameter naming in order to avoid conflicting with a convenient member variable name.
We should use try-with-resources here (for `DataInputStream`).
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I think we should call `deserializer.configure(...)` here
I think the result does not need to include anything here if we organize the top-level future as a map of members -> the corresponding futures of `Void`.
I think we should call `deserializer.configure(...)` here
It's not super-important, but it probably makes sense to set -1 as the default for `ProducerId` in `InitProducerIdResponse`. Same for `ProducerEpoch` But maybe keep the explicit assignment as well since that makes it very clear...
Hey @junrao, It was discussed on the dev channel that we shouldn't store or pass around the '*' the end as this then requires places to validate the resource name ends in a '*' on API calls and when loading from ZK. Also, with the rebrand of this from 'wildcard-suffixed' to simply 'prefixed' then I think we can drop the '*' completely. e.g. the user would add an ACL to any topic resource the has the prefix 'foo'. Look mum, no asterisks! This also helps separate this from the current 'wildcard' support i.e. '*'.
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
We should read the metadata inside the while loop since it could change.
We should read the metadata inside the while loop since it could change.
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
That's a good idea. Note: Kafka does not use this JUnit functionality yet (i.e. no use of ExternalResource, ClassRule, Rule as far as I can tell). @ijuma: Would it ok for us to introduce this? There's no additional dependency etc., it's just using a new JUnit feature that was introduced in 4.7 (we're on 4.12).
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
nit `RocksDB` without space
nit: Indicate that this needs deep iterations on the entries.
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
I'm not sure this is really the right place to test the `prefixScan` functionality for all of these different store types, this test class is really more for making sure the topology itself is all wired up correctly. If you're just trying to test a method on a specific store type, that generally makes sense to do in the test class for that store itself. In other words you don't need to have a separate test here for each underlying store type (eg `PersistentTimestampedStore` or `LruMap`, etc), there are dedicated test classes for that (like `RocksDBTimestampedStoreTest` or `InMemoryLRUCacheStoreTest`) That said, it sounds like the original bug report uncovered the missing implementations "when accessing the state stores through the processor context" -- which does sound like it could/would be reproduced through a test here. Maybe you can just pick a store type and write a single test that reproduces the issue when run without this patch, and I would consider that sufficient for this.
I'm not sure this is really the right place to test the `prefixScan` functionality for all of these different store types, this test class is really more for making sure the topology itself is all wired up correctly. If you're just trying to test a method on a specific store type, that generally makes sense to do in the test class for that store itself. In other words you don't need to have a separate test here for each underlying store type (eg `PersistentTimestampedStore` or `LruMap`, etc), there are dedicated test classes for that (like `RocksDBTimestampedStoreTest` or `InMemoryLRUCacheStoreTest`) That said, it sounds like the original bug report uncovered the missing implementations "when accessing the state stores through the processor context" -- which does sound like it could/would be reproduced through a test here. Maybe you can just pick a store type and write a single test that reproduces the issue when run without this patch, and I would consider that sufficient for this.
Same as before, `new Integer[]{}' not required for `Arrays.asList`.
This doesn't seem to be used.
This doesn't seem to be used.
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Can we also assert that the state gets to `RUNNING` after the new thread has joined
none from what I can see, but I'm not sure it's worth holding up the PR for it.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
remove empty line
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
Could we just add a toString function to ProcessorNode / SourceNode / SinkNode so that this code just becomes: ``` print(node) { // node.toString // also include listing children names foreach(child <- children) print(child). } ``` And also you do not to maintain the mapping as well.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
typo: byteArrray -> byteArray
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
Same question for ProcessorSupplier for using a delegate, but is minor to me.
nit: could be set to final and refactor as: ``` final Integer partition; if (partitioner != null) { final List<PartitionInfo> partitions = producer.partitionsFor(topic); if (partitions.size() > 0) { partition = partitioner.partition(topic, key, value, partitions.size()); } else { throw new StreamsException("Could not get partition information for topic '" + topic + "' for task " + taskId + ". This can happen if the topic does not exist."); } } else { partition = null; }
Can you re-warp this block to 79 chars? (First line is too short.)
I'd also consider removing this one too if we are not using it.
Maybe use the `addNode()` available on this class for consistency? (applies a few times in this file)
nit: parameters on a separate line
Could this result in NPE? May be we can directly throw an IllegalArgumentException here.
This should disappear with my suggestion.
I think we just leave the expiration of the next connection in the next poll() call.
nit: parameters on a separate line
nit: We use singular verbs in other functions (e.g. line 54 above), would be better to be consistent.
nit: We use singular verbs in other functions (e.g. line 54 above), would be better to be consistent.
Could this result in NPE? May be we can directly throw an IllegalArgumentException here.
nit: Empty line could be removed.
Is the current implementation vulnerable to the following race condition? 1. thread1 grabs `CHANNELS` lock, get the channel object from the map; and then exists the `CHANNELS` lock; 2. thread2 grabs the lock, release the lock on it, close the channel, remove from the map. 3. thread1 now calls `channel.tryLock`, which throws `ClosedChannelException`.
Thanks for cleaning up the code duplication.
Let's piggy-back on this PR: it should not be a big fix.
Let's piggy-back on this PR: it should not be a big fix.
We can use `assertThrows` here.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
`TaskManager#tasks` has to be accessed through the state change thread. It can't be accessed here by incoming requests since there is no lock or synchronization. Probably the easiest thing to do is to have a CreateTasks runnable which does what you want.
nit: was -> were
Hmm.. This method is invoked from `unsubscribe`. It seems like we might want to use `onPartitionsRevoked` in that case because it can still be a graceful handoff.
typo: moreq -> more
> I've been going back and forth on whether to add this as a "per-cluster" or "per-instance" config, @vvcephei and I discussed briefly but @cadonna any opinion? If we do go with cluster-wide I think we should make the default pretty big, but I'm now leaning towards towards making it per-instance. Thoughts? per cluster: - (+) We would have more freedom in the assignment algorithm, because we do not need to consider the value of this config for each client. - (-) How should we react to distinct values on clients? How should we even know whether there are distinct values configured? We could just say Streams assumes the values of this config are the same on all clients and whatever is specified on the group leader is the truth. per client: - (+) Each client host might differ in performance and users might want to adapt the value of this config for each client - (-) Within the algorithm, how should we know the value of this config for a specific client? Don't we need to adapt the protocol to get all values at the group leader? Since assignment and restoration (a.k.a. warming-up) is done on stream thread level, it might be better to specify the value per stream thread. For example, 1 would mean that one extra replica per stream thread might be assigned. If a Streams client has three stream threads it can host up to three extra replica. The config would be global (a.k.a. cluster-wide) but users could account for different performances of the hosts by specifying different number of stream threads (which they probably have to do anyways). Here again, the value specified at the group leader is the truth.
I did notice that you renamed the method in a subsequent commit which covers the "name should also ideally indicate the difference" part. :)
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
```suggestion response, info = fetch_url(module=module, url=base_url, headers=json.loads(headers), method='GET') ```
I think we should also log the error in `failed && isRetriable()` case
```suggestion response, info = fetch_url(module=module, url=base_url, headers=json.loads(headers), method='GET') ```
Thanks @enothereska and @ijuma , I'm convinced.
There's also https://github.com/apache/kafka/pull/11128 to consider.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
same as above for parameters
Ditto on removing before/after
Ditto on removing before/after
This is the wrong format for this log message. The exception won't be logged. You have to format the string first: ```suggestion log.debug( String.format("Timeout exception. Remaining time to deadline %d; retrying.", deadlineMs - currentWallClockMs), timeoutException ); ```
nit: move `process()` to next line (easier to read)
Same question here as earlier about the `Locale`
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
For global state stores, here is the ordering of each stage: 1) Initialization: `GlobalStreamThread.initialize()` -> `GlobalStateUpdateTask.initialize()` -> `GlobalStateManagerImpl.initialize()`, where we read the checkpoint file into `checkpointableOffsets`. 2) Restoration: In the same `GlobalStateManagerImpl.initialize()`, we call `stateStore.init()`, in which `GlobalStateManagerImpl.register()` is called, and hence `restoreState()` will read from the loaded `checkpointableOffsets`: if it contains offset seekTo(), otherwise seekToBeginning(). 3) Starting: The restoration will bootstrap the global stores up to the log end offset, and after that we will write the restored offset to `checkpointableOffsets`: i.e. we will update the map, with the new values. At this stage the non-persistent stores' offsets should be written to it as well (i.e. line 288). Then we will call `GlobalStateUpdateTask.initTopology` to create the update node and go ahead the normal execution. So here the returned `stateMgr.checkpointed()` should already contain the restored offset already, therefore we can safely call `globalConsumer.seek()` in its caller now. 4) Checkpointing: When we call checkpoint(), we should make sure that non-persistent stores are not written to the checkpoint file, and actually whether we should filter on the `checkpointableOffsets` does not affect correctness anyways since we do not use it anywhere anymore, but to be consistent with its name I think it is still better to filter out those non-checkpointing offsets. Note that the whole logic is a bit awkward as it was spin off the `ProcessorStateManager` class, and as I mentioned above we can consider consolidating them in the future.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
Yeah, you can use a volatile field and synchronize on the assignment if still null. And then file a separate Jira to remove it from the class in a separate PR.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
this will never be called if one of the assertions fails
super-nit: this should say `Check that this is a Decimal`, not `date`. repeated below for time and timestamp, but slightly less egregiously :)
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
nit: add a size? There are a few cases in here where we could do this.
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
Since we have three threads for this test, there can be multiple rebalances before the streams instance stabilize and start processing...
nit: 'else' can be dropped
nit: `immediatelyÃ¥` -> `immediately`
Looks good. I like the additional checking that you're doing here.
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
nit: 'else' can be dropped
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
We can remove `requireNonNull` here, because `getter.keySerde()` would already throw a `ConfigException` if the default serde is null.
ð fair enough
This method is not `synchronized`. So there could be a race condition here. I think it should be: ``` final NamedCache cache = getOrCreateCache(namespace); final LRUCacheEntry result = cache.putIfAbsent(Bytes.wrap(key), value); maybeEvict(namespace); return result; ```
This doesn't seem to be used.
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
This doesn't seem to be used.
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
think we can chop the blank lines in the last 3 tests
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
I think we should call `deserializer.configure(...)` here
I think we should call `deserializer.configure(...)` here
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
You might consider using `OptionalDouble`.
I think we should call `deserializer.close()` here
We only applied for `ElementType.METHOD`, so `ElementType.ANNOTATION_TYPE` can be removed.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
"*" is considered "LITERAL" for compatibility reasons
nit: add `final`
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
Yea, my suggestion would be to reuse the existing constructor as the construction of the `AlterConfigsResponseData` seems non trivial for a caller to do, compared with passing a map of errors.
"*" is considered "LITERAL" for compatibility reasons
Yea, my suggestion would be to reuse the existing constructor as the construction of the `AlterConfigsResponseData` seems non trivial for a caller to do, compared with passing a map of errors.
nit: remove blank line
nit: remove blank line
nit: remove blank line
Nit: remove the `:` after "type", since this forms a readable sentence.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
may be use Objects.requireNonNull
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
I vote yes for this. I think if we use this for writing snapshot from the state machine, then minimum size is a more interesting metrics for flushing to disk vs lingerMs. If we implement this so that either one has to be true then the client can set the `lingerMs` or `minSize` to MAX_VALUE if it wants to ignore those values.
Ah, my bad. I think the variable I had in mind is actually called `Double.BYTES`. Not 100% sure it's defined for all possible primitive types, but I would hope so
Maybe we can just a better name for `path` since it makes this code look suspicious.
Maybe we can just a better name for `path` since it makes this code look suspicious.
added `per key` (twice)
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
Should be final
Should be final
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
Should be final
Second parameter should be `serverConfigs`
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
formatting: no need to curly braces
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Should we include the config source instead for compatibility? Also, just double-checking that it is intentional to leave the synonyms out of `equals`.
Yeah, I think it's worth the bit of logic to fail more quickly.
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
req: we'll never hit this, as `taskToCaughtUpClients` only contains tasks _with_ caught-up clients IIUC. Can we just construct `unassignedTasksWithoutCaughtUpClients` as the set `totalTasks - taskToCaughtUpClients.keySet`? We can do that in `assignTasksWithoutCaughtUpClients` and remove `unassignedTasksWithoutCaughtUpClients` from `assignTasksWithCaughtUpClients` entirely
Perhaps: `With the COOPERATIVE protocol, owned partitions cannot be reassigned...`
nit: rename this function to `restoreStarted` to be consistent with other names. Such will help other code readers to understand these functions are for the same code granularity and semantics.
what about the case that both if's are `false` -- can this happen? If not, we should throw an exception
unnecessary type in constructor, can use `new HashMap<>()`
```suggestion processed = new AtomicBoolean(true); ```
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
nit: initialize `appId` with the prefix you want (eg `appID_`, or something more descriptive like `TaskMetadataTest_`) and then just append testId, ie ``` appId = appId + testId; ``` Just makes it easier to locate what the prefix is (same with `inputTopic` below)
There are two issues I see with this: In terms of code, the `elif key=='TEST'`executed for every key that isn't TEST_\* is a little funny. In terms of semantics, you assume that not including a value in the dict is the same as setting it to None, which isn't true (e.g. `TEST['CREATE_DB']` is a Boolean which defaults to True ). I think it is better to do something like (untested) ``` python test_settings = conn.setdefault('TEST', {}) old_test_settings = {} for key, value in six.iteritems(conn): if key.startswith('TEST_'): new_key = key[5:] new_key = self.TEST_SETTING_RENAMES.get(new_key, new_key) old_test_settings[new_key] = value if old_test_settings: if test_settings: if test_settings!=old_test_settings: raise ImproperlyConfigured(...) else: #not test_settings test_settings = old_test_settings warnings.warn(...) # now test_settings can be used ``` This doesn't pin exactly any mismatch, but that can be done only when an error has been detected (and then TEST_SETTING_RENAMES_REVERSE may still be useful)
Also it can be static, as it's thread-safe. Or an alternative option. In terms of flexibility, it's wise to move initialization to configure() method. This way you'll be able to retrieve some jackson-specific options (if necessary) from the "props" Map.
`Integer.toString` is a slightly more concise way of doing this.
getters should not use get. i.e. use `networkDevice` here, etc.
Also it can be static, as it's thread-safe. Or an alternative option. In terms of flexibility, it's wise to move initialization to configure() method. This way you'll be able to retrieve some jackson-specific options (if necessary) from the "props" Map.
maybe a nit: I understand what you are doing here, but IMHO there should be two separate tests.
formatting: no need to curly braces
Are both host groups really needed? Does the one that contains ':' handle both? We have regex in other places in the project that do similar parsing we may want to keep in sync: - https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/utils/Utils.java#L53 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/BrokerEndPoint.scala#L27 - https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/cluster/EndPoint.scala#L29
nit: add a size? There are a few cases in here where we could do this.
Should it be valid for this to be null? I would think that these Serdes should be configured either by instantiating it directly via this constructor, or via the default constructor + setting configs (eg list.key.serializer.inner). It doesn't seem to make sense to use this constructor and not pass in valid arguments. WDYT about throwing an exception if either parameter is `null` -- not sure if ConfigException or IllegalArgumentException is more appropriate, up to you
Nit: can be `final`
nit: add a size? There are a few cases in here where we could do this.
Sorry for my denseness... Why are these "not re-assigned"? They're part of a data structure called "assigned tasks", which seems to imply that they are assigned.
nit: add a size? There are a few cases in here where we could do this.
I'd suggest moving this static method after the non-static methods.
The order is not really that important here, either way works
nit: add `final` (2x)
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
`<byte[]>` this explicit type is unnecessary
nit: add `final` (2x)
nit: it would improve readability to factor out some functions for some of the work here. Here we can have a separate function with a nice name for building the assignments
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
One extra line.
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
This is synchronized and will await on the produceFuture. `await()` is called by `awaitFlushCompletion()` which is called when a user calls `flush()`. I am concerned that a user can call `flush()` and end up effectively dead locking other operations on the ProducerBatch, as getChildrenProducerBatch and addChildrenProducerBatch will not be able to be called by other threads - my concern is that the sender thread may become deadlocked in splitAndReenqueue in this state.
Also set the store name in this test.
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
Kafka doesn't mandate braces in `if` statements.
Nit: please use single parameter per line formatting
Kafka doesn't mandate braces in `if` statements.
Nit: please use single parameter per line formatting
Nit: rename to `shouldThrowOnInvalidTopicNames`
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
Can we use `Optional<String>` for this? Using magic string values feels messy, and will leak into the API
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
This doesn't seem to be used.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
Not something we have to do here, but one way we could improve this in the future is by taking into account leader epoch information from individual partitions. We can ensure that epochs increase monotonically in order to prevent using stale information during retry. Another thing we could do is reduce the topics we are fetching metadata for as the ListOffsets requests complete. Ideally we'd only be refetching metadata for topics with metadata errors.
Not something we have to do here, but one way we could improve this in the future is by taking into account leader epoch information from individual partitions. We can ensure that epochs increase monotonically in order to prevent using stale information during retry. Another thing we could do is reduce the topics we are fetching metadata for as the ListOffsets requests complete. Ideally we'd only be refetching metadata for topics with metadata errors.
Just let the Exception flow, that will automatically fail the test
He means that you don't need an `else` in this case.
nit: Empty line could be removed.
Hmm, why did we do this? I thought we'd have a try/catch block.
adding the registraiton part into Config file doesn't look good to me. Generally speaking Config classes are only there to express the config members and validation around them but not to take any action. SecurityUtils.java would be a better place.
nit: npe is possible here, though state overall won't be ok, but npe is still seems possibe
Copy/paste bug: should be "source."
Not sure if this will actually be cleaner or end up more complicated, but you may be able to reuse some of the `StickyTaskAssignor` code here which does similar things
I think we should call `deserializer.close()` here
I think we ditch the before/after methods as I previously recommended.
I think we ditch the before/after methods as I previously recommended.
python3 tests failed because `six.iteritems(old_test_settings)`.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
nit: "User rebalance callback **threw** an error"
I think we're testing `testDir` Occupied here, not `AppDir`.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
Instead of doing this, we can simply override `toString` in each enum. However, if we go with my suggestion of renaming the enum values, the `toString` will be the right one by default, I think.
This always scheduled in the future with `timeout`. Shouldn't it be the time until next timeout? Let's say timeout is 1000ms and I get an onNext call every 50ms. This code seems to schedule each action to execute 1000ms in the future even if it comes in 950ms since the last onNext was permitted through.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
nit: We could use `singletonMap` here.
We can use `List<Class<? extends Connector>` to avoid the warning
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
Usually we don't use the URL as `video_id`. If `video_id` is unknown yet, it's OK to use part of the URL, for example "a-housecat-a-stray-god-and-a-tail".
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
Ideally we'd not wrap the exception if there are no retries, so I guess it just depends on how hard it is to make that work.
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
It seems that we need to automatically create metadata topic in RLMM implementation, not just in tests.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
ok. Just curious what is target date when all implementation for this will be merged? cc@saisandeep
@jeffchao traditionally Kafka used key,value pairs in properties and pass it everywhere and each implementation takes look at this config and pulls their interested key,value pairs. Example, authorizer interface https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/security/auth/Authorizer.scala#L35 . The pluggable class when it gets instantiated a configure method will be called and all the key,value in server.properties will be passed and it will pick whats relevant to the class. We can do the same here instead of asking users append key,values into the a config which is hard to configure and hard to get it right.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
Same minor nitpick about whether or not we need to check for an empty group ID.
How about returning a Set instead of List? ``` return topics .stream() .filter(topic -> !topic.isEmpty()) .collect(Collectors.toSet()); ```
Could we just use `Errors` throughout? You can always get the code from `Errors` if you really need it.
Same minor nitpick about whether or not we need to check for an empty group ID.
This is a weird line break. It would be better to shorten the line by assigning the result of `mapper.apply` to a variable.
Nit: go with single parameter per line.
Nit: go with single parameter per line.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
Yeah, I think it's worth the bit of logic to fail more quickly.
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
Can you please fix this output too -- the tool does "seek to beginning" and does not set offsets to zero.
nit: add `final`
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
again, naming of the test
This block can be moved outside of the `try-catch-block`
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Thanks. Will merge after Jenkins is green.
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
We recently "fixed" `listAllTaskDirectories` to guarantee that it never returns null. We just missed to update all the null checks when we did that
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
if you added a method to `NodeFactory` `String[] parents()` then in `SourceNodeFactory` you implement it by returning `new String[0]` This code becomes ``` String[] predecessorNames = nodeFactory.parents() for(final String predecessorName : predecessorNames) { ... } ```
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
It looks like there is an extra whitespace after return.
nit: add `final`
Nit: every conditional needs to have braces (per the code style) not nit: I find this logic a little difficult to follow. Contrary to what @mjsax suggested, wouldn't it be pretty straightforward to map the old semantics on to the new ones like this: * negative numbers => 0 * 0 => Long.MAX_VALUE * all other arguments stay the same ? Then, the old close method could just transform its arguments and call the new method, with no need to have this "new semantics" flag and an early return in the middle of the loop.
records to it, and reading all records from it, such that
Same for generation and member.id. We could just call `request.data().generationId()`
Same for generation and member.id. We could just call `request.data().generationId()`
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
Slots aren't nodes in Redis Cluster. Slots are logical partitions, so `slots_up` and `slots_fail` would fit better.
Let's use `assertEquals`: ```suggestion assertEquals(0, raftNode.counter.getHandleSnapshotCalls()); ```
Remove double blank.
nit: extra line can be removed
I think we just want to get rid of the special handling for logical types, but if it stays, the handling here needs to change. Any user defined schema can have a name too.
I think we just want to get rid of the special handling for logical types, but if it stays, the handling here needs to change. Any user defined schema can have a name too.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
What about promotion? We need to actually perform the type promotion. It isn't valid, for example, to use an `int8` field's `Byte` value directly for a `float32` field.
This list is small anyway, so I'm not too worried about the cost, but this seems wasteful. Seems like this promotion check should be a simple lookup in a precomputed table.
Hmm.. In fact, there is not necessarily any relation between the partitions that are being consumed and those that are being written. Usually you would expect them not to overlap. I wonder if it actually makes more sense to track these offsets in a separate map.
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
style nit: normally we'd use braces around blocks unless they're a single line
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Seems this `fail` did not work as expected? Otherwise the test would have failed all the time? Maybe we should rather set a boolean flag that we evaluate outside of the callback to let the test fail? Also, we have one run with zero exceptions and one run with 2 exception (one exception type each) -- not 4. Thus, we need to handle this differently for the error-injection and the "clean run" differently depending on the boolean test flag.
Seems this `fail` did not work as expected? Otherwise the test would have failed all the time? Maybe we should rather set a boolean flag that we evaluate outside of the callback to let the test fail? Also, we have one run with zero exceptions and one run with 2 exception (one exception type each) -- not 4. Thus, we need to handle this differently for the error-injection and the "clean run" differently depending on the boolean test flag.
nit: Empty line could be removed.
This formatting is going to fail checkstyle. There seem to be other failures as well. For the changes in this patch, run `./gradlew clean clients:test` to make sure everything will pass.
That can be a class-level attribute -- no need to assign it in `setUp` for each test. Probably should have a more descriptive name like `no_attribute_msg`.
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
I'd prefer to keep these in the same class as the other Java-related conventions.
I'd prefer to keep these in the same class as the other Java-related conventions.
I'd prefer to keep these in the same class as the other Java-related conventions.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
I think we can be more concise and simply say `// Single writer thread, multiple reader threads`
I think we can be more concise and simply say `// Single writer thread, multiple reader threads`
I mean the `ProductionExceptionHandlerResponse` class itself
@rodesai I see your point here. However, the downside of not throwing is that we will also not notice the bad behavior in our tests like the soak tests. I personally prefer to improve tests instead of downgrading the reaction to bad behavior. Assume in future somebody makes a change that breaks the assumption of the non-shared metrics registry, we would find this bug immediately during development instead of during production. Another option that comes to my mind is to classify exceptions that originate from the metrics framework differently in the uncaught exception handler, but that would probably need some more work.
Could just use `false`
Looks like you can do these 7 lines in a `@Before` method and not repeat it in all of your tests
Changed this to generate a name `<userName>-cogroup-merge` to align to `<userName>-cogroup-agg-<counter>` instead of just `<userName>` for the merge node.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
Ah, yes. Of course. I'd forgotten that we still bind directly to the `Flyway` instance. You're right. Let's keep the `SpringBootFlyway` class please.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
For some test cases we may want to use the same `MockTime` object on both server and client, for example in window store changelog truncation (cc @dguy ). So instead of creating the object internally we may want to pass it through parameters.
fair enough - we still don't need the assertion though as it is already true as of line 69
the `try{...} finally` has been removed
`start` is not used.
Should this be included here, or should it refer to a dedicated section in the connect docs? I guess there's two cases: bootstrapping a whole new connect cluster, or upgrading an existing one. For the bootstrapping case it's not completely clear whether the "preparing" round is required.
This should call `configState.rawConnectorConfig(connector)`, which returns the _user-supplied_ configuration _with variables not resolved_. The `connectorConfig(connector)` call returns the configuration _with variables already replaced_, which means we might be leaking passwords and other secrets specified using variables.
This might be instable in Jenkins.
we can use `TestUtils.assertFutureThrows()` here too
nit: add `final`
nit: add `final`
Q: Why do you use a mock here? In the ticket you said you just want to replace `MockStreamsMetrics` with `StreamsMetricsImpl`. req: If there is no specific reason, I would propose to either create a common mock that can be used everywhere as I proposed or to consistently replace `MockStreamsMetrics` with `StreamsMetricsImpl`.
We should update this test and use `assertThrows` instead of `try-fail-catch`.
I think we should provide some context on the exception here.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
You might consider using `OptionalDouble`.
You might consider using `OptionalDouble`.
unnecessary type in constructor, can use `new HashMap<>()`
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
Please use hanging indent: ``` self.assertEqual( set(request.META.keys()), {'PATH_INFO', 'REQUEST_METHOD', 'SCRIPT_NAME', 'CONTENT_TYPE', 'wsgi.input'} ) ```
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
Nitpick: I'd call this `getOrCreateFileChannel`.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
the `try{...} finally` has been removed
the `try{...} finally` has been removed
the `try{...} finally` has been removed
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
the `try{...} finally` has been removed
the `try{...} finally` has been removed
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
We need to keep the old method as before and deprecate.
nit: As said in the other PR, this is a good idea but I would only do it if we do it for all exceptions.
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
e.getMessage will be more accurate.
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
I think we tend to use `forXxx` rather than `create` for mapping names to enums.
nit: remove empty line
nit: remove empty line
This probably needs to check `clientResponse.hasResponse()` otherwise it could throw `NullPointerException`
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
nit: remove the redundant line. Same as below.
immediatelly -> immediately
could we turn this into a loop? i.e., sth-like? ``` List<KeyValue> records = Arrays.asList(...); for(KeyValue record : records) { mockTime.sleep(10); IntegrationTestUtils.... } ```
Do you mean it should NOT be included...
While I think it would be fine, it would be "new" -- if we think `instance` is better, we might want to migrate all other code lazily to use `instance`, too. It's always best to have the same naming conventions throughout the whole codebase IMHO.
We tend to use different `node` value when multiple connections are created by a test. You could just replace `node` here with "1" and a couple of lines below with "2".
super nit: the message should explain what happened if the condition fails, ie it should be the opposite, something like ```suggestion TestUtils.waitForCondition(() -> !process.get(), "The record was not processed"); ```
Could we fail the test right here? It doesn't seem like there is much benefit to returning the missing metrics from the method. That would let us simplify this a little. Instead of this: ```java Set<String> missingMetrics = getMissingMetricNames(expectedMetricNames, expectedGroup, expectedType); assertEquals(Collections.emptySet(), missingMetrics, "Expected metrics did not exist"); ``` we could have: ```java assertRegisteredMetrics(expectedMetricNames, expectedGroup, expectedType); ``` We could probably also drop `expectedGroup` since we only have `kafka.controller`.
+1 on Jun's suggestion if it works. If not, it might make sense at least to return a flag indicating whether the read completed.
Perhaps something like "Represents a pattern that is used by ACLs to match zero or more Resources"
"*" is considered "LITERAL" for compatibility reasons
Is the following error code also retriable? 0x15 | KDC_ERR_CLIENT_NOTYET | Client not yet validâtry again later
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
Could store `entry.getKey()` in a local variable since it is used several times
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
prop: Should we use `MockTime` here? prop: Could you use a more meaningful name for `ts`? The above is also valid for the overload.
This is an asynchronous method, and it's likely the connector will not be started and running before the test proceeds to the next statements. This can lead to very flaky tests. We could instead wait until the connector is actually running, using something like: ``` connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, NUM_TASKS, "Connector tasks did not start in time."); ```
the norm (ideally) for AK is to only use `this.` as needed to handle masking. i'm sure there are exceptions, but almost universally the use case is for constructors to avoid awkward parameter naming in order to avoid conflicting with a convenient member variable name.
the norm (ideally) for AK is to only use `this.` as needed to handle masking. i'm sure there are exceptions, but almost universally the use case is for constructors to avoid awkward parameter naming in order to avoid conflicting with a convenient member variable name.
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
add `final` twice
nit: we can just throw a `TopologyException` exception here.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
nit: we can just throw a `TopologyException` exception here.
nit: we can just throw a `TopologyException` exception here.
nit: maybe we can separate AbstractTaskCreator and its two impls into separate classes once we are finalizing the refactoring in a follow-up PR (this PR can stay as is to keep it from exploding LOC)
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
We should wrap `KafkaException` as `StreamsException` but rethrow all other `RuntimeException` unwrapped (at least this is the pattern we use everywhere else, and thus we should follow it here, too)
nit: the name is a bit awkward. How about `maybeInvokeOnPartitionsLost`? We can change the others similarly.
nit: log.info("Suspended {}", state());
nit: log.info("Suspended {}", state());
nit: These two functions are not for testing only.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Also? ```suggestion assertEmptyRecords(); assertNoEmptyDeques(); ```
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
Use `KafkaException` instead of `RuntimeException`
Please add `observeOn(Scheduler, boolean delayError, int bufferSize)` overload as well.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Yeah, the underlying store compares the serializer bytes lexicographically, it doesn't have any concept of "Integer" or any other type. And the really tricky thing is that it scans lexicographically, which means from left to right, whereas when we serialize things we usually do so from right to left. eg `2` in binary is `10` whereas 11 in binary is `1011` and 13 is `1101`. The problem here is that the serialized version of 2 is a different number of bytes than the serialized form of 11/13, so the lexicographical comparator is effectively comparing digits of a different magnitude.
nit `getMetadata` -> get`
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
`state` is shared between threads. I think this block needs a `synchronized(AbstractCoordinator.this)` (and same below)
Nit: add `final` to both parameters -- please follow a "one parameter per line" formatting.
`needCommit` -> `needsCommit`
Also: should only call onPartitionsLost on owned partitions that no longer exist
Yeah, we're still feeling out the best patterns for handling older versions.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
nit: add `final`
Refer to the `processing.guarantee` config here.
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
I guess it a typo? now -> not
Updated this when merging.
Updated this when merging.
the `try{...} finally` has been removed
One extra line.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
immediatelly -> immediately
immediatelly -> immediately
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
It seems like we are not totally consistent in the naming convention: `readRawUnsignedVarInt` versus `readRawVarUnsignedInt` below.
immediatelly -> immediately
super nit: maybe reverse statement to `maxInFlightRequestsAsInteger > 5` IMHO easier to grok, but this is highly opinionated, so feel free to ignore.
Naming this the same as the one in `WorkerTest` is causing failures in `WorkerTest` because the search for the connector by reflection finds both classes.
Could the cluster aliases be constant as these are used all over the place
This can also happen when topic exists but offline, right? or when we simply fail to connect (network issues, etc)? I like the specific error message, but I'm concerned it may be misleading if there can be other causes to the error (and user is certain the topic exists...)
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Hmm, I thought you planned to use the "parent processor node name" as the prefix if it is not specified, which seems more user friendly to me? EDIT: actually my bad, nvm.
ok - same thing three times. Maybe extract it to a method `verifyTransactionInflight`
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
the naming used above seems better here ```suggestion Throwable exception = null; ```
The two cases are differ that one throwing KafkaException (fatal) and the other throwing ProducerFencedException (task-migrated).
I think a better test scenario is to move the logic in `close()` call, i.e. when the stream thread is being shutdown, and topology is closing, we call `processorNode.close()` in which we wait for a while and then tries to access the global store. It mimics the case where in closing the store cache is flushed and hence tries to access the global store again.
What do we do if there's an exception? If it's expected, let's make it clear
Sorry, I'd missed that there are two URIs being configured, one with credentials and one without.
Maybe we can just a better name for `path` since it makes this code look suspicious.
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
As discussed in the JIRA, I still think we should use `FileChannel.open`.
Please use hanging indent: ``` self.assertEqual( set(request.META.keys()), {'PATH_INFO', 'REQUEST_METHOD', 'SCRIPT_NAME', 'CONTENT_TYPE', 'wsgi.input'} ) ```
This doesn't seem to be used.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
We can also get here if handshake has already failed (state == `State.HANDSHAKE_FAILED`) and there are still bytes to be flushed in `netWriteBuffer`.
same for the store
What's the purpose of this warning? It doesn't seem needed.
> At the moment, I am leaning toward the latter. In any case, I suggest we let the errors propagate for now and file a jira to reconsider once we are closer to integration. Does that sound fair? Sounds fair to create a Jira and revisit this later.
> At the moment, I am leaning toward the latter. In any case, I suggest we let the errors propagate for now and file a jira to reconsider once we are closer to integration. Does that sound fair? Sounds fair to create a Jira and revisit this later.
What's the purpose of this warning? It doesn't seem needed.
Good point, I think we should add `this.nano += TimeUnit.NANOSECONDS.convert(autoTickMs, TimeUnit.MILLISECONDS)` in `nanoseconds()` as well.
@guozhangwang Yep, sounds good to me.
At a high level, our store ecosystem looks like an onion. On the outside, we have a <K,V> store, and on the inside, we have a <bytes,bytes> store. All the layers in between have different responsibilities, like changelogging, caching, add metrics, etc. The nice thing about this PR is that it gives us one clean layer that's responsible for the transition `<K,V> <=> <bytes, bytes>`. When we need to look at the de/serialization into/out-of the stores, we have exactly one place to look. The prior code did mostly this, but to accommodate cache flushing in conjunction with the fact that the cache layer is below the transition from objects to bytes, we had to poke a hole in the onion and tell the caching layer (a bytes layer) how to deserialize. So, then there were two layers that independently know how to de/serialize, and the onion had a hole in it. This idea to move the serialization out to the TupleForwarder is basically the same, but in the opposite direction. Again, there are two components that need to perform serialization (the serialization layer and the tuple forwarder), and again, we need to poke a hole in the onion so that the tuple forwarder can communicate directly with an inner layer. It's not always practical to go for a "pure" design, but if readability is the goal, then it seems like we should try to avoid mixing layers, unwrapping layers, etc. as much as possible. To be fair, this is just my take on the situation.
Please remove empty line.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Read https://github.com/ansible/ansible/blob/devel/CODING_GUIDELINES.md#regexes. So you can ignore `regex`
Nit: go with single parameter per line.
No need to specify encoding. `fatal` should be `True` (default) since you are not providing any alternative extraction scenario.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
The first exception will be the "cause"
also please rename entity_id to job_id, no need to have it too generic here
We should read the metadata inside the while loop since it could change.
nit. I think there is `.` missing `since 3.0[.] Use`
What do we do if there's an exception? If it's expected, let's make it clear
nit: we could set a final int for numRetries as: ``` put(StreamsConfig.adminClientPrefix(StreamsConfig.RETRIES_CONFIG), numRetries); ``` and use (numRetries + 1) here to clearly indicate we are trying to go beyond the retry limit.
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
Nit: I was thinking that the variable name should be `batchHeader` and this string seems to confirm that.
Let's use `Map` on the left side instead of `HashMap`
I think this would be clearer if called `isSendToPartitionAllowed`. At first I thought this method was sending to a partition. :)
Maybe we can just a better name for `path` since it makes this code look suspicious.
Although the constructor was pre-existing, I'm thinking we could clean things up a little bit by adding a constructor ```java public TableProcessorNode(final String nodeName, final ProcessorParameters<K, V> processorParameters, final StoreBuilder<KeyValueStore<K, V>> storeBuilder) { this(nodeName, processorParameters, null, storeBuilder); } ``` Then it's more clear in the code when we call ```java final StreamsGraphNode tableNode = new TableProcessorNode<>( name, processorParameters, storeBuilder ); ``` And we can leave the existing constructor using all 4 parameters alone.
I see @mjsax has already a PR for that, great!
I see @mjsax has already a PR for that, great!
If only Java made it possible to declare immutable local variables and method parameters in a more concise way!
Susan, your latest PR doeesn't seem to take the above suggestion into account.
Why not organizing the thread-level sensors as cache-level sensors as well? I.e. `Map<String, Deque<String>> threadLevelSensors = new HashMap<>()` where the string key is just `threadName`, since we will only remove sensors for the whole thread at once.
nit: unneeded newline
nit: add `final`
Why not organizing the thread-level sensors as cache-level sensors as well? I.e. `Map<String, Deque<String>> threadLevelSensors = new HashMap<>()` where the string key is just `threadName`, since we will only remove sensors for the whole thread at once.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
See my question regarding using mocks above.
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
Looks a little odd to use the offset commit interval as the poll timeout when commits have been disabled.
We should log an error that prints out what the two configs actually are
Check TROGDOR.md. > All Trogdor RPCs are idempotent except the shutdown requests. Sending an idempotent RPC twice in a row has the same effect as sending the RPC once. Because the request is idempotent, sending it twice has the same effect, including the same result code.
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
I'm not too worried about it. We might try some "extract variable/method" refactoring when we merge.
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
I'm not too worried about it. We might try some "extract variable/method" refactoring when we merge.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
I see, in that case it's probably fine.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
Yes, that is fine.
Yes, that is fine.
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
Do we need to prefix these with `msg.`? Also, it might be nice to control the message format when message keys and values are to be included. I know that's more code, but it could be made to be similar to the other option.
As above: `Arrays.<Fault>asList(FAULT_D, FAULT_B, FAULT_C, FAULT_A)`
I would disable auto-formatting...
This name seems backwards.
I would disable auto-formatting...
`asList` -> `Collections.singletonList`
I think upon close(), we can also use `maybeAutoCommitOffsetsAsync` and then we can remove the whole function fo `maybeAutoCommitOffsetsSync`.
Since this is usually the entry point where users would call `toString`, the indent is used for wrapping it. For example, `toString()` prints ``` Kafka Streams Thread Tasks Topology States ``` `toString(">")` prints ``` >Kafka Streams > Thread > Tasks > Topology > States ``` We do not need to let users override the internal ones, only the entry point of nested prints.
`Integer.toString` is a slightly more concise way of doing this.
nit: some extra newlines here.
nit: add a size? There are a few cases in here where we could do this.
formatting: no need to curly braces
Not sure what has changed here.
nit: you could just specify one `String` variable at the top of the method and set it accordingly if `topics` is `null` or not then have a single `return` statement. Just a personal preference though.
Rather than doing `if(nodeFactory instanceof blah)` could we add an abstract method `ToplogoyDescription.Node describe(...)` to `NodeFactory` and then implement it in the subclasses. My skin crawls when i see `instanceof` :-)
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
This seems overly complicated. An easier structure to follow would be something like this: ```java String expectedType = "KafkaController"; Set<String> expectedMetricNames = Utils.mkSet( "ActiveControllerCount", "GlobalTopicCount", "GlobalPartitionCount", "OfflinePartitionsCount", "PreferredReplicaImbalanceCount" ); MetricsRegistry registry = new MetricsRegistry(); try (QuorumControllerMetrics quorumControllerMetrics = new QuorumControllerMetrics(registry)) { assertMetricsCreated(registry, expectedMetricNames); } assertMetricsRemoved(registry, expectedMetricNames); ```
What about promotion? We need to actually perform the type promotion. It isn't valid, for example, to use an `int8` field's `Byte` value directly for a `float32` field.
same here. let's make all method params as `final`
We could port this function when it is actually needed.
- you can just do `e.cause.read()` instead of `e.cause.fp.read()`. - extract `message` into a variable as it's going to be used either way.
Can `LogManager.getRootLogger().getLevel()` be `null`? With other loggers you return the effective level if that's the case.
Is this used anywhere? I see we have changed client code to use the other C'tor.
Is there a reason not to include support for casting `DECIMAL` to other primitives? Yes, this might be lossy, but it also would help in cases where there would be no loss of precision.
Fair enough. Let's leave it as-is.
If `useContextSerdes` is false, we should use `Serdes.serdeFrom(keyClass)` and `Serdes.serdeFrom(valueClass)` since the context may not set the serdes.
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
I would use `get_version()` instead.
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
```suggestion if (r.startsWith(rule) || r.equals(defaultRule)) { ```
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
```suggestion - Specifying C(present) is the same as running C(docker-compose up) / C(docker-compose stop) (with I(stopped)) / C(docker-compose restart) ``` `I(...)` is used for Ansible option names, `C(...)` is used for option values and other stuff. (Also applies to many other changes.)
I think it will be `None` and not `{}` if the network does not exist.
// It shouldn't affect the comparison though since loop is present in both Flowable and Observable benchmarks
Shouldn't this be a config exception? It is not really invalid partitions.
nit: add `final`
Typo: space after `uuid,`
Typo: space after `uuid,`
nit: unneeded parenthesis
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
Is the following error code also retriable? 0x15 | KDC_ERR_CLIENT_NOTYET | Client not yet validâtry again later
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
just be wary that this entire loop capturing state is a bit dangerous. of course you don't expect it to happen, but it's possible there is a rebalance (unintentionally due to timeouts) and you get some inconsistent set of results wrt connector state/location. at a bare minimum, tons of repeated tests locally and many repeated tests on jenkins would be warranted here to avoid any potential flakiness, especially given AK jenkins' penchant for unexpected timing issues.
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
We can remove `requireNonNull` here, because `getter.keySerde()` would already throw a `ConfigException` if the default serde is null.
These should be constant values or an enum since they are used in multiple places
Could also use `Collections.singletonList`, which would also make this immutable
Hmm.. I am not sure this is sufficient. Any of the responses could return from the heartbeat thread.
This should go away. `@ConditionalOnClass` already does that.
I think, here it makes sense to wait until all Streams clients are `RUNNING` so that we know that the rebalance is done.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
Cool, yeah that addresses my concern ð
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
It is a shame we have to do it like this, but i don't see a viable alternative
+1 for me on `AutoCloseable`
That's where I'm referring to: `String fieldName = targetField.name();` but I didn't follow too many levels of redirection ...
nit: unnecessary newline
I think the basic idea makes sense and is what I was expecting. It might not feel too elegant, but I think a simple approach is best initially. An interesting point to consider is what would happen if an offset fetch is in-flight while a rebalance is in progress. When it returns, the offsets may be stale. I am wondering if it makes sense to fence the response using the group generation. In other words, we record the generation at the time of the request and then verify when we receive the response that it matches the current group generation.
Nit: please use single parameter per line formatting
nit ```suggestion public EagerBufferConfigImpl(final long maxRecords, final long maxBytes, final Map<String, String> logConfig) { ```
Hmm, why did we do this? I thought we'd have a try/catch block.
You need to close the `Connection`.
You need to close the `Connection`.
You need to close the `Connection`.
OK, will remove before merging.
and -> a
We could use a "for each" loop here, something like: ``` for (Class<? extends Connector> connector : connectorClasses) { connectCluster.configureConnector(connector.getSimpleName(), mm2Config.connectorBaseConfig( new SourceAndTarget(primary, backup), connector)); } ```
That makes sense, I think keeping it as-is is better.
This check `records.size() < offset` seems a bit sketchy to me. Basically we are assuming that the input topic `data`'s starting offset is always 0, and there is no "holes" in the topic partitions so that the `offset` indicates the number of records we can read from the input topic. Maybe a more robust way to do that would be 1) read the input topics `data` and optionally `repartition` based on `withRepartitioning`, stop when the current record's offset is equal to or larger than the committed offset, and remember the number of records; 2) read the output topics (again optionally `repartition`) from the beginning to the end (use `seekTo`), and check that the number of records are the same as the number of records read from the input. Then we do not need to truncate, and also in verification we do not need to check list size again since they are already checked here.
recommended; ditto below.
nit: add `a {@link Named} config`
super nit: taskCreationLock --> taskDirCreationLock
nit: add `final`
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
If only Java made it possible to declare immutable local variables and method parameters in a more concise way!
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
while this is fine, perhaps we should follow the same pattern for getters in these 3 new classes.
We should read the metadata inside the while loop since it could change.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
That's quite fragile IMO. There is no guarantee that `CouchbaseProperties` won't be processed differently in the future.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
That's quite fragile IMO. There is no guarantee that `CouchbaseProperties` won't be processed differently in the future.
Also not clear why "numSegments - 1" here.
Also not clear why "numSegments - 1" here.
Also not clear why "numSegments - 1" here.
@kkonstantine I think the point is to avoid walking nested data structures that would require pointer chasing, so essentially yes it is a cache efficiency thing. If we really wanted to optimize this we would want to make sure everything that can be inlined in the class is checked first, i.e. `optional`, `type`, and `version`, before other simple fields like `name` and `doc`.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
Updated this when merging.
the method name changed to `windowedTable` and `windowSize` parameter is missing
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
as above mentioned, the `listStore.all()` is not closed here.
I don't have all the context, but isn't `3` pretty low? We don't do exponential back-offs, so the recommendation for no data loss is typically higher.
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
rewrite test as above using `assertThrows()`.
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
How about this transport configuration that we se to `NettyConnectionFactory`? @wilkinsona mentioned that on the original issue and we'd like some feedback on that.
Can we use something like `TestUtils.waitUntilTrue`? This approach will make tests unnecessarily slow.
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
```suggestion processed = new AtomicBoolean(true); ```
Use markdown format for links
Some of these lines have extra 4 space. Other lines have extra 8 spaces.
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
I think the original algorithm assumes that when reaching this step, all consumers are at the min capacity. So that it could just do this to set `comsuersToFill`: ```java if (!unassignedStatefulTasks.isEmpty()) consumersToFill.addAll(consumers); ``` But I didn't see the where we change this algorithm. Please let me know where I missed. Thanks.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
It would be nice to have a unit test for this.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
Same question here as earlier about the `Locale`
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
```suggestion NO_LOG_REGEX = re.compile(r'(?:pass(?!ive)|secret|token|key)', re.I) ``` That part wasn't used anymore anyway...
It seems that we compare with this value to check if there is no leader or epoch. It's a bit more robust to check if both `leader` and `epoch` are empty, no? Then it still behaves correctly if we have some code that passes empty to both constructor parameters.
nit. Add `{ }` to block (we always use them). Same below.
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
nit: add `final`
The functionality of process() now is completely covered by transform: users can define a transform function with return type R be "Void" and add a dummy "return null" in the end of the function. And then in KStream we can add public void transform(TransformerSupplier<K, V, Void>) to replace the "process()" call. Having both process() and transform() might be confusing to users, so I would suggest we just remove process() here.
nit: usually we write this like this: ```java this.groupInstanceId = requireNonNull(groupInstanceId, "group.instance.id can't be null"); ```
We can use `new ProducerRecord<>(topic, "value");` to simplify it a tiny bit
We can use `new ProducerRecord<>(topic, "value");` to simplify it a tiny bit
Preferred leader election is an optimization. If we can't move the leader to the preferred one, it seems there is no need to do anything extra.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
I think parameterize this class with `eos-alpha` and `eos-beta` is a better idea --- for some tests that do not rely on the flag and hence would be a duplicated one, we can move it to a separate non-parameterized class.
It's unfortunate for admin we use `source.admin` as the prefix ... So we'd be left with a configuration like: ``` "source.cluster.bootstrap.servers": "localhost:9092", "source.cluster.security.protocol": "SASL_SSL", "source.cluster.producer.some-producer-setting": 123, "source.cluster.consumer.some-consumer-setting": 123, "source.admin.some-admin-setting": 123 ```
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
same here. let's make all method params as `final`
Other enums in Kafka tend to use id for this.
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
It would be nice if the calling code could pass a string with context for what is being read. That way we don't lose information like: ```java if (buf.hasRemaining()) - throw new KafkaException("Failed to read magic byte from FileChannel " + channel); ``` For the case above, we could pass "magic byte" and then the error message would read: "Reached EOF before filling the buffer with magic byte..." or something along those lines.
This change is not needed.
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
Just out of curiosity, how does this differ from the following? ``` assertTrue(streams.close(10, TimeUnit.SECONDS)); ```
I submitted a PR for KAFKA-2711. I think we do need clientPrincipalName, and I hope this is clearer with the changes in that PR: https://github.com/apache/kafka/pull/390
I submitted a PR for KAFKA-2711. I think we do need clientPrincipalName, and I hope this is clearer with the changes in that PR: https://github.com/apache/kafka/pull/390
Technically, this is `numDrainedRecords`.
nit: add `final`
I wonder if we can just get a Map with the default size. I don't expect this code path to be very hot
Just let the Exception flow, that will automatically fail the test
We need to choose at least a live replica.
We need to choose at least a live replica.
Could we rename this to something like "remainingPartitions"
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Ditto on removing before/after
@bbejeck @guozhangwang Oops, looks like I missed this. Bill has a point here. I will probably log a JIRA to get this done.
@bbejeck @guozhangwang Oops, looks like I missed this. Bill has a point here. I will probably log a JIRA to get this done.
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Yeah that is fine. My bad.
same here. let's make all method params as `final`
same here. let's make all method params as `final`
Why is `completed` count being tracked? It doesn't seem to be used anywhere.
same here. let's make all method params as `final`
same here. let's make all method params as `final`
Just let the Exception flow, that will automatically fail the test
Just let the Exception flow, that will automatically fail the test
It might be more robust to use "contains" instead of "startsWith", but I won't insist on it.
I think this'll break up-to-date checking for the jar. Creating a text resource from a string results in the creation of a temporary file with a random name. As that random name varies from build-to-build, the jar tasks will never be considered up-to-date as it'll look like its inputs have changed. We had this problem when adding the classpath index support to `BootJar`. The solution was to get the text resource's file and rename it before adding it to the copy spec rather than as part of the spec.
Thanks. I should have linked to the relevant code earlier. It is the following: https://github.com/spring-projects/spring-boot/blob/16111f126e707fb5064bab6150df7a77f54850ee/spring-boot-project/spring-boot-tools/spring-boot-gradle-plugin/src/main/java/org/springframework/boot/gradle/tasks/bundling/BootJar.java#L113-L119 This will result in a `NOTICE.txt` and `LICENSE.txt` file beneath each project's `build` directory. An alternative could be to access the files in `buildSrc/src/main/resources` directly from the filesystem.
I think this'll break up-to-date checking for the jar. Creating a text resource from a string results in the creation of a temporary file with a random name. As that random name varies from build-to-build, the jar tasks will never be considered up-to-date as it'll look like its inputs have changed. We had this problem when adding the classpath index support to `BootJar`. The solution was to get the text resource's file and rename it before adding it to the copy spec rather than as part of the spec.
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
The `KeyValue` class allows null values for `key` and `value` (at least I didn't see input validations such as throwing IAE in its constructor when either key or value are null). So we must guard against nulls / NPEs here.
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
Doesn't this introduce the possibility of conflict between two plugins (or I guess specifically connectors, since those are the only ones we strip suffixes from) which have different fully-qualified class names, but the same simple class name? Or where they would have the same simple class name, except that one ends with `Connector` and the other doesn't? In practice this is unlikely to come up but if we support it at the moment, probably best to take care here to avoid introducing a potential regression, especially if someone for some reason wants to run, e.g., two different `MySqlSink` connectors on their worker.
I wonder if we can just get a Map with the default size. I don't expect this code path to be very hot
Maybe we can use `setIfExists`.
formatting: no need to curly braces
Please add @return
I think we are guaranteed to have the listener present, but perhaps it's worth checking explicitly and throwing if it is not the case.
I think we are guaranteed to have the listener present, but perhaps it's worth checking explicitly and throwing if it is not the case.
It's not about capacity, is it? It's about having not task that does not have the task assigned (as active or standby). -> `shouldNotAssignStandbyTaskReplicasWhenNoClientAvailableWithoutHavingTheTaskAssigned`
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
This could be `ConfigException` instead. With the `ConnectException` hierarchy we get a little bit stuck because we can't have `ConnectException` be the base of all our exceptions and not redefine some. There are some from core Kafka that are fine if triggered from within the framework, and `ConfigException` falls under that category -- the biggest value aside from standardization that asking for `ConnectException`/`RetriableException` from connectors/tasks is that it is a signal for how to handle the exception, but the runtime code doesn't require that everything inherits from those (and in fact we handle other exceptions from connectors as well, we just would prefer that the connector think about how it wants the framework to handle possible errors).
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
:+1: It looks like the two-arg constructor is unused.
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
empty line needed
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
May be better to use a limited size rather than `Integer.MAX_VALUE`. That would make it easier to test the limit.
Is this constructor used at all? If not, I'd not include it one should generally provide a message explaining more.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
Why not handling the ```InvalidStateStoreException``` in the helper method ```until```
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Did we save a heap to heap copy? I thought we only saved the reallocation of new buffers.
Did we save a heap to heap copy? I thought we only saved the reallocation of new buffers.
Did we save a heap to heap copy? I thought we only saved the reallocation of new buffers.
I don't get this. So a boolean parameter can only be True, False or None. So in this case I would expect this (and other checks) to state: ```python if meraki.params['disable_my_meraki'] is not None: payload['disableMyMerakiCom'] = meraki.params['disable_my_meraki'] ```
It's not a bid deal, but I found the naming here a bit confusing, since the `nonExistingSourceNode` is clearly added to the topology down on line 223, so it definitely exists. But I'm not sure what a better name would be...msybe `removedSourceNode`? Idk
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
```suggestion * is an empty {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
We use to log all leader and isr changes in info even for clean leader election.
nit: 'else' can be dropped
We use to log all leader and isr changes in info even for clean leader election.
Nit: I think we can simply say `Idempotence will be disabled...` (instead of `enable.idempotence` will be disabled...`)
Looks good. I like the additional checking that you're doing here.
I had the same question. It appears better to just duplicate the properties.
Do we need this? It seems that it's easier to just duplicate the property for producer and consumer.
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
nit: seems unnecessary? similar for `State.FAILED` below.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
nit: `child` -> `toChild`
I think we should call `deserializer.close()` here
For standby tasks `init` is no-op, so we can just remove it? PS: logically we should call `resume` not `init` here, but the former is also no-op anyways..
Instead of `new MetricName("batch-size-avg", "producer-metrics", "", tags)`, I think we should use `metrics.metricName("batch-size-avg", "producer-metrics")`, right? The doc says `Please create MetricName by method {@link org.apache.kafka.common.metrics.Metrics#metricName(String, String, String, Map)}`. Same for other MetricName instantiation.
There is a race here. If `run()` gets here and `onNext` is fired, throttling will be disposed and the `onNext` value gets emitted. Here then the cached value gets emitted as well and now there are two tasks delayed for the subsequent interactions.
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
Nit on the spacing so the description of parameters is column-aligned. ```suggestion * @param callable the function to execute. * @param maxRetries maximum number of retries; must be 0 or more * @param retryBackoffMs the number of milliseconds to delay upon receiving a * {@link org.apache.kafka.connect.errors.RetriableException} before retrying again; * must be 0 or more ```
Should we chain the `UnsupportedVersionException` `e` when creating the new `InvalidRequestException`? E.g. ```java throw new InvalidRequestException("Unknown API key " + apiKey, e); ```
The code that gets replaced by this method (in crc32 for ex), the url is downloaded to a dir local to the module source. Here, a new temp dir is created. Afaict, those could have different permissions. If the mkdtemp() result is more open than the __file__/* path, a downloaded file may be readable with different permissions. Haven't tested to see if that is a problem so would like some clarification.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
nit: remove empty line
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
Thinking about it, this may be the root of the problem. We are removing from the head of the ArrayList, one at a time. For each removal, we cause all the elements to be shifted in the underlying array, which is very inefficient if n is not small.
Thinking about it, this may be the root of the problem. We are removing from the head of the ArrayList, one at a time. For each removal, we cause all the elements to be shifted in the underlying array, which is very inefficient if n is not small.
I would say it's important _not_ to be able to create bogus requests. ;) We can introduce specific mechanisms for testing, but a public constructor for a request should do its own validation.
Use `StringBuilder`? Possibly also change the name of the method since it is not a getter.
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Great catch, thanks @showuon !
Nit: why not `failIfNotReadyForSend`? One character longer, but reads a bit better. :)
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
There is a file lock on this file that causes the issue, which might be hiding another issue even on other platforms.
ditto on removing before/after.
We prefer forward merges to back-ports, however, if switching the base branch to 2.7.x is proving tricky, please leave it as main and switch to Spring Retry 1.3.3-SNAPSHOT in your PR. We can then take care of getting the changes based on top of 2.7.x as part of merging the contribution.
nit: if you use `Utils.mkSet`, then you won't need the conversion below.
If the subscription changes, the `onPartitionsRevoked` would be triggered and the owned-partitions in subscription would not include them. The original reasoning is just to make sure all partitions except the ones that are attempted for reassignment-hence-revocation-first are owned by someone. But like we discussed in the other PR, today we are not checking these conditions anyways, e.g.: 1. assignor assign one partition to multiple consumers. 2. assignor assign one partition to no one. They are both bad situations but Coordinator does not check for those today. We discussed about this and think it worth a more general solution as a separate JIRA.
Update return type to `L` (if we introduce `L`)
This overload does not take `Materialized` parameter
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
Thanks for the discussion, all. Coming back to this proposal, and considering the points you've raised, it seems like we should re-use the generated repartition node when the name is generated, and create two repartition nodes when they are named. The purpose of re-using the repartition node in this PR isn't exactly to optimize anything, just to avoid throwing the exception that happens when we currently try to create the exact same repartition node twice. We could instead _always_ create two nodes, but this is needlessly wasteful. Reusing the same-named node makes perfect sense. When the operations are named, on the other hand, there is no problem right now, since we are creating differently named nodes. Since there's no problem, we shouldn't "solve" it ;) It's true that this isn't the most optimal physical plan, but for anyone who cares enough to look into it, they can just add the repartition node first, as you suggested @mjsax; we don't need to throw an exception to force them to fine-tune their program. The other option is that they can enable topology optimization, which will also collapse the named repartition nodes in a well-defined way. Compatibility is a concern, and it seems like it's satisfied if we follow this path: 1. You currently cannot reuse the same stream in two anonymous joins, so we can share the node without breaking any program 2. You currently _can_ reuse the same stream in two _named_ joins, and we will create two (named) repartition topics. We have no choice but to maintain this, or we will break compatibility. 3. Inserting a repartition node is well defined to break compatibility, so people will know they have to reset. 4. Adding Optimization is well defined to break compatibility, so people will know they have to reset. Have I missed some consideration? Thanks, -John
Nit, to improve readability and precision, especially around how many Kafka transactions would be used: > Whether to enable exactly-once support for source connectors in the cluster by using transactions to write source records and their source offsets, and by proactively fencing out old task generations before bringing up new ones.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
nit: add a size? There are a few cases in here where we could do this.
Why was this removed? This is testing reconfiguration without a truststore.
Why was this removed? This is testing reconfiguration without a truststore.
Is there any way to put this into methods on the `ProcessingContext`, like `toString(boolean includeRecord)`? That way, its `toString()` method could really just be `toString(false)`. Not only is it a bit more testable, the logic of this reporter is more readable and focused on writing to the log.
nit: break line
See #1353 for concern about the parameter name "time" (similar parameters in other operators are called "timespan", "timeout", "interval", "period", "intervalDuration", etc.; those parameters that have pretty much the same function should have the same name).
We should read the metadata inside the while loop since it could change.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Are all negative numbers acceptable? If so, the negative numbers which get positive by overflow (like `-1610612735`) encounter error.
Use `js_to_json` and `parse_json`.
Use `js_to_json` and `parse_json`.
Is there a reason not to include support for casting `DECIMAL` to other primitives? Yes, this might be lossy, but it also would help in cases where there would be no loss of precision.
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
strictly speaking, you don't need this yet. Still needed when we evolve I suppose
Meta: this and the existing class still share a lot of common code; I'm wondering if it is possible to just add a flag to the existing class, based on which we can decide whether use Options v.s. DBOptions / CFOptions, and use RocksDBAcccessor.
`>` appears to be a typo
`>` appears to be a typo
I really don't like that we increase indentation here, it make code less readable, and it's complicated even without this :disappointed: We could reduce the number of changes significantly with: ```python if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) clause.add(condition, AND) # When col is nullable, add IS NOT NULL. col = self._gen_cols(reffed_expression) if col: lookup_type = condition.lookup_name target = col.target if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None and self.is_nullable(target): lookup_class = target.get_lookup('isnull') col = self._get_col(target, target, alias) clause.add(lookup_class(col, False), AND) return clause, () ``` and reverting related adjustments.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
the `try{...} finally` has been removed
Good point! @vpapavas , can you handle stuff like this in a follow-on PR? I'm doing a final pass to try and get this one merged.
This cleanup seems a bit awkward. It assumes that tests will initialize the driver but not close it, which seems like a strange abdication of responsibility. I think it would be cleaner and clearer to get rid of the driver field entirely. Tests that need the driver already initialize it; they can declare it as a local variable as well. Then, they clearly need to close it as well. Since `TopologyTestDriver` is `AutoCloseable`, one option is to declare the driver in try-with-resources style: ```java @Test public void myTest() { try (final TopologyTestDriver driver) { // the test code } } ```
This cleanup seems a bit awkward. It assumes that tests will initialize the driver but not close it, which seems like a strange abdication of responsibility. I think it would be cleaner and clearer to get rid of the driver field entirely. Tests that need the driver already initialize it; they can declare it as a local variable as well. Then, they clearly need to close it as well. Since `TopologyTestDriver` is `AutoCloseable`, one option is to declare the driver in try-with-resources style: ```java @Test public void myTest() { try (final TopologyTestDriver driver) { // the test code } } ```
nit: remove blank line
This should go on the previous line after a space.
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
This should return `-1` as old `BadValueTransformer`
Nit: add `final` to both parameters -- please follow a "one parameter per line" formatting.
and -> a
same for the store
nit: unneeded newline
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
Ditto here, can be moved into the StreamsMetrics interface as part of the follow-up JIRA.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
This should return `-1` as old `BadValueTransformer`
As i said above, we should `requireNonNull(mapper, ...)`
Could store `entry.getKey()` in a local variable since it is used several times
The importance of the topic name depends on the serializer being used. For example, if you are using an Avro Serde with the Schema Registry, then the topic might be the subject name. So in this case it is quite important.
As i said above, we should `requireNonNull(mapper, ...)`
Great catch, thanks @showuon !
nit: add a size? There are a few cases in here where we could do this.
nit: revert this change.
We can also get here if handshake has already failed (state == `State.HANDSHAKE_FAILED`) and there are still bytes to be flushed in `netWriteBuffer`.
Nit: somehow I don't like `blah`. Otherwise LGTM
This is definitely a nitpick, but can you put this one fewer lines? 2 lines should be enough for this. Same for the ones below.
@rajinisivaram The login callback handler class isn't getting its #configure(Map<String, ?>, String, List<AppConfigurationEntry>) invoked. Perhaps it might be better to treat the login callback handler class the same way the client and server callback handler classes are treated, which is to create/configure them in SaslChannelBuilder? Note that the login callback handler class is potentially used both on the client side **and** on the server side (it is used on the broker when the mechanism is the inter-broker protocol).
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
`name()` -> `wrapped.name()`
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
Ditto here, can be moved into the StreamsMetrics interface as part of the follow-up JIRA.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
I like to include a trailing comma in cases like this so if more args are later edited it doesn't require editing this line again (keeps git blame cleaner)
The compiler uses `MustacheResourceTemplateLoader` internally and that one is configured to use the configured charset.
This should return `-1` as old `BadValueTransformer`
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
typo: byteArrray -> byteArray
I'm +1 on supporting the timestamps, even if it's not commonly used now, users will often look to tests for example usage (at least I do). I'm also +1 on removing `childIndex` for the same reason, but I don't have too strong an opinion on that.
I'm +1 on supporting the timestamps, even if it's not commonly used now, users will often look to tests for example usage (at least I do). I'm also +1 on removing `childIndex` for the same reason, but I don't have too strong an opinion on that.
This is unused too
nit: I would add a `:` after `set` to stay consistent with the other error messages in this PR.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
It seems like we're duplicating some of the logic contained in `Plugins` into this class by tracking class alias names and pre-computing plugin type based on them. Did you consider a `Herder` method that only accepted the name of the plugin, and took on the responsibility of deducing the plugin type itself? ```java List<ConfigKeyInfo> connectorPluginConfig(String pluginName); ``` In `AbstractHerder`, we could do something like this: ```java @Override public List<ConfigKeyInfo> connectorPluginConfig(String pluginName) { try { Object plugin = Plugins.newPlugin(pluginName); PluginType pluginType = PluginType.from(plugin.class); List<ConfigKeyInfo> results = new ArrayList<>(); ConfigDef configDefs; switch (pluginType) { case SINK: case SOURCE: configDefs = ((Connector) plugin).config(); break; case CONVERTER: configDefs = ((Converter) plugin).config(); break; // ... Rest of switch statement follows same pattern, and rest of the method remains unchanged } ``` And in `Plugins` we could do this: ```java public Object newPlugin(String classOrAlias) throws ClassNotFoundException { Class<? extends Object> klass = pluginClass(delegatingLoader, classOrAlias, Object.class); return newPlugin(klass); } ``` Or alternatively, we could introduce a common interface for plugins that expose a `ConfigDef`: ```java interface DefinedConfigPlugin { ConfigDef config(); } ``` Which could really simplify some of the `AbstractHerder` logic: ```java @Override public List<ConfigKeyInfo> connectorPluginConfig(String pluginName) { try { DefinedConfigPlugin plugin = Plugins.newDefinedConfigPlugin(pluginName); ConfigDef configDefs = plugin.config(); // No switch statement on plugin type necessary // ... Rest of the method remains unchanged } ``` And the change to `Plugins` would be lightweight as well: ```java public DefinedConfigPlugin newDefinedConfigPlugin(String classOrAlias) throws ClassNotFoundException { Class<? extends DefinedConfigPlugin> klass = pluginClass(delegatingLoader, classOrAlias, DefinedConfigPlugin.class); return newPlugin(klass); } ``` Worth noting that if we want to differentiate to users between "this plugin is not on the worker" and "we don't expose config information for this type of plugin", we'd have to make a few further tweaks.
Oh, gotcha--in that case, should we do a check somewhere else, since this will be triggered potentially multiple times for a single plugin? For example, if there are three copies of a connector, the warning will be logged twice right now, with different values for `inner.keySet()` each time. Also, it may also help to log exactly which one we're going to use either instead of or in addition to the complete set of discovered versions of the duplicated plugin.
```suggestion // TODO K9113: this is used from StreamThread only for a hack to collect metrics from the record collectors inside of StreamTasks ``` Just marking this for later follow-up.
add `final` twice
add `final` twice
nit: parameter/line formatting
There's already an expected exception, we can remove the `fail(...)` call here.
There's already an expected exception, we can remove the `fail(...)` call here.
There's already an expected exception, we can remove the `fail(...)` call here.
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
This logic is not exactly the most straightforward. What about something like this? ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { Versioned versioned; if (pluginImpl != null) { versioned = (Versioned) pluginImpl; } else { versioned = (Versioned) pluginKlass.newInstance(); } return versioned.version(); } return "undefined"; ``` or ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { if (pluginImpl == null) { pluginImpl = pluginKlass.newInstance(); } return ((Versioned) pluginImpl).version(); } return "undefined"; ```
Ah, you are right: `valueOf()` `Throws: IllegalArgumentException - if the specified enum type has no constant with the specified name, or the specified class object does not represent an enum type.` Thanks for catching/testing for/fixing it.
