Test failure is because this is missing `geography=True` on PostGIS.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Test failure is because this is missing `geography=True` on PostGIS.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Test failure is because this is missing `geography=True` on PostGIS.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
dashboardId parameter is missing.
Maybe I'm missing sth, but can we use `@contextmanager`? ```python class TestCase(TransactionTestCase): ... @contextmanager def captureOnCommitCallbacks(self, *, using=DEFAULT_DB_ALIAS, execute=False): self.callbacks = [] start_count = len(connections[using].run_on_commit) try: yield self.callbacks finally: run_on_commit = connections[using].run_on_commit[start_count:] self.callbacks[:] = [func for sids, func in run_on_commit] if execute: for callback in self.callbacks: callback() ```
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
"Both Y and X must be provided". Switch the Y and X in the error.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
```not (foo is None)``` => ```foo is not None```
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
I think we can move entire `ordering` logic to a separate branch i.e. ```python if self.ordering: ... sql, sql_params = super().as_sql(compiler, connection, ordering=( 'ORDER BY ' + ', '.join(ordering_expr_sql) )) return sql, sql_params + ordering_params return super().as_sql(compiler, connection, ordering='') ```
Please chop all unnecessary blank lines.
It might be worth compiling the regexp in the class or [module level and reuse](https://github.com/django/django/blob/master/django/contrib/localflavor/ca/forms.py#L16-L17).
@puzan `rabbitmqctl status` doesn't support `vhost`. I run RabbitMQ 3.6.16. As quick fix, I added `add_vhost=True` as default argument to `_exec` to have something like this : ```python def _exec(self, args, run_in_check_mode=False, split_lines=True, add_vhost=True): .... some code here .... if add_vhost: args.insert(1, '-p') args.insert(2, self._vhost) ```
need to catch BotoCoreError here too.
```python mo_file_en.with_suffix('.po').touch() ```
There are some options to `AnsibleModule` which you may be able to use to validate options passed in. Look at existing modules for examples: ``` required_together required_one_of require_if ```
Can be simplified if you do `type='int'`.
```python if state == "disabled": if current_state == "enabled": self._commands.append('interface {0} {1} no traffic-class {2} congestion-control'.format(if_type, if_id, tc)) continue ```
There are some options to `AnsibleModule` which you may be able to use to validate options passed in. Look at existing modules for examples: ``` required_together required_one_of require_if ```
Can be simplified if you do `type='int'`.
```python if state == "disabled": if current_state == "enabled": self._commands.append('interface {0} {1} no traffic-class {2} congestion-control'.format(if_type, if_id, tc)) continue ```
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
There are some options to `AnsibleModule` which you may be able to use to validate options passed in. Look at existing modules for examples: ``` required_together required_one_of require_if ```
Can be simplified if you do `type='int'`.
Add a trailing comma.
It used to be that way (in Python 2 era). Now gettext is an alias to ugettext and the latter will be deprecated in the future.
Use `gettext` instead of `ugettext`
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
argument ordering should be reversed
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
We already test this exact configuration in upgrade test (from 0.9 to 0.10, using both 0.9 producer and consumer, and default timestamp type). I would change timestamp_type of this test to LogAppendTime to make it different.
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
I partly restored `dates_or_datetimes` (removed in e88d2dfcf4daa2b4ee451f518085413bb3b8deeb), it looks simpler IMO.
Would it be better to raise `NotImplementedError()` so backends don't overlook implementing it? They can always return an empty list if it's not supported.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
Read: coding conventions, mandatory fields.
Read: coding conventions, optional fields.
You should be able to use `SimpleTestCase` (which prevents any queries) by setting an `id` manually on your score instance, avoiding the `save()` call and passing a singleton list containing `score` to `serializer.serialize()`: ``` python data = serializer.serialize([Score(id=1, score=3.4)]) ``` With this approach you should be able to hardcode the `"pk": 1` below as well.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
This could be shortened to: ```python if str(retry[1]).startswith('inf'): ```
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Yeah, it's fine.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
you can use `state` to avoid the 'or' to the user
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
not a list of dicts, just pass a dict to the with: ```yaml with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ```
@pilou-, cyberark-bizdev I had a chance to talk to bcoca today and he said the best way to do this is to pass a list of dicts to the lookup. Then either of these playbook constructs can be valid: ``` with_cyberaskpassword: - {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - {'appid': 'Application2', 'query': 'safe=Safe2;Folder=root;Object=User2', 'output': 'password,passprops.username,passprops.address'} with_cyberarkpassword: {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - debug: msg='{{ lookup('cyberark_password', {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'}) }}' ``` Implementing that will take a little restructuring. I'll go into that in the run method below.
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
`copy()` in unnecessary.
`_combine()` is unnecessary since its introduction, I moved it to a separate commit b62c58d5fccaeedc7bc4a064b4678e4ed1e77581.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
`copy()` in unnecessary.
`_combine()` is unnecessary since its introduction, I moved it to a separate commit b62c58d5fccaeedc7bc4a064b4678e4ed1e77581.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
This syntax is not supported in python2.6. You will need to index your format like `{0}`
This syntax is not supported in python2.6. You will need to index your format like {0}
This syntax is not supported in python2.6. You will need to index your format like {0}
I wonder if it's worth pointing to the alternative here. 🤔
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
Right, but the order in which you're doing things would at a glance result in the not-uncommon case of, eg `foo (cr)(lf)` not being properly treated, since the break `sub` wouldn't see that, but the char drop would remove the (cr), leaving a line ending that wouldn't format the right way.
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
```suggestion for key, value in self.parameters.plugin_options.items(): ```
Please don't use lists for tracking differences, but `DifferenceTracker`. That produces a much better output.
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
excellent handling of congestion control
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
I believe it's ```suggestion raise ImportError("We weren't able to import the module {0}".format(module_name)) ```
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
I believe it's ```suggestion raise ImportError("We weren't able to import the module {0}".format(module_name)) ```
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
You added the return statement to the above if the condition which means no need else statement. You should remove it to make it easier to read.
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
That's not true, `return` is to avoid setting new migrations.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
```not (foo is None)``` => ```foo is not None```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Defining `__init__()` to specify a default `output_field` is required until we re-arrange `runtests.py` to avoid importing settings dependant modules before calling `django.setup()`.
We can keep `invert` directly in the `SearchQuery` instead of `extra`, e.g. ```python ... self.invert = invert super().__init__(*expressions, output_field=output_field, function=function) ```
`copy()` in unnecessary.
Defining `__init__()` to specify a default `output_field` is required until we re-arrange `runtests.py` to avoid importing settings dependant modules before calling `django.setup()`.
We can keep `invert` directly in the `SearchQuery` instead of `extra`, e.g. ```python ... self.invert = invert super().__init__(*expressions, output_field=output_field, function=function) ```
`copy()` in unnecessary.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
put closing parenthesis on the next line
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
```not (foo is None)``` => ```foo is not None```
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
We don't need tags in this function, I think.
need to catch BotoCoreError here too.
Add a task ```.yaml - debug: var: result.docker_host_facts ``` And similar tasks after the other examples.
We don't need tags in this function, I think.
need to catch BotoCoreError here too.
Add a task ```.yaml - debug: var: result.docker_host_facts ``` And similar tasks after the other examples.
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
This condition is the problem. It leads to `icinga2 feature list` never beeing executed in `check_mode`, which results in empty `out`. The condition should be removed alltogether. `self._exec` is only invoked twice anyway: first to run `icinga2 feature list` (should be done regardless of `check_mode` or not) and second at a place in code that is never reached in `check_mode` anyway.
`_search_regex`, `_parse_json`. Again: read coding conventions.
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
This condition is the problem. It leads to `icinga2 feature list` never beeing executed in `check_mode`, which results in empty `out`. The condition should be removed alltogether. `self._exec` is only invoked twice anyway: first to run `icinga2 feature list` (should be done regardless of `check_mode` or not) and second at a place in code that is never reached in `check_mode` anyway.
`_search_regex`, `_parse_json`. Again: read coding conventions.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
Make a method to determine constructing dict from which object will be confused
That makes sense, let's keep it in that sense. EDIT: Actually, I'm wondering that if the `monitor` would always grep the same log4j entry in the outside verification or it always try to grep the new lines after the inner verification? If it's the first case, then the outside verification would always be redundant as we are doomed to just grep the same lines.
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
Please use a style like this: ``` python reverse( 'admin:%s_%s_change' % (opts.app_label, opts.model_name), args=(quote(pk_value),), current_app=self.admin_site.name, ) ```
Maybe @felixxm or @carltongibson can guide, but I believe it'd be good practice to use a `warnings.warn` in `__init__`, although a deprecation timeline has not been determined for `django.contrib.postgres.field.JSONField`.
I don't see a need for string interpolation in cases like this.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
for py2/3 and i18n issues we've created a to_text function to use for stringification of errors, avoid str()
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
I don't like this warning. If the force parameter is given, this is expected behavior. So no warning is needed. It just clutters the Ansible output. Logging something that is not shown by default seems enough if needed.
Should the default be https, if so update docs
Use same `env_fallback` as `X_AUTH_TOKEN`
This is unnecessary, AnsibleAWSModule handles it.
This whole connection block can be replaced with `conn = module.client('ssm')`
Ah, i'd expect a bool to always be True/False, if that is not the case (no time to test really right now :)), then indeed, this needs to stay (and this goes for my other bool remarks)
Unessecary blank line
~~~diff - if self.hcloud_volume.size <= size: + if self.hcloud_volume.size < size: if not self.module.check_mode: self.hcloud_volume.resize(size).wait_until_finished() self._mark_as_changed() + elsif self.hcloud_volume.size > size: + self.module.warn("Shrinking of volumes is not supported") ~~~
- extract mandatory information first. - incorrect fallback.
```suggestion - If C(false) (NO CYCLE) is specified, any calls to nextval after the sequence ```
use `_hidden_inputs` method.
comma after tuple
chop "one of" add comma before "or"
put closing parenthesis on the next line
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Could you add at the top of Apply the following line. This will create an ems log event for users with auto support turned on. netapp_utils.ems_log_event("na_ontap_ldap", self.server)
```suggestion # RemovedInDjango50Warning: When the deprecation ends, revert to # FORM_RENDERER="django.forms.renderers.Jinja2", ```
missing space after comma (check code with flake8)
Ah -- I see you want to use a user name for the ESTABLISH DOCKER CONNECTION line later... we can save docker_remote_user for that purpose as well.
Also missing parentheses: > during vm execution (e.g. due to a vm label update),
Lines 58-60 have inconsistent indent.
I would make it a list so user can pass more versions
I think we can move entire `ordering` logic to a separate branch i.e. ```python if self.ordering: ... sql, sql_params = super().as_sql(compiler, connection, ordering=( 'ORDER BY ' + ', '.join(ordering_expr_sql) )) return sql, sql_params + ordering_params return super().as_sql(compiler, connection, ordering='') ```
I don't see a need for string interpolation in cases like this.
please use a variable for this string so that if it changes, we don't have to update it below as well
I think that there is no need to check all empty values, so maybe: ``` # Default should be populated on an empty value. pub_form = PubForm({}) pub_form.mocked_mode = '' pub = mf2.save(commit=False) self.assertEqual(pub.mode, default_mode) ```
This should be: ``params = config_params + params``
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
is not specified.
put `warnings.warn()` outside the if/else so you don't need to repeat it
Is there a need to hardcode pks? This is generally to be avoided, I think.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
I think that there is no need to check all empty values, so maybe: ``` # Default should be populated on an empty value. pub_form = PubForm({}) pub_form.mocked_mode = '' pub = mf2.save(commit=False) self.assertEqual(pub.mode, default_mode) ```
`copy()` in unnecessary.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Raise `AnsibleCallbackError`, which can be imported from `ansible.errors`.
It also looks you you are missing the variable to be inserted for the `%s`.
Function calls are complex. For example: ``` from youtube_dl.jsinterp import JSInterpreter jsi = JSInterpreter(''' function a(x) { return x; } function b(x) { return x; } function c() { return [a, b][0](0); } ''') print(jsi.call_function('c')) ```
We don't need tags in this function, I think.
> They can't be multiline, can they? Yep. According to [ECMA 262 5.1](http://www.ecma-international.org/ecma-262/5.1/), CR (U+000D), LF (U+000A), LS (U+2028) and PS (U+2029) are not allowed in RegExp literals
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Oh I see :)
We don't need tags in this function, I think.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Oh I see :)
We don't need tags in this function, I think.
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Oh I see :)
need to catch BotoCoreError here too.
put closing parenthesis on the next line
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
probably inside the `if` instead of before since it's kind of confusing to see this for a test that isn't going to actually read the DLQ
`copy()` in unnecessary.
`_combine()` is unnecessary since its introduction, I moved it to a separate commit b62c58d5fccaeedc7bc4a064b4678e4ed1e77581.
Sure, a separate PR sounds good.
`copy()` in unnecessary.
Sure, a separate PR sounds good.
you can move it to before `if` as just `docs = {}` line, this should read better.
`copy()` in unnecessary.
you can move it to before `if` as just `docs = {}` line, this should read better.
Sure, a separate PR sounds good.
chop "one of" add comma before "or"
okay, but would be helpful to say _why_ we need to always return True.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
chop "one of" add comma before "or"
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
okay, but would be helpful to say _why_ we need to always return True.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
prefer hanging indent style with 1 arg per line
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
I think this should be false (not a string)
This should be: ``params = config_params + params``
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
prefer hanging indent style with 1 arg per line
`band_input`, you don't get much by saving one char :-)
I think `enumerate` would work here
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
I realize this predates your PR, but why is 'unused' not used? It appears to be the target field provided by the SQLUpdateCompiler during as_sql(). This seems like a really good spot to allow a backend to hook in and CAST the expression to a type that is allowed by the target column.
What do you think about using `argparse.SUPPRESS` instead (as suggested in the previous patch)? e.g. ```suggestion parser.add_argument( '-v', '--verbosity', default=1, type=int, choices=[0, 1, 2, 3], help=argparse.SUPPRESS if 'verbosity' in self.suppressed_arguments else ( 'Verbosity level; 0=minimal output, 1=normal output, ' '2=verbose output, 3=very verbose output' ), ) ``` This way the list of options will not be misleading anymore and at the same time default values will be available for subcommands :thinking: This should increase backward compatibility.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
remove u'' prefix (syntax error on Python 3.2 and unnecessary since this file has `from __future__ import unicode_literals`).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
You want to do it the other way around; no adjustments should be required to the base schema adaptor. In order to achieve that you'll want to have the PostGIS `_create_index_sql` method *not* pass `fields` but `expressions` when necessary ```python def _create_index_sql(self, model, *, fields=None, **kwargs): if fields is None or len(fields) != 1 or not hasattr(fields[0], 'geodetic'): return super()._create_index_sql(model, fields=fields, **kwargs) field = fields[0] template = None if field.geom_type == 'RASTER': # For raster fields, wrap index creation SQL statement with ST_ConvexHull. # Indexes on raster columns are based on the convex hull of the raster. template = self.rast_index_wrapper % '%(expressions)s' elif field.dim > 2 and not field.geography: # Use "nd" ops which are fast on multidimensional cases template = "%%(expressions)s %s" % self.geom_index_ops_nd expressions = None if template is not None: fields = None expressions = [Func(Col(field.column), template=template)] using = ' USING %s' % self.geom_index_type return super()._create_index_sql(model, fields=fields, expressions=expressions, using=using) ```
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
For long query strings, it's better to use ```query``` parameter here.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
For long query strings, it's better to use ```query``` parameter here.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
I prefer putting the closing ) on the next line
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
prefer hanging indent style with 1 arg per line
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
This is usually not needed
For algorithmic code, it can make sense to test private methods and private functions in isolation from the rest of the code. This does seem to be a place where that could be justified. The code being tested is functional (meaning it operates via parameters and return values rather than callbacks) and it plugs into a larger framework which is outside of our control. What I'll sometimes do is push all the permutations of data that I care about at the private function and then push a small subset at the public interface to make sure that the interaction between the public and private code is working as expected.
not Python 3 compatible
Remove print statement: ```suggestion ```
this is a setting 'resolved' not the definition, you are mixing the concepts here.
As per PEP257 you should have a sentence here, hence it should end with a period: ```suggestion """Test that lenient_lowercase() proper results.""" ``` Also, let's rephrase it to contain useful info.
For the author information we normally only keep name and GitHub handle.
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
If changing to `None` from `''` in `.slice_expression()` above, then: ```suggestion if self.end is None: return f'{lhs}[%s:]', params + [self.start] else: return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
IMO it's valuable, because it explains why we can always use `self.start` without an extra check.
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
Remove print statement: ```suggestion ```
not Python 3 compatible
Looking at collections source code I think you mean `collections.Iterator` here.
Match the error message
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
You're checking two separate properties here. This should be in a separate test.
Line is too long.
Too long line.
Too long line.
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
Please ignore, my suggestion is invalid syntax.
note: the 'startswith' _ is still needed for deprecations (but that is handled elsewhere), so we only skipped when it was a symlink (rename deprecating old name, not module itself) so this should 'work'tm as it is now
`George. R. R. Martin` → `George R. R. Martin` (Remove the extra period, and throughout below.)
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
> both `CombinedExpression` and `Lookup` combine a left and a right expression. Not always, many lookups are complicated expressions or even function calls. The only common factor for me is that both have two arguments. Also `CombinedExpression` has a lot of unnecessary logic, e.g. `SQLiteNumericMixin`. We should probably compare `Lookup` subclassing `Expression` vs. `CombinedExpression` :thinking:
With this simplification, the pythonic way of generating a list is to use list comprehension. You can replace the whole function body with: ```python return [parse_to_obj(r) for r in parse_to_logical_rows(vlan_out)] ```
Oh, I see. `run_commands()` runs list of commands and returns list of results.
Needs to be `run_commands(module, ['show vlan brief'])[0]`.
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
You can also drop the parentheses :wink:
I don't think we need the extra assignment here as this is only used once.
We can also go faster by using a list comprehension instead of a generator - they're cheaper to create: ```suggestion obj.combined_queries = tuple([query.clone() for query in self.combined_queries]) ``` Simple benchmark: ``` In [2]: items = [1, 2, 3, 4] In [3]: %timeit tuple(x*2 for x in items) 508 ns ± 10 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [4]: %timeit tuple([x*2 for x in items]) 358 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
`os.chmod` should be before the `try`. It doesn't make a big difference but that's the common pattern in general.
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
Code duplication 80-86, 89-94.
I think names like `float_nan` would be more consistent with our coding style.
I simplified this test with `@mock_inputs()`.
Code duplication 80-86, 89-94.
I think names like `float_nan` would be more consistent with our coding style.
I simplified this test with `@mock_inputs()`.
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
should we ask for a file name? (default to stdout is fine)
> wirte write
no restructured text (:class:) in docstrings please
Please rewrite as ``` if __name__ == '__main__': main() ```
Any problem with: ``` @property def media(self): ```
no restructured text (:class:) in docstrings please
Please rewrite as ``` if __name__ == '__main__': main() ```
Any problem with: ``` @property def media(self): ```
no restructured text (:class:) in docstrings please
Please rewrite as ``` if __name__ == '__main__': main() ```
Any problem with: ``` @property def media(self): ```
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
Any problem with: ``` @property def media(self): ```
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
It'll look more clean if you name these `returncode`, `out`, and `_` (the underscore denotes you're not going to use that, and it's a common pattern in Python). You can also drop the parenthesis, they're not needed
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
It'll look more clean if you name these `returncode`, `out`, and `_` (the underscore denotes you're not going to use that, and it's a common pattern in Python). You can also drop the parenthesis, they're not needed
`client.start_execution` is idempotent but `start_execution` always returns `changed=True` if `action=start`. We probably want to `client.list_executions` to see if the execution is already running before proceeding.
I haven't actually used stepfunctions myself so I'm just going off the docs. AIUI, `ExecutionAlreadyExists` would only be returned on a running execution if the `execution_input` is different, not in a case where the input is the same. As an ansible user who is new to step functions, I feel like if I gave the same input and ran the playbook twice I would expect the 2nd time to be `changed=false` if the first execution is still running. But that doesn't mean that's how AWS users familiar with step functions will expect it.
```suggestion module.exit_json(changed=True,**camel_dict_to_snake_dict(res))) ```
Migrations plans with both forwards and backwards migrations are not supported.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
You can also drop the parentheses :wink:
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
It seems this URL doesn't work anymore.
I think a simple `django.template.Context` will do here.
Use single quotes consistently.
no restructured text (:class:) in docstrings please
Is there a typo? I'm not sure what "hub" means in this sentence.
Any problem with: ``` @property def media(self): ```
no restructured text (:class:) in docstrings please
Is there a typo? I'm not sure what "hub" means in this sentence.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
Any problem with: ``` @property def media(self): ```
I guess some tests might be needed for the router stuff.
Needs to be `run_commands(module, ['show vlan brief'])[0]`.
no restructured text (:class:) in docstrings please
Use single quotes consistently.
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
Use single quotes consistently.
It would have been more appropriate if `run_checks()` took an `Apps` instance as a parameter instead of a list of `AppConfig`s.
DRY 105, 107.
There is a minor behaviour change here. Previously calling `decr()` with `delta=0` would call `self._cache.decr()`, but now it'll call `self._cache.incr()` instead. In theory this shouldn't be a problem, but am highlighting it.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
This conditional is not required anymore given the check above.
Alright, missed that!
We should omit `default_bounds` when the default value is used: ```suggestion if self.default_bounds and self.default_bounds != '[)': kwargs['default_bounds'] = self.default_bounds ```
Chop blank line.
In MySQL introspection we use `table_schema = DATABASE()`, I think we should use it here.
Chop blank line.
`video_id` literal is not a video id.
Doesn't work in python 2.6.
Remove all debug output.
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
IMO `else`is unnecessary i.e. ```python if '.' in opt_val: ... setattr(options, opt_name, os.path.normpath(opt_val)) ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
`enumerate` on for range.
Should contain `quality` key.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
`enumerate` on for range.
Should contain `quality` key.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
You could use RenameMethodsBase.
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
We can also go faster by using a list comprehension instead of a generator - they're cheaper to create: ```suggestion obj.combined_queries = tuple([query.clone() for query in self.combined_queries]) ``` Simple benchmark: ``` In [2]: items = [1, 2, 3, 4] In [3]: %timeit tuple(x*2 for x in items) 508 ns ± 10 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [4]: %timeit tuple([x*2 for x in items]) 358 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
You could use RenameMethodsBase.
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
We can also go faster by using a list comprehension instead of a generator - they're cheaper to create: ```suggestion obj.combined_queries = tuple([query.clone() for query in self.combined_queries]) ``` Simple benchmark: ``` In [2]: items = [1, 2, 3, 4] In [3]: %timeit tuple(x*2 for x in items) 508 ns ± 10 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [4]: %timeit tuple([x*2 for x in items]) 358 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
Need spaces around `+` sign.
immediatelly -> immediately
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
- i don't think that `type="hidden"` is important. - checking for ext is not needed here.
You can also add a deprecation warning for usages like `from django.forms.extras.widgets import SelectDateWidget`.
```suggestion ) ```
There seems to be an assumed structure of what is returned by the API endpoint, operating under the pretense that the structure won't change since the API is versioned, is there any chance that this assignment could fail and cause an unhandled exception? (similar question for other functions doing similar things below)
@sdodsley sounds good, thank you for the clarification
```suggestion raise Exception ```
How about this - ```suggestion msg = "No corresponding incident" if len(incidents) == 0: if state in ('acknowledged', 'resolved'): return msg, False return msg, True elif state != incidents[0]["status"]: return incidents[0], True return incidents[0], False ```
Duration calculation is incorrect.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
I would remove all aliases if possible.
You should provide an example. Also, I would expect this to be of type `dict`, not `str`.
(In general, I don't think modules should have such options.)
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Code duplication 80-86, 89-94.
Whether it has changed or not does not mean there should be a format with invalid URL.
There are multiple formats, some may have `file` some may not. If some new hq format is introduced with different rendition your approach will break downloading by default while proper URL handling will not. Finally read coding conventions.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
I don't see any need for this attribute.
I think [`_extract_m3u8_formats`](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/common.py#L847) does the work better. If the existing method does not fit the need, feel free to modify it.
`field_preference` must be a list or a tuple.
Code duplication 80-86, 89-94.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
with -> width
point -> points
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
with -> width
point -> points
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
with -> width
point -> points
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
with -> width
point -> points
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
with -> width
point -> points
For long query strings, it's better to use ```query``` parameter here.
```not (foo is None)``` => ```foo is not None```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
Should also update based on `block_size` and `parallelism`
Test failure is because this is missing `geography=True` on PostGIS.
``` # Transform minus sign prefixed strings into an OrderBy() expression. ordering = [ (OrderBy(F(o[1:]), descending=True) if isinstance(o, str) and o[0] == '-' else o) for o in ordering ] ```
Use `super()` since Python 2 is no longer supported. Single line looks okay.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
argument ordering should be reversed
We don't need to test multiple cases because we want to ignore only locales with hyphens.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
Is anything `required_together`, if not please remove this line
Oh I see :)
I think this should be `if tags and tags != igw.tags:`. Otherwise if we're creating a gateway with no tags this condition will be met and it will crash later since there are no tags. On second thought, just make the default of tags be an empty dict instead of None, [here](https://github.com/ansible/ansible/pull/23782/files#diff-7c7439a69b0a017fb8e03a769c5ef29bR179) and it will fix the problem.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
argument ordering should be reversed
We don't need to test multiple cases because we want to ignore only locales with hyphens.
`gluster_peer_ops` is unconditionally called and this method always calls `get_nodes`. `get_nodes` fails when `nodes` parameter isn't set: this parameter must be mandatory (and non empty). For that, you could use a custom method, meaning something like that: ``` class AnsibleModuleCheckListNotEmpty(AnsibleModule): def _check_type_list_not_empty(self, value): value = self._check_type_list(value) # default checks for a list if not value: raise ValueError("list must not be empty") return value [...] module = AnsibleModuleCheckListNotEmpty( argument_spec=dict( force=dict(type='bool', required=False), nodes=dict(type=self._check_type_list_not_empty, required=True), [...] ``` Once implemented you could remove the `get_nodes` method.
http://docs.ansible.com/ansible/latest/dev_guide/developing_modules_general.html#new-module-development There is written: ``` # during the execution of the module, if there is an exception or a # conditional state that effectively causes a failure, run # AnsibleModule.fail_json() to pass in the message and the result if module.params['name'] == 'fail me': module.fail_json(msg='You requested this to fail', **result) ``` AFAIK module should return with `module.exit_json` or `module.fail_json`, not `raise ValueError` for example.
Also you may get here(or on many other places) an exception, and you don't catch any. AFAIK Ansible modules should return always with `module.exit_json` or `module.fail_json` rather then raising `Exception`.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
```suggestion query=dict(type='list', elements='str'), ```
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
If you're only going to get `APSCOOKIE_` _or_ `ccsrftoken`, then you can just return `None` if you don't find anything and the existing token will be reused. If you are expecting to have both, then I would just dedent the next line to be outside the for loop, so that the token is always added to the dictionary on every run. Then you should be able to at least remove the manual headers building in `send_request`.
Above, you wrote that `ov_eligible` is returned when `success and I(domain_status) is C(APPROVED), C(RE_VERIFICATION) or C(EXPIRING).`. But here, you only return it if it has value `True`.
with -> width
width, height, and offset
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
```suggestion # just get value from attribute itself as normal ```
I would prefer to avoid the try/except block. Because it can potentially hide a problem and it reduces the readability. This being said, it was already here, so it's up to you.
prefer if you use hanging indent style for this assertion to match the other tests
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
`band_input`, you don't get much by saving one char :-)
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
`_search_regex`, `_parse_json`. Again: read coding conventions.
Mandatory. Read coding conventions.
Please use a single quote.
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
```suggestion description: Can be used to request certificates from ECS, with C(provider=entrust). ```
```suggestion - There is a small delay (typically about 5 seconds, but can be as long as 30 seconds) before obtaining the random values when requesting a validation. ```
This is always a tough question, and I'm not sure what's the best solution :) In Ansible, things are usually lower-case. I guess you have to decide what you want in the end :)
How about lower-case? ```suggestion choices: [ 'dns', 'email', 'manual', 'webserver'] ```
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
do we really need that `is not None` check? `check_token` should return `False` for None tokens.
immediatelly -> immediately
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
Migrations plans with both forwards and backwards migrations are not supported.
Is `plan` meant as the second argument? Looks like we're missing a test for this branch.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
```suggestion poly = Polygon(((0, 0), (0, 1), (1, 1), (1, 0), (0, 0))) ```
I would use kwargs ```suggestion check=models.Q(geom__within=poly), ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
this module is marked as "legacy" and therefore the CI is not complaining about pep8 here, but it would help if we try to be pep8 compliant.
yep, that is what I meant, basically make sure new code is pep8 compliant
Minor but I'd move this control flow block after the `weights` one to match the args order.
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
Having an overridable method seems like the most orthodox OOP solution (it's what a Java programmer would do :-) ) but I'm not convinced it really gives a useful abstraction: by coincidence it's the right place to make this one change, but I'm not sure there's a useful class of future modifications it opens up, so it feels like overkill to me. My thought with an instance variable was just to set it in the constructor in the base class, and overwrite it in the subclass constructor (not exposing it as a kwarg). I'm not sure there's any advantage to this; I think I was thinking about this because it's what I'd do in C++. I don't have a particularly strong feeling on this. I think if I were writing it I'd go with the class-level attribute.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
If you use `to_text(xxx, errors='surrogate_or_strict')` it won't throw exceptions.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
It'd be good to include a default sleep here so this loop doesn't continuously hit the oVirt endpoint. Even just a one or two second sleep would be fine between tries.
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
Just in case it's probably a good idea to use `.get()` instead of dict access syntax in case the key is unset.
Can we also add the ability to traverse a list of dicts? ``` def generate_final_config(self, cfg_dict): """ Generate final config dictionary :param cfg_dict: A dictionary parsed in the facts system :rtype: A dictionary :returns: A dictionary by eliminating keys that have null values """ final_cfg = {} if not cfg_dict: return final_cfg for key, val in iteritems(cfg_dict): dct = None if isinstance(val, dict): child_val = self.generate_final_config(val) if child_val: dct = {key: child_val} elif (isinstance(val, list) and val and all([isinstance(x, dict) for x in val])): child_val = [self.generate_final_config(x) for x in val] if child_val: dct = {key: child_val} elif val not in [None, [], {}, (), '']: dct = {key: val} if dct: final_cfg.update(dct) return final_cfg ``` something like this ^^^
Minor but I'd move this control flow block after the `weights` one to match the args order.
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
> scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum You missed the parentheses.
As the Python `urlencode()` already handles scalars, I think this could be slightly simplified to: ```py if isinstance(value, (list, tuple)): query_val = [ item if isinstance(item, bytes) else str(item) for item in value ] else: query_val = value ```
Nitpick: Append a \ to the end so it doesn't generate an empty first line.
You are completely right. What about this? Too ugly?: ``` js_catalog_template = \ r"""{% autoescape off %} ... ```
Then use `enumerate()` instead.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
My only concern with this in general is if `run_command()` fails or raises an exception, the file may not get deleted, leaving the `sudo` password in clear text on disk. Use `module.add_cleanup_file()` to add the tempfile to the list of files that will be cleaned up up in the event of failure.
bcoca's patch has been merged so we can use `play_context.executable` instead of C.DEFAULT_EXECUTABLE. And the default value should be built in so no need for the final `else /bin/sh`
Doesn't isatty bomb on none? It does for me...
"Mixin for combining with a lookup"
Instead of defining `success`, just return directly in the above code. I think it is simple enough.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Do note that this only looks at the primary credential cache. This means that if you use a collection credential cache such as DIR, KEYRING or KCM (default in most distributions these days), you might not see a ticket that exists in a non-primary credential cache. Maybe consider using `klist -A`, or try a `kswitch -p <principal>`? The latter is easier to parse, but might break stuff if people are still using the old krb5 APIs (rather than GSSAPI) and were using the primary credential that you just made secondary.
Similarly, I don't see much advantage to creating indirection with a method.
A bit DRYer? ``` python value = self.rhs if isinstance(value, datetime.datetime): output_field = models.DateTimeField() elif isinstance(value, datetime.date): output_field = models.DateField() else: output_field = None if output_field: value = models.Value(value, output_field=output_field) self.rhs = value.resolve_expression(compiler.query) ```
```suggestion pkg_version = line.partition(':')[-1].strip() ```
A bit DRYer? ``` python value = self.rhs if isinstance(value, datetime.datetime): output_field = models.DateTimeField() elif isinstance(value, datetime.date): output_field = models.DateField() else: output_field = None if output_field: value = models.Value(value, output_field=output_field) self.rhs = value.resolve_expression(compiler.query) ```
```suggestion pkg_version = line.partition(':')[-1].strip() ```
Is there a way to format the stdout? When applying it gets hard to read: ``` "sdtout": "aws_instance.example: Creating...\n ami: \"\" => \"ami-ff4ea59d\"\n associate_public_ip_address: \"\" => \"<computed>\"\n availability_zone: \"\" => \"<computed>\"\n ebs_block_device.#: \"\" => \"<computed>\"\n ephemeral_block_device.#: \"\" => \"<computed>\"\n instance_state: \"\" => \"<computed>\"\n instance_type: \"\" => \"t2.micro\"\n ipv6_address_count: \"\" => \"<computed>\"\n ipv6_addresses.#: \"\" => \"<computed>\"\n key_name: \"\" => \"<computed>\"\n network_interface.#: \"\" => \"<computed>\"\n network_interface_id: \"\" => \"<computed>\"\n placement_group: \"\" => \"<computed>\"\n primary_network_interface_id: \"\" => \"<computed>\"\n private_dns: \"\" => \"<computed>\"\n private_ip: \"\" => \"<computed>\"\n public_dns: \"\" => \"<computed>\"\n public_ip: \"\" => \"<computed>\"\n root_block_device.#: \"\" => \"<computed>\"\n security_groups.#: \"\" => \"<computed>\"\n source_dest_check: \"\" => \"true\"\n subnet_id: \"\" => \"<computed>\"\n tenancy: \"\" => \"<computed>\"\n volume_tags.%: \"\" => \"<computed>\"\n vpc_security_group_ids.#: \"\" => \"<computed>\"\naws_instance.example: Still creating... (10s elapsed)\naws_instance.example: Still creating... (20s elapsed)\naws_instance.example: Still creating... (30s elapsed)\naws_instance.example: Creation complete after 34s (ID: i-04362e7210c113e2c)\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n" ```
I'd put the trailing `}` in a new line.
I think you can use `django.utils.deconstruct` to decorate the class, the `path` argument can be passed explicitly. Since Django 2.0+ is Python 3 only, you can use keyword-only arguments with `*, arg1=None, arg2=None`.
I think normally we don't `raise NotImplemented` but just return `False` so ```py return ( isinstance(other, CheckConstraint) and self.name == other.name and self.constraint == other.constraint ) ```
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
Thanks for the patch @Giebisch, I think we should adjust the `expected_outputs` instead to be properly formatted in order to ensure formatting is actually used. https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L90-L111 https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L124-L133 The adjustments made make the tests pass with and without the proposed changes.
I'm thinking these parameters shouldn't be filled in, since we're popping `stack_description` so if a user wanted a hard-fail for nonexistent stacks, they could do: ``` - cloudformation_facts: stack_name: not-real failed_when: not cloudformation['not-real'] ```
`field_preference` must be a list or a tuple.
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
Code duplication 80-86, 89-94.
It would be clearer to the end-user if the help was "Shows output from passing tests."
These 2 lines could be replaced by: ```python uploader_url, uploader_id = uploader_data[0][0:2] ```
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Please ignore, my suggestion is invalid syntax.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
I think you might want to rollback at this point.
Please ignore, my suggestion is invalid syntax.
Is this needed? You were the author and if you used code from win_psmodule the copyright is enough.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
I realize this predates your PR, but why is 'unused' not used? It appears to be the target field provided by the SQLUpdateCompiler during as_sql(). This seems like a really good spot to allow a backend to hook in and CAST the expression to a type that is allowed by the target column.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Similarly, ```if tc['skip'].get('i')```
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
I think this could be increased to 10 just in case the system is really slow. The important thing is that it doesn't loop forever.
Single quotes please.
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
I think this could be increased to 10 just in case the system is really slow. The important thing is that it doesn't loop forever.
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
Would it be enough to check `form.fields`? This might make the test a bit easier to follow instead of having to parse the HTML to see what's expected..
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
This seems overly simplistic, we should at least be sure to the extend that we should check the signature of the function on whether or not it supports more than two arguments.
Any case where the method raises a `TypeError` which is not caused by the missing argument
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
Generally, I'd have put the static regex directly as the first argument of `re.search()`.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
hmmm.. now I think I'm wrong, you want to only have the first partial func.. `func.func` shouldn't anyway be another partial or else that would be problematic I think, as views have to return something else.. Sorry for disturbance ;)
```suggestion assert isinstance(wrap_var(b'foo'), type(b'')) ```
```suggestion assert isinstance(wrap_var(dict(foo='bar')), dict) ```
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Please rewrite as ``` if __name__ == '__main__': main() ```
Missing `=dict` on this and the next few lines
Missing `=dict` on this and the next few lines
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Please ignore, my suggestion is invalid syntax.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Please rewrite as ``` if __name__ == '__main__': main() ```
Missing `=dict` on this and the next few lines
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
Missing `=dict` on this and the next few lines
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Please rewrite as ``` if __name__ == '__main__': main() ```
`load_config` doesn't return anything https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ios.py#L121
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Please rewrite as ``` if __name__ == '__main__': main() ```
`load_config` doesn't return anything https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ios.py#L121
Please use triple double quotes around docstrings. ([PEP 257](https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring))
The leading underscore in the '_meta' key is missing here.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Remove this since it doesn't do anything and `Mock` isn't defined.
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
This is not changed.
This is not fixed.
This is not changed.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
This is not changed.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
This is not changed.
This is not fixed.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
I would chop blank lines in this test.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
Chop `Ensure that`.
I would chop blank lines in this test.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
Chop `Ensure that`.
> I think this isn't a great trade-off to make, the special branch for "is the length exactlyt the same" will cost more than it saves across a range of different input string types. Only a few will match it. Yeah, I wondered whether the exact length check might be detrimental. > Regardless this is a rarely used DB function, this is too much time spent optimizing it already :) 😄 Yup. Happy with your solution.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Hah. Had the same thought before I got here. See the caveats mentioned above.
Please remove this blank line as requested by Paolo.
I would change this to a `NotSupportedError`, e.g. ```python raise NotSupportedError( 'Bulk create a multi-table inherited model is not supported ' 'on this database backend.' ) ```
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
(And round-tripping of the messages is already tested in other tests)
I don't see any need for this attribute.
As with the old `_batched_insert` code, I think we should pass the db alias here `self._insert(objs_without_pk, fields, using=self.db)`, it defaults to that but passing it seems more explicit.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
single line as above
Unindent by 1 space. Indention must be a multiple of 4 spaces.
I would suggest to also warn a bit about so users won't "forget" they are using the sandbox url ~~~python self.module.warn(warning="Sandbox is enabled. All actions are made against the URL %s" % self.baseurl) ~~~
Revert unrelated change.
See my previous review for indentation style of this. Perhaps the common qs stuff before the last filter can be moved to setUpTestData.
I have to admit that I turned several module-level functions into engine methods without giving it much thought. Feel free to move engine methods in other classes as needed.
I'm reluctant to pass a `Template` to the `Engine` because that creates a circular relation between the two classes. If you keep this design, you must at least rename `compile_string`, because it no longer accepts a string in argument. In fact I would add a new method and deprecate `compile_string`.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
You'll want to branch off `< 3.6`.
`always_text` is gone.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
What if the prepared value contains unicode? (As I said before, you should use a list comprehension instead of a generator, it'll be about 2 times faster here)
Avoid using `IntegrityError` here. It is a `ValueError` to not provide `update_fields` with `update_conflicts`. ```suggestion if ignore_conflicts and update_conflicts: raise ValueError('The ignore_conflicts and update_conflicts flags are mutually exclusive.') if ignore_conflicts: self._check_on_conflicts_supported(OnConflict.IGNORE, unique_fields) return OnConflict.IGNORE if update_conflicts: self._check_on_conflicts_supported(OnConflict.UPDATE, unique_fields) if not update_fields: raise ValueError('The update_conflicts flag requires update_fields to be specified.') for name in update_fields: if name == 'pk': name = self.model._meta.pk.name try: self.model._meta.get_field(name) except exceptions.FieldDoesNotExist: raise ValueError(f'The update_fields list contains an unknown field: {name}.') return OnConflict.UPDATE return None ```
Please add a trailing comma: ```suggestion update_conflicts=False, update_fields=None, unique_fields=None, ```
It seems like no_log and deprecation are separate things and should be handled in separate functions.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
- try to use `refreshTokenUrl` and fallback to static URL. - break long lines when possible. - `data` should not be a dict. - extract `token` directly.
when subfield(`user`) is used multiple times, extract the value into a variable and reuse it.
surround only the part that will threw the exception.
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
I think it should be a KafkaException (or a subclass of it). IllegalStateException in this class refers to an invalid configuration that is more compile time than runtime, whereas a partitioning problem is purely runtime and only occurs with custom partitioners.
I think you might want to rollback at this point.
A message string would good to say that image is not preset or something similar.
If you use a catchall exception handler like this then you should also provide the traceback like this: ``` python import traceback from ansible.module_utils._text import to_native [...] module.fail_json(msg='Unanticipated error running atomic: %s' % to_native(e), exception=traceback.format_exc()) ```
while purging all username we should preserve the username which is used to run the playbook otherwise we might hit connection timeout in middle and leave the box with partial configurations
Please wrap at 79 chars.
Ah. lambda is prettier though :). maybe we can run pep8 with ignore lambda error.
I would use `choices` in `labels` and `values` to simplify implementation, e.g. ```python @property def labels(cls): return [label for _, label in cls.choices] @property def values(cls): return [value for value, _ in cls.choices] ```
I don't see any need for this attribute.
You have some unmerged lines here
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
you can use `state` to avoid the 'or' to the user
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
So we have to probably use try-except blocks for all the stuff that could fail. Nowadays with python3 you'd be doing something like: ```python from ansible.module_utils.pycompat24 import get_exception .... try: <whatever action that could fail> except: e = get_exception() module.fail_json(msg=str(e))
I am a bit scared by this. Because the module indicates it supports check-mode, but if I look at the code it seems to be doing all the stuff and only at the end appear to say there hasn't been a change. That cannot be right (it's dangerous!).
The mixup to me is that people using incorrect units will silently be using bytes, whereas it should report this as an error.
This means that if you'd be using 16m, it will be 16 bytes too. You will have to do a lot more to avoid mixups here.
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
The mixup to me is that people using incorrect units will silently be using bytes, whereas it should report this as an error.
This means that if you'd be using 16m, it will be 16 bytes too. You will have to do a lot more to avoid mixups here.
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
These should be handled in the arg_spec using `aliases`.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
This logic seems ignore the use case of removing all tags.
Does this need to be a separate method? Seems unnecessary to me.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
Do we need to define `async_generator` in `__aiter__`? ```python async def _async_generator(self): # Generators don't actually start running until the first time you call # next() on them, so we make the generator object in the async thread # and then repeatedly dispatch to it in a sync thread. sync_generator = self.__iter__() # So, you can't raise StopIteration up through sync_to_async as # too much of the Python async system was originally built on # generators. Instead, we capture it inside a custom sync function # and change it to an exception we *can* propagate. # We should probably move this logic inside asgiref at some point. def custom_next(gen): try: return next(gen) except StopIteration: raise StopAsyncIteration() while True: try: yield await sync_to_async(custom_next)(sync_generator) except StopAsyncIteration: return # Note: __aiter__ is a *synchronous* method that has to then return an # *asynchronous* iterator/generator. Thus, we nest an async generator # inside it. # Also note: This is a generic iterable converter for now, and is going to # suffer a performance penalty on large sets of items due to the cost of # crossing over the sync barrier each time. We should write custom ones # for each Iterable subclass, but we'll need some work in Compiler first. def __aiter__(self): return self._async_generator() ```
You could use lambda to save some lines defining the function
Since the same result is expected as above, wouldn't it be clearer to save the output in a variable? Something like: ``` expected = ( "[ ] author_app.0001_initial\n" "[ ] book_app.0001_initial\n" "[ ] author_app.0002_alter_id\n" "[ ] mutate_state_b.0001_initial\n" "[ ] mutate_state_b.0002_add_field\n" ) ```
Yes and no. Keeping the output explicit feels easier to read.
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Add here that the `key_alias` or `key_arn` are both ways to provide it.
colors should all be configurable
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Add here that the `key_alias` or `key_arn` are both ways to provide it.
colors should all be configurable
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Add here that the `key_alias` or `key_arn` are both ways to provide it.
colors should all be configurable
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Add here that the `key_alias` or `key_arn` are both ways to provide it.
colors should all be configurable
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
Any problem with: ``` @property def media(self): ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
As noted in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style, we're not so strict about it in code.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Any problem with: ``` @property def media(self): ```
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
I would actually assume most of the users will not be using ID but name. Don't think it matters that much though.
IIRC get_cols() was renamed to get_group_by_cols() some time ago - no need to have both.
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
```suggestion print('hijacked sys.path to use ansible-vendored files, bwahaha', file=sys.stderr) ``` (because this log entry is added after the fact)
```suggestion print('hijacking sys.path to use ansible-vendored files, bwahaha ð£ð£ð£') ```
Read: coding conventions, mandatory fields.
What the hell are you doing? `urljoin(url, '/api/v1/videos/%s' % video_id)`. All.
1. `_sort_formats`. 2. Must not break if any of these keys is missing.
yeah I think it would be worthwhile to at least test a single JOIN scenario.
Same style as above.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
yeah I think it would be worthwhile to at least test a single JOIN scenario.
Same style as above.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
like diff = load_config(self._module, config_xml, [])
`id` isn't used, it is sufficient to iterate on keys.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Please ignore, my suggestion is invalid syntax.
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
1. `_sort_formats`. 2. Must not break if any of these keys is missing.
This is not fixed.
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I don't think extending `Subquery.__init__` to allow any `QuerySet` some method (e.g. `filter`, `order_by`, ...) is desirable.
Test failure is because this is missing `geography=True` on PostGIS.
`del` is a builtin, not a function. These parens don't have to be here
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
This can instead be `continue` and let the `else` unnest.
`del` is a builtin, not a function. These parens don't have to be here
Can you move the global declarations to one place? Easy for the future maintainer.
Can you move this function above main() as per ansible guildelines: " Ansible follows C-style code flow where the caller functions/methods are towards the bottom of the file and the callee implementations are above them. "
If you use a catchall exception handler like this then you should also provide the traceback like this: ``` python import traceback from ansible.module_utils._text import to_native [...] module.fail_json(msg='Unanticipated error running atomic: %s' % to_native(e), exception=traceback.format_exc()) ```
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Test failure is because this is missing `geography=True` on PostGIS.
I don't think extending `Subquery.__init__` to allow any `QuerySet` some method (e.g. `filter`, `order_by`, ...) is desirable.
`output_field` is not necessary.
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
like diff = load_config(self._module, config_xml, [])
this is a catchall, we normally frown on those. also note that for all of your `% e` they should be `% to_native(e)` to ensure proper character conversions
I think [`_extract_m3u8_formats`](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/common.py#L847) does the work better. If the existing method does not fit the need, feel free to modify it.
So we have to probably use try-except blocks for all the stuff that could fail. Nowadays with python3 you'd be doing something like: ```python from ansible.module_utils.pycompat24 import get_exception .... try: <whatever action that could fail> except: e = get_exception() module.fail_json(msg=str(e))
How about: ``` if storage_engine == 'InnoDB': return self.connection.mysql_version >= ( (10, 2, 2) if self.connection.mysql_is_mariadb else (5, 7, 5) ) return storage_engine in ('MyISAM', 'Aria') ```
This should be paginated
Can we emit a warning/info instead of silently failing
Test failure is because this is missing `geography=True` on PostGIS.
This can use set comprehension ```suggestion reverse_fields = { ```
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Use built-in method? Also, should it crash (raise) if `json.loads()` fails, or just return an empty dict again? ```suggestion try: return self._download_json( url, song_id, data=data.encode('ascii'), headers=headers) except ExtractorError as e: if type(e.cause) in (ValueError, TypeError): # JSON load failure raise except Exception: pass return {} ```
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
This is not fixed.
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
Should also update based on `block_size` and `parallelism`
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Ah. lambda is prettier though :). maybe we can run pep8 with ignore lambda error.
This seems like it would break galaxy which needed expand_paths
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Ah. lambda is prettier though :). maybe we can run pep8 with ignore lambda error.
This seems like it would break galaxy which needed expand_paths
Should be ``self.weight``
Please don't make lines longer! There was nothing really wrong with this line before
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
There's a few things that I'd change about this function. But I think the toplevel concern is that it's doing too much. It doesn't need to take req. It should just decide whether we're using the pycrypto or cryptography backend, format and return that one dependency. The calling code can then substitute the value.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
As discussed on IRC: no.
```suggestion Test that the returned value for timezone consists of only uppercase ```
Use single quotes consistently.
I think `name.rsplit('-', 1)[-1]` is easier to read.
```suggestion Test that the returned value for timezone consists of only uppercase ```
I think `name.rsplit('-', 1)[-1]` is easier to read.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I prefer putting the closing ) on the next line
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Please ignore, my suggestion is invalid syntax.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
flake8 complains about missing spaces around `*`
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
I think [`_extract_m3u8_formats`](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/common.py#L847) does the work better. If the existing method does not fit the need, feel free to modify it.
Is there specific value in doing this for all variants here? In particular, does the security protocol variation get us something that existing tests don't? Another way of asking this is, beyond the failures we would catch with existing tests where brokers generally fail to communicate with each other when using specific security protocols, is there a way we think reassignment specifically would fail that would be related to the security protocol? E.g. is there a different inter-broker connection that's being made that otherwise wouldn't be made? I ask because I think we already test a lot of stuff with variations of security protocols and I'm a bit worried about test bloat due to parametrizing tests being relatively easy (and leading to much longer test runs).
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
This check can be also moved to `module_utils`.
Is anything `required_together`, if not please remove this line
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
I don't see a need for string interpolation in cases like this.
```suggestion module.fail_json(msg="The following packages are absent in the currently booted rpm-ostree commit: %s" % ' '.join(pkgs)) ```
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
The hexdigest will always be a fixed length so this only happens if the provided suffix is too long, correct? In that case, I think it would be better to raise an error that the provided suffix is too long.
I don't see a need for string interpolation in cases like this.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
I don't see a need for string interpolation in cases like this.
```suggestion type: list suboptions: ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Is there precisely one time you can specify this? It sounds to me like this should be allowed to repeat multiple times. So this should be a `list`. Or maybe even better a `dict`, so people can specify things like ``` blkio_weight_device: /dev/sda: 100 /dev/sdb: 200 ```
Please don't make lines longer! There was nothing really wrong with this line before
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
```suggestion raise AnsibleParserError("the field '%s' should be a list, but is a %s" % (value, type(value))) ```
[`get_param`](https://github.com/spotify/pyfg/blob/master/pyFG/forticonfig.py#L249) should not raise an exception. I guess you could check if `f.running_config[path]` contains `module.params['name']Ì`.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
Is there precisely one time you can specify this? It sounds to me like this should be allowed to repeat multiple times. So this should be a `list`. Or maybe even better a `dict`, so people can specify things like ``` blkio_weight_device: /dev/sda: 100 /dev/sdb: 200 ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Hmm, doesn't seem like this is correct. >version ['1', '0', '0-SNAPSHOT'] major_minor ['1', '0'] Extracting ['tar', 'xf', '/Users/ijuma/src/kafka/core/build/distributions/kafka_2.11-1.0.0-SNAPSHOT-site-docs.tgz', '--strip-components', '1'] Traceback (most recent call last): File "./release.py", line 235, in <module> command_stage_docs() File "./release.py", line 227, in command_stage_docs cmd('Extracting ', 'tar xf %s --strip-components 1' % docs_tar, cwd=os.path.join(kafka_site_repo_path, docs_version(version))) File "./release.py", line 108, in cmd output = subprocess.check_output(cmd, *args, stderr=subprocess.STDOUT, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 566, in check_output process = Popen(stdout=PIPE, *popenargs, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 710, in __init__ errread, errwrite) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 1335, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory: '/Users/ijuma/src/kafka/../kafka-site/10'
Also, it seems like our convention for docs versions is quite bad. If we didn't want to use `.`, we could use something else like `_`.
Minor but I'd move this control flow block after the `weights` one to match the args order.
There is no point to use `remove_start` since line is always a string.
>besides the test is there to make sure that breakage in this part of code will be detected That's a doubtful argument considering broken core tests at the beginning of this PR. The length of this string is const until one decides to refactor here something. Using 10 is a variation of code duplication since the length is already implicitly defined in the string literal itself. Also using 10 indicates no relation to the string literal so that one unfamiliar with code who decides to refactor it may forgot to change the number and may be unaware of the tests at all.
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Is there a typo? I'm not sure what "hub" means in this sentence.
no restructured text (:class:) in docstrings please
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
happy new year ! yeah effectively finally this is required for python < 3.5 as you explain (I just tested it in an interactive session). I'm happy to open a PR with this specific change so.. should not be too long to come..
hmmm.. now I think I'm wrong, you want to only have the first partial func.. `func.func` shouldn't anyway be another partial or else that would be problematic I think, as views have to return something else.. Sorry for disturbance ;)
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
happy new year ! yeah effectively finally this is required for python < 3.5 as you explain (I just tested it in an interactive session). I'm happy to open a PR with this specific change so.. should not be too long to come..
hmmm.. now I think I'm wrong, you want to only have the first partial func.. `func.func` shouldn't anyway be another partial or else that would be problematic I think, as views have to return something else.. Sorry for disturbance ;)
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
happy new year ! yeah effectively finally this is required for python < 3.5 as you explain (I just tested it in an interactive session). I'm happy to open a PR with this specific change so.. should not be too long to come..
hmmm.. now I think I'm wrong, you want to only have the first partial func.. `func.func` shouldn't anyway be another partial or else that would be problematic I think, as views have to return something else.. Sorry for disturbance ;)
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
like diff = load_config(self._module, config_xml, [])
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
check here for the regex fix https://github.com/Qalthos/ansible/pull/5/commits/89f2a106db4f7296822e118ad24f66cea84f3be9#diff-e72efaa6b72beb5339ad847e21a31220L87 Good catch on the first_port / last_port ... will add a fix for those. This is a common pattern to be used by eos modules. I have held off on pushing the modules upstream until we get the initial push of the refactored network shared modules
```suggestion vault_data(), ```
```suggestion assert ansible_json_encoder.default(test_input) == {'__ansible_vault': expected} ```
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
This one is a bit newer to CliBase, but also implemented verbatim in superclass
disconnect() is likewise handled in CliBase, and should be entirely unnecessary here.
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
This one is a bit newer to CliBase, but also implemented verbatim in superclass
disconnect() is likewise handled in CliBase, and should be entirely unnecessary here.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
like diff = load_config(self._module, config_xml, [])
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
This one is a bit newer to CliBase, but also implemented verbatim in superclass
disconnect() is likewise handled in CliBase, and should be entirely unnecessary here.
```suggestion assert ansible_json_encoder.default(test_input) == {'__ansible_vault': expected} ```
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
```suggestion assert ansible_json_encoder.default(test_input) == {'__ansible_vault': expected} ```
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This one is a bit newer to CliBase, but also implemented verbatim in superclass
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
like diff = load_config(self._module, config_xml, [])
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
self._connected is set by CliBase.connect(), shouldn't need to specify it here
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
This one is a bit newer to CliBase, but also implemented verbatim in superclass
disconnect() is likewise handled in CliBase, and should be entirely unnecessary here.
IIRC get_cols() was renamed to get_group_by_cols() some time ago - no need to have both.
No need to split the line.
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
No need to split the line.
Various modules allow to specify the name of the executable in order to use a binary from a non-standard location (i.e. a binary not located in the PATH). Look at e.g. the isoextract on how to do this.
Also here, I don't know why you are splitting lines. It does not make it easier to read. Usually it is done out of necessity (e.g. PEP8 rules require it), but in this case there is no need to make this weird.
Any problem with: ``` @property def media(self): ```
No need to split the line.
Various modules allow to specify the name of the executable in order to use a binary from a non-standard location (i.e. a binary not located in the PATH). Look at e.g. the isoextract on how to do this.
No need to split the line.
Various modules allow to specify the name of the executable in order to use a binary from a non-standard location (i.e. a binary not located in the PATH). Look at e.g. the isoextract on how to do this.
Also here, I don't know why you are splitting lines. It does not make it easier to read. Usually it is done out of necessity (e.g. PEP8 rules require it), but in this case there is no need to make this weird.
If changing to `None` from `''` in `.slice_expression()` above, then: ```suggestion if self.end is None: return f'{lhs}[%s:]', params + [self.start] else: return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
You don't need the inner list comprehension: `tuple(i for i in x)` works just fine.
Thanks for the patch @Giebisch, I think we should adjust the `expected_outputs` instead to be properly formatted in order to ensure formatting is actually used. https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L90-L111 https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L124-L133 The adjustments made make the tests pass with and without the proposed changes.
Also probably put that in the examples, for if users want that behavior but maybe don't know about `failed_when`.
I'm thinking these parameters shouldn't be filled in, since we're popping `stack_description` so if a user wanted a hard-fail for nonexistent stacks, they could do: ``` - cloudformation_facts: stack_name: not-real failed_when: not cloudformation['not-real'] ```
This is a "set" method called from redfish_config (which doesn't pass in the systems_uri param). So need to remove that param here and just use self.system_uris[0] below.
```suggestion assert expected == "exception" ```
```suggestion assert expected == "exception" ```
We confirmed that `parallelism` should be taken into account.
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
Matching empty string is senseless.
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
I think so, btw please do `resolver.kwargs.copy()` to leave the original kwargs in place on the resolver object.
do we really need that `is not None` check? `check_token` should return `False` for None tokens.
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
to be -> are
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
put the closing parenthesis on the next line
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
Remove `self.function = 'CONCAT_WS'` and the following line which mutates `self.template` and instead: ``` return super(ConcatPair, self).as_sql( compiler, connection, function='CONCAT_WS', template="%(function)s('', %(expression)s)" ```
Turn (capitalize) add period. sql -> SQL
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
`# Filter out fields contributed....` (chop comma before as)
Dict literals are preferred (0d74c41981687598d3fa0a7eb9712ce4c387ca19).
This should be handled by the fields themselves, what you've written here is what a special cased `JSONFieldGinIndex.create_sql` implementation would look like.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
We can reuse existing objects.
CI failure due to trailing whitespace (PEP 8 check): ``` 2017-02-08 14:44:54 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2_win_password.py:167:10: W291 trailing whitespace (legacy) ```
Again: ```suggestion ['{0}={1}'.format(k, v if v is not None else 'undefined') ```
Making this change here doesn't work because we aren't guaranteed to have passlib installed. The crypt.crypt() method will require that we have a salt set. You could move salt generation into the conditional for ```not HAS_PASSLIB```.
to be -> are
It depends, but it can be public. You can solve metaclass conflicts manually creating class inhertiting from all of your metaclasses, or automatically by using this function (`metaclassmaker` or `six_with_metaclassmaker`), that would do exactly the same new metaclass for you.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
to be -> are
It depends, but it can be public. You can solve metaclass conflicts manually creating class inhertiting from all of your metaclasses, or automatically by using this function (`metaclassmaker` or `six_with_metaclassmaker`), that would do exactly the same new metaclass for you.
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
Turn (capitalize) add period. sql -> SQL
to be -> are
Turn (capitalize) add period. sql -> SQL
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
`# Filter out fields contributed....` (chop comma before as)
put the closing parenthesis on the next line
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
Remove `self.function = 'CONCAT_WS'` and the following line which mutates `self.template` and instead: ``` return super(ConcatPair, self).as_sql( compiler, connection, function='CONCAT_WS', template="%(function)s('', %(expression)s)" ```
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
bcoca also mentioned that the facts end up being set on the host that's being processed in the task loop, not one that's being delegated_to. So we should only return the ansible_pkg_mgr fact if we are not delegating.
When delegating, I'd think that we'd need to run the facts module for the delegated host rather than for the inventory_hostname host....
I don't see a need for string interpolation in cases like this.
Still need to add the ansible_pkg-mgr fact to results if: * We selected one of yum, yum4, or dnf * And we are not delegating.
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
I don't see a need for string interpolation in cases like this.
Still need to add the ansible_pkg-mgr fact to results if: * We selected one of yum, yum4, or dnf * And we are not delegating.
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
Make a method to determine constructing dict from which object will be confused
Fail here make the process exit, but we need to create it if the state is present
It's more readable to write this out into multiple if-then statements.
```suggestion updates.extend(line for line in set_commands if line not in config) ```
There's no need to wrap the strings like this. Our project lint settings accept up to 160 characters wide. ```suggestion result['warnings'].append('Some configuration commands were unmanaged, review unmanaged list') if result.get('invalid'): result['warnings'].append('Some configuration commands were invalid, review invalid list') ```
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
Minor but the `else` clause wrapping is unnecessary here given you return in the `except`.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
```not (foo is None)``` => ```foo is not None```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
```not (foo is None)``` => ```foo is not None```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
```not (foo is None)``` => ```foo is not None```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
```not (foo is None)``` => ```foo is not None```
For long query strings, it's better to use ```query``` parameter here.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
```not (foo is None)``` => ```foo is not None```
@chrisvanheuveln and I chatted about this. No further changes needed here since we avoid the 400 error with the order change and the command is blocking.
a simpler fix i was already working on: `+ display.display(json.dumps(text, cls=AnsibleJSONEncoder, sort_keys=True, indent=4))`
well, not die with unexpected exception .. tempted to say there is no real reason the type should be incorrect for any keys. So ending in an error should be fine, just not an unhandled one.
Please change this to `2.7`.
@chrisvanheuveln and I chatted about this. No further changes needed here since we avoid the 400 error with the order change and the command is blocking.
I think this option is deprecated - https://www.vmware.com/support/developer/converter-sdk/conv51_apireference/vim.vm.RelocateSpec.Transformation.html
Oh, so these modules have existed for a while, we are just upstreaming them now, that makes sense.
This is only ever called once. Do we need the default? (Same with SQL version)
This is only used once. Can we move it back to the `color` module? (That way `termcolors` is still only ever used by `color`)
Simplify this by not adding required=False, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
On all your parameters, if there are not required, there is no need to specify the `required=False`. But if they are, you should speficy `required=True`
width, height, and offset
This regex does not make any sense.
no need for `.keys()`. `if property_id in vapp_properties_current:` is the same as `if property_id in vapp_properties_current.keys():`
I think a list comprehension would be more readable.
Should also include `block_size` and `parallelism`
```suggestion Test that the returned value for timezone consists of only uppercase ```
Should also update based on `block_size` and `parallelism`
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
Should also include `block_size` and `parallelism`
Should also update based on `block_size` and `parallelism`
This doesn't allow the caller to cancel downtime by scope. _get_downtime returns an empty dictionary when id is not specified. It'd be great if this was changed to require id or scope instead of just id.
Please ignore, my suggestion is invalid syntax.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
This looks like a good change, however, for consistency with the rest of the code, I think we should use `self._play_context.ssh_executable` until we decide to switch the connection plugin in full over to using `get_option`.
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
Same style as above.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
The final command should probably return its stdout, stderr and rc back to the playbook.
There is a much easier way to do this, by using the index in the list. Something like: ```python unit = size[-1] units = list('b', 'k', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y') try: multiplier = 1024**units.index(unit) except ValueError:: e = get_exception() module.fail_json(msg="No valid size unit specified. %s" % e) ```
I don't think this is working correctly, did you test it for all possible inputs ? - First of all the size_unit is only correct if it is a known unit. - And if that's not true, and it's not a digit, you have to escalate. - If it is a digit, you likely won't have a unit and then you could assume bytes.
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
Should also include `block_size` and `parallelism`
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
Same style as above.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
Same style as above.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
Same style as above.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
Replace all `f''` expressions: * where possible as below * for an expression where the braced expressions aren't just local variables, replace each `{expr}` by `{n}` with n starting at 0 and incrementing, and append `.format(expr0, expr1, ...)` to the string literal, or rewrite using `%` formatting * if the braced expressions are all local variables, you can just add `.format(locals())` (possibly distasteful) * for format literals used to add or change URL query parameters, consider using `update_url_query()` instead. ```suggestion msg = 'Panopto said: ' + response.get('ErrorMessage') ```
`_search_regex`, `_parse_json`. Again: read coding conventions.
It would be better to mention that in the release notes. :-)
Just use: ``` datetime.utcfromtimestamp(ts).replace(tzinfo=timezone.utc) ``` This will be more efficient. You don't need `make_aware` here because UTC doesn't have DST. Sure, this is a micro-optimization, but I like avoiding overhead at the lower levels ;-)
```suggestion vault_data(), ```
It would be better to mention that in the release notes. :-)
Just use: ``` datetime.utcfromtimestamp(ts).replace(tzinfo=timezone.utc) ``` This will be more efficient. You don't need `make_aware` here because UTC doesn't have DST. Sure, this is a micro-optimization, but I like avoiding overhead at the lower levels ;-)
```suggestion vault_data(), ```
shouldn't this line and the one below just not be here, and the loop be `for arg, version in self.DEFAULT_DEPRECATED_ARGS` (though those aren't really a default either, so `DEFAULT` is a bit of a misnomer)
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
I'd chop the intermediate variable
like diff = load_config(self._module, config_xml, [])
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
User of this inventory plugin should be able to use `v6_main_ip` for value of `ansible_host` (i don't know if it makes sens to be able to use `internal_ip`) or no `ansible_host` at all (meaning that `server['label']` will be used instead).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
okay, but would be helpful to say _why_ we need to always return True.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
This can be single-lined: ```suggestion return (matched_tags or not tags) and not test_tags.intersection(exclude_tags) ```
I would chop `does_`: ```suggestion if test_match_tags(test, tags, exclude_tags) ```
is the `any` required here - `if metrics_to_disable:` should suffice, I'd think
Minor but I'd move this control flow block after the `weights` one to match the args order.
Please use [standard exception handling guidelines](https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-2)
I don't think we should be promoting using this feature of scripting. If someone wants this level of control over scores, they should implement their own Similarity; that is its purpose.
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
`# Filter out fields contributed....` (chop comma before as)
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
Yes, from what I can see this doesn't work now. My `state: absent` is ignored when target is used by target group. Where is `else`? :)
may be blind, but think this will never get fired if v is empty. you create an empty list, which will be skipped in the for loop.
For some reason this causes ``` {aliases: [attr]} {choices: [all, 'no', none, safe, urllib2, 'yes']} {default: [200]} ``` while non-sequence values for `default` yield ``` default: 30 ``` without the `{...}`.
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
Ah, that does work. :-)
It'll look more clean if you name these `returncode`, `out`, and `_` (the underscore denotes you're not going to use that, and it's a common pattern in Python). You can also drop the parenthesis, they're not needed
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
Maybe simplify with: ``` decoded_url.translate(None, '"\',').decode('utf-8') ``` Or in case there could be spaces in `['"cod", "ed ", "URL"]`: ``` re.sub(r'[\s"\',]', '', decoded_url).decode('utf-8') ```
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
the same for `streaming` key.
`items = value.split(self.delimiter) if value else []` is slightly faster.
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
~~Maybe a list comprehension here too.~~
Maybe simplify with: ``` decoded_url.translate(None, '"\',').decode('utf-8') ``` Or in case there could be spaces in `['"cod", "ed ", "URL"]`: ``` re.sub(r'[\s"\',]', '', decoded_url).decode('utf-8') ```
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
`items = value.split(self.delimiter) if value else []` is slightly faster.
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
~~Maybe a list comprehension here too.~~
set default `step_size=None` instead of `"any"` and only render that attribute if it's `not None`.
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
`items = value.split(self.delimiter) if value else []` is slightly faster.
Here however, you shouldn't use a list comprehension as it makes you call `regex.match` two times instead of one. Plus a dict iterates on keys by default, so you don't need to write `.keys()`.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
IMO this should not raise a warning.
No need to parametrize with just one case.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
As discussed on IRC: no.
Minor but I'd move this control flow block after the `weights` one to match the args order.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
If we're just testing broker compatibility I don't think we even need this part of the test.
We tend to sort the imports alphabetically. It's a common thing in python.
This is also why shippable is failing.
```suggestion EPOCH_TS = 1594449296.124356 ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
I don't think we should be promoting using this feature of scripting. If someone wants this level of control over scores, they should implement their own Similarity; that is its purpose.
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion for table_name, table_rows in rows: ```
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
A general remark: you should always use complete sentences. So this should end with a period.
(In general, I don't think modules should have such options.)
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
`# Filter out fields contributed....` (chop comma before as)
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
We don't need to support different bases or other negation signs so I would expect a simplified implementation.
```suggestion return '-' + value if neg else value ```
Same. The `filter` doesn't make sense to me
Trailing commas: ```suggestion MAX_NUM_FORM_COUNT: self.max_num, }, renderer=self.renderer, ```
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
We confirmed that `parallelism` should be taken into account.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
> this test is checking the support for a possible object that is seekable but has no `.tell()`. > `tempfile.NamedTemporaryFile()` has `.tell()`. Just as an aside, whether there is any change here or not, but you could do: ```python with tempfile.NamedTemporaryFile() as tmp: del tmp.tell # Emulate seekable file handle without .tell(). ... ```
identical here for pod,
`not_data_actions` + tests (same as above)
This error is raised when instantiating so we don't need to include a `route` in the message.
I would revert this change. We want to add a system check so this seems redundant.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
This must be checked **before** any processing.
This must be checked **before** any processing.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
should probably use `if stdout is not None:`
This doesn't support aurora snapshots. Besides that, this looks great.
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` Here this var needs to stay as you had it originally - ansible prefers snake cased but boto typically needs camelcase. `instance_parameters` will be passed into the boto connection so needs to match what the API expects, both here and later when you access the returned parameters. https://docs.aws.amazon.com/dms/latest/APIReference/API_CreateReplicationSubnetGroup.html#API_CreateReplicationSubnetGroup_RequestSyntax
2.6 or 2.7? Also you `requirements` listed here and the modules.
What kind of values are valid here? I would expect this to be `float` based on the `0.0` in the description.
A general remark: you should always use complete sentences. So this should end with a period.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
`del` is a builtin, not a function. These parens don't have to be here
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I don't think extending `Subquery.__init__` to allow any `QuerySet` some method (e.g. `filter`, `order_by`, ...) is desirable.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Why we don't use `super().deconstruct()`? ```python def deconstruct(self): path, args, kwargs = super().deconstruct() kwargs['expressions'] = self.expressions if self.condition is not None: kwargs['condition'] = self.condition if self.index_type != 'GIST': kwargs['index_type'] = self.index_type return path, args, kwargs ```
It will be `django.contrib.postgres.constraints.XXX` but I don't think that's an issue for core constraints we return `django.db.models.XXX`.
Using `str('name=Hello%20G%C3%BCnter')` would also work here but using `six.PY2` could be a nice reminder to remove the `b'...'` branch.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Could you keep `'MANIFEST.json'` in a var? I was hoping to extract https://github.com/ansible/ansible/blob/4a82e2c/lib/ansible/galaxy/dependency_resolution/dataclasses.py#L44 into a publicly exposed constant at some point...
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
please fail if required stuff is null
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
please fail if required stuff is null
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
Again, error handling changed.
`Could not recursively set attri...`
Please convert this to just a list comprehension: ```suggestion groups = [e.name for e in entities if isinstance(e, Group)] ``` Additionally, just convert to a list of names here, since you only ever need that, and not the object later.
needs a space before the quote here too
The log message makes no sense. You are trying to normalize (or rather kludge) something that should be a locale to be a language code/tag, to then convert to a locale. But you are saying the locale has been normalized to a language code/tag which is incorrect. A language code/tag is not a locale, and here we *should be providing a locale*, hence my misgivings already stated about this whole thing. Regardless, you probably want to do this: ```python def normalize_locale(original, stdout): """ Normalizes incorrect locale strings, e.g. zh-cn, zh_cn, ZH-CN are converted to zh_CN. """ corrected = to_locale(original.lower().replace('_', '-')) if original != corrected: stdout.write('Normalized %s to %s.' % (original, corrected)) return corrected ```
Oh yes, there definitely was some confusion. When looking at the code, I saw references to `obj.pk` and thought we were potentially dealing with a QuerySet (which I guess that _technically_ we _could_ be, but that wouldn't be the right way to use it). My apologies! Carry on. 😋
Read also https://www.ianlewis.org/en/mixins-and-python
The code I've reviewed recently always has mixins on the left. I think it's easier to be consistent than have to think about it, but feel free to propose some different guidelines if you like.
Referring specifically to the kubeconfig definition, the remote file path will cover a lot of use cases but I was wondering if it would be useful to be able to specify it inline as well, which would open the door for keeping your authentication with your ansible playbooks/roles.
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Hah. Had the same thought before I got here. See the caveats mentioned above.
What's the purpose of http://example.com/v.flv here? It always gives a 404 error and I think it's unrelated to iQiyi
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
Thanks :+1: , IMO a separate ticket is not necessary, we can `Refs #33348 -- ...`.
Can we deprecate passing `None` in `errors` in a separate PR? and do this in advance. There is already a lot of changes in this patch, that should make it more readable and easier to review. I can try to refactor this out if you don't have time to keep working on this.
no restructured text (:class:) in docstrings please
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
This could be a bare `super()`.
a single file or a list ...
``` return files.getlist(name) if self.multiple else files.get(name) ```
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
```python total_ordering_fields = {'pk'} | { field.attname for field in self.lookup_opts.fields if field.unique and not field.null } ```
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
@jrwdunham I think you can drop this if, yes
@jrwdunham I'm not an expert here, but from what I read the true assumption is that `SCRIPT_NAME` **never** ends with trailing slash. So in case you do not have subfolder, `SCRIPT_NAME` should be just empty/unset.
Does this check make sense now that we only handle it if it starts with a relative path? (ie if the prefix where there it would start with a slash anyways)
@jrwdunham I think you can drop this if, yes
@jrwdunham I'm not an expert here, but from what I read the true assumption is that `SCRIPT_NAME` **never** ends with trailing slash. So in case you do not have subfolder, `SCRIPT_NAME` should be just empty/unset.
Does this check make sense now that we only handle it if it starts with a relative path? (ie if the prefix where there it would start with a slash anyways)
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
It'll look more clean if you name these `returncode`, `out`, and `_` (the underscore denotes you're not going to use that, and it's a common pattern in Python). You can also drop the parenthesis, they're not needed
Thanks :+1: , IMO a separate ticket is not necessary, we can `Refs #33348 -- ...`.
Can we deprecate passing `None` in `errors` in a separate PR? and do this in advance. There is already a lot of changes in this patch, that should make it more readable and easier to review. I can try to refactor this out if you don't have time to keep working on this.
no restructured text (:class:) in docstrings please
you might want to get the module/action as the include can be given a name that does not match `include:`
with -> width
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
flake8 complains about missing spaces around `*`
2.6 or 2.7? Also you `requirements` listed here and the modules.
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
pass original exception as orig_exc so traceback can be shown with -vvv
2.6 or 2.7? Also you `requirements` listed here and the modules.
Since it's the only plugin which does that, I would remove it. Either all plugins should do that, or none.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
comma after tuple
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
comma after tuple
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
comma after tuple
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
with -> width
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
It's not actually a comprehension - this could just use a tuple literal.
@Ian-Foote thanks for the clarification I always mix up the two terms.
`if it encounter` => `if it encounters`
It's not actually a comprehension - this could just use a tuple literal.
@Ian-Foote thanks for the clarification I always mix up the two terms.
`if it encounter` => `if it encounters`
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
chop newline for consistency with other tests
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
For clarity here, shouldn't we use `Func` rather than `Transform`, since they are equivalent and the latter is a back-compat-only name? It seems like using `Transform` might suggest to someone reading this code that there's something distinct about `Transform` as opposed to `Func`.
IIRC get_cols() was renamed to get_group_by_cols() some time ago - no need to have both.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
We could keep tests more DRY and use loop (maybe with `subTest`) e.g. ```python def test_formsets_with_order_custom_widget(self): class OrderingAttributFormSet(BaseFormSet): ordering_widget = HiddenInput class OrderingMethodFormSet(BaseFormSet): def get_ordering_widget(self): return HiddenInput for formset in (OrderingAttributFormSet, OrderingMethodFormSet): ArticleFormSet = formset_factory(ArticleForm, formset=formset, can_order=True) ... ```
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
Please ignore, my suggestion is invalid syntax.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
The `bool` type handles more cases than just `yes`. To assign the public_ip variable here to be true/false when provided or None by default, all you should need is to set the default to `None` as below, then assign the variable using: ``` module.params.get('assign_public_ip') ```
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
perhaps "if not region"? that keeps the standard flow from being in an "else", lets us bring the indenting back a level, etc. Otherwise this is fantastic. Thanks for pep8 and removing the stray code.
it means the same thing, it's just the flow.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion pkg_version = line.partition(':')[-1].strip() ```
Is it possible ? For me it would mean that it exist a package without version.
It doesn't work if pkg_provides contain a version: ``` max@mde-oxalide % pacman -Qqei perl | grep Provide Provides : perl-archive-tar=2.30 perl-attribute-handlers=1.01 perl-autodie=2.29 perl-autoloader=5.74 perl-autouse=1.11 perl-b-debug=1.26 perl-base=2.27 perl-bignum=0.49 perl-carp=1.50 perl-compress-raw-bzip2=2.074 perl-compress-raw-zlib=2.076 perl-config-perl-v=0.29 perl-constant=1.33 perl-cpan-meta-requirements=2.140 perl-cpan-meta-yaml=0.018 perl-cpan-meta=2.150010 perl-cpan=2.20 perl-data-dumper=2.170 perl-db_file=1.840 perl-devel-ppport=3.40 perl-devel-selfstubber=1.06 perl-digest-md5=2.55 perl-digest-sha=6.01 perl-digest=1.17_01 perl-dumpvalue=1.18 perl-encode=2.97 perl-encoding-warnings=0.13 perl-env=1.04 perl-experimental=0.019 perl-exporter=5.73 perl-extutils-cbuilder=0.280230 perl-extutils-constant=0.25 perl-extutils-install=2.14 perl-extutils-makemaker=7.34 perl-extutils-manifest=1.70 perl-extutils-parsexs=3.39 perl-file-fetch=0.56 perl-file-path=2.15 perl-file-temp=0.2304 perl-filter-simple=0.95 perl-filter-util-call=1.58 perl-getopt-long=2.5 perl-http-tiny=0.070 perl-i18n-collate=1.02 perl-i18n-langtags=0.43 perl-if=0.0608 perl-io-compress=2.074 perl-io-socket-ip=0.39 perl-io-zlib=1.10 perl-io=1.39 perl-ipc-cmd=1.00 perl-ipc-sysv=2.07 perl-json-pp=2.97001 perl-lib=0.64 perl-libnet=3.11 perl-locale-codes=3.56 perl-locale-maketext-simple=0.21_01 perl-locale-maketext=1.29 perl-math-bigint-fastcalc=0.5006 perl-math-bigint=1.999811 perl-math-bigrat=0.2613 perl-math-complex=1.5901 perl-memoize=1.03_01 perl-mime-base64=3.15 perl-module-corelist=5.20180622 perl-module-load-conditional=0.68 perl-module-load=0.32 perl-module-loaded=0.08 perl-module-metadata=1.000033 perl-net-ping=2.62 perl-params-check=0.38 perl-parent=0.236 perl-pathtools=3.74 perl-perl-ostype=1.010 perl-perlfaq=5.021011 perl-perlio-via-quotedprint=0.08 perl-pod-checker=1.73 perl-pod-escapes=1.07 perl-pod-parser=1.63 perl-pod-perldoc=3.2801 perl-pod-simple=3.35 perl-pod-usage=1.69 perl-podlators=5.006 perl-safe=2.40 perl-scalar-list-utils=1.50 perl-search-dict=1.07 perl-selfloader=1.25 perl-socket=2.027 perl-storable=3.08 perl-sys-syslog=0.35 perl-term-ansicolor=4.06 perl-term-cap=1.17 perl-term-complete=1.403 perl-term-readline=1.17 perl-test-harness=3.42 perl-test-simple=1.302133 perl-test=1.31 perl-text-abbrev=1.02 perl-text-balanced=2.03 perl-text-parsewords=3.30 perl-text-tabs=2013.0523 perl-thread-queue=3.12 perl-thread-semaphore=2.13 perl-threads-shared=1.58 perl-threads=2.22 perl-tie-file=1.02 perl-tie-refhash=1.39 perl-time-hires=1.9759 perl-time-local=1.25 perl-time-piece=1.3204 perl-unicode-collate=1.25 perl-unicode-normalize=1.26 perl-version=0.9923 perl-xsloader=0.30 ```
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
What if `default` is not a constant but a field reference? e.g. `F('integer')`
You can use [`env_fallback`](https://github.com/ansible/ansible/blob/8f41270a010c00d058c70bdccdc611df8b454139/lib/ansible/module_utils/basic.py#L726)
2.6 or 2.7? Also you `requirements` listed here and the modules.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
No need to quote.
```suggestion pkg_version = line.partition(':')[-1].strip() ```
Is it possible ? For me it would mean that it exist a package without version.
It doesn't work if pkg_provides contain a version: ``` max@mde-oxalide % pacman -Qqei perl | grep Provide Provides : perl-archive-tar=2.30 perl-attribute-handlers=1.01 perl-autodie=2.29 perl-autoloader=5.74 perl-autouse=1.11 perl-b-debug=1.26 perl-base=2.27 perl-bignum=0.49 perl-carp=1.50 perl-compress-raw-bzip2=2.074 perl-compress-raw-zlib=2.076 perl-config-perl-v=0.29 perl-constant=1.33 perl-cpan-meta-requirements=2.140 perl-cpan-meta-yaml=0.018 perl-cpan-meta=2.150010 perl-cpan=2.20 perl-data-dumper=2.170 perl-db_file=1.840 perl-devel-ppport=3.40 perl-devel-selfstubber=1.06 perl-digest-md5=2.55 perl-digest-sha=6.01 perl-digest=1.17_01 perl-dumpvalue=1.18 perl-encode=2.97 perl-encoding-warnings=0.13 perl-env=1.04 perl-experimental=0.019 perl-exporter=5.73 perl-extutils-cbuilder=0.280230 perl-extutils-constant=0.25 perl-extutils-install=2.14 perl-extutils-makemaker=7.34 perl-extutils-manifest=1.70 perl-extutils-parsexs=3.39 perl-file-fetch=0.56 perl-file-path=2.15 perl-file-temp=0.2304 perl-filter-simple=0.95 perl-filter-util-call=1.58 perl-getopt-long=2.5 perl-http-tiny=0.070 perl-i18n-collate=1.02 perl-i18n-langtags=0.43 perl-if=0.0608 perl-io-compress=2.074 perl-io-socket-ip=0.39 perl-io-zlib=1.10 perl-io=1.39 perl-ipc-cmd=1.00 perl-ipc-sysv=2.07 perl-json-pp=2.97001 perl-lib=0.64 perl-libnet=3.11 perl-locale-codes=3.56 perl-locale-maketext-simple=0.21_01 perl-locale-maketext=1.29 perl-math-bigint-fastcalc=0.5006 perl-math-bigint=1.999811 perl-math-bigrat=0.2613 perl-math-complex=1.5901 perl-memoize=1.03_01 perl-mime-base64=3.15 perl-module-corelist=5.20180622 perl-module-load-conditional=0.68 perl-module-load=0.32 perl-module-loaded=0.08 perl-module-metadata=1.000033 perl-net-ping=2.62 perl-params-check=0.38 perl-parent=0.236 perl-pathtools=3.74 perl-perl-ostype=1.010 perl-perlfaq=5.021011 perl-perlio-via-quotedprint=0.08 perl-pod-checker=1.73 perl-pod-escapes=1.07 perl-pod-parser=1.63 perl-pod-perldoc=3.2801 perl-pod-simple=3.35 perl-pod-usage=1.69 perl-podlators=5.006 perl-safe=2.40 perl-scalar-list-utils=1.50 perl-search-dict=1.07 perl-selfloader=1.25 perl-socket=2.027 perl-storable=3.08 perl-sys-syslog=0.35 perl-term-ansicolor=4.06 perl-term-cap=1.17 perl-term-complete=1.403 perl-term-readline=1.17 perl-test-harness=3.42 perl-test-simple=1.302133 perl-test=1.31 perl-text-abbrev=1.02 perl-text-balanced=2.03 perl-text-parsewords=3.30 perl-text-tabs=2013.0523 perl-thread-queue=3.12 perl-thread-semaphore=2.13 perl-threads-shared=1.58 perl-threads=2.22 perl-tie-file=1.02 perl-tie-refhash=1.39 perl-time-hires=1.9759 perl-time-local=1.25 perl-time-piece=1.3204 perl-unicode-collate=1.25 perl-unicode-normalize=1.26 perl-version=0.9923 perl-xsloader=0.30 ```
oh I see, it makes sense then.
I would not as .format breaks in older versions and we are trying to still keep this kind of module working on older machines
I know this is a small one, but I can imagine % formatting will be decommissioned at some point, I would change this to .format() method if it's not too much of a hassle. To back-up this up, ansible is undergoing an effort to be Python3 compatible, as per Python docs the recommendation is to prefer string.format() method against string % formatting operator. [1][2] Also keep in mind that % might have undesired effects [3] [1] https://docs.python.org/2/library/stdtypes.html#str.format [2] https://www.python.org/dev/peps/pep-3101/ [3] http://stackoverflow.com/questions/5082452/python-string-formatting-vs-format
@charettes thanks for the idea. I made PR #7755 with regression fix.
Maybe it will be better to move `force_text` to the return line ```python return force_text(query, self.charset), self._format_params(params) ``` instead of repeating it in each case.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
We already test this exact configuration in upgrade test (from 0.9 to 0.10, using both 0.9 producer and consumer, and default timestamp type). I would change timestamp_type of this test to LogAppendTime to make it different.
The last parenthesis should be moved to the next line due to hanging indentation, i.e.: ```python qs = WindowTestModel.objects.annotate(dense_rank=Window( expression=DenseRank(), partition_by=F('department'), order_by=[F('salary').desc(), F('name').asc()], )).order_by('department', 'dense_rank') ```
The trailing comma looks unneeded.
`field_preference` must be a list or a tuple.
Code duplication 80-86, 89-94.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
This is not fixed.
s/CONSTURCTOR/CONSTRUCTOR/ (and usages)
Right, but the order in which you're doing things would at a glance result in the not-uncommon case of, eg `foo (cr)(lf)` not being properly treated, since the break `sub` wouldn't see that, but the char drop would remove the (cr), leaving a line ending that wouldn't format the right way.
new versions still support --check for backwards compatibility
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
Let's not block the merge on this. The current implementation matches the DEP which was largely discussed. I'm brainstorming to avoid future problems. Seeing the code sometimes gives new ideas.
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
```suggestion 'field_name': 'related_questions', ```
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
```suggestion 'field_name': 'related_questions', ```
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
(suggesting to delete this test anyway, however, this could fit on the previous line and if not, use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style)).
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
"Always clear..." would be sufficient
Fair, but we are still in a critical section of code performance-wise.
While my tests suggest that iterating a set is ~8% slower in this case, it is a negligible difference once you look at the whole `_expire_cache` function.
You: `[0-9|a-f]`. Stackoverflow: `[0-9a-f]`. Difference? You have to learn to distinguish `(...)` and `[...]`.
I'd use .objects.create
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
If rc != 0 it is always err. You don't need out or err.
This will throw an exception every time when a server is down. When glusterfsd is down the output looks like this: Brick 10.70.43.200:/mnt/engine Status: Transport endpoint is not connected Number of entries: - And you'll be trying to do int('-') which will throw ValueError. And the module throws error: fatal: [10.70.42.25]: FAILED! => {"changed": false, "msg": "Invalid heal status option."} in the function main.
immediatelly -> immediately
extra space after [
~~ use the shared open_url function, it takes care of many issues with python's ssl ~~
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
Does this need to be a separate method? Seems unnecessary to me.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
single line looks more readable here
immediatelly -> immediately
Single quotes please.
Line 41. By the way, it would make the patch a bit easier to review and see what has changed if you didn't reorder methods (e.g. set is moved above _set) and delete above _discard). Perhaps the reordering could be done in a separate commit afterwards if it's needed.
I take this back and have a deeper look at the tests.
immediatelly -> immediately
Thanks. This PR is assigned to the 2.12 milestone, which we'll be going through after creating the stable-2.11 branch (which will be done when 2.11 RC1 comes out).
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
I don't think this is working correctly, did you test it for all possible inputs ? - First of all the size_unit is only correct if it is a known unit. - And if that's not true, and it's not a digit, you have to escalate. - If it is a digit, you likely won't have a unit and then you could assume bytes.
This means that if you'd be using 16m, it will be 16 bytes too. You will have to do a lot more to avoid mixups here.
The mixup to me is that people using incorrect units will silently be using bytes, whereas it should report this as an error.
I would change this to a `NotSupportedError`, e.g. ```python raise NotSupportedError( 'Bulk create a multi-table inherited model is not supported ' 'on this database backend.' ) ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
This doesn't seem right, size is an integer at this point.
The final command should probably return its stdout, stderr and rc back to the playbook.
The final command should probably return its stdout, stderr and rc back to the playbook.
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
`else` is unnecessary, I think we can leave: ```python if self.ignorenonexistent: continue raise ```
`field_names` are used only when `self.ignorenonexistent is True`, so we can optimize this part, e.g.: ```python field_names = set() if self.ignorenonexistent: if Model not in field_names_cache: self.field_names_cache[Model] = {f.name for f in Model._meta.get_fields()} field_names = self.field_names_cache[Model] ```
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
IMHO it's an antipattern when you catch everything wholesale. You mask future bugs this way.
```suggestion module.fail_json(msg="The following packages are absent in the currently booted rpm-ostree commit: %s" % ' '.join(pkgs)) ```
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
IMHO it's an antipattern when you catch everything wholesale. You mask future bugs this way.
we should also return if we both delegate executions and delegate_facts
```suggestion type: list suboptions: ```
I don't see a need for string interpolation in cases like this.
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
Might be worth renaming this to `self.root_queryset`.
These lines will be unnecessary with the new version of `resolve_model_field_relations()` (see #14781) because it uses `self.real_apps` and handles `concretes`.
Much better IMO, I haven't managed to fail it but let's see what @aaugustin thinks. I didn't find any other usages of `get_app_paths()`. Edit: I probably should have posted that globally since it's not directly connected to this line of code.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Code duplication. Keep the original `_write_thumbnails` code and generalize item part. `param_name` is a bad name for something that describes an item's kind.
we probably want to move this 'adhoc list' into constants.py anyways
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
IMHO it's an antipattern when you catch everything wholesale. You mask future bugs this way.
```suggestion module.fail_json(msg="The following packages are absent in the currently booted rpm-ostree commit: %s" % ' '.join(pkgs)) ```
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
prefer hanging indent style with 1 arg per line
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This would be more readable and consistent with our indentation style with something like: ``` foo_constraints = [ name for name, details in constraints.items() if details['columns'] == ['name'] and details['unique'] and name != custom_constraint_name] ] self.assertEqual(len(foo_constraints), 1) ``` (choosing a different name than "foo"
I think we'd want more details about why this hack is needed.
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
Getting an error about an index when creating a constraint is confusing unless you understand the implementation details.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
prefer hanging indent style with 1 arg per line
`band_input`, you don't get much by saving one char :-)
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
Omit these lines please.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
No need to assign to `self.widgets` ```python if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = [w() if isinstance(w, type) else w for w in widgets] ```
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
So if I update some parameter+ change state to running, it won't start, IIUC
No need to assign to `self.widgets` ```python if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = [w() if isinstance(w, type) else w for w in widgets] ```
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
please reuse the code, it's very same
Good catch, I will remove it before final squash.
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Should be ``self.weight``
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Good catch, I will remove it before final squash.
Too long line.
Line is too long.
Too long line.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
please fail if required stuff is null
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
please fail if required stuff is null
`band_input`, you don't get much by saving one char :-)
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
I think `enumerate` would work here
Similarly, ```if tc['skip'].get('i')```
Add trailing comma.
argument ordering should be reversed
please use a variable for this string so that if it changes, we don't have to update it below as well
@chouseknecht thanks a bunch, it makes sense to me. FWIW, I'm happy to help with the maintenance of the openshift client too. I'd like to help keeping the ansible module and the openshift client aligned with upstream kubernetes.
This change looks unrelated.
`constraint_name` should also be quoted.
WDYT about adding `or self.title` here? ``` python self.title = title or self.title or self.lookup_title ``` This would add support for the following: ``` python class MyStaffFilter(BooleanFieldListFilter): title = "By can haz admin" # no effect :( overwritten in __init__ @admin.register(User) class UserAdmin(UserAdminBase): list_filter = ( ("is_staff", MyStaffFilter), ) ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
docstring with example input/output would be really helpful
a simpler fix i was already working on: `+ display.display(json.dumps(text, cls=AnsibleJSONEncoder, sort_keys=True, indent=4))`
^ that seems to be an expression not really a data type issue (sorting keys, this is another known json issue), in any case, there is also an existing `jsonify` in module_utils.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Can you re-warp this block to 79 chars? (First line is too short.)
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
This variable is never assigned ```suggestion api.get_collection_versions('namespace', 'collection') ```
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
I think it may be cleaner to check this right away ```suggestion actual_versions = api.get_collection_versions('namespace', 'collection') assert actual_versions == [u'1.0.0', u'1.0.1', u'1.0.2', u'1.0.3', u'1.0.4', u'1.0.5'] ``` and this would simplify the check at the end of this test.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Right, this was more a of suggestion open to discussion given the composite nature of `(-180.0, -90.0, 180.0, 90.0)`. I kind of wish `Field.deconstruct` was more smart wrt to `__init__` defaults by relying on `inspect` reflection in the first place.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
If we `from itertools import chain` we can save the overhead of attribute access here.
I think there's no reason that 'template' and 'arg_joiner' need to go into `data` -- they aren't meant to be interpolated into `template`, correct? Instead of the `data.get()` lines below, wouldn't this work: ``` python template = template or self.template arg_joiner = arg_joiner or self.arg_joiner ```
Ah. Yes, quite right. So this could be simplified to: ```python return None if None in args else func(*args, **kwargs) ```
If we `from itertools import chain` we can save the overhead of attribute access here.
I think there's no reason that 'template' and 'arg_joiner' need to go into `data` -- they aren't meant to be interpolated into `template`, correct? Instead of the `data.get()` lines below, wouldn't this work: ``` python template = template or self.template arg_joiner = arg_joiner or self.arg_joiner ```
Ah. Yes, quite right. So this could be simplified to: ```python return None if None in args else func(*args, **kwargs) ```
If we `from itertools import chain` we can save the overhead of attribute access here.
I think there's no reason that 'template' and 'arg_joiner' need to go into `data` -- they aren't meant to be interpolated into `template`, correct? Instead of the `data.get()` lines below, wouldn't this work: ``` python template = template or self.template arg_joiner = arg_joiner or self.arg_joiner ```
Ah. Yes, quite right. So this could be simplified to: ```python return None if None in args else func(*args, **kwargs) ```
If we `from itertools import chain` we can save the overhead of attribute access here.
I think there's no reason that 'template' and 'arg_joiner' need to go into `data` -- they aren't meant to be interpolated into `template`, correct? Instead of the `data.get()` lines below, wouldn't this work: ``` python template = template or self.template arg_joiner = arg_joiner or self.arg_joiner ```
Ah. Yes, quite right. So this could be simplified to: ```python return None if None in args else func(*args, **kwargs) ```
We can reuse existing objects.
I guess `get_admin_readonly_field()` could take `response` instead of `response.context['adminform']`.
Missing asserts here? Also, please split the test into smaller parts.
We can reuse existing objects.
I would use: ``` self.assertRaisesMessage(AttributeError, "'ProxyModel' has no attribute 'test_objects'"):` TestModel.test_objects ```
Maybe: ```suggestion try: self.assertInHTML('<th>1</th>', f.render()) except RecursionError: self.fail('Cyclic reference in BoundField.render().') ```
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
This module will be rewritten into 'exos_lldp_interfaces' using Resource Module Builder.
```suggestion - Exactly one of I(name) or I(group_id) must be provided. ```
```suggestion - Exactly one of I(name) or I(group_id) must be provided. ```
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
s/strng or or/string or/
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
s/strng or or/string or/
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
This will still result in a command like `git config --unset foo ''`. According to the git config man page, that extra argument is a "value_regex" and its presence means only those values matching this regex will be unset. Luckily the empty string is a regex that matches everything, so it all works out fine in the end.
This variable is never assigned ```suggestion api.get_collection_versions('namespace', 'collection') ```
I think it may be cleaner to check this right away ```suggestion actual_versions = api.get_collection_versions('namespace', 'collection') assert actual_versions == [u'1.0.0', u'1.0.1', u'1.0.2', u'1.0.3', u'1.0.4', u'1.0.5'] ``` and this would simplify the check at the end of this test.
```suggestion version_added: '2.9' ```
alright. let's keep it as is.
use python bool for the default `default=False`
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
I would be in favor of including the full exception text for the two cases with `if PY2`, etc. It's more cryptic than it needs to be. And when switching to Django 2, the `PY2` block can simply be deleted rather than having to remember to fill in the fuller message.
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
I'd name this argument with a simpler name, maybe something like `file` or `path`, in opposition to `query`, or at least giving an alias making it easier to use.
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
Per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/ these could use `assertIs(..., True)`. I've done this for existing `.check_token()` tests in #12380.
This should be set only for values.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
Single quotes for all of these as well.
This shouldn't be needed once you add the custom `deconstruct()`.
Single quotes for all of these as well.
I saw that you're now handling this at the database level. It makes more sense to me.
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
Per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/ these could use `assertIs(..., True)`. I've done this for existing `.check_token()` tests in #12380.
This should be set only for values.
The code I've reviewed recently always has mixins on the left. I think it's easier to be consistent than have to think about it, but feel free to propose some different guidelines if you like.
I second Tim. Unless a very specific use case, mixins should be on the left.
Read also https://www.ianlewis.org/en/mixins-and-python
This is not necessary.
These doesn't use hooks from `OperationTestBase`.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
I think this could be increased to 10 just in case the system is really slow. The important thing is that it doesn't loop forever.
Single quotes please.
Does this need to be a separate method? Seems unnecessary to me.
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
I think this could be increased to 10 just in case the system is really slow. The important thing is that it doesn't loop forever.
Single quotes please.
Not sure it makes a difference but before it looks like we got `form=None` in the context.
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
Similarly, ```if tc['skip'].get('i')```
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
This should be extracted in the first place.
But this code is never going to be hit if the argument_spec is set to required=True, unless someone set `url: ""`, but it's difficult to test for every bad input format - someone could equally pass `url: "not_a_protocol://thisisnonsense"`
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
comma after tuple
flake8 complains about missing spaces around `*`
Ahh true, sorry for the noise. No changes are required.
I removed it.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
I prefer putting the closing ) on the next line
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
This is a private function (starts with an underscore) so I'd hope we could move this without having to leave a stub for backwards compatibility. If you want to remove the stub in a separate commit/PR just in case, though, I can live with that.
After taking a look at the new function, I could see leaving the stub function in so that it can establish default values for arg_spec and params.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
I prefer putting the closing ) on the next line
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
Since the same result is expected as above, wouldn't it be clearer to save the output in a variable? Something like: ``` expected = ( "[ ] author_app.0001_initial\n" "[ ] book_app.0001_initial\n" "[ ] author_app.0002_alter_id\n" "[ ] mutate_state_b.0001_initial\n" "[ ] mutate_state_b.0002_add_field\n" ) ```
This could be final? Also, applies to parameters in the other models
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This could be final? Also, applies to parameters in the other models
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
It looks like just setting `instance_monitoring` to `true` now won't really do anything, since basic monitoring is on by default and the value of `advanced_instance_monitoring` would default to `False`. This seems confusing.
Use dict literals: ```suggestion return {} ```
```suggestion b_opath = os.path.realpath(to_bytes(os.path.join(path, group))) ```
We should probably do more here than just reraise the exception with a different type. Add a message here so it gives context about the failure. The same with the next one too.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
Running the legacy ec2_asg integration tests that use this module, I think this line should be `if block_device_mapping:` because it doesn't look like it can be None or an empty list. The error: ``` An exception occurred during task execution. To see the full traceback, use -vvv. The error was: Missing required parameter in BlockDeviceMappings[0]: "DeviceName" fatal: [localhost]: FAILED! => {"changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 436, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 430, in main\n create_launch_config(connection, module)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 326, in create_launch_config\n connection.create_launch_configuration(**launch_config)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 253, in _api_call\n return self._make_api_call(operation_name, kwargs)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 517, in _make_api_call\n api_params, operation_model, context=request_context)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 572, in _convert_to_request_dict\n api_params, operation_model)\n File \"/Library/Python/2.7/site-packages/botocore/validate.py\", line 270, in serialize_to_request\n raise ParamValidationError(report=report.generate_report())\nbotocore.exceptions.ParamValidationError: Parameter validation failed:\nMissing required parameter in BlockDeviceMappings[0]: \"DeviceName\"\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0} ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Minor but I'd move this control flow block after the `weights` one to match the args order.
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
```suggestion type: list suboptions: ```
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
`if it encounter` => `if it encounters`
`mentionned` => `mentioned`
I'd do this unconditionally.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
May I ask you to implement an exponential backoff algorithm here? https://en.wikipedia.org/wiki/Exponential_backoff
`default=None` is the default, it's not required.
Is this the only way this can fail? If not, might be nice to provide the out, err in the message, if this is the only way this can fail this is fine though.
Why do the clone here and not use the clone/fetch/... code that already exists? The archive option in this way works only with a local checkout, which the module already does, so I'd rather use the existing checkout setup and run archive afterwards.
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
Is this the only way this can fail? If not, might be nice to provide the out, err in the message, if this is the only way this can fail this is fine though.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
I'd do this unconditionally.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
May I ask you to implement an exponential backoff algorithm here? https://en.wikipedia.org/wiki/Exponential_backoff
I'd do this unconditionally.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
May I ask you to implement an exponential backoff algorithm here? https://en.wikipedia.org/wiki/Exponential_backoff
It seems like you could simplify things if you had an operator map and do smth like: ```suggestion import operator ... op_map = { '!=': operator.ne, '==': operator.eq, '>=': operator.ge, '>': operator.gt, ... '*': operator.eq, } ... pos = 2 if req[1] == '=' else 1 op_map(req[:pos])(LooseVersion(version), LooseVersion(req[pos:])) ... ```
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
Is this the only way this can fail? If not, might be nice to provide the out, err in the message, if this is the only way this can fail this is fine though.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
You should at least add real values for `datastore`, `source`, and `destination`.
You should add real values: https://github.com/ansible/ansible/pull/47271#discussion_r226405450
All modules in VMware space uses Jinja variables like the current implementation. I would stick to this naming scheme as this will make all modules same and readable. Adding arbitary values does not make sense to me.
This is useless. `filepath` must be required to be a valid path. This must be asserted.
This will break unicode strings under python 2.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
In what case is this branch reached? Should there be a test for it? I guess you meant `raise CommandError(e)`.
I'd do this unconditionally.
maybe just ```suggestion part_boundary, b"--", ```
It seems like you could simplify things if you had an operator map and do smth like: ```suggestion import operator ... op_map = { '!=': operator.ne, '==': operator.eq, '>=': operator.ge, '>': operator.gt, ... '*': operator.eq, } ... pos = 2 if req[1] == '=' else 1 op_map(req[:pos])(LooseVersion(version), LooseVersion(req[pos:])) ... ```
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
It seems like you could simplify things if you had an operator map and do smth like: ```suggestion import operator ... op_map = { '!=': operator.ne, '==': operator.eq, '>=': operator.ge, '>': operator.gt, ... '*': operator.eq, } ... pos = 2 if req[1] == '=' else 1 op_map(req[:pos])(LooseVersion(version), LooseVersion(req[pos:])) ... ```
How about: ```suggestion if not os.path.exists(file_path): continue ```
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
I'm curious if this should be a `BaseException` so that it'd work on `Ctrl+C` (`SIGINT`) or `SystemExit` (`SIGTERM`).
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
I'm curious if this should be a `BaseException` so that it'd work on `Ctrl+C` (`SIGINT`) or `SystemExit` (`SIGTERM`).
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
I'd do ```suggestion if not ignore_errors: raise ```
It's actually missing `--ignore-certs` CLI arg that implies `validate_certs=True` according to the code I saw...
How about: ```suggestion if not os.path.exists(file_path): continue ```
This will break unicode strings under python 2.
Is this the only way this can fail? If not, might be nice to provide the out, err in the message, if this is the only way this can fail this is fine though.
Why do the clone here and not use the clone/fetch/... code that already exists? The archive option in this way works only with a local checkout, which the module already does, so I'd rather use the existing checkout setup and run archive afterwards.
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
I'm curious if this should be a `BaseException` so that it'd work on `Ctrl+C` (`SIGINT`) or `SystemExit` (`SIGTERM`).
Is this the only way this can fail? If not, might be nice to provide the out, err in the message, if this is the only way this can fail this is fine though.
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
Is this the only way this can fail? If not, might be nice to provide the out, err in the message, if this is the only way this can fail this is fine though.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
I'd do this unconditionally.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
May I ask you to implement an exponential backoff algorithm here? https://en.wikipedia.org/wiki/Exponential_backoff
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
Omit expected type.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
No such meta field.
`acodec == 'none'`.
Use built-in method? Also, should it crash (raise) if `json.loads()` fails, or just return an empty dict again? ```suggestion try: return self._download_json( url, song_id, data=data.encode('ascii'), headers=headers) except ExtractorError as e: if type(e.cause) in (ValueError, TypeError): # JSON load failure raise except Exception: pass return {} ```
`enumerate` on for range.
If `video_detail.get('spl')` should be `None`, or something else that can't have a `compat_str` added, this will crash. The extraction would have failed, but it might be better to crash in `_extract_sdn_formats() ` instead. Try (eg) `'%sspl2,3,VOD' % (str_or_none(video_detail.get('spl')) or '', )`. Or make sure it does crash here with `['spl']` instead of `.get(...)`.
Don't capture groups you don't use. Unused captured group.
docstring with example input/output would be really helpful
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
And this can be reverted.
After taking a look at the new function, I could see leaving the stub function in so that it can establish default values for arg_spec and params.
This is a private function (starts with an underscore) so I'd hope we could move this without having to leave a stub for backwards compatibility. If you want to remove the stub in a separate commit/PR just in case, though, I can live with that.
`if it encounter` => `if it encounters`
Can we detect if this is not a json and fallback to print it directly
Code duplication. Keep the original `_write_thumbnails` code and generalize item part. `param_name` is a bad name for something that describes an item's kind.
It's not obvious to me that the template approach is the best solution for readability as opposed to just creating another test settings file.
You can also add a deprecation warning for usages like `from django.forms.extras.widgets import SelectDateWidget`.
You don't modify ignore_when_null in this function so it's probably harmless to use [] as its default value but it's a bad habit to get into. You should try to always use a immutable as a default value. In this case, you can do: ```ignore_when_null=tuple()```.
If you're unfamiliar with why that is, you should probably google it. It has to do with python processing the function declaration once when the function is declared and therefore there's only one copy of the default value which is used every time the function is called. If you have a mutable container as a default value, it will not be recreated between invocations so it may not be empty the second time you call the function.
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
test failure says this should be `(None, None)`
Do we need to call `list(fields)` here? :thinking:
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
I would revert this change, the previous version is clearer to me.
```suggestion the I(verification_method) will be updated and validation data (if applicable) will be returned. ```
```suggestion - If the domain is already in the validation process but the I(verification_method) specified is different than the current I(verification_method), ```
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
docstring with example input/output would be really helpful
Please ignore, my suggestion is invalid syntax.
flake8 complains about missing spaces around `*`
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
The `to_bytes` should be on the `self._basedir` instead: ```suggestion b_opath = os.path.realpath(os.path.join(to_bytes(self._basedir), b'r_group_vars')) ```
Might be worth adding a `note:` to say that only the hash of the file is used for comparisons, not any filemode/permissions/etc.
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
no restructured text (:class:) in docstrings please
Is there a typo? I'm not sure what "hub" means in this sentence.
Please wrap: ``` # If true, uniqueness validation checks will consider this a new, unsaved # object. Necessary for correct validation of new instances of objects with # explicit (non-auto) PKs. This impacts validation only; it has no effect # on the actual ```
Thanks both :+1: I pushed edits.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
chop newline for consistency with other tests
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
The `to_bytes` should be on the `self._basedir` instead: ```suggestion b_opath = os.path.realpath(os.path.join(to_bytes(self._basedir), b'r_group_vars')) ```
Might be worth adding a `note:` to say that only the hash of the file is used for comparisons, not any filemode/permissions/etc.
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
The `to_bytes` should be on the `self._basedir` instead: ```suggestion b_opath = os.path.realpath(os.path.join(to_bytes(self._basedir), b'r_group_vars')) ```
Might be worth adding a `note:` to say that only the hash of the file is used for comparisons, not any filemode/permissions/etc.
First we should verify this passes before we toggle `is_active` to False.
check the group permissions before `is_active = False` too.
Actually I guess the ideal way to test this would be something like: ``` backend = ModelBackend() backend.get_user_permissions(user) ```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
@wrouesnel CI failure due to PEP 8 issue: ``` 2017-01-28 07:26:38 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2.py:930:1: W293 blank line contains whitespace (legacy) ```
```suggestion # Nested coalesce ```
You could use `subtest()` for the loop.
According to pep8, there's a missing space after `+` in here.
`xrange` has been removed in Python 3. Simply use `range` instead.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
@wrouesnel CI failure due to PEP 8 issue: ``` 2017-01-28 07:26:38 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2.py:930:1: W293 blank line contains whitespace (legacy) ```
```suggestion # Nested coalesce ```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
@wrouesnel CI failure due to PEP 8 issue: ``` 2017-01-28 07:26:38 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2.py:930:1: W293 blank line contains whitespace (legacy) ```
```suggestion # Nested coalesce ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Any problem with: ``` @property def media(self): ```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
@wrouesnel CI failure due to PEP 8 issue: ``` 2017-01-28 07:26:38 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2.py:930:1: W293 blank line contains whitespace (legacy) ```
```suggestion # Nested coalesce ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
okay, but would be helpful to say _why_ we need to always return True.
Put the ending `)` on a new line.
I'd omit a blank line after each docstring.
Can you re-warp this block to 79 chars? (First line is too short.)
You are leaking information about whether somebody has access or something doesn't exist.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Any problem with: ``` @property def media(self): ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Any problem with: ``` @property def media(self): ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Any problem with: ``` @property def media(self): ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Any problem with: ``` @property def media(self): ```
I'd omit a blank line after each docstring.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I'd omit a blank line after each docstring.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I'd omit a blank line after each docstring.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Any problem with: ``` @property def media(self): ```
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Passing title here makes no sense for non playlists since it will be overridden by delegated extractor. If you want to pass metadata that won't be overridden you should return info dict of [`url_transparent` type](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/makertv.py#L28-L31).
``` for i, video_url in enumerate(video_urls): ```
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
Does this need to be a separate method? Seems unnecessary to me.
`always_text` is gone.
This seems like it will make for a hard API to use because it will fail when the lock_file is owned by another user (so playbooks run by different users or async with tasks that become different users will raise Permission denied errors). It seems like problems opening the lock_file should be part of the timeout.
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
I think we are missing the `call_command()` here.
`always_text` is gone.
Should have a default set to `present`.
Should become parameter `username` (with a backward-compatible alias). (See #20160 and #25398)
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Use single quotes consistently.
nit: since the error message says "the elements" shouldn't this check all elements? ```suggestion if not all(val): ``` alternatively, we can leave the if-statement as-is and instead change the error to something like "the first key in the list must not be empty"
We do not have to overdo it, but `if not all(val)` seems easier and brings over the intent better than `if not val[0]`
If `getattr()` is not necessary, do we need this round trip at all? ```python if val is None: ... val = data[field_name] data[field_name] = val ``` It looks that we can remove [this line](https://github.com/django/django/pull/13036/files#diff-1e7fc0d7d1b36358e371fab97bd1ddb1R152) :thinking: , e.g. ```python if val is None: instance.refresh_from_db(fields=[field_name]) else: data[field_name] = val ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
with -> width
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Right, this was more a of suggestion open to discussion given the composite nature of `(-180.0, -90.0, 180.0, 90.0)`. I kind of wish `Field.deconstruct` was more smart wrt to `__init__` defaults by relying on `inspect` reflection in the first place.
I wonder if it's worth adding two class attributes constants for these defaults.
We can register model without defining `OfficeAdminWithOrdering` with the same effect: ```python site.register(Office) ```
Keep the `r`
is_vapp_changed = False
I think you didn't understand what I was suggesting. What you do : Add each of the property the user have asked for in new_vmconfig_spec.property, and if at least one of them modify the properties already attached to the VM â apply new_vmconfig_spec What I propose : Only add to new_vmconfig_spec.property the property the user have asked for that actually modify (add/remove/edit) the properties already attached to the VM. And then, if there is some properties in new_vmconfig_spec.property â apply new_vmconfig_spec.
no need for `.keys()`. `if property_id in vapp_properties_current:` is the same as `if property_id in vapp_properties_current.keys():`
I think you didn't understand what I was suggesting. What you do : Add each of the property the user have asked for in new_vmconfig_spec.property, and if at least one of them modify the properties already attached to the VM â apply new_vmconfig_spec What I propose : Only add to new_vmconfig_spec.property the property the user have asked for that actually modify (add/remove/edit) the properties already attached to the VM. And then, if there is some properties in new_vmconfig_spec.property â apply new_vmconfig_spec.
is_vapp_changed = False
no need for `.keys()`. `if property_id in vapp_properties_current:` is the same as `if property_id in vapp_properties_current.keys():`
I think you didn't understand what I was suggesting. What you do : Add each of the property the user have asked for in new_vmconfig_spec.property, and if at least one of them modify the properties already attached to the VM â apply new_vmconfig_spec What I propose : Only add to new_vmconfig_spec.property the property the user have asked for that actually modify (add/remove/edit) the properties already attached to the VM. And then, if there is some properties in new_vmconfig_spec.property â apply new_vmconfig_spec.
is_vapp_changed = False
I would chop blank lines in this test.
Chop `Ensure that`.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
I'd be great to assert the permission and content types were appropriately created as well!
Silenced the output. The `create_default_site` method deserves a more basic test, but there's more to it than the output, could be another ticket I guess (this one is pretty convolved as is). Here's a [sketch of a test](https://github.com/wrwrwr/django/commit/8927a52a4271ab8208783ce4c2af31814314a6c8).
preferred format is "#15346, #15573 - Issue description"
Interesting thought. But if a key is compromised one would switch from one key in the list to still one key (the new one) because you wouldn't want to keep the compromised key active. So in the case of a compromise I'd always expect the list to stay constant in length because the offending key would be replace with a new one (independent of other keys probably). Either way for the majority of cases (ie under normal operation) I'd expect just one key in there (or always two if one rotates a key every $x weeks)
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
I would chop blank lines in this test.
Chop `Ensure that`.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
with -> width
width, height, and offset
As discussed on IRC: no.
I would chop blank lines in this test.
Chop `Ensure that`.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
We should state clearly what to use when deprecation ends, there is a risk that we'll remove logging of suspicious session: ```python def decode(self, session_data): try: return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer) # RemovedInDjango40Warning: when the deprecation ends, replace with: # except signing.BadSignature: # logger = logging.getLogger('django.security.SuspiciousSession') # logger.warning('Session data corrupted') # except Exception: # # ValueError, unpickling exceptions. If any of these happen, # # return an empty dictionary (an empty session). # pass # return {} except Exception: return self._legacy_decode(session_data) ```
with -> width
We can also write a single line return statement. Please see if it makes sense. ```suggestion return (uid is not None and path_stat.st_uid == uid) or (gid is not None and path_stat.st_gid == gid) or (uid is None and gid is None) ```
no need for this line as None is already a False value
your rigth ! when I developped this module, there was no `uid` in Grafana, so i've removed the `uid` same as was doing for the `id` field before when adding the Grafana 5 compatibility.
Does the order matter? If yes, it's probably better to use ```suggestion return '/'.join(sorted(priv_list)) ```
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
What if `default` is not a constant but a field reference? e.g. `F('integer')`
```suggestion pkg_version = line.partition(':')[-1].strip() ```
Change the following: ```python import hashlib ``` Into: ```python from hashlib import sha1, sha224, sha256, sha384, sha512 ``` Then: ```suggestion return sha1(text.encode()).hexdigest() ``` And for `_sqlite_sha224()`, etc.
Good catch, I will remove it before final squash.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Is there precisely one time you can specify this? It sounds to me like this should be allowed to repeat multiple times. So this should be a `list`. Or maybe even better a `dict`, so people can specify things like ``` blkio_weight_device: /dev/sda: 100 /dev/sdb: 200 ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
No need to wrap.
might be better to have some kind of mapping here ``` convert_list = ['image_id', 'instance_type', 'instance_id', ...] camel_params = dict((k,v) for k, v in snake_dict_to_camel_dict(module.params).items() if v is not None and k is in convert_list) ``` and then special case any exceptions like IamInstanceProfile and InstanceMonitoring
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Could you also change this line for me? ```diff - Cast(expression, FloatField()) if not isinstance(expression.output_field, FloatField) + Cast(expression, FloatField()) if isinstance(expression.output_field, IntegerField) ``` Don't forget to import `IntegerField`.
`if it encounter` => `if it encounters`
`mentionned` => `mentioned`
`load_config` doesn't return anything https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ios.py#L121
`if it encounter` => `if it encounters`
`load_config` doesn't return anything https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ios.py#L121
`mentionned` => `mentioned`
Combine line 99 with this line: ```suggestion - May not be used with C(backrefs) or C(insertafter). ```
Why change the example docs? The yaml dict style is the preferred format for EXAMPLES
Please also fix this on the original method (line 1739)
Why change the example docs? The yaml dict style is the preferred format for EXAMPLES
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
You could use RenameMethodsBase.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
You could use RenameMethodsBase.
prefer hanging indent style with 1 arg per line
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
`elif` might be clearer (I understand it's not necessary)
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
`if it encounter` => `if it encounters`
`load_config` doesn't return anything https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ios.py#L121
`mentionned` => `mentioned`
`if it encounter` => `if it encounters`
`mentionned` => `mentioned`
`load_config` doesn't return anything https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ios.py#L121
is this the same as "validate_certs" in other modules? if so I would prefer to standardize the naming to that
non required fields should show default, even if just null
`while` seems to be missing
use of one the styles in 04de4369325097472d7ad036dac262555002ba88
This test name mentions multi-table inheritance but the body of the test has nothing to do with it.
I would use: ``` self.assertRaisesMessage(AttributeError, "'ProxyModel' has no attribute 'test_objects'"):` TestModel.test_objects ```
You can join this line with the previous.
I think there is, just so folks have a little less to learn between the two.
Better yet: `empty_label or VERBOSE_BLANK_CHOICE_DASH`
Referring specifically to the kubeconfig definition, the remote file path will cover a lot of use cases but I was wondering if it would be useful to be able to specify it inline as well, which would open the door for keeping your authentication with your ansible playbooks/roles.
Can we use instead `assertEqual()` and `assertIsNot()`? ```suggestion self.assertEqual(clone, source) self.assertIsNot(clone, source) ```
```suggestion description: Can be used to request certificates from ECS, with C(provider=entrust). ```
You could do this setup in Python. `self.school.students.add(...)`
``` change_url = reverse('admin:admin_widgets_school_change', args=(self.school.id,) self.selenium.get(self.live_server_url + change_url) ```
This regex does not make any sense.
For these 3, add expected_type `int`, eg: ```py 'width': try_get(item, lambda x: x['video']['width'], int), ``` (equivalent in effect to wrapping in `int_or_none()`).
Sarmonise with yt-dlp pt7: ```suggestion # Stripchat declares the RTA meta-tag, but in an non-standard format so _rta_search() can't be used 'age_limit': 18, } ```
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
* use the resulting match object * avoid excessive indentation * `r'\s'` includes any whitespace * simplify `clean_html()` expressions ```suggestion href = extract_attributes(html[mobj.start(0):mobj.start('content')]).get('href') if not href: continue mobj1 = re.search(r'/(?P<s_id>\d+)\.html', href) if mobj1 and mobj1.group('s_id') == series_id: series_title = clean_html(re.sub(r'\s+', ' ', mobj.group('content'))) title = clean_html(re.sub(r'\s+', ' ', html)) break ```
It should always return a list.
Fix test: ```suggestion 'ext': 'mp4', ```
Referring specifically to the kubeconfig definition, the remote file path will cover a lot of use cases but I was wondering if it would be useful to be able to specify it inline as well, which would open the door for keeping your authentication with your ansible playbooks/roles.
Can we use instead `assertEqual()` and `assertIsNot()`? ```suggestion self.assertEqual(clone, source) self.assertIsNot(clone, source) ```
```suggestion description: Can be used to request certificates from ECS, with C(provider=entrust). ```
prefer hanging indent style (allows longer lines, indentation always multiple of 4): ``` rasterheader = ( 1, 0, ... ) ```
We try to avoid line continuation backslashes in Django, and it's not a problem to overcome the 80-chars limit when it makes readability better.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
No need to define another attribute. The form class should be accessible as `self.TestForm`.
Ah, ok so maybe we can check both in one call, i.e. ```python self.assertEqual(check_language_settings_consistent(None), [ Error( ... ), Warning( ... ), ]) ```
No need for the `u` prefix, we're already importing `unicode_literals`.
No need for the `u` prefix, we're already importing `unicode_literals`.
```suggestion self.assertFormError(response, 'form', 'field', 'invalid value') ```
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
it should also check if it can write there
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
again, code not needed as this is already 'required'
it should also check if it can write there
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
this is not a 1.0 callback, its using 2.0 API
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
> ... so I made it a required parameter. Sorry, I think we're not understanding each other. 🤔 * The `on_bind` parameter is defined as `on_bind=None`, so it's optional. * Exactly when `on_bind=None` that `server_bind` is only declared conditionally with lead to a `... is referenced before assignment` problem. If looks like this: ``` >>> on_bind = None >>> if on_bind is not None: ... a = "I won't be defined" ... >>> a Traceback (most recent call last): File "<stdin>", line 1, in <module> NameError: name 'a' is not defined ```
Maybe _"The 'no_color' and 'force_color' cannot be used together."_.
2.0 is what you want here
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
Use another lookup instead of `epoch` e.g. `second`.
What I meant was that you could stick the following in the top of `_destruct_iterable_mapping_values()` to make it more DRY: ```python if isinstance(data, Mapping): yield from data.items() return ``` I don't see why you think we'd need an extra for-loop...
There are only two uses of `_destruct_iterable_mapping_values()` and we use this same pattern exactly. I think that you could push the `isinstance(..., Mapping)` check into that function.
As a separate commit, I think that it is also probably worth moving that global function to be a `@staticmethod` on the `CaseInsensitiveMapping` class. It is closely associated with this class and would avoid the need to import it separately in `django.http.response`.
Minor but I'd move this control flow block after the `weights` one to match the args order.
we should also return if we both delegate executions and delegate_facts
```suggestion type: list suboptions: ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
Do we need to call `list(fields)` here? :thinking:
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
We want to save file with the `symlink.txt` name so this assertion doesn't have much value IMO. I would check that the new file exists.
We've been using "Take / apply" verb-style in new docstrings.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
For consistency path pruning should be done the same as in the boilerplate test: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L13-L14 https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L41-L42
I think we should add an `allow_overwrite` or similar param.
We should indicate that this is only a guess - the value may be smaller or larger than the actual size.
No need to wrap.
We should indicate that this is only a guess - the value may be smaller or larger than the actual size.
The locale should be set to C if we do string matching.
```suggestion - For tracking function statistics the PostgreSQL C(track_functions) parameter must be enabled. ```
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
`items = value.split(self.delimiter) if value else []` is slightly faster.
What if the prepared value contains unicode? (As I said before, you should use a list comprehension instead of a generator, it'll be about 2 times faster here)
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
`items = value.split(self.delimiter) if value else []` is slightly faster.
What if the prepared value contains unicode? (As I said before, you should use a list comprehension instead of a generator, it'll be about 2 times faster here)
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
it should also check if it can write there
`DigitalOcean droplet size facts` would be clear to the end user.
So yeah, the callers that I see are fine. You should be able to simply remove to_text() here.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
It's better to actually say that there's no file in place or it's inaccessible.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
It's better to actually say that there's no file in place or it's inaccessible.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
It's better to actually say that there's no file in place or it's inaccessible.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
It's better to actually say that there's no file in place or it's inaccessible.
`field_preference` must be a list or a tuple.
Code duplication 80-86, 89-94.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
It's better to actually say that there's no file in place or it's inaccessible.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
comma after tuple
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
It's better to actually say that there's no file in place or it's inaccessible.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
It's better to actually say that there's no file in place or it's inaccessible.
`field_preference` must be a list or a tuple.
Code duplication 80-86, 89-94.
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Similarly, ```if tc['skip'].get('i')```
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
Similarly, ```if tc['skip'].get('i')```
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
Similarly, ```if tc['skip'].get('i')```
To be consistent with other modules each of the options should be on a single line (unless they have many choices)
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
This is only ever called once. Do we need the default? (Same with SQL version)
That's a really interesting piece of information I did not know.
IMO, we can use `assertEqual` instead of `assertAlmostEqual` in all tests.
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
and please format it with indent, so it's more clear
add this condition also to lin 2063
But it must be in this if.
No such meta field.
No such meta field.
No such meta field.
`check_rc` is false by default, no need to pass.
Please replace with `type: false`
Ok then we should have a message in the docs then to warn users that this module/option will not be idempotent, so that it doesn't catch them unawares.
I think this should probably be `'auto'` instead of `None` ... unless I missed something (which I'm always open to the possibility that I have): ```python use_backend = self._task.args.get('use', self._task.args.get('use_backend', 'auto')) ```
I'd go for `try/except IOError` in order to make a point that variable initialized above is in fact a fallback.
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_API_VERSION') ``` Will not work for azure-mgmt-resource before 1.3.0 if you want multi-api support there as well.
I'm thinking these parameters shouldn't be filled in, since we're popping `stack_description` so if a user wanted a hard-fail for nonexistent stacks, they could do: ``` - cloudformation_facts: stack_name: not-real failed_when: not cloudformation['not-real'] ```
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_PROFILE') ```
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_API_VERSION') ``` Will not work for azure-mgmt-resource before 1.3.0 if you want multi-api support there as well.
could move this to the previous line
Or ```if not hasattr(filename, 'write')``` or ```if isinstance(filename, compat_str)```? Checking for an exact type makes the codes less flexible.
Should be better with ```isinstanceof(filename, BytesIO)```
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
Thanks for the patch @Giebisch, I think we should adjust the `expected_outputs` instead to be properly formatted in order to ensure formatting is actually used. https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L90-L111 https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L124-L133 The adjustments made make the tests pass with and without the proposed changes.
Meanwhile, I merged a conflicting patch. I think you just need to remove the quotes from around the star.
flake8 doesn't like the hanging indent here.
Meanwhile, I merged a conflicting patch. I think you just need to remove the quotes from around the star.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
could switch to single quotes for consistency
Cases from lines 361 and 363 work with the previous implementation.
Such an extensive docstring is not necessary, IMO.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Chop `Ensure that`.
I would chop blank lines in this test.
```suggestion msg = 'Slice stop must be greater than slice start.' ```
Any problem with: ``` @property def media(self): ```
I think `name.rsplit('-', 1)[-1]` is easier to read.
No indentation is needed: ```suggestion "Optimizing from %d operations to %d operations." % ```
I would chop blank lines in this test.
Chop `Ensure that`.
```suggestion msg = 'Slice stop must be greater than slice start.' ```
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Is there a typo? I'm not sure what "hub" means in this sentence.
This command has always left a trailing `,`. You could potentially omit the commands after the `cut` and just do a split/join in python that will give exactly what we want. Also, not sure if it was intentional or not, but this command seems to elide the alphabetical sorting that's in the command on the wiki.
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
I double people will update this script correctly. We can only hope, that release managers verify this before sending the email... As an alternative, we can also wildcard this, and let release manger insert those manually. Similar to `<DETAILS OF THE CHANGES>` above.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
This code isn't correct. (2, 7) is the check you want, and then with >= if I am not mistaken.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
This is an identity check: ```suggestion if default is NoDefaultValue: ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
Since this isn't implemented, perhaps lets not mention it? I found it confusing
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
`del` is a builtin, not a function. These parens don't have to be here
Since this isn't implemented, perhaps lets not mention it? I found it confusing
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
You don't need this conditional, since Ansible enforces that these are the only choices.
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
`field_preference` must be a list or a tuple.
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
`field_preference` must be a list or a tuple.
Code duplication 80-86, 89-94.
No need to assign to `self.widgets` ```python if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = [w() if isinstance(w, type) else w for w in widgets] ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
`field_preference` must be a list or a tuple.
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
as a tuple
prefer hanging indent style (allows longer lines, indentation always multiple of 4): ``` rasterheader = ( 1, 0, ... ) ```
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
I prefer putting the closing ) on the next line
This must be checked **before** any processing.
This must be checked **before** any processing.
This must be checked **before** any processing.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Any problem with: ``` @property def media(self): ```
`del` is a builtin, not a function. These parens don't have to be here
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This is superfluous, the extension can be extracted automatically.
Eliminate all methods that is only used once.
You will add it when there will be a playlist support. For now it's completely useless.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
point -> points
Useless with timestamp available.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Useless with timestamp available.
Useless with timestamp available.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
`del` is a builtin, not a function. These parens don't have to be here
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
`del` is a builtin, not a function. These parens don't have to be here
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
`del` is a builtin, not a function. These parens don't have to be here
Since this isn't implemented, perhaps lets not mention it? I found it confusing
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
`del` is a builtin, not a function. These parens don't have to be here
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
redundant, remove ```suggestion ```
Good catch, I will remove it before final squash.
`del` is a builtin, not a function. These parens don't have to be here
This can instead be `continue` and let the `else` unnest.
> I think this isn't a great trade-off to make, the special branch for "is the length exactlyt the same" will cost more than it saves across a range of different input string types. Only a few will match it. Yeah, I wondered whether the exact length check might be detrimental. > Regardless this is a rarely used DB function, this is too much time spent optimizing it already :) 😄 Yup. Happy with your solution.
Use built-in method? Also, should it crash (raise) if `json.loads()` fails, or just return an empty dict again? ```suggestion try: return self._download_json( url, song_id, data=data.encode('ascii'), headers=headers) except ExtractorError as e: if type(e.cause) in (ValueError, TypeError): # JSON load failure raise except Exception: pass return {} ```
`enumerate` on for range.
Again: ```suggestion return ('params={0}'.format(encrypted_params), headers) ```
This needs to incorporate `name` somehow else it will break when form prefixes are involved or on top level field names collisions.
All `Col` should have an `alias`.
put closing parenthesis on the next line
This needs to incorporate `name` somehow else it will break when form prefixes are involved or on top level field names collisions.
You could zip here as well ```python for i, (widget_name, widget) in enumerate(self.widget_names, self.widgets): if input_type is not None: widget.input_type = input_type widget_name = name + self.widgets_names[i] ```
This whole logic can be simplified to ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index 4e120d2741..0d39671f0b 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1620,17 +1620,22 @@ class Query(BaseExpression): _resolve_cols(self.annotations[name].get_source_expressions()) return set(cols) + @classmethod + def _gen_col_aliases(cls, exprs): + for expr in exprs: + if isinstance(expr, Col): + yield expr.alias + else: + yield from cls._gen_col_aliases(expr.get_source_expressions()) + def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False, simple_col=False): if not allow_joins and LOOKUP_SEP in name: raise FieldError("Joined field references are not permitted in this query") - if name in self.annotations: - if not allow_joins and self.annotations[name].contains_column_references: - for alias in ( - {getattr(self.annotations[name], 'alias', None)} - if isinstance(self.annotations[name], Col) else - self.resolve_cols(name) - ): - if alias and isinstance(self.alias_map[alias], Join): + annotation = self.annotations.get(name) + if annotation is not None: + if not allow_joins: + for alias in self._gen_col_aliases([annotation]): + if isinstance(self.alias_map[alias], Join): raise FieldError('Joined field references are not permitted in this query') if summarize: # Summarize currently means we are doing an aggregate() query @@ -1639,7 +1644,7 @@ class Query(BaseExpression): # that case we need to return a Ref to the subquery's annotation. return Ref(name, self.annotation_select[name]) else: - return self.annotations[name] + return annotation else: field_list = name.split(LOOKUP_SEP) join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse) ```
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Is there a typo? I'm not sure what "hub" means in this sentence.
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
It'll look more clean if you name these `returncode`, `out`, and `_` (the underscore denotes you're not going to use that, and it's a common pattern in Python). You can also drop the parenthesis, they're not needed
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
Same here, default parameter is **validate_certs**, the aliases should be removed. We also simplify this by *not* adding `required=False`, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
So add `type='str'` here too. And we tend to sort lists if the order is of no importance.
So removed `required=False` and add `type='str' instead. Do this for the others as well.
It would be useful to tell the user which `key` is invalid.
hmm, true, not sure how this was passing the tests before ...
Sure, a separate PR sounds good.
Sure, a separate PR sounds good.
you can move it to before `if` as just `docs = {}` line, this should read better.
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
I think a better wording would be: "Backwards compatibility for storage backends without support for `max_length` will be removed in Django 2.0."
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
@graingert Probably it doesn't worth it, but still doable :-) ``` In [85]: class desc: ...: def __init__(self, f): ...: self.name = f.__name__ ...: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: ...: for cls in cls.__mro__: ...: name = '_%s%s' % (cls.__name__, self.name) ...: if cls.__dict__.get(name) is self: ...: return name ...: ...: class A: ...: @desc ...: def __x(self): ...: pass ...: ...: ...: class B(A): ...: pass ...: In [86]: a = A() ...: a._A__x ...: Out[86]: '_A__x' In [87]: b = B() ...: b._A__x ...: Out[87]: '_A__x' ```
I think it's the right class: ``` In [38]: class desc: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: return instance.__dict__['_%s__mangled' % cls.__name__] In [39]: class A: ...: d = desc() ...: ...: def __init__(self): ...: self.__mangled = 42 ...: In [40]: A().d Out[40]: 42 ```
`import ansible.module_utils.parsing.convert_bool import BOOLEANS` and use that constant
This should just force strict and leave unchanged on typeerror ```diff --git a/lib/ansible/plugins/action/set_fact.py b/lib/ansible/plugins/action/set_fact.py index d7fe573c1a..934245d07c 100644 --- a/lib/ansible/plugins/action/set_fact.py +++ b/lib/ansible/plugins/action/set_fact.py @@ -51,8 +51,11 @@ class ActionModule(ActionBase): "letters, numbers and underscores." % k) return result - if not C.DEFAULT_JINJA2_NATIVE and isinstance(v, string_types) and v.lower() in ('true', 'false', 'yes', 'no'): - v = boolean(v, strict=False) + if not C.DEFAULT_JINJA2_NATIVE and isinstance(v, string_types): + try: + v = boolean(v, strict=True) + except TypeError: + pass # not valid bool string facts[k] = v result['changed'] = False```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
"any other input"
Should also include `block_size` and `parallelism`
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Is there a good reason to order the data like this? I'd personally expect the hash to be at the end, so it could include a `$` .
Should also include `block_size` and `parallelism`
Such an extensive docstring is not necessary, IMO.
Need spaces around `+` sign.
nit: it's not a regex and there's no escaped symbols so there's really no need to make use of raw-strings
Maybe this should be a class docstring :thinking:
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
`quote` isn't used anywhere.
Maybe this should be a class docstring :thinking:
Need spaces around `+` sign.
Such an extensive docstring is not necessary, IMO.
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
This needs to be a failure, the `OrderedDict` object is used. Maybe just do a straight import with the try / except ``` python try: from collections import OrderedDict except ImportError: from ordereddict import OrderedDict ```
we should not be adding a python dependency on ordereddict here, as python2.7 can also use ordereddict from collections: https://docs.python.org/2/library/collections.html#collections.OrderedDict This also means, that python2.7 users now need an additional python dependency installed.
Since we are already using `six`, we should use `six.moves` here instead. ``` from six.moves.urllib.parse import urlencode ```
no `u''` prefixes on strings please
I would change this to a `NotSupportedError`, e.g. ```python raise NotSupportedError( 'Bulk create a multi-table inherited model is not supported ' 'on this database backend.' ) ```
I’m not comfortable with how this is calculated. There ought to be a better way to handle this, e.g. by inspecting `sys.path` for common ancestors.
Does this really need to be a global? Can it not be a property on the `VarsModule` instead>
```suggestion self._display.debug("recursive_group_vars - Traversing dir : %s with groups : %s" % (path, to_text(groups))) ```
Try using `.format()` or `%s` formatting instead: ```suggestion self._display.debug("recursive_group_vars - Matched file : %s" % to_text(found)) ```
please wrap {}
This could be simplified to match the implementation in `_sqlite_datetime_extract()`: ```suggestion month_in_quarter = ceil(dt.month / 3) ```
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Does this really need to be a global? Can it not be a property on the `VarsModule` instead>
```suggestion self._display.debug("recursive_group_vars - Traversing dir : %s with groups : %s" % (path, to_text(groups))) ```
Try using `.format()` or `%s` formatting instead: ```suggestion self._display.debug("recursive_group_vars - Matched file : %s" % to_text(found)) ```
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
immediatelly -> immediately
Do we need to define `async_generator` in `__aiter__`? ```python async def _async_generator(self): # Generators don't actually start running until the first time you call # next() on them, so we make the generator object in the async thread # and then repeatedly dispatch to it in a sync thread. sync_generator = self.__iter__() # So, you can't raise StopIteration up through sync_to_async as # too much of the Python async system was originally built on # generators. Instead, we capture it inside a custom sync function # and change it to an exception we *can* propagate. # We should probably move this logic inside asgiref at some point. def custom_next(gen): try: return next(gen) except StopIteration: raise StopAsyncIteration() while True: try: yield await sync_to_async(custom_next)(sync_generator) except StopAsyncIteration: return # Note: __aiter__ is a *synchronous* method that has to then return an # *asynchronous* iterator/generator. Thus, we nest an async generator # inside it. # Also note: This is a generic iterable converter for now, and is going to # suffer a performance penalty on large sets of items due to the cost of # crossing over the sync barrier each time. We should write custom ones # for each Iterable subclass, but we'll need some work in Compiler first. def __aiter__(self): return self._async_generator() ```
okay, but would be helpful to say _why_ we need to always return True.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
do we really need that `is not None` check? `check_token` should return `False` for None tokens.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
immediatelly -> immediately
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
we want want -> we want
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
```suggestion item, fields=fields, using=self.db, ```
Can you re-warp this block to 79 chars? (First line is too short.)
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
we want want -> we want
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Can you re-warp this block to 79 chars? (First line is too short.)
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
immediatelly -> immediately
Do we need to define `async_generator` in `__aiter__`? ```python async def _async_generator(self): # Generators don't actually start running until the first time you call # next() on them, so we make the generator object in the async thread # and then repeatedly dispatch to it in a sync thread. sync_generator = self.__iter__() # So, you can't raise StopIteration up through sync_to_async as # too much of the Python async system was originally built on # generators. Instead, we capture it inside a custom sync function # and change it to an exception we *can* propagate. # We should probably move this logic inside asgiref at some point. def custom_next(gen): try: return next(gen) except StopIteration: raise StopAsyncIteration() while True: try: yield await sync_to_async(custom_next)(sync_generator) except StopAsyncIteration: return # Note: __aiter__ is a *synchronous* method that has to then return an # *asynchronous* iterator/generator. Thus, we nest an async generator # inside it. # Also note: This is a generic iterable converter for now, and is going to # suffer a performance penalty on large sets of items due to the cost of # crossing over the sync barrier each time. We should write custom ones # for each Iterable subclass, but we'll need some work in Compiler first. def __aiter__(self): return self._async_generator() ```
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
Does this need to be a separate method? Seems unnecessary to me.
List comprehensions create unnecessary throw-away lists in memory. It's better to use generator expressions because they are lazy. Also, this is a great case for using `all()`/`any()` (these two exit iterating through generators early, when possible): ```suggestion return all(part != ".." for part in path.split(os.sep)) ```
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
we want want -> we want
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
we want want -> we want
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
`django/core/files/copy.py:28:37: E127 continuation line over-indented for visual indent` pep8 wants you to indent it like this: ``` fd = os.open(new_file_name, os.O_WRONLY | os.O_CREAT | getattr(os, 'O_BINARY', 0) | (not allow_overwrite and os.O_EXCL or 0)) ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
It doesn't make sense to turn a unicode string into a unicode string. It's just `str(str(''))`, which is probably not what you want. Maybe you wanted to turn bytes into text here? In such case check'd be against `binary_type` and the translation should use `to_text()` shim.
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
Curious what the behavior would be if the name/namespace/apiversion/kind were provided at the top level and here and did not match.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
This should be `RemovedInDjango50Warning` I think.
I suggested this realiasing for tests only, I'd prefer a `if six.PY3 unquote_to_bytes() else unquote()` in the actual function. It helps with comprehension.
Please remove `weakref_backports.py` and its mention in `setup.cfg`.
a OrderedSet, like @timgraham suggested
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
Does this need to be a separate method? Seems unnecessary to me.
we want want -> we want
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
we want want -> we want
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
set the safe
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
Should also include `block_size` and `parallelism`
Should also update based on `block_size` and `parallelism`
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
okay, but would be helpful to say _why_ we need to always return True.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Can you re-warp this block to 79 chars? (First line is too short.)
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
I would chop blank lines in this test.
Chop `Ensure that`.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
`import botocore` will make this code a lot more consistent with most other boto3-based ansible modules
I suggested this realiasing for tests only, I'd prefer a `if six.PY3 unquote_to_bytes() else unquote()` in the actual function. It helps with comprehension.
Please remove `weakref_backports.py` and its mention in `setup.cfg`.
Maybe even in advance with the current form.
Maybe: ```python self.assertEqual(len(self.selenium.find_elements( By.CSS_SELECTOR, '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]', )), 1) ``` or ```python selector = '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]' self.assertEqual(len(self.selenium.find_elements(By.CSS_SELECTOR, selector)), 1) ```
This should go to the 2nd commit :pick:
Yeah, I had the same problem. I tried changing the exception type raised in `templar.template()` and catching that here, but still couldn't get it quite right. Seems like putting it in `-v` is an improvement over what we have now until we can come up with something better.
I think it would be more helpful to the user to show them both errors by default rather than hiding one in `-v`. Ideally we could have templating errors take precedence over loop errors and only display the templating error first, but that may not make sense in all situations. If we don't want to display both as was done originally, then I'm fine with the current use of `-v` rather than using debug since debug is information overload for users.
this might end up confusing users as to which error produced the failure, i suggest pushing the conditional error into a debug statement
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
`else` can be removed, i.e.: ```python ... elif end is None: return self.UNBOUNDED_FOLLOWING raise ValueError('Illegal argument for end, must be either a positive integer, zero or None') ```
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
Should have a trailing dot. (Only the short_description must not have one)
I'd go for `try/except IOError` in order to make a point that variable initialized above is in fact a fallback.
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
They are helpful when using (i)pdb.
Right, I think we could use model fields as a parallel -- we don't include all options a field is initialized with in the `__repr__()`. Here's the implementation: ``` def __repr__(self): """Display the module, class, and name of the field.""" path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__) name = getattr(self, 'name', None) if name is not None: return '<%s: %s>' % (path, name) return '<%s>' % path ``` So I'm +1 to not implementing a custom `__repr__()` for each subclass unless someone can present a counter argument. \cc @akki I created https://github.com/django/django/pull/8643 to remove `BrinIndex.__repr__()`.
Do you think we're adding value with such complicated `__repr__` methods? I've thought maybe we should ditch worrying about including of Index's params in them and just let `Index.__repr__` show the basics. Does the repr should up anywhere important? I can't think of anywhere.
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
rather than custom caching with a dict, this might be clearer with a module-level function using `@lru_cache(maxsize=2)`, with the current value of `USE_TZ` as the only argument. It would save some lines and clarify it's a cache.
Is there any reason why this method accepts `level` and `md_device` as argument? IMHO, it would be natural to use `self.level` and `self.md_device` instead.
I moved this check to the `DurationExpression`.
This is not covered by tests, also raising an exceptions in user-defined functions is not really helpful for users: ```python django.db.utils.OperationalError: user-defined function raised exception ``` I think we should return `None` instead.
True, sorry for an undoable request. Folks can always use `sqlite3.enable_callback_tracebacks(True)` to see this message :shrug: .
They are helpful when using (i)pdb.
Maybe it will be better to raise `NotSupportedError` instead of `NotImplementedError`. I would say `Window expressions are not supported on this database backend`.
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
This is not strictly related with functional indexes, I'm going to move it to a separate PR.
Could be nice to fix and test this typo separately.
I was expecting to raise a ValueError if these conditions aren't met, similar to what we do with "Index names cannot be longer". I don't think it's a good idea to modify the user provided value as it seems like that would only cause confusion.
`Backend` supports negative precision, `SQLite` does not: ```suggestion raise ValueError('SQLite does not support negative precision.') ```
This line doesn't need to change. Passing `function='Max'` as a kwarg will do the right thing, since the super implementation will do the mixing of `self.extra` and `**kwargs` for you.
put closing parenthesis on the next line
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
They are helpful when using (i)pdb.
Maybe it will be better to raise `NotSupportedError` instead of `NotImplementedError`. I would say `Window expressions are not supported on this database backend`.
Ah. lambda is prettier though :). maybe we can run pep8 with ignore lambda error.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
I wouldn't exactly call a dictionary `list`.
```suggestion 'conflicts with specifying unique fields that can ' ```
```suggestion raise NotSupportedError( 'This database backend does not support updating ' 'conflicts with specifying unique fields that will ' 'trigger the upsert.' ) ```
```suggestion raise NotSupportedError( 'This database backend does not support ignoring conflicts.' ) ```
```suggestion 'conflicts with specifying unique fields that can ' ```
```suggestion raise NotSupportedError( 'This database backend does not support updating ' 'conflicts with specifying unique fields that will ' 'trigger the upsert.' ) ```
```suggestion raise NotSupportedError( 'This database backend does not support ignoring conflicts.' ) ```
As long as they both equals it shouldn't make a difference. By that I mean you should have a test asserts `Index('foo') == Index(F('foo'))` An alternative could be to defer that to `create_sql`.
I'd omit a blank line here.
put closing parenthesis on the next line
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
Maybe add an empty line above this one and give it a name, it seems like the `assert` task is just a parameter of the `openssl_certificate_info` one.
single line docstring is okay if it fits
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
They are helpful when using (i)pdb.
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
`else` can be removed, i.e.: ```python ... elif end is None: return self.UNBOUNDED_FOLLOWING raise ValueError('Illegal argument for end, must be either a positive integer, zero or None') ```
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Missing `=dict` on this and the next few lines
`del` is a builtin, not a function. These parens don't have to be here
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
They are helpful when using (i)pdb.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
They are helpful when using (i)pdb.
@wrouesnel CI failure due to PEP 8 issue: ``` 2017-01-28 07:26:38 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2.py:930:1: W293 blank line contains whitespace (legacy) ```
if min_count <=
```suggestion module.fail_json(msg="The following packages are absent in the currently booted rpm-ostree commit: %s" % ' '.join(pkgs)) ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
They are helpful when using (i)pdb.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
The current idiom might be required because some backends (perhaps third-party ones) choke on empty `params`. I'd keep it.
What do you think about ```python def __repr__(self): template = "<%(name)s: fields='%(fields)s'%(fastupdate)s%(gin_pending_list_limit)s>" template_values = { 'name': self.__class__.__name__, 'fields': ', '.join(self.fields), 'fastupdate': '', 'gin_pending_list_limit': '', } if self.fastupdate is not None: template_values['fastupdate'] = ', fastupdate=%s' % ('True' if self.fastupdate else 'False') if self.gin_pending_list_limit is not None: template_values['gin_pending_list_limit'] = ', gin_pending_list_limit=%d' % self.gin_pending_list_limit return template % template_values```
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
```suggestion raise ValueError('Error while adding new LUKS keyslot to %s: %s' ``` While you're at it ;)
```suggestion url_json = self._parse_json(self._html_search_regex(r'''<div\b[^>]+\bdata-item\s*=\s*(["'])(?P<videourls>\{.*})\1''', webpage, 'videourls', group='videourls', default='{}'), video_id, fatal=False) or {} ```
Right, I think we could use model fields as a parallel -- we don't include all options a field is initialized with in the `__repr__()`. Here's the implementation: ``` def __repr__(self): """Display the module, class, and name of the field.""" path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__) name = getattr(self, 'name', None) if name is not None: return '<%s: %s>' % (path, name) return '<%s>' % path ``` So I'm +1 to not implementing a custom `__repr__()` for each subclass unless someone can present a counter argument. \cc @akki I created https://github.com/django/django/pull/8643 to remove `BrinIndex.__repr__()`.
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
What do you think about ```python def __repr__(self): template = "<%(name)s: fields='%(fields)s'%(fastupdate)s%(gin_pending_list_limit)s>" template_values = { 'name': self.__class__.__name__, 'fields': ', '.join(self.fields), 'fastupdate': '', 'gin_pending_list_limit': '', } if self.fastupdate is not None: template_values['fastupdate'] = ', fastupdate=%s' % ('True' if self.fastupdate else 'False') if self.gin_pending_list_limit is not None: template_values['gin_pending_list_limit'] = ', gin_pending_list_limit=%d' % self.gin_pending_list_limit return template % template_values```
Do you think we're adding value with such complicated `__repr__` methods? I've thought maybe we should ditch worrying about including of Index's params in them and just let `Index.__repr__` show the basics. Does the repr should up anywhere important? I can't think of anywhere.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
"is_required=False and an initial value that's a file, renders..."
Minor but the `else` clause wrapping is unnecessary here given you return in the `except`.
no blank line needed
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
This one is a bit newer to CliBase, but also implemented verbatim in superclass
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
This seems random and can lead to flaky tests. So there is no way to measure latency while Trogdor task is running? For the rate limit test below we do wait for task to run.
"for working with retry limiting"
nit: doc how the output of `iperf` looks like. helps with understanding this code and regex.
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
```suggestion with open('/var/run/secrets/kubernetes.io/serviceaccount/token') as file: ```
Use `with open(` instead of `open(`
Please chop blank line.
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
should be `extra_context or {},` (include a trailing comma)
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
I would prefer to wrap value with `Value()` and compile `options` separately.
like diff = load_config(self._module, config_xml, [])
This seems random and can lead to flaky tests. So there is no way to measure latency while Trogdor task is running? For the rate limit test below we do wait for task to run.
"for working with retry limiting"
nit: doc how the output of `iperf` looks like. helps with understanding this code and regex.
This seems random and can lead to flaky tests. So there is no way to measure latency while Trogdor task is running? For the rate limit test below we do wait for task to run.
"for working with retry limiting"
nit: doc how the output of `iperf` looks like. helps with understanding this code and regex.
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
I would prefer to wrap value with `Value()` and compile `options` separately.
like diff = load_config(self._module, config_xml, [])
This can be simplified. Both Random and SystemRandom accept a seed value, in both cases the default value is None. So there is no need for a condition. The default value can be passed unconditionally
ditto ```suggestion ```
I don't see any need for this attribute.
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
I would prefer to wrap value with `Value()` and compile `options` separately.
like diff = load_config(self._module, config_xml, [])
This can be simplified. Both Random and SystemRandom accept a seed value, in both cases the default value is None. So there is no need for a condition. The default value can be passed unconditionally
ditto ```suggestion ```
I don't see any need for this attribute.
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
Inner functions are slow, especially for pypy - best to extract this!
Any problem with: ``` @property def media(self): ```
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
Inner functions are slow, especially for pypy - best to extract this!
Any problem with: ``` @property def media(self): ```
This change breaks MTVServicesEmbeddedIE
It's an attribute so folks can try to change it dynamically. I would add `if self.default_bounds and ..`
We should omit `default_bounds` when the default value is used: ```suggestion if self.default_bounds and self.default_bounds != '[)': kwargs['default_bounds'] = self.default_bounds ```
Any problem with: ``` @property def media(self): ```
Inner functions are slow, especially for pypy - best to extract this!
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
I guess `get_admin_readonly_field()` could take `response` instead of `response.context['adminform']`.
I don't think this assertion is necessary -- if it's None we'll get an error in the next assertion which should be just as easy to debug.
it should also check if it can write there
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
This bare `except` will catch anything, including the exception that marks a failing test, I think :-) Better to use `assertRaises` and explicitly assert that the specific expected uncaught exception bubbles up.
it should also check if it can write there
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
This bare `except` will catch anything, including the exception that marks a failing test, I think :-) Better to use `assertRaises` and explicitly assert that the specific expected uncaught exception bubbles up.
it should also check if it can write there
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
This bare `except` will catch anything, including the exception that marks a failing test, I think :-) Better to use `assertRaises` and explicitly assert that the specific expected uncaught exception bubbles up.
This bare `except` will catch anything, including the exception that marks a failing test, I think :-) Better to use `assertRaises` and explicitly assert that the specific expected uncaught exception bubbles up.
This doesn't allow the caller to cancel downtime by scope. _get_downtime returns an empty dictionary when id is not specified. It'd be great if this was changed to require id or scope instead of just id.
also need to check whether the workspace is name or resource id
Minor but I'd move this control flow block after the `weights` one to match the args order.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
> scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum You missed the parentheses.
I don't see a need for string interpolation in cases like this.
Minor but I'd move this control flow block after the `weights` one to match the args order.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
> scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum You missed the parentheses.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
TBH this is not what I suggested, I wanted to use `mocked_mode` to keep code DRY. I pushed edits.
I would override `clean()` as described in the ticket, e.g. ```python class PubForm(forms.ModelForm): mode = forms.CharField(max_length=255, required=False) mocked_mode = None def clean(self): self.cleaned_data['mode'] = self.mocked_mode return self.cleaned_data class Meta: model = PublicationDefaults fields = ('mode',) default_mode = 'di' pub_form = PubForm({}) pub_form.mocked_mode = 'de' pub = pub_form.save(commit=False) ... ```
You need to wrap the second instantiation in its own assertRaises to actually test it.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Can you please run `pages_per_range` through `quote_value()` (internal function on the schema editor).
The usual pattern is to implement `get_source_expressions` and `set_source_expressions`. ```python def get_source_expressions(self): return [self.config] def set_source_expressions(self, expressions): self.config, = expressions
`extra.get()` returns `None` by default, so we can simplify this: ```python self.options = extra.get('options') ```
IMO we should check options against PostreSQL names.
`# Without form data` seem sufficient.
and please format it with indent, so it's more clear
add this condition also to lin 2063
In Python, it's common to include docstrings as per PEP 257: ```suggestion def fake_now(monkeypatch): """Patch `datetime.datetime.now()` to return a deterministic value.""" ```
FYI when you accept the suggested changes using GitHub UI, it preserves the authorship of the patch.
```suggestion short_description: Execute tasks inside a VM via VMware Tools ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
`# Without form data` seem sufficient.
and please format it with indent, so it's more clear
add this condition also to lin 2063
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
```not (foo is None)``` => ```foo is not None```
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Do we need to call `list(fields)` here? :thinking:
Few naming suggestions: `ordering_element` -> `expr` `ord_sql` -> `expr_sql` `ord_sql_params` -> `expr_params` `additional_sql_params` -> `ordering_params` `ord_clauses` -> `ordering_expr_sql`
We can ignore `name`, `path`, and `args`, e.g. `*_, kwargs = field.deconstruct()`
Chop blank line.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
I think some caching would make sense here.
The main issue here is that overriding `DATABASE_ROUTERS` doesn't allow passing initialization arguments to the specified classes hence why I suggested overriding `routers` directly. Another solution could be to make `Router` depend on a class attribute instead and override it in the loop: ``` python class Router(object): target = None def db_for_read(self, model, **hints): return self.target db_for_write = db_for_read @override_settings(DATABASE_ROUTERS=['admin_views.test_multidb.Router']) def test_foo(self): for db in connections: Router.target = db ... ```
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
I think some caching would make sense here.
The main issue here is that overriding `DATABASE_ROUTERS` doesn't allow passing initialization arguments to the specified classes hence why I suggested overriding `routers` directly. Another solution could be to make `Router` depend on a class attribute instead and override it in the loop: ``` python class Router(object): target = None def db_for_read(self, model, **hints): return self.target db_for_write = db_for_read @override_settings(DATABASE_ROUTERS=['admin_views.test_multidb.Router']) def test_foo(self): for db in connections: Router.target = db ... ```
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
I think some caching would make sense here.
The main issue here is that overriding `DATABASE_ROUTERS` doesn't allow passing initialization arguments to the specified classes hence why I suggested overriding `routers` directly. Another solution could be to make `Router` depend on a class attribute instead and override it in the loop: ``` python class Router(object): target = None def db_for_read(self, model, **hints): return self.target db_for_write = db_for_read @override_settings(DATABASE_ROUTERS=['admin_views.test_multidb.Router']) def test_foo(self): for db in connections: Router.target = db ... ```
```suggestion f'site={self.admin_site!r}>' ) ```
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
single line as above
use a single line or use hanging indent (we avoid non-4 space indents)
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
single line as above
use a single line or use hanging indent (we avoid non-4 space indents)
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Could you also change this line for me? ```diff - Cast(expression, FloatField()) if not isinstance(expression.output_field, FloatField) + Cast(expression, FloatField()) if isinstance(expression.output_field, IntegerField) ``` Don't forget to import `IntegerField`.
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Could you also change this line for me? ```diff - Cast(expression, FloatField()) if not isinstance(expression.output_field, FloatField) + Cast(expression, FloatField()) if isinstance(expression.output_field, IntegerField) ``` Don't forget to import `IntegerField`.
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
I'd suggest this for the indentation: ```python return [ force_text( capi.get_field_name(capi.get_field_defn(self._layer._ldefn, i)), self.encoding, strings_only=True, ) for i in range(self.num_fields) ] ``` Any concern about having no tests for the `self.encoding, strings_only=True` bit? I'm not sure we would expect non-string values in the first place? Also, at least on my system, there are no failures with it removed here or in `layer_name` above.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I don't see a need for string interpolation in cases like this.
Right, but the order in which you're doing things would at a glance result in the not-uncommon case of, eg `foo (cr)(lf)` not being properly treated, since the break `sub` wouldn't see that, but the char drop would remove the (cr), leaving a line ending that wouldn't format the right way.
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
flake8 complains about missing spaces around `*`
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I don't see a need for string interpolation in cases like this.
I'd suggest this for the indentation: ```python return [ force_text( capi.get_field_name(capi.get_field_defn(self._layer._ldefn, i)), self.encoding, strings_only=True, ) for i in range(self.num_fields) ] ``` Any concern about having no tests for the `self.encoding, strings_only=True` bit? I'm not sure we would expect non-string values in the first place? Also, at least on my system, there are no failures with it removed here or in `layer_name` above.
I think `name.rsplit('-', 1)[-1]` is easier to read.
I don't see a need for string interpolation in cases like this.
I'd suggest this for the indentation: ```python return [ force_text( capi.get_field_name(capi.get_field_defn(self._layer._ldefn, i)), self.encoding, strings_only=True, ) for i in range(self.num_fields) ] ``` Any concern about having no tests for the `self.encoding, strings_only=True` bit? I'm not sure we would expect non-string values in the first place? Also, at least on my system, there are no failures with it removed here or in `layer_name` above.
I think `name.rsplit('-', 1)[-1]` is easier to read.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
Chop the blank lines
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
Playlist metadata must not be fatal.
Playlist id and title should not be fatal.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
I would change this to a `NotSupportedError`, e.g. ```python raise NotSupportedError( 'Bulk create a multi-table inherited model is not supported ' 'on this database backend.' ) ```
single line as above
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
Chop the blank lines
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
here you need just a 'steps' not whole module as well.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
Chop the blank lines
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
here you need just a 'steps' not whole module as well.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
No worries :)
```suggestion Test that the returned value for timezone consists of only uppercase ```
Thanks. This PR is assigned to the 2.12 milestone, which we'll be going through after creating the stable-2.11 branch (which will be done when 2.11 RC1 comes out).
This could be shortened to: ```python if str(retry[1]).startswith('inf'): ```
WDYT about adding `or self.title` here? ``` python self.title = title or self.title or self.lookup_title ``` This would add support for the following: ``` python class MyStaffFilter(BooleanFieldListFilter): title = "By can haz admin" # no effect :( overwritten in __init__ @admin.register(User) class UserAdmin(UserAdminBase): list_filter = ( ("is_staff", MyStaffFilter), ) ```
Plz also use `match` arg here
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
You should probably expect unicode strings
When referring to `bulk_save()` in messages, include parenthesis (and periods).
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Do we need to call `list(fields)` here? :thinking:
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
you can use `state` to avoid the 'or' to the user
single line as above
In Python3, `super()` is enough.
I think that this docstring should be simplified. There is no need to mention that this originated from the admin site.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
As Collin said, slightly longer lines are okay rather than awkward wrappings like this.
You can skip the blank lines in these tests as three lines long isn't too difficult too read with spaces.
Please use assertRaisesMessage to verify this is the ValueError we expect.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Since Ansible subscribes to unicode sandwich, this should be the callers' (actually, where the data enters the system) responsibility.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
Since for Python, a non-empy string is True, you can just do: `if self.params['esxi_hostname']:`.
version added requires quotes, otherwise it will be processed as number
```suggestion I(minvalue), I(maxvalue), I(start), I(cache), I(cycle), I(rename_to), ```
Use `==` to compare booleans. The `is` test should *only* be used when you really want to compare identities of objects! Finally, there's no need to compare a boolean to `True` or `False` explicitly; simply write `elif self._has_migs(local):`.
Don't you simply want an `else:` here? Or do you explicitly want to have the case that you call `self._has_migs(local)` twice in a row (without a sleep inbetween), and once it returns `False` and then `True`? Otherwise this `elif` makes no sense.
Ah, I didn't knew there was a template :) Well, in that case, keep it. It doesn't really hurt.
I think it's a better API; a custom manager could be using its name in a `__new__` method.
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
```suggestion type: list suboptions: ```
Why not use keyed groups and let the users decide themselves whether they want to create such a group, instead of creating it by default? (There should be an example of how to do this if the user is suposed to do it by herself.)
Thanks for that note ewen. I learned something!
`return migs != 0` is equivalent ot lines 380 to 382.
Use `==` to compare booleans. The `is` test should *only* be used when you really want to compare identities of objects! Finally, there's no need to compare a boolean to `True` or `False` explicitly; simply write `elif self._has_migs(local):`.
Don't you simply want an `else:` here? Or do you explicitly want to have the case that you call `self._has_migs(local)` twice in a row (without a sleep inbetween), and once it returns `False` and then `True`? Otherwise this `elif` makes no sense.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Same question for dropping lambda here as well.
Rather than use a `lamdba` here, it would be better to use a generator expression for clarity ```suggestion lines = line.split('::::')[1].split(';') tmp = dict(x.split('=') for x in lines) ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
Use of the mixin isn't ideal here since there a lot of unrelated tests which aren't affected. If we have some other deprecation that affects these tests, we might miss updating them.
This version downgrade is not acceptable. This module can call update_stack(), which is was added in 1.8.0, so you'd be breaking others by allowing an older version. Please don't change required versions.
Oh wow, I *totally* misread this version as a LOWER version. I should not review before at least 2 cups of coffee! Apologies. Yes, upgrading the version for a new feature is fine. However, we should only require the newer version if a tag is specified. Users not specifying a tag shouldn't be required to upgrade shade.
```suggestion item, fields=fields, using=self.db, ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
```suggestion item, fields=fields, using=self.db, ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
```suggestion item, fields=fields, using=self.db, ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
Historic moment! I don't see a reason why we shouldn't use them.
Is it too late to move the conversion of `auto` to an integer to a post-processing step (e.g. your `get_num_test_processes()` function)? I feel like the `parallel_type` function's job here should only be to check that the value equals `auto` if the value is a string, but not to apply the environment-dependent business logic to convert `auto` to a number. (I also see that `get_num_test_processes()` is already calling `multiprocessing.cpu_count()`, so there may be some duplication of logic with the way things are currently structured.)
version added requires quotes, otherwise it will be processed as number
Do we need to define `async_generator` in `__aiter__`? ```python async def _async_generator(self): # Generators don't actually start running until the first time you call # next() on them, so we make the generator object in the async thread # and then repeatedly dispatch to it in a sync thread. sync_generator = self.__iter__() # So, you can't raise StopIteration up through sync_to_async as # too much of the Python async system was originally built on # generators. Instead, we capture it inside a custom sync function # and change it to an exception we *can* propagate. # We should probably move this logic inside asgiref at some point. def custom_next(gen): try: return next(gen) except StopIteration: raise StopAsyncIteration() while True: try: yield await sync_to_async(custom_next)(sync_generator) except StopAsyncIteration: return # Note: __aiter__ is a *synchronous* method that has to then return an # *asynchronous* iterator/generator. Thus, we nest an async generator # inside it. # Also note: This is a generic iterable converter for now, and is going to # suffer a performance penalty on large sets of items due to the cost of # crossing over the sync barrier each time. We should write custom ones # for each Iterable subclass, but we'll need some work in Compiler first. def __aiter__(self): return self._async_generator() ```
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
I feel like you're just testing argparse here, and this test can be removed. We don't test parsing any other arguments, since we can assume argparse works as advertised.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
This test is too specific, IMO. It's should be enough to check that `SECRET_KEY` is lazy validated.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
A little confusing to set `local_temp_dir = "/tmp"` since it in theory should never be set to `/tmp` I think this line is actually not necessary since `local_temp_dir` can be set inside the try block, and be available to the surrounding scope
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
I don't see any need for this attribute.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
Missing `=dict` on this and the next few lines
`load_config` doesn't return anything https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ios.py#L121
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
`items = value.split(self.delimiter) if value else []` is slightly faster.
Don't mix unrelated changed in single PR.
This regex does not make any sense.
Remove all pointless changes.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
Put the } on the next line and add a trailing comma on this line. That's our convention to ease later adding more items to a dictionary, tuple, etc., if needed.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
Put the } on the next line and add a trailing comma on this line. That's our convention to ease later adding more items to a dictionary, tuple, etc., if needed.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
This one could do with assigning to a variable: ```suggestion path = base_path / f self.assertTrue(path.exists()) with path.open() as fh: ```
```suggestion files = sorted(self.storage_dir.joinpath("dotted.path").iterdir()) self.assertFalse(self.storage_dir.joinpath("dotted_.path").exists()) ```
```suggestion files = sorted(self.storage_dir.joinpath("dotted.path").iterdir()) self.assertFalse(self.storage_dir.joinpath("dotted_.path").exists()) ```
We want to save file with the `symlink.txt` name so this assertion doesn't have much value IMO. I would check that the new file exists.
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
This could be moved inside the conditional that follows to avoid checking when there are no vendored modules.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
The usual pattern is ``` try: import IPython except ImportError: IPython = None ``` No need for an extra variable.
also, this should not be by default as it changes current operations and might surprise users that expect it to fail when the path is 'polluted'.
Sure. We can address this in a follow up PR.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
We want to save file with the `symlink.txt` name so this assertion doesn't have much value IMO. I would check that the new file exists.
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
Chop `Ensure that`.
I would chop blank lines in this test.
`enumerate` on for range.
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
add trailing comma
include trailing ,
As with `@raise_deprecation`, this should be a module-level utility, not a method on the class.
could switch to single quotes for consistency
`always_text` is gone.
A minor matter of style, but "GO below this line" isn't needed. All you need is the section header. I'd also suggest making the header more prominent - precede and follow the header text line with a line of `####` that goes the full width (or to col 76, anyway - 1 indent back from max line length) of the code. ``` ########################################################################### # Deprecated methods ########################################################################### ```
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
add trailing comma
include trailing ,
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
include trailing ,
add trailing comma
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
add trailing comma
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
Delete this blank line.
Yeah that's what I suspected too. Stupid SQL.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
In theory a locale dependant pattern could be provided and `locale.setlocale` be called but this is really unlikely.
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
use x.items() here, no need for the iteritems import
use tags.items() here, no need for iteritems import
In theory a locale dependant pattern could be provided and `locale.setlocale` be called but this is really unlikely.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
It's already stripped: ```suggestion (PODMAN_OUTPUT, ''), ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
In this case, I think a ternary is more complicated to read than: ``` if srid == -1: srid = None ```
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
Is `plan` meant as the second argument? Looks like we're missing a test for this branch.
This should be a feature flag as CockroachDB (which tries to emulate PostgreSQL in a lot of ways) has the same restriction.
I don't see a need for string interpolation in cases like this.
```suggestion type: list suboptions: ```
This should be a feature flag as CockroachDB (which tries to emulate PostgreSQL in a lot of ways) has the same restriction.
I don't see a need for string interpolation in cases like this.
```suggestion type: list suboptions: ```
Maybe you can use `subTest` here, e.g.: ```python for model, pk_pos in ( (Book, -1), # Unmanaged origin model. (Author, 0), # Unmanaged related model. ): with self.subTest(model=model, pk_pos=pk_pos): with mock.patch.object(model._meta, 'managed', False): _, _, grouping = queryset.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(grouping), len(model._meta.fields) + 1) self.assertIn(Author._meta.pk.name, grouping[pk_pos][0]) for index, field in enumerate(model._meta.fields): self.assertIn(field.name, grouping[index + pk_pos + 1][0]) assert_queryset_results(queryset) ``` but I'm not convinced that it isn't less readable.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
consider assertRaisesMessage to make the test a bit more specific.
chop "one of" add comma before "or"
put closing parenthesis on the next line
IMO it will me more readable to move `base` outside, also we resolve `F()` expressions twice (line 28 & 29), so maybe, e.g. ```python if isinstance(expression, str): expression = F(expression) if isinstance(expression, F): expression = base.resolve_expression(query=query, simple_col=True) else: expression = expression.resolve_expression(query=query) ``` Moreover I think we don't need to iterate twice over the expressions: ```python for expression, operator in self.expressions: ... expressions.append('%s WITH %s' % (sql % params, operator) return expressions ```
This could fit on a single line: `# Subqueries must use a different set of aliases than the outer query.`
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
1 line is okay --- we prefer longer lines up to 119 characters when it helps readability.
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
Is the `sorted()` actually useful here? You're adding the keys to a standard python dict, which is unsorted by nature.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
1 line is okay --- we prefer longer lines up to 119 characters when it helps readability.
Subtests can also be used here.
if datastore already exists
single line as above
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
remove this assertion? (see 90af278203963e3e3f96e443971cd38a2dad34e4)
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
As Collin said, slightly longer lines are okay rather than awkward wrappings like this.
Yes, I think Django would be obviously broken in such a configuration anyway.
I don't think there's a use case for `settings.AUTHENTICATION_BACKENDS` without any backends that have a `get_user()` method.
I would chop blank lines in this test.
Chop `Ensure that`.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
I would chop blank lines in this test.
Chop `Ensure that`.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
missing space after the second comma (please check code with flake8)
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
comma after tuple
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
You want to do it the other way around; no adjustments should be required to the base schema adaptor. In order to achieve that you'll want to have the PostGIS `_create_index_sql` method *not* pass `fields` but `expressions` when necessary ```python def _create_index_sql(self, model, *, fields=None, **kwargs): if fields is None or len(fields) != 1 or not hasattr(fields[0], 'geodetic'): return super()._create_index_sql(model, fields=fields, **kwargs) field = fields[0] template = None if field.geom_type == 'RASTER': # For raster fields, wrap index creation SQL statement with ST_ConvexHull. # Indexes on raster columns are based on the convex hull of the raster. template = self.rast_index_wrapper % '%(expressions)s' elif field.dim > 2 and not field.geography: # Use "nd" ops which are fast on multidimensional cases template = "%%(expressions)s %s" % self.geom_index_ops_nd expressions = None if template is not None: fields = None expressions = [Func(Col(field.column), template=template)] using = ' USING %s' % self.geom_index_type return super()._create_index_sql(model, fields=fields, expressions=expressions, using=using) ```
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
You want to do it the other way around; no adjustments should be required to the base schema adaptor. In order to achieve that you'll want to have the PostGIS `_create_index_sql` method *not* pass `fields` but `expressions` when necessary ```python def _create_index_sql(self, model, *, fields=None, **kwargs): if fields is None or len(fields) != 1 or not hasattr(fields[0], 'geodetic'): return super()._create_index_sql(model, fields=fields, **kwargs) field = fields[0] template = None if field.geom_type == 'RASTER': # For raster fields, wrap index creation SQL statement with ST_ConvexHull. # Indexes on raster columns are based on the convex hull of the raster. template = self.rast_index_wrapper % '%(expressions)s' elif field.dim > 2 and not field.geography: # Use "nd" ops which are fast on multidimensional cases template = "%%(expressions)s %s" % self.geom_index_ops_nd expressions = None if template is not None: fields = None expressions = [Func(Col(field.column), template=template)] using = ' USING %s' % self.geom_index_type return super()._create_index_sql(model, fields=fields, expressions=expressions, using=using) ```
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
You can drop the `.all()` here.
super nit: the string is slightly malformatted. The script displays: Enter reviewers in the format of "name1 <email1>", "name2 <email2>: Also, Its not clear if I should actually type the quotes when entering reviewers.
Please ignore, my suggestion is invalid syntax.
This is always a tough question, and I'm not sure what's the best solution :) In Ansible, things are usually lower-case. I guess you have to decide what you want in the end :)
How about lower-case? ```suggestion choices: [ 'dns', 'email', 'manual', 'webserver'] ```
This shouldn't be automatically adjusted, just a note saying refs style must be 64.
I don't see a need for string interpolation in cases like this.
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
we should also return if we both delegate executions and delegate_facts
```suggestion item, fields=fields, using=self.db, ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
I feel like it might be a good idea to eventually require that one or both of these be set explicitly, rather than relying on these hardcoded defaults. (I can't completely articulate why, though, so maybe it's not that good an idea.)
returning `b''` for BinaryField (as original code did) should be required under Python 3, IIRC.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
I feel like it might be a good idea to eventually require that one or both of these be set explicitly, rather than relying on these hardcoded defaults. (I can't completely articulate why, though, so maybe it's not that good an idea.)
returning `b''` for BinaryField (as original code did) should be required under Python 3, IIRC.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
```suggestion item, fields=fields, using=self.db, ```
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
```suggestion item, fields=fields, using=self.db, ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
`enumerate` on for range.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
```suggestion module.exit_json(changed=True,**camel_dict_to_snake_dict(res))) ```
Please add a docstring explaining this.
Oh, I see `raise_last_exception` also looks like it moved. Maybe it makes sense to do some reordering to keep the diff a bit smaller. Maybe not.
Do we still need kind? For service I think it should always be v1
extra space after `*` needs to be removed here too
extra space after `*` needs to be removed
nit: remove empty line
```suggestion - Facts representing the current state of the node. Matches the C(docker node inspect) output. ```
You should mention instead of this that the required API version is 1.24. ```suggestion - "Docker API >= 1.24" ```
```suggestion - Returns whether the node exists in docker swarm cluster. ``` I don't think it is necessary to mention `Module will fail if executed on a non-manager node` here, since you already mention `Must be executed on a host running as Swarm Manager.` in the module's description.
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
You can achieve this same result output with `module.exit_json(changed=True,**camel_dict_to_snake_dict(execution))` which can be imported from `ansible.module_utils.ec2`. That will automatically cover if AWS ever starts returning additional keys from this API and is generally easier to maintain.
```suggestion module.exit_json(changed=True,**camel_dict_to_snake_dict(res))) ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
You can achieve this same result output with `module.exit_json(changed=True,**camel_dict_to_snake_dict(execution))` which can be imported from `ansible.module_utils.ec2`. That will automatically cover if AWS ever starts returning additional keys from this API and is generally easier to maintain.
Do we still need kind? For service I think it should always be v1
Please add a docstring explaining this.
Oh, I see `raise_last_exception` also looks like it moved. Maybe it makes sense to do some reordering to keep the diff a bit smaller. Maybe not.
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
Also make the comparison case-insensitive, i.e. ```python if self.index_type.lower() != 'gist': ```
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
IMO it will me more readable to move `base` outside, also we resolve `F()` expressions twice (line 28 & 29), so maybe, e.g. ```python if isinstance(expression, str): expression = F(expression) if isinstance(expression, F): expression = base.resolve_expression(query=query, simple_col=True) else: expression = expression.resolve_expression(query=query) ``` Moreover I think we don't need to iterate twice over the expressions: ```python for expression, operator in self.expressions: ... expressions.append('%s WITH %s' % (sql % params, operator) return expressions ```
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Also make the comparison case-insensitive, i.e. ```python if self.index_type.lower() != 'gist': ```
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Also make the comparison case-insensitive, i.e. ```python if self.index_type.lower() != 'gist': ```
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Also make the comparison case-insensitive, i.e. ```python if self.index_type.lower() != 'gist': ```
IMO it will me more readable to move `base` outside, also we resolve `F()` expressions twice (line 28 & 29), so maybe, e.g. ```python if isinstance(expression, str): expression = F(expression) if isinstance(expression, F): expression = base.resolve_expression(query=query, simple_col=True) else: expression = expression.resolve_expression(query=query) ``` Moreover I think we don't need to iterate twice over the expressions: ```python for expression, operator in self.expressions: ... expressions.append('%s WITH %s' % (sql % params, operator) return expressions ```
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
point -> points
point -> points
It will be `django.contrib.postgres.constraints.XXX` but I don't think that's an issue for core constraints we return `django.db.models.XXX`.
Why we don't use `super().deconstruct()`? ```python def deconstruct(self): path, args, kwargs = super().deconstruct() kwargs['expressions'] = self.expressions if self.condition is not None: kwargs['condition'] = self.condition if self.index_type != 'GIST': kwargs['index_type'] = self.index_type return path, args, kwargs ```
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
please fail if required stuff is null
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
test failure says this should be `(None, None)`
I believe this relates to team accounts. Users are able to create an image for their account and not expose it to additional team members.
Might be worth adding a `note:` to say that only the hash of the file is used for comparisons, not any filemode/permissions/etc.
So we have to probably use try-except blocks for all the stuff that could fail. Nowadays with python3 you'd be doing something like: ```python from ansible.module_utils.pycompat24 import get_exception .... try: <whatever action that could fail> except: e = get_exception() module.fail_json(msg=str(e))
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
The final command should probably return its stdout, stderr and rc back to the playbook.
test failure says this should be `(None, None)`
So we have to probably use try-except blocks for all the stuff that could fail. Nowadays with python3 you'd be doing something like: ```python from ansible.module_utils.pycompat24 import get_exception .... try: <whatever action that could fail> except: e = get_exception() module.fail_json(msg=str(e))
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
There is a much easier way to do this, by using the index in the list. Something like: ```python unit = size[-1] units = list('b', 'k', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y') try: multiplier = 1024**units.index(unit) except ValueError:: e = get_exception() module.fail_json(msg="No valid size unit specified. %s" % e) ```
You could make the unit mandatory (which is what I would do), or you could allow no unit (which means in bytes) and in that case you will have to consider that case as well. (i.e.if unit is a digit)
That's up to you. There is no requirement to have a 1:1 mapping between the command and the Ansible interface. And I personally prefer to always have units (e.g. the AIX LV interface assumes no unit to mean MB, not MiB so...)
So we have to probably use try-except blocks for all the stuff that could fail. Nowadays with python3 you'd be doing something like: ```python from ansible.module_utils.pycompat24 import get_exception .... try: <whatever action that could fail> except: e = get_exception() module.fail_json(msg=str(e))
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
I am a bit scared by this. Because the module indicates it supports check-mode, but if I look at the code it seems to be doing all the stuff and only at the end appear to say there hasn't been a change. That cannot be right (it's dangerous!).
These will need to be module parameters if they need to be configurable. Constants are not available to modules.
Modules do not have access to get or set configuration values. An action plugin should be able to check the configuration before invoking the module, but I don't think that is something we're doing with any other modules currently. You may want to bring this up in tomorrow's Network Working Group meeting on IRC to see what thoughts the network team has on this.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
This error is raised when instantiating so we don't need to include a `route` in the message.
Can you re-warp this block to 79 chars? (First line is too short.)
i don't think we want roles in roles
This should always be true if the receiver is connected with `sender=migrations.RenameModel` as it is right now.
Yes and no. Keeping the output explicit feels easier to read.
Since the same result is expected as above, wouldn't it be clearer to save the output in a variable? Something like: ``` expected = ( "[ ] author_app.0001_initial\n" "[ ] book_app.0001_initial\n" "[ ] author_app.0002_alter_id\n" "[ ] mutate_state_b.0001_initial\n" "[ ] mutate_state_b.0002_add_field\n" ) ```
This doesn't look like it is tested.
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
This doesn't look like it is tested.
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
non existing -> nonexistent
It would help readability to use a name like "nonexistent_app" rather than "duth..".
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
It would help readability to use a name like "nonexistent_app" rather than "duth..".
non existing -> nonexistent
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
non existing -> nonexistent
It would help readability to use a name like "nonexistent_app" rather than "duth..".
Please use a single quote.
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
Why's that? It's non-obvious at first glance.
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
``` py self.assertTrue(r.closed) ```
up with Django imports
```suggestion updates.extend(line for line in set_commands if line not in config) ```
This should really be: ``` - Set custom DNS search domains. (Use I(dns_search) with C('') if you don't wish to set the search domain.) ```
(Same for the related options.)
Can it be simpler? E.g. without nic_device/device_type ```python for device in vm.config.hardware.device: if device.macAddress == mac: return device ```
Maybe wrapping mac comparison with try/except/pass will work on nonexistent attribute? Just to avoid additional iteration, though I still not fully understand how often are there cases when device with certain device type won't have macAddress attribute.
(Same for the related options.)
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
This will remove check for datacenter from line 215 ```suggestion dc_obj = self.find_datacenter_by_name(datacenter_name=self.params['datacenter']) if not dc_obj: self.module.fail_json(msg="Failed to find the datacenter %s" % self.params['datacenter']) objects = get_all_objs(content, vimtype, folder=dc_obj.networkFolder) ```
+1 for to_text
```suggestion updates.extend(line for line in set_commands if line not in config) ```
Maybe wrapping mac comparison with try/except/pass will work on nonexistent attribute? Just to avoid additional iteration, though I still not fully understand how often are there cases when device with certain device type won't have macAddress attribute.
Can it be simpler? E.g. without nic_device/device_type ```python for device in vm.config.hardware.device: if device.macAddress == mac: return device ```
Maybe wrapping mac comparison with try/except/pass will work on nonexistent attribute? Just to avoid additional iteration, though I still not fully understand how often are there cases when device with certain device type won't have macAddress attribute.
Can it be simpler? E.g. without nic_device/device_type ```python for device in vm.config.hardware.device: if device.macAddress == mac: return device ```
(Same for the related options.)
That does make sense. Thanks.
oh I see, it makes sense then.
I would not as .format breaks in older versions and we are trying to still keep this kind of module working on older machines
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
+1 for to_text
This will remove check for datacenter from line 215 ```suggestion dc_obj = self.find_datacenter_by_name(datacenter_name=self.params['datacenter']) if not dc_obj: self.module.fail_json(msg="Failed to find the datacenter %s" % self.params['datacenter']) objects = get_all_objs(content, vimtype, folder=dc_obj.networkFolder) ```
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Ah, i'd expect a bool to always be True/False, if that is not the case (no time to test really right now :)), then indeed, this needs to stay (and this goes for my other bool remarks)
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
+1 for to_text
I would add a flag to `Index`, e.g. `is_functional` that could be used here together with `supports_expression_indexes` to skip such indexes, e.g. ```python if not index.is_functional or self.connection.features.supports_expression_indexes: output.append(index.create_sql(model, self)) ``` Also we should return `None` in `_create_index_sql()` and `_delete_index_sql` if `index.is_functional` and `self.connection.features.supports_expression_indexes`
We already compare columns in: ```python old_field.column != new_field.column or ``` so we can simply ignore `db_column` in kwargs, e.g. ```python def _field_should_be_altered(self, old_field, new_field): _, old_path, old_args, old_kwargs = old_field.deconstruct() _, new_path, new_args, new_kwargs = new_field.deconstruct() # Ignore db_column to not alter when changing only a db_column but it's # the same as a field name. old_kwargs.pop('db_column', None) new_kwargs.pop('db_column', None) # Don't alter when changing only a field name. return ( old_field.column != new_field.column or (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs) ) ```
This test is too specific, IMO. It's should be enough to check that `SECRET_KEY` is lazy validated.
Would `functools.partial` work here? ```python from functools import partial bound_method = partial(method.__get__(self, type(self))) ```
Is `expanduser()` needed? Seems like it's done automatically.
Once again, exec is not needed here.
`yield from` is not allowed in async functions.
Yes, your version is simpler, Simon.
The variable name `shand` is non-descriptive
It would be better if we could refactor the control flow so we don't have to repeat these lines which also occur after the last else statement in this file.
Is there the potential that the response could be 200, but the JSON not include these keys? Maybe they should be guarded with try/except to avoid exceptions.
Our code formatting standards allow for 160 character width, move this onto the same line to make it more readable.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Does this check make sense now that we only handle it if it starts with a relative path? (ie if the prefix where there it would start with a slash anyways)
@jrwdunham I'm not an expert here, but from what I read the true assumption is that `SCRIPT_NAME` **never** ends with trailing slash. So in case you do not have subfolder, `SCRIPT_NAME` should be just empty/unset.
It would be useful to tell the user which `key` is invalid.
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
the module in general is just a thin api wrapper, not really that useful for users, I'm not against having an 'expert mode' but this is in addition to actual options usage.
couldn't -> can't
I'm not sure it really matters, but I'd put `self.ALLOW_BASE_THROTTLING` first.
Is there some other way other than doing a len on `self._workers`? With forking and your threading work this should be reliable, but is it possible that 3rd party process plugins in the future would not have a static length list? Maybe they pop and append, and this could catch at a point where it's not at the max.
`always_text` is gone.
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
Can we deprecate passing `None` in `errors` in a separate PR? and do this in advance. There is already a lot of changes in this patch, that should make it more readable and easier to review. I can try to refactor this out if you don't have time to keep working on this.
~~ use the shared open_url function, it takes care of many issues with python's ssl ~~
ignore it then, I stopped reading at import ssl, did not realize it is an encrypted tcp socket connection and assumed http/s
single line looks more readable here
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
I removed it.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
I removed it.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Drop the comma/space in `[FakeFieldFile(), ]`
```suggestion item, fields=fields, using=self.db, ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Drop the comma/space in `[FakeFieldFile(), ]`
```suggestion item, fields=fields, using=self.db, ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Drop the comma/space in `[FakeFieldFile(), ]`
```suggestion item, fields=fields, using=self.db, ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Drop the comma/space in `[FakeFieldFile(), ]`
```suggestion item, fields=fields, using=self.db, ```
Unless I missed something: - before: all `OSError` exceptions are converted to `CommandError`; in addition a specific message is added when the file already exists - after: only `FileExistsError` is converted to `CommandError`
IIRC raising CommandError prevents management commands from displaying a stack trace. This doesn't seem very important but I wanted to point out the change in behavior in case it was accidental.
I think we should use `relpath()` but only if it is below the working directory, e.g. ```diff diff --git a/django/core/management/templates.py b/django/core/management/templates.py index c7252a5ad2..db417443b2 100644 --- a/django/core/management/templates.py +++ b/django/core/management/templates.py @@ -65,6 +65,7 @@ class TemplateCommand(BaseCommand): self.validate_name(name) # if some directory is given, make sure it's nicely expanded + app_python_path = name if target is None: top_dir = path.join(os.getcwd(), name) try: @@ -77,6 +78,11 @@ class TemplateCommand(BaseCommand): if app_or_project == 'app': self.validate_name(os.path.basename(target), 'directory') top_dir = os.path.abspath(path.expanduser(target)) + # Use a relative path if it's below the current working + # directory, or an app name otherwise. + rel_path = os.path.relpath(top_dir) + if not rel_path.startswith('..'): + app_python_path = rel_path.replace('\\', '/').replace('/', '.') if not os.path.exists(top_dir): raise CommandError("Destination directory '%s' does not " "exist, please create it first." % top_dir) @@ -101,6 +107,7 @@ class TemplateCommand(BaseCommand): context = Context({ **options, + **({'app_python_path': app_python_path} if app_or_project == 'app' else {}), base_name: name, base_directory: top_dir, camel_case_name: camel_case_value, ```
```suggestion help=( 'Shuffle the order of test cases to help check that tests are ' 'properly isolated.' ), ) ```
ditto ```suggestion ```
Not exactly, we only changed the `parallel` to `1` when it was not given. Please see an example call :point_up:
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
2.6 or 2.7? Also you `requirements` listed here and the modules.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
2.6 or 2.7? Also you `requirements` listed here and the modules.
Again, error handling changed.
Sorry, these parameters are already checked in `save()` so there is no need to change these assertions.
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
Again, error handling changed.
Sorry, these parameters are already checked in `save()` so there is no need to change these assertions.
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
I think we can increase the readability with constant for `1` and `2`. ```python DAILY_COUNTER=1 WEEKLY_COUNTER=2 ``` And then you can just do `key=WEEKLY_COUNTER,`
Was there a `stop_node` method here before? It's a good idea to have both `stop_node` and `clean_node` defined. Or, if you expect the process to actually be gone by the time we hit the "stop" portion of the service lifecycle (`stop_node` is the "graceful shutdown" option), it's helpful to do a check that the process is actually gone (i.e. check that the actual state matches our expectations of what the state should be) and at least log a warning if the process is still running
Perhaps: ```suggestion def esxi_version_at_least(self, version): """ Check that the ESXi Host is at least a specific version number. Inputs: - version (tuple): a version tuple, for example (6, 7, 1) Returns: bool """ ``` Suggest moving into module_utils/vmware.py and providing a unit test.
Could you please use Python regex instead of external egrep command ? egrep command may not be installed on given system.
redundant parens `% (names)`
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
`yield from` is not allowed in async functions.
Does this need to be a separate method? Seems unnecessary to me.
I think `get_internal_type` is better to use.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
Thanks for the patch @Giebisch, I think we should adjust the `expected_outputs` instead to be properly formatted in order to ensure formatting is actually used. https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L90-L111 https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L124-L133 The adjustments made make the tests pass with and without the proposed changes.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
We need a trailing space to separate times from results, e.g. ``` test_order_index (schema.tests.SchemaTests) ... 0.000sok
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
> Why? 🤔 Do you mean that get() shouldn't be called in post()? We use this pattern in many places and I don't see anything wrong in it. Okay, maybe I'm not used to common flows in class-based views. > Is it not already applied when next_page is set? Yes it is applied in that case. Still, a user could: 1. Click "logout", see the "logged out" page 2. Open a new tab and login 3. Restart their browser 4. The browser resubmits the "logout" tab, and the user is logged out again. I guess this pattern was here before, and this could be a separate issue.
We need a trailing space to separate times from results, e.g. ``` test_order_index (schema.tests.SchemaTests) ... 0.000sok
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
Yes they do, but I think on restarting and being presented with confirm on top of a blank screen, most people would just click "yes, resubmit".
It's likely fine. 🤔 Let me have a play in the debugger tomorrow.
This is probably fine... We loose the **this thread** check but...
This unfortunately doesn't guarantee that all transactions are always rolled back. _dirty is never set if you run read-only queries in the default autocommit mode, yet transaction is started by any query (the cursor.is_dirty() checks if transactions are managed before setting ._dirty). It seems making sure ._rollback is called after every request would be a god idea if the connection isn't going to be persisted. Even better approach is to make the _dirty flag behave somewhat sanely. But this is not this issue's problem.
Minor but I'd move this control flow block after the `weights` one to match the args order.
use US spelling (behavior)
I see, thanks!
Minor but I'd move this control flow block after the `weights` one to match the args order.
use US spelling (behavior)
Can we check `fk_field` instead to avoid unnecessary queries? e.g. ```python for field in self._meta.private_fields:) if field.is_relation and hasattr(field, 'fk_field') and field.is_cached(self): if getattr(self, field.fk_field, None) is None: raise ValueError( "%s() prohibited to prevent data loss due to unsaved " "related object '%s'." % (operation_name, field.name) ) ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
use US spelling (behavior)
I see, thanks!
Minor but I'd move this control flow block after the `weights` one to match the args order.
use US spelling (behavior)
Can we check `fk_field` instead to avoid unnecessary queries? e.g. ```python for field in self._meta.private_fields:) if field.is_relation and hasattr(field, 'fk_field') and field.is_cached(self): if getattr(self, field.fk_field, None) is None: raise ValueError( "%s() prohibited to prevent data loss due to unsaved " "related object '%s'." % (operation_name, field.name) ) ```
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
They should always be the same but you might want to use `model._meta.object_name` instead.
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
No such meta field.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
No such meta field.
I would suggest to use the ungettext_lazy('%(number)d minute', ''%(number)d minutes', 'number') syntax, if possible.
This must be checked **before** any processing.
This must be checked **before** any processing.
This must be checked **before** any processing.
Duration calculation is incorrect.
This must be checked **before** any processing.
I would suggest to use the ungettext_lazy('%(number)d minute', ''%(number)d minutes', 'number') syntax, if possible.
This must be checked **before** any processing.
This must be checked **before** any processing.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Please turn this into a `dict`. Strings are a really horrible format for complex data such as this. Also, is there precisely one mount available per container? If podman is really trying to be compatible to docker, I cannot believe that.
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
`always_text` is gone.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
What kind of values are valid here? I would expect this to be `float` based on the `0.0` in the description.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
What kind of values are valid here? I would expect this to be `float` based on the `0.0` in the description.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
Please turn this into a `dict`. Strings are a really horrible format for complex data such as this. Also, is there precisely one mount available per container? If podman is really trying to be compatible to docker, I cannot believe that.
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
```suggestion description: Can be used to request certificates from ECS, with C(provider=entrust). ```
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
Use another lookup instead of `epoch` e.g. `second`.
```suggestion Test that the returned value for timezone consists of only uppercase ```
no restructured text (:class:) in docstrings please
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
flake8 complains about missing spaces around `*`
```suggestion item, fields=fields, using=self.db, ```
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
add trailing comma
A general remark: you should always use complete sentences. So this should end with a period.
(Same for the related options.)
This should really be: ``` - Set custom DNS search domains. (Use I(dns_search) with C('') if you don't wish to set the search domain.) ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
I believe selinux uses native strings (byte strings in python2 and text strings in python3) rather than always using byte strings. So that's why we weren't using to_bytes here earlier. We may need to move the to_native call earlier, though. I'm not sure if it was all selinux functions or only some of them which had bugs if the wrong type of string was passed to them.
This logic seems a little convoluted. Consider: ``` python conns = connetions.values() if settings.DATABASE_ROUTERS else [connections[DEFAULT_DB_ALIAS]] for conn in conns: if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(router.allow_migrate(connection.alias, label) for label in labels)): ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
I opened an issue for better visibility of this discussion: https://github.com/elastic/elasticsearch/issues/19359
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Something like: ``` patch --- test/units/module_utils/facts/test_collectors.py +++ test/units/module_utils/facts/test_collectors.py @@ -258,12 +258,8 @@ class TestPkgMgrFactsAptFedora(BaseFactsTest): "ansible_pkg_mgr": "apt" } - import ansible.module_utils.facts.system.pkg_mgr - ansible.module_utils.facts.system.pkg_mgr.os = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path.exists = Mock(side_effect=_sanitize_os_path_apt_get) - - def test_collect(self): + @patch('ansible.module_utils.facts.system.pkg_mgr.os.path.exists', side_effect=_sanitize_os_path_apt_get) + def test_collect(self, mock_os_path_exists): module = self._mock_module() fact_collector = self.collector_class() facts_dict = fact_collector.collect(module=module, collected_facts=self.collected_facts) ```
Is it possible ? For me it would mean that it exist a package without version.
It doesn't work if pkg_provides contain a version: ``` max@mde-oxalide % pacman -Qqei perl | grep Provide Provides : perl-archive-tar=2.30 perl-attribute-handlers=1.01 perl-autodie=2.29 perl-autoloader=5.74 perl-autouse=1.11 perl-b-debug=1.26 perl-base=2.27 perl-bignum=0.49 perl-carp=1.50 perl-compress-raw-bzip2=2.074 perl-compress-raw-zlib=2.076 perl-config-perl-v=0.29 perl-constant=1.33 perl-cpan-meta-requirements=2.140 perl-cpan-meta-yaml=0.018 perl-cpan-meta=2.150010 perl-cpan=2.20 perl-data-dumper=2.170 perl-db_file=1.840 perl-devel-ppport=3.40 perl-devel-selfstubber=1.06 perl-digest-md5=2.55 perl-digest-sha=6.01 perl-digest=1.17_01 perl-dumpvalue=1.18 perl-encode=2.97 perl-encoding-warnings=0.13 perl-env=1.04 perl-experimental=0.019 perl-exporter=5.73 perl-extutils-cbuilder=0.280230 perl-extutils-constant=0.25 perl-extutils-install=2.14 perl-extutils-makemaker=7.34 perl-extutils-manifest=1.70 perl-extutils-parsexs=3.39 perl-file-fetch=0.56 perl-file-path=2.15 perl-file-temp=0.2304 perl-filter-simple=0.95 perl-filter-util-call=1.58 perl-getopt-long=2.5 perl-http-tiny=0.070 perl-i18n-collate=1.02 perl-i18n-langtags=0.43 perl-if=0.0608 perl-io-compress=2.074 perl-io-socket-ip=0.39 perl-io-zlib=1.10 perl-io=1.39 perl-ipc-cmd=1.00 perl-ipc-sysv=2.07 perl-json-pp=2.97001 perl-lib=0.64 perl-libnet=3.11 perl-locale-codes=3.56 perl-locale-maketext-simple=0.21_01 perl-locale-maketext=1.29 perl-math-bigint-fastcalc=0.5006 perl-math-bigint=1.999811 perl-math-bigrat=0.2613 perl-math-complex=1.5901 perl-memoize=1.03_01 perl-mime-base64=3.15 perl-module-corelist=5.20180622 perl-module-load-conditional=0.68 perl-module-load=0.32 perl-module-loaded=0.08 perl-module-metadata=1.000033 perl-net-ping=2.62 perl-params-check=0.38 perl-parent=0.236 perl-pathtools=3.74 perl-perl-ostype=1.010 perl-perlfaq=5.021011 perl-perlio-via-quotedprint=0.08 perl-pod-checker=1.73 perl-pod-escapes=1.07 perl-pod-parser=1.63 perl-pod-perldoc=3.2801 perl-pod-simple=3.35 perl-pod-usage=1.69 perl-podlators=5.006 perl-safe=2.40 perl-scalar-list-utils=1.50 perl-search-dict=1.07 perl-selfloader=1.25 perl-socket=2.027 perl-storable=3.08 perl-sys-syslog=0.35 perl-term-ansicolor=4.06 perl-term-cap=1.17 perl-term-complete=1.403 perl-term-readline=1.17 perl-test-harness=3.42 perl-test-simple=1.302133 perl-test=1.31 perl-text-abbrev=1.02 perl-text-balanced=2.03 perl-text-parsewords=3.30 perl-text-tabs=2013.0523 perl-thread-queue=3.12 perl-thread-semaphore=2.13 perl-threads-shared=1.58 perl-threads=2.22 perl-tie-file=1.02 perl-tie-refhash=1.39 perl-time-hires=1.9759 perl-time-local=1.25 perl-time-piece=1.3204 perl-unicode-collate=1.25 perl-unicode-normalize=1.26 perl-version=0.9923 perl-xsloader=0.30 ```
```suggestion pkg_version = line.partition(':')[-1].strip() ```
Outer parentheses are not idiomatic in python.
> return it directly ``` python return self.url_result('http://imgur.com/%s' % album_id) ```
You don't need list here. Just return it directly.
Please remove this blank line as requested by Paolo.
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
hmmm.. now I think I'm wrong, you want to only have the first partial func.. `func.func` shouldn't anyway be another partial or else that would be problematic I think, as views have to return something else.. Sorry for disturbance ;)
Minor but I'd move this control flow block after the `weights` one to match the args order.
I opened an issue for better visibility of this discussion: https://github.com/elastic/elasticsearch/issues/19359
#19359 will take more time to discuss (so far no reaction at all) and it makes no sense to stall this pr on it. We can remove the examples for now and if we find we keep `IndexLookup` anyway add them again.
Minor but I'd move this control flow block after the `weights` one to match the args order.
I opened an issue for better visibility of this discussion: https://github.com/elastic/elasticsearch/issues/19359
#19359 will take more time to discuss (so far no reaction at all) and it makes no sense to stall this pr on it. We can remove the examples for now and if we find we keep `IndexLookup` anyway add them again.
Make sure you use `format_lazy()` to prevent issues with translated strings: ```suggestion self.verbose_name_plural = format_lazy('{}s', self.verbose_name) ``` This is also consistent with the following: https://github.com/django/django/blob/c70cd2a926ffab47f6613e83e0c8828eb6c2c064/django/db/models/options.py#L188-L191
I know this is preexisting issue, but the condition should be checking the boolean value, not just the existence
I'd vote for making `returning` a `property` instead of a stealth field option at least for now because this is not something we've done in the past. ```python @property def returning(self): return hasattr(self.default, 'as_sql') AutoField.returning = True ``` That would make `DateTimeField(default=Now)` work and avoid the ambiguity of `default=Now, returning=False`. We'd still have to deal with backends that don't support returning fields.
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
Can you please run `pages_per_range` through `quote_value()` (internal function on the schema editor).
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
I don't see a need for string interpolation in cases like this.
Running the entire test suite I could reproduce the error, but not if only running `django.contrib.gis`. Not sure exactly the cause but this code seems suspicious as we leave a different model admin registered for other tests.
please use a variable for this string so that if it changes, we don't have to update it below as well
Minor but I'd move this control flow block after the `weights` one to match the args order.
There is no point to use `remove_start` since line is always a string.
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
Good catch, I will remove it before final squash.
```python if state == "disabled": if current_state == "enabled": self._commands.append('interface {0} {1} no traffic-class {2} congestion-control'.format(if_type, if_id, tc)) continue ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
you can use `state` to avoid the 'or' to the user
Nitpick, but shouldn't these be assertEqual()? This would be consistent with `if len(queryset) == 2` instead of `if len(queryset) is 2`.
Chop the blank lines
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
TextInput -> Input? I suppose a `test_input.py` file would be better. I wasn't sure about the `test_no_trailing_newline_in_attrs` test -- it's meant to test a template rather than Python code -- probably I could have clarified that. `strict=True` isn't needed since the newline isn't being tested.
I think we don't need it. but lets @felixxm decide about it. Thanks for the patch :+1:
You should probably expect unicode strings
Plz also use `match` arg here
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
No need to parametrize with just one case.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
It probably makes sense to test that the exception reason also matches expectations
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
Does this need to be a separate method? Seems unnecessary to me.
Need spaces around `+` sign.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
Can you please test with Java 11 or newer? Looks like you tested with Java 8 which uses the slower crc32c method.
Yes, they were.
`a['adress']` could be used instead of `(len(a['address']) > 0)`.
since the plugin is called `aws_ssm`, I'd change this to `ansible_aws_ssm_retries`
Shouldn't we have a decorator for that? (kinda off-topic, I know)
+1 (in separate patch)
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
The following properties indicate if
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
```suggestion masked = var_list[key].get('masked', False) ```
Tests shouldn't rely on internal APIs to trigger a bug.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
```suggestion masked = var_list[key].get('masked', False) ```
Tests shouldn't rely on internal APIs to trigger a bug.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
```suggestion masked = var_list[key].get('masked', False) ```
Tests shouldn't rely on internal APIs to trigger a bug.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
I'd use `ref.assert_called_once_with()` here.
From looking at the code the call could differ from Python 2 to 3 and is really an implementation detail which is not worth testing after all. My initial reflexion was more about the fact `assert_not_called()` was used below instead of `self.assertFalse(ref.called)` but now I realize there's no `assert_called()` method. LGTM
Can you elaborate on this except branch. Trying to figure out when this happens.
no space between "e. g."
I guess we could simply use `f.content_type = Image.MIME.get(image.format)`
test failure says this should be `(None, None)`
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
single line looks more readable here
Not sure it makes a difference but before it looks like we got `form=None` in the context.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
single line looks more readable here
Not sure it makes a difference but before it looks like we got `form=None` in the context.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
single line looks more readable here
Not sure it makes a difference but before it looks like we got `form=None` in the context.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
single line looks more readable here
Not sure it makes a difference but before it looks like we got `form=None` in the context.
Does this need to be a separate method? Seems unnecessary to me.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
Does this need to be a separate method? Seems unnecessary to me.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
This module supports check mode, but you're not checking whether you're in check mode before adding tags.
can be ignored
when using dict you can just do `dict(msg=to_text(body), message_count=....`.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
single line looks more readable here
Not sure it makes a difference but before it looks like we got `form=None` in the context.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
single line looks more readable here
Not sure it makes a difference but before it looks like we got `form=None` in the context.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
Does this need to be a separate method? Seems unnecessary to me.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
As long as they both equals it shouldn't make a difference. By that I mean you should have a test asserts `Index('foo') == Index(F('foo'))` An alternative could be to defer that to `create_sql`.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
"for BRIN indexes" doesn't seem consistent with usual error messages.
I think it's fine.
As long as they both equals it shouldn't make a difference. By that I mean you should have a test asserts `Index('foo') == Index(F('foo'))` An alternative could be to defer that to `create_sql`.
Please ignore, my suggestion is invalid syntax.
comma after tuple
flake8 complains about missing spaces around `*`
I'm not sure what the best solution is, but at the moment I would lean towards not supporting `.repo` files and asking people to specify the repo URL directly. To properly support `.repo` files we would have to download them, parse them and compare them to the configured repos, which is a lot of effort. Are you aware of a usecase that actually requires `.repo` files? I no longer use suse in my day job and all repo usage that I can remember also worked fine with pointing to directories directly.
comma after tuple
chop blank line
like diff = load_config(self._module, config_xml, [])
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
use a single loop? ~~~python for server in _retrieve_servers(api_key): server = Vultr.normalize_result(server, SCHEMA) .... ~~~ ~~~
What I meant was that you could stick the following in the top of `_destruct_iterable_mapping_values()` to make it more DRY: ```python if isinstance(data, Mapping): yield from data.items() return ``` I don't see why you think we'd need an extra for-loop...
There are only two uses of `_destruct_iterable_mapping_values()` and we use this same pattern exactly. I think that you could push the `isinstance(..., Mapping)` check into that function.
As a separate commit, I think that it is also probably worth moving that global function to be a `@staticmethod` on the `CaseInsensitiveMapping` class. It is closely associated with this class and would avoid the need to import it separately in `django.http.response`.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
Any problem with: ``` @property def media(self): ```
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
chop blank line
should probably use `if stdout is not None:`
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
chop blank line
should probably use `if stdout is not None:`
Oops, I misread the diff and see that you only modified the existing archives. Still an explanation of exactly what going on would be nice as it's not obvious to me.
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
Does the raised exception have the same `errno` on both platforms? If that's the case you could do: ``` python with self.assertRaises(IOError) as ctx: # .... self.assertEqual(ctx.exception.errno, errno.WHATEVER) ```
```not (foo is None)``` => ```foo is not None```
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
I think all the calls to `render()` can be removed (it worked for me in this test at least)
```not (foo is None)``` => ```foo is not None```
I think all the calls to `render()` can be removed (it worked for me in this test at least)
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
```not (foo is None)``` => ```foo is not None```
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
It probably makes sense to test that the exception reason also matches expectations
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
(And round-tripping of the messages is already tested in other tests)
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Is there specific value in doing this for all variants here? In particular, does the security protocol variation get us something that existing tests don't? Another way of asking this is, beyond the failures we would catch with existing tests where brokers generally fail to communicate with each other when using specific security protocols, is there a way we think reassignment specifically would fail that would be related to the security protocol? E.g. is there a different inter-broker connection that's being made that otherwise wouldn't be made? I ask because I think we already test a lot of stuff with variations of security protocols and I'm a bit worried about test bloat due to parametrizing tests being relatively easy (and leading to much longer test runs).
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
I would chop blank lines in this test.
Chop `Ensure that`.
Similarly, ```if tc['skip'].get('i')```
I would chop blank lines in this test.
Chop `Ensure that`.
Similarly, ```if tc['skip'].get('i')```
wo -> without
I would chop blank lines in this test.
Chop `Ensure that`.
I would chop blank lines in this test.
Chop `Ensure that`.
Breaks. Read coding conventions.
I think `if opt_val:` is sufficient.
`print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-'))`
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
Capital letter at the beginning.
Dot at the end.
Capital letter at the beginning and dot at the end.
Too long line.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
Too long line.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Is there specific value in doing this for all variants here? In particular, does the security protocol variation get us something that existing tests don't? Another way of asking this is, beyond the failures we would catch with existing tests where brokers generally fail to communicate with each other when using specific security protocols, is there a way we think reassignment specifically would fail that would be related to the security protocol? E.g. is there a different inter-broker connection that's being made that otherwise wouldn't be made? I ask because I think we already test a lot of stuff with variations of security protocols and I'm a bit worried about test bloat due to parametrizing tests being relatively easy (and leading to much longer test runs).
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Can we calculate that beforehand? Also `os.environ.get` could make this much more readable.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
I don't think printing an informational message is that useful. Just `pass` here instead
we should also return if we both delegate executions and delegate_facts
this got named use_backend
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Add that the user can specify the backend to use via the ```use``` parameter.
Still need to add something like ```You can manually specify use_backend to tell the module whether to use the yum (yum-3) or dnf (yum-4) backend.```
How about: ```suggestion from ansible.module_utils.parsing.convert_bool import boolean as to_bool try: verify = to_bool(option) except TypeError: # it wasn't a boolean value verify = option # Set to a CA bundle: finally: if verify is False: # is only set to bool if try block succeeds requests.packages.urllib3.disable_warnings() self._display.warning( u"SSL verification of %s disabled" % self.foreman_url, ) return verify ```
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
this got named use_backend
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
```suggestion - When using in a chroot environment you always need to specify the name of the unit with the extension. For example, C(crond.service). ```
`always_text` is gone.
Not strictly necessary as the default for parameter is that they're not required.
Note that format strings changed in python-2.7 So things like "{} {}".format() needs to change to "{0} {1}".format() for python-2.6 compatibility.
When there is only one capture group just use unnamed one.
When hitting an error you must exit with module.fail_json
If you don't modify the task args then you don't need to copy() them. However, I think we want to add a ```use``` parameter for the action plugin and we will want to delete that parameter before we pass the args on to the module. So this section would look like: ``` python new_module_args = self._task.args.copy() del new_module_args['use'] [...] result.update(self._execute_module(module_name=module, module_args=new_module_args, task_vars=task_vars, wrap_async=self._task.async_val)) ```
this got named use_backend
Still need to add something like ```You can manually specify use_backend to tell the module whether to use the yum (yum-3) or dnf (yum-4) backend.```
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Similarly, ```if tc['skip'].get('i')```
This must be checked **before** any processing.
And this one.
Omit 0/1. There was a past commit that removed all usage of that since it just adds verbosity.
It would have been more appropriate if `run_checks()` took an `Apps` instance as a parameter instead of a list of `AppConfig`s.
`del` is a builtin, not a function. These parens don't have to be here
add trailing comma
`get_random_string()` will never allow you to connect to the same memory database instance. You can probably use `self.connection.alias` for that so each database alias has it's own unique memory database. This also allows it to work with `threading.local`.
This hook is unnecessary, IMO. I would move the logic to `_select_on_conflict()`.
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
It probably makes sense to test that the exception reason also matches expectations
Yes please remove unnecessary blank lines.
Breaks extraction completely if `params` does not match number of values to unpack.
Similarly, ```if tc['skip'].get('i')```
Maybe you can extract the test code from the Py3ExceptionReporterTests and skip importing the "actual test code" if six.PY3 is False? ``` python class Py3ExceptionReporterTests(TestCase): rf = RequestFactory() @unittest.skipIf(not six.PY3, "Python 3 only test") def test_reporting_of_nested_exceptions(self): from other_module import do_actual_testing do_actual_testing(self.rf) ```
This can be directly imported from six: ``` python from ansible.module_utils.six.moves import configparser ```
no space between "e. g."
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Maybe you can extract the test code from the Py3ExceptionReporterTests and skip importing the "actual test code" if six.PY3 is False? ``` python class Py3ExceptionReporterTests(TestCase): rf = RequestFactory() @unittest.skipIf(not six.PY3, "Python 3 only test") def test_reporting_of_nested_exceptions(self): from other_module import do_actual_testing do_actual_testing(self.rf) ```
This can be directly imported from six: ``` python from ansible.module_utils.six.moves import configparser ```
no space between "e. g."
normalize_interface import is unnecessary here
As per naming convention, the name is `get_lldp_global_facts`
This condition can be removed
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
I would actually assume most of the users will not be using ID but name. Don't think it matters that much though.
okay, but would be helpful to say _why_ we need to always return True.
`del` is a builtin, not a function. These parens don't have to be here
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
I would remove all aliases if possible.
okay, but would be helpful to say _why_ we need to always return True.
This isn't needed, since we now only support 2.6+ anyway.
These parens aren't necessary for unpacking the return values.
(Same for the related options.)
A general remark: you should always use complete sentences. So this should end with a period.
This should really be: ``` - Set custom DNS search domains. (Use I(dns_search) with C('') if you don't wish to set the search domain.) ```
okay, but would be helpful to say _why_ we need to always return True.
This isn't needed, since we now only support 2.6+ anyway.
These parens aren't necessary for unpacking the return values.
normalize_interface import is unnecessary here
As per naming convention, the name is `get_lldp_global_facts`
This condition can be removed
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint` (the same in all new tests).
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Good catch, I will remove it before final squash.
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
Please wrap docstrings at 79 characters. Ticket references are only needed for obscure issues that benefit from the additional context of the ticket. Not sure that's the case here.
Good catch :+1: Thanks
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Did you try the ORM rather than raw SQL? I'm not sure if there's a reason the test above doesn't use it.
Minor but I'd move this control flow block after the `weights` one to match the args order.
> scheduling requirements (resource request, requiredDuringScheduling anti-affinity expressions, etc.), compute a sum You missed the parentheses.
Also missing parentheses: > during vm execution (e.g. due to a vm label update),
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
I don't think we should be promoting using this feature of scripting. If someone wants this level of control over scores, they should implement their own Similarity; that is its purpose.
```suggestion database='default', verbosity=0, skip_empty=True, ```
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
```suggestion database='default', verbosity=0, skip_empty=True, ```
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
I don't think we should be promoting using this feature of scripting. If someone wants this level of control over scores, they should implement their own Similarity; that is its purpose.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Please add `type='str'`
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion type: list suboptions: ```
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
```suggestion database='default', verbosity=0, skip_empty=True, ```
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
Minor but I'd move this control flow block after the `weights` one to match the args order.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion type: list suboptions: ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion type: list suboptions: ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
```suggestion on_conflict=on_conflict, ```
Getting rid of the unnecessary constant for the `None` case, `ON_CONFLICTS_NONE`, will simplify the diff and make review easier: ```suggestion if connection.features.can_return_rows_from_bulk_insert and not on_conflict: ```
As with the old `_batched_insert` code, I think we should pass the db alias here `self._insert(objs_without_pk, fields, using=self.db)`, it defaults to that but passing it seems more explicit.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Please don't make lines longer! There was nothing really wrong with this line before
Minor but I'd move this control flow block after the `weights` one to match the args order.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Same here, don't we usually use byte strings for file operations.
@smithdc1 it does thanks!
Minor but I'd move this control flow block after the `weights` one to match the args order.
>besides the test is there to make sure that breakage in this part of code will be detected That's a doubtful argument considering broken core tests at the beginning of this PR. The length of this string is const until one decides to refactor here something. Using 10 is a variation of code duplication since the length is already implicitly defined in the string literal itself. Also using 10 indicates no relation to the string literal so that one unfamiliar with code who decides to refactor it may forgot to change the number and may be unaware of the tests at all.
This is error prone, `len` of the actual string should be used instead.
`enumerate` on for range.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
We try to avoid line continuation backslashes in Django, and it's not a problem to overcome the 80-chars limit when it makes readability better.
You need either `to_bytes(text)` or `text.encode('utf-8')` here as well.
Use dict literals: ```suggestion return {} ```
Please convert this to just a list comprehension: ```suggestion groups = [e.name for e in entities if isinstance(e, Group)] ``` Additionally, just convert to a list of names here, since you only ever need that, and not the object later.
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
Again, error handling changed.
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
Again, error handling changed.
You're checking two separate properties here. This should be in a separate test.
Match the error message
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
You're checking two separate properties here. This should be in a separate test.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
You're checking two separate properties here. This should be in a separate test.
You're checking two separate properties here. This should be in a separate test.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
plz don't use EOL escaping, wrap with braces instead.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
plz don't use EOL escaping, wrap with braces instead.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
The various `CALLBACK_` prefixed class attributes are missing. Take a look at the other callbacks for an example. In particular, this is needed: ``` python CALLBACK_NEEDS_WHITELIST = True ```
nit: doc how the output of `iperf` looks like. helps with understanding this code and regex.
Use `(?i)` in regex itself if you want case insensitivity.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
this is a catchall, we normally frown on those. also note that for all of your `% e` they should be `% to_native(e)` to ensure proper character conversions
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
plz don't use EOL escaping, wrap with braces instead.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
Match the error message
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Thanks for that note ewen. I learned something!
is the `any` required here - `if metrics_to_disable:` should suffice, I'd think
Thanks for that note ewen. I learned something!
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Since we expect the name to start with 'http://' or 'https://' I would so this: ```python if name.startswith('http://') or name.startswith('https://'): ... ```
Thanks for that note ewen. I learned something!
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Please use [standard exception handling guidelines](https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-2)
`for data in json.loads(...):`
`Klass` → `model`
maybe: `# If no browsers were specified, skip this class (it'll still be discovered).`
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Need to import reduce from ansible.module_utils.six.moves.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
`for data in json.loads(...):`
`Klass` → `model`
maybe: `# If no browsers were specified, skip this class (it'll still be discovered).`
Thanks for that note ewen. I learned something!
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
don't use print, display.error or raise an AnsibleError exception, Ansible already does not fail due to an Exception from a callback event.
Chop "Makes sure" prefix in favor of stating the expected behavior as described in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/.
Since the same result is expected as above, wouldn't it be clearer to save the output in a variable? Something like: ``` expected = ( "[ ] author_app.0001_initial\n" "[ ] book_app.0001_initial\n" "[ ] author_app.0002_alter_id\n" "[ ] mutate_state_b.0001_initial\n" "[ ] mutate_state_b.0002_add_field\n" ) ```
Yes and no. Keeping the output explicit feels easier to read.
Chop "Makes sure" prefix in favor of stating the expected behavior as described in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/.
Since the same result is expected as above, wouldn't it be clearer to save the output in a variable? Something like: ``` expected = ( "[ ] author_app.0001_initial\n" "[ ] book_app.0001_initial\n" "[ ] author_app.0002_alter_id\n" "[ ] mutate_state_b.0001_initial\n" "[ ] mutate_state_b.0002_add_field\n" ) ```
Yes and no. Keeping the output explicit feels easier to read.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Thanks for that note ewen. I learned something!
Here, you might want to return `out` if `re.findall` returns `[]`
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Thanks for that note ewen. I learned something!
Here, you might want to return `out` if `re.findall` returns `[]`
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Thanks for that note ewen. I learned something!
Here, you might want to return `out` if `re.findall` returns `[]`
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Thanks for that note ewen. I learned something!
Here, you might want to return `out` if `re.findall` returns `[]`
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
Since the same result is expected as above, wouldn't it be clearer to save the output in a variable? Something like: ``` expected = ( "[ ] author_app.0001_initial\n" "[ ] book_app.0001_initial\n" "[ ] author_app.0002_alter_id\n" "[ ] mutate_state_b.0001_initial\n" "[ ] mutate_state_b.0002_add_field\n" ) ```
Yes and no. Keeping the output explicit feels easier to read.
The input values for tags can be integers but they need to be converted to a string before using e.g. `compare_aws_tags` because they're always strings when returned by boto. I definitely think we should be able to do this in a better way (which is likely just forcing conversion to string, rather than declaring non-string things invalid)
@aioue Thanks for the patch for this. What do you think about doing away with the valid tags check altogether? Some other opinions on this would probably be good too. I haven't noticed this attempted verification in other modules and I'm not sure what purpose it has. Tags should be able to be integers as well.
Might want to avoid `id` shadowing.
It's probably better to use MiB instead of Mb or MB. (Here and few more times below.)
We tend to quote names and values in messages for readability. ```suggestion meraki.fail_json(msg="Parameters 'org_name' or 'org_id' parameters are required") ```
This regexp should be put into a constant, especially since it is reused multiple times. Also, maybe it makes sense to precompile it (and potentially others) with `re.compile()`.
don't need a trailing comma for lists with a single element (only needed for tuples)
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
, keeping a reference to the cyptes object so that the vsimem file...
prefer hanging indent style with 1 arg per line
It's not clear to me why it's valuable to change the semantics here so that this validation doesn't happen first if `fail_silently=False`. I don't think the message must be changed to add "like".
I would put the arguments all on this line
rather than custom caching with a dict, this might be clearer with a module-level function using `@lru_cache(maxsize=2)`, with the current value of `USE_TZ` as the only argument. It would save some lines and clarify it's a cache.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
, keeping a reference to the cyptes object so that the vsimem file...
prefer hanging indent style with 1 arg per line
no blank line
`field_names_cache` should be moved an initialized in the `__init__()`, currently we clean it for each `obj`.
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
`enumerate` on for range.
Breaks. Read coding conventions.
Must not break extraction if missing.
Should contain `quality` key.
`enumerate` on for range.
Should contain `quality` key.
Must not break extraction if missing.
`enumerate` on for range.
Should contain `quality` key.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
`enumerate` on for range.
What kind of values are valid here? I would expect this to be `float` based on the `0.0` in the description.
A general remark: you should always use complete sentences. So this should end with a period.
2.6 or 2.7? Also you `requirements` listed here and the modules.
Should contain `quality` key.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
`enumerate` on for range.
I thought `formset = ChoiceFormSet(self.data, auto_id=False, prefix='choices')` could go in `setUp()` also.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
I thought `formset = ChoiceFormSet(self.data, auto_id=False, prefix='choices')` could go in `setUp()` also.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
I'd include the min length in the error message
I would code it like this: ``` DEFAULT_USER_ATTRIBUTES = ('username', 'first_name', 'last_name', 'email') def __init__(self, user_attributes=DEFAULT_USER_ATTRIBUTES, max_similarity=0.7): self.user_attributes = user_attributes ```
If `user_attributes` is set to `()` or `[]`, the default set of attributes will be used. That may be surprising. Can you make a strict check for `user_attributes is None`? I understand that the validator doesn't do anything then and can simply be removed from the settings in that case, but I can imagine situations where someone would control `user_attributes` (e.g. through an UI) and not `AUTH_PASSWORD_VALIDATORS`.
I'd include the min length in the error message
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
its so that, for example, a ...
If something on the managed machine messes up, this could be in some other encoding. Also, there's always the chance that the way the client machine handles non-utf-8 bytes will lead to those bytes coming through unescaped. Basically, the connection plugin is a boundary between Ansible and another system. So we need to be a little more paranoid in sanitizing our data in this area.
You might want to specify a different error handler here. The default handler is surrogate_or_replace. When non-utf8 byte sequences are encountered, it either uses surrogateescape if available or replace. This can munge output on python2. Since we're sending this to json.loads (rather than displaying it to the user) it might be better to use surrogate_or_strict as the error handler here.
I remember having to add the to_bytes()... it could be that an old version of winrm returned text here. I do not remember for sure if that was fixed in the lowest winrm version that we support. Two other notes: 1) This needs to return bytes on python3 as well as python2 2) to_bytes() is a no-op (overhead of the function call and a couple conditionals but no encoding is done) if the string is already a byte string.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I'm not sure if `isinstance(pages_per_range, int)` is required. I think Python/Django doesn't do strict type checking like that in general.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I'm not sure if `isinstance(pages_per_range, int)` is required. I think Python/Django doesn't do strict type checking like that in general.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
~~~diff - state=dict(type='str', required=True, choices=['absent', 'present']), + state=dict(type='str', default='present', choices=['absent', 'present']), ~~~
```not (foo is None)``` => ```foo is not None```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
~~~diff - state=dict(type='str', required=True, choices=['absent', 'present']), + state=dict(type='str', default='present', choices=['absent', 'present']), ~~~
```not (foo is None)``` => ```foo is not None```
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
Please use a single quote.
one more for the single line version
```suggestion b_opath = os.path.realpath(to_bytes(os.path.join(path, group))) ```
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
The `to_bytes` should be on the `self._basedir` instead: ```suggestion b_opath = os.path.realpath(os.path.join(to_bytes(self._basedir), b'r_group_vars')) ```
I'm not sure it really matters, but I'd put `self.ALLOW_BASE_THROTTLING` first.
Is it too late to move the conversion of `auto` to an integer to a post-processing step (e.g. your `get_num_test_processes()` function)? I feel like the `parallel_type` function's job here should only be to check that the value equals `auto` if the value is a string, but not to apply the environment-dependent business logic to convert `auto` to a number. (I also see that `get_num_test_processes()` is already calling `multiprocessing.cpu_count()`, so there may be some duplication of logic with the way things are currently structured.)
version added requires quotes, otherwise it will be processed as number
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
The CamelCase exception .response attribute is particular to boto3's ClientError. IOError doesn't have .response so you can remove the `**camel_dict_to_snake_dict(e.response)` bit of this.
It would be good to wrap this in a try/except botocore.exceptions.ClientError as e
Running the legacy ec2_asg integration tests that use this module, I think this line should be `if block_device_mapping:` because it doesn't look like it can be None or an empty list. The error: ``` An exception occurred during task execution. To see the full traceback, use -vvv. The error was: Missing required parameter in BlockDeviceMappings[0]: "DeviceName" fatal: [localhost]: FAILED! => {"changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 436, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 430, in main\n create_launch_config(connection, module)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 326, in create_launch_config\n connection.create_launch_configuration(**launch_config)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 253, in _api_call\n return self._make_api_call(operation_name, kwargs)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 517, in _make_api_call\n api_params, operation_model, context=request_context)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 572, in _convert_to_request_dict\n api_params, operation_model)\n File \"/Library/Python/2.7/site-packages/botocore/validate.py\", line 270, in serialize_to_request\n raise ParamValidationError(report=report.generate_report())\nbotocore.exceptions.ParamValidationError: Parameter validation failed:\nMissing required parameter in BlockDeviceMappings[0]: \"DeviceName\"\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0} ```
I think a more elegant solution would be to add one more list element and `str.join()` will do the rest: ```suggestion b_outs.append(b'') self.editor.write_data(b'\n'.join(b_outs), context.CLIARGS['output_file'] or '-') ```
Okay, I just tested this and it looks like fd.close() does not cause an error. It's useless to have it there but not strictly necessary to remove it.
This can be single-lined: ```suggestion return (matched_tags or not tags) and not test_tags.intersection(exclude_tags) ```
`yield from` is not allowed in async functions.
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
Let's be consistent, if the previous test we have `newsecret`: ```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
`yield from` is not allowed in async functions.
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
Let's be consistent, if the previous test we have `newsecret`: ```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
`yield from` is not allowed in async functions.
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
Let's be consistent, if the previous test we have `newsecret`: ```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
I don't see a need for string interpolation in cases like this.
I'd suggest this for the indentation: ```python return [ force_text( capi.get_field_name(capi.get_field_defn(self._layer._ldefn, i)), self.encoding, strings_only=True, ) for i in range(self.num_fields) ] ``` Any concern about having no tests for the `self.encoding, strings_only=True` bit? I'm not sure we would expect non-string values in the first place? Also, at least on my system, there are no failures with it removed here or in `layer_name` above.
Running the entire test suite I could reproduce the error, but not if only running `django.contrib.gis`. Not sure exactly the cause but this code seems suspicious as we leave a different model admin registered for other tests.
Similarly, ```if tc['skip'].get('i')```
> I think this isn't a great trade-off to make, the special branch for "is the length exactlyt the same" will cost more than it saves across a range of different input string types. Only a few will match it. Yeah, I wondered whether the exact length check might be detrimental. > Regardless this is a rarely used DB function, this is too much time spent optimizing it already :) 😄 Yup. Happy with your solution.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Line is too long.
Too long line.
This line is too long. Max line length allowed in Ansible is 120 characters.
What's the purpose of http://example.com/v.flv here? It always gives a 404 error and I think it's unrelated to iQiyi
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Similarly, ```if tc['skip'].get('i')```
docstring with example input/output would be really helpful
Please ignore, my suggestion is invalid syntax.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
docstring with example input/output would be really helpful
Please ignore, my suggestion is invalid syntax.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
docstring with example input/output would be really helpful
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
docstring with example input/output would be really helpful
Please ignore, my suggestion is invalid syntax.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
docstring with example input/output would be really helpful
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
m3u8 can't be extracted now since `formats` will be overwritten by the code below.
docstring with example input/output would be really helpful
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
m3u8 can't be extracted now since `formats` will be overwritten by the code below.
Please ignore, my suggestion is invalid syntax.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
It seems these could fit on a single file. We could define `args = (str(self.name), bases, body)` to avoid repeating them.
Repeating would be quite rare situation, only for classes with multiple metaclasses, so defining new value used only once in 98% of time would be slower in the end.
Using `_` for unused variable is a common idiom.
This is missing other likely candidates: `y` and `yes` I'd also argue it should be simplified to be case-insensitive so that `TRUE` == `true` (which requires you actually assert the incoming `val` is actuall stringy enough to have `.lower()`, rather than simply doing an equality match against any of the values)
I typically use something like the following: ```python return str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'} ``` This works whether you pass a boolean, integer or string, although we are only expecting a string from the environment anyway. If we wanted to be strict, we should reject invalid values: ```python if str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'}: return True if str(val).lower() in {'0', 'f', 'n', 'off', 'false', 'no'}: return False raise ValueError('Non-boolean string provided.') ```
2.6 or 2.7? Also you `requirements` listed here and the modules.
This is missing other likely candidates: `y` and `yes` I'd also argue it should be simplified to be case-insensitive so that `TRUE` == `true` (which requires you actually assert the incoming `val` is actuall stringy enough to have `.lower()`, rather than simply doing an equality match against any of the values)
I typically use something like the following: ```python return str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'} ``` This works whether you pass a boolean, integer or string, although we are only expecting a string from the environment anyway. If we wanted to be strict, we should reject invalid values: ```python if str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'}: return True if str(val).lower() in {'0', 'f', 'n', 'off', 'false', 'no'}: return False raise ValueError('Non-boolean string provided.') ```
2.6 or 2.7? Also you `requirements` listed here and the modules.
`_select_on_conflict` name is misleading because this method mainly checks options. Maybe `_check_bulk_create_options(...)` :thinking:
I would use an early return (in both cases): ```suggestion return OnConflict.IGNORE ```
Was already highlighted [here](https://github.com/django/django/pull/13065#discussion_r684521409) but was missed.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
```suggestion type: list suboptions: ```
Running the legacy ec2_asg integration tests that use this module, I think this line should be `if block_device_mapping:` because it doesn't look like it can be None or an empty list. The error: ``` An exception occurred during task execution. To see the full traceback, use -vvv. The error was: Missing required parameter in BlockDeviceMappings[0]: "DeviceName" fatal: [localhost]: FAILED! => {"changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 436, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 430, in main\n create_launch_config(connection, module)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 326, in create_launch_config\n connection.create_launch_configuration(**launch_config)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 253, in _api_call\n return self._make_api_call(operation_name, kwargs)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 517, in _make_api_call\n api_params, operation_model, context=request_context)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 572, in _convert_to_request_dict\n api_params, operation_model)\n File \"/Library/Python/2.7/site-packages/botocore/validate.py\", line 270, in serialize_to_request\n raise ParamValidationError(report=report.generate_report())\nbotocore.exceptions.ParamValidationError: Parameter validation failed:\nMissing required parameter in BlockDeviceMappings[0]: \"DeviceName\"\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0} ```
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
It probably makes sense to test that the exception reason also matches expectations
You should probably expect unicode strings
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
nit: this doesn't need to be a field, you can just use a local variable
`deferred_sql` [will automatically be added to `collected_sql` on `__exit__` so iterating over it outside of the context should make it less awkward](https://github.com/django/django/blob/c1c361677d9400c8e2cdaddda0c16086bb358492/django/db/backends/base/schema.py#L112-L137). ```suggestion with connection.schema_editor(collect_sql=True) as editor: editor.create_model(CacheTable) for statement in editor.collected_sql: self.stdout.write(statement) ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
No such meta field.
If we're just testing broker compatibility I don't think we even need this part of the test.
no blank line needed
Any problem with: ``` @property def media(self): ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
no blank line needed
Any problem with: ``` @property def media(self): ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
`>` appears to be a typo
If we're just testing broker compatibility I don't think we even need this part of the test.
unicode -> str (Python 3, first)
Move into `_download_json`.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
No such meta field.
no blank line needed
Any problem with: ``` @property def media(self): ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
This would be better as a set rather than a list.
Scanning a list will not be faster than a membership test of a set (unless the list of words is very small).
Since the list is in order of most common use, the code detects incorrect passwords slightly faster if you preserve the order. :bikeshed:
This can be converted to return True. No need of new variable retry_request
Are these put/post/delete/patch/update methods used anywhere? I don't see uses of them.
Please change these vars to ansible Host vars rather OS env vars.
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
I can see a decent reason to use the `DjangoJSONEncoder` as the default as it gives us `Decimal` and `datetime` support for free. These are very common use cases for django sites (especially datetime!).
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
I can see a decent reason to use the `DjangoJSONEncoder` as the default as it gives us `Decimal` and `datetime` support for free. These are very common use cases for django sites (especially datetime!).
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
no blank line needed
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
yep, that is what I meant, basically make sure new code is pep8 compliant
this module is marked as "legacy" and therefore the CI is not complaining about pep8 here, but it would help if we try to be pep8 compliant.
The issue with this is the timestamp in the filename and the actual timestamp for file changed might not be the same. Thus returning the wrong timestamp within the filename. To avoid this you can check if configurable backup path is given as input to the module. Refer https://github.com/ansible/ansible/pull/50801
Use the Python 2 and low 3 Time Machine: `'url too short: %s' % (video_pre_parts, )` or: `'url too short: %(video_pre_parts)s' % {'video_pre_parts': video_pre_parts, }` or: `'url too short: {video_pre_parts}'.format(video_pre_parts=video_pre_parts)` or: `'url too short: {0}'.format(video_pre_parts)` No doubt there are other ways (eg `....format(**locals())`
Generally, I'd have put the static regex directly as the first argument of `re.search()`.
chop newline for consistency with other tests
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Need a colon at the end here
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Need a colon at the end here
```suggestion the I(verification_method) will be updated and validation data (if applicable) will be returned. ```
```suggestion - There is a small delay (typically about 5 seconds, but can be as long as 60 seconds) before obtaining the random values when requesting a validation ```
```suggestion - There is a small delay (typically about 5 seconds, but can be as long as 30 seconds) before obtaining the random values when requesting a validation. ```
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
Remove this. But do add: ```yaml choices: [ absent, present ] ```
No quote around list members.
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
`always_text` is gone.
Use single quotes consistently.
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
I would remove all aliases if possible.
You should provide an example. Also, I would expect this to be of type `dict`, not `str`.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Yes, that's more helpful for me.
Perhaps this could be a docstring? You might elaborate a bit more -- as someone not familiar with MySQL, it's not clear to me what "improved" means.
This line looks backwards... (If I add a `required` to the select, the HTML validator will trigger on the lack of the empty value.)
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
That's weird -- `timezone.utc` is a `tzinfo` instance, not a subclass, like `timezone.UTC` was.
No strong feelings! Whatever works.
It seems consistent with the changes below but it's still weird...
docstring with example input/output would be really helpful
```suggestion (?:www\.)?(?:safaribooksonline|learning\.oreilly)\.com/ ``` This would handle also new URLs starting with learning.oreilly.
No such meta field.
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
My only question is if this skip logic is still correctly applied (i.e. none of the other classes that inherited `ExtractorTests` require it)? If you verify that, ship it.
ditto as `required_if`
I think for this case, this should work: ``` python required_if = [('state', 'present', ('value', 'value_type'))] ``` But haven't tested that...
If config_source is only used in combo with direct, whichs looks to be the case, it may make sense to collapse it into one arg (config_source). Then GConfTool2.__init__ could: ``` python if config_source: self.base_command += ["--direct", "--config-source", config_source] ``` That assumes there won't be a scenario where it makes sense to call 'gconftool-2 --direct' or 'gconftool-2 --config-souce some_config_source' independently.
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
Might want to use simple quote here.
FWIW using `monkeypatch` is preferable because it's pytest-native unless I need something like mocks or spies.
with -> width
width, height, and offset
comma after tuple
```suggestion msg_format="Error scaling {0} - %s".format(service.name)) ```
Would it be the acme of foolishness to suggest that we just always "load-two"? Then, we wouldn't have to maintain the extra lists of tests at the top of the file, and we wouldn't need this condition here. And also, we'd eliminate a difference among the benchmarks, since the brokers would be loaded with the same dataset in all cases (even if one of them is unused).
Alternatively, we can get rid of those lists by just matching on whether the test name ends with "join" (we match on table name elsewhere in this PR)
```suggestion msg_format="Error scaling {0} - %s".format(service.name)) ```
Would it be the acme of foolishness to suggest that we just always "load-two"? Then, we wouldn't have to maintain the extra lists of tests at the top of the file, and we wouldn't need this condition here. And also, we'd eliminate a difference among the benchmarks, since the brokers would be loaded with the same dataset in all cases (even if one of them is unused).
Alternatively, we can get rid of those lists by just matching on whether the test name ends with "join" (we match on table name elsewhere in this PR)
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
I don't think this is working correctly, did you test it for all possible inputs ? - First of all the size_unit is only correct if it is a known unit. - And if that's not true, and it's not a digit, you have to escalate. - If it is a digit, you likely won't have a unit and then you could assume bytes.
That's up to you. There is no requirement to have a 1:1 mapping between the command and the Ansible interface. And I personally prefer to always have units (e.g. the AIX LV interface assumes no unit to mean MB, not MiB so...)
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
That's up to you. There is no requirement to have a 1:1 mapping between the command and the Ansible interface. And I personally prefer to always have units (e.g. the AIX LV interface assumes no unit to mean MB, not MiB so...)
You could make the unit mandatory (which is what I would do), or you could allow no unit (which means in bytes) and in that case you will have to consider that case as well. (i.e.if unit is a digit)
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
You could make the unit mandatory (which is what I would do), or you could allow no unit (which means in bytes) and in that case you will have to consider that case as well. (i.e.if unit is a digit)
That's up to you. There is no requirement to have a 1:1 mapping between the command and the Ansible interface. And I personally prefer to always have units (e.g. the AIX LV interface assumes no unit to mean MB, not MiB so...)
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
You could make the unit mandatory (which is what I would do), or you could allow no unit (which means in bytes) and in that case you will have to consider that case as well. (i.e.if unit is a digit)
That's up to you. There is no requirement to have a 1:1 mapping between the command and the Ansible interface. And I personally prefer to always have units (e.g. the AIX LV interface assumes no unit to mean MB, not MiB so...)
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
I guess some tests might be needed for the router stuff.
chop trailing ", "
Put the } on the next line and add a trailing comma on this line. That's our convention to ease later adding more items to a dictionary, tuple, etc., if needed.
We should leave here `for_update_part = None` (in the same line as it was previously) and calculate it only in `not combinator` branch, because it's not used for combined queries.
It's not used only for combined queries so we should call it only in `not combinator` branch.
Clarified version of what I had in mind: ``` # Helper method to provide a way to access this without caching it. # For example, admin checks run before the app cache is ready and we # need to be able to lookup fields before we cache the final result. ```
I guess some tests might be needed for the router stuff.
chop trailing ", "
Put the } on the next line and add a trailing comma on this line. That's our convention to ease later adding more items to a dictionary, tuple, etc., if needed.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Please ignore, my suggestion is invalid syntax.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
Minor but I'd move this control flow block after the `weights` one to match the args order.
For the sake of consistency, can we convert `model_name` to lower in here. All occurrences are calling `.lower()` explicitly.
Yes, this should be taken care of before.
docstring with example input/output would be really helpful
Please ignore, my suggestion is invalid syntax.
@smithdc1 it does thanks!
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
```suggestion params = self.settings[alias].copy() ```
I'd go for `try/except IOError` in order to make a point that variable initialized above is in fact a fallback.
```suggestion params = self.settings[alias].copy() ```
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
The docstring should explain why such proxy is needed.
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
I'd go for `try/except IOError` in order to make a point that variable initialized above is in fact a fallback.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
Test failure is because this is missing `geography=True` on PostGIS.
You don't like f-strings at all, do you? :-)
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Please, at most one alias, even better none. Having a long list of aliases is really bad UX IMO.
`of the it's last` -> `of its last`
nit add `a {@link Named} config`
Same could be said of newCost and newModel
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
No need to parametrize with just one case.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Maybe add an empty line above this one and give it a name, it seems like the `assert` task is just a parameter of the `openssl_certificate_info` one.
s/HashMap<String, Object> expected/Map<String, Object> expected
a list of dictionaries
This is undoing the example.
It wouldn't validate the following: - http://.com - http://. - http://.. - http://../ - http://.www.foo.bar/ - http://.www.foo.bar./ It would indeed validate the following URL (but they are actually valid): - http://example - http://example. All the others are about leading and trailing hyphens, if we really want to filter them out despite the increased complexity then I suggest we break the pattern into multiple variable for readability: https://gist.github.com/386830e46e8d2aca9dcb Regarding formal grammar, it's spread out among a bunch of RFCs, I doubt it's worth the effort.
`localhost` or rather `localhost.` is a FQDN, that shouldn't require a special case.
This can instead be `continue` and let the `else` unnest.
`del` is a builtin, not a function. These parens don't have to be here
ACk. Just FYI OS discovery can be done after CLICONF is implemented.
This can instead be `continue` and let the `else` unnest.
`del` is a builtin, not a function. These parens don't have to be here
ACk. Just FYI OS discovery can be done after CLICONF is implemented.
Maybe add an empty line above this one and give it a name, it seems like the `assert` task is just a parameter of the `openssl_certificate_info` one.
s/HashMap<String, Object> expected/Map<String, Object> expected
a list of dictionaries
Typo in `aggressive`
Typo in `aggressive`
required=False is the default, so you can omit that, same for any of the following. `name_regex=dict()`.
This is undoing the example.
Typo in `aggressive`
Typo in `aggressive`
This is undoing the example.
Typo in `aggressive`
Typo in `aggressive`
Wouldn't this approach fix the slicable fields to just these types? A mixin along with `slicable = True/False` on `F` may be an approach. Besides, I believe the policy is to keep `django.contrib.postgres` as separate as possible.
I think `get_internal_type` is better to use.
I think a mixin is a bit complicated. The attribute sounds simpler - it could be a function instead of just a boolean, then it could return the transform if applicable, else `None` for non-sliceable fields (default implementation).
All methods only used once should be explicitly inlined.
Read: coding conventions, optional fields.
Do not use underscore as prefix.
All methods only used once should be explicitly inlined.
Do not use underscore as prefix.
Read: coding conventions, optional fields.
Please change to: `options: {}`
Maybe C(.pem)? I'm not sure you need to specify that .pem is a file type since it's just the extension. @gundalow might know.
Use `C` formatting function for the sample list.
Do not use underscore as prefix.
All methods only used once should be explicitly inlined.
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
typo: ot -> to
Again, suggest rewording this as suggested for win_http_proxy.
Please change to: `options: {}`
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
I missed where you're doing the .decode.... the new version of the line should look like this: ``` python dumped += to_text(yaml.dump(abridged_result, allow_unicode=True, width=1000, Dumper=AnsibleDumper, default_flow_style=False)) ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
I think there's an extra 'if so' here.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Simplify error reporting as below, or skip this check and just let the `_html_search_regex()` calls raise the exception? ```suggestion for token in ('apiToken', 'widgetId'): if token not in rf_token_js: raise ExtractorError( 'Unable to fetch ' + token, expected=True) ```
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
```suggestion r'''widgetId:\s+["'](\w+)''', rf_token_js, 'widgetId') ```
I'd do: ``` kwargs['separators'] = kwargs.get('separators', (',', ':')) ``` On Wed, Aug 21, 2013 at 8:06 PM, Tim Graham notifications@github.comwrote: > In django/contrib/messages/storage/session.py: > > > ``` > > else: > > self.request.session.pop(self.session_key, None) > > return [] > > ``` > > > > + > > - def serialize_messages(self, messages): > > - encoder = MessageEncoder(separators=(',', ':')) > > look ok? https://gist.github.com/timgraham/dc1cc1abe202d3830eab > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/1488/files#r5903355 > .
I'd move the `separators=(',', ':')` into `__init__` of `MessageEncoder`, so we always get "efficient" (having '__json_message' as key doesn't look to efficient ;)) json without having to specify it everywhere. But we can do this in a 1.6 cleanup commit after committing this.
I think so, btw please do `resolver.kwargs.copy()` to leave the original kwargs in place on the resolver object.
Simplify error reporting as below, or skip this check and just let the `_html_search_regex()` calls raise the exception? ```suggestion for token in ('apiToken', 'widgetId'): if token not in rf_token_js: raise ExtractorError( 'Unable to fetch ' + token, expected=True) ```
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
```suggestion r'''widgetId:\s+["'](\w+)''', rf_token_js, 'widgetId') ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
consider assertRaisesMessage to make the test a bit more specific.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
consider assertRaisesMessage to make the test a bit more specific.
Same here. `self.api_client` instead of `client`
* Please use `assertRaisesMessage` here. * `flake8` will require whitespace after the `:` in the lambda.
```suggestion self.run_on_commit.append((set(self.savepoint_ids), func, True)) ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
consider assertRaisesMessage to make the test a bit more specific.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
consider assertRaisesMessage to make the test a bit more specific.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
consider assertRaisesMessage to make the test a bit more specific.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
consider assertRaisesMessage to make the test a bit more specific.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
Must not return `None`.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
I don't see any need for this attribute.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
You have some unmerged lines here
Good catch about the filter name! (And I like the extra spacing around `|` :) ) How about keeping the parantheses? I think it makes it easier to understand for the less jinja2-fluent what happens here. ```suggestion multi_group: (group_names | intersect(['alpha', 'beta', 'omega'])) | length >= 2 ```
not a show stopper, but the code might be clearer if we just add the '-n' and '%s'/dir_arg in the `if/else` and just execute `run_command` at the end
you can use `state` to avoid the 'or' to the user
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
convention for the name of the first argument of a classmethod is "cls". If the parameter isn't used at all, make it a @staticmethod instead and remove the parameter altogether.
Ah, I see it now. yeah, so just change self to be cls to match convention when using `@classmethod` and it should be fine.
not a show stopper, but the code might be clearer if we just add the '-n' and '%s'/dir_arg in the `if/else` and just execute `run_command` at the end
you can use `state` to avoid the 'or' to the user
both are valid tests, i don't see why you need to eliminate the existing one
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
as a tuple
```suggestion module.fail_json(msg="value must be of type string, integer or dict") ```
docstring with example input/output would be really helpful
you can use `state` to avoid the 'or' to the user
After looking at this some more, I don't see a good reason to open the file in binary mode only to convert each line to native string type for further manipulation. ```suggestion with open(self.USER_ATTR, 'r') as file_handler: ```
If the file isn't open in binary mode, there is no reason to decode here. ```suggestion line = line.strip() ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
prefer hanging indent style (allows longer lines, indentation always multiple of 4): ``` rasterheader = ( 1, 0, ... ) ```
This can instead be `continue` and let the `else` unnest.
This method isn't necessary.
Rather than use a `lamdba` here, it would be better to use a generator expression for clarity ```suggestion lines = line.split('::::')[1].split(';') tmp = dict(x.split('=') for x in lines) ```
Maybe `argon2_hash` -> `rest`
This method isn't necessary.
`if it encounter` => `if it encounters`
`mentionned` => `mentioned`
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
`if it encounter` => `if it encounters`
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Maybe use `self.TEST_SIZE` to avoid storing the large list of authors.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
`if it encounter` => `if it encounters`
`mentionned` => `mentioned`
It's not actually a comprehension - this could just use a tuple literal.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
I can see a decent reason to use the `DjangoJSONEncoder` as the default as it gives us `Decimal` and `datetime` support for free. These are very common use cases for django sites (especially datetime!).
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
I can see a decent reason to use the `DjangoJSONEncoder` as the default as it gives us `Decimal` and `datetime` support for free. These are very common use cases for django sites (especially datetime!).
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
chop "one of" add comma before "or"
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
@pilou-, cyberark-bizdev I had a chance to talk to bcoca today and he said the best way to do this is to pass a list of dicts to the lookup. Then either of these playbook constructs can be valid: ``` with_cyberaskpassword: - {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - {'appid': 'Application2', 'query': 'safe=Safe2;Folder=root;Object=User2', 'output': 'password,passprops.username,passprops.address'} with_cyberarkpassword: {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - debug: msg='{{ lookup('cyberark_password', {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'}) }}' ``` Implementing that will take a little restructuring. I'll go into that in the run method below.
not a list of dicts, just pass a dict to the with: ```yaml with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ```
double interpolation is very hard to read. And this looks wrong. Should probably be: `'%s%s%s%s%s' % (prefix, sep, gname, sep, gval)` (rather than `gname, prefix, gval, prefix, sep` which would generate `EnvironmenttagDevtag_`)
```suggestion self._module.fail_json(msg="value must be of type string or dict") ```
This will make the syntax Python 2.6 compatible: ```suggestion items = dict((key, _get_item(item)) for key, item in items.items()) ``` The requirement for Python 2.6 syntax compatibility will be going away, but in the meantime this will fix the CI failure.
double interpolation is very hard to read. And this looks wrong. Should probably be: `'%s%s%s%s%s' % (prefix, sep, gname, sep, gval)` (rather than `gname, prefix, gval, prefix, sep` which would generate `EnvironmenttagDevtag_`)
```suggestion self._module.fail_json(msg="value must be of type string or dict") ```
This will make the syntax Python 2.6 compatible: ```suggestion items = dict((key, _get_item(item)) for key, item in items.items()) ``` The requirement for Python 2.6 syntax compatibility will be going away, but in the meantime this will fix the CI failure.
Just a nitpick: The test name looks already readable to me so I'd drop the docstring.
I couldn't see a reason not to use `super` here, otherwise LGTM.
Never use bare except.
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
"manual" is a recent occurrence, for older versions it was 'unmarkauto' iirc
I'd use a name like `assertBackendInSession`.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
```suggestion item, fields=fields, using=self.db, ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
```suggestion item, fields=fields, using=self.db, ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
```suggestion item, fields=fields, using=self.db, ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
This should verify the output.
I don't see a reason for modifying a source exception, you can use: ```python raise ValueError(...) from e ``` Also `blew up` is not a appropriate wording and a new exception is not more informative because it refers to the field class `... the field <django.db.models.fields.CharField>` instead of `<app_label>.<model_name>.<field_name>`, maybe: ```python raise ValueError('Error during %s serializing: %s' % (field, e)) from e ``` I don't have a quick answer how to get a field path.
Thanks for updates :+1: > ... but I had trouble getting the field name, any ideas on that one? Unfortunately not, moreover I'm afraid that we will not be able to get `<app label>.<model name>.<field name>` or even `<app label>.<model name>` in a reliable way. We serialize `field` from `django.db.models` not a model attribute, that's why it's complicated or even not feasible. Each approach doesn't work in some cases, e.g. constructing messages in the `FunctionTypeSerializer` will not work for `lambda`s defined in the module: ``` Error during serializing test_one.models.<lambda>: ... ``` or imported from other modules: ``` ValueError: Error during serializing test_one.utils.<lambda>: ... ``` I think we should close this as wontfix :disappointed:
falback to a static URL.
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
Could you add at the top of Apply the following line. This will create an ems log event for users with auto support turned on. netapp_utils.ems_log_event("na_ontap_ldap", self.server)
Actually someone can sent for example '123213321321321', which isn't valid name nor ID, so it will fail with HTTP 404.
Check this: https://github.com/ansible/ansible/pull/29175/files If you will do it the same we can close that PR.
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
It looks that `test_sqlmigrate_replaced_second_migration()` and `test_sqlmigrate_replaced_migration()` are redundant. Please remove one of them.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
We can remove this block since Python 2.6 is not supported.
Please explain this in doc.
I think a mixin is a bit complicated. The attribute sounds simpler - it could be a function instead of just a boolean, then it could return the transform if applicable, else `None` for non-sliceable fields (default implementation).
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
You don't need to mock, it will return `False` for a bad file descriptor.
Download archive behavior must not change, it must only take place after success of the actual download and post processing.
```IOError``` and ```OSError``` may occur here, too. For example, if I attempt to write to ```/root``` with as a non-user user: ``` $ youtube-dl -v --skip-download test:xiami:song -o "/root/%(id)s.%(ext)s" --write-sub [debug] System config: [] [debug] User config: [] [debug] Custom config: [] [debug] Command-line args: ['-v', '--skip-download', 'test:xiami:song', '-o', '/root/%(id)s.%(ext)s', '--write-sub'] [debug] Encodings: locale UTF-8, fs utf-8, out UTF-8, pref UTF-8 [debug] youtube-dl version 2017.04.28 [debug] Git HEAD: b5c39537b [debug] Python version 3.6.1 - Linux-4.10.11-1-ARCH-x86_64-with-arch [debug] exe versions: ffmpeg 3.3, ffprobe 3.3, rtmpdump 2.4 [debug] Proxy map: {} [TestURL] Test URL: http://www.xiami.com/song/1775610518 [xiami:song] 1775610518: Downloading JSON metadata [info] Writing video subtitles to: /root/1775610518.origin.lrc Traceback (most recent call last): File "<string>", line 23, in <module> File "/home/yen/Projects/youtube-dl/youtube_dl/__init__.py", line 465, in main _real_main(argv) File "/home/yen/Projects/youtube-dl/youtube_dl/__init__.py", line 455, in _real_main retcode = ydl.download(all_urls) File "/home/yen/Projects/youtube-dl/youtube_dl/YoutubeDL.py", line 1897, in download url, force_generic_extractor=self.params.get('force_generic_extractor', False)) File "/home/yen/Projects/youtube-dl/youtube_dl/YoutubeDL.py", line 771, in extract_info return self.process_ie_result(ie_result, download, extra_info) File "/home/yen/Projects/youtube-dl/youtube_dl/YoutubeDL.py", line 832, in process_ie_result extra_info=extra_info) File "/home/yen/Projects/youtube-dl/youtube_dl/YoutubeDL.py", line 771, in extract_info return self.process_ie_result(ie_result, download, extra_info) File "/home/yen/Projects/youtube-dl/youtube_dl/YoutubeDL.py", line 825, in process_ie_result return self.process_video_result(ie_result, download=download) File "/home/yen/Projects/youtube-dl/youtube_dl/YoutubeDL.py", line 1539, in process_video_result self.process_info(new_info) File "/home/yen/Projects/youtube-dl/youtube_dl/YoutubeDL.py", line 1717, in process_info with io.open(encodeFilename(sub_filename), 'wb') as subfile: PermissionError: [Errno 13] Permission denied: '/root/1775610518.origin.lrc' ``` It should report an error ```Cannot write subtitles file``` in this case.
chop "should" (just state the behavior)
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
```suggestion pkg_version = line.partition(':')[-1].strip() ```
It doesn't work if pkg_provides contain a version: ``` max@mde-oxalide % pacman -Qqei perl | grep Provide Provides : perl-archive-tar=2.30 perl-attribute-handlers=1.01 perl-autodie=2.29 perl-autoloader=5.74 perl-autouse=1.11 perl-b-debug=1.26 perl-base=2.27 perl-bignum=0.49 perl-carp=1.50 perl-compress-raw-bzip2=2.074 perl-compress-raw-zlib=2.076 perl-config-perl-v=0.29 perl-constant=1.33 perl-cpan-meta-requirements=2.140 perl-cpan-meta-yaml=0.018 perl-cpan-meta=2.150010 perl-cpan=2.20 perl-data-dumper=2.170 perl-db_file=1.840 perl-devel-ppport=3.40 perl-devel-selfstubber=1.06 perl-digest-md5=2.55 perl-digest-sha=6.01 perl-digest=1.17_01 perl-dumpvalue=1.18 perl-encode=2.97 perl-encoding-warnings=0.13 perl-env=1.04 perl-experimental=0.019 perl-exporter=5.73 perl-extutils-cbuilder=0.280230 perl-extutils-constant=0.25 perl-extutils-install=2.14 perl-extutils-makemaker=7.34 perl-extutils-manifest=1.70 perl-extutils-parsexs=3.39 perl-file-fetch=0.56 perl-file-path=2.15 perl-file-temp=0.2304 perl-filter-simple=0.95 perl-filter-util-call=1.58 perl-getopt-long=2.5 perl-http-tiny=0.070 perl-i18n-collate=1.02 perl-i18n-langtags=0.43 perl-if=0.0608 perl-io-compress=2.074 perl-io-socket-ip=0.39 perl-io-zlib=1.10 perl-io=1.39 perl-ipc-cmd=1.00 perl-ipc-sysv=2.07 perl-json-pp=2.97001 perl-lib=0.64 perl-libnet=3.11 perl-locale-codes=3.56 perl-locale-maketext-simple=0.21_01 perl-locale-maketext=1.29 perl-math-bigint-fastcalc=0.5006 perl-math-bigint=1.999811 perl-math-bigrat=0.2613 perl-math-complex=1.5901 perl-memoize=1.03_01 perl-mime-base64=3.15 perl-module-corelist=5.20180622 perl-module-load-conditional=0.68 perl-module-load=0.32 perl-module-loaded=0.08 perl-module-metadata=1.000033 perl-net-ping=2.62 perl-params-check=0.38 perl-parent=0.236 perl-pathtools=3.74 perl-perl-ostype=1.010 perl-perlfaq=5.021011 perl-perlio-via-quotedprint=0.08 perl-pod-checker=1.73 perl-pod-escapes=1.07 perl-pod-parser=1.63 perl-pod-perldoc=3.2801 perl-pod-simple=3.35 perl-pod-usage=1.69 perl-podlators=5.006 perl-safe=2.40 perl-scalar-list-utils=1.50 perl-search-dict=1.07 perl-selfloader=1.25 perl-socket=2.027 perl-storable=3.08 perl-sys-syslog=0.35 perl-term-ansicolor=4.06 perl-term-cap=1.17 perl-term-complete=1.403 perl-term-readline=1.17 perl-test-harness=3.42 perl-test-simple=1.302133 perl-test=1.31 perl-text-abbrev=1.02 perl-text-balanced=2.03 perl-text-parsewords=3.30 perl-text-tabs=2013.0523 perl-thread-queue=3.12 perl-thread-semaphore=2.13 perl-threads-shared=1.58 perl-threads=2.22 perl-tie-file=1.02 perl-tie-refhash=1.39 perl-time-hires=1.9759 perl-time-local=1.25 perl-time-piece=1.3204 perl-unicode-collate=1.25 perl-unicode-normalize=1.26 perl-version=0.9923 perl-xsloader=0.30 ```
Most of the time if you want a list and you're using map() you can convert to a list comprehension for a more pythonic (and faster, although that's almost never an issue) implementation: ``` python current_rules = [(x['priority'], x['rule_name']) for x in get_rules(api, name)] ```
Looks like this could be a single line.
Same. The `filter` doesn't make sense to me
Looks like this could be a single line.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Looks like this could be a single line.
I am split on my feelings about this function. It doesn't work the same as it did as part of `AnsibleModule`. Before, it would error on the first time that `count > 1`, whereas we aren't doing so now, we are collecting them all, but then not using them all. Additionally, this is more like `list_mutually_exclusive`. I think this function should raise some form of Exception, instead of just returning a list of the mutually exclusive args that were provided by the user.
This code isn't correct. (2, 7) is the check you want, and then with >= if I am not mistaken.
it should also check if it can write there
Might want to use simple quote here.
Might want to check `rc` status before return output.
Use _ (underline) instead of webpage if the value is not used.
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
Use _download_webpage is urlh is not used. And note should be meaningful for typical users.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
I think something like `SETTING_BOTH` will be fine. No need to memorialize the bug number.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Since Ansible subscribes to unicode sandwich, this should be the callers' (actually, where the data enters the system) responsibility.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
I can't think of any reason off the top of my head that we'd need to customize the module object creation, so just having create_module return `None` *should* be fine. IIRC `exec_module` is literally just about populating the module (already created by create_module or the base import machinery) from the code; the 3.x import machinery takes care of the transactional insertion/removal from `sys.modules` on fresh imports and reloads, so we should probably never mess with that in the 3.x loader code at all. It's been awhile, but I think it basically just calls create_module (and does the stock creation if we didn't return something), provisionally inserts the module to `sys.modules`, calls exec_module under an exception handler, and removes the module on an error if it inserted it.
Add trailing comma.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
Remove blank line (and below).
Remove blank line (and below).
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
So if I update some parameter+ change state to running, it won't start, IIUC
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
Should be ``self.weight``
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Should be ``self.weight``
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Should be ``self.weight``
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
```python if state == "disabled": if current_state == "enabled": self._commands.append('interface {0} {1} no traffic-class {2} congestion-control'.format(if_type, if_id, tc)) continue ```
Please don't make lines longer! There was nothing really wrong with this line before
Good catch, I will remove it before final squash.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Please don't make lines longer! There was nothing really wrong with this line before
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
```not (foo is None)``` => ```foo is not None```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
Good catch, I will remove it before final squash.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
`target` is only available for `Col`, so it crashes for expressions, see `test_slicing_of_f_expression_with_annotated_expression`.
This will not work for `OuterRef()` :disappointed: because we don't resolve it properly, so it generates: ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING(U0."name", 3, 1)) LIMIT 1 ) ``` instead of ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING("expressions_company"."name", 3, 1)) LIMIT 1 ) ``` see `test_slicing_of_outerref`.
We allow up to 119 characters, so this doesn't need to be wrapped. ```suggestion def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): ```
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
I don't see any need for this attribute.
OTOH, this does nothing since the module is already cached by the time this gets executed. So it's a no-op.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
Note that format strings changed in python-2.7 So things like "{} {}".format() needs to change to "{0} {1}".format() for python-2.6 compatibility.
okay, but would be helpful to say _why_ we need to always return True.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
okay, but would be helpful to say _why_ we need to always return True.
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
`form_class` is defined in `RangeField.formfield()` so this is redundant.
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
You can skip the blank lines in these tests as three lines long isn't too difficult too read with spaces.
I'd use a name like `assertBackendInSession`.
Please use assertRaisesMessage to verify this is the ValueError we expect.
> Umh... this is a breaking change. @phihag should we add a hidden backwards compatibility `--write-srt`, or just specify the change in release notes? > Please stay backwards-compatible.
As Collin said, slightly longer lines are okay rather than awkward wrappings like this.
I'd revert this as I don't think it is better and it isn't making this more consistent with code elsewhere. ```suggestion if isinstance(stored_backend, RemoteUserBackend): ```
Please ignore, my suggestion is invalid syntax.
with -> width
comma after tuple
like diff = load_config(self._module, config_xml, [])
`id` isn't used, it is sufficient to iterate on keys.
User of this inventory plugin should be able to use `v6_main_ip` for value of `ansible_host` (i don't know if it makes sens to be able to use `internal_ip`) or no `ansible_host` at all (meaning that `server['label']` will be used instead).
In Python3, `super()` is enough.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
Can this fail with KeyError? It looks like that was transformed to InvalidCacheBackendError in the old code.
You can skip the blank lines in these tests as three lines long isn't too difficult too read with spaces.
```suggestion params = self.settings[alias].copy() ```
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
`enumerate` on for range.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
`enumerate` on for range.
This should be extracted very first.
Instead, please set `self.index = json.load(f)`. The JSON library uses the `.load` function to stream straight from files without needing to `.read()` first. This also avoids pesky encoding issues with Python2/3.
CI failure due to trailing whitespace (PEP 8 check): ``` 2017-02-08 14:44:54 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2_win_password.py:167:10: W291 trailing whitespace (legacy) ```
use same indent style as previous item
Instead, please set `self.index = json.load(f)`. The JSON library uses the `.load` function to stream straight from files without needing to `.read()` first. This also avoids pesky encoding issues with Python2/3.
CI failure due to trailing whitespace (PEP 8 check): ``` 2017-02-08 14:44:54 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2_win_password.py:167:10: W291 trailing whitespace (legacy) ```
If you use a catchall exception handler like this then you should also provide the traceback like this: ``` python import traceback from ansible.module_utils._text import to_native [...] module.fail_json(msg='Unanticipated error running atomic: %s' % to_native(e), exception=traceback.format_exc()) ```
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
You might want to specify a different error handler here. The default handler is surrogate_or_replace. When non-utf8 byte sequences are encountered, it either uses surrogateescape if available or replace. This can munge output on python2. Since we're sending this to json.loads (rather than displaying it to the user) it might be better to use surrogate_or_strict as the error handler here.
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
You might want to specify a different error handler here. The default handler is surrogate_or_replace. When non-utf8 byte sequences are encountered, it either uses surrogateescape if available or replace. This can munge output on python2. Since we're sending this to json.loads (rather than displaying it to the user) it might be better to use surrogate_or_strict as the error handler here.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
Not strictly necessary as the default for parameter is that they're not required.
Please remove this. It is wrong. Don't add a default in this case.
Again, this could be a class level attribute.
Do we need to return module_path? I don't see that we modify it anywhere and the calling code already has it.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
flake8 complains about missing spaces around `*`
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
with -> width
Gotcha, okay I think this is acceptable.
I think all the calls to `render()` can be removed (it worked for me in this test at least)
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
comma after tuple
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
```suggestion return '-' + value if neg else value ```
```suggestion return '-' + value if neg else int(value) ```
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
are you sure about this point of "consist of only A-z0-9-_=", as opposed to those characters may not appear in the separator? (not too familiar with this restriction myself) I don't know that the complexity of a `setter` is necessary. I'd just modify the test to initialize a `Signer` each time.
I think this should be: ``` python values = map(lambda x: x.strip(), tags['Value'].split(',')) ``` Basically the same as it was before this change but with `tags['Value']` instead.
may be blind, but think this will never get fired if v is empty. you create an empty list, which will be skipped in the for loop.
Use the context manager version of `open()` so you don't need to worry about closing it manually.
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
I think all the calls to `render()` can be removed (it worked for me in this test at least)
Gotcha, okay I think this is acceptable.
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
I think it's fine. Separate test cases are normally a good thing since they can fail individually.
What concerns me is the implication (not directly stated in the docs, at least that I can find) that you can't add/modify a Lightsail instance's keypair after creation (short of ssh'ing to the instance with an existing key and editing auth keys by hand). **If** this is correct, I feel like we should anticipate users having a problem here and make keypair a required option for create actions. It may not be boto-y, but it's still something we can easily anticipate and make nicer for our users. If that's not correct and I'm just missing something about Lightsail key management, then maybe keypair management or a lightsail_key module would be good future improvements (but outside the scope of this PR).
Personal niggle: boto3 doesn't list keyPairName as a 'required' argument. I have some use cases where I bake the keys into the AMI and don't want to pass an additional key to the instances...
Why not use a list comprehension here? It's probably more efficient: `return [self.sanitize_keys(i) for i in data]`
Instead of `list`, use `Sequence`. Similarly, replace `dict` above by `Mapping`. (You'll need `from ansible.module_utils.common._collections_compat import Mapping, Sequence` to be able to do that.)
may be blind, but think this will never get fired if v is empty. you create an empty list, which will be skipped in the for loop.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
I can see a decent reason to use the `DjangoJSONEncoder` as the default as it gives us `Decimal` and `datetime` support for free. These are very common use cases for django sites (especially datetime!).
Code duplication 80-86, 89-94.
Try except blocks should be as small as possible. In this case, if is only needed around the calls to modify and delete. Perhaps put the try except around the if state conditional to limit the statements that it surrounds
`call_command()` raises an exception so these lines are unreachable.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
> I think this isn't a great trade-off to make, the special branch for "is the length exactlyt the same" will cost more than it saves across a range of different input string types. Only a few will match it. Yeah, I wondered whether the exact length check might be detrimental. > Regardless this is a rarely used DB function, this is too much time spent optimizing it already :) 😄 Yup. Happy with your solution.
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
I think we don't need it. but lets @felixxm decide about it. Thanks for the patch :+1:
Do we really need this test? seems it doesn't relate to this change.
You can skip the blank lines in these tests as three lines long isn't too difficult too read with spaces.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
> I think this isn't a great trade-off to make, the special branch for "is the length exactlyt the same" will cost more than it saves across a range of different input string types. Only a few will match it. Yeah, I wondered whether the exact length check might be detrimental. > Regardless this is a rarely used DB function, this is too much time spent optimizing it already :) 😄 Yup. Happy with your solution.
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
Inline everything used only once.
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
`enumerate` on for range.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
It should be `if self._module.params.get('sparse') is not None`, because if `sparse` is `False` it won't send `sparse=False`
@chrisvanheuveln and I chatted about this. No further changes needed here since we avoid the 400 error with the order change and the command is blocking.
I think this option is deprecated - https://www.vmware.com/support/developer/converter-sdk/conv51_apireference/vim.vm.RelocateSpec.Transformation.html
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Plz also use `match` arg here
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Yeah, so none of the tests failed if I forced either the multiple or single argument form of the function. That can't be right.
I'd split this line in two
```suggestion query=dict(type='list', elements='str'), ```
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
Is there specific value in doing this for all variants here? In particular, does the security protocol variation get us something that existing tests don't? Another way of asking this is, beyond the failures we would catch with existing tests where brokers generally fail to communicate with each other when using specific security protocols, is there a way we think reassignment specifically would fail that would be related to the security protocol? E.g. is there a different inter-broker connection that's being made that otherwise wouldn't be made? I ask because I think we already test a lot of stuff with variations of security protocols and I'm a bit worried about test bloat due to parametrizing tests being relatively easy (and leading to much longer test runs).
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
Note: this is usually expressed as: ``` python if not full_version: ```
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
I don't see any need for this attribute.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
You have some unmerged lines here
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
I don't see any need for this attribute.
with -> width
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
Casting `int` to `int` is not necessary.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
We allow up to 119 characters, so this doesn't need to be wrapped. ```suggestion def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): ```
it should also check if it can write there
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Similarly, ```if tc['skip'].get('i')```
For some reason this causes ``` {aliases: [attr]} {choices: [all, 'no', none, safe, urllib2, 'yes']} {default: [200]} ``` while non-sequence values for `default` yield ``` default: 30 ``` without the `{...}`.
`is` tests identity in python so if statement always produces a change. We need to use `!=` here to compare equality instead of identity.
This would be a nice place to use tuple expansion `action, index = index_of_matching_route(....)`
```suggestion (u'1', u'PB', 1125899906842624), (u'1E', 1152921504606846976), (u'1EX', 1152921504606846976), (u'1Z', 1180591620717411303424), (u'1ZB', 1180591620717411303424), (u'1Y', 1208925819614629174706176), (u'1YB', 1208925819614629174706176), ```
last loaded wins, but iirc, we reverse search on handlers list
I know, was just wondering if it's intended that it works that way.
For some reason this causes ``` {aliases: [attr]} {choices: [all, 'no', none, safe, urllib2, 'yes']} {default: [200]} ``` while non-sequence values for `default` yield ``` default: 30 ``` without the `{...}`.
`is` tests identity in python so if statement always produces a change. We need to use `!=` here to compare equality instead of identity.
This would be a nice place to use tuple expansion `action, index = index_of_matching_route(....)`
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
`if it encounter` => `if it encounters`
Drop the `as e` since it's not used, and is not compatible with python 2.4.
Another map that can be a list comprehension: ``` content = [x.strip() for x in m.group(3).split(" and ")] ```
Instead of including a stacktrace in the message, better to put it into the exception field: ``` module.fail_json(msg="Xpath %s causes a failure: %s\n -- tree is %s" % (xpath, to_native(e), etree.tostring(tree, pretty_print=True)), exception=traceback.format_exc()) ```
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
oh, woops. thought I counted right. sry
```suggestion 'url': 'https://learning.oreilly.com/learning-paths/learning-path-python/9781788996396', ``` I assume it would be good to include one link starting with "learning.oreilly.com" in tests.
This can be a separate ticket, but this message probably needs to be revised now that migrations are compulsory for all apps in 1.9.
Migrations plans with both forwards and backwards migrations are not supported.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
should this be super()
`None` as a default value to `get()` is not required here. I would also just do `if method` since `None` is falsey it's really a nitpick.
I believe this was meant to be a `references` check instead of a `reduce` check? Since `reduce` returns operations, not a boolean. Something like "`not op.references(other)`" so that we can ensure that `other` can properly be pulled forwards
This can be a separate ticket, but this message probably needs to be revised now that migrations are compulsory for all apps in 1.9.
Migrations plans with both forwards and backwards migrations are not supported.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
++ thanks for changing this :)
You should be able to use `self.vmware_test_platform` here.
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
Remove the blank lines.
++ thanks for changing this :)
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
++ thanks for changing this :)
please fail if required stuff is null
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
Remove unnecessary whitespace.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Remove unnecessary whitespace.
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Remove unnecessary whitespace.
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
No, `set_fs_attributes_if_different` respects `module.check`.
Minor consistency nit- our stuff seems to be using `[action]_[backend]()`, where these aliased imports have that reversed. I'd vote for `[action]_[backend]()` over this- makes the code a little easier to read...
```suggestion params = self.settings[alias].copy() ```
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
Usually, testing private interfaces doesn't make sense.
It doesn't matter whether it's a method or a function. A private function is related to the module scope, a private method is related to the class. Still, both are private, it's just a different level of namespacing. If a module name starts with an underscore it'd be also private.
For algorithmic code, it can make sense to test private methods and private functions in isolation from the rest of the code. This does seem to be a place where that could be justified. The code being tested is functional (meaning it operates via parameters and return values rather than callbacks) and it plugs into a larger framework which is outside of our control. What I'll sometimes do is push all the permutations of data that I care about at the private function and then push a small subset at the public interface to make sure that the interaction between the public and private code is working as expected.
Do we need this check? All tests pass without it.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
Wouldn't this approach fix the slicable fields to just these types? A mixin along with `slicable = True/False` on `F` may be an approach. Besides, I believe the policy is to keep `django.contrib.postgres` as separate as possible.
After taking a look at the new function, I could see leaving the stub function in so that it can establish default values for arg_spec and params.
This is a private function (starts with an underscore) so I'd hope we could move this without having to leave a stub for backwards compatibility. If you want to remove the stub in a separate commit/PR just in case, though, I can live with that.
You'll want to branch off `< 3.6`.
Might make sense to raise exception in this case: ``` class Test: @cached_property def a(self): pass b = a ```
@graingert Probably it doesn't worth it, but still doable :-) ``` In [85]: class desc: ...: def __init__(self, f): ...: self.name = f.__name__ ...: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: ...: for cls in cls.__mro__: ...: name = '_%s%s' % (cls.__name__, self.name) ...: if cls.__dict__.get(name) is self: ...: return name ...: ...: class A: ...: @desc ...: def __x(self): ...: pass ...: ...: ...: class B(A): ...: pass ...: In [86]: a = A() ...: a._A__x ...: Out[86]: '_A__x' In [87]: b = B() ...: b._A__x ...: Out[87]: '_A__x' ```
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
`items = value.split(self.delimiter) if value else []` is slightly faster.
And this can be reverted.
I would chop blank lines in this test.
Chop `Ensure that`.
Technically since we're doing this in a fixture, either `monkeypatch` should be used to insert these into `globals()`, or you should return `mod`, and then just use `mod.Template` and `mod.AnsibleNativeEnvironment` in your tests.
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
`items = value.split(self.delimiter) if value else []` is slightly faster.
And this can be reverted.
Try to minimize the test that demonstrates the regression. I think this part isn't important -- assigning a value when creating the model should work just as well.
Instead of infinite checking, please cap the amount of time to some (can be long) value. 5 or 10 minutes would be *plenty* for CFN to generate a changeset.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
```suggestion item, fields=fields, using=self.db, ```
single line as above
Similarly, ```if tc['skip'].get('i')```
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
I think a better wording would be: "Backwards compatibility for storage backends without support for `max_length` will be removed in Django 2.0."
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
I'm not sure the docstring adds any value here.
Honestly, I just failed to invent a better name
Having it upstream would be nice, but I doubt we can change our minimum required Jinja2 version anytime soon.
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
Remove unnecessary whitespace.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
Does replication factor matter in this test at all? I can't think of why it would matter for the replication factor, so it seems weird to make it 2 here.
Remove unnecessary whitespace.
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
Remove unnecessary whitespace.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
with -> width
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
Does replication factor matter in this test at all? I can't think of why it would matter for the replication factor, so it seems weird to make it 2 here.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
ð to not needing this
This is usually not needed
Indeed, you are right.
I'd omit the blank line since it's hard to get confused in 3 lines of code. Also the commit message could describe the issue being fixed instead of the implementation of the fix.
I typically use something like the following: ```python return str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'} ``` This works whether you pass a boolean, integer or string, although we are only expecting a string from the environment anyway. If we wanted to be strict, we should reject invalid values: ```python if str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'}: return True if str(val).lower() in {'0', 'f', 'n', 'off', 'false', 'no'}: return False raise ValueError('Non-boolean string provided.') ```
It seems `AMQPConnectionError` could be used instead of `Exception`.
can be ignored
hm maybe that's what I've searched for
It seems `AMQPConnectionError` could be used instead of `Exception`.
hm maybe that's what I've searched for
can be ignored
Is this possible? If so, it will be good to cover this scenario with tests.
I fixed this issue in fe0ddbc84e4d8836ce8d27a1218d360c5482c2be.
I think this should use the `request['path']`.
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
If you're going to do partition, I'd rather use the fact that it'll always return a 3-tuple instead of using `-1` to index the third element. i.e.: ```python line.partition(':')[2] ```
The following properties indicate if
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
If you're going to do partition, I'd rather use the fact that it'll always return a 3-tuple instead of using `-1` to index the third element. i.e.: ```python line.partition(':')[2] ```
The following properties indicate if
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
```suggestion pkg_version = line.partition(':')[-1].strip() ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Having a class for just one test method is unnecessary.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Having a class for just one test method is unnecessary.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
1. No umask respected. 2. There is no `os.chmod` in python 3.2 according to python [docs](https://docs.python.org/3/library/os.html#os.chmod). 3. flake8.
Maybe `files_total`? We already break things, so...
Might be nice for demonstration purposes if the two records actually have different keys. Maybe: ```suggestion aTopic.pipeInput(1, "999-alpha"); bTopic.pipeInput(999, "beta"); ```
One thing that worries me here is that it'll discard any `kwargs` so if `output_field` is provided, since we allow it to be passed as a positional argument it will be lost. e.g. `Subquery(queryset, models.BooleanField())`.
use tags.items() here, no need for iteritems import
flake8 complains about missing spaces around `*`
I don't see a need for string interpolation in cases like this.
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
Should contain `quality` key.
`enumerate` on for range.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
This doesn't look like it is tested.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
`self._options_context` stores the context of parent options in case of nested suboptions. As the `elif` block does not have a recursive call to `_handle_options` context handling is not required here. However, context information can be added as part of error message in case this argument is part of nested sub-options (similar to other error messages in sub-option handling).
This doesn't look like it is tested.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
`self._options_context` stores the context of parent options in case of nested suboptions. As the `elif` block does not have a recursive call to `_handle_options` context handling is not required here. However, context information can be added as part of error message in case this argument is part of nested sub-options (similar to other error messages in sub-option handling).
I think `get_internal_type` is better to use.
This should probably be the last method in the class.
this is unsafe and can lead to race conditions and data corruption, you should write to a temp file and use `basic`'s `atomic_move` method to finalize changes.
I think `get_internal_type` is better to use.
This should probably be the last method in the class.
this is unsafe and can lead to race conditions and data corruption, you should write to a temp file and use `basic`'s `atomic_move` method to finalize changes.
Instead of infinite checking, please cap the amount of time to some (can be long) value. 5 or 10 minutes would be *plenty* for CFN to generate a changeset.
I think `get_internal_type` is better to use.
It'd be better here to catch boto exceptions & other exceptions separately, since generic exceptions (like IOError if the network fails, for example) don't have status codes and other boto-isms.
this is unsafe and can lead to race conditions and data corruption, you should write to a temp file and use `basic`'s `atomic_move` method to finalize changes.
`is` tests identity in python so if statement always produces a change. We need to use `!=` here to compare equality instead of identity.
This can instead be `continue` and let the `else` unnest.
this is unsafe and can lead to race conditions and data corruption, you should write to a temp file and use `basic`'s `atomic_move` method to finalize changes.
`is` tests identity in python so if statement always produces a change. We need to use `!=` here to compare equality instead of identity.
This can instead be `continue` and let the `else` unnest.
```suggestion assert expected == "exception" ```
Ahh true, sorry for the noise. No changes are required.
I removed it.
Maybe `subTest` to make tests less repetitive e.g.: ```python msg = 'Geotransform must consist of 6 numeric values.' for geotransform in ([1, 2], [1, 2, 3, 4, 5, 'foo'], [1, 2, 3, 4, 5, 6, 'foo']): with self.subTest(geotransform=geotransform): with self.assertRaisesMessage(ValueError, msg): rsmem.geotransform = geotransform ```
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Don't we usually subscribe to a "unicode sandwich" strategy where functions pass around unicode strings and the function converts to bytes or native strings when it crosses an external boundary? I've also seen the `b_` or `n_` prefix being used if a function specifically accepts a byte or native string but not sure if that's an actual guideline we have going forward.
If `date` and `time` is not added as part of a file name (in case of a configurable backup path option) `date` and `time` logic can be changed to fetch from the file information probably using os.stat()
```suggestion self.assertTrue(self.temp_dir.joinpath(name).exists()) ```
I'm not sure it's useful to implement _set_container in the base class, as the path seems different depending on stream.
These last four lines are duplicated in both conditions, should therefore come after the if block.
I'm curious if this should be a `BaseException` so that it'd work on `Ctrl+C` (`SIGINT`) or `SystemExit` (`SIGTERM`).
This doesn't look right. This basically allows Python 3.0.1+, not 3.0.0+ as you probably intended. But even with that, it's best to just compare the major version and use "py2 or not py2" because py3+ also means py4+. OTOH we vendor `six` which contains proper constants already. So just import that: ```python from ansible.module_utils import six if six.PY2: ... else: ... ```
I am split on my feelings about this function. It doesn't work the same as it did as part of `AnsibleModule`. Before, it would error on the first time that `count > 1`, whereas we aren't doing so now, we are collecting them all, but then not using them all. Additionally, this is more like `list_mutually_exclusive`. I think this function should raise some form of Exception, instead of just returning a list of the mutually exclusive args that were provided by the user.
```suggestion 'module': ('async_wrapper', ), 'cache': ('base', ), ```
I think we prefer the closing paren on a newline
this is too aggressive as it removes all ACLs, not just the ones we added take into account that directories can have 'default acl' to be added to all new files in a directory, this would wipe those along with the one we added to copy the file into place
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
Based on my reading of the MSDN doc this should just result in returning the default value, not throwing an Exception. "Returns the last element of an observable sequence that matches the predicate, or a default value if no value is found." http://msdn.microsoft.com/en-us/library/hh228948(v=vs.103).aspx It should return the last value that matches the predicate, but if nothing matches then it should return the default value.
This whole block should be changed into: ```python module = AnsibleModule( argument_spec=dict( name=dict(type='str', required=True), remote=dict(type='str'), state=dict(type='str', default="present", choices=['absent', 'present']) ), supports_check_mode=True, ) ``` Assuming that **name** is always required, and **repo** is required when **state == 'present'**. - Put the type-option first, as this one is usually always added - Lines in Ansible can be 160 chars wide, so there's usually no need to split it a line
No need to split the line.
#66872 seems to think this would be 1.10.0, from experience I'd suspect it's actually a botocore version that's required...
It requires `botocore>=1.13.21`
Rather than running this test inside create_autoscaling_group I'd recommend running it in main() prior to any possible changes happening.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Do we need to call `list(fields)` here? :thinking:
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
This should be botocore.exceptions.NoCredentialsError.
Catch botocore.exceptions.ClientError instead of Exception here too.
If this is set to type='int' this should avoid the later type conversion
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
I don't think you should re-number the existing tests.
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
Omit these lines please.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Breaks once `userData` is not first.
Carry long lines. Bother to finally read coding conventions.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
++ thanks for changing this :)
```suggestion # Note: These examples do not set authentication details, see the AWS Guide for details. ``` It's helpful to hint the AWS Guide here so folks know about it.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
add 'python library' , then the 'pip install' becomes redundant, some people cannot use pip to install libraries
Chop blank line.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Add trailing comma.
Chop blank line.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Add trailing comma.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
`form_class` is defined in `RangeField.formfield()` so this is redundant.
This is actually useful, since a `.get('volumes', [])` can still return `None` if the value `volumes` is explicitly None, as opposed to nonexistent.
This will also have to take into account `filter(m2m__field=val1, criteria=m2m__otherfield=val2)` != `filter(m2m__field=val1).filter(m2m__otherfield=val2)` as explained in [spanning multi-valued relationships](https://docs.djangoproject.com/en/1.11/topics/db/queries/#spanning-multi-valued-relationships)
I think chaining `filter`/`exclude` should be an `AND` not an `OR`. It makes more sense to me and I'm pretty sure that what queryset `filter`/`exclude` do.
Just in case it's probably a good idea to use `.get()` instead of dict access syntax in case the key is unset.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Please ignore, my suggestion is invalid syntax.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
use to_native (module_utils._text) instead of str, it deals with py2/py3 compatiblity
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
Clarify 'we', if possible.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
iirc we decided to allow configure commands as part of cli_command to support config commands that result in a command prompt
following task -> the following task
Please use a single quote.
set the safe
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Please use a single quote.
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
Indeed, you are right.
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
is the `any` required here - `if metrics_to_disable:` should suffice, I'd think
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Ah, yes. Good observation. 🙂
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
I'd revert this as I don't think it is better and it isn't making this more consistent with code elsewhere. ```suggestion if isinstance(stored_backend, RemoteUserBackend): ```
This is a "set" method called from redfish_config (which doesn't pass in the systems_uri param). So need to remove that param here and just use self.system_uris[0] below.
Use single quotes for strings, unless there's a nested single quote. ([Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style))
Should check for a list.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Should check for a list.
Check for `compat_str` also.
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
I'd revert this as I don't think it is better and it isn't making this more consistent with code elsewhere. ```suggestion if isinstance(stored_backend, RemoteUserBackend): ```
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
I'd revert this as I don't think it is better and it isn't making this more consistent with code elsewhere. ```suggestion if isinstance(stored_backend, RemoteUserBackend): ```
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
There are multiple formats, some may have `file` some may not. If some new hq format is introduced with different rendition your approach will break downloading by default while proper URL handling will not. Finally read coding conventions.
Whether it has changed or not does not mean there should be a format with invalid URL.
This sentence ``` "To validate an individual application's models rather than all applications' models, call ``self.check(app_configs)`` from ``handle()``, where ``app_configs`` is the list of application's configuration provided by the app registry." ``` is still valid. I will restore it.
```suggestion to iterate use a C(with_) directive. ```
(In general, I don't think modules should have such options.)
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Co-locate this with Lag and the base class rather than defining alphabetically. Same as First/LastValue.
`arity = 1`
Also here, I don't know why you are splitting lines. It does not make it easier to read. Usually it is done out of necessity (e.g. PEP8 rules require it), but in this case there is no need to make this weird.
Various modules allow to specify the name of the executable in order to use a binary from a non-standard location (i.e. a binary not located in the PATH). Look at e.g. the isoextract on how to do this.
I don't think Lightsail allows custom AMIs, at least from what I've seen in the docs and prodding at the console a bit. There is a question of if we should have a default to use the region default key when state=present instead of requiring a user specification, generally the way lightsail does keys is different from the way ec2 does keys though and I'm still familiarizing myself with the differences.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Just trash it IMO, and the corresponding one in gis. The converters changes already completely removed/renamed two (private) methods on DatabaseOperations and Compiler
`target` is only available for `Col`, so it crashes for expressions, see `test_slicing_of_f_expression_with_annotated_expression`.
This will not work for `OuterRef()` :disappointed: because we don't resolve it properly, so it generates: ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING(U0."name", 3, 1)) LIMIT 1 ) ``` instead of ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING("expressions_company"."name", 3, 1)) LIMIT 1 ) ``` see `test_slicing_of_outerref`.
```suggestion raise ValueError('Slice stop must be greater than slice start.') ```
Match the error message
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
```suggestion - There is a small delay (typically about 5 seconds, but can be as long as 30 seconds) before obtaining the random values when requesting a validation. ```
I was also confused by this logic for a while and I got an optimization idea from the [Raft dissertation](http://wcl.cs.rpi.edu/pilots/library/papers/consensus/RAFTOngaroPhD.pdf) about this, The sentence below is taken from section "5.4.2 Committing entries from previous terms": ``` There are some situations where a leader could safely conclude that an older log entry is committed (for example, if that entry is stored on every server), but Raft takes a more conservative approach for simplicity. ``` so we can also update commitIndex(highWatermark) if logEndOffset of all followers have passed the highWatermark. I don't think this is a good idea since it makes the logic opaque but will not necessarily really optimize any performance, so I just mention it here and feel free to ignore it ð.
aws_ip_ranges -> aws_service_ip_ranges
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
You probably should add yourself to the authors list as well.
You should really have at least one example with `state=absent`.
I see the old tests do this, but (AFAICS) there's no reason to to store `post_data` on `self`. (It's not accessed outside this test case.)
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
with -> width
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
with -> width
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
with -> width
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
with -> width
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
redundant, remove ```suggestion ```
I'm not sure why these tests raises a `ProgrammingError` :thinking:
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
with -> width
Ok thanks Tim
I think a better wording would be: "Backwards compatibility for storage backends without support for `max_length` will be removed in Django 2.0."
I would consider that as not working
I think it's the right class: ``` In [38]: class desc: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: return instance.__dict__['_%s__mangled' % cls.__name__] In [39]: class A: ...: d = desc() ...: ...: def __init__(self): ...: self.__mangled = 42 ...: In [40]: A().d Out[40]: 42 ```
I would prefer to keep a slice logic with `start` and `stop` instead of `low` and `length`.
Chop blank line.
We can remove this check after fixing the `Field.slice_expression()`.
```suggestion assert isinstance(wrap_var(['foo']), list) ```
```suggestion assert wrap_var([None])[0] is None ```
```suggestion assert isinstance(wrap_var(set(['foo'])), set) ```
> But I think it would be better if we didn't let the debug implementation slow the non-debug implementation more. Yeah. That did occur to me, but haven't had time to check the performance. It might still work out in concert with other ideas I've had… But those don't need to hold this up.
I think that you could move the slicing inside `DebugLexer._tag_re_split()` and then `DebugLexer.tokenize()` will be even closer to `Lexer.tokenize()`: ```suggestion for bit, position in self._tag_re_split(): ``` Maybe with these changes it makes sense to rename `DebugLexer._tag_re_split()` to something like `.split()` and add the same method to `Lexer` with something like: ```python def split(): yield from ((bit, None) for bit in tag_re.split(self.template_string)) ``` Then you should be able to ditch `DebugLexer.tokenize()` entirely and inherit it.
I think `get_internal_type` is better to use.
this module is marked as "legacy" and therefore the CI is not complaining about pep8 here, but it would help if we try to be pep8 compliant.
yep, that is what I meant, basically make sure new code is pep8 compliant
Plz use a context manager to have a safe resource closing ```suggestion with tarfile.open(tar_filepath, mode='w:gz') as tar_file: ```
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Yeah, it's fine.
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Yeah, it's fine.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
WDYT about adding `or self.title` here? ``` python self.title = title or self.title or self.lookup_title ``` This would add support for the following: ``` python class MyStaffFilter(BooleanFieldListFilter): title = "By can haz admin" # no effect :( overwritten in __init__ @admin.register(User) class UserAdmin(UserAdminBase): list_filter = ( ("is_staff", MyStaffFilter), ) ```
What do you think about ```python def __repr__(self): template = "<%(name)s: fields='%(fields)s'%(fastupdate)s%(gin_pending_list_limit)s>" template_values = { 'name': self.__class__.__name__, 'fields': ', '.join(self.fields), 'fastupdate': '', 'gin_pending_list_limit': '', } if self.fastupdate is not None: template_values['fastupdate'] = ', fastupdate=%s' % ('True' if self.fastupdate else 'False') if self.gin_pending_list_limit is not None: template_values['gin_pending_list_limit'] = ', gin_pending_list_limit=%d' % self.gin_pending_list_limit return template % template_values```
Do you think we're adding value with such complicated `__repr__` methods? I've thought maybe we should ditch worrying about including of Index's params in them and just let `Index.__repr__` show the basics. Does the repr should up anywhere important? I can't think of anywhere.
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion pkg_name = line.partition(':')[-1].strip() ``` idem, no need to lower.
@thomwiggers `line.partition(':')[2]` yes, I have no problem with that.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
```suggestion item, fields=fields, using=self.db, ```
Would it be better to raise `NotImplementedError()` so backends don't overlook implementing it? They can always return an empty list if it's not supported.
This can be single-lined: ```suggestion return (matched_tags or not tags) and not test_tags.intersection(exclude_tags) ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
maybe should be get('properties', {}).get('ipConfigurations') so it will be shorter
these lines are a bit long... ``` m2m_field = models.ManyToManyField( VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz, related_name="rn1", ) ```
Note that ...
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
Indeed, you are right.
Such an extensive docstring is not necessary, IMO.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
I think we should create a hook similar to the `_field_should_be_indexed()`, that will allow 3rd-party backends to adjust this behavior, e.g. ```python class BaseDatabaseSchemaEditor: ... def _field_should_be_altered(self, old_field, new_field): # Don't alter when changing only a field name. return ( old_field.column != new_field.column or old_field.deconstruct()[1:] != new_field.deconstruct()[1:] ) ```
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
This is a private function (starts with an underscore) so I'd hope we could move this without having to leave a stub for backwards compatibility. If you want to remove the stub in a separate commit/PR just in case, though, I can live with that.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Ensure that the new arguments are keyword only: ```suggestion def handle_word( self, word, *, safe_input, trim_url_limit=None, nofollow=False, autoescape=False, ): ```
I removed the NotIn assertions in my edits because they are brittle since a typo in the message means they would inadvertently pass. I suppose if error messages were class attributes that would make it more robust, but it seems unlikely to me that a regression could be introduced such that both messages are displayed.
The new implementation should support signatures for a number of resolvelib versions. They could be defined dynamically in runtime.
Ah, right, got it :+1:
I think we should add an `allow_overwrite` or similar param.
This check is also redundant.
Maybe add "ansible versions below 2.10" or something so it's clear this is a one-time problem, not that they can never upgrade `ansible` again...
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
```python raise ValueError( "ISO week directive '%s' is incompatible with the year " "directive '%s'. Use the ISO year '%%G' instead." % ( week_format, year_format, ) ) ```
As long as they both equals it shouldn't make a difference. By that I mean you should have a test asserts `Index('foo') == Index(F('foo'))` An alternative could be to defer that to `create_sql`.
flake8 complains about missing spaces around `*`
Whoaw, I knew there was an impact, but did not suspect this. This is ugly. cc @kbreit Opened a ticket for this. https://github.com/ansible/ansible/issues/52717
We tend to use HAS_REQUESTS as a standard way of doing this, but... We actually prefer that modules use *lib/ansible/module_utils/urls.py*, specifically **fetch_url()** or **open_url()** for anything HTTP/REST based.
```suggestion - requests (Python library) ```
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
I removed it.
add trailing comma
I wonder if something like `serialize_result` might be a more descriptive name for this function.
Actually this should be `classmethod` for `InlineModelAdmin` and a regular method for `ModelAdmin`.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
it seems this and other parameters are missing from docs
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
```suggestion old_item['aliases'] = sorted(old_item['aliases']) ```
Please create shallow copies to avoid the original data to be modified: ```suggestion new_item = dict(new_item) old_item = dict(old_item) # Sort the aliases ```
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
yeah I think it would be worthwhile to at least test a single JOIN scenario.
I think this test would be fine without the blank lines, it's fairly short.
single line looks okay here
yeah I think it would be worthwhile to at least test a single JOIN scenario.
I think this test would be fine without the blank lines, it's fairly short.
single line looks okay here
Since utilities functions can be called in tight loops it's best to minimize the number of Python function calls when readability doesn't suffer too much.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
Not convinced we need this example, particularly with `with_` going away.
2.6 or 2.7? Also you `requirements` listed here and the modules.
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
Not convinced we need this example, particularly with `with_` going away.
2.6 or 2.7? Also you `requirements` listed here and the modules.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
I'm not sure why but other parts of the code are using "my" for the variable name for a yum_base object so we should keep doing that.
With this reinstated, it looks as though a test is needed as you didn't remove one...
`import botocore` will make this code a lot more consistent with most other boto3-based ansible modules
Minor but I'd move this control flow block after the `weights` one to match the args order.
It should not. See the description of the field.
Yes, fine with me.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
`wait` should be used if the `Service` is expected to exit naturally based on previous commands: ``` Wait for the service to finish. This only makes sense for tasks with a fixed amount of work to do. For services that generate output, it is only guaranteed to be available after this call returns. ``` You generally do not need to use it in concert with `stop` as `stop` is generally implemented either to synchronously wait (on a clean shutdown via SIGTERM) or kills aggressively enough that you don't actually have to wait (i.e. SIGKILL). I suspect many of the uses of `wait`/`stop` with these `Service` classes are just redundant -- that is rare or non-existent elsewhere. Use of `wait` elsewhere is mostly limited to things like a console producer/consumer that are known to need to consume a limited amount of data.
@ewencp thanks for chiming in! Just double checked the code of `StreamsTestBaseService#stop_node()` is indeed calling with clean_shutdown to true, i.e. to wait for the pid to die out. So the second `wait` call should be removable.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
So I noticed this long list of options without defaults or choices. Possibly this is exactly what is intended. However, in a lot of cases there is an implicit default that could be mentioned (even when it's not enforced when missing). If you initialize a new swarm I expect there are defaults set.
What are the default values for te below parameters if you do not specify it on creation ? - task_history_retention_limit - keep_old_snapshots - log_entries_for_slow_followers - heartbeat_tick - election_tick - dispatcher_heartbeat_period - node_cert_expiry - ca_force_rotate - autolock_managers These possibly require an additional entry in the description to state the defaults on creation. (So you can't add a real default value, because that may modify an existing entry)
nit: needs a comma after the `{@link ...}`
nit: remove empty line
I don't think we can do this. Also, I would only mention it, when we start to deprecate an API.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
it should be `minor_vers = int(version[1])`
Note that `LooseVersion` could be used there: ``` from distutils.version import LooseVersion [...] return LooseVersion(version) < LooseVersion('3.2') ```
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
```suggestion assert expected == "exception" ```
```suggestion assert expected == "exception" ```
@CruxBox my point is that you are already returning in the case of an exception *and* in the `else` clause so the code is equivalent to ```python try: date_value = datetime.date(int(y), int(m), int(d)) except ValueError: # Return pseudo-ISO dates with zeros for any unselected values, # e.g. '2017-0-23'. return '%s-%s-%s' % (y or 0, m or 0, d or 0) date_value = datetime_safe.new_date(date_value) return date_value.strftime(input_format) ``` Again, this is minor but we usually avoid using `try/else` in the rest of the code base unless it's necessary.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
chop "one of" add comma before "or"
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
I think I'd keep the `fields` parameter as a list, perhaps passing `None` for `params` here.
That's already better, but there is even a cached_property decorator in django.utils.functional that does the job of caching the value.
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
Cross-compability, backwards compatibility, command line compatibility, ease of discovery. * Other packaging modules support comma separated package entries. * The pip module itself supports comma separated package entries * pip supports single string entries as valid packages * comma separated list entries are the natural way to write lists on the commandline. * error messages if people were to violate these rules (for instance: ```ansible localhost -m pip -a 'names=django>=1.11.0,<1.12.0'``` wonn't point to the actual solution unless we implement this sort of detection for creating the error message... in which case we might as well do the right thing.
As far as I understand this is only necessary to support stuff like `djang>1.11.0,<1.12.0,bottle>0.10,<0.20,!=0.11`. Why should we support this? Using a list is to me the obviously better API and support this structure adds a lot of (to me unnecessary) complexity.
Functions which are side effect free and don't deal with external information like this one are excellent choices to unittest. You can give the function a wide range of potential inputs and check that they match up with the expected outputs far cheaper than you can with intergration tests.
I think I'd keep the `fields` parameter as a list, perhaps passing `None` for `params` here.
`,` is fine here.
this should be done once(in `_real_initialize`).
```suggestion assert expected == "exception" ```
```suggestion assert expected == "exception" ```
@CruxBox my point is that you are already returning in the case of an exception *and* in the `else` clause so the code is equivalent to ```python try: date_value = datetime.date(int(y), int(m), int(d)) except ValueError: # Return pseudo-ISO dates with zeros for any unselected values, # e.g. '2017-0-23'. return '%s-%s-%s' % (y or 0, m or 0, d or 0) date_value = datetime_safe.new_date(date_value) return date_value.strftime(input_format) ``` Again, this is minor but we usually avoid using `try/else` in the rest of the code base unless it's necessary.
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
Ensure that the new arguments are keyword only: ```suggestion def handle_word( self, word, *, safe_input, trim_url_limit=None, nofollow=False, autoescape=False, ): ```
I prefer putting the closing ) on the next line
Good catch, I will remove it before final squash.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Good catch, I will remove it before final squash.
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Good catch, I will remove it before final squash.
Should be ``self.weight``
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
I prefer putting the closing ) on the next line
prefer hanging indent style with 1 arg per line
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
`band_input`, you don't get much by saving one char :-)
`elif` might be clearer (I understand it's not necessary)
prefer hanging indent style with 1 arg per line
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
I prefer putting the closing ) on the next line
This doesn't need to be quoted.
The same like above.
This should also start on the line above if the other is moved.
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
"any other input"
2.6 or 2.7? Also you `requirements` listed here and the modules.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
tempted to have no default and make it 'yes|no' boolean, use 'default' behaviour when `None`
`if it encounter` => `if it encounters`
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
tempted to have no default and make it 'yes|no' boolean, use 'default' behaviour when `None`
`if it encounter` => `if it encounters`
Minor but I'd move this control flow block after the `weights` one to match the args order.
Thanks. This PR is assigned to the 2.12 milestone, which we'll be going through after creating the stable-2.11 branch (which will be done when 2.11 RC1 comes out).
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.headers = { 'Content-Type': "application/json" } ```
This can be moved to `check_dict` method.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
```suggestion self.params[k] = 2 if v == 'dns' else 1 ```
```suggestion self.headers = { 'Content-Type': "application/json" } ```
preferred format is "#15346, #15573 - Issue description"
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
`band_input`, you don't get much by saving one char :-)
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
How about adding `self.assertIs(response.context['is_multipart'], True)` before the `assertContains()` (since those can be difficult to debug)? (Might be worth adding a similar assertion somewhere for the False case.)
I prefer putting the closing ) on the next line
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
`field_preference` must be a list or a tuple.
Code duplication 80-86, 89-94.
I prefer putting the closing ) on the next line
Code duplication 80-86, 89-94.
prefer hanging indent style with 1 arg per line
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
`((app_label, model_name), [fields])` LGTM On April 1, 2015 3:46:12 PM GMT+02:00, Alex Hill notifications@github.com wrote: > > - from those operations and use them to provide a nicer error > > message. > > + > > - This will work for any function passed to > > lazy_related_operation that > > - has a keyword argument called 'field'. > > - """ > > + > > - def extract_field(operation): > > - # Expect a functools.partial with a kwarg called 'field' > > applied. > > - try: > > - return operation.func.keywords['field'] > > - except (AttributeError, KeyError): > > - return None > > + > > - extract_fields = lambda ops: list(filter(None, > > map(extract_field, ops))) > > + > > - # Generate pairs of (("app_label", "modelname), [fields]) > > Yes you do. The idea was to give an example of the literal contents of > the variable rather than its origins, hence the quotes surrounding each > element. I'm happy to go with `(app_label, model_name)`, without the > quotes. > > --- > > Reply to this email directly or view it on GitHub: > https://github.com/django/django/pull/4423/files#r27569838
missing quote after `modelname` which should also be `model_name`
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
`((app_label, model_name), [fields])` LGTM On April 1, 2015 3:46:12 PM GMT+02:00, Alex Hill notifications@github.com wrote: > > - from those operations and use them to provide a nicer error > > message. > > + > > - This will work for any function passed to > > lazy_related_operation that > > - has a keyword argument called 'field'. > > - """ > > + > > - def extract_field(operation): > > - # Expect a functools.partial with a kwarg called 'field' > > applied. > > - try: > > - return operation.func.keywords['field'] > > - except (AttributeError, KeyError): > > - return None > > + > > - extract_fields = lambda ops: list(filter(None, > > map(extract_field, ops))) > > + > > - # Generate pairs of (("app_label", "modelname), [fields]) > > Yes you do. The idea was to give an example of the literal contents of > the variable rather than its origins, hence the quotes surrounding each > element. I'm happy to go with `(app_label, model_name)`, without the > quotes. > > --- > > Reply to this email directly or view it on GitHub: > https://github.com/django/django/pull/4423/files#r27569838
missing quote after `modelname` which should also be `model_name`
`re.sub` part can be put in `transform_source` parameter of `_parse_json`.
**Always** check code with flake8.
I think you can get rid of the rstrip('\n') here for the same reason as you got rid of it in _find_bind_mounts() (or alternatively, if rstrip is necessary here, then it's probably still needed in _find_bind_mounts() as well).
Since this `int()` call is no longer inside a `try` `except`, we now get a stack trace if the checksum is an invalid base 16 value. ``` ValueError: invalid literal for int() with base 16: '541a1ef5373be3dc49fc542fd9a65177b664aec01c8d8608f99e6ec95577d8ci' ``` ```suggestion try: int(checksum, 16) except ValueError: module.fail_json(msg='The checksum format is invalid', **result) ```
Trick credit: https://twitter.com/raymondh/status/967927989752098816
Oh.. I missed the part about "more than two lines", so please post example output, so we could take a closer look at the issue together :)
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
this get_field_by_name should be adjusted with formalized model meta API I guess
There should be a sane API through `schema` ( A SchemaEditor, I presume) to do this.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
2.6 or 2.7? Also you `requirements` listed here and the modules.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
I might be missing something but I can't come up with a way `escape_isnt_last_filter is True` when reaching this branch as the only way to get in there is when `seen_escape_filter is True` which is only set in the `isinstance(obj, EscapeData)` branch below where `escape_isnt_last_filter` is immediately set to `False`.
It's hard to assess the correctness of this change through visual inspection. I'll trust you (and the test suite) on this.
IMO, we can use `self.template_string` without an extra variable.
Why has this logic changed? I can't see what it has to do with removing the use of `_clone()`
No, I think you've changed both of them. I don't think they're any more similar now than they were, the logic is fundamentally the same and this sort of change is not needed.
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
Why has this logic changed? I can't see what it has to do with removing the use of `_clone()`
No, I think you've changed both of them. I don't think they're any more similar now than they were, the logic is fundamentally the same and this sort of change is not needed.
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
I might be missing something but I can't come up with a way `escape_isnt_last_filter is True` when reaching this branch as the only way to get in there is when `seen_escape_filter is True` which is only set in the `isinstance(obj, EscapeData)` branch below where `escape_isnt_last_filter` is immediately set to `False`.
It's hard to assess the correctness of this change through visual inspection. I'll trust you (and the test suite) on this.
IMO, we can use `self.template_string` without an extra variable.
Why has this logic changed? I can't see what it has to do with removing the use of `_clone()`
No, I think you've changed both of them. I don't think they're any more similar now than they were, the logic is fundamentally the same and this sort of change is not needed.
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
First we should verify this passes before we toggle `is_active` to False.
I think there isn't much organization there. Using an existing site should be fine.
Please do not revert this doc change. The old text is wrong in almost every important way.
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
For consistency path pruning should be done the same as in the boilerplate test: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L13-L14 https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L41-L42
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
multiple dictionary access: instead of ```python if required_config.get('rotation', None): rotation = required_config['rotation'] ``` use: ```python rotation = required_config('rotation') if rotation is not None: # do your stuff ``` use this rule for all dictionary access below
No need for get(key, None) as None is the default fix also for following get()
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
Is there precisely one time you can specify this? It sounds to me like this should be allowed to repeat multiple times. So this should be a `list`. Or maybe even better a `dict`, so people can specify things like ``` blkio_weight_device: /dev/sda: 100 /dev/sdb: 200 ```
You should emphasize that the module can and will not do any idempotence checking for this.
(In general, I don't think modules should have such options.)
2.6 or 2.7? Also you `requirements` listed here and the modules.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
[...] remove matching rows **for rel_b**.
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
[...] remove matching rows **for rel_b**.
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
The wording we usually use is "django.utils.translate.string_concat() is deprecated in favor of django.utils.text.format_lazy()."
It would be better to mention that in the release notes. :-)
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
Meanwhile, I merged a conflicting patch. I think you just need to remove the quotes from around the star.
flake8 doesn't like the hanging indent here.
The wording we usually use is "django.utils.translate.string_concat() is deprecated in favor of django.utils.text.format_lazy()."
It would be better to mention that in the release notes. :-)
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
That does make sense. Thanks.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
#19359 will take more time to discuss (so far no reaction at all) and it makes no sense to stall this pr on it. We can remove the examples for now and if we find we keep `IndexLookup` anyway add them again.
```suggestion Set I(version=latest) to get the most recent version of a given image. ```
This shouldn't be automatically adjusted, just a note saying refs style must be 64.
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I don't see any need for this attribute.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
```suggestion b_opath = os.path.realpath(to_bytes(os.path.join(path, group))) ```
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
it seems this and other parameters are missing from docs
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
Hmm, I thought we'd have `LATEST_0_10_1` and `LATEST_0_10_0` instead of `LATEST_0_10` (which doesn't make sense because we have multiple feature releases in the `0_10` line.
Nit: maybe there should be no default for `should_fail` since we always pass a value.
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
Nit: maybe there should be no default for `should_fail` since we always pass a value.
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
I'd personally expand these to `kafka1` and `kafka2` as I reserve single character varnames (or variants with numbers appended) to indexes, but that's very much a nit.
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
This should be wrapped like this: ``` state=dict( required=False, default="present", choices=['present', 'absent']) ```
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
I'd personally expand these to `kafka1` and `kafka2` as I reserve single character varnames (or variants with numbers appended) to indexes, but that's very much a nit.
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
Shouldn't need this line, it's handled by the superclass's constructor.
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
it seems this and other parameters are missing from docs
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
it seems this and other parameters are missing from docs
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
Good call. I've confirmed that if we leave this as-is, the topic creation command leaves out `min.insync.replicas` We want `"min.insync.replicas": 2` -> `'configs': {'min.insync.replicas': 2}`
In another PR (https://github.com/apache/kafka/pull/563/files), Rajini is claiming that this doesn't work as expected. @granders is verifying that claim and we may want to update this based on the outcome of that investigation.
Basically `os.path.isfile(metadata_filename)` is superfluous here since we control the file lifetime on our own and since we don't delete the file it should exist. This check may only fail if someone touched our file that is unexpected scenario that normally should not happen. In such cases we should stop right at failed `os.remove` rather than skipping such unexpected outcome with this check. If someone touches our files then it's definitely wrong and we should not continue.
Exception is raised if the file can't be created or opened. You'll never reach here in this case.
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
These last four lines are duplicated in both conditions, should therefore come after the if block.
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
don't use print, display.error or raise an AnsibleError exception, Ansible already does not fail due to an Exception from a callback event.
This can be single lined.
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
to_text and u prefix on string.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
I was also confused by this logic for a while and I got an optimization idea from the [Raft dissertation](http://wcl.cs.rpi.edu/pilots/library/papers/consensus/RAFTOngaroPhD.pdf) about this, The sentence below is taken from section "5.4.2 Committing entries from previous terms": ``` There are some situations where a leader could safely conclude that an older log entry is committed (for example, if that entry is stored on every server), but Raft takes a more conservative approach for simplicity. ``` so we can also update commitIndex(highWatermark) if logEndOffset of all followers have passed the highWatermark. I don't think this is a good idea since it makes the logic opaque but will not necessarily really optimize any performance, so I just mention it here and feel free to ignore it ð.
```suggestion * 5) {@link FetchSnapshotRequestData}: Sent by the follower to the epoch leader in order to fetch a snapshot. * This happens when a FetchResponse includes a snapshot ID due to the follower's log end offset being less * than the leader's log start offset. This API is similar to the Fetch API since the snapshot is stored * as FileRecords, but we use {@link UnalignedRecords} in FetchSnapshotResponse because the records * are not necessarily offset-aligned. ```
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
Thanks. This PR is assigned to the 2.12 milestone, which we'll be going through after creating the stable-2.11 branch (which will be done when 2.11 RC1 comes out).
There is no point to use `remove_start` since line is always a string.
I removed it.
check here for the regex fix https://github.com/Qalthos/ansible/pull/5/commits/89f2a106db4f7296822e118ad24f66cea84f3be9#diff-e72efaa6b72beb5339ad847e21a31220L87 Good catch on the first_port / last_port ... will add a fix for those. This is a common pattern to be used by eos modules. I have held off on pushing the modules upstream until we get the initial push of the refactored network shared modules
I believe you would need to add a custom `save_form` method to a `ModelAdmin` and somehow incorporate the `change` flag in it -- perhaps modify the form's cleaned_data to assign the field to a model field before save.
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
is the `any` required here - `if metrics_to_disable:` should suffice, I'd think
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
`update_fields` can be any iterable, `iter({}) -> dict_keyiterator` ```suggestion obj.save(using=self.db, update_fields=defaults) ```
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
`update_fields` can be any iterable, `iter({}) -> dict_keyiterator` ```suggestion obj.save(using=self.db, update_fields=defaults) ```
Why double-underscore? I would also rename `func` to `callback`: ```suggestion for _, callback in connections[using].run_on_commit[start_count:]: callbacks.append(callback) if execute: callback() ```
This should work: ```suggestion transaction.on_commit(self.enqueue_callback) ```
Maybe I'm missing sth, but can we use `@contextmanager`? ```python class TestCase(TransactionTestCase): ... @contextmanager def captureOnCommitCallbacks(self, *, using=DEFAULT_DB_ALIAS, execute=False): self.callbacks = [] start_count = len(connections[using].run_on_commit) try: yield self.callbacks finally: run_on_commit = connections[using].run_on_commit[start_count:] self.callbacks[:] = [func for sids, func in run_on_commit] if execute: for callback in self.callbacks: callback() ```
Why double-underscore? I would also rename `func` to `callback`: ```suggestion for _, callback in connections[using].run_on_commit[start_count:]: callbacks.append(callback) if execute: callback() ```
This should work: ```suggestion transaction.on_commit(self.enqueue_callback) ```
Maybe I'm missing sth, but can we use `@contextmanager`? ```python class TestCase(TransactionTestCase): ... @contextmanager def captureOnCommitCallbacks(self, *, using=DEFAULT_DB_ALIAS, execute=False): self.callbacks = [] start_count = len(connections[using].run_on_commit) try: yield self.callbacks finally: run_on_commit = connections[using].run_on_commit[start_count:] self.callbacks[:] = [func for sids, func in run_on_commit] if execute: for callback in self.callbacks: callback() ```
should this be super()
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
preferred format is "#15346, #15573 - Issue description"
Since Ansible subscribes to unicode sandwich, this should be the callers' (actually, where the data enters the system) responsibility.
Such an extensive docstring is not necessary, IMO.
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
a OrderedSet, like @timgraham suggested
Such an extensive docstring is not necessary, IMO.
This doesn't need to be quoted.
This should also start on the line above if the other is moved.
The same like above.
This doesn't need to be quoted.
What kind of values are valid here? I would expect this to be `float` based on the `0.0` in the description.
I would remove all aliases if possible.
