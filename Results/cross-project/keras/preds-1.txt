Test failure is because this is missing `geography=True` on PostGIS.
Test failure is because this is missing `geography=True` on PostGIS.
Test failure is because this is missing `geography=True` on PostGIS.
dashboardId parameter is missing.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
I think we can move entire `ordering` logic to a separate branch i.e. ```python if self.ordering: ... sql, sql_params = super().as_sql(compiler, connection, ordering=( 'ORDER BY ' + ', '.join(ordering_expr_sql) )) return sql, sql_params + ordering_params return super().as_sql(compiler, connection, ordering='') ```
@puzan `rabbitmqctl status` doesn't support `vhost`. I run RabbitMQ 3.6.16. As quick fix, I added `add_vhost=True` as default argument to `_exec` to have something like this : ```python def _exec(self, args, run_in_check_mode=False, split_lines=True, add_vhost=True): .... some code here .... if add_vhost: args.insert(1, '-p') args.insert(2, self._vhost) ```
There are some options to `AnsibleModule` which you may be able to use to validate options passed in. Look at existing modules for examples: ``` required_together required_one_of require_if ```
There are some options to `AnsibleModule` which you may be able to use to validate options passed in. Look at existing modules for examples: ``` required_together required_one_of require_if ```
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
Add a trailing comma.
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
argument ordering should be reversed
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
You should be able to use `SimpleTestCase` (which prevents any queries) by setting an `id` manually on your score instance, avoiding the `save()` call and passing a singleton list containing `score` to `serializer.serialize()`: ``` python data = serializer.serialize([Score(id=1, score=3.4)]) ``` With this approach you should be able to hardcode the `"pk": 1` below as well.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Minor but I'd move this control flow block after the `weights` one to match the args order.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
not a list of dicts, just pass a dict to the with: ```yaml with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ```
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
`copy()` in unnecessary.
`copy()` in unnecessary.
This syntax is not supported in python2.6. You will need to index your format like `{0}`
I wonder if it's worth pointing to the alternative here. 🤔
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
```python if threshold_mode == "absolute": delimiter = ' ' else: delimiter = '%' min_val = int(min_threshold.split(delimiter)[0]) max_val= int(max_threshold.split(delimiter)[0]) congestion_control = dict( control=mode.lower(), threshold_mode=threshold_mode, min_threshold=min_val, max_threshold=max_val) ```
You added the return statement to the above if the condition which means no need else statement. You should remove it to make it easier to read.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
Defining `__init__()` to specify a default `output_field` is required until we re-arrange `runtests.py` to avoid importing settings dependant modules before calling `django.setup()`.
Defining `__init__()` to specify a default `output_field` is required until we re-arrange `runtests.py` to avoid importing settings dependant modules before calling `django.setup()`.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
```not (foo is None)``` => ```foo is not None```
We don't need tags in this function, I think.
We don't need tags in this function, I think.
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
I don't see a need for string interpolation in cases like this.
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
Use same `env_fallback` as `X_AUTH_TOKEN`
Ah, i'd expect a bool to always be True/False, if that is not the case (no time to test really right now :)), then indeed, this needs to stay (and this goes for my other bool remarks)
- extract mandatory information first. - incorrect fallback.
comma after tuple
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
```suggestion # RemovedInDjango50Warning: When the deprecation ends, revert to # FORM_RENDERER="django.forms.renderers.Jinja2", ```
Also missing parentheses: > during vm execution (e.g. due to a vm label update),
I think we can move entire `ordering` logic to a separate branch i.e. ```python if self.ordering: ... sql, sql_params = super().as_sql(compiler, connection, ordering=( 'ORDER BY ' + ', '.join(ordering_expr_sql) )) return sql, sql_params + ordering_params return super().as_sql(compiler, connection, ordering='') ```
I think that there is no need to check all empty values, so maybe: ``` # Default should be populated on an empty value. pub_form = PubForm({}) pub_form.mocked_mode = '' pub = mf2.save(commit=False) self.assertEqual(pub.mode, default_mode) ```
is not specified.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Function calls are complex. For example: ``` from youtube_dl.jsinterp import JSInterpreter jsi = JSInterpreter(''' function a(x) { return x; } function b(x) { return x; } function c() { return [a, b][0](0); } ''') print(jsi.call_function('c')) ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
put closing parenthesis on the next line
`copy()` in unnecessary.
`copy()` in unnecessary.
`copy()` in unnecessary.
chop "one of" add comma before "or"
chop "one of" add comma before "or"
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
I think this should be false (not a string)
prefer hanging indent style with 1 arg per line
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
For long query strings, it's better to use ```query``` parameter here.
For long query strings, it's better to use ```query``` parameter here.
I prefer putting the closing ) on the next line
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
not Python 3 compatible
As per PEP257 you should have a sentence here, hence it should end with a period: ```suggestion """Test that lenient_lowercase() proper results.""" ``` Also, let's rephrase it to contain useful info.
If changing to `None` from `''` in `.slice_expression()` above, then: ```suggestion if self.end is None: return f'{lhs}[%s:]', params + [self.start] else: return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
Remove print statement: ```suggestion ```
Match the error message
Line is too long.
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
`George. R. R. Martin` → `George R. R. Martin` (Remove the extra period, and throughout below.)
With this simplification, the pythonic way of generating a list is to use list comprehension. You can replace the whole function body with: ```python return [parse_to_obj(r) for r in parse_to_logical_rows(vlan_out)] ```
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
We can also go faster by using a list comprehension instead of a generator - they're cheaper to create: ```suggestion obj.combined_queries = tuple([query.clone() for query in self.combined_queries]) ``` Simple benchmark: ``` In [2]: items = [1, 2, 3, 4] In [3]: %timeit tuple(x*2 for x in items) 508 ns ± 10 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [4]: %timeit tuple([x*2 for x in items]) 358 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
Code duplication 80-86, 89-94.
Code duplication 80-86, 89-94.
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
no restructured text (:class:) in docstrings please
no restructured text (:class:) in docstrings please
no restructured text (:class:) in docstrings please
Is there a typo? I'm not sure what "hub" means in this sentence.
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
`client.start_execution` is idempotent but `start_execution` always returns `changed=True` if `action=start`. We probably want to `client.list_executions` to see if the execution is already running before proceeding.
Migrations plans with both forwards and backwards migrations are not supported.
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
It seems this URL doesn't work anymore.
no restructured text (:class:) in docstrings please
no restructured text (:class:) in docstrings please
Any problem with: ``` @property def media(self): ```
no restructured text (:class:) in docstrings please
no restructured text (:class:) in docstrings please
DRY 105, 107.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
This conditional is not required anymore given the check above.
Chop blank line.
`video_id` literal is not a video id.
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
`enumerate` on for range.
`enumerate` on for range.
You could use RenameMethodsBase.
You could use RenameMethodsBase.
Need spaces around `+` sign.
- i don't think that `type="hidden"` is important. - checking for ext is not needed here.
There seems to be an assumed structure of what is returned by the API endpoint, operating under the pretense that the structure won't change since the API is versioned, is there any chance that this assignment could fail and cause an unhandled exception? (similar question for other functions doing similar things below)
How about this - ```suggestion msg = "No corresponding incident" if len(incidents) == 0: if state in ('acknowledged', 'resolved'): return msg, False return msg, True elif state != incidents[0]["status"]: return incidents[0], True return incidents[0], False ```
I would remove all aliases if possible.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Code duplication 80-86, 89-94.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
`field_preference` must be a list or a tuple.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
For long query strings, it's better to use ```query``` parameter here.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
Test failure is because this is missing `geography=True` on PostGIS.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
Is anything `required_together`, if not please remove this line
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
`gluster_peer_ops` is unconditionally called and this method always calls `get_nodes`. `get_nodes` fails when `nodes` parameter isn't set: this parameter must be mandatory (and non empty). For that, you could use a custom method, meaning something like that: ``` class AnsibleModuleCheckListNotEmpty(AnsibleModule): def _check_type_list_not_empty(self, value): value = self._check_type_list(value) # default checks for a list if not value: raise ValueError("list must not be empty") return value [...] module = AnsibleModuleCheckListNotEmpty( argument_spec=dict( force=dict(type='bool', required=False), nodes=dict(type=self._check_type_list_not_empty, required=True), [...] ``` Once implemented you could remove the `get_nodes` method.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
with -> width
```suggestion # just get value from attribute itself as normal ```
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
Please use a single quote.
```suggestion - There is a small delay (typically about 5 seconds, but can be as long as 30 seconds) before obtaining the random values when requesting a validation. ```
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
As the Python `urlencode()` already handles scalars, I think this could be slightly simplified to: ```py if isinstance(value, (list, tuple)): query_val = [ item if isinstance(item, bytes) else str(item) for item in value ] else: query_val = value ```
Then use `enumerate()` instead.
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
Doesn't isatty bomb on none? It does for me...
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Similarly, I don't see much advantage to creating indirection with a method.
A bit DRYer? ``` python value = self.rhs if isinstance(value, datetime.datetime): output_field = models.DateTimeField() elif isinstance(value, datetime.date): output_field = models.DateField() else: output_field = None if output_field: value = models.Value(value, output_field=output_field) self.rhs = value.resolve_expression(compiler.query) ```
I'd put the trailing `}` in a new line.
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
`field_preference` must be a list or a tuple.
It would be clearer to the end-user if the help was "Shows output from passing tests."
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
I think you might want to rollback at this point.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
This seems overly simplistic, we should at least be sure to the extend that we should check the signature of the function on whether or not it supports more than two arguments.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
```suggestion assert isinstance(wrap_var(b'foo'), type(b'')) ```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Missing `=dict` on this and the next few lines
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Please use triple double quotes around docstrings. ([PEP 257](https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring))
Similarly, ```if tc['skip'].get('i')```
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
This is not changed.
This is not changed.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
I would chop blank lines in this test.
I would chop blank lines in this test.
> I think this isn't a great trade-off to make, the special branch for "is the length exactlyt the same" will cost more than it saves across a range of different input string types. Only a few will match it. Yeah, I wondered whether the exact length check might be detrimental. > Regardless this is a rarely used DB function, this is too much time spent optimizing it already :) 😄 Yup. Happy with your solution.
Please remove this blank line as requested by Paolo.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
As with the old `_batched_insert` code, I think we should pass the db alias here `self._insert(objs_without_pk, fields, using=self.db)`, it defaults to that but passing it seems more explicit.
Unindent by 1 space. Indention must be a multiple of 4 spaces.
See my previous review for indentation style of this. Perhaps the common qs stuff before the last filter can be moved to setUpTestData.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
What if the prepared value contains unicode? (As I said before, you should use a list comprehension instead of a generator, it'll be about 2 times faster here)
It seems like no_log and deprecation are separate things and should be handled in separate functions.
- try to use `refreshTokenUrl` and fallback to static URL. - break long lines when possible. - `data` should not be a dict. - extract `token` directly.
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
A message string would good to say that image is not preset or something similar.
Please wrap at 79 chars.
I don't see any need for this attribute.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
The mixup to me is that people using incorrect units will silently be using bytes, whereas it should report this as an error.
The mixup to me is that people using incorrect units will silently be using bytes, whereas it should report this as an error.
These should be handled in the arg_spec using `aliases`.
Does this need to be a separate method? Seems unnecessary to me.
You could use lambda to save some lines defining the function
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Is there a typo? I'm not sure what "hub" means in this sentence.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Any problem with: ``` @property def media(self): ```
okay, but would be helpful to say _why_ we need to always return True.
Please remove choices for `type='bool'`, as `bool` accepts yes,1,true, etc.
Read: coding conventions, mandatory fields.
yeah I think it would be worthwhile to at least test a single JOIN scenario.
yeah I think it would be worthwhile to at least test a single JOIN scenario.
like diff = load_config(self._module, config_xml, [])
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
1. `_sort_formats`. 2. Must not break if any of these keys is missing.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
`del` is a builtin, not a function. These parens don't have to be here
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Can you move the global declarations to one place? Easy for the future maintainer.
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
Test failure is because this is missing `geography=True` on PostGIS.
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
this is a catchall, we normally frown on those. also note that for all of your `% e` they should be `% to_native(e)` to ensure proper character conversions
How about: ``` if storage_engine == 'InnoDB': return self.connection.mysql_version >= ( (10, 2, 2) if self.connection.mysql_is_mariadb else (5, 7, 5) ) return storage_engine in ('MyISAM', 'Aria') ```
Test failure is because this is missing `geography=True` on PostGIS.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Use built-in method? Also, should it crash (raise) if `json.loads()` fails, or just return an empty dict again? ```suggestion try: return self._download_json( url, song_id, data=data.encode('ascii'), headers=headers) except ExtractorError as e: if type(e.cause) in (ValueError, TypeError): # JSON load failure raise except Exception: pass return {} ```
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Should be ``self.weight``
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
```suggestion Test that the returned value for timezone consists of only uppercase ```
```suggestion Test that the returned value for timezone consists of only uppercase ```
I prefer putting the closing ) on the next line
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Is there a typo? I'm not sure what "hub" means in this sentence.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Is there a typo? I'm not sure what "hub" means in this sentence.
Is there a typo? I'm not sure what "hub" means in this sentence.
Is there a typo? I'm not sure what "hub" means in this sentence.
happy new year ! yeah effectively finally this is required for python < 3.5 as you explain (I just tested it in an interactive session). I'm happy to open a PR with this specific change so.. should not be too long to come..
happy new year ! yeah effectively finally this is required for python < 3.5 as you explain (I just tested it in an interactive session). I'm happy to open a PR with this specific change so.. should not be too long to come..
happy new year ! yeah effectively finally this is required for python < 3.5 as you explain (I just tested it in an interactive session). I'm happy to open a PR with this specific change so.. should not be too long to come..
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
like diff = load_config(self._module, config_xml, [])
```suggestion vault_data(), ```
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
like diff = load_config(self._module, config_xml, [])
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
```suggestion assert ansible_json_encoder.default(test_input) == {'__ansible_vault': expected} ```
```suggestion assert ansible_json_encoder.default(test_input) == {'__ansible_vault': expected} ```
This one is a bit newer to CliBase, but also implemented verbatim in superclass
like diff = load_config(self._module, config_xml, [])
Another new addition is a bunch of *_config methods raising NotImplementedError if not overriden in the subclass. Which is to say, `replace_config()` is also unnecessary here
IIRC get_cols() was renamed to get_group_by_cols() some time ago - no need to have both.
No need to split the line.
Any problem with: ``` @property def media(self): ```
No need to split the line.
If changing to `None` from `''` in `.slice_expression()` above, then: ```suggestion if self.end is None: return f'{lhs}[%s:]', params + [self.start] else: return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
Thanks for the patch @Giebisch, I think we should adjust the `expected_outputs` instead to be properly formatted in order to ensure formatting is actually used. https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L90-L111 https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L124-L133 The adjustments made make the tests pass with and without the proposed changes.
This is a "set" method called from redfish_config (which doesn't pass in the systems_uri param). So need to remove that param here and just use self.system_uris[0] below.
We confirmed that `parallelism` should be taken into account.
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
put the closing parenthesis on the next line
Turn (capitalize) add period. sql -> SQL
Dict literals are preferred (0d74c41981687598d3fa0a7eb9712ce4c387ca19).
We can reuse existing objects.
Making this change here doesn't work because we aren't guaranteed to have passlib installed. The crypt.crypt() method will require that we have a salt set. You could move salt generation into the conditional for ```not HAS_PASSLIB```.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
Turn (capitalize) add period. sql -> SQL
put the closing parenthesis on the next line
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
I don't see a need for string interpolation in cases like this.
I don't see a need for string interpolation in cases like this.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
It's more readable to write this out into multiple if-then statements.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
For long query strings, it's better to use ```query``` parameter here.
@chrisvanheuveln and I chatted about this. No further changes needed here since we avoid the 400 error with the order change and the command is blocking.
Please change this to `2.7`.
Oh, so these modules have existed for a while, we are just upstreaming them now, that makes sense.
Simplify this by not adding required=False, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
This regex does not make any sense.
Should also include `block_size` and `parallelism`
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Should also include `block_size` and `parallelism`
Please ignore, my suggestion is invalid syntax.
This looks like a good change, however, for consistency with the rest of the code, I think we should use `self._play_context.ssh_executable` until we decide to switch the connection plugin in full over to using `get_option`.
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
The final command should probably return its stdout, stderr and rc back to the playbook.
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
If the issue is corrected. There will be some cases triggering this branch, please also update the user cases of the `raw_cloud_env` variable.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
It would be better to mention that in the release notes. :-)
It would be better to mention that in the release notes. :-)
shouldn't this line and the one below just not be here, and the loop be `for arg, version in self.DEFAULT_DEPRECATED_ARGS` (though those aren't really a default either, so `DEFAULT` is a bit of a misnomer)
like diff = load_config(self._module, config_xml, [])
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
okay, but would be helpful to say _why_ we need to always return True.
This can be single-lined: ```suggestion return (matched_tags or not tags) and not test_tags.intersection(exclude_tags) ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
may be blind, but think this will never get fired if v is empty. you create an empty list, which will be skipped in the for loop.
Ah, that does work. :-)
Maybe simplify with: ``` decoded_url.translate(None, '"\',').decode('utf-8') ``` Or in case there could be spaces in `['"cod", "ed ", "URL"]`: ``` re.sub(r'[\s"\',]', '', decoded_url).decode('utf-8') ```
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
`items = value.split(self.delimiter) if value else []` is slightly faster.
Maybe simplify with: ``` decoded_url.translate(None, '"\',').decode('utf-8') ``` Or in case there could be spaces in `['"cod", "ed ", "URL"]`: ``` re.sub(r'[\s"\',]', '', decoded_url).decode('utf-8') ```
`items = value.split(self.delimiter) if value else []` is slightly faster.
set default `step_size=None` instead of `"any"` and only render that attribute if it's `not None`.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
`items = value.split(self.delimiter) if value else []` is slightly faster.
IMO this should not raise a warning.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
We tend to sort the imports alphabetically. It's a common thing in python.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
I'm worried about Ruby quoting. If any setting contains a single quote, this will break. What I suggest is passing via ARGV. `rails r` leaves in ARGV any args following the ruby fragment, e.g. this works: ``` # The \' escaping below is only to type this via shell; # run_command() takes an array of strings and I think this way could pass arbitrary JSON with no other escaping at all. rails r 'puts MiqServer.my_server.set_config(JSON.parse(ARGV.last))' '{"goodbye": "Qapla\', Worf"}' ```
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
We don't need to support different bases or other negation signs so I would expect a simplified implementation.
Trailing commas: ```suggestion MAX_NUM_FORM_COUNT: self.max_num, }, renderer=self.renderer, ```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
> this test is checking the support for a possible object that is seekable but has no `.tell()`. > `tempfile.NamedTemporaryFile()` has `.tell()`. Just as an aside, whether there is any change here or not, but you could do: ```python with tempfile.NamedTemporaryFile() as tmp: del tmp.tell # Emulate seekable file handle without .tell(). ... ```
This error is raised when instantiating so we don't need to include a `route` in the message.
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
This doesn't support aurora snapshots. Besides that, this looks great.
2.6 or 2.7? Also you `requirements` listed here and the modules.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Using `str('name=Hello%20G%C3%BCnter')` would also work here but using `six.PY2` could be a nice reminder to remove the `b'...'` branch.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Again, error handling changed.
needs a space before the quote here too
Read also https://www.ianlewis.org/en/mixins-and-python
Maybe these functions should go into `module_utils/crypto`? Seem useful for CSRs and certificates (maybe even SSH keys?) too.
What's the purpose of http://example.com/v.flv here? It always gives a 404 error and I think it's unrelated to iQiyi
Thanks :+1: , IMO a separate ticket is not necessary, we can `Refs #33348 -- ...`.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
This could be a bare `super()`.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
@jrwdunham I think you can drop this if, yes
@jrwdunham I think you can drop this if, yes
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
Thanks :+1: , IMO a separate ticket is not necessary, we can `Refs #33348 -- ...`.
you might want to get the module/action as the include can be given a name that does not match `include:`
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
2.6 or 2.7? Also you `requirements` listed here and the modules.
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
pass original exception as orig_exc so traceback can be shown with -vvv
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
with -> width
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
It's not actually a comprehension - this could just use a tuple literal.
It's not actually a comprehension - this could just use a tuple literal.
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
perhaps "if not region"? that keeps the standard flow from being in an "else", lets us bring the indenting back a level, etc. Otherwise this is fantastic. Thanks for pep8 and removing the stray code.
```suggestion pkg_version = line.partition(':')[-1].strip() ```
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
2.6 or 2.7? Also you `requirements` listed here and the modules.
```suggestion pkg_version = line.partition(':')[-1].strip() ```
oh I see, it makes sense then.
@charettes thanks for the idea. I made PR #7755 with regression fix.
We already test this exact configuration in upgrade test (from 0.9 to 0.10, using both 0.9 producer and consumer, and default timestamp type). I would change timestamp_type of this test to LogAppendTime to make it different.
`field_preference` must be a list or a tuple.
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
s/CONSTURCTOR/CONSTRUCTOR/ (and usages)
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
"Always clear..." would be sufficient
You: `[0-9|a-f]`. Stackoverflow: `[0-9a-f]`. Difference? You have to learn to distinguish `(...)` and `[...]`.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
immediatelly -> immediately
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
single line looks more readable here
Line 41. By the way, it would make the patch a bit easier to review and see what has changed if you didn't reorder methods (e.g. set is moved above _set) and delete above _discard). Perhaps the reordering could be done in a separate commit afterwards if it's needed.
Thanks. This PR is assigned to the 2.12 milestone, which we'll be going through after creating the stable-2.11 branch (which will be done when 2.11 RC1 comes out).
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
I don't think this is working correctly, did you test it for all possible inputs ? - First of all the size_unit is only correct if it is a known unit. - And if that's not true, and it's not a digit, you have to escalate. - If it is a digit, you likely won't have a unit and then you could assume bytes.
I would change this to a `NotSupportedError`, e.g. ```python raise NotSupportedError( 'Bulk create a multi-table inherited model is not supported ' 'on this database backend.' ) ```
This doesn't seem right, size is an integer at this point.
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
```suggestion type: list suboptions: ```
Might be worth renaming this to `self.root_queryset`.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
This would be more readable and consistent with our indentation style with something like: ``` foo_constraints = [ name for name, details in constraints.items() if details['columns'] == ['name'] and details['unique'] and name != custom_constraint_name] ] self.assertEqual(len(foo_constraints), 1) ``` (choosing a different name than "foo"
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
No need to assign to `self.widgets` ```python if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = [w() if isinstance(w, type) else w for w in widgets] ```
No need to assign to `self.widgets` ```python if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = [w() if isinstance(w, type) else w for w in widgets] ```
Good catch, I will remove it before final squash.
Should be ``self.weight``
Too long line.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
`band_input`, you don't get much by saving one char :-)
Similarly, ```if tc['skip'].get('i')```
please use a variable for this string so that if it changes, we don't have to update it below as well
`constraint_name` should also be quoted.
docstring with example input/output would be really helpful
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
This variable is never assigned ```suggestion api.get_collection_versions('namespace', 'collection') ```
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
If we `from itertools import chain` we can save the overhead of attribute access here.
If we `from itertools import chain` we can save the overhead of attribute access here.
If we `from itertools import chain` we can save the overhead of attribute access here.
If we `from itertools import chain` we can save the overhead of attribute access here.
We can reuse existing objects.
We can reuse existing objects.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
This module will be rewritten into 'exos_lldp_interfaces' using Resource Module Builder.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
This will still result in a command like `git config --unset foo ''`. According to the git config man page, that extra argument is a "value_regex" and its presence means only those values matching this regex will be unset. Luckily the empty string is a regex that matches everything, so it all works out fine in the end.
```suggestion version_added: '2.9' ```
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
This shouldn't be needed once you add the custom `deconstruct()`.
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
The code I've reviewed recently always has mixins on the left. I think it's easier to be consistent than have to think about it, but feel free to propose some different guidelines if you like.
This is not necessary.
I think this could be increased to 10 just in case the system is really slow. The important thing is that it doesn't loop forever.
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
Not sure it makes a difference but before it looks like we got `form=None` in the context.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
Ahh true, sorry for the noise. No changes are required.
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
This is a private function (starts with an underscore) so I'd hope we could move this without having to leave a stub for backwards compatibility. If you want to remove the stub in a separate commit/PR just in case, though, I can live with that.
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
This could be final? Also, applies to parameters in the other models
This could be final? Also, applies to parameters in the other models
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Use dict literals: ```suggestion return {} ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Running the legacy ec2_asg integration tests that use this module, I think this line should be `if block_device_mapping:` because it doesn't look like it can be None or an empty list. The error: ``` An exception occurred during task execution. To see the full traceback, use -vvv. The error was: Missing required parameter in BlockDeviceMappings[0]: "DeviceName" fatal: [localhost]: FAILED! => {"changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 436, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 430, in main\n create_launch_config(connection, module)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_g_YCzK/ansible_module_ec2_lc.py\", line 326, in create_launch_config\n connection.create_launch_configuration(**launch_config)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 253, in _api_call\n return self._make_api_call(operation_name, kwargs)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 517, in _make_api_call\n api_params, operation_model, context=request_context)\n File \"/Library/Python/2.7/site-packages/botocore/client.py\", line 572, in _convert_to_request_dict\n api_params, operation_model)\n File \"/Library/Python/2.7/site-packages/botocore/validate.py\", line 270, in serialize_to_request\n raise ParamValidationError(report=report.generate_report())\nbotocore.exceptions.ParamValidationError: Parameter validation failed:\nMissing required parameter in BlockDeviceMappings[0]: \"DeviceName\"\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0} ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
I'd do this unconditionally.
`default=None` is the default, it's not required.
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
I'd do this unconditionally.
I'd do this unconditionally.
It seems like you could simplify things if you had an operator map and do smth like: ```suggestion import operator ... op_map = { '!=': operator.ne, '==': operator.eq, '>=': operator.ge, '>': operator.gt, ... '*': operator.eq, } ... pos = 2 if req[1] == '=' else 1 op_map(req[:pos])(LooseVersion(version), LooseVersion(req[pos:])) ... ```
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
You should at least add real values for `datastore`, `source`, and `destination`.
This is useless. `filepath` must be required to be a valid path. This must be asserted.
In what case is this branch reached? Should there be a test for it? I guess you meant `raise CommandError(e)`.
It seems like you could simplify things if you had an operator map and do smth like: ```suggestion import operator ... op_map = { '!=': operator.ne, '==': operator.eq, '>=': operator.ge, '>': operator.gt, ... '*': operator.eq, } ... pos = 2 if req[1] == '=' else 1 op_map(req[:pos])(LooseVersion(version), LooseVersion(req[pos:])) ... ```
It seems like you could simplify things if you had an operator map and do smth like: ```suggestion import operator ... op_map = { '!=': operator.ne, '==': operator.eq, '>=': operator.ge, '>': operator.gt, ... '*': operator.eq, } ... pos = 2 if req[1] == '=' else 1 op_map(req[:pos])(LooseVersion(version), LooseVersion(req[pos:])) ... ```
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
I'm curious if this should be a `BaseException` so that it'd work on `Ctrl+C` (`SIGINT`) or `SystemExit` (`SIGTERM`).
I'd do ```suggestion if not ignore_errors: raise ```
This will break unicode strings under python 2.
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
Probably a typo here? ```suggestion shutil.rmtree(b_path) ```
I'd do this unconditionally.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
No such meta field.
`enumerate` on for range.
docstring with example input/output would be really helpful
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
After taking a look at the new function, I could see leaving the stub function in so that it can establish default values for arg_spec and params.
Can we detect if this is not a json and fallback to print it directly
You can also add a deprecation warning for usages like `from django.forms.extras.widgets import SelectDateWidget`.
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
```suggestion the I(verification_method) will be updated and validation data (if applicable) will be returned. ```
docstring with example input/output would be really helpful
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
Please wrap: ``` # If true, uniqueness validation checks will consider this a new, unsaved # object. Necessary for correct validation of new instances of objects with # explicit (non-auto) PKs. This impacts validation only; it has no effect # on the actual ```
chop newline for consistency with other tests
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
First we should verify this passes before we toggle `is_active` to False.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
You could use `subtest()` for the loop.
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
I'd omit a blank line after each docstring.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
I'd omit a blank line after each docstring.
I'd omit a blank line after each docstring.
I'd omit a blank line after each docstring.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
This seems like it will make for a hard API to use because it will fail when the lock_file is owned by another user (so playbooks run by different users or async with tasks that become different users will raise Permission denied errors). It seems like problems opening the lock_file should be part of the timeout.
`always_text` is gone.
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
nit: since the error message says "the elements" shouldn't this check all elements? ```suggestion if not all(val): ``` alternatively, we can leave the if-statement as-is and instead change the error to something like "the first key in the list must not be empty"
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
with -> width
Right, this was more a of suggestion open to discussion given the composite nature of `(-180.0, -90.0, 180.0, 90.0)`. I kind of wish `Field.deconstruct` was more smart wrt to `__init__` defaults by relying on `inspect` reflection in the first place.
Keep the `r`
no need for `.keys()`. `if property_id in vapp_properties_current:` is the same as `if property_id in vapp_properties_current.keys():`
no need for `.keys()`. `if property_id in vapp_properties_current:` is the same as `if property_id in vapp_properties_current.keys():`
I would chop blank lines in this test.
I'd be great to assert the permission and content types were appropriately created as well!
Interesting thought. But if a key is compromised one would switch from one key in the list to still one key (the new one) because you wouldn't want to keep the compromised key active. So in the case of a compromise I'd always expect the list to stay constant in length because the offending key would be replace with a new one (independent of other keys probably). Either way for the majority of cases (ie under normal operation) I'd expect just one key in there (or always two if one rotates a key every $x weeks)
I would chop blank lines in this test.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
As discussed on IRC: no.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
We can also write a single line return statement. Please see if it makes sense. ```suggestion return (uid is not None and path_stat.st_uid == uid) or (gid is not None and path_stat.st_gid == gid) or (uid is None and gid is None) ```
Does the order matter? If yes, it's probably better to use ```suggestion return '/'.join(sorted(priv_list)) ```
What if `default` is not a constant but a field reference? e.g. `F('integer')`
Good catch, I will remove it before final squash.
Minor but I'd move this control flow block after the `weights` one to match the args order.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
`if it encounter` => `if it encounters`
`if it encounter` => `if it encounters`
Combine line 99 with this line: ```suggestion - May not be used with C(backrefs) or C(insertafter). ```
Why change the example docs? The yaml dict style is the preferred format for EXAMPLES
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
prefer hanging indent style with 1 arg per line
`elif` might be clearer (I understand it's not necessary)
`if it encounter` => `if it encounters`
`if it encounter` => `if it encounters`
is this the same as "validate_certs" in other modules? if so I would prefer to standardize the naming to that
use of one the styles in 04de4369325097472d7ad036dac262555002ba88
You can join this line with the previous.
Referring specifically to the kubeconfig definition, the remote file path will cover a lot of use cases but I was wondering if it would be useful to be able to specify it inline as well, which would open the door for keeping your authentication with your ansible playbooks/roles.
You could do this setup in Python. `self.school.students.add(...)`
For these 3, add expected_type `int`, eg: ```py 'width': try_get(item, lambda x: x['video']['width'], int), ``` (equivalent in effect to wrapping in `int_or_none()`).
* use the resulting match object * avoid excessive indentation * `r'\s'` includes any whitespace * simplify `clean_html()` expressions ```suggestion href = extract_attributes(html[mobj.start(0):mobj.start('content')]).get('href') if not href: continue mobj1 = re.search(r'/(?P<s_id>\d+)\.html', href) if mobj1 and mobj1.group('s_id') == series_id: series_title = clean_html(re.sub(r'\s+', ' ', mobj.group('content'))) title = clean_html(re.sub(r'\s+', ' ', html)) break ```
Referring specifically to the kubeconfig definition, the remote file path will cover a lot of use cases but I was wondering if it would be useful to be able to specify it inline as well, which would open the door for keeping your authentication with your ansible playbooks/roles.
prefer hanging indent style (allows longer lines, indentation always multiple of 4): ``` rasterheader = ( 1, 0, ... ) ```
No need to define another attribute. The form class should be accessible as `self.TestForm`.
No need for the `u` prefix, we're already importing `unicode_literals`.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
it should also check if it can write there
it should also check if it can write there
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
2.0 is what you want here
What I meant was that you could stick the following in the top of `_destruct_iterable_mapping_values()` to make it more DRY: ```python if isinstance(data, Mapping): yield from data.items() return ``` I don't see why you think we'd need an extra for-loop...
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Do we need to call `list(fields)` here? :thinking:
We've been using "Take / apply" verb-style in new docstrings.
I think we should add an `allow_overwrite` or similar param.
We should indicate that this is only a guess - the value may be smaller or larger than the actual size.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
`items = value.split(self.delimiter) if value else []` is slightly faster.
`items = value.split(self.delimiter) if value else []` is slightly faster.
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
it should also check if it can write there
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
`field_preference` must be a list or a tuple.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
Oh, I missed that the check is slightly different. but still such function could accept key + check type class and could be reused 3 times if you want to go for it :)
`field_preference` must be a list or a tuple.
Similarly, ```if tc['skip'].get('i')```
Similarly, ```if tc['skip'].get('i')```
Similarly, ```if tc['skip'].get('i')```
Similarly, ```if tc['skip'].get('i')```
This is only ever called once. Do we need the default? (Same with SQL version)
Similarly, ```if tc['skip'].get('i')```
and please format it with indent, so it's more clear
No such meta field.
`check_rc` is false by default, no need to pass.
I think this should probably be `'auto'` instead of `None` ... unless I missed something (which I'm always open to the possibility that I have): ```python use_backend = self._task.args.get('use', self._task.args.get('use_backend', 'auto')) ```
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_PROFILE') ```
could move this to the previous line
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
flake8 doesn't like the hanging indent here.
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
Such an extensive docstring is not necessary, IMO.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Chop `Ensure that`.
Any problem with: ``` @property def media(self): ```
I would chop blank lines in this test.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
This command has always left a trailing `,`. You could potentially omit the commands after the `cut` and just do a split/join in python that will give exactly what we want. Also, not sure if it was intentional or not, but this command seems to elide the alphabetical sorting that's in the command on the wiki.
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Should this be ``` python checked_list.sort(key=lambda x: sorted(list(x.items())) if isinstance(x, dict) else x) ``` tracebacks from test failures in CI make me suspect the view object from set(x.items()) fails because set() wants hashable items and the view object from x.items() is not. Does wrapping it in a list() or tuple() work? ``` 2017-06-26 16:43:33 The full traceback is: 2017-06-26 16:43:33 Traceback (most recent call last): 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_module_ecs_ecr.py", line 304, in run 2017-06-26 16:43:33 policy = sort_json_policy_dict(policy) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 603, in sort_json_policy_dict 2017-06-26 16:43:33 ordered_policy_dict[key] = value_is_list(value) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in value_is_list 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 File "/tmp/ansible_cLYNf7/ansible_modlib.zip/ansible/module_utils/ec2.py", line 595, in <lambda> 2017-06-26 16:43:33 checked_list.sort(key=lambda x: sorted(set(x.items())) if isinstance(x, dict) else x) 2017-06-26 16:43:33 TypeError: unhashable type: 'list' ```
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Since this isn't implemented, perhaps lets not mention it? I found it confusing
Since this isn't implemented, perhaps lets not mention it? I found it confusing
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
No need to assign to `self.widgets` ```python if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = [w() if isinstance(w, type) else w for w in widgets] ```
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
as a tuple
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
This must be checked **before** any processing.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
`del` is a builtin, not a function. These parens don't have to be here
This is superfluous, the extension can be extracted automatically.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Useless with timestamp available.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Since this isn't implemented, perhaps lets not mention it? I found it confusing
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
`del` is a builtin, not a function. These parens don't have to be here
Use built-in method? Also, should it crash (raise) if `json.loads()` fails, or just return an empty dict again? ```suggestion try: return self._download_json( url, song_id, data=data.encode('ascii'), headers=headers) except ExtractorError as e: if type(e.cause) in (ValueError, TypeError): # JSON load failure raise except Exception: pass return {} ```
This needs to incorporate `name` somehow else it will break when form prefixes are involved or on top level field names collisions.
This needs to incorporate `name` somehow else it will break when form prefixes are involved or on top level field names collisions.
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
Same here, default parameter is **validate_certs**, the aliases should be removed. We also simplify this by *not* adding `required=False`, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
It would be useful to tell the user which `key` is invalid.
Sure, a separate PR sounds good.
I think a better wording would be: "Backwards compatibility for storage backends without support for `max_length` will be removed in Django 2.0."
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
`import ansible.module_utils.parsing.convert_bool import BOOLEANS` and use that constant
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
Should also include `block_size` and `parallelism`
Should also include `block_size` and `parallelism`
nit: it's not a regex and there's no escaped symbols so there's really no need to make use of raw-strings
`quote` isn't used anywhere.
Such an extensive docstring is not necessary, IMO.
This needs to be a failure, the `OrderedDict` object is used. Maybe just do a straight import with the try / except ``` python try: from collections import OrderedDict except ImportError: from ordereddict import OrderedDict ```
no `u''` prefixes on strings please
Does this really need to be a global? Can it not be a property on the `VarsModule` instead>
please wrap {}
Does this really need to be a global? Can it not be a property on the `VarsModule` instead>
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
okay, but would be helpful to say _why_ we need to always return True.
do we really need that `is not None` check? `check_token` should return `False` for None tokens.
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
Can you re-warp this block to 79 chars? (First line is too short.)
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
okay, but would be helpful to say _why_ we need to always return True.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
Can you re-warp this block to 79 chars? (First line is too short.)
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
List comprehensions create unnecessary throw-away lists in memory. It's better to use generator expressions because they are lazy. Also, this is a great case for using `all()`/`any()` (these two exit iterating through generators early, when possible): ```suggestion return all(part != ".." for part in path.split(os.sep)) ```
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
we want want -> we want
we want want -> we want
`django/core/files/copy.py:28:37: E127 continuation line over-indented for visual indent` pep8 wants you to indent it like this: ``` fd = os.open(new_file_name, os.O_WRONLY | os.O_CREAT | getattr(os, 'O_BINARY', 0) | (not allow_overwrite and os.O_EXCL or 0)) ```
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
This should be `RemovedInDjango50Warning` I think.
a OrderedSet, like @timgraham suggested
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
we want want -> we want
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
we want want -> we want
okay, but would be helpful to say _why_ we need to always return True.
set the safe
Should also include `block_size` and `parallelism`
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
Can you re-warp this block to 79 chars? (First line is too short.)
we want want -> we want
I would chop blank lines in this test.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
okay, but would be helpful to say _why_ we need to always return True.
okay, but would be helpful to say _why_ we need to always return True.
`import botocore` will make this code a lot more consistent with most other boto3-based ansible modules
Maybe even in advance with the current form.
Yeah, I had the same problem. I tried changing the exception type raised in `templar.template()` and catching that here, but still couldn't get it quite right. Seems like putting it in `-v` is an improvement over what we have now until we can come up with something better.
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
`else` can be removed, i.e.: ```python ... elif end is None: return self.UNBOUNDED_FOLLOWING raise ValueError('Illegal argument for end, must be either a positive integer, zero or None') ```
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Right, I think we could use model fields as a parallel -- we don't include all options a field is initialized with in the `__repr__()`. Here's the implementation: ``` def __repr__(self): """Display the module, class, and name of the field.""" path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__) name = getattr(self, 'name', None) if name is not None: return '<%s: %s>' % (path, name) return '<%s>' % path ``` So I'm +1 to not implementing a custom `__repr__()` for each subclass unless someone can present a counter argument. \cc @akki I created https://github.com/django/django/pull/8643 to remove `BrinIndex.__repr__()`.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
I moved this check to the `DurationExpression`.
They are helpful when using (i)pdb.
This is not strictly related with functional indexes, I'm going to move it to a separate PR.
`Backend` supports negative precision, `SQLite` does not: ```suggestion raise ValueError('SQLite does not support negative precision.') ```
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
Ah. lambda is prettier though :). maybe we can run pep8 with ignore lambda error.
```suggestion 'conflicts with specifying unique fields that can ' ```
```suggestion 'conflicts with specifying unique fields that can ' ```
As long as they both equals it shouldn't make a difference. By that I mean you should have a test asserts `Index('foo') == Index(F('foo'))` An alternative could be to defer that to `create_sql`.
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
`else` can be removed, i.e.: ```python ... elif end is None: return self.UNBOUNDED_FOLLOWING raise ValueError('Illegal argument for end, must be either a positive integer, zero or None') ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
@wrouesnel CI failure due to PEP 8 issue: ``` 2017-01-28 07:26:38 ERROR: PEP 8: lib/ansible/modules/cloud/amazon/ec2.py:930:1: W293 blank line contains whitespace (legacy) ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
The current idiom might be required because some backends (perhaps third-party ones) choke on empty `params`. I'd keep it.
```suggestion raise ValueError('Error while adding new LUKS keyslot to %s: %s' ``` While you're at it ;)
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
no blank line needed
This one is a bit newer to CliBase, but also implemented verbatim in superclass
This seems random and can lead to flaky tests. So there is no way to measure latency while Trogdor task is running? For the rate limit test below we do wait for task to run.
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
Please chop blank line.
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
This seems random and can lead to flaky tests. So there is no way to measure latency while Trogdor task is running? For the rate limit test below we do wait for task to run.
This seems random and can lead to flaky tests. So there is no way to measure latency while Trogdor task is running? For the rate limit test below we do wait for task to run.
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
This can be simplified. Both Random and SystemRandom accept a seed value, in both cases the default value is None. So there is no need for a condition. The default value can be passed unconditionally
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
This can be simplified. Both Random and SystemRandom accept a seed value, in both cases the default value is None. So there is no need for a condition. The default value can be passed unconditionally
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
This change breaks MTVServicesEmbeddedIE
Any problem with: ``` @property def media(self): ```
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
it should also check if it can write there
it should also check if it can write there
it should also check if it can write there
This bare `except` will catch anything, including the exception that marks a failing test, I think :-) Better to use `assertRaises` and explicitly assert that the specific expected uncaught exception bubbles up.
Minor but I'd move this control flow block after the `weights` one to match the args order.
I don't see a need for string interpolation in cases like this.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
You need to wrap the second instantiation in its own assertRaises to actually test it.
The usual pattern is to implement `get_source_expressions` and `set_source_expressions`. ```python def get_source_expressions(self): return [self.config] def set_source_expressions(self, expressions): self.config, = expressions
`# Without form data` seem sufficient.
In Python, it's common to include docstrings as per PEP 257: ```suggestion def fake_now(monkeypatch): """Patch `datetime.datetime.now()` to return a deterministic value.""" ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
`# Without form data` seem sufficient.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
That was the thing I was saying earlier- checking for/failing on undefined inputs upfront would probably be what most people would expect, but that'd be a breaking change. Even if we chose that breaking change, we'd probably need a way for filters that *want* to allow undefined inputs to do so (transparently to the caller of the filter). And yeah, we probably need an analogue for tests, since the same problems exist.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Few naming suggestions: `ordering_element` -> `expr` `ord_sql` -> `expr_sql` `ord_sql_params` -> `expr_params` `additional_sql_params` -> `ordering_params` `ord_clauses` -> `ordering_expr_sql`
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
```suggestion f'site={self.admin_site!r}>' ) ```
single line as above
single line as above
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
I'd suggest this for the indentation: ```python return [ force_text( capi.get_field_name(capi.get_field_defn(self._layer._ldefn, i)), self.encoding, strings_only=True, ) for i in range(self.num_fields) ] ``` Any concern about having no tests for the `self.encoding, strings_only=True` bit? I'm not sure we would expect non-string values in the first place? Also, at least on my system, there are no failures with it removed here or in `layer_name` above.
Right, but the order in which you're doing things would at a glance result in the not-uncommon case of, eg `foo (cr)(lf)` not being properly treated, since the break `sub` wouldn't see that, but the char drop would remove the (cr), leaving a line ending that wouldn't format the right way.
flake8 complains about missing spaces around `*`
I don't see a need for string interpolation in cases like this.
I don't see a need for string interpolation in cases like this.
flake8 complains about missing spaces around `*`
Chop the blank lines
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
I would change this to a `NotSupportedError`, e.g. ```python raise NotSupportedError( 'Bulk create a multi-table inherited model is not supported ' 'on this database backend.' ) ```
Chop the blank lines
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Chop the blank lines
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
Thanks. This PR is assigned to the 2.12 milestone, which we'll be going through after creating the stable-2.11 branch (which will be done when 2.11 RC1 comes out).
Plz also use `match` arg here
When referring to `bulk_save()` in messages, include parenthesis (and periods).
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
In Python3, `super()` is enough.
As Collin said, slightly longer lines are okay rather than awkward wrappings like this.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Since Ansible subscribes to unicode sandwich, this should be the callers' (actually, where the data enters the system) responsibility.
Since for Python, a non-empy string is True, you can just do: `if self.params['esxi_hostname']:`.
Use `==` to compare booleans. The `is` test should *only* be used when you really want to compare identities of objects! Finally, there's no need to compare a boolean to `True` or `False` explicitly; simply write `elif self._has_migs(local):`.
I think it's a better API; a custom manager could be using its name in a `__new__` method.
```suggestion type: list suboptions: ```
`return migs != 0` is equivalent ot lines 380 to 382.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Use of the mixin isn't ideal here since there a lot of unrelated tests which aren't affected. If we have some other deprecation that affects these tests, we might miss updating them.
```suggestion item, fields=fields, using=self.db, ```
```suggestion item, fields=fields, using=self.db, ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
```suggestion item, fields=fields, using=self.db, ```
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
Historic moment! I don't see a reason why we shouldn't use them.
Do we need to define `async_generator` in `__aiter__`? ```python async def _async_generator(self): # Generators don't actually start running until the first time you call # next() on them, so we make the generator object in the async thread # and then repeatedly dispatch to it in a sync thread. sync_generator = self.__iter__() # So, you can't raise StopIteration up through sync_to_async as # too much of the Python async system was originally built on # generators. Instead, we capture it inside a custom sync function # and change it to an exception we *can* propagate. # We should probably move this logic inside asgiref at some point. def custom_next(gen): try: return next(gen) except StopIteration: raise StopAsyncIteration() while True: try: yield await sync_to_async(custom_next)(sync_generator) except StopAsyncIteration: return # Note: __aiter__ is a *synchronous* method that has to then return an # *asynchronous* iterator/generator. Thus, we nest an async generator # inside it. # Also note: This is a generic iterable converter for now, and is going to # suffer a performance penalty on large sets of items due to the cost of # crossing over the sync barrier each time. We should write custom ones # for each Iterable subclass, but we'll need some work in Compiler first. def __aiter__(self): return self._async_generator() ```
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
I don't see any need for this attribute.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
Don't mix unrelated changed in single PR.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
This one could do with assigning to a variable: ```suggestion path = base_path / f self.assertTrue(path.exists()) with path.open() as fh: ```
We want to save file with the `symlink.txt` name so this assertion doesn't have much value IMO. I would check that the new file exists.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
The usual pattern is ``` try: import IPython except ImportError: IPython = None ``` No need for an extra variable.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
We want to save file with the `symlink.txt` name so this assertion doesn't have much value IMO. I would check that the new file exists.
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
`enumerate` on for range.
add trailing comma
could switch to single quotes for consistency
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
use x.items() here, no need for the iteritems import
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
In this case, I think a ternary is more complicated to read than: ``` if srid == -1: srid = None ```
This should be a feature flag as CockroachDB (which tries to emulate PostgreSQL in a lot of ways) has the same restriction.
This should be a feature flag as CockroachDB (which tries to emulate PostgreSQL in a lot of ways) has the same restriction.
Maybe you can use `subTest` here, e.g.: ```python for model, pk_pos in ( (Book, -1), # Unmanaged origin model. (Author, 0), # Unmanaged related model. ): with self.subTest(model=model, pk_pos=pk_pos): with mock.patch.object(model._meta, 'managed', False): _, _, grouping = queryset.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(grouping), len(model._meta.fields) + 1) self.assertIn(Author._meta.pk.name, grouping[pk_pos][0]) for index, field in enumerate(model._meta.fields): self.assertIn(field.name, grouping[index + pk_pos + 1][0]) assert_queryset_results(queryset) ``` but I'm not convinced that it isn't less readable.
chop "one of" add comma before "or"
This could fit on a single line: `# Subqueries must use a different set of aliases than the outer query.`
Please do not remove this trailing comma, this is our preference with dicts and lists to minimize future diffs when lines are changed.
1 line is okay --- we prefer longer lines up to 119 characters when it helps readability.
single line as above
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
As Collin said, slightly longer lines are okay rather than awkward wrappings like this.
I would chop blank lines in this test.
I would chop blank lines in this test.
missing space after the second comma (please check code with flake8)
flake8 complains about missing spaces around `*`
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
You can drop the `.all()` here.
This is always a tough question, and I'm not sure what's the best solution :) In Ansible, things are usually lower-case. I guess you have to decide what you want in the end :)
I don't see a need for string interpolation in cases like this.
```suggestion item, fields=fields, using=self.db, ```
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
```suggestion item, fields=fields, using=self.db, ```
```suggestion item, fields=fields, using=self.db, ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
`enumerate` on for range.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Please add a docstring explaining this.
extra space after `*` needs to be removed here too
```suggestion - Facts representing the current state of the node. Matches the C(docker node inspect) output. ```
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Do we still need kind? For service I think it should always be v1
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
IMO it will me more readable to move `base` outside, also we resolve `F()` expressions twice (line 28 & 29), so maybe, e.g. ```python if isinstance(expression, str): expression = F(expression) if isinstance(expression, F): expression = base.resolve_expression(query=query, simple_col=True) else: expression = expression.resolve_expression(query=query) ``` Moreover I think we don't need to iterate twice over the expressions: ```python for expression, operator in self.expressions: ... expressions.append('%s WITH %s' % (sql % params, operator) return expressions ```
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
IMO it will me more readable to move `base` outside, also we resolve `F()` expressions twice (line 28 & 29), so maybe, e.g. ```python if isinstance(expression, str): expression = F(expression) if isinstance(expression, F): expression = base.resolve_expression(query=query, simple_col=True) else: expression = expression.resolve_expression(query=query) ``` Moreover I think we don't need to iterate twice over the expressions: ```python for expression, operator in self.expressions: ... expressions.append('%s WITH %s' % (sql % params, operator) return expressions ```
point -> points
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
test failure says this should be `(None, None)`
So we have to probably use try-except blocks for all the stuff that could fail. Nowadays with python3 you'd be doing something like: ```python from ansible.module_utils.pycompat24 import get_exception .... try: <whatever action that could fail> except: e = get_exception() module.fail_json(msg=str(e))
test failure says this should be `(None, None)`
There is a much easier way to do this, by using the index in the list. Something like: ```python unit = size[-1] units = list('b', 'k', 'M', 'G', 'T', 'P', 'E', 'Z', 'Y') try: multiplier = 1024**units.index(unit) except ValueError:: e = get_exception() module.fail_json(msg="No valid size unit specified. %s" % e) ```
So we have to probably use try-except blocks for all the stuff that could fail. Nowadays with python3 you'd be doing something like: ```python from ansible.module_utils.pycompat24 import get_exception .... try: <whatever action that could fail> except: e = get_exception() module.fail_json(msg=str(e))
These will need to be module parameters if they need to be configurable. Constants are not available to modules.
This error is raised when instantiating so we don't need to include a `route` in the message.
This should always be true if the receiver is connected with `sender=migrations.RenameModel` as it is right now.
This doesn't look like it is tested.
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
Please use a single quote.
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
```suggestion updates.extend(line for line in set_commands if line not in config) ```
Can it be simpler? E.g. without nic_device/device_type ```python for device in vm.config.hardware.device: if device.macAddress == mac: return device ```
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
```suggestion updates.extend(line for line in set_commands if line not in config) ```
Maybe wrapping mac comparison with try/except/pass will work on nonexistent attribute? Just to avoid additional iteration, though I still not fully understand how often are there cases when device with certain device type won't have macAddress attribute.
That does make sense. Thanks.
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Ah, i'd expect a bool to always be True/False, if that is not the case (no time to test really right now :)), then indeed, this needs to stay (and this goes for my other bool remarks)
I would add a flag to `Index`, e.g. `is_functional` that could be used here together with `supports_expression_indexes` to skip such indexes, e.g. ```python if not index.is_functional or self.connection.features.supports_expression_indexes: output.append(index.create_sql(model, self)) ``` Also we should return `None` in `_create_index_sql()` and `_delete_index_sql` if `index.is_functional` and `self.connection.features.supports_expression_indexes`
Would `functools.partial` work here? ```python from functools import partial bound_method = partial(method.__get__(self, type(self))) ```
`yield from` is not allowed in async functions.
It would be better if we could refactor the control flow so we don't have to repeat these lines which also occur after the last else statement in this file.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
It would be useful to tell the user which `key` is invalid.
couldn't -> can't
`always_text` is gone.
~~ use the shared open_url function, it takes care of many issues with python's ssl ~~
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Unless I missed something: - before: all `OSError` exceptions are converted to `CommandError`; in addition a specific message is added when the file already exists - after: only `FileExistsError` is converted to `CommandError`
```suggestion help=( 'Shuffle the order of test cases to help check that tests are ' 'properly isolated.' ), ) ```
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Again, error handling changed.
Again, error handling changed.
I think we can increase the readability with constant for `1` and `2`. ```python DAILY_COUNTER=1 WEEKLY_COUNTER=2 ``` And then you can just do `key=WEEKLY_COUNTER,`
Could you please use Python regex instead of external egrep command ? egrep command may not be installed on given system.
`yield from` is not allowed in async functions.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
We need a trailing space to separate times from results, e.g. ``` test_order_index (schema.tests.SchemaTests) ... 0.000sok
We need a trailing space to separate times from results, e.g. ``` test_order_index (schema.tests.SchemaTests) ... 0.000sok
It's likely fine. 🤔 Let me have a play in the debugger tomorrow.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
No such meta field.
I would suggest to use the ungettext_lazy('%(number)d minute', ''%(number)d minutes', 'number') syntax, if possible.
This must be checked **before** any processing.
I would suggest to use the ungettext_lazy('%(number)d minute', ''%(number)d minutes', 'number') syntax, if possible.
flake8 complains about missing spaces around `*`
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Please turn this into a `dict`. Strings are a really horrible format for complex data such as this. Also, is there precisely one mount available per container? If podman is really trying to be compatible to docker, I cannot believe that.
```suggestion description: Can be used to request certificates from ECS, with C(provider=entrust). ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
flake8 complains about missing spaces around `*`
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
no restructured text (:class:) in docstrings please
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
flake8 complains about missing spaces around `*`
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
A general remark: you should always use complete sentences. So this should end with a period.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Is it possible ? For me it would mean that it exist a package without version.
Outer parentheses are not idiomatic in python.
Please remove this blank line as requested by Paolo.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Make sure you use `format_lazy()` to prevent issues with translated strings: ```suggestion self.verbose_name_plural = format_lazy('{}s', self.verbose_name) ``` This is also consistent with the following: https://github.com/django/django/blob/c70cd2a926ffab47f6613e83e0c8828eb6c2c064/django/db/models/options.py#L188-L191
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
I don't see a need for string interpolation in cases like this.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Good catch, I will remove it before final squash.
you can use `state` to avoid the 'or' to the user
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
TextInput -> Input? I suppose a `test_input.py` file would be better. I wasn't sure about the `test_no_trailing_newline_in_attrs` test -- it's meant to test a template rather than Python code -- probably I could have clarified that. `strict=True` isn't needed since the newline isn't being tested.
Plz also use `match` arg here
No need to parametrize with just one case.
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Yes, they were.
Shouldn't we have a decorator for that? (kinda off-topic, I know)
The following properties indicate if
```suggestion masked = var_list[key].get('masked', False) ```
```suggestion masked = var_list[key].get('masked', False) ```
```suggestion masked = var_list[key].get('masked', False) ```
I'd use `ref.assert_called_once_with()` here.
no space between "e. g."
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
Does this need to be a separate method? Seems unnecessary to me.
Does this need to be a separate method? Seems unnecessary to me.
This module supports check mode, but you're not checking whether you're in check mode before adding tags.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
Does this need to be a separate method? Seems unnecessary to me.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
"for BRIN indexes" doesn't seem consistent with usual error messages.
Please ignore, my suggestion is invalid syntax.
I'm not sure what the best solution is, but at the moment I would lean towards not supporting `.repo` files and asking people to specify the repo URL directly. To properly support `.repo` files we would have to download them, parse them and compare them to the configured repos, which is a lot of effort. Are you aware of a usecase that actually requires `.repo` files? I no longer use suse in my day job and all repo usage that I can remember also worked fine with pointing to directories directly.
like diff = load_config(self._module, config_xml, [])
What I meant was that you could stick the following in the top of `_destruct_iterable_mapping_values()` to make it more DRY: ```python if isinstance(data, Mapping): yield from data.items() return ``` I don't see why you think we'd need an extra for-loop...
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
Oops, I misread the diff and see that you only modified the existing archives. Still an explanation of exactly what going on would be nice as it's not obvious to me.
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Is there specific value in doing this for all variants here? In particular, does the security protocol variation get us something that existing tests don't? Another way of asking this is, beyond the failures we would catch with existing tests where brokers generally fail to communicate with each other when using specific security protocols, is there a way we think reassignment specifically would fail that would be related to the security protocol? E.g. is there a different inter-broker connection that's being made that otherwise wouldn't be made? I ask because I think we already test a lot of stuff with variations of security protocols and I'm a bit worried about test bloat due to parametrizing tests being relatively easy (and leading to much longer test runs).
I would chop blank lines in this test.
I would chop blank lines in this test.
wo -> without
I would chop blank lines in this test.
I think `if opt_val:` is sufficient.
Capital letter at the beginning.
Too long line.
Too long line.
flake8 complains about missing spaces around `*`
flake8 complains about missing spaces around `*`
Is there specific value in doing this for all variants here? In particular, does the security protocol variation get us something that existing tests don't? Another way of asking this is, beyond the failures we would catch with existing tests where brokers generally fail to communicate with each other when using specific security protocols, is there a way we think reassignment specifically would fail that would be related to the security protocol? E.g. is there a different inter-broker connection that's being made that otherwise wouldn't be made? I ask because I think we already test a lot of stuff with variations of security protocols and I'm a bit worried about test bloat due to parametrizing tests being relatively easy (and leading to much longer test runs).
Can we calculate that beforehand? Also `os.environ.get` could make this much more readable.
we should also return if we both delegate executions and delegate_facts
Add that the user can specify the backend to use via the ```use``` parameter.
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
```suggestion - When using in a chroot environment you always need to specify the name of the unit with the extension. For example, C(crond.service). ```
Note that format strings changed in python-2.7 So things like "{} {}".format() needs to change to "{0} {1}".format() for python-2.6 compatibility.
If you don't modify the task args then you don't need to copy() them. However, I think we want to add a ```use``` parameter for the action plugin and we will want to delete that parameter before we pass the args on to the module. So this section would look like: ``` python new_module_args = self._task.args.copy() del new_module_args['use'] [...] result.update(self._execute_module(module_name=module, module_args=new_module_args, task_vars=task_vars, wrap_async=self._task.async_val)) ```
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
This must be checked **before** any processing.
It would have been more appropriate if `run_checks()` took an `Apps` instance as a parameter instead of a list of `AppConfig`s.
`get_random_string()` will never allow you to connect to the same memory database instance. You can probably use `self.connection.alias` for that so each database alias has it's own unique memory database. This also allows it to work with `threading.local`.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Yes please remove unnecessary blank lines.
Maybe you can extract the test code from the Py3ExceptionReporterTests and skip importing the "actual test code" if six.PY3 is False? ``` python class Py3ExceptionReporterTests(TestCase): rf = RequestFactory() @unittest.skipIf(not six.PY3, "Python 3 only test") def test_reporting_of_nested_exceptions(self): from other_module import do_actual_testing do_actual_testing(self.rf) ```
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
Maybe you can extract the test code from the Py3ExceptionReporterTests and skip importing the "actual test code" if six.PY3 is False? ``` python class Py3ExceptionReporterTests(TestCase): rf = RequestFactory() @unittest.skipIf(not six.PY3, "Python 3 only test") def test_reporting_of_nested_exceptions(self): from other_module import do_actual_testing do_actual_testing(self.rf) ```
normalize_interface import is unnecessary here
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
okay, but would be helpful to say _why_ we need to always return True.
it seems this and other parameters are missing from docs
okay, but would be helpful to say _why_ we need to always return True.
(Same for the related options.)
okay, but would be helpful to say _why_ we need to always return True.
normalize_interface import is unnecessary here
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint` (the same in all new tests).
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion database='default', verbosity=0, skip_empty=True, ```
```suggestion database='default', verbosity=0, skip_empty=True, ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion database='default', verbosity=0, skip_empty=True, ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion on_conflict=on_conflict, ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
Minor but I'd move this control flow block after the `weights` one to match the args order.
`enumerate` on for range.
You need either `to_bytes(text)` or `text.encode('utf-8')` here as well.
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
You're checking two separate properties here. This should be in a separate test.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
You're checking two separate properties here. This should be in a separate test.
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
The various `CALLBACK_` prefixed class attributes are missing. Take a look at the other callbacks for an example. In particular, this is needed: ``` python CALLBACK_NEEDS_WHITELIST = True ```
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Thanks for that note ewen. I learned something!
Thanks for that note ewen. I learned something!
`for data in json.loads(...):`
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
`for data in json.loads(...):`
Thanks for that note ewen. I learned something!
Chop "Makes sure" prefix in favor of stating the expected behavior as described in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/.
Chop "Makes sure" prefix in favor of stating the expected behavior as described in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
The input values for tags can be integers but they need to be converted to a string before using e.g. `compare_aws_tags` because they're always strings when returned by boto. I definitely think we should be able to do this in a better way (which is likely just forcing conversion to string, rather than declaring non-string things invalid)
It's probably better to use MiB instead of Mb or MB. (Here and few more times below.)
don't need a trailing comma for lists with a single element (only needed for tuples)
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
It's not clear to me why it's valuable to change the semantics here so that this validation doesn't happen first if `fail_silently=False`. I don't think the message must be changed to add "like".
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
no blank line
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
Must not break extraction if missing.
Should contain `quality` key.
Should contain `quality` key.
What kind of values are valid here? I would expect this to be `float` based on the `0.0` in the description.
Should contain `quality` key.
I thought `formset = ChoiceFormSet(self.data, auto_id=False, prefix='choices')` could go in `setUp()` also.
I thought `formset = ChoiceFormSet(self.data, auto_id=False, prefix='choices')` could go in `setUp()` also.
I'd include the min length in the error message
I'd include the min length in the error message
If something on the managed machine messes up, this could be in some other encoding. Also, there's always the chance that the way the client machine handles non-utf-8 bytes will lead to those bytes coming through unescaped. Basically, the connection plugin is a boundary between Ansible and another system. So we need to be a little more paranoid in sanitizing our data in this area.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
since `list_type` can only be `top` or `global` you can change it to `else:` and safely remove `jsonp_url = ""` (which should have been set to `None`).
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
```suggestion b_opath = os.path.realpath(to_bytes(os.path.join(path, group))) ```
I'm not sure it really matters, but I'd put `self.ALLOW_BASE_THROTTLING` first.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The CamelCase exception .response attribute is particular to boto3's ClientError. IOError doesn't have .response so you can remove the `**camel_dict_to_snake_dict(e.response)` bit of this.
I think a more elegant solution would be to add one more list element and `str.join()` will do the rest: ```suggestion b_outs.append(b'') self.editor.write_data(b'\n'.join(b_outs), context.CLIARGS['output_file'] or '-') ```
`yield from` is not allowed in async functions.
`yield from` is not allowed in async functions.
`yield from` is not allowed in async functions.
I don't see a need for string interpolation in cases like this.
Similarly, ```if tc['skip'].get('i')```
Line is too long.
What's the purpose of http://example.com/v.flv here? It always gives a 404 error and I think it's unrelated to iQiyi
docstring with example input/output would be really helpful
docstring with example input/output would be really helpful
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
docstring with example input/output would be really helpful
docstring with example input/output would be really helpful
docstring with example input/output would be really helpful
Please ignore, my suggestion is invalid syntax.
It seems these could fit on a single file. We could define `args = (str(self.name), bases, body)` to avoid repeating them.
This is missing other likely candidates: `y` and `yes` I'd also argue it should be simplified to be case-insensitive so that `TRUE` == `true` (which requires you actually assert the incoming `val` is actuall stringy enough to have `.lower()`, rather than simply doing an equality match against any of the values)
This is missing other likely candidates: `y` and `yes` I'd also argue it should be simplified to be case-insensitive so that `TRUE` == `true` (which requires you actually assert the incoming `val` is actuall stringy enough to have `.lower()`, rather than simply doing an equality match against any of the values)
`_select_on_conflict` name is misleading because this method mainly checks options. Maybe `_check_bulk_create_options(...)` :thinking:
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
no blank line needed
no blank line needed
`>` appears to be a typo
Move into `_download_json`.
no blank line needed
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
```suggestion cmd = "%s --query --quiet --explicit --info" % pacman_path ```
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
This would be better as a set rather than a list.
This can be converted to return True. No need of new variable retry_request
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
I can see a decent reason to use the `DjangoJSONEncoder` as the default as it gives us `Decimal` and `datetime` support for free. These are very common use cases for django sites (especially datetime!).
no blank line needed
yep, that is what I meant, basically make sure new code is pep8 compliant
Use the Python 2 and low 3 Time Machine: `'url too short: %s' % (video_pre_parts, )` or: `'url too short: %(video_pre_parts)s' % {'video_pre_parts': video_pre_parts, }` or: `'url too short: {video_pre_parts}'.format(video_pre_parts=video_pre_parts)` or: `'url too short: {0}'.format(video_pre_parts)` No doubt there are other ways (eg `....format(**locals())`
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
```suggestion the I(verification_method) will be updated and validation data (if applicable) will be returned. ```
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Yes, that's more helpful for me.
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
That's weird -- `timezone.utc` is a `tzinfo` instance, not a subclass, like `timezone.UTC` was.
docstring with example input/output would be really helpful
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
ditto as `required_if`
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
with -> width
```suggestion msg_format="Error scaling {0} - %s".format(service.name)) ```
```suggestion msg_format="Error scaling {0} - %s".format(service.name)) ```
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
I guess some tests might be needed for the router stuff.
We should leave here `for_update_part = None` (in the same line as it was previously) and calculate it only in `not combinator` branch, because it's not used for combined queries.
I guess some tests might be needed for the router stuff.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Minor but I'd move this control flow block after the `weights` one to match the args order.
docstring with example input/output would be really helpful
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
I'd go for `try/except IOError` in order to make a point that variable initialized above is in fact a fallback.
The docstring should explain why such proxy is needed.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
`of the it's last` -> `of its last`
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Maybe add an empty line above this one and give it a name, it seems like the `assert` task is just a parameter of the `openssl_certificate_info` one.
This is undoing the example.
This can instead be `continue` and let the `else` unnest.
This can instead be `continue` and let the `else` unnest.
Maybe add an empty line above this one and give it a name, it seems like the `assert` task is just a parameter of the `openssl_certificate_info` one.
Typo in `aggressive`
This is undoing the example.
This is undoing the example.
Wouldn't this approach fix the slicable fields to just these types? A mixin along with `slicable = True/False` on `F` may be an approach. Besides, I believe the policy is to keep `django.contrib.postgres` as separate as possible.
All methods only used once should be explicitly inlined.
All methods only used once should be explicitly inlined.
Please change to: `options: {}`
Do not use underscore as prefix.
typo: ot -> to
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Simplify error reporting as below, or skip this check and just let the `_html_search_regex()` calls raise the exception? ```suggestion for token in ('apiToken', 'widgetId'): if token not in rf_token_js: raise ExtractorError( 'Unable to fetch ' + token, expected=True) ```
I'd do: ``` kwargs['separators'] = kwargs.get('separators', (',', ':')) ``` On Wed, Aug 21, 2013 at 8:06 PM, Tim Graham notifications@github.comwrote: > In django/contrib/messages/storage/session.py: > > > ``` > > else: > > self.request.session.pop(self.session_key, None) > > return [] > > ``` > > > > + > > - def serialize_messages(self, messages): > > - encoder = MessageEncoder(separators=(',', ':')) > > look ok? https://gist.github.com/timgraham/dc1cc1abe202d3830eab > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/1488/files#r5903355 > .
Simplify error reporting as below, or skip this check and just let the `_html_search_regex()` calls raise the exception? ```suggestion for token in ('apiToken', 'widgetId'): if token not in rf_token_js: raise ExtractorError( 'Unable to fetch ' + token, expected=True) ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
Same here. `self.api_client` instead of `client`
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
I don't see any need for this attribute.
Good catch about the filter name! (And I like the extra spacing around `|` :) ) How about keeping the parantheses? I think it makes it easier to understand for the less jinja2-fluent what happens here. ```suggestion multi_group: (group_names | intersect(['alpha', 'beta', 'omega'])) | length >= 2 ```
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
not a show stopper, but the code might be clearer if we just add the '-n' and '%s'/dir_arg in the `if/else` and just execute `run_command` at the end
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
```suggestion module.fail_json(msg="value must be of type string, integer or dict") ```
After looking at this some more, I don't see a good reason to open the file in binary mode only to convert each line to native string type for further manipulation. ```suggestion with open(self.USER_ATTR, 'r') as file_handler: ```
prefer hanging indent style (allows longer lines, indentation always multiple of 4): ``` rasterheader = ( 1, 0, ... ) ```
Rather than use a `lamdba` here, it would be better to use a generator expression for clarity ```suggestion lines = line.split('::::')[1].split(';') tmp = dict(x.split('=') for x in lines) ```
`if it encounter` => `if it encounters`
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
`if it encounter` => `if it encounters`
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
double interpolation is very hard to read. And this looks wrong. Should probably be: `'%s%s%s%s%s' % (prefix, sep, gname, sep, gval)` (rather than `gname, prefix, gval, prefix, sep` which would generate `EnvironmenttagDevtag_`)
double interpolation is very hard to read. And this looks wrong. Should probably be: `'%s%s%s%s%s' % (prefix, sep, gname, sep, gval)` (rather than `gname, prefix, gval, prefix, sep` which would generate `EnvironmenttagDevtag_`)
Just a nitpick: The test name looks already readable to me so I'd drop the docstring.
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
"manual" is a recent occurrence, for older versions it was 'unmarkauto' iirc
```suggestion item, fields=fields, using=self.db, ```
```suggestion item, fields=fields, using=self.db, ```
```suggestion item, fields=fields, using=self.db, ```
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
This should verify the output.
falback to a static URL.
Actually someone can sent for example '123213321321321', which isn't valid name nor ID, so it will fail with HTTP 404.
It looks that `test_sqlmigrate_replaced_second_migration()` and `test_sqlmigrate_replaced_migration()` are redundant. Please remove one of them.
We can remove this block since Python 2.6 is not supported.
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
Download archive behavior must not change, it must only take place after success of the actual download and post processing.
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
Most of the time if you want a list and you're using map() you can convert to a list comprehension for a more pythonic (and faster, although that's almost never an issue) implementation: ``` python current_rules = [(x['priority'], x['rule_name']) for x in get_rules(api, name)] ```
Looks like this could be a single line.
Looks like this could be a single line.
it should also check if it can write there
Use _ (underline) instead of webpage if the value is not used.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
I think something like `SETTING_BOTH` will be fine. No need to memorialize the bug number.
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Should be ``self.weight``
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
what `_show_interface_dcb_ets(if_type, if_id)` fails: better to handle the case if the return value is None
Good catch, I will remove it before final squash.
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
```not (foo is None)``` => ```foo is not None```
Good catch, I will remove it before final squash.
`target` is only available for `Col`, so it crashes for expressions, see `test_slicing_of_f_expression_with_annotated_expression`.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
`form_class` is defined in `RangeField.formfield()` so this is redundant.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
You can skip the blank lines in these tests as three lines long isn't too difficult too read with spaces.
> Umh... this is a breaking change. @phihag should we add a hidden backwards compatibility `--write-srt`, or just specify the change in release notes? > Please stay backwards-compatible.
Please ignore, my suggestion is invalid syntax.
like diff = load_config(self._module, config_xml, [])
In Python3, `super()` is enough.
Can this fail with KeyError? It looks like that was transformed to InvalidCacheBackendError in the old code.
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
Instead, please set `self.index = json.load(f)`. The JSON library uses the `.load` function to stream straight from files without needing to `.read()` first. This also avoids pesky encoding issues with Python2/3.
Instead, please set `self.index = json.load(f)`. The JSON library uses the `.load` function to stream straight from files without needing to `.read()` first. This also avoids pesky encoding issues with Python2/3.
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
Again, this could be a class level attribute.
flake8 complains about missing spaces around `*`
Gotcha, okay I think this is acceptable.
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
are you sure about this point of "consist of only A-z0-9-_=", as opposed to those characters may not appear in the separator? (not too familiar with this restriction myself) I don't know that the complexity of a `setter` is necessary. I'd just modify the test to initialize a `Signer` each time.
Use the context manager version of `open()` so you don't need to worry about closing it manually.
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
I think all the calls to `render()` can be removed (it worked for me in this test at least)
I think it's fine. Separate test cases are normally a good thing since they can fail individually.
Why not use a list comprehension here? It's probably more efficient: `return [self.sanitize_keys(i) for i in data]`
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Code duplication 80-86, 89-94.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
I think we don't need it. but lets @felixxm decide about it. Thanks for the patch :+1:
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Inline everything used only once.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
It should be `if self._module.params.get('sparse') is not None`, because if `sparse` is `False` it won't send `sparse=False`
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
Yeah, so none of the tests failed if I forced either the multiple or single argument form of the function. That can't be right.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
Note: this is usually expressed as: ``` python if not full_version: ```
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
I don't see any need for this attribute.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
I don't see any need for this attribute.
Casting `int` to `int` is not necessary.
it should also check if it can write there
For some reason this causes ``` {aliases: [attr]} {choices: [all, 'no', none, safe, urllib2, 'yes']} {default: [200]} ``` while non-sequence values for `default` yield ``` default: 30 ``` without the `{...}`.
```suggestion (u'1', u'PB', 1125899906842624), (u'1E', 1152921504606846976), (u'1EX', 1152921504606846976), (u'1Z', 1180591620717411303424), (u'1ZB', 1180591620717411303424), (u'1Y', 1208925819614629174706176), (u'1YB', 1208925819614629174706176), ```
For some reason this causes ``` {aliases: [attr]} {choices: [all, 'no', none, safe, urllib2, 'yes']} {default: [200]} ``` while non-sequence values for `default` yield ``` default: 30 ``` without the `{...}`.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
Drop the `as e` since it's not used, and is not compatible with python 2.4.
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
This can be a separate ticket, but this message probably needs to be revised now that migrations are compulsory for all apps in 1.9.
should this be super()
This can be a separate ticket, but this message probably needs to be revised now that migrations are compulsory for all apps in 1.9.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
You should be able to use `self.vmware_test_platform` here.
++ thanks for changing this :)
++ thanks for changing this :)
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
Remove unnecessary whitespace.
Remove unnecessary whitespace.
Minor consistency nit- our stuff seems to be using `[action]_[backend]()`, where these aliased imports have that reversed. I'd vote for `[action]_[backend]()` over this- makes the code a little easier to read...
Usually, testing private interfaces doesn't make sense.
Do we need this check? All tests pass without it.
Wouldn't this approach fix the slicable fields to just these types? A mixin along with `slicable = True/False` on `F` may be an approach. Besides, I believe the policy is to keep `django.contrib.postgres` as separate as possible.
You'll want to branch off `< 3.6`.
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
I would chop blank lines in this test.
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
Try to minimize the test that demonstrates the regression. I think this part isn't important -- assigning a value when creating the model should work just as well.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
Similarly, ```if tc['skip'].get('i')```
I think a better wording would be: "Backwards compatibility for storage backends without support for `max_length` will be removed in Django 2.0."
I'm not sure the docstring adds any value here.
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
Remove unnecessary whitespace.
This must be in a separate try-except so that it does not break renaming to correct name if any of these statements fails.
with -> width
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
Indeed, you are right.
It seems `AMQPConnectionError` could be used instead of `Exception`.
It seems `AMQPConnectionError` could be used instead of `Exception`.
Is this possible? If so, it will be good to cover this scenario with tests.
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
1. No umask respected. 2. There is no `os.chmod` in python 3.2 according to python [docs](https://docs.python.org/3/library/os.html#os.chmod). 3. flake8.
One thing that worries me here is that it'll discard any `kwargs` so if `output_field` is provided, since we allow it to be passed as a positional argument it will be lost. e.g. `Subquery(queryset, models.BooleanField())`.
I don't see a need for string interpolation in cases like this.
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
``` for key, label in (('play_addr_lowbr', 'Low'), ('play_addr', 'Normal'), ('download_addr', 'Download')): format_url = url_or_none(try_get(data, lambda x: x['video'][key]['url_list'])) if not format_url: continue formats.append(...) ```
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
This doesn't look like it is tested.
This doesn't look like it is tested.
I think `get_internal_type` is better to use.
I think `get_internal_type` is better to use.
Instead of infinite checking, please cap the amount of time to some (can be long) value. 5 or 10 minutes would be *plenty* for CFN to generate a changeset.
this is unsafe and can lead to race conditions and data corruption, you should write to a temp file and use `basic`'s `atomic_move` method to finalize changes.
this is unsafe and can lead to race conditions and data corruption, you should write to a temp file and use `basic`'s `atomic_move` method to finalize changes.
```suggestion assert expected == "exception" ```
Maybe `subTest` to make tests less repetitive e.g.: ```python msg = 'Geotransform must consist of 6 numeric values.' for geotransform in ([1, 2], [1, 2, 3, 4, 5, 'foo'], [1, 2, 3, 4, 5, 6, 'foo']): with self.subTest(geotransform=geotransform): with self.assertRaisesMessage(ValueError, msg): rsmem.geotransform = geotransform ```
Don't we usually subscribe to a "unicode sandwich" strategy where functions pass around unicode strings and the function converts to bytes or native strings when it crosses an external boundary? I've also seen the `b_` or `n_` prefix being used if a function specifically accepts a byte or native string but not sure if that's an actual guideline we have going forward.
I'm not sure it's useful to implement _set_container in the base class, as the path seems different depending on stream.
This doesn't look right. This basically allows Python 3.0.1+, not 3.0.0+ as you probably intended. But even with that, it's best to just compare the major version and use "py2 or not py2" because py3+ also means py4+. OTOH we vendor `six` which contains proper constants already. So just import that: ```python from ansible.module_utils import six if six.PY2: ... else: ... ```
I think we prefer the closing paren on a newline
Based on my reading of the MSDN doc this should just result in returning the default value, not throwing an Exception. "Returns the last element of an observable sequence that matches the predicate, or a default value if no value is found." http://msdn.microsoft.com/en-us/library/hh228948(v=vs.103).aspx It should return the last value that matches the predicate, but if nothing matches then it should return the default value.
#66872 seems to think this would be 1.10.0, from experience I'd suspect it's actually a botocore version that's required...
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
This should be botocore.exceptions.NoCredentialsError.
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
```suggestion # Note: These examples do not set authentication details, see the AWS Guide for details. ``` It's helpful to hint the AWS Guide here so folks know about it.
Chop blank line.
Chop blank line.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This will also have to take into account `filter(m2m__field=val1, criteria=m2m__otherfield=val2)` != `filter(m2m__field=val1).filter(m2m__otherfield=val2)` as explained in [spanning multi-valued relationships](https://docs.djangoproject.com/en/1.11/topics/db/queries/#spanning-multi-valued-relationships)
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
Please ignore, my suggestion is invalid syntax.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
use to_native (module_utils._text) instead of str, it deals with py2/py3 compatiblity
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
following task -> the following task
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Indeed, you are right.
is the `any` required here - `if metrics_to_disable:` should suffice, I'd think
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
No need, I will commit the patch soon.
No need, I will commit the patch soon.
No need, I will commit the patch soon.
No need, I will commit the patch soon.
No need, I will commit the patch soon.
No need, I will commit the patch soon.
No need, I will commit the patch soon.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
This is a "set" method called from redfish_config (which doesn't pass in the systems_uri param). So need to remove that param here and just use self.system_uris[0] below.
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
This sentence ``` "To validate an individual application's models rather than all applications' models, call ``self.check(app_configs)`` from ``handle()``, where ``app_configs`` is the list of application's configuration provided by the app registry." ``` is still valid. I will restore it.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Also here, I don't know why you are splitting lines. It does not make it easier to read. Usually it is done out of necessity (e.g. PEP8 rules require it), but in this case there is no need to make this weird.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
`target` is only available for `Col`, so it crashes for expressions, see `test_slicing_of_f_expression_with_annotated_expression`.
Match the error message
I was also confused by this logic for a while and I got an optimization idea from the [Raft dissertation](http://wcl.cs.rpi.edu/pilots/library/papers/consensus/RAFTOngaroPhD.pdf) about this, The sentence below is taken from section "5.4.2 Committing entries from previous terms": ``` There are some situations where a leader could safely conclude that an older log entry is committed (for example, if that entry is stored on every server), but Raft takes a more conservative approach for simplicity. ``` so we can also update commitIndex(highWatermark) if logEndOffset of all followers have passed the highWatermark. I don't think this is a good idea since it makes the logic opaque but will not necessarily really optimize any performance, so I just mention it here and feel free to ignore it ð.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
You probably should add yourself to the authors list as well.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
I think a better wording would be: "Backwards compatibility for storage backends without support for `max_length` will be removed in Django 2.0."
I would prefer to keep a slice logic with `start` and `stop` instead of `low` and `length`.
```suggestion assert isinstance(wrap_var(['foo']), list) ```
> But I think it would be better if we didn't let the debug implementation slow the non-debug implementation more. Yeah. That did occur to me, but haven't had time to check the performance. It might still work out in concert with other ideas I've had… But those don't need to hold this up.
this module is marked as "legacy" and therefore the CI is not complaining about pep8 here, but it would help if we try to be pep8 compliant.
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
This function is too complex. Could you please factor and avoid: - more than 2 level of condition - inner loop. You can probably break down the function in several small functions.
WDYT about adding `or self.title` here? ``` python self.title = title or self.title or self.lookup_title ``` This would add support for the following: ``` python class MyStaffFilter(BooleanFieldListFilter): title = "By can haz admin" # no effect :( overwritten in __init__ @admin.register(User) class UserAdmin(UserAdminBase): list_filter = ( ("is_staff", MyStaffFilter), ) ```
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Would it be better to raise `NotImplementedError()` so backends don't overlook implementing it? They can always return an empty list if it's not supported.
maybe should be get('properties', {}).get('ipConfigurations') so it will be shorter
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
Indeed, you are right.
I think we should create a hook similar to the `_field_should_be_indexed()`, that will allow 3rd-party backends to adjust this behavior, e.g. ```python class BaseDatabaseSchemaEditor: ... def _field_should_be_altered(self, old_field, new_field): # Don't alter when changing only a field name. return ( old_field.column != new_field.column or old_field.deconstruct()[1:] != new_field.deconstruct()[1:] ) ```
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
The new implementation should support signatures for a number of resolvelib versions. They could be defined dynamically in runtime.
This check is also redundant.
```python raise ValueError( "ISO week directive '%s' is incompatible with the year " "directive '%s'. Use the ISO year '%%G' instead." % ( week_format, year_format, ) ) ```
Whoaw, I knew there was an impact, but did not suspect this. This is ugly. cc @kbreit Opened a ticket for this. https://github.com/ansible/ansible/issues/52717
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
add trailing comma
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
```suggestion old_item['aliases'] = sorted(old_item['aliases']) ```
yeah I think it would be worthwhile to at least test a single JOIN scenario.
yeah I think it would be worthwhile to at least test a single JOIN scenario.
Since utilities functions can be called in tight loops it's best to minimize the number of Python function calls when readability doesn't suffer too much.
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
I'm not sure why but other parts of the code are using "my" for the variable name for a yum_base object so we should keep doing that.
Minor but I'd move this control flow block after the `weights` one to match the args order.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
nit: needs a comma after the `{@link ...}`
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
it should be `minor_vers = int(version[1])`
```suggestion assert expected == "exception" ```
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
I think I'd keep the `fields` parameter as a list, perhaps passing `None` for `params` here.
Cross-compability, backwards compatibility, command line compatibility, ease of discovery. * Other packaging modules support comma separated package entries. * The pip module itself supports comma separated package entries * pip supports single string entries as valid packages * comma separated list entries are the natural way to write lists on the commandline. * error messages if people were to violate these rules (for instance: ```ansible localhost -m pip -a 'names=django>=1.11.0,<1.12.0'``` wonn't point to the actual solution unless we implement this sort of detection for creating the error message... in which case we might as well do the right thing.
I think I'd keep the `fields` parameter as a list, perhaps passing `None` for `params` here.
```suggestion assert expected == "exception" ```
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
Good catch, I will remove it before final squash.
Good catch, I will remove it before final squash.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
prefer hanging indent style with 1 arg per line
`elif` might be clearer (I understand it's not necessary)
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This doesn't need to be quoted.
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
```suggestion # Run masked_action when enabled param is not provided or service is supposed to be enabled/started. if not module.check_mode and module.params['enabled'] in [None, True]): ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
preferred format is "#15346, #15573 - Issue description"
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
How about adding `self.assertIs(response.context['is_multipart'], True)` before the `assertContains()` (since those can be difficult to debug)? (Might be worth adding a similar assertion somewhere for the False case.)
`field_preference` must be a list or a tuple.
Code duplication 80-86, 89-94.
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
`re.sub` part can be put in `transform_source` parameter of `_parse_json`.
Since this `int()` call is no longer inside a `try` `except`, we now get a stack trace if the checksum is an invalid base 16 value. ``` ValueError: invalid literal for int() with base 16: '541a1ef5373be3dc49fc542fd9a65177b664aec01c8d8608f99e6ec95577d8ci' ``` ```suggestion try: int(checksum, 16) except ValueError: module.fail_json(msg='The checksum format is invalid', **result) ```
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
I might be missing something but I can't come up with a way `escape_isnt_last_filter is True` when reaching this branch as the only way to get in there is when `seen_escape_filter is True` which is only set in the `isinstance(obj, EscapeData)` branch below where `escape_isnt_last_filter` is immediately set to `False`.
Why has this logic changed? I can't see what it has to do with removing the use of `_clone()`
Why has this logic changed? I can't see what it has to do with removing the use of `_clone()`
I might be missing something but I can't come up with a way `escape_isnt_last_filter is True` when reaching this branch as the only way to get in there is when `seen_escape_filter is True` which is only set in the `isinstance(obj, EscapeData)` branch below where `escape_isnt_last_filter` is immediately set to `False`.
Why has this logic changed? I can't see what it has to do with removing the use of `_clone()`
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
Please do not revert this doc change. The old text is wrong in almost every important way.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
multiple dictionary access: instead of ```python if required_config.get('rotation', None): rotation = required_config['rotation'] ``` use: ```python rotation = required_config('rotation') if rotation is not None: # do your stuff ``` use this rule for all dictionary access below
Is there precisely one time you can specify this? It sounds to me like this should be allowed to repeat multiple times. So this should be a `list`. Or maybe even better a `dict`, so people can specify things like ``` blkio_weight_device: /dev/sda: 100 /dev/sdb: 200 ```
2.6 or 2.7? Also you `requirements` listed here and the modules.
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
The wording we usually use is "django.utils.translate.string_concat() is deprecated in favor of django.utils.text.format_lazy()."
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
The wording we usually use is "django.utils.translate.string_concat() is deprecated in favor of django.utils.text.format_lazy()."
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
Minor but I'd move this control flow block after the `weights` one to match the args order.
```suggestion Set I(version=latest) to get the most recent version of a given image. ```
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
it seems this and other parameters are missing from docs
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Hmm, I thought we'd have `LATEST_0_10_1` and `LATEST_0_10_0` instead of `LATEST_0_10` (which doesn't make sense because we have multiple feature releases in the `0_10` line.
Nit: maybe there should be no default for `should_fail` since we always pass a value.
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
I'd personally expand these to `kafka1` and `kafka2` as I reserve single character varnames (or variants with numbers appended) to indexes, but that's very much a nit.
it seems this and other parameters are missing from docs
it seems this and other parameters are missing from docs
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
I thought we had these in a GCP docs fragment, but now I'm not able to find it.
it seems this and other parameters are missing from docs
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
Basically `os.path.isfile(metadata_filename)` is superfluous here since we control the file lifetime on our own and since we don't delete the file it should exist. This check may only fail if someone touched our file that is unexpected scenario that normally should not happen. In such cases we should stop right at failed `os.remove` rather than skipping such unexpected outcome with this check. If someone touches our files then it's definitely wrong and we should not continue.
These last four lines are duplicated in both conditions, should therefore come after the if block.
This can be single lined.
to_text and u prefix on string.
I was also confused by this logic for a while and I got an optimization idea from the [Raft dissertation](http://wcl.cs.rpi.edu/pilots/library/papers/consensus/RAFTOngaroPhD.pdf) about this, The sentence below is taken from section "5.4.2 Committing entries from previous terms": ``` There are some situations where a leader could safely conclude that an older log entry is committed (for example, if that entry is stored on every server), but Raft takes a more conservative approach for simplicity. ``` so we can also update commitIndex(highWatermark) if logEndOffset of all followers have passed the highWatermark. I don't think this is a good idea since it makes the logic opaque but will not necessarily really optimize any performance, so I just mention it here and feel free to ignore it ð.
Thanks. This PR is assigned to the 2.12 milestone, which we'll be going through after creating the stable-2.11 branch (which will be done when 2.11 RC1 comes out).
check here for the regex fix https://github.com/Qalthos/ansible/pull/5/commits/89f2a106db4f7296822e118ad24f66cea84f3be9#diff-e72efaa6b72beb5339ad847e21a31220L87 Good catch on the first_port / last_port ... will add a fix for those. This is a common pattern to be used by eos modules. I have held off on pushing the modules upstream until we get the initial push of the refactored network shared modules
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
Why double-underscore? I would also rename `func` to `callback`: ```suggestion for _, callback in connections[using].run_on_commit[start_count:]: callbacks.append(callback) if execute: callback() ```
Why double-underscore? I would also rename `func` to `callback`: ```suggestion for _, callback in connections[using].run_on_commit[start_count:]: callbacks.append(callback) if execute: callback() ```
should this be super()
Since Ansible subscribes to unicode sandwich, this should be the callers' (actually, where the data enters the system) responsibility.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
This doesn't need to be quoted.
This doesn't need to be quoted.
