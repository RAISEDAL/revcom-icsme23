Condition the value? ```suggestion bitrate = int_or_none(details.get('bitrate')) or 999000 ```
Condition the value? ```suggestion bitrate = int_or_none(details.get('bitrate')) or 999000 ```
so this assertion looks incorrect, i would expect and empty string as the ssh args
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
how about the root cause? I remember we discussed that it is a problem when we get more than one, but can we add a TODO for it somewhere or do at least something when we have a single one? I don't see where we parse them but I may be missing something. Maybe they end up skipped where we parse metadata arrays in `innerFromXContent`
I think this is outdated based on the addition of schemaless support.
I think this is outdated based on the addition of schemaless support.
I think this is outdated based on the addition of schemaless support.
I think this is outdated based on the addition of schemaless support.
I think this is outdated based on the addition of schemaless support.
OTOH this all can be made way easier: ```suggestion return max(v for v in self.versions if v != '*', default='*', key=LooseVersion) ``` (no need for sorting, faster)
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
Should check for a list.
I guess the problem is we don't have a separate principal in tests that we can assign those to. Could we separate out `Create` and `Alter` into another method, so that tests can set them as necessary or would that impact every test? We expect brokers to have only `ClusterAction`, but our docs and generally everyone expects broker to have more permissions. This sort of makes our tests run with a combination of permissions that we never expect a principal to have - broker principal should have only ClusterAction, no one else should have ClusterAction. Separating out into two methods may be better even if we end up using the same principal in tests.
I guess the problem is we don't have a separate principal in tests that we can assign those to. Could we separate out `Create` and `Alter` into another method, so that tests can set them as necessary or would that impact every test? We expect brokers to have only `ClusterAction`, but our docs and generally everyone expects broker to have more permissions. This sort of makes our tests run with a combination of permissions that we never expect a principal to have - broker principal should have only ClusterAction, no one else should have ClusterAction. Separating out into two methods may be better even if we end up using the same principal in tests.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Also, things like int(True) == 1 and int(False) == 0, in python3 int(b'characters'[0]) == 99....
This TODO needs work
This TODO needs work
`dynamic` is not a very descriptive name. It looks like what you want is to pass the output both to a file and to stdout. In general, this problem has already been solved by `tee`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
@samdoran then, I'd say that there's something wrong with the setup and TZ should be adjusted somewhere.
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
``` for key in data: if ':' in key or '-' in key: newkey = key.replace(':', '_').replace('-', '_') data[newkey] = data.pop(key) ```
All formats should be extracted.
This is never reached if Content-length is not set.
I'm not sure this is right, because I don't think that `ansible.module_utils.ansible_tower.HAS_TOWER_CLI` exists in `stable-2.4` It looks to me like you need a mix of the two, something like this: ```diff +import os + +from ansible.module_utils.ansible_tower import tower_argument_spec, tower_auth_config, tower_check_mode + ``` ```diff try: - import os import tower_cli import tower_cli.utils.exceptions as exc from tower_cli.conf import settings - from ansible.module_utils.ansible_tower import tower_auth_config, tower_check_mode - HAS_TOWER_CLI = True except ImportError: HAS_TOWER_CLI = False ```
If `port` is changed to a `list`, you'll need to do this here: ```suggestion ports = module.params['port'] if isinstance(ports, list): ports = ','.join(to_native(x) for x in ports) fullurl = ("%s%s/api/v2/config/serialports?ports=%s" % (protocol, to_native(module.params['cpm_url']), ports)) ```
No need to parametrize with just one case.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
looks like there are common options for all graylog modules, Shared code are located in lib/ansible/module_utils (note that this must not be GPL here). But this can be done later on. Not a blocker, just a hint.
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
Having a class for just one test method is unnecessary.
It would be awesome if buildah supported copying from a container.
It would be awesome if buildah supported copying from a container.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
`current_version` could be mentioned in the error message.
Lists also have .extend() which might be what you need here
`current_version` could be mentioned in the error message.
`current_version` could be mentioned in the error message.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
and convert filename to bytes again.
and convert filename to bytes again.
What's the point combining original and translated lyrics to a single file? There should be 2 separated entries in `subtitles` instead.
What's the point combining original and translated lyrics to a single file? There should be 2 separated entries in `subtitles` instead.
aws_ip_ranges -> aws_service_ip_ranges
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
Should not be fatal.
A simpler fix would be to do `join(to_install + to_upgrade)`
```suggestion module.exit_json(changed=True, db=db_name, db_list=db) ``` So behavior is the same as without `check_mode`.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
This should contain the copy-and-pastable code of the call layer (like we do for the Dense layer).
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
the second parameter for `_download_*` methods is `video_id`, use the `note` parameter for the message.
This should be a character string (prefixed with `u`)
This should be a character string (prefixed with `u`)
@davidharrigan Nice spot, thanks. From a quick Google I've found * https://github.com/TAXIIProject/libtaxii/commit/59e18912e90550e2248779518fb63fac77d2f5a1 * https://bugs.python.org/issue4773
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
no, if the variable is set but empty, you should empty out the options
I'd go for underlining.
same here, we really dont want to test the particular setting, just that both the default (dynamic template) and the nii entry are correctly parsed.
Feel free to ignore me here but `get_*_coverage_files()` is common between python and powershell, you could just have the 1 function and have ``` def _get_coverage_files(language): coverage_dir = ResultType.COVERAGE.path coverage_files = [os.path.join(coverage_dir, f) for f in os.listdir(coverage_dir) if '=coverage.' in f and ('=%s' % language) in f] return coverage_files def get_python_coverage_files(): return _get_coverage_files('python') def get_powershell_coverage_files(): return _get_coverage_files('powershell') ```
no, if the variable is set but empty, you should empty out the options
This method isn't necessary.
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
`False` is default.
Got it. But this is very confusing error message. anyways, not a blocker as such.
And the same here
Got it. But this is very confusing error message. anyways, not a blocker as such.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
you need `C`, not `c` to actually pick them up from constants
Ah, ok. As I said, I've never used docker-machine, so I assumed that it actually connects to the machine (using that shell) and exports the environment from there. If that's just the format, then yes, it really doesn't matter (as long as it is a format you can parse :) ). Both `bash` and `sh` are fine for me, use whatever you want then.
Move flags into regex.
`url` is not a video id.
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Move flags into regex.
Query should be passed as `query` parameter.
This can be simplified to `[None] * 5` or `(None, ) * 5`.
Code duplication. This is already implemented in `CeskaTelevizeIE`.
Use _html_search_meta for ```<meta>``` tags
Since this is length 1 always, you can use `connection.extend(response['connections'])` for the same result.
In Python, it's common to include docstrings as per PEP 257: ```suggestion def fake_now(monkeypatch): """Patch `datetime.datetime.now()` to return a deterministic value.""" ```
I think this code should just be: ``` dummy, dummy, boto_params = get_aws_connection_info(module, boto3=True) profile = boto_params.get('profile_name') s = session.Session(profile_name=profile)(**boto_params) credentials = s.get_credentials() return credentials.access_key, credentials.secret_key, credentials.token ```
These two lines can be made conditional on `threshold != 0.5`
Can we calculate that beforehand? Also `os.environ.get` could make this much more readable.
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
We don't have access to ansible.compat.six in modules (and thus we shouldn't use it in module_utils either.) Use this instead: ``` python from ansible.module_utils.six moves import reduce ```` We plan on merging the two together eventually, once we can remove module-side support for python-2.4 (Right now the python-2.4 requirement means that module_utils has an older version of six than in ansible.compat.)
Can setting above three keys moved in `nxapi_implementation()`
Do we want floats like int(1.9999999999) to convert to 1? We might want to throw an error on float still. OTOH, if we allow floats, we probably also need to handle a string value of "1.0".
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
`full_url` does not exist on Python 2.x
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
`filter_for = socket.AF_INET if '.' in source_address else socket.AF_INET6`.
We should probably put this into ansible.utils.unicode with a note about when to use it and what sort of literals to use it with for those that don't understand the native string distinction.
<nod> I see what you mean about checking the length for the secret leaking information about the secret that the attacker would not otherwise know. However, checking the length for the plaintext doesn't seem to suffer from that same problem. The attacker already has an idea of how long the plaintext is because the length of the ciphertext will reflect that. So checking the length of the plaintext and falling back to os.urandom() if the plaintext is too short seems like it can prevent some problems without revealing new information? (Hmm... it would reveal that the plaintext is less than a precise value whereas looking at the length of the ciphertext would be more vague.... Would that be important or not?) The attacker can learn a lot about what is in a vault file from external sources... for instance, since they're yaml files, they likely have a rough outline of: ``` --- var: value ``` an attacker might also find the precise name to use for "var" by looking at playbooks to see which variable names exist that are not defined outside of a playbook. So then the only thing about the plaintext that they'd be lacking would be the actual value....
no need to specify required=False or type=str as these are defaults
it is useful to also add the api exception info: module.fail_json(msg="Unable to connect to vCenter or ESXi API on TCP/443.", apierror=str(e))
Okay I think this makes sense, let's just follow this pattern then.
You should be able to use `self.vmware_test_platform` here.
Better to use `_keras_history`
List or tuple. Iterables implement `__iter__()` and thus may not necessarily be indexable (requires `__getitem__()`).
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
All Ubuntu versions or only certain ones? That will make it clearer if someone needs to update this in the future to know what needs testing
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
Thanks for that note ewen. I learned something!
Thanks for that note ewen. I learned something!
Breaks extraction if not available. Again read coding conventions.
No. Use `smuggle_url` if you need to pass some additional attribute.
I find this a bit too 'magical' also it might collide with existing tags. -1
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Same here (and the other two missing).
You should probably expect unicode strings
```suggestion module.fail_json(msg="Cannot dump database(s) %r - not found" % (', '.join(non_existence_list))) ```
This can be more PEP8 with a '\n': ``` Python class YahooSearchIE(LazyLoadExtractor): _VALID_URL = None _module = 'youtube_dl.extractor.yahoo' @classmethod def suitable(cls, url): return re.match(cls._make_valid_url(), url) is not None @classmethod def _make_valid_url(cls): return 'yvsearch(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' ```
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
This should be `to_text` from ` ansible.module_utils._text` instead of `str` for python3 compatibility.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
It is highly recommended to use `assert` statements in the pytest env because it integrates with its reporting better and more natively. ```suggestion assert len(ret) == 3 ```
Looks like another JWPlayer site. Use `_extract_jwplayer_data` instead.
Looks like another JWPlayer site. Use `_extract_jwplayer_data` instead.
This will still result in a command like `git config --unset foo ''`. According to the git config man page, that extra argument is a "value_regex" and its presence means only those values matching this regex will be unset. Luckily the empty string is a regex that matches everything, so it all works out fine in the end.
Looks like another JWPlayer site. Use `_extract_jwplayer_data` instead.
data_len is a string so it's wrong to compare it with an integer, and it can't be done on python 3.x
The `elif attributes.startswith('='):` isn't required. The `else` arm has the same code.
you need to skip value from parent if include_tasks/include_role, but still inherit
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
You don't need a lambda here. Also, don't break lines with `\`.
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
In line with naming conventions in this API, this should be `_num_constants`.
@davidharrigan Nice spot, thanks. From a quick Google I've found * https://github.com/TAXIIProject/libtaxii/commit/59e18912e90550e2248779518fb63fac77d2f5a1 * https://bugs.python.org/issue4773
@davidharrigan Nice spot, thanks. From a quick Google I've found * https://github.com/TAXIIProject/libtaxii/commit/59e18912e90550e2248779518fb63fac77d2f5a1 * https://bugs.python.org/issue4773
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Almost all modules use `dict()` constructor here. `required: False`, `default: None`, and `type: 'str'` are defaults and not required. Not really a blocker, more advisory.
Almost all modules use `dict()` constructor here. `required: False`, `default: None`, and `type: 'str'` are defaults and not required. Not really a blocker, more advisory.
We could fall back to `__file__` or something in that case at minimum. Could be useful to include that regardless.
Almost all modules use `dict()` constructor here. `required: False`, `default: None`, and `type: 'str'` are defaults and not required. Not really a blocker, more advisory.
Query must go to `query`.
I think this description makes it more confusing. You already explain this above. Please remove this edit.
If nothing matches `None` will be returned.
I think there is something wrong with GCE http client code and we will need this around it, we grant the permission as a workaround. It would be really good if we could get this fixed in their code though. It makes it difficult for apps to protect credentials etc to their services!
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
`[^/]*$` is completely pointless here.
skip a line to be consistent
Another option is to use `threading=True` or `use_threads=True`
This assertion doesn't make sense: you're testing whether your fixture returns a Mapping instance which it always does. ```suggestion ```
fixture with load_json
I missed this one in my last review: ```suggestion raise SystemExit('ERROR: Ansible requires the filesystem encoding to be UTF-8; Detected %s.' % fs_enc) ```
`InfoExtractor._check_formats` should be used for validating download URLs.
my personal preference here is to dump all of these 2.7 specific modules into a Test class that has a pytest decorator of @pytest.skipif(sys.version_info <(2,7)) or whatever the syntax is. By collecting the version specific tests in their own classes, you can avoid this conditional logic in the test itself
This assertion doesn't make sense: you're testing whether your fixture returns a Mapping instance which it always does. ```suggestion ```
This assertion doesn't make sense: you're testing whether your fixture returns a Mapping instance which it always does. ```suggestion ```
Ah CONTENT_TYPE I see. Sorry for the noise ;)
I think there is something wrong with GCE http client code and we will need this around it, we grant the permission as a workaround. It would be really good if we could get this fixed in their code though. It makes it difficult for apps to protect credentials etc to their services!
skip a line to be consistent
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
Ah, right, got it :+1:
`(?s)` has no effects in regular expressions without `.`
`a['adress']` could be used instead of `(len(a['address']) > 0)`.
Python 3.5 does not have `unicode`. Take a look at the [ansible text helper methods](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/_text.py) for alternatives. Only noting the first occurrence.
Use a context manager with this read operation to ensure the file handler is closed as soon as it is no longer needed rather than relying on successful program termination. ```suggestion with open(self.LOGIN_DEFS, 'r') as f: for line in f.readlines(): ```
CI failure due to PEP 8 issue: ``` 2017-02-16 00:21:02 ERROR: PEP 8: lib/ansible/modules/cloud/docker/docker_service.py:525:59: W291 trailing whitespace (current) ```
CI failure due to PEP 8 issue: ``` 2017-02-16 00:21:02 ERROR: PEP 8: lib/ansible/modules/cloud/docker/docker_service.py:525:59: W291 trailing whitespace (current) ```
If you're using autouse on your fixture then you won't need to reference the fixture for it to inject the XenAPI import. Forgetting it will only mean you won't have a local reference to it.
it should also check if it can write there
not sure why you moved all the code to _version ... why not keep here? seems like useless jump
not sure why you moved all the code to _version ... why not keep here? seems like useless jump
not sure why you moved all the code to _version ... why not keep here? seems like useless jump
I think this two lines are better using compat_urllib_parse_urlparse and the `_replace` method: - It's not immediately clear clear why you use `video_url[:10]`, it's better if you explicitly change the path - `rendition_url.rindex('.')` won't works as expected if the query contains a dot, and normal `index` will match the dot from the domain.
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
I think this two lines are better using compat_urllib_parse_urlparse and the `_replace` method: - It's not immediately clear clear why you use `video_url[:10]`, it's better if you explicitly change the path - `rendition_url.rindex('.')` won't works as expected if the query contains a dot, and normal `index` will match the dot from the domain.
I think this two lines are better using compat_urllib_parse_urlparse and the `_replace` method: - It's not immediately clear clear why you use `video_url[:10]`, it's better if you explicitly change the path - `rendition_url.rindex('.')` won't works as expected if the query contains a dot, and normal `index` will match the dot from the domain.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
I think truststore and ca could be stored in a single directory. The files are related and are created together.
actually, any var that is not the 'item' in vars= should be removed
Tests shouldn't be invoked directly, so this isn't needed.
In python 3.X print is a function, for printing to screen use `self.to_screen`. But if it's a fatal error then `raise ExtractorError`
1. Single quotes. 2. `expected`.
Instead of such hacks you can name group differently and capture it without any issue.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
This check doesn't work as-is and raises issues when running the following playbook two times in a row: ``` --- - hosts: localhost tasks: - openssl_privatekey: path: /tmp/private.key - openssl_csr: path: /tmp/csr.csr privatekey_path: /tmp/private.key commonName: www.ansible.com ``` This is due to the fact thatthe current code relies on `expected` being an array when it could be actually None, hence raising: ``` TypeError: 'NoneType' object is not iterable ``` Here is an alternative implentation that did what was expected, feel free to modify adapt/modify/get ideas from it: ``` usages_ext = [str(ext) for ext in extensions if ext.get_short_name() == extName] if (not usages_ext and expected) or (usages_ext and not expected): return False elif not usages_ext and not expected: return True else: current = [usage.strip() for usage in usages_ext[0].split(',')] expected = [long[usage] for usage in expected] return current == expected ```
This check doesn't work as-is and raises issues when running the following playbook two times in a row: ``` --- - hosts: localhost tasks: - openssl_privatekey: path: /tmp/private.key - openssl_csr: path: /tmp/csr.csr privatekey_path: /tmp/private.key commonName: www.ansible.com ``` This is due to the fact thatthe current code relies on `expected` being an array when it could be actually None, hence raising: ``` TypeError: 'NoneType' object is not iterable ``` Here is an alternative implentation that did what was expected, feel free to modify adapt/modify/get ideas from it: ``` usages_ext = [str(ext) for ext in extensions if ext.get_short_name() == extName] if (not usages_ext and expected) or (usages_ext and not expected): return False elif not usages_ext and not expected: return True else: current = [usage.strip() for usage in usages_ext[0].split(',')] expected = [long[usage] for usage in expected] return current == expected ```
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
I don't think so. If one explicitly specify an `--external-downloader` he does this intentionally and expresses own will to use exactly this downloader thus all the consequences (that the whole video will be downloaded instead of a fragment) are his responsibility.
Just to be sure add a `if not host_data: ...`
```suggestion # just get value from attribute itself as normal ```
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
This would trigger a hard-to-read exception if the module is not available. Better to throw a proper exception with an appropriate message.
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Typo: space after `uuid,`
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
I guess it's best to remove the version number here (and in all the other copies of the config). Not sure whether that should happen in this PR though :)
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Typo: space after `uuid,`
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Docstring contains a few typos, please fix / rephrase
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
Docstring contains a few typos, please fix / rephrase
Please use consistent quote chars. If you know at which PIL version these attributes were introduce, prefer doing a version number check instead of repeated `hasattr` calls.
Don't remove tests for the original JSInterpreter. Before jsinterp2 replaces jsinterp, tests should be there to guarantee nothing gets broken by accident.
Don't remove tests for the original JSInterpreter. Before jsinterp2 replaces jsinterp, tests should be there to guarantee nothing gets broken by accident.
No that's not the correct behavior. A Keras tensor is a tensor with the `_keras_shape` or `_keras_history` attributes set (if would actually be preferable to test for `_keras_history` than `_keras_shape` as we were before). We should raise a `ValueError` if `not isinstance(x, tf.Tensor)`
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
should be handled someway in `js_to_json`, at least add a `TODO` to indicate that this should be fixed in a general way.
`False` is default.
Should `args[1:]` here (the first entry in `args` is `self`).
This extracts mess instead of download URL: ``` >youtube-dl http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/ -f 720p-1500k-cdn2b-0 -g http://cdn2b.download.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500 &s=1445177200&e=1445350800&h=178da8509b9b869e9ad12809e016f078' title='Download Video'>MP4 HD - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(37 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/480p_370k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=e5b5291f1ade3a2ea66af312daf37a04' title='Download Video'>MP4 - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(9 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=7b1ceb68fd3affe8f2308a6501cbb218' title='Download Video'>MP4 - For iPhone/iPod</a> <span class='downloadsize'>(6 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/180p_150k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.3gp?rs=150 &ri=1000&s=1445177200&e=1445350800&h=c8ce8aa7f320c8c9253a1a3a6817539c ```
Playlist metadata must not be fatal.
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
``` sh >>> input_list = [[]] * 10 >>> input_list[0] += [1] >>> input_list [[1], [1], [1], [1], [1], [1], [1], [1], [1], [1]] ``` Probably not what you intended.
[`get_param`](https://github.com/spotify/pyfg/blob/master/pyFG/forticonfig.py#L249) should not raise an exception. I guess you could check if `f.running_config[path]` contains `module.params['name']Ì`.
Nice, I like this pattern :+1:
use `unfrackpath(filename)` to ensure we get something the user can always use
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
Lookup plugins run on the controller. The minimum python version for the controller is python 2.6. So str.format() can't use "{}". The easy workaround is to use "{0}" and "{1}" instead.
Lookup plugins run on the controller. The minimum python version for the controller is python 2.6. So str.format() can't use "{}". The easy workaround is to use "{0}" and "{1}" instead.
`User has been updated`
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Like above, I think this should be `userid, name, password, group, email`
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```suggestion - name: Install python package using a proxy # Pip doesn't use the standard environment variables, please use the CAPITALIZED ones below ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I don't see a reason to keep all, they were kept in the past since new modules were created without changing previous ones.Since there are a few modules being updated / refactored and because this is part of the module_utils now, maybe we can change this *behaviour* in the next Ansbile release to not break things in minor releases.
This should not be moved. They're libraries from the current project so go below the imports for stdlib and third party libraries.
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
Move on a single line.
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
Move on a single line.
we want want -> we want
I don't see a reason to keep all, they were kept in the past since new modules were created without changing previous ones.Since there are a few modules being updated / refactored and because this is part of the module_utils now, maybe we can change this *behaviour* in the next Ansbile release to not break things in minor releases.
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
Use `'` everywhere for consistency. Do not break lines with `\`
Use the `fake_xenapi` fixture on tests that need to reference it and this import won't be needed. ```suggestion ```
`IGNORE[xxx]` is used as something iterable, and I don't think any of the calling code wants a list of letters :)
Use code markers around `put()`
`IGNORE[xxx]` is used as something iterable, and I don't think any of the calling code wants a list of letters :)
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Use the `fake_xenapi` fixture on tests that need to reference it and this import won't be needed. ```suggestion ```
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
If you turn this into ```suggestion if not os.path.exists(collection_output): _build_collection_tar( collection_path, collection_output, collection_manifest, file_manifest, ) return ``` you could reduce some nesting which improves readability.
If you turn this into ```suggestion if not os.path.exists(collection_output): _build_collection_tar( collection_path, collection_output, collection_manifest, file_manifest, ) return ``` you could reduce some nesting which improves readability.
action plugin should have already taken care of this
I find the inconsistent capitalization very confusing. There's `Name` and `Facts` but also `all_parameters`. Here we have `environment` but also `Location` and `Organization`. Ideally the original API response would be normalized.
I would add an additional check here to catch syntax errors like `-f 'bestvideo,,best'`. ``` python if not current_selector: raise syntax_error('Expected a selector', start) ```
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
facts modules can trivially support check mode (#23107)
facts modules can trivially support check mode (#23107)
nit: this doesn't need to be a field, you can just use a local variable
Not sure if this is the best way to refer to the module... what happens if we don't run nosetests form the right directory? Maybe relative imports are what we want to use here (since the unittest code is python2.6+). I think it's `from ... import swap_stdin_and_argv`)
Would this ever return false under normal circumstances? Seems like we'd lose items if it did...
This is performing a job match against the artifact name. In order to filter artifacts based on jobs you need to use the timeline results and match the artifact `source` against the timeline `id` for a given job.
f is already at 0, the `truncate()` is uselesss.
you can move it to before `if` as just `docs = {}` line, this should read better.
This is performing a job match against the artifact name. In order to filter artifacts based on jobs you need to use the timeline results and match the artifact `source` against the timeline `id` for a given job.
The validator should be updated to include validation of of `required_by`.
This should be split into building url and extracting formats.
Technically since we're doing this in a fixture, either `monkeypatch` should be used to insert these into `globals()`, or you should return `mod`, and then just use `mod.Template` and `mod.AnsibleNativeEnvironment` in your tests.
no, if the variable is set but empty, you should empty out the options
It likely makes sense to add the remaining psycopg2 parameters including host and port.
Adding the exception string to the error would help the user narrow down what the issue is.
should be self.forward.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
f is already at 0, the `truncate()` is uselesss.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
I'd want to see the role stay atomic and have either everything or nothing change. If the module fails, nothing should change on the system. That might either mean moving the loop into the `semanage_boolean_value` function, or supporting externally-triggered commit for the function.
```suggestion file_name, file_exts = os.path.splitext(str(url.rsplit('/', 1)[1])) # Preserving double filename extensions like .tar.gz _, double_ext = os.path.splitext(file_name) if double_ext: file_exts = double_ext + file_exts: ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
Let's add a TODO for this one
It might also be useful to print login response code to supplement earlier login method debug. white testing this patch I felt login did not go through
Use `errors='replace'` so that we don't traceback in case of invalid utf-8. Since this is a logging function, it's okay to display a mangled string.
Missing `=dict` on this and the next few lines
could reverse the update ordering and update templar._get_filters() (or a copy...) with e.filters so that the e.filters 'wins'
BotoCoreError should be caught here as well and all other places catching ClientError https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-1 BotoCoreError does not have a .response, so using AnsibleAWSModule will cut down on exception handling logic as I suggested above.
boto3_conn() now handles NoRegionError and ClientError so you can remove that here.
I'd sort the set when showing the error message, to guarantee consistent results for the same package list.
BotoCoreError should be caught here as well and all other places catching ClientError https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-1 BotoCoreError does not have a .response, so using AnsibleAWSModule will cut down on exception handling logic as I suggested above.
```suggestion - Create or delete project variable. ```
Missing `=dict` on this and the next few lines
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
result is attempted to be used below
Missing from docs
`del` is a builtin, not a function. These parens don't have to be here
Move the check_mode test into the `do_notify_teams` function, and see if you can do something relevant instead e.g. test the connectivity so you do as much as possible in check-mode.
It's a good practice to have a trailing comma after the last sequence item as well. This way, when someone will add or remove an item it will generate only one line of diff, as opposed to two lines: one for the logical change and one for editing comma next to unrelated item. This practice makes doing reviews easier and more joyful :)
IIRC should be just `raise` to re-raise the existing error
last loaded wins, but iirc, we reverse search on handlers list
there is an ansible specific dumper we create, not sure if pertinent to this plugin, but worth looking into as i think it can save you work
you may want Y_rev = K.permute_dimensions(Y_rev, (1, 0, 2)) Y_rev = Y_rev[::-1]
```suggestion - Opaque blob of data which is made available to the EC2 instance. ```
Maybe add an empty line above this one and give it a name, it seems like the `assert` task is just a parameter of the `openssl_certificate_info` one.
Please put the new parameters on a new line
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
The result of this: `- apt: clean=yes package=whatever state=installed` would be that 'whatever' is ignored and user gets told 'all ok and changed', this is misleading. while 'upgrade' goes through many hoops to ensure compatibility with others states/info (too many IMHO, i would simplify this a lot)
Please remove this example, since I would consider this usage as not recommended.
Please add one more space indent to match the indent above
Please add one more space indent to match the indent above
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
can be removed, the call to 'supper' below already takes care of this
This change is unrelated and breaks updating.
I wonder if the output can be simplified to avoid repeating `unset` and `export`.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion module.fail_json(msg=to_native(e.details)) ```
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
result is attempted to be used below
I'd rather see this part for all extractor errors.
You don't need to specify this field if there is no return output
both are valid tests, i don't see why you need to eliminate the existing one
No need for this line
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
Is this try/except necessary? It's a test
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
Format your docstrings like other docstrings in the codebase
You don't need to specify this field if there is no return output
You don't need to specify this field if there is no return output
Just an empty line, could be removed for cleaner code
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
What's the point of this? `set-cookie` headers are handled internally.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
`return not owner or owner == publication_info['owner']` could be used.
This doc should be updated.
I guess there's no need to download the key to the dist and read it from the disk. Just `urlopen` should be fine.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I think we should just let this exception propagate. We aren't adding any value by catching it here (and might be removing value if the traceback were useful). This isn't code in ansible itself so we don't have to create a nicer error message either.
Just making a note that we should probably restrict this to the exceptions that will likely occur and call fail_json instead of raising an Exception again.
Just making a note that we should probably restrict this to the exceptions that will likely occur and call fail_json instead of raising an Exception again.
This line is superfluous, the youtube-dl core can guess the extension better than that already.
Isn't `raise` missing there ? Calls to `str` are useless.
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
That's required. `0o600` works starting python 2.6. If authorized_key still wants to support 2.4 (not sure when this will die) one can do `int('600', 8)`, but that's probably not more readable than your suggestion.
Same here. Don't do that!
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Looks like you have an unnecessarily nested if block. You should deindent everything you've changed, change the first if to an elif and remove the else above it.
1. Explicit `encoding` may be added to `_parse_json` and forwarded there from `_download_json`. With this one will be able to specify encoding manually, `utf-8-sig` in this case. 2. BOM may be dropped in `_parse_json` leaving webpage intact.
Usually we don't use the URL as `video_id`. If `video_id` is unknown yet, it's OK to use part of the URL, for example "a-housecat-a-stray-god-and-a-tail".
In general argument_specs should be returned to the caller rather than subclassing AnsibleModule just to add it. AnsibleModule's behaviour could change in the future and subclassing makes it more likely that things would break than if you are simply passing an arg_spec to the module which it then uses to instantiate an AnsibleModule.
In general argument_specs should be returned to the caller rather than subclassing AnsibleModule just to add it. AnsibleModule's behaviour could change in the future and subclassing makes it more likely that things would break than if you are simply passing an arg_spec to the module which it then uses to instantiate an AnsibleModule.
no, if the variable is set but empty, you should empty out the options
The playlists are public: there should be tests for them. Watch this space.
```suggestion self.queue_message('vvv', "ESTABLISH GRPC CONNECTION FOR USER: %s on PORT %s TO %s" % (self.get_option('remote_user'), port, host)) self._channel = implementations.Channel(channel) ``` This to be consistent with other connection plugins (netconf, paramiko_ssh, etc.)
no, if the variable is set but empty, you should empty out the options
In general argument_specs should be returned to the caller rather than subclassing AnsibleModule just to add it. AnsibleModule's behaviour could change in the future and subclassing makes it more likely that things would break than if you are simply passing an arg_spec to the module which it then uses to instantiate an AnsibleModule.
This is unnecessary, AnsibleAWSModule automatically merges the argument_spec that you pass with ec2_argument_spec().
This is unnecessary, AnsibleAWSModule automatically merges the argument_spec that you pass with ec2_argument_spec().
Break the line after the `(` to unify the style across the file.
In other modules that support `authorize` we have some code here to check we are in the right context (privileged shell vs non-privileged). If you were to test the code with a task that requires privileged then one that requires non-privileged then I believe the current code would fail. `ios` supports `authorize` as well: https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/action/ios.py#L72-L86
In general argument_specs should be returned to the caller rather than subclassing AnsibleModule just to add it. AnsibleModule's behaviour could change in the future and subclassing makes it more likely that things would break than if you are simply passing an arg_spec to the module which it then uses to instantiate an AnsibleModule.
no, if the variable is set but empty, you should empty out the options
so this assertion looks incorrect, i would expect and empty string as the ssh args
This is unnecessary, AnsibleAWSModule automatically merges the argument_spec that you pass with ec2_argument_spec().
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
This is unnecessary, AnsibleAWSModule automatically merges the argument_spec that you pass with ec2_argument_spec().
Procedure for what? Once description changes test will fail regardless of whether it's an md5 or complete description.
Procedure for what? Once description changes test will fail regardless of whether it's an md5 or complete description.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
This one will fail with the new to_unicode. With no arguments, this will return `"None"``(the equivalent of``str(none)`` ). If we want the test to return None, then update like this: ``` python none = ansible.utils.unicode.to_unicode(None, nonstring=passthru) ```
This has to be ``` .addPathPartAsIs("Strings", "hard", "coded") .addPathPart(indexUpgradeRequest.index()) ``` for sanitization
This should not be fatal.
Actually, it's an opposite. It's a check for successful login.
There should be fallbacks for these values since they are more or less static.
This should not be fatal.
Don't lookup `lang_code` twice.
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
`**{'Bucket': bucket}` is equivalent to `Bucket=bucket`. Please use the latter :)
Maybe this should read: > Perform leader election for the partition of the topic passed in as argument and waits until leadership changes replica.
self.zone += '.'
You can just use 'playlist_count'
Traceback please ð
Same here - please include a traceback.
facts modules can trivially support check mode (#23107)
`expected_status` to `_download_json` instead.
also change this to 0.6.2, just came to my attention that I made an error in the release process and the 0.6.1 release didn't update the openshift.__version__. 0.6.2 is identical to 0.6.1 except with the version properly set. Sorry for the inconvenience
This method can be simplified to: ``` return [{"ParameterName": str(k), "ParameterValue": str(v)} for (k,v) in params.items] ```
Prefer importing `layers` then using e.g. `layers.Conv2D`
I think we should just let this exception propagate. We aren't adding any value by catching it here (and might be removing value if the traceback were useful). This isn't code in ansible itself so we don't have to create a nicer error message either.
This is performing a job match against the artifact name. In order to filter artifacts based on jobs you need to use the timeline results and match the artifact `source` against the timeline `id` for a given job.
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
I would like to move this conditional check at the very beginning of the method, before the client_kwargs defined.
I would like to move this conditional check at the very beginning of the method, before the client_kwargs defined.
(Additional whitespaceânumber of spaces not multiple of 4.)
This methods is only used when subtitles' extraction depends on additional expensive work, i.e. network I/O. In this case subtitles are already extracted along with formats and using this method does not make any sense.
`and not info_dict.get('requested_formats')` part should be removed here since it blocks ffmpeg from choosing as downloader via `--external-downloader` when single video/audio media file is requested.
``` r'itemprop\s*=\s*\"ratingValue\"\s*> ``` ``` r'itemprop\s*=\s*\"ratingValue\"[^>]*> ``` So that the code can live even if new attributes are added to this element Also, there's no need to escape double quotes in strings encapulated by single quotes.
If you check for the folder path here [compile_folder_path_for_obj] (before breaking) you could return the result and ignore all the other strategies.
```suggestion # just get value from attribute itself as normal ```
I think this should be 'exit' instead of 'abort'
`images` is not guaranteed to be a list.
use single quotes consistently, check for the availability of value before using them(`season_id` and `video_id`). `/title` part is not needed, can be simplified into(after checking for the values): ```suggestion video_url = '/'.join([url, season_id, video_id]) ```
Remove excessive verbosity. This fits well on a single line.
`images` is not guaranteed to be a list.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
`and not info_dict.get('requested_formats')` part should be removed here since it blocks ffmpeg from choosing as downloader via `--external-downloader` when single video/audio media file is requested.
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
no, as i said you would extract the metadata and return immediately.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
no, as i said you would extract the metadata and return immediately.
OK. I'll open an issue for discussing this. For now you can remove this line.
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
You could collapse these lines w/o having to create a variable for it.
a leftover here which can be removed
Can we print entire error rpc. In case of error `message` alone is not very helpful.
a leftover here which can be removed
Indeed, `extract_name` needs to be called only once per host. In order to do that add a parameter to `add_host_to_groups` method: ``` self.add_host_to_groups(host, name) ``` ``` def add_host_to_groups(self, host, name): ... ```
No direct URLs in tests.
User should be able to delete key. Keys with `None` value could be deleted.
User should be able to delete key. Keys with `None` value could be deleted.
Use `self._search_regex` and `utils.unified_strdate` instead.
Move into `_download_json`.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
Please enable the test for all the backends.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Request wrapping code can be moved to the base class.
New unit tests should be written to use pytest instead of unittest.
Replace all `f''` expressions: * where possible as below * for an expression where the braced expressions aren't just local variables, replace each `{expr}` by `{n}` with n starting at 0 and incrementing, and append `.format(expr0, expr1, ...)` to the string literal, or rewrite using `%` formatting * if the braced expressions are all local variables, you can just add `.format(locals())` (possibly distasteful) * for format literals used to add or change URL query parameters, consider using `update_url_query()` instead. ```suggestion msg = 'Panopto said: ' + response.get('ErrorMessage') ```
ok, just something for consideration, I trust your/the community's judgement on it
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
small typo ```suggestion # table availability in check_src/dst. ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Well, basically that's the problem of these people not us. We don't care whether one can read regexp or not. Moreover most likely next time this code is read by someone is when extractor breaks due to layout change. Chances are this snippet is already irrelevant by that time.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
If either of these attrs is missing whole playlist extraction is broken.
If either of these attrs is missing whole playlist extraction is broken.
Must be separate extractor.
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Might be worth validating that zones is a list rather than a single zone provided as a string.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
These examples are confusing. dim ordering should be referred to as "th dim ordering / tf dim ordering". Please pick one of them and have the entire example use the same convention. You may then follow up with the same example in the alternative dim ordering.
1. Explicit `encoding` may be added to `_parse_json` and forwarded there from `_download_json`. With this one will be able to specify encoding manually, `utf-8-sig` in this case. 2. BOM may be dropped in `_parse_json` leaving webpage intact.
1. Explicit `encoding` may be added to `_parse_json` and forwarded there from `_download_json`. With this one will be able to specify encoding manually, `utf-8-sig` in this case. 2. BOM may be dropped in `_parse_json` leaving webpage intact.
Similarly, ```if tc['skip'].get('i')```
Similarly, ```if tc['skip'].get('i')```
This should not be here as done by downloader.
Similarly, ```if tc['skip'].get('i')```
we might need both unless file_name is always absolute
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
If we use `self.api_client` then this API will look like - ```suggestion self.datacenter_id = self.get_datacenter_by_name(datacenter_name=self.datacenter) ```
If it's not found you will try extracting from 404 page. Remove all this 404 mess.
The regexp can be problematic when the json payload contains ";", for example the anime title can be "Dat Girl;ï¼". In this case the matched result is not a valid json string.
You don't need start with this code as it will be virtually the same for all the things launched by apply_async in your loop. You can just use a single scalar local variable to hold the value. (It also is the end time or max time (and maxtime is really max_timeout), not start). Adding that together with the note that we should probably process statvfs information separate from the uuid info: ``` python results[mount] = {'info': mount_info, 'statvfs': pool.apply_async(get_mount_size, (mount_info['mount'],)), 'uuid': uuids.get(mount_info['device']) or pool.apply_async(self._udevadm_uuid, (mount_info['device'],)),} max_time = time.time() + max_timeout ```
The regexp can be problematic when the json payload contains ";", for example the anime title can be "Dat Girl;ï¼". In this case the matched result is not a valid json string.
Yeah, a list is fine.
`del` is a builtin, not a function. These parens don't have to be here
Please remove this example, since I would consider this usage as not recommended.
If VMM domain, add support for "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
If VMM domain, add support for "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
Please do not make this a list, it should be singular. We have other modules and plugins that have similar functionality and they are singular. We should try to maintain consistency. The default should only by `utf-8` and the user must be responsible for explicitly setting it to a singular value.
Note that format strings changed in python-2.7 So things like "{} {}".format() needs to change to "{0} {1}".format() for python-2.6 compatibility.
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
should match urls with query, fragment, etc...(https://www.vvvvid.it/show/156/psycho-pass?foo=bar, https://www.vvvvid.it/show/156/psycho-pass/, ...).
```suggestion datastore_id = self.pyv.find_datastore_by_name(datastore_name=self.datastore_name) if not datastore_id: self.module.fail_json(msg="Failed to find the datastore %s" % self.datastore_name) ```
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
> Well, as I state in PR description, version in trunk practically disables ec2.py cache when using python 3. The idea was to replaces `hash()` call with any hashing function that gives stable results between script runs. Anything from hashlib module will do, `md5` does not have any advantage. One important note: `md5` will not be available on some systems (such as FIPS compliant systems). It's probably better to use `sha256` (as `sha1` could also be removed). > hashlib functions require byte string as input. Python 2 and 3 differ in what is stored in `__file__` variable: python 2 has simple string and in python 3 all strings are unicode. You could do ```.py from ansible.module_utils._text import to_bytes ``` and then ```.py cache_name += '-' + hashlib.sha256(to_bytes(__file__)).hexdigest()[:6] ``` This will work for both Python 2 and Python 3.
Please remove this example, since I would consider this usage as not recommended.
We should disable pylint's check for this one line rather than doing this. doing this defeats part of the purpose of having a compatibility library.
I don't mind the current structure. I'd even be ok with setting `HAS_DNF = True` outside the `try` `except`. `Â¯\_(ã)_/Â¯`
At first I thought this might be overkill, but all hosts need to rebuild their groups vars to remove this host from them. Making note in case someone else goes down same road.
You don't need dedicated function for that - you already have it `compat_urllib_parse_unquote`.
Use markdown format for links
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Use fail_json_aws for AWS exceptions as the messages contain a lot more info
Newline before this line
No. You should not shadow the original explicitly provided password.
Please remove this example, since I would consider this usage as not recommended.
This should not be moved. They're libraries from the current project so go below the imports for stdlib and third party libraries.
```suggestion - name: Install python package using a proxy # Pip doesn't use the standard environment variables, please use the CAPITALIZED ones below ```
Also, things like int(True) == 1 and int(False) == 0, in python3 int(b'characters'[0]) == 99....
```suggestion Test that the returned value for timezone consists of only uppercase ```
@samdoran then, I'd say that there's something wrong with the setup and TZ should be adjusted somewhere.
no, if the variable is set but empty, you should empty out the options
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
When running as `youtube-dl.exe` build with python 2 from path containing non-ASCII `find_file_in_root` ends up returning `None`. When `localedir=None` is passed to `gettext.translation` it picks up `_default_localedir` constructed using `os.path.join` with mixture of byte strings and unicode strings that results in similar problem: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "gettext.pyo", line 468, in translation File "gettext.pyo", line 451, in find File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` We can workaround be skipping it completely when we found no locale dir: ``` python locale_dir = find_file_in_root('share/locale/') if locale_dir: try: ... ``` Or we can mimic what `gettext` do by appending extra path in `get_root_dirs`: ``` python ret.append(os.path.join(decodeFilename(sys.prefix), 'share', 'locale')) ```
Combining could be moved to a postprocessor and exposed as a new generic cli option (I would prefer it to be in different PR if any).
This probably won't help with your actual problem, but the following PR was very helpful when I needed to fix feed dict issues: https://github.com/fchollet/keras/pull/7064
What's the point combining original and translated lyrics to a single file? There should be 2 separated entries in `subtitles` instead.
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
```suggestion message_text = self.get_deprecation_message(msg, version=version, removed=removed, date=date, collection_name=collection_name, warn_change=warn_change) ```
I think you should only do this whole `if` if `mode == 'persist_only'`.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
this is a catchall, we normally frown on those. also note that for all of your `% e` they should be `% to_native(e)` to ensure proper character conversions
i don't think we want roles in roles
i don't think we want roles in roles
i don't think we want roles in roles
In Python 3.x `bytearray` accepts only bytes-like objects, and strings are not.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Don't need to import HAS_BOTO3 now.
It Python, you should use a proper camel case for classes: ```suggestion class TestJsonEncodeFallback: ```
maybe just start a unicast cluster for now
Lists also have .extend() which might be what you need here
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
Should be `fatal=False`. Use `utils.int_or_none`. It must be in seconds.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Could you clarify what's happening by adding an example 2-line CSV file? I think that would improve the docs.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
self.act_fn => self.activation (unless self.activation is reserved already)
Could you clarify what's happening by adding an example 2-line CSV file? I think that would improve the docs.
Same. The `filter` doesn't make sense to me
Could you clarify what's happening by adding an example 2-line CSV file? I think that would improve the docs.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
self.act_fn => self.activation (unless self.activation is reserved already)
Same. The `filter` doesn't make sense to me
small typo ```suggestion # table availability in check_src/dst. ```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Lists also have .extend() which might be what you need here
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
Same. The `filter` doesn't make sense to me
```suggestion for key, value in self.parameters.plugin_options.items(): ```
```suggestion for key, value in self.parameters.plugin_options.items(): ```
shade isn't gonna be here anymore - see recent changes to the module utils. we have an sdk module returned now. That said - 2.6 and beyond have a hard requirement on openstacksdk - so we can probably skip this version check.
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
s/write target file {0}/put_file to {0}/
s/write target file {0}/put_file to {0}/
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
s/write target file {0}/put_file to {0}/
You should explicit the fact that vm_name is not a string, but a vmodl.â¦ object containing a propSet containing the VM name.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
Please remove this example, since I would consider this usage as not recommended.
`current_version` could be mentioned in the error message.
Style: space needed after comma.
Style: space needed after comma.
Style: space needed after comma.
Style: space needed after comma.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
You could extend this condition and avoid having to indent a bunch of code: ```suggestion display_path_warning = collection_path_warnings and len([p for p in collections_path if p.startswith(path)]) if display_path_warning: ```
This implies that constructing some callbacks doesn't result in an instance, but also doesn't raise an Exception? That doesn't sound right...
we should not be adding a python dependency on ordereddict here, as python2.7 can also use ordereddict from collections: https://docs.python.org/2/library/collections.html#collections.OrderedDict This also means, that python2.7 users now need an additional python dependency installed.
This could be moved inside the conditional that follows to avoid checking when there are no vendored modules.
same as others, return directly test
For public APIs we should be accepting text strings and internally convert to bytes where needed. If we really must accept bytes (which in this case I don't see a reason to) we should prefix the arg with `b_` to indicate that. The `b_` prefix may go away as we start to add type annotations but so far the behaviour is the standard we usually follow in ansible.
Tests shouldn't be invoked directly, so this isn't needed.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
Name an example URL where `og:description` has HTML tags.
No need to escape whitespace.
Do note that this does not take `self.principal` into account, neither is that being checked. So you might return with `changed=False` if there's a tgt for a totally different principal.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
No need to escape whitespace.
Do note that this does not take `self.principal` into account, neither is that being checked. So you might return with `changed=False` if there's a tgt for a totally different principal.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Instead of repeating the import try/except here, just add `cmd_quote` to the `from lib.util import` below.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
No need to parametrize with just one case.
Technically since we're doing this in a fixture, either `monkeypatch` should be used to insert these into `globals()`, or you should return `mod`, and then just use `mod.Template` and `mod.AnsibleNativeEnvironment` in your tests.
```suggestion # coding: utf-8 from __future__ import unicode_literals ```
to_text and u prefix on string.
Sure, a separate PR sounds good.
As we no longer care about 2.4, I think this can be cleaned
`expected_status` to `_download_json` instead.
`expected_status` to `_download_json` instead.
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
Use `self.url_result(inner_url, 'Generic')` instead.
`expected_status` to `_download_json` instead.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
`expected_status` to `_download_json` instead.
you can move it to before `if` as just `docs = {}` line, this should read better.
You can just use 'playlist_count'
`pzuid` does not look to be used anywhere.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
We could fall back to `__file__` or something in that case at minimum. Could be useful to include that regardless.
why i wanted a irc meeting on it, to get a consensus if we make this the norm for lookkups (it 1/2 is already, but not officially)
Forward slash does not need escaping.
I'd argue that it's less readable because line is too long now
`/`, `:`, `\`, `|`, `<`, `>`, `"`, `?` and `*` are already always stripped.
Please fix url to` 'https://api.telegram.org/bot' + token + '/sendMessage?text='` and examples descriptions to `token: '9999999:XXXXXXXXXXXXXXXXXXXXXXX'` Because BotFather return token without "bot" string
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
This is not used in single video extractor thus should not be here.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
This is not used in single video extractor thus should not be here.
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
Also, please don't use `\` to break up lines
The various `CALLBACK_` prefixed class attributes are missing. Take a look at the other callbacks for an example. In particular, this is needed: ``` python CALLBACK_NEEDS_WHITELIST = True ```
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
Is that error "the port is in use by something" or "port is already in the state you asked for"? If it's the former (as I suspect), it's arguably incorrect to silently succeed (as the port will not be in the requested state since it's a member of the wrong broadcast domain).
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
Sorry - dismiss that
```suggestion return super(cls, new_cls).__new__(new_cls, *args, **kwargs) ```
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
`data` must be `bytes` so you'll need to `encode` it.
Add `default=playlist_title` in order not to fail when `<title>` does not contain `- BBC`. Regex should match at least one characted and title should be greedy `r'(.+)\s*-\s*BBC'`.
In line with naming conventions in this API, this should be `_num_constants`.
Better to use `unified_strdate()`.
Sarmonise with yt-dlp pt7: ```suggestion # Stripchat declares the RTA meta-tag, but in an non-standard format so _rta_search() can't be used 'age_limit': 18, } ```
I feel like it would actually be clearer and more economical to separate the two cases entirely: one input vs. multiple inputs.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Returning would close the file (I think) since you're already in a 'with' statement.
```suggestion query=dict(type='list', elements='str'), ```
This can be changed to look for only one space now that #57209 is merged. Thanks again for writing tests. Much appreciated.
Just a note that if you are in an environment where all strings should be text strings (controller-only code), there are several better ways to do this: ``` python # If you can require Python-3 only table = str.maketrans('', '', string.punctuation) table[ord(' ')] = None default_name = self.params['name'].translate(table) # If you can require Python-2.7+ table = {ord(c): None for c in string.punctuation} table[ord(' ')] = None default_name = self.params['name'].translate(table) # otherwise: from ansible.module_utils.six.moves import zip_longest table = dict(zip_longest((ord(c) for c in string.punctuation), None)) table[ord(' ')] = None default_name = self.params['name'].translate(table) ``` Just something to keep in your toolbox for the day when you'll eventually be able to use it :-)
Sorry, hadn't seen this else here, and it's fine to have it like now.
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
Group names are supposed to be named similar to variables, i.e. alphanumeric and underscore. So at least the prefix should adhere to that. Besides that, look at this PR: https://github.com/ansible/ansible/pull/52748
Braces in non inline dicts **should** be carried. Parentheses != braces.
There could be a check in here to prevent both label and label_id from being specified if state is absent.
Actually, we had some discussions about group names the previous days on IRC. Apparently dashes have been not allowed in group names from Ansible 2.4 on; this hasn't been enforced so far, but now (with Ansible 2.8) it will be. It's still possible to disallow it, but every group with a dash (or other invalid chars) in them will trigger a big fat warning. So please get rid of the dashes here so users of this inventory plugin won't automatically get a list of warnings, even if they don't have invalid chars in their labels.
instead of: ```python tracks = data['tracks'] for track_type in tracks: for video in tracks[track_type]: ``` you can just do something like: ```python for tracks in data.get('tracks', {}).values(): for video in tracks: ```
Remove leading space
Seems like a bug? `self.datacenter` doesn't exist ```suggestion datastore_name, datacenter=self._datacenter) ```
This code block is redundant with the logic of `save_weights_to_hdf5_group`. I would recommend extracting an abstract function that can be reused in both locations.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
I wonder if the output can be simplified to avoid repeating `unset` and `export`.
How about selecting a semantically better exception? ```suggestion raise LookupError( 'File "{target_path!s}" not found in collection path "{coll_path!s}".'. format(target_path=path, coll_path=ANSIBLE_COLLECTIONS_PATH), ) ``` P.S. `str()` is unnecessary since the specifier does that already.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
For `persist_only`, this behavior is wrong: you can only do this if `value_wanted == value_in_auto_cnf` in that case.
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
I'm also learning this as I go :smile:
makedirs_safe already does this, just use that function
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
terms can be a list, not sure if this is being handled correctly
This is fatal.
I believe it's ```suggestion raise ImportError("We weren't able to import the module {0}".format(module_name)) ```
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
aws_ip_ranges -> aws_service_ip_ranges
so this assertion looks incorrect, i would expect and empty string as the ssh args
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
Can we detect if this is not a json and fallback to print it directly
Raise `AnsibleCallbackError`, which can be imported from `ansible.errors`.
i would prefer to not add more connection specific arguments
Can we detect if this is not a json and fallback to print it directly
I know, was just wondering if it's intended that it works that way.
You could replace this entire block with: ``` from distutils.version import StrictVersion return StrictVersion(host_version) >= StrictVersion('.'.join(map(str,version))) ```
```suggestion # require that the final recorded stack state was DELETE_COMPLETE ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
cropping, not padding
cropping, not padding
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```suggestion module.fail_json(msg="Cannot dump database(s) %r - not found" % (', '.join(non_existence_list))) ```
Same suggestion as above. .get() doesn't have to return a Nonetype so you can use it for "port" too.
Same suggestion as above. .get() doesn't have to return a Nonetype so you can use it for "port" too.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Same suggestion as above. .get() doesn't have to return a Nonetype so you can use it for "port" too.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
I think if the currentName is null we have a bigger problem. why do we do the comparison even? have you tried passing in fieldName set to <null> ? if the current token is a field name, currentName should not be null ever. I would treat that corner case differently.
Declaring a method with a pointer-ish type (like list) as the default can result in some unexpected behavior. ``` >>> class Fooo(object): ... def bar(self, fizz=[]): ... print(self, fizz) ... fizz.append('a') >>> f = Fooo() >>> f.bar() (<Fooo object at 0x7f5a61543290>, []) >>> f.bar() (<Fooo object at 0x7f5a61543290>, ['a']) >>> f.bar() (<Fooo object at 0x7f5a61543290>, ['a', 'a']) ``` Instead, we can use `None` as the default and then check `if added_exceptions is not None:` to decide whether to extend the default exception list or not.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
This should not be fatal.
small typo ```suggestion # table availability in check_src/dst. ```
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
Just an empty line, could be removed for cleaner code
No, this should always be entered if `input_shape[0]`.
Any way to block/poll for completion on this? Otherwise this is a built-in race condition for anyone that wants to do anything with a renamed infinite volume from Ansible...
Yeah, a list is fine.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
we want want -> we want
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
@nitzmahone and I talked about this last night and the timeout is an expectation of how long fact gathering as a whole will take, not how long any specific piece of fact gathering will take. We thought that probably the best place to enforce that sort of fact gathering would be in the action plugin being worked on in a separate PR. However, for this PR, it would make more sense to at least try to replicate the status quo as much as possible, ie: take a time at the start of this function. Then every time we check the time to see if it's time to exit due to timeout, we compare time.time() > function_start_time + timeout to see if it's time to exit.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Same as in the doc
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
we want want -> we want
we want want -> we want
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
The docstring should state that `print_fn` defaults to `print` if unspecified.
Any way to block/poll for completion on this? Otherwise this is a built-in race condition for anyone that wants to do anything with a renamed infinite volume from Ansible...
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
If you use `to_text(xxx, errors='surrogate_or_strict')` it won't throw exceptions.
```suggestion # just get value from attribute itself as normal ```
Oh, I see. `run_commands()` runs list of commands and returns list of results.
we want want -> we want
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
No, this should always be entered if `input_shape[0]`.
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
And the same here
It should not match `h|`.
It seems there is four spaces missing (unrelated to your changes).
It's more readable to write this out into multiple if-then statements.
It seems like I'm being overly cautious. I've checked with @pradyunsg and he confirmed that pip isn't calling `sdist` command and it suppresses output anyway so users wouldn't see it unless in case of failure...
no, if the variable is set but empty, you should empty out the options
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
I would separate the try-except-else blocks to improve readability of the tests.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
so this assertion looks incorrect, i would expect and empty string as the ssh args
Line is too long.
no need to call compat_str if it's already as `string` and `title` field should be extracted before formats.
The way this is done is going to lead to unicode errors eventually. This is probably the least messy way to handle that: ``` python msg = u"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s" % (name, type(e), to_text(e)) if errors == 'warn': display.warning(msg) elif errors == 'ignore': display.log(msg) else: raise AnsibleError(to_native(msg)) ```
This looks odd - shouldn't each parameter be separated by a `,` and have its own `'` around it? I can't test this, but I would guess it should be: ```suggestion msg: "{{ lookup('consul_kv', 'my/key', host='10.10.10.10', token='a20f2009-a1cf-4e19-8286-0632ea3bcad6', recurse='yes', port='2000') }}" ```
All methods only used once should be explicitly inlined.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This looks odd - shouldn't each parameter be separated by a `,` and have its own `'` around it? I can't test this, but I would guess it should be: ```suggestion msg: "{{ lookup('consul_kv', 'my/key', host='10.10.10.10', token='a20f2009-a1cf-4e19-8286-0632ea3bcad6', recurse='yes', port='2000') }}" ```
Since you're not modifying the data, you can just do: ``` for key in resource: ``` here.
These should be `vid_info.get('short_description')` for the individual video descriptions, this is currently adding the playlist description to every video.
What's the point of this complication? Each clip has `show-clip` value for class attribute for `a`. Replace with single playlist extractor based on this approach.
Fix test: ```suggestion 'ext': 'mp4', ```
ignore_errors doesn't normally cover unreachable
hd should be always tried to be extracted whether it's present or not. There is no need in this flag.
No need to parametrize with just one case.
```suggestion r'''widgetId:\s+["'](\w+)''', rf_token_js, 'widgetId') ```
```suggestion # just get value from attribute itself as normal ```
Use _request_webpage instead of plain urlopen. The former includes fixes and custom features missing from urllib.request
```suggestion r'''widgetId:\s+["'](\w+)''', rf_token_js, 'widgetId') ```
Having a class for just one test method is unnecessary.
Having a class for just one test method is unnecessary.
`autonumber` is not reset to zero in the first place.
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
Having a class for just one test method is unnecessary.
It's seems that this statement is useless ```diff - existing_variables = this_gitlab.list_all_project_variables() ```
fatal=True is default.
#11205 already adds the `tile` op. So I don't think it's necessary to add it in this PR.
It would be useful to tell the user which `key` is invalid.
Please consider the same for `manifest_url`. See my explanation in #30703.
Prefer consistent using of single quotes when possible.
Technically since we're doing this in a fixture, either `monkeypatch` should be used to insert these into `globals()`, or you should return `mod`, and then just use `mod.Template` and `mod.AnsibleNativeEnvironment` in your tests.
This should use the proper LDAP attribute name for DN ```suggestion - This value is either the C(distinguishedName) or C(objectGUID) or the AD object to lookup. ```
If `Migrations()` doesn't have unwanted side-effects (like changing something), you should add `if module.check_mode:` after this. You could for example do it as follows: ```.py if module.check_mode: has_migrations, skip_reason = True, None else: has_migrations, skip_reason = migrations.has_migs(module.params['local_only']) ``` Then continue as before with `if not has_migrations: ...`. (I'm assuming that `True, None` is the more common return value which is to be expected.)
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
Probably the same with `--label` instead of `--uuid` here.
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
Unnecessary blank lines here, removing these blank lines is preferable.
I guess this function is too long to be a nested function.
Make this: ```python result = set_vm_power_state(pyv.content, vm, module.params['state'], module.params['force']) ``` Remove the stuff below.
```suggestion "on the root node: %s" % to_native(admin_permission) ```
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
This is not relevant to Keras (which does not accept tf.data.Dataset instances as inputs)
```suggestion "on the root node: %s" % to_native(admin_permission) ```
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('Europe/Helsinki')), '2019-06-15T14:45:00+01:40'), ```
```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('Europe/Helsinki')), '2019-06-15T14:45:00+01:40'), ```
```suggestion file_name, file_exts = os.path.splitext(str(url.rsplit('/', 1)[1])) # Preserving double filename extensions like .tar.gz _, double_ext = os.path.splitext(file_name) if double_ext: file_exts = double_ext + file_exts: ```
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
Would this ever return false under normal circumstances? Seems like we'd lose items if it did...
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
``` "Unable to get hooks from repository %s: %s" % to_native(err) ``` to ``` Unable to get hooks from repository :%s" % to_native(err) ```
You have the 'check_client' function to figure out if the requirements are present, but never actually use it, so the module fails on in import exception. I recommend you place a call in the class init so you dont have to remember to call it in every module.
Move data and query into `_download_webpage` call.
Move data and query into `_download_webpage` call.
Similarly, ```if tc['skip'].get('i')```
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
This needs to be a failure, the `OrderedDict` object is used. Maybe just do a straight import with the try / except ``` python try: from collections import OrderedDict except ImportError: from ordereddict import OrderedDict ```
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
You have underindented here with just a tab instead of two. We uses spaces.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Move data and query into `_download_webpage` call.
You have the 'check_client' function to figure out if the requirements are present, but never actually use it, so the module fails on in import exception. I recommend you place a call in the class init so you dont have to remember to call it in every module.
I'd put `(self._flags['become_success'] or chan.exit_status_ready())` into a `@property` for readability so that it'd look like ```suggestion while not self._cmd_finished: ```
It would be awesome if buildah supported copying from a container.
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
Ideally it's best if we can avoid `sleep` calls Is there a reason why you can't use `stop_node` without sleeping? This should block until the process is gone and the background thread has finished processing output from the consumer
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Update this docstring.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
I think this should be more distinct: ```suggestion except ImportError: HAS_DNF = False else: HAS_DNF = True ```
121, 124 - DRY.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Recursion should be replaced with plain loop.
we use getpass.getuser() in many places, we might want to make this a generic function in module_utils and replace the current instances of it, instead of fixing just this one
```suggestion query=dict(type='list', elements='str'), ```
```suggestion query=dict(type='list', elements='str'), ```
Please remove this, `AnsibleModule` already prevents this.
avconv does not support `-cookies`, use `-headers` instead. You should also pass all headers.
Array ellipsis is an obscure feature and not necessary here. It hinders readability
Please put the docstring description on the first line
Okay, I'll take a look.
You have an extra `,` before the URL
Should this have some exception handling? (I suggest here rather than paginated_list as paginated_list might not be able to handle exceptions if it does the retry)
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
Simplify error reporting as below, or skip this check and just let the `_html_search_regex()` calls raise the exception? ```suggestion for token in ('apiToken', 'widgetId'): if token not in rf_token_js: raise ExtractorError( 'Unable to fetch ' + token, expected=True) ```
`if not check_rc` is not required. It can go in else part
Don't use this pattern. No try/except block here.
Sometimes you have a trailing dot (here), sometimes not (previous one). I guess you should pick one style and stick to it :)
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
I feel like this should be moved to `else:`
It would be awesome if buildah supported copying from a container.
It would be awesome if buildah supported copying from a container.
Change `should` to `would`.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
Could make this into a generated testcase if you were so inclined.
Per bcoca: please switch this over to `to_native()` instead of `str`
``` def __init__(self, module): super(VmwareConfigFactsManager, self).__init__(module) cluster_name = self.params.get('cluster_name', None) esxi_hostname = self.params.get('esxi_hostname', None) if cluster_name: cluster_obj = self.find_cluster_by_name(cluster_name=cluster_name) if cluster_obj: self.hosts = [host for host in cluster_obj.host] else: module.fail_json(changed=False, msg="Cluster '%s' not found"%cluster_name) elif esxi_hostname: esxi_host_obj = self.find_hostsystem_by_name(host_name=esxi_hostname) if esxi_host_obj: self.hosts = [ esxi_host_obj ] else: module.fail_json(changed=False, msg="ESXi '%s' not found"%esxi_hostname) ``` @Akasurde What do you think ? No variable except `hosts` has to be attributes. The module should fail if the cluster or ESXi isn't found.
``` def __init__(self, module): super(VmwareConfigFactsManager, self).__init__(module) cluster_name = self.params.get('cluster_name', None) esxi_hostname = self.params.get('esxi_hostname', None) if cluster_name: cluster_obj = self.find_cluster_by_name(cluster_name=cluster_name) if cluster_obj: self.hosts = [host for host in cluster_obj.host] else: module.fail_json(changed=False, msg="Cluster '%s' not found"%cluster_name) elif esxi_hostname: esxi_host_obj = self.find_hostsystem_by_name(host_name=esxi_hostname) if esxi_host_obj: self.hosts = [ esxi_host_obj ] else: module.fail_json(changed=False, msg="ESXi '%s' not found"%esxi_hostname) ``` @Akasurde What do you think ? No variable except `hosts` has to be attributes. The module should fail if the cluster or ESXi isn't found.
``` def __init__(self, module): super(VmwareConfigFactsManager, self).__init__(module) cluster_name = self.params.get('cluster_name', None) esxi_hostname = self.params.get('esxi_hostname', None) if cluster_name: cluster_obj = self.find_cluster_by_name(cluster_name=cluster_name) if cluster_obj: self.hosts = [host for host in cluster_obj.host] else: module.fail_json(changed=False, msg="Cluster '%s' not found"%cluster_name) elif esxi_hostname: esxi_host_obj = self.find_hostsystem_by_name(host_name=esxi_hostname) if esxi_host_obj: self.hosts = [ esxi_host_obj ] else: module.fail_json(changed=False, msg="ESXi '%s' not found"%esxi_hostname) ``` @Akasurde What do you think ? No variable except `hosts` has to be attributes. The module should fail if the cluster or ESXi isn't found.
Well, this is also very boilerplate, which you could deduplicate.
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
terms can be a list, not sure if this is being handled correctly
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
Since this isn't implemented, perhaps lets not mention it? I found it confusing
so this assertion looks incorrect, i would expect and empty string as the ssh args
Please fix docstring typos
1. Do not remove the old pattern. 2. Relax regex.
This could simple read "converted"
fixture with load_json
~~don't you still need the else? won't this fail when using stdin/stdout?~~ nvmd, missed the 'return'
@wwitzel3 started this pattern. Check mode for tower modules doesn't do anything action-specific. We should track this in another issue.
I wouldn't exactly call a dictionary `list`.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
I did this so I can deprecate `--get-url` (along with all other --get options). Unless you want to do that too, `urls` field isn't really needed
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
`no_log=True` is argument spec will handle this.
`pzuid` does not look to be used anywhere.
This is missing a `cwd=` spec at the latest. If we need a git revision number, we should really think about releasing more often instead.
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
Check for `compat_str` also.
Must return info dict.
We could fall back to `__file__` or something in that case at minimum. Could be useful to include that regardless.
```suggestion if type is not None: ```
Probably the same with `--label` instead of `--uuid` here.
```suggestion options.extend(['--label', label]) type = 'luks2' ```
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
It should always return a list.
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
This can instead be `continue` and let the `else` unnest.
This can instead be `continue` and let the `else` unnest.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
Prefer consistent using of single quotes when possible.
Please use lowercase variable names.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
```suggestion module.fail_json(msg="Cannot dump database(s) %r - not found" % (', '.join(non_existence_list))) ```
```suggestion module.fail_json(msg="Cannot dump database(s) %r - not found" % (', '.join(non_existence_list))) ```
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Rather than a try/except you could do: `old_port = self.data.get("endpoint", {}).get("port")`
`del` is a builtin, not a function. These parens don't have to be here
This introduces a different race condition, file can now be looked at in 'intermediate' state.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
To use Constructable options you can add something like ``` self._set_composite_vars(self.get_option('compose'), item, hostname) self._add_host_to_composed_groups(self.get_option('groups'), item, hostname) self._add_host_to_keyed_groups(self.get_option('keyed_groups'), item, hostname) ``` to this method.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
Move this to line 175
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
This snippet looks just like one in `role_find`. It probably deserves being moved into a reusable function.
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
This will fail when there is no vlanId or vswitch in portgroup. I don't remember the exact reason, but I encountered error here sometimes in past.
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
This condition is not needed, t is always None here.
`not source_url` implies `source_url == ''`.
The `root_uri` may include a port number (e.g. 192.168.1:8000). Should probably split that off also.
Not catching non-200 responses.
Exact error should be stored here, since debugging any potential issues in the future will be next to impossible without having the error. Something like `"Unknown error: %s" % str(e)` should be enough.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
to_text and u prefix on string.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
The query should be something like ``` G.V().Has('TID', 'bd7f5334-115c-5943-487d-a77c486fa854') ``` according to the `name`
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
It seems like no_log and deprecation are separate things and should be handled in separate functions.
to_text and u prefix on string.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
It seems like no_log and deprecation are separate things and should be handled in separate functions.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
This should be `b_output_path` to indicate it is a series of bytes. Even if the caller is sending in bytes, this function should convert it to bytes just like `b_collection_path` at the beginning. That allows our `b_` naming convention to hold, making this code look incorrect (trying to join `bytes` and `str`).
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
You seem to have gone through the process of making this class a context manager, but don't use it as a context manager.
small typo ```suggestion # table availability in check_src/dst. ```
Could be: ```python json.dump(host, sys.stdout, indent=2) ```
parent name also needs to be 'safe'
Currently, you just retry the same thing again if there's a `/` already. Maybe you should drop it? ```suggestion # Some archives contain directories that end with '/' if not dirname.endswith(os.path.sep): dirname += os.path.sep else: dirname = dirname[:-1] ```
You don't need to specify this field if there is no return output
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
Bother to read coding conventions on optional meta fields.
required is by-default is 'False', so no need to add explicitly.
we normally use display instead of print
please add a `version_added: "2.8"`
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
In line with naming conventions in this API, this should be `_num_constants`.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
This should succeed, since the goal state of `absent` has been met by the group not existing in the first place.
This should succeed, since the goal state of `absent` has been met by the group not existing in the first place.
This is not used in single video extractor thus should not be here.
This one will fail with the new to_unicode. With no arguments, this will return `"None"``(the equivalent of``str(none)`` ). If we want the test to return None, then update like this: ``` python none = ansible.utils.unicode.to_unicode(None, nonstring=passthru) ```
`(?P<id>[^/]+)` should not be mandatory, the information needed for extraction rely only on `show_id`(for API calls).
```suggestion info = self.playlist_result( OnDemandPagedList( functools.partial(self._fetch_page, base_url, query_params, display_id), self._PAGE_SIZE), playlist_id=display_id, playlist_title=display_id) if folder_id: info.update(self._extract_folder_metadata(base_url, folder_id)) ```
```suggestion info = self.playlist_result( OnDemandPagedList( functools.partial(self._fetch_page, base_url, query_params, display_id), self._PAGE_SIZE), playlist_id=display_id, playlist_title=display_id) if folder_id: info.update(self._extract_folder_metadata(base_url, folder_id)) ```
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
I missed that, then you should either use [itertools.islice](https://docs.python.org/2/library/itertools.html#itertools.islice) or ``` python for i, track in enumerate(tracks): if i >= n: break ```
Use `height` attribute is better here. `_sort_formats` can sort formats by heights.
1. This does not work [properly](https://github.com/rg3/youtube-dl/issues/14814). 2. This is ad hoc micro optimization exclusively for pluralsight for reducing number of requests and overall sleeping time while downloading. Remove.
You don't need to specify this field if there is no return output
You don't need to specify this field if there is no return output
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
Better to put the activation as the `activation` keyword of the layer below
Note for us: Before merging, switch this to the new #980 structure, i.e. `formats` entry consisting only of url+format+ext. All further listformats or selection business can be removed as well.
Move flags into regex.
Please remove this example, since I would consider this usage as not recommended.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
Use ... instead of â¦ here. Non-ascii outputs may break random things.
Just use `replace` or `re.sub`.
Just use `replace` or `re.sub`.
Just use `replace` or `re.sub`.
Just use `replace` or `re.sub`.
Move flags into regex.
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
Just use `replace` or `re.sub`.
Just use `replace` or `re.sub`.
this produces an exception when binary cannot be found, you should capture and return parser error
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
nit: it's not a regex and there's no escaped symbols so there's really no need to make use of raw-strings
Why not leverage .setdefault here ? ``` kwargs.setdefault('url', os.environ.get('OVIRT_URL')) kwargs.setdefault('username', os.environ.get('OVIRT_USERNAME')) kwargs.setdefault('password', os.environ.get('OVIRT_PASSWORD')) ``` ï¿¼
Also, why do you need to call `db_exists` again at all? You already have `existence_list` and `existence_list`, that should be enough for the rest of the module.
Also, why do you need to call `db_exists` again at all? You already have `existence_list` and `existence_list`, that should be enough for the rest of the module.
This can instead be `continue` and let the `else` unnest.
same here, we really dont want to test the particular setting, just that both the default (dynamic template) and the nii entry are correctly parsed.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
That's something we should fix in the Keras backend.
no need to specify required=False or type=str as these are defaults
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
no need to specify required=False or type=str as these are defaults
That's something we should fix in the Keras backend.
no need to specify required=False or type=str as these are defaults
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
```python if size_pct is not None ```
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Got it. But this is very confusing error message. anyways, not a blocker as such.
These 2 regexes ought to be merged, though maybe not in the scope of this PR: ``` r'(?:\b|[^a-zA-Z0-9$])(?P<sig>[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\)(?:;[a-zA-Z0-9$]{2}\.[a-zA-Z0-9$]{2}\(a,\d+\))?', ```
Suffer. In addition to that they can install python and run this themselves quite fine.
These 2 regexes ought to be merged, though maybe not in the scope of this PR: ``` r'(?:\b|[^a-zA-Z0-9$])(?P<sig>[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\)(?:;[a-zA-Z0-9$]{2}\.[a-zA-Z0-9$]{2}\(a,\d+\))?', ```
You are missing that it's a metadata provided by a 3dparty and there can by anything. So that you must ensure it's `int` before returning its value in info dict.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
``` python try: webpage = self._download_webpage(request, url) except ExtractorError as e: if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403: raise ExtractorError('%s is not available in your region.' % self.IE_NAME, expected=True) raise ```
``` python try: webpage = self._download_webpage(request, url) except ExtractorError as e: if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403: raise ExtractorError('%s is not available in your region.' % self.IE_NAME, expected=True) raise ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
tempted to say just use check_opts=True and remove syntax check afterward with remove_option (we do this in ansible-inventory).
```suggestion params = dict(timeout=timeout) if PY3: params['host'] = host params['port'] = port smtp = smtplib.SMTP_SSL(**params) code, smtpmessage = smtp.connect(host=host, port=port) ```
the `and retries >= CONFIRM_UPDATE_MAX_RETRY` is redundant here. If the execution got here, it'll always be `True`
Each example task should be a continuous block, please do not have blank lines between sections
Please detail the `yield` of the generator
Please detail the `yield` of the generator
+1 to stating this. I wonder if an example would be useful
Instead of equality, I think you want to check for `isinstance` here.
Instead of equality, I think you want to check for `isinstance` here.
Instead of equality, I think you want to check for `isinstance` here.
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
This discussion more or less took place in: https://github.com/keras-team/keras/pull/9200 https://github.com/keras-team/keras/issues/8657
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
+1 to stating this. I wonder if an example would be useful
Could you have a syntax close to : ``` if not re.match(): raise ... ``` That we don't have as much indentation levels.
Instead of equality, I think you want to check for `isinstance` here.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Instead of equality, I think you want to check for `isinstance` here.
Instead of equality, I think you want to check for `isinstance` here.
Instead of equality, I think you want to check for `isinstance` here.
Instead of equality, I think you want to check for `isinstance` here.
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
What if `connected` attribute is set to `false` ? It's ignored!
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
py3.x-only code; can safely ditch the args to `super()`
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
Instead of equality, I think you want to check for `isinstance` here.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I don't think this is useful in this example. Please remove.
This condition is not needed, t is always None here.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
Instead of equality, I think you want to check for `isinstance` here.
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
For rtmp it's always flv despite of the extension.
Please add our boilerplate to the top of this file. One of those pieces of boilerplate makes all classes defined in the file new-style classes. Without it, a class definition which doesn't inherit from object is an old-style class. ``` from __future__ import (absolute_import, division, print_function) __metaclass__ = type ```
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
Return is not compulsory but will help end user to understand return value of module.
@rajinisivaram Sorry should have caught this before -- instead of `time.sleep` here, using `wait_until` on the checks for errors below and then moving the assertion for `self.producer.num_acked == 0` to below those `wait_until`'s might make the test more robust. We'll still have a timeout on the `wait_until` calls, but it can be a lot more conservative and the test may be able to finish a lot faster.
No. As already said it's an implementation detail and may be changed any time. [This](https://github.com/ytdl-org/youtube-dl/blob/a6e6673e825f6225c3a316b164ddca03fd20b5d2/youtube_dl/YoutubeDL.py#L140-L321) and [this](https://github.com/ytdl-org/youtube-dl/blob/master/youtube_dl/extractor/common.py#L100-L325) are maintained. Embeddable metadata is not.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
Oh, we should `%s/conig/config/`
Don't assign a lambda function, use def
This snippet looks just like one in `role_find`. It probably deserves being moved into a reusable function.
Does this throw any exception? In the code you're removing it's inside `try:`.
suggestion: ```py subtitles = {} for sub in re.findall(r'\bsrc="/w/api\s*(.+?)\s*srt\b', webpage): ... subtitles.setdefault(lang, []).append(...) return { 'url': video_url, ... } ```
This change breaks MTVServicesEmbeddedIE
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
Request wrapping code can be moved to the base class.
This syntax is not supported on Python 2.6.
An equivalent to this would be `extra['Metadata'].update(metadata)`
nit: this doesn't need to be a field, you can just use a local variable
Just an empty line, could be removed for cleaner code
nit: this doesn't need to be a field, you can just use a local variable
nit: this doesn't need to be a field, you can just use a local variable
nit: this doesn't need to be a field, you can just use a local variable
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
@willthames bcoca asked me to look at your problem. I think that we want to use to_native() here and we probably want to use errors='surrogate_or_strict' as well. to_native() converts the string into the type which an undecorated string literal has on that version of python. That type is called "str" on both python2 and python3 but it's a byte string on python2 and a text string on python3. It will have the following benefits: * It's the most compatible since it's the same type as str on both platforms. (It just has better defaults and more flexible error handling than using str()). * For most module_utils code, we use native string types right now so that a module author can mostly write idiomatic python and it mostly just works. They don't run into a problem combining byte and text type. (They do have to worry about it when they deal with an external API which needs a specific type but those are not as common so it's easier to deal with those when the time comes and not worry the rest of the time).
CI failure due to missing conditional when calling main: ```python if __name__ == '__main__': main() ```
We should use the various `compat_*` down below and delete these imports, so that the code also runs on Python 3.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
We should use the various `compat_*` down below and delete these imports, so that the code also runs on Python 3.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
This conditional is never going to evaluate properly, since `('us-east-1' or None)` evaluates to `True`, so the only way this evaluates as wrong is if location == True. I think what you mean is `location not in ('us-east-1', None):`
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Have you even read it? Percent encoding is a plain mapping of characters to `%XX` representation per se. RFC 3989 determines the set of rules for applying this mapping to URIs, roughly speaking it determines the set of characters that should not be percent encoded so that this set is used in `escape_rfc3986` to fix some invalid URIs to meet the requirements. What `compat_urllib_parse.unquote` does is simply mapping `%XX` back to character representation for a plain string. This have nothing to do with URIs and with rules determined in RFC 3989.
Nothing to do with RFC 3986.
Maybe simplify with: ``` decoded_url.translate(None, '"\',').decode('utf-8') ``` Or in case there could be spaces in `['"cod", "ed ", "URL"]`: ``` re.sub(r'[\s"\',]', '', decoded_url).decode('utf-8') ```
Have you even read it? Percent encoding is a plain mapping of characters to `%XX` representation per se. RFC 3989 determines the set of rules for applying this mapping to URIs, roughly speaking it determines the set of characters that should not be percent encoded so that this set is used in `escape_rfc3986` to fix some invalid URIs to meet the requirements. What `compat_urllib_parse.unquote` does is simply mapping `%XX` back to character representation for a plain string. This have nothing to do with URIs and with rules determined in RFC 3989.
Nothing to do with RFC 3986.
Nothing to do with RFC 3986.
Have you even read it? Percent encoding is a plain mapping of characters to `%XX` representation per se. RFC 3989 determines the set of rules for applying this mapping to URIs, roughly speaking it determines the set of characters that should not be percent encoded so that this set is used in `escape_rfc3986` to fix some invalid URIs to meet the requirements. What `compat_urllib_parse.unquote` does is simply mapping `%XX` back to character representation for a plain string. This have nothing to do with URIs and with rules determined in RFC 3989.
Have you even read it? Percent encoding is a plain mapping of characters to `%XX` representation per se. RFC 3989 determines the set of rules for applying this mapping to URIs, roughly speaking it determines the set of characters that should not be percent encoded so that this set is used in `escape_rfc3986` to fix some invalid URIs to meet the requirements. What `compat_urllib_parse.unquote` does is simply mapping `%XX` back to character representation for a plain string. This have nothing to do with URIs and with rules determined in RFC 3989.
Nothing to do with RFC 3986.
Nothing to do with RFC 3986.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Missing space after comma.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Bravo on tackling one of the gnarlier test setups ;-> :+1:
no, if the variable is set but empty, you should empty out the options
Include a `host=kwargs[Jail.modified_jailname_key]` kwarg when calling `display.vvv`. This will maintain consistency with other calls to `display.vvv` made by the `Jail` connection plugin.
shouldn't this be like the following? ~~~python if rule == _rule['rule'] or rule == _rule['id']: ~~~
I like this
shouldn't this be like the following? ~~~python if rule == _rule['rule'] or rule == _rule['id']: ~~~
```suggestion "4. The account cannot be removed due to permission issues : %s" % to_native(security_error.msg) ```
Please remove this example, since I would consider this usage as not recommended.
no, the title should match what is used in `VVVVIDIE`, and also this would prevent users from customizing the output filename(ex: the user may prefer to use `ep - title`).
Minor: if the test fails, the value of `basic.has_journal` won't be restored. This probably doesn't matter.
These examples are confusing. dim ordering should be referred to as "th dim ordering / tf dim ordering". Please pick one of them and have the entire example use the same convention. You may then follow up with the same example in the alternative dim ordering.
These examples are confusing. dim ordering should be referred to as "th dim ordering / tf dim ordering". Please pick one of them and have the entire example use the same convention. You may then follow up with the same example in the alternative dim ordering.
Ah, I was actually thinking that any message (in particular a consumed message?) after a shutdown complete would be a thing to raise an error over. Really just a sanity check, might not actually be of use.
Move data and query into `_download_webpage` call.
You should ensure it is a string (see string_types)
Also, it seems like our convention for docs versions is quite bad. If we didn't want to use `.`, we could use something else like `_`.
```suggestion raise ExtractrorError('No episodes returned for program with ID: %s' % program_id, expected=True) ```
self.current_feed_dict = {} if self.feed_dict is None else self.feed_dict Clearer
```suggestion # just get value from attribute itself as normal ```
this still has the #73643 issue, we might want to store the 'raw' notification instead and reprocess handler matching so we always get the 'latest' version of that handler
Missing `=dict` on this and the next few lines
```suggestion Test that the returned value for timezone consists of only uppercase ```
If found this part weird with using `self` for temporary variables
You should not rely on private property `_keras_shape` which may not be set
2.6 or 2.7? Also you `requirements` listed here and the modules.
Don't shadow built-in names.
There should be fallbacks for these values since they are more or less static.
2.6 or 2.7? Also you `requirements` listed here and the modules.
avconv does not support `-cookies`, use `-headers` instead. You should also pass all headers.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
As above; Separate log exception method for the normal situation where the RT does not exists VS all other errors.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
connection plugins should not have their own python logic. If distros are using different python/missing python it is up to user to add (plenty of examples with raw and ansible_python_interpreter).
both are valid tests, i don't see why you need to eliminate the existing one
* Use built-in sorting (needs https://github.com/dirkf/youtube-dl/tree/df-kikuyan-jwplayer-patch) * Get `description` in different ways * Extract `upload_date` by translating month names from Georgian ```suggestion formats = self._parse_jwplayer_formats(jwplayer_sources or [], video_id) for f in formats or []: f['preference'] = self._quality(f['format_id']) self._sort_formats(formats) description = ( self._og_search_description(webpage) or get_element_by_id('long_desc_holder', webpage) or self._html_search_meta('description', webpage)) uploader = self._search_regex(r'<a[^>]+class="mv_user_name"[^>]*>([^<]+)<', webpage, 'uploader', fatal=False) upload_date = get_element_by_class('mv_vid_upl_date', webpage) # as ka locale may not be present roll a custom date conversion upload_date = (unified_strdate( # translate any ka month to en re.sub('|'.join(self._MONTH_NAMES_KA), lambda m: MONTH_NAMES['en'][self._MONTH_NAMES_KA.index(m.group(0))], upload_date, re.I)) if upload_date else None) ```
Move data and query into `_download_webpage` call.
Title is mandatory.
Remove unused codes.
Remove unused codes.
```suggestion def state_update_library(self): ```
Avoid shadowing built-in names.
It would be awesome if buildah supported copying from a container.
```suggestion with open('/var/run/secrets/kubernetes.io/serviceaccount/token') as file: ```
IMO no need to. Each step is idempotent, we failed to reach desired state but we got closer. But mostly, it's just easier ;-)
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
Don't use automatic field numbering!
I would prefer to reuse
Maybe we should move "This is also effectively a cap on ... which may be different from this." to after "This setting will limit ... sending huge requests.". It seems like the latter describes the purpose of the setting while the former is an additional implication.
terms can be a list, not sure if this is being handled correctly
Maybe we should move "This is also effectively a cap on ... which may be different from this." to after "This setting will limit ... sending huge requests.". It seems like the latter describes the purpose of the setting while the former is an additional implication.
1. Single quotes. 2. `expected`.
terms can be a list, not sure if this is being handled correctly
Got it. But this is very confusing error message. anyways, not a blocker as such.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
```suggestion query=dict(type='list', elements='str'), ```
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
Returning would close the file (I think) since you're already in a 'with' statement.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
both are valid tests, i don't see why you need to eliminate the existing one
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Please remove this example, since I would consider this usage as not recommended.
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
Sure, a separate PR sounds good.
I wouldn't exactly call a dictionary `list`.
> parses `parse`, because it's an action. But I'd go for smth like `get_packages_from_specs`.
```suggestion matches = [re.search(r'^[ #]+- env: T=(?P<group>[^/]+)/(?P<params>.+)/(?P<number>[1-9][0-9]?)$', line) for line in self.shippable_yml_lines] ```
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
Please remove this example, since I would consider this usage as not recommended.
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
Yeah I was thinking about debugging purposes as well. If it is more noise the usefulness, I'm fine with dropping it.
result is attempted to be used below
no trailing conditionals, people tend to miss these (i'm guilty of having written too many of em)
no trailing conditionals, people tend to miss these (i'm guilty of having written too many of em)
no trailing conditionals, people tend to miss these (i'm guilty of having written too many of em)
I would name the method `passwd_set`.
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
This should be split into building url and extracting formats.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
This method definition shares most of its functionality with `get_request` method, which indicates that the common functionality (common parameters, error handling, etc.) should be extracted into private method.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
Net new tests should be `pytest` style tests.
You can import `try_rm` from helper
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
```suggestion Test that the returned value for timezone consists of only uppercase ```
```suggestion Test that the returned value for timezone consists of only uppercase ```
fixture with load_json
as discussed previously, no such thing "alert policies". every mention of "policy/ies" should be renamed...
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
please remove the extra space at the start of the line to fix the failing tests
This function call is already (indirectly) included in `_download_webpage`.
This function call is already (indirectly) included in `_download_webpage`.
This won't work at all if starting playlist entry is not in `daterange`.
When using pytest, create top-level functions without using a class.
I think this approach might read simpler: ```suggestion new_galaxy_yml = dict.from_keys(optional_strings) new_galaxy_yml.update(dict.from_keys(optional_lists), []) new_galaxy_yml.update(dict.from_keys(optional_dicts), {}) new_galaxy_yml.update(galaxy_yml) ```
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
I think this approach might read simpler: ```suggestion new_galaxy_yml = dict.from_keys(optional_strings) new_galaxy_yml.update(dict.from_keys(optional_lists), []) new_galaxy_yml.update(dict.from_keys(optional_dicts), {}) new_galaxy_yml.update(galaxy_yml) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Add these 3 classes to `utils/__init__.py` so they can be imported from `utils` by users (internally it doesn't matter)
I would separate the try-except-else blocks to improve readability of the tests.
just a small typo, serached->searched
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
```suggestion matches = [re.search(r'^[ #]+- env: T=(?P<group>[^/]+)/(?P<params>.+)/(?P<number>[1-9][0-9]?)$', line) for line in self.shippable_yml_lines] ```
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
This one will fail with the new to_unicode. With no arguments, this will return `"None"``(the equivalent of``str(none)`` ). If we want the test to return None, then update like this: ``` python none = ansible.utils.unicode.to_unicode(None, nonstring=passthru) ```
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
```suggestion for app in sorted(set(apps)): ``` This way, you won't have trouble if apps show up more than once in the list (in which case `is_installed` and `is_outdated` can return wrong information), and the order is still deterministic also for older Python versions.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
You don't need a copy of the list in memory here. Better use a generator expression: ```suggestion versions = (v for v in self.versions if v != '*') ```
I did this so I can deprecate `--get-url` (along with all other --get options). Unless you want to do that too, `urls` field isn't really needed
You don't need a copy of the list in memory here. Better use a generator expression: ```suggestion versions = (v for v in self.versions if v != '*') ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
you should not need to checked disabled, as the plugin itself wont be called at all if true
`, no_log = True`
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
Please remove this, `AnsibleModule` already prevents this.
`, no_log = True`
`, no_log = True`
`, no_log = True`
`, no_log = True`
`, no_log = True`
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
It's better to actually say that there's no file in place or it's inaccessible.
It's better to actually say that there's no file in place or it's inaccessible.
It's better to actually say that there's no file in place or it's inaccessible.
I'd want to see the role stay atomic and have either everything or nothing change. If the module fails, nothing should change on the system. That might either mean moving the loop into the `semanage_boolean_value` function, or supporting externally-triggered commit for the function.
I'd want to see the role stay atomic and have either everything or nothing change. If the module fails, nothing should change on the system. That might either mean moving the loop into the `semanage_boolean_value` function, or supporting externally-triggered commit for the function.
I'd want to see the role stay atomic and have either everything or nothing change. If the module fails, nothing should change on the system. That might either mean moving the loop into the `semanage_boolean_value` function, or supporting externally-triggered commit for the function.
I completely missed that, apologies
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
> They can't be multiline, can they? Yep. According to [ECMA 262 5.1](http://www.ecma-international.org/ecma-262/5.1/), CR (U+000D), LF (U+000A), LS (U+2028) and PS (U+2029) are not allowed in RegExp literals
> They can't be multiline, can they? Yep. According to [ECMA 262 5.1](http://www.ecma-international.org/ecma-262/5.1/), CR (U+000D), LF (U+000A), LS (U+2028) and PS (U+2029) are not allowed in RegExp literals
Okay... We shouldn't let tests drive implementation (unless it's a case where the implementation is more modular, easier to read, or more flexible once it's adapted to the test case). let me take a look at updating the test case.
Okay... We shouldn't let tests drive implementation (unless it's a case where the implementation is more modular, easier to read, or more flexible once it's adapted to the test case). let me take a look at updating the test case.
nit: this doesn't need to be a field, you can just use a local variable
alright. let's keep it as is.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
nit: this doesn't need to be a field, you can just use a local variable
Just use `replace` or `re.sub`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
Space after #
why fail here? I think we should just do nothing
Some extractors use the domain name as `IE_DESC`, so I guess it's OK.
` // <1>` is unnecessary.
Some extractors use the domain name as `IE_DESC`, so I guess it's OK.
Not necessary but this map and the one on 690 are better written as: ``` python elif LooseVersion('.'.join(to_native(ver_field) for ver_field in etree.LXML_VERSION)) < LooseVersion('2.3.0'):
Not necessary but this map and the one on 690 are better written as: ``` python elif LooseVersion('.'.join(to_native(ver_field) for ver_field in etree.LXML_VERSION)) < LooseVersion('2.3.0'):
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Not necessary but this map and the one on 690 are better written as: ``` python elif LooseVersion('.'.join(to_native(ver_field) for ver_field in etree.LXML_VERSION)) < LooseVersion('2.3.0'):
Not necessary but this map and the one on 690 are better written as: ``` python elif LooseVersion('.'.join(to_native(ver_field) for ver_field in etree.LXML_VERSION)) < LooseVersion('2.3.0'):
Not necessary but this map and the one on 690 are better written as: ``` python elif LooseVersion('.'.join(to_native(ver_field) for ver_field in etree.LXML_VERSION)) < LooseVersion('2.3.0'):
Refer https://github.com/ansible/ansible/pull/49414#pullrequestreview-180616762 The capability dict in onyx cliconf plugin can store version and other product releated information at time of connection initilaization instead of executing `show version` for every task run.
Refer https://github.com/ansible/ansible/pull/49414#pullrequestreview-180616762 The capability dict in onyx cliconf plugin can store version and other product releated information at time of connection initilaization instead of executing `show version` for every task run.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
I completely missed that, apologies
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
Again, this only works on the primary credential cache. If the ticket is in another, this might not work.
Use `to_native` rather than `str()`: ```suggestion cmd.append(to_native(calendar.timegm(self.expires))) ```
use ```from ansible.module_utils.vmware import get_cluster```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Please ignore, this is called when non-existin number is passed. So it's ok
Please ignore, this is called when non-existin number is passed. So it's ok
Minor: if the test fails, the value of `basic.has_journal` won't be restored. This probably doesn't matter.
Please ignore, this is called when non-existin number is passed. So it's ok
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
~~1. This won't work for UTF-8.~~ Nevermind, `BaseCookie.__ParseString` does not seem to be capable of UTF-8. 2. This will produce `"None"` string if there is no cookies, i.e. `cookie_header` is `None` that is completely wrong. 3. Also this should only taken place when `cookie_header` is a not a bytestring already.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
Not catching non-200 responses.
Isn't `raise` missing there ? Calls to `str` are useless.
Please remove this example, since I would consider this usage as not recommended.
Isn't `raise` missing there ? Calls to `str` are useless.
These 2 lines could be replaced by: ```python uploader_url, uploader_id = uploader_data[0][0:2] ```
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
no, if the variable is set but empty, you should empty out the options
Note that str() can fail if the object's __str__ method returns non-ascii characters. You probably control the objects being used here so you know whether that's the case or not. I usually use ```to_native(self.change_relelvant_keys, nonstring='simplerepr')``` in similar situations so I don't have to worry about it.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Technically, it's not a stack data structure, so it's better to pick other name, which also reflects the purpose of it. Something like `single_package` or `package_parts` might be better.
Technically, it's not a stack data structure, so it's better to pick other name, which also reflects the purpose of it. Something like `single_package` or `package_parts` might be better.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Could we set a default on the FA instead of adding this method? I think it would be as simple as `default=LoopControl`
Could potentially be moved to the module_utils? (same for lines 112 -> 122)
Could potentially be moved to the module_utils? (same for lines 112 -> 122)
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
You should be able to know the length too (either the default or specify it) and then you don't have to loop through each character in result.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Instead of equality, I think you want to check for `isinstance` here.
Instead of equality, I think you want to check for `isinstance` here.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Say "botocore/boto3" since boto isn't used in this module.
ok, I get that though I think that's just tech debt. for any test related files, we really shouldn't be using anything other than `PERSISTENT_ROOT` so that we can at least attempt to ensure each test/service gets a clean workspace
ok, I get that though I think that's just tech debt. for any test related files, we really shouldn't be using anything other than `PERSISTENT_ROOT` so that we can at least attempt to ensure each test/service gets a clean workspace
This should not be a new paragraph, but continue the previous paragraph (item), right? ```suggestion port 3000 if available or asinfo -v status returns ok ```
```suggestion query=dict(type='list', elements='str'), ```
This should not be a new paragraph, but continue the previous paragraph (item), right? ```suggestion port 3000 if available or asinfo -v status returns ok ```
This should not be a new paragraph, but continue the previous paragraph (item), right? ```suggestion port 3000 if available or asinfo -v status returns ok ```
Please remove this example, since I would consider this usage as not recommended.
and if possible please: `Destination %s is not writable` (the word `is` is missing)
and if possible please: `Destination %s is not writable` (the word `is` is missing)
Same suggestion as above. .get() doesn't have to return a Nonetype so you can use it for "port" too.
And remove this afterwards.
This should be `b_output_path` to indicate it is a series of bytes. Even if the caller is sending in bytes, this function should convert it to bytes just like `b_collection_path` at the beginning. That allows our `b_` naming convention to hold, making this code look incorrect (trying to join `bytes` and `str`).
Don't use `\` for breaking lines, prefer using parentheses
What's the point combining original and translated lyrics to a single file? There should be 2 separated entries in `subtitles` instead.
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
We want to print the full shapes for clarity. Creating a new array in the exception is not an issue: we're interrupting execution anyway, so we don't care about resources consumption.
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
Use `self._search_regex` and `utils.unified_strdate` instead.
These looks like mandatory fields.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
You have identical code on lines 159-163, 193-197, 228-232... Move it into a function.
You have identical code on lines 159-163, 193-197, 228-232... Move it into a function.
You have identical code on lines 159-163, 193-197, 228-232... Move it into a function.
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
Similarly, ```if tc['skip'].get('i')```
Do not escape quotes inside triple quotes.
Do not escape quotes inside triple quotes.
What about to create shortcuts for all these `p['...']` variables? It would be easier to read the code then: ``` # Create the object swupd = SwUpd(module) # Create shortcuts update = p['update'] verify = p['verify'] state = p['state'] name = p['name'] # Trigger action if update: swupd.update() elif verify: swupd.verify() elif state == "present": swupd.install(name) elif state == "absent": swupd.remove(name) ``` If you would implement the object approach, then you can create more shortcuts in the `__init__()` method. For example for `p["format"]`, `p["manifest"]`, `p["contenturl"]` and `p["versionurl"]` and then use `self.format`, `self.manifest`, `self.contenturl` and `self.versionurl` instead.
Since this isn't implemented, perhaps lets not mention it? I found it confusing
should we ask for a file name? (default to stdout is fine)
`load_fixture()` takes the module name as the first parameter now, so you can lose the `os.path.join()` above and just have `load_fixture('nxos_switchport', filename)`
`load_fixture()` takes the module name as the first parameter now, so you can lose the `os.path.join()` above and just have `load_fixture('nxos_switchport', filename)`
Why don't you just encode suffix like `u'-\u00c5\u00d1\u015a\u00cc\u03b2\u0141\u00c8'.encode('utf-8')` and for the no_temp_unicode override just do `suffix = b'-ansible'`? No need for this check which is arguably more confusing.
Could you please keep the same string quoting style across the module? ```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('UTC')), '2019-06-15T14:45:00+00:00'), ```
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
I may not be allowed to write to current directory. Maybe log path should be passed as parameter.
Fix test: ```suggestion 'ext': 'mp4', ```
```suggestion msg: "{{ lookup('azure_keyvault', 'secret_name=someSecretName secret_version=169591fb vault_uri=https://anothervault.vault.azure.net/') }}" ```
You don't need a copy of the list in memory here. Better use a generator expression: ```suggestion versions = (v for v in self.versions if v != '*') ```
avconv does not support `-cookies`, use `-headers` instead. You should also pass all headers.
required is by-default is 'False', so no need to add explicitly.
Good practice since the `%` operator can be ambiguous: ```suggestion return self._extract_videos(model_id, self._BASE_URL_TEMPL % (model_id, )) ```
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
Is the match on trailing `\s+title` necessary to avoid false matches? ```suggestion for video_id in re.findall(r'(?is)<div\s[^>]*\bclass\s*=\s*["'.*?\bvideo-item\b.*?["'][^>]*>\s*<a\s[^>]*\bhref\s*=\s*["'](.*?)["']', webpage): ```
There is no point to use `remove_start` since line is always a string.
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
I'd like to not pull SEQUENCETYPE into this file but this one is a little tricky. A Mapping is an iterable and we have a separate conditional block to work with those. If we just check for collections.abc.Sequence then we wouldn't catch things like sets and keyview.... I think what we can do is put the Mapping conditional before this one and then change this one to ```if is_iterable(obj)```.
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
This needs to be in a fixture so it doesn't affect all unit tests. To avoid the need to reference the fixture on each test you may want to use `@pytest.fixture(autouse=True)` on the fixture. Perhaps something like this: ```suggestion @pytest.fixture(autouse=True) def fake_xenapi(): xen_api = importlib.import_module('units.module_utils.xenserver.FakeXenAPI') sys.modules['XenAPI'] = xen_api return xen_api ```
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
This can be more PEP8 with a '\n': ``` Python class YahooSearchIE(LazyLoadExtractor): _VALID_URL = None _module = 'youtube_dl.extractor.yahoo' @classmethod def suitable(cls, url): return re.match(cls._make_valid_url(), url) is not None @classmethod def _make_valid_url(cls): return 'yvsearch(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' ```
Almost all modules use `dict()` constructor here. `required: False`, `default: None`, and `type: 'str'` are defaults and not required. Not really a blocker, more advisory.
return dict((key, self.get(key)) for key in self.keys())
A flush is missing either here, or at the end of _save_model itself.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
I think it's not good style to use `global`.
You don't need to specify this field if there is no return output
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
I'm not certain that we want to name this *Module. Just from reading this PR it appears that it will be used more for managing keys and certs rather than managing a program (the ansible module).
To restore almost the old behavior, add `import errno` at the top and apply this change: ```suggestion except EnvironmentError as exc: if exc.errno == errno.ENOENT: self.fail("Error opening image %s - %s" % (self.load_path, str(exc))) self.fail("Error loading image %s - %s" % (self.name, str(exc))) except Exception as exc: ```
Again, this doesn't look like an availability check.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
CI failure due to PEP 8 issue: ``` 2017-02-16 00:21:02 ERROR: PEP 8: lib/ansible/modules/cloud/docker/docker_service.py:525:59: W291 trailing whitespace (current) ```
maybe render it shorter? ```suggestion sanitized with :func:`~ansible.module_utils.common.parameters.sanitize_keys` before logging or displaying. ```
replace "chroot connection" in messages with "nspawn connection".
Also, it seems like our convention for docs versions is quite bad. If we didn't want to use `.`, we could use something else like `_`.
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
We should convert filenames to bytes before passing to open. Like this: ``` python with open(to_bytes(in_path, errors='surrogate_or_strict'), 'rb') as in_file: ```
s/write target file {0}/fetch file to {0}/
s/write target file {0}/fetch file to {0}/
```suggestion self.module.fail_json(msg='Unable to add required signing key for%s ', rc=rc, stderr=stderr, error=to_native(e)) ```
This line is unnecessary.
This can be more PEP8 with a '\n': ``` Python class YahooSearchIE(LazyLoadExtractor): _VALID_URL = None _module = 'youtube_dl.extractor.yahoo' @classmethod def suitable(cls, url): return re.match(cls._make_valid_url(), url) is not None @classmethod def _make_valid_url(cls): return 'yvsearch(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' ```
Change to 0.
Change to 0.
This doc should be updated.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
I believe it should be `success, rx, tx, rtt = parse_ping(ping_results_list[-1])`
Remove excessive verbosity. This fits well on a single line.
Remove excessive verbosity. This fits well on a single line.
A simpler fix would be to do `join(to_install + to_upgrade)`
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
ERROR rather than BLAH :)
Imports run before AnsibleAWSModule instantiation, so you still need this try.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
enumerate is not needed here. i is not used
Do not escape quotes inside triple quotes.
Do not escape quotes inside triple quotes.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
Please use lowercase variable names.
The point of these conversion interfaces is that old code should still work. So in this case we should figure out a better solution. Please leave out this layer.
Please use backquotes around code keywords.
i'll wait for someone to name a host or group 'false' and cry when that ticket is opened
note, if expanded paths is large, this might be slow. It's faster to do it like this, if so: ```suggestion expanded_paths=to_native(b', '.join(b_expanded_paths), errors='surrogate_or_strict') ```
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
If you don't modify the task args then you don't need to copy() them. However, I think we want to add a ```use``` parameter for the action plugin and we will want to delete that parameter before we pass the args on to the module. So this section would look like: ``` python new_module_args = self._task.args.copy() del new_module_args['use'] [...] result.update(self._execute_module(module_name=module, module_args=new_module_args, task_vars=task_vars, wrap_async=self._task.async_val)) ```
this got named use_backend
Please remove this example, since I would consider this usage as not recommended.
`display.deprecated` takes a `version` kwarg that defines the version that the functionality will be removed in. Please use this as it will help us audit the code later to find items needing removed.
`display.deprecated` takes a `version` kwarg that defines the version that the functionality will be removed in. Please use this as it will help us audit the code later to find items needing removed.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Missing `=dict` on this and the next few lines
`display.deprecated` takes a `version` kwarg that defines the version that the functionality will be removed in. Please use this as it will help us audit the code later to find items needing removed.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
`display.deprecated` takes a `version` kwarg that defines the version that the functionality will be removed in. Please use this as it will help us audit the code later to find items needing removed.
Period at end of the sentence
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
```suggestion url_json = self._parse_json(self._html_search_regex(r'''<div\b[^>]+\bdata-item\s*=\s*(["'])(?P<videourls>\{.*})\1''', webpage, 'videourls', group='videourls', default='{}'), video_id, fatal=False)) or {} video_url = url_or_none(try_get(url_json, lambda x: x['sources'][0]['src'], compat_str) or self._og_search_video_url(webpage)) # Get the video url ```
Depending on where in the page the target may be, consider `self._html_search_regex()` which unescapes the returned match (eg, if it contains `&amp;` that should be `&`, or just `&#0049;` that should be `1`).
task_uuid seems unused
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
No such meta field.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
Code duplication 173, 213. There is no sense to extract fields explicitly.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
Use `b_dest` as the var here. It'll likely require more changes, but for long lived bytes, we should differentiate by using `b_` prefix
Cause it's an **utility function** and it's used in other places you've broken with this change.
This will fail if user provides `int` values. ``` >>> a = 1 >>> a.isdigit() Traceback (most recent call last): File "<stdin>", line 1, in <module> AttributeError: 'int' object has no attribute 'isdigit' ``` you might want to add additional check like ```python timezone = self.params['customization'].get(timezone') if isinstance(timezone, int): ident.guiUnattended.timeZone = timezone elif isinstance(timezone, string_types) and timezone.isdigit(): ident.guiUnattended.timeZone = int(timezone) else: self.module.fail_json(msg="customization.timezone attribute should be an integer value.") ```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
```suggestion - Path of the authentication file. Default is ``${XDG_RUNTIME_DIR}/containers/auth.json`` ```
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
```suggestion query=dict(type='list', elements='str'), ```
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
1) No need to inherit from object explicitly due to `__metaclass__ = type` set above 2) It's nice to properly support all stringifications ```suggestion @six.python_2_unicode_compatible class CollectionRequirement: ```
Use `self.assertEqual(d, d)` instead of `self.assertTrue(d == d)`.
```suggestion # just get value from attribute itself as normal ```
```suggestion if gql_auth: ```
```suggestion if gql_auth: ```
I would rather see ValueError instead of general exception
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
I would rather see ValueError instead of general exception
I would keep the `HAS_LDAP` local to this package. Just set it to `True` after you import it bellow.
```suggestion return b'\r\n'.join(to_bytes(line, nonstring='passthru') for line in result) ``` (and import `to_bytes`)
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
The entries in `config` should match the arguments in `__init__`.
The interface should be the same for Theano and TensorFlow.
The interface should be the same for Theano and TensorFlow.
The interface should be the same for Theano and TensorFlow.
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
not sure `6.` is needed as you have `from __future__ import division`
self.current_feed_dict = {} if self.feed_dict is None else self.feed_dict Clearer
Glancing over the code, `packages_to_remove` might be a clearer name here- I saw the `packages.remove('setuptools')` below and was like, "wait, I thought we wanted to keep it?!" until I realized what was happening...
Whenever I call a function twice like this (first to check if the value meets a condition and then to make use of that value) I like to turn it into calling the function once and storing the value. That way the cost of calling the function and any logic the function has to perform are only done once. ``` python warnings = get_warning_messages() if warnings: kwargs['warnings'] = warnings ``` In this case, we're only saving the cost of calling the function and converting a list into a tuple (and only doing it once per module) so it shouldn't be a big overhead. But it is nice to do as not everyone will know that the implementation of `get_warning_messages()` is so lightweight (and who knows, it might become a more costly operation in the future)
not a blocker, but a small optimization, `elif` will avoid the check if fail_msg was `None`, since you are hardcoding to string you should not need to do this
Got it. But this is very confusing error message. anyways, not a blocker as such.
not a blocker, but a small optimization, `elif` will avoid the check if fail_msg was `None`, since you are hardcoding to string you should not need to do this
not a blocker, but a small optimization, `elif` will avoid the check if fail_msg was `None`, since you are hardcoding to string you should not need to do this
not sure `6.` is needed as you have `from __future__ import division`
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
Similarly, ```if tc['skip'].get('i')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```suggestion - name: Install bottle for Python 3.3 specifically, using the 'pip3.3' executable ```
Similarly, ```if tc['skip'].get('i')```
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
"Post the tags" is not very clear (and the fact it uses POST not interesting). "Perform assign/unassign action" ? More importantly I'd say a few words about what `tags` is.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Similarly, ```if tc['skip'].get('i')```
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
you can move it to before `if` as just `docs = {}` line, this should read better.
``` r'itemprop\s*=\s*\"ratingValue\"\s*> ``` ``` r'itemprop\s*=\s*\"ratingValue\"[^>]*> ``` So that the code can live even if new attributes are added to this element Also, there's no need to escape double quotes in strings encapulated by single quotes.
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
netrics => metrics
This loop should be integrated with the first one. Otherwise we need two calls to `batch_set_values`, which is less efficient. Weights should be converted in Numpy-space before being set.
netrics => metrics
Modify existing regex instead.
My bad. Could you please add this to vmware.py
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
Use `self._search_regex` and `utils.unified_strdate` instead.
should be self.forward.
I think what you've got it good, thanks
Don't remove tests for the original JSInterpreter. Before jsinterp2 replaces jsinterp, tests should be there to guarantee nothing gets broken by accident.
Don't remove tests for the original JSInterpreter. Before jsinterp2 replaces jsinterp, tests should be there to guarantee nothing gets broken by accident.
Don't remove tests for the original JSInterpreter. Before jsinterp2 replaces jsinterp, tests should be there to guarantee nothing gets broken by accident.
First two groups are useless.
Playlist metadata must not be fatal.
Only one space after periods.
Playlist metadata must not be fatal.
Part in the middle should not be greedy. Also use `_parse_html5_media_entries` as main path.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Get rid of `dim_ordering`, as it isn't doing anything anymore.
@jacquerie I believe this is the right way to do it.
We generally call it "KTF"
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
`_parse_jwplayer_data` should also be used. See `tvnoe.py` for an example.
Should `args[1:]` here (the first entry in `args` is `self`).
```suggestion 'Unable to connect to socket %s. See the socket path issue category in ' ```
```suggestion 'Unable to connect to socket %s. See the socket path issue category in ' ```
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
Minor: if the test fails, the value of `basic.has_journal` won't be restored. This probably doesn't matter.
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
This snippet looks just like one in `role_find`. It probably deserves being moved into a reusable function.
I think either name should be mandatory or this should take a label selector.
Though not thoroughly tested, I think [`int_or_none`](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/utils.py#L1278-1284) has similar functionality.
```suggestion module.exit_json(changed=True, db=db_name, db_list=db) ``` So behavior is the same as without `check_mode`.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
Remove this flush, it is doing nothing just before the closing of the file.
Remove this flush, it is doing nothing just before the closing of the file.
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
You can import `try_rm` from helper
You can import `try_rm` from helper
If we are not exposing this detail, then it would be a bit weird to classify them in the first place.
qvm-run just require this to be a single argument, no extra quotes are needed
eliminate intermediate list ```suggestion new_versions = set(v for v in self.versions if self._meets_requirements(v, requirement)) ```
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
I'm curious if this should be a `BaseException` so that it'd work on `Ctrl+C` (`SIGINT`) or `SystemExit` (`SIGTERM`).
'+' is redundant here.
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Unalbe -> Unable
Same question for dropping lambda here as well.
```python if size_pct is not None ```
`pzuid` does not look to be used anywhere.
this is unsafe and can lead to race conditions and data corruption, you should write to a temp file and use `basic`'s `atomic_move` method to finalize changes.
`pzuid` does not look to be used anywhere.
Same question for dropping lambda here as well.
note: You can combine these loops to be more efficient: ``` python ppaths = [p for p in ppaths if not p.endswith('/ansible_modlib.zip') and not p.endswith('/debug_dir')] ```
this is too generic and can lead to picking the wrong video.
f is already at 0, the `truncate()` is uselesss.
Valid ISO 3166-1 code for Sweden is `se`.
What's the point of this? `set-cookie` headers are handled internally.
You might want to use another variable name.
You might want to use another variable name.
Regex must look for this kind of prefix.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
It should be clarified in the docstring what "compilation" entails.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
One import per line
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
On further thought, this actually might break something with the new stuff, since you're relying on pyyaml blindly `call`ing whatever is passed in, but the prototype logic that supports object instances only does that call if `isinstance(loader, Reader)` is true. We could probably tweak that somehow, like `callable()` instead, which might be a little more resilient/Pythonic anyway... So this is definitely fine for released code, and it's something I'll keep in mind for the new stuff.
On further thought, this actually might break something with the new stuff, since you're relying on pyyaml blindly `call`ing whatever is passed in, but the prototype logic that supports object instances only does that call if `isinstance(loader, Reader)` is true. We could probably tweak that somehow, like `callable()` instead, which might be a little more resilient/Pythonic anyway... So this is definitely fine for released code, and it's something I'll keep in mind for the new stuff.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
I'm trying to think of a different class name, especially less confusable with `ManageIQAlert`. But I don't have any good suggestion. (this does fit the class naming in existing manageiq modules, matching the module name, but that's not such a good scheme IMHO, no reason to stick to it...)
@ns3284 Squash function has to be applied according to paper.
On further thought, this actually might break something with the new stuff, since you're relying on pyyaml blindly `call`ing whatever is passed in, but the prototype logic that supports object instances only does that call if `isinstance(loader, Reader)` is true. We could probably tweak that somehow, like `callable()` instead, which might be a little more resilient/Pythonic anyway... So this is definitely fine for released code, and it's something I'll keep in mind for the new stuff.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
`# Returns `
I don't think this is needed, seems like we just need to remove `short_description` here and just duplicate it across to `template.py` and `win_template.py`.
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
same here, we really dont want to test the particular setting, just that both the default (dynamic template) and the nii entry are correctly parsed.
```suggestion if any([i in network for i in ['ip', 'domain', 'netmask']]) ```
`delete` and `create` are not valid states
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Some more: avc2, avc3, avc4. These would be enough.
Break the line after the `(` to unify the style across the file.
small typo ```suggestion # table availability in check_src/dst. ```
Newline before this line
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
I think it would be good to include a message giving context before we start listing unresolved issues.
I think it would be good to include a message giving context before we start listing unresolved issues.
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
f is already at 0, the `truncate()` is uselesss.
This change is specific to static shape inference in Theano. It should be made in `K.any` and `K.not_equal` (only in the Theano backend).
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
f is already at 0, the `truncate()` is uselesss.
f is already at 0, the `truncate()` is uselesss.
nit: it will be hard to keep these arguments up-to-date- with those from `AnsibleModule` if they ever change. Perhaps we could just have `*args, **kwargs` here and pass it to the `AnsibleModule` init call. If unsupported params are passed through, the `AnsibleModule` will fail to initialize.
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
To be honest, this feels very much unsafe.
use basic.py's `missing_required_lib` function as it gives details on host and python to avoid user confusion
we want want -> we want
Got it. But this is very confusing error message. anyways, not a blocker as such.
f is already at 0, the `truncate()` is uselesss.
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
f is already at 0, the `truncate()` is uselesss.
you could narrow this down to oserror/ioerror
Returning would close the file (I think) since you're already in a 'with' statement.
The formats code should be ordered by format quality: prefering mp4 over webm, for the video it would be: 138 137 248 136 247 ...
you could narrow this down to oserror/ioerror
we probably want `<= 2` ... those using the OS package for redis python might have ancient libs
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
This will fail if `len(data) == 1`, which you explicitly allow above.
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
Won't this cause no task to ever be printed? You have nested the 'TASK' banner display under a check that ensures that the task name is 'include' and that the verbosity needs to be greater than 1.
```suggestion elif date_string.match(self.when): ```
```suggestion elif date_string.match(self.when): ```
Won't this cause no task to ever be printed? You have nested the 'TASK' banner display under a check that ensures that the task name is 'include' and that the verbosity needs to be greater than 1.
Won't this cause no task to ever be printed? You have nested the 'TASK' banner display under a check that ensures that the task name is 'include' and that the verbosity needs to be greater than 1.
I think this should be false (not a string)
I think this should be false (not a string)
nit: `java.util.` can be removed (note, we only specify the whole package for `Topology`, because otherwise we would need to add an `import` statement and get a warning about "unused imports" and a failing build.
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
1. Does not work in python 3. 2. Sorting is invalid. Sorting must be done with _sort_formats.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Don't shadow built-in names.
Wrong key. Again breaks if no such key.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Please raise a `NotIplementedError` when the use case is not supported yet.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Two line breaks after the first sentence.
```suggestion assert expected == "exception" ```
Debugging, I assume, but should be limited before merging.
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
Adding the exception string to the error would help the user narrow down what the issue is.
we normally use display instead of print
we normally use display instead of print
"webinterface" should be "web interface"
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
This may apply to some of the other PRs in flight, as well as some of your existing modules.
It probably makes sense to test that the exception reason also matches expectations
This may apply to some of the other PRs in flight, as well as some of your existing modules.
this one is not really needed as there is no user data passed back in skip_result
Probably the same with `--label` instead of `--uuid` here.
Please remove this example, since I would consider this usage as not recommended.
However without checking, `auth` for root will be overwritten.
`User has been updated`
However without checking, `auth` for root will be overwritten.
Probably the same with `--label` instead of `--uuid` here.
I think we want to deprecate NUMBERTYPES so instead of moving it, just use its definition here (list(ansible.module_utils.six.integer_types) + [float])
Please restore, or the module will fail to work in v2.7+
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
The Keras API does not require `compile` before calling `predict`, because `compile` merely configures training and is not related to inference. If MXNet requires it, that's a bug and it should be fixed.
`The value C( _public_) is...`
Matching empty string is senseless.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
Add `cmd_verbosity` to the docstring.
@s-hertel that would be really nice for vanilla pulp ansible installations, which don't currently have token auth.
This loop is a little puzzling to me. Is it not the same as the following: ```python assert all_captured_preferred_read_replicas[non_leader_idx] > 0, ... ```
Need these to be kwargs for safety; generated Azure SDK is unsafe to use positional args. We're trying to move everything there to use kwargs.
Use `_request_webpage` instead.
so this assertion looks incorrect, i would expect and empty string as the ssh args
Wouldn't it be better to let `openssl dhparam` write into a temp file, and on success move the temp file to the real file (with `module.atomic_move()`)? Then in case of interruptions or errors, existing destinations wouldn't be trashed (except of course if `atomic_move` itself goes terribly wrong).
You must delegate with `url_result` instead.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
I would prefer to reuse
There seems to be an assumed structure of what is returned by the API endpoint, operating under the pretense that the structure won't change since the API is versioned, is there any chance that this assignment could fail and cause an unhandled exception? (similar question for other functions doing similar things below)
this probably needs updating to ansible.legacy.X see constants.py for function that deals with the multiple possible names
I would prefer to reuse
Right, I didn't catch this.
Technically, cookie may change between requests so that moving `Authorization` calculation in `_real_initialize` may result in expired token.
Verifying here that IP address and prefix are in correct format would be good. Look for APIs: `socket.inet_pton(socket.AF_INET, address)` and `socket.inet_pton(socket.AF_INET6, address)`
`check_args()` is a empty function. Is this call required? For other networks platforms `check_args()` is present for legacy reason.
Optimizers have a `get_config` method precisely for this purpose.
One option would be to pass add an arg for the local fs path (or even an open file handler).
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
we want want -> we want
Use code markers around `put()`
use `unfrackpath(filename)` to ensure we get something the user can always use
Line too long, and not PEP8 compliant. Break it down into a few lines.
Line too long, and not PEP8 compliant. Break it down into a few lines.
Line too long, and not PEP8 compliant. Break it down into a few lines.
Line too long, and not PEP8 compliant. Break it down into a few lines.
There's a few things that I'd change about this function. But I think the toplevel concern is that it's doing too much. It doesn't need to take req. It should just decide whether we're using the pycrypto or cryptography backend, format and return that one dependency. The calling code can then substitute the value.
Use code markers around `put()`
rule_number += 1
Does qvm-run resolve the quotes around "cat in_path" itself? If it just needs to be a single argument, you should be able to remove the quotes and it will still work (because you're now passing a list to subprocess.Popen).
Line too long, and not PEP8 compliant. Break it down into a few lines.
```suggestion raise AnsibleParserError("the field '%s' should be a list, but is a %s" % (value, type(value))) ```
Does qvm-run resolve the quotes around "cat in_path" itself? If it just needs to be a single argument, you should be able to remove the quotes and it will still work (because you're now passing a list to subprocess.Popen).
This condition is not needed, t is always None here.
we want want -> we want
If you're unfamiliar with why that is, you should probably google it. It has to do with python processing the function declaration once when the function is declared and therefore there's only one copy of the default value which is used every time the function is called. If you have a mutable container as a default value, it will not be recreated between invocations so it may not be empty the second time you call the function.
If you're unfamiliar with why that is, you should probably google it. It has to do with python processing the function declaration once when the function is declared and therefore there's only one copy of the default value which is used every time the function is called. If you have a mutable container as a default value, it will not be recreated between invocations so it may not be empty the second time you call the function.
If I got it right, resourse unpacking happens every time `tr` is called. Have you measured the overhead imposed by this approach? Probably it would be better to unpack it once to temp dir on start and cleanup on exit.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
Please remove this example, since I would consider this usage as not recommended.
tempted to add a warning 'path not found'
The `root_uri` may include a port number (e.g. 192.168.1:8000). Should probably split that off also.
Prefer consistent using of single quotes when possible.
This one should follow the same logic as above, as well.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
What kinds of failures are we trying to mask here? Frequently retries also require delays between retries.
Harmonise with yt-dlp pt1: ```suggestion _TESTS = [{ ```
``` from .common import InfoExtractor from ..compat import ( compat_str, compat_urllib_parse_unquote ) ``` Also, if @dstfw were to review this, he would probably complain about the next two IE imports being moved as not related to the actual change.
Actually, it's an opposite. It's a check for successful login.
This logic tried to enforce a minimum version requirement, which the new code does not. Since it doesn't sound like you have added compatibility with older versions (or have any reason to), why not do something like: ``` min_version = '2.4' if loose_srv_version < LooseVersion(min_version): module.fail_json(msg='MongoDB {0] found, the minimum version supported by this module is {1}'.format(srv_version, min_version)) ```
Similarly, ```if tc['skip'].get('i')```
use `to_native` instead of `str` and add a space after like this ``` to_native(e), e.lineno ```
Must not be fatal.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Same, please rename
This doesn't appear to support the use parameter but probably should.
style note on all of these.. Unless you need lines later, it's more idiomatic python not to allocate a named temporary variable here. Instead use out.splitlines() directly: ``` python for line in out.splitlines(): ```
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Same, please rename
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
it is all you...
An alternative might be to let verifiable producer accept just one compression type. Then in your test case, you could create separate instances, each with a different compression type. Seems a little more intuitive that way to me.
I'm not sure it really matters, but I'd put `self.ALLOW_BASE_THROTTLING` first.
use `to_native` instead of `str` and add a space after like this ``` to_native(e), e.lineno ```
The way this is done is going to lead to unicode errors eventually. This is probably the least messy way to handle that: ``` python msg = u"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s" % (name, type(e), to_text(e)) if errors == 'warn': display.warning(msg) elif errors == 'ignore': display.log(msg) else: raise AnsibleError(to_native(msg)) ```
Yes, it's good this way!
```suggestion if gql_auth: ```
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
I like it!
not removed, and getvm is not static
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
okay, seems right. Just the typo correction for `user` is required. Everything else looks good :)
This ignores additional keyword arguments possibly passed by the user.
self.cache contains function `get_all_objs` which already does this, so we can reuse it directly rather than modifying `find_obj`
Maybe C(.pem)? I'm not sure you need to specify that .pem is a file type since it's just the extension. @gundalow might know.
Maybe C(.pem)? I'm not sure you need to specify that .pem is a file type since it's just the extension. @gundalow might know.
Maybe C(.pem)? I'm not sure you need to specify that .pem is a file type since it's just the extension. @gundalow might know.
Maybe C(.pem)? I'm not sure you need to specify that .pem is a file type since it's just the extension. @gundalow might know.
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
You don't need to re-include some of these fixtures, as they are used in the `elb` fixture but never called in this test.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
see my loop over waiting on threads here #49398 to get a py2/py3 compatible way
see my loop over waiting on threads here #49398 to get a py2/py3 compatible way
Currently IEs are randomly sorted. I guess sorted IE names make `lazy_extractors.py` look better.
#11205 already adds the `tile` op. So I don't think it's necessary to add it in this PR.
@jainnikhil30 and I took a look at the tower_cli code which is backing this tonight and decided that tower_cli is trying to coerce the types from a schema that it retrieves from the tower server. So it looks like the module code does not have to worry about this conversion.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
```suggestion # just get value from attribute itself as normal ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Yeah, I think what you have is fine, since we have to iterate over the generator one way or another, and the set comparison it's really straightforward either. I guess the only downside of this algorithm is that, if the broker nefariously listed the same topic multiple times, it would give us a false positive. But I seriously doubt that can happen.
please reuse the code, it's very same
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Code markers around tuples
Could you have a syntax close to : ``` if not re.match(): raise ... ``` That we don't have as much indentation levels.
Should check for a list.
Use markdown format for links
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Please remove this example, since I would consider this usage as not recommended.
url and formats are not used together.
Should add a point here saying not allowed with `I(identity)`
Ok, it shouldn't be needed unless the extractor accepts different types of urls (like the youtube extractor).
Should add a point here saying not allowed with `I(identity)`
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
New unit tests should be created using pytest style, not unittest style.
@rajinisivaram I think @guozhangwang has observed unnecessary empty stub files cluttering the code base in the past, and is suggesting that as a pattern to avoid. Correct me if I'm wrong, but the way this logic is structured, it looks like like very little extra effort to add a default properties file as soon as non-empty defaults are needed (add the file, and switch to `self.prop_file = self.render(...)` Since this is such a minor edit, having an empty stub file in place doesn't really buy much. As for rendering missing templates as empty strings in ducktape - I don't think this is the right approach, since it would hide error conditions and potentially cause confusing behavior. For example, if the user's intention is to use a nonempty template file, but the location is wrong, he or she should receive an error (easy to diagnose) than potentially start up the service with different settings than intended (harder to diagnose).
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Similarly, ```if tc['skip'].get('i')```
Yes, the `lun` could be 0, but I think there is no necessary to check it here. Maybe you want to check the range of the input? `isinstance` can check if the input `lun` is a number.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
This should not be moved. They're libraries from the current project so go below the imports for stdlib and third party libraries.
Adding the exception string to the error would help the user narrow down what the issue is.
Adding the exception string to the error would help the user narrow down what the issue is.
Adding the exception string to the error would help the user narrow down what the issue is.
Better to put the activation as the `activation` keyword of the layer below
`str` isn't needed here.
`str` isn't needed here.
This should be relaxed since in most cases there is no need in exact match of dicts or dicts' keys. Moreover some internal, compatibility or autocalculated fields may be placed in original dict. So, `same_keys` feature should be removed completely.
Unless there's a reason, I'd put all these toplevel variable definitions right after the imports. They're also constants so they probably should be uppercase but I won't block on that.
This is warning, not an exception. Tests fail on warnings if you not tell them otherwise. If description can really be missing and this is expected behavior you should pass `default=None` to `self._html_search_regex`.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Remove parans for every if ```suggestion if find_vm_by_name(self.content, self.name, folder=folder_obj): ```
Okay I think this makes sense, let's just follow this pattern then.
It seems like you could simplify things if you had an operator map and do smth like: ```suggestion import operator ... op_map = { '!=': operator.ne, '==': operator.eq, '>=': operator.ge, '>': operator.gt, ... '*': operator.eq, } ... pos = 2 if req[1] == '=' else 1 op_map(req[:pos])(LooseVersion(version), LooseVersion(req[pos:])) ... ```
```python mutually_exclusive=[ ['api_username', 'api_token'], ['api_password', 'api_token'], ], required_together=[ ['api_username', 'api_password'], ], required_one_of=[ ['api_username', 'api_token'] ], supports_check_mode=True, ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```python mutually_exclusive=[ ['api_username', 'api_token'], ['api_password', 'api_token'], ], required_together=[ ['api_username', 'api_password'], ], required_one_of=[ ['api_username', 'api_token'] ], supports_check_mode=True, ```
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This usage of filter won't work on python3. filter on python3 will return a generator which will evaluate to true in the conditional below. Use a list comprehension so that found_networks ends up with an empty list on python3 which will evaluate to false.
Okay I think this makes sense, let's just follow this pattern then.
no need to specify required=False or type=str as these are defaults
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
`del` is a builtin, not a function. These parens don't have to be here
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
self.act_fn => self.activation (unless self.activation is reserved already)
For rtmp it's always flv despite of the extension.
self.act_fn => self.activation (unless self.activation is reserved already)
we really need something generic.... getting complex :-)
For rtmp it's always flv despite of the extension.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Here you ignore the fractional parts (milliseconds, microseconds). You need to add `1000 * timedelta(**time_params).microseconds`. (Also, you should store `timedelta(**time_params)` in a variable, instead of `time_in_seconds`, and work with that one.) I.e. something like: ``` .py time = timedelta(**time_params) time_in_nanoseconds = (time.seconds * 1000000 + time.microseconds) * 1000 ```
Here you ignore the fractional parts (milliseconds, microseconds). You need to add `1000 * timedelta(**time_params).microseconds`. (Also, you should store `timedelta(**time_params)` in a variable, instead of `time_in_seconds`, and work with that one.) I.e. something like: ``` .py time = timedelta(**time_params) time_in_nanoseconds = (time.seconds * 1000000 + time.microseconds) * 1000 ```
Here you ignore the fractional parts (milliseconds, microseconds). You need to add `1000 * timedelta(**time_params).microseconds`. (Also, you should store `timedelta(**time_params)` in a variable, instead of `time_in_seconds`, and work with that one.) I.e. something like: ``` .py time = timedelta(**time_params) time_in_nanoseconds = (time.seconds * 1000000 + time.microseconds) * 1000 ```
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
Here you ignore the fractional parts (milliseconds, microseconds). You need to add `1000 * timedelta(**time_params).microseconds`. (Also, you should store `timedelta(**time_params)` in a variable, instead of `time_in_seconds`, and work with that one.) I.e. something like: ``` .py time = timedelta(**time_params) time_in_nanoseconds = (time.seconds * 1000000 + time.microseconds) * 1000 ```
Should not break if no `type`.
Got it. In that case, prefer using `evaluate` and check that the resulting losses are the same (on the same data) with both data formats.
You can import `try_rm` from helper
```suggestion def deprecated(self, msg, version=None, removed=False, date=None, collection_name=None, warn_change=False): ```
```suggestion def deprecated(self, msg, version=None, removed=False, date=None, collection_name=None, warn_change=False): ```
Insert markdown link to the callbacks page (like we do for layer activations, regularizers)
use ```from ansible.module_utils.vmware import get_parent_datacenter```
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
Also add a `# Arguments` section for `*args`
Preference would be for a unit test to be mocked sufficiently that a cleanup like this is not required. However, in this case if that involves a large amount of fragile mocking, I wouldn't worry about it now as having test coverage is better than not having it, even if it is a little messy.
should be self.forward.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
If we can't delete the publication for whatever reason, there will be no error and the module will be trapped in a endless recursive loop.
should be self.forward.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
Format your docstrings like other docstrings in the codebase
Format your docstrings like other docstrings in the codebase
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
```not (foo is None)``` => ```foo is not None```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
```not (foo is None)``` => ```foo is not None```
Format your docstrings like other docstrings in the codebase
no, if the variable is set but empty, you should empty out the options
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
It seems like no_log and deprecation are separate things and should be handled in separate functions.
Similarly, ```if tc['skip'].get('i')```
Is this try/except necessary? It's a test
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
Function calls are complex. For example: ``` from youtube_dl.jsinterp import JSInterpreter jsi = JSInterpreter(''' function a(x) { return x; } function b(x) { return x; } function c() { return [a, b][0](0); } ''') print(jsi.call_function('c')) ```
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
I don't see why `default: false` should not be there. At least here :) Depends a bit on what kind of option it is... What definitely shouldn't be there is `required: false`, but that's another option...
No need for this line
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
All formats should be extracted.
All formats should be extracted.
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
All formats should be extracted.
This should be relaxed since in most cases there is no need in exact match of dicts or dicts' keys. Moreover some internal, compatibility or autocalculated fields may be placed in original dict. So, `same_keys` feature should be removed completely.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
How are the `user_details` used by the caller here? It looks like it's embedded in a string.
```suggestion # just get value from attribute itself as normal ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
There's a lot of copying going on here as well. Both on this line and on line 456. Copying is slow so you want to eliminate any that aren't needed.
Better to do this like this: ``` python return list(merged_items.values()) ``` Using list there will make sure that it is a list on python 3 (rather than a DictView).
Remove this flush, it is doing nothing just before the closing of the file.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
Argh, it's so frustrating that the Elasticache API doesn't return ARNs! This is probably the best way to get user ID though: https://stackoverflow.com/a/10198870/3538079 There is always a chance that a user allowed to use Elasticache isn't allowed to use `rds.describe_db_instances`, so it's best to rely on as few other APIs as possible (I think everyone has permission to run `iam.get_caller_identity`)
Argh, it's so frustrating that the Elasticache API doesn't return ARNs! This is probably the best way to get user ID though: https://stackoverflow.com/a/10198870/3538079 There is always a chance that a user allowed to use Elasticache isn't allowed to use `rds.describe_db_instances`, so it's best to rely on as few other APIs as possible (I think everyone has permission to run `iam.get_caller_identity`)
You might want to use another variable name.
Any specific reason to remove traceback ? Just curious.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
Should this be `if parent not in parents:` instead? Otherwise, I do not see how this helps anything.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Should this be `if parent not in parents:` instead? Otherwise, I do not see how this helps anything.
This is not used in single video extractor thus should not be here.
Should this be `if parent not in parents:` instead? Otherwise, I do not see how this helps anything.
More pythonic to combine this unpacking with the for loop: ``` python for device, mount, fstype, options in mtab_entries: ```
Should this be `if parent not in parents:` instead? Otherwise, I do not see how this helps anything.
Please add: ``` if not self._module.check_mode: ```
Writing out `ms` as `milliseconds` might make it a little easier to understand for some people.
`raise NotImplementedError` may be more appropriate.
Also, you don't actually need these error messages after `assert` since this is a unit test
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
Is this try/except necessary? It's a test
Also, please don't use `\` to break up lines
Argh, it's so frustrating that the Elasticache API doesn't return ARNs! This is probably the best way to get user ID though: https://stackoverflow.com/a/10198870/3538079 There is always a chance that a user allowed to use Elasticache isn't allowed to use `rds.describe_db_instances`, so it's best to rely on as few other APIs as possible (I think everyone has permission to run `iam.get_caller_identity`)
Don't use this pattern. No try/except block here.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Passing `sys.argv[:]` here is useless wrt current implementation. If you look at the `main()`'s first three lines there's: ```python def main(args): ... (options, args) = parser.parse_args() # <-- immediatelly rewrites args variable ``` It looks like the initial implementation has been written by the person with some C-like background, where main accepts args data and returns 0. But in fact in this case it's not needed. Please remove this arg.
Style nit: avoid strange line breaking ```python node_key = self._node_key(layer, original_node_index) if node_key in self.container_nodes: ``` Also applicable in several other places in this PR. Please fix.
`changed=True` would be better.
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
If we're just testing broker compatibility I don't think we even need this part of the test.
Python (capital letter when referring go the software)
If we're just testing broker compatibility I don't think we even need this part of the test.
Python (capital letter when referring go the software)
it should also check if it can write there
If we're just testing broker compatibility I don't think we even need this part of the test.
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
May be None.
~~1. This won't work for UTF-8.~~ Nevermind, `BaseCookie.__ParseString` does not seem to be capable of UTF-8. 2. This will produce `"None"` string if there is no cookies, i.e. `cookie_header` is `None` that is completely wrong. 3. Also this should only taken place when `cookie_header` is a not a bytestring already.
May be None.
1. Single quotes. 2. `expected`.
```suggestion ip_pool_assoc = vim.vApp.IpPool.Association() ```
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
you can just return from inside these cases and avoid the local var / null initializer problem.
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
In line with naming conventions in this API, this should be `_num_constants`.
Some more: avc2, avc3, avc4. These would be enough.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Thanks for that note ewen. I learned something!
There doesn't seem to be a reference in the commit or the PR as to why this is being removed. I'm ok with it being removed if there's a good reason
```suggestion try_get, url_or_none, ```
There doesn't seem to be a reference in the commit or the PR as to why this is being removed. I'm ok with it being removed if there's a good reason
Shouldn't this be using `.get()` ```suggestion inventory = self._cache.get(self.cache_key)[url] ```
Ah, you'll need to use the `print('foo')` function instead of the statement for Python 3.x compatibility.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
no, if the variable is set but empty, you should empty out the options
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
FTR I was going to name it `tried-restarting` once but never got to finish that PR: https://github.com/ansible/ansible/pull/40441/files#diff-1dbc7ca500073aa0f56b8d6d7de5b8bdR446-R447 I think that this form with both parts changed better suits the naming convention.
Do note that this only looks at the primary credential cache. This means that if you use a collection credential cache such as DIR, KEYRING or KCM (default in most distributions these days), you might not see a ticket that exists in a non-primary credential cache. Maybe consider using `klist -A`, or try a `kswitch -p <principal>`? The latter is easier to parse, but might break stuff if people are still using the old krb5 APIs (rather than GSSAPI) and were using the primary credential that you just made secondary.
from my testing we should switch the order of these: ``` python b_filename = to_bytes(filename, errors='surrogate_then_strict') if expand: b_filename = os.path.expanduser(os.path.expandvars(b_filename)) # Optional: only needed if the method uses filename instead of b_filename later filename = to_text(b_filename, errors='surrogate_then_strict') ```
Another map that can be a list comprehension: ``` content = [x.strip() for x in m.group(3).split(" and ")] ```
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
I wouldn't consider it the most elegant code, but it at least has no chance of exposing the private key with a wrong mode. I am not really concerned about in essence creating an empty file first. Performance wise, yes it'll be slower but I bet that the by far limiting factor of this module (next to network latency) is the private key generation, not a few filesystem calls. If this is actually of concern, the `_symbolic_mode_to_octal` function is something that might need a further look to work without a lstat call. For now I'd prefer @abadger's solution in combination with a default `0o600` mode - maaaaaybe even setting the initial mode already in `privatekey_file = os.open(self.path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC)` hardcoded to `0o600`.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Better to name this after what it is used for. BUFSIZE is used in other connection plugins.
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
small typo ```suggestion # table availability in check_src/dst. ```
This is not used in single video extractor thus should not be here.
By the way, you don't need `else:`, since this will be evaluated anyway.
This is not used in single video extractor thus should not be here.
This should be processed with `self._extract_m3u8_formats` instead.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
small typo ```suggestion # table availability in check_src/dst. ```
This should probably just be done with a mutually exclusive group in the CLI argparse declaration.
not sure we need this here as we should always be writing to a tmp file
connection plugins should not have their own python logic. If distros are using different python/missing python it is up to user to add (plenty of examples with raw and ansible_python_interpreter).
Causes unhelpful error if get() returns None ``` $ cat nmap_inv.yml plugin: nmap $ ansible-inventory -i nmap_inv.yml --graph ERROR! Invalid settings supplied for address: argument of type 'NoneType' is not iterable ```
```suggestion for b_path in b_colldirs: ```
Since you assign to underlying private/protected variable, you don't need this public interface for someone external to modify it.
there is an ansible specific dumper we create, not sure if pertinent to this plugin, but worth looking into as i think it can save you work
there is an ansible specific dumper we create, not sure if pertinent to this plugin, but worth looking into as i think it can save you work
Causes unhelpful error if get() returns None ``` $ cat nmap_inv.yml plugin: nmap $ ansible-inventory -i nmap_inv.yml --graph ERROR! Invalid settings supplied for address: argument of type 'NoneType' is not iterable ```
Add imports to make the script compatible with py2/3: ```python from __future__ import absolute_import from __future__ import division from __future__ import print_function ```
You can avoid if/else in this case also
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
"for convolutional-recurrent layers"
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
Move into method call.
Please s/collector/facts_collector as used on line 128. lgtm.
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
1. Does not work in python 3. 2. Sorting is invalid. Sorting must be done with _sort_formats.
so this makes more sense now
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
I think it's confusing having enabled and present
~~typo result~~ fixed
Actually, it's an opposite. It's a check for successful login.
Actually, it's an opposite. It's a check for successful login.
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
~~typo result~~ fixed
~~typo result~~ fixed
The style checker will complain that there's no exception class/tuple (eg, `(ExtractorError, RegexNotFoundError, KeyError, )`). Otherwise you could make all the calls non-fatal and (as appropriate) test for falsity or supply defaults.
The style checker will complain that there's no exception class/tuple (eg, `(ExtractorError, RegexNotFoundError, KeyError, )`). Otherwise you could make all the calls non-fatal and (as appropriate) test for falsity or supply defaults.
required=False is default so no need to add.
```suggestion - name: list hooks for a repository on GitHub enterprise (token auth) github_webhook_facts: ```
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
```suggestion - name: list hooks for a repository on GitHub enterprise (token auth) github_webhook_facts: ```
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
The method does nothing, should not this method be removed ? * [X] Done
The method does nothing, should not this method be removed ? * [X] Done
This should be using `module.fail_json()` instead.
Lists also have .extend() which might be what you need here
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
My only suggestion is that I think it could be easier in the long run to do the following instead of duplicating the transaction logic, but at the same time the current code is saving cycle by not evaluating the `if module.check_mode` conditional multiple times so it's purely preference and I don't care to block the PR on it. ð ```python if state == "present": if not shard_find(client, shard): if not module.check_mode: shard_add(client, shard) changed = True else: changed = False elif state == "absent": if shard_find(client, shard): if not module.check_mode: shard_remove(client, shard) changed = True else: changed = False ```
My only suggestion is that I think it could be easier in the long run to do the following instead of duplicating the transaction logic, but at the same time the current code is saving cycle by not evaluating the `if module.check_mode` conditional multiple times so it's purely preference and I don't care to block the PR on it. ð ```python if state == "present": if not shard_find(client, shard): if not module.check_mode: shard_add(client, shard) changed = True else: changed = False elif state == "absent": if shard_find(client, shard): if not module.check_mode: shard_remove(client, shard) changed = True else: changed = False ```
1) No need to inherit from object explicitly due to `__metaclass__ = type` set above 2) It's nice to properly support all stringifications ```suggestion @six.python_2_unicode_compatible class CollectionRequirement: ```
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
If you use `to_text(xxx, errors='surrogate_or_strict')` it won't throw exceptions.
*be a string
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
1) No need to inherit from object explicitly due to `__metaclass__ = type` set above 2) It's nice to properly support all stringifications ```suggestion @six.python_2_unicode_compatible class CollectionRequirement: ```
Oops.... When you were talking about this yesterday, I thought you were going to change the return value to be a dict rather than passing in a dict. Mea culpa. I just read what you said you were planning to do wrong. I don't think operating by side effect, is the best way to write this, especially when we have a side effect and returning a value from the function. Since we're under time pressure I could see doing it this way for 2.9.x but I think it should get changed to being the return value in devel. (Unless it's simple to take what @mattclay did to identify the locations that need to be updated and then use a dist instead of a tuple for all of those).
requiring this as a dict and not using suboptions nor no_log makes the connection password too exposed.
1) No need to inherit from object explicitly due to `__metaclass__ = type` set above 2) It's nice to properly support all stringifications ```suggestion @six.python_2_unicode_compatible class CollectionRequirement: ```
**Always** check code with flake8.
You should use a broadcast rather than a repeat, for performance reasons
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
DRY 105, 107.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Perhaps: ```suggestion idx = i if idx == o: idx = l elif idx == l: idx = o new += newmagic[idx] ```
Perhaps: ```suggestion idx = i if idx == o: idx = l elif idx == l: idx = o new += newmagic[idx] ```
this is a catchall, we normally frown on those. also note that for all of your `% e` they should be `% to_native(e)` to ensure proper character conversions
this is a catchall, we normally frown on those. also note that for all of your `% e` they should be `% to_native(e)` to ensure proper character conversions
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
`<display_id> is not a video`.
Then use `enumerate()` instead.
No need to use a backslash before the single quotes.
we use getpass.getuser() in many places, we might want to make this a generic function in module_utils and replace the current instances of it, instead of fixing just this one
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
we use getpass.getuser() in many places, we might want to make this a generic function in module_utils and replace the current instances of it, instead of fixing just this one
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I completely missed that, apologies
```suggestion - A string containing the base URL of the server hosting the Central Credential Provider type: str ```
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
indentation doesn't look right here
facts modules can trivially support check mode (#23107)
You need either `to_bytes(text)` or `text.encode('utf-8')` here as well.
This is not used in single video extractor thus should not be here.
facts modules can trivially support check mode (#23107)
```suggestion fail_reason = get_failure_info(exc, out_redir_name, err_redir_name, msg_format="Error stopping project - %s") self.client.fail(**fail_reason) else: cleanup_redirection_tempfiles(out_redir_name, err_redir_name) ```
Since this is only used once, it should stay in-lined in the caller function.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
use ```from ansible.module_utils.vmware import get_parent_datacenter```
use ```from ansible.module_utils.vmware import get_parent_datacenter```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
No need to parametrize with just one case.
Functions which are side effect free and don't deal with external information like this one are excellent choices to unittest. You can give the function a wide range of potential inputs and check that they match up with the expected outputs far cheaper than you can with intergration tests.
Breaks all videos embedded with exact `<ul class="media-list items" id="media-related-items"><li data-video-info`.
You could create a helper method: ```python def _test_ipsubnet(self, ipsubnet_args, expected_result): self.assertEqual(ipsubnet(*ipsubnet_args), expected_result) # and then reuse it by looping over test data: def test_ipsubnet(self): test_cases = ( (('1.1.1.1/25', ), '0'), ... (('192.168.144.5', '18', '-5'), '192.168.144.0/27'), ) for args, res in test_cases: self._test_ipsubnet(args, res) ```
You don't need to specify this field if there is no return output
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
```python if 'name' in self.params and self.params['name']: ```
```python if 'name' in self.params and self.params['name']: ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
No sure there: why should databases with `_` in their names should be escaped ? I'd understand for `-` but not for `_`
No sure there: why should databases with `_` in their names should be escaped ? I'd understand for `-` but not for `_`
No, catch exception.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
I don't really get this, why not just do. ```suggestion auth_str = "Signature" ```
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
I don't really get this, why not just do. ```suggestion auth_str = "Signature" ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
I don't really get this, why not just do. ```suggestion auth_str = "Signature" ```
I don't really get this, why not just do. ```suggestion auth_str = "Signature" ```
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
The return value is not strictly cookies. The return value is a dictionary of headers
Oh sorry, I should have mentioned, how to specify metaclasses changed between python2 and python3. So there's a helper in six so that you can do this acroos both versions. ``` from ansible.module_utils.six import with_metaclass [...] class OneViewModuleBase(with_metaclass(ABCMeta, object)): ```
First import is already present in the file, second import is not necessary.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
You've forgot to pass `info_dict` to `supports()`.
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
It should always return a list.
You don't get it. `xpath_text(item, 'res', 'resolution', True)` => `<height>p`. Extract this height, put into format entry along with `url` and `resolution` as `height`. Stuff all formats into `info['formats']`. Run `_sort_formats` on it, it [sorts on height](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/common.py#L759). In case of flv you obviously should not sort anything. However for simplicity you can handle flv-case the same way - putting it into `info['formats']` (single format entry is ok).
so this assertion looks incorrect, i would expect and empty string as the ssh args
You must provide account credentials for testing.
Again, this only works on the primary credential cache. If the ticket is in another, this might not work.
This will fail if `vidwidth` is missing.
Bare excepts scare me. Also, there are resource names which appear in both openshift and kubernetes, and I think we need to provide a way for the user to determine which project's API they want to use. This approach could be a sane default though.
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
inserts are expensive. Just add -R earlier than adding mode and path.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
regarding backup, the way this is implemented will backup the file to the location where the module is executed. When we exeucte this as local_action or `ansible_connection=local`, it will backup the file to the control machine, however we run this module with `ansible_connection=ssh` it will be backuped to the remote machine. This is probably not what is intended. So this should be solved as "action_plugin" (identical to ios_config) which will ensure, the backup is going to the control machine.
yt-dlp's `--print` is a bit more complex, allowing printing data at multiple stages. Eg: `-O "after_move:%(filepath)s" will print the final file path. This function is needed to (easily) support that syntax, (and also other similar options)
This and other instance attributes should be defined inside `__init__`. Recommendation: - Define as `None` in `__init__` and set in another method. - Set in `__init__` directly or by using the return value of another method. This makes it easier to locate all the instance attributes since they're all listed one place.
This looks needlessly generic. why not just do: ``` python if op == 'get_password': get_password([...]) elif op == 'create_host': create_host([..]) ``` If you think you're going to have a lot of operations, you can have a lookup table: ``` OPERATIONS = {'get_password': get_password, 'create_host': create_host} method = OPERATIONS[op]([...]) ``` but for just a few operations I'm not sure I would do that... it obscures what the code is doing in any given situation to code it like that.
Since the very first thing that both of the above do is create a ```PasswordManagerPro``` object and then they just lightly wrap a method call on that object, it seems like they should really be integrated into the methods they're calling.
Sometimes you have a trailing dot (here), sometimes not (previous one). I guess you should pick one style and stick to it :)
Probably better to write this as ``` python if self.args.refresh_cache or not self.is_cache_valid(): self.update_cache() ```
Probably better to write this as ``` python if self.args.refresh_cache or not self.is_cache_valid(): self.update_cache() ```
You can use ```required_if``` which is built into AnsibleModule instead of having your own code. Look at https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/cloudstack/cs_storage_pool.py#L489 as a random example of using that.
This looks needlessly generic. why not just do: ``` python if op == 'get_password': get_password([...]) elif op == 'create_host': create_host([..]) ``` If you think you're going to have a lot of operations, you can have a lookup table: ``` OPERATIONS = {'get_password': get_password, 'create_host': create_host} method = OPERATIONS[op]([...]) ``` but for just a few operations I'm not sure I would do that... it obscures what the code is doing in any given situation to code it like that.
Since the very first thing that both of the above do is create a ```PasswordManagerPro``` object and then they just lightly wrap a method call on that object, it seems like they should really be integrated into the methods they're calling.
It's a list of elements not the first element.
Since the very first thing that both of the above do is create a ```PasswordManagerPro``` object and then they just lightly wrap a method call on that object, it seems like they should really be integrated into the methods they're calling.
It's a list of elements not the first element.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
This should be max.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Please don't use `\`, there are better ways Also use proper indent
Please don't use `\`, there are better ways Also use proper indent
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
By the way, you don't need `else:`, since this will be evaluated anyway.
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
1. Does not work in python 3. 2. Sorting is invalid. Sorting must be done with _sort_formats.
1. Does not work in python 3. 2. Sorting is invalid. Sorting must be done with _sort_formats.
You could create a helper method: ```python def _test_ipsubnet(self, ipsubnet_args, expected_result): self.assertEqual(ipsubnet(*ipsubnet_args), expected_result) # and then reuse it by looping over test data: def test_ipsubnet(self): test_cases = ( (('1.1.1.1/25', ), '0'), ... (('192.168.144.5', '18', '-5'), '192.168.144.0/27'), ) for args, res in test_cases: self._test_ipsubnet(args, res) ```
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Why must batch size be one? Just looking for clarification because I'm not 100% sure what this case is checking for because dense prediction tasks including FCNs can train with batch sizes >1.
Not sure if this is the best way to refer to the module... what happens if we don't run nosetests form the right directory? Maybe relative imports are what we want to use here (since the unittest code is python2.6+). I think it's `from ... import swap_stdin_and_argv`)
You should be able to use `self.vmware_test_platform` here.
You should be able to use `self.vmware_test_platform` here.
I don't think this is appropriate here. check_mode for this module should check what the setting is currently and return changed=True or changed=False depending on whether it matches what was specified in the option value.
No need to parametrize with just one case.
```suggestion assert ansible_json_encoder.default(test_input) == expected ```
It probably makes sense to test that the exception reason also matches expectations
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
This should be regular text. ```suggestion - Creates or destroys a data migration services subnet group. ```
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
You don't need a lambda here. Also, don't break lines with `\`.
This can instead be `continue` and let the `else` unnest.
`current_version` could be mentioned in the error message.
Sometimes you have a trailing dot (here), sometimes not (previous one). I guess you should pick one style and stick to it :)
`return not owner or owner == publication_info['owner']` could be used.
This should be regular text. ```suggestion - Creates or destroys a data migration services subnet group. ```
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
This can instead be `continue` and let the `else` unnest.
Looks like dead code here
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
Going to nitpick style a bit, but how about: ```python url = '%s/api/v2/hosts' % self.foreman_url if want_params: url += '?include=all_parameters' return self._get_json(url) ```
This can instead be `continue` and let the `else` unnest.
You don't need to specify this field if there is no return output
You don't need to specify this field if there is no return output
`api_token` is a required parameter
You don't need to specify this field if there is no return output
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
And remove this afterwards.
This will break for Windows users. Check how we construct file paths elsewhere (e.g. in `backend/common.py`).
You don't need a lambda here. Also, don't break lines with `\`.
should be self.forward.
You don't need a lambda here. Also, don't break lines with `\`.
I believe the plan is to do a single PR to address this in all Postgres modules
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Also, please don't use `\` to break up lines
You don't need to specify this field if there is no return output
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
Shouldn't this be using `.get()` ```suggestion inventory = self._cache.get(self.cache_key)[url] ```
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
i would add the aliases to the options in this way: option1 (alias1, alias2), option2 (alias1, .... Or simpler to direct them to `ansible-doc -l <module name>` for 'valid options', specially if you consider 'sub options'
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
Remove excessive verbosity. This fits well on a single line.
both are valid tests, i don't see why you need to eliminate the existing one
Breaks if `node_views_class` is `None`.
DRY 105, 107.
If the output should include the URL, we would do that generally. Instead, pass something useful (like the user name or so) into the second parameter.
If the output should include the URL, we would do that generally. Instead, pass something useful (like the user name or so) into the second parameter.
If the output should include the URL, we would do that generally. Instead, pass something useful (like the user name or so) into the second parameter.
Please use 'msg' for returned messages, this is a standardized return value.
Read coding conventions on optional fields.
- `'%s/' % show_id` part is also repeated twice. - as i said before, the `info` request should not be break the extraction it fails.
Read coding conventions on optional fields.
Format your docstrings like other docstrings in the codebase
This is a private function (starts with an underscore) so I'd hope we could move this without having to leave a stub for backwards compatibility. If you want to remove the stub in a separate commit/PR just in case, though, I can live with that.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
Similarly, ```if tc['skip'].get('i')```
(Similarly, mark any string that you are going to call decode on with as a b"string".)
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Looks like we have `distribution_release: Core` currently for CentOS. I think it would make sense to have that be `distribution_release: Stream`.
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Can you explain what this option does and why it is needed? From the implementation, it looks like this can be used to overwrite arbitrary module options, without any type checks or other sanity checks. I don't think modules should have such options.
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
works also for me :+1:
Remove superfluous verbosity.
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
This branch is never reached.
Or you could finish with: ``` result = self.playlist_from_matches(urls, playlist_id, title) if uploader_id: result['uploader_id'] = uploader_id return result ```
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
You should be able to remove a few transformations here: ``` python elif isinstance(value, tuple(chain(integer_types, (float, bool, NoneType)))): ```
Missing a space between "argument" and "has". Also tell users to use the `unit_forget_bias` argument instead.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
Simplify error reporting as below, or skip this check and just let the `_html_search_regex()` calls raise the exception? ```suggestion for token in ('apiToken', 'widgetId'): if token not in rf_token_js: raise ExtractorError( 'Unable to fetch ' + token, expected=True) ```
Simplify error reporting as below, or skip this check and just let the `_html_search_regex()` calls raise the exception? ```suggestion for token in ('apiToken', 'widgetId'): if token not in rf_token_js: raise ExtractorError( 'Unable to fetch ' + token, expected=True) ```
small typo ```suggestion # table availability in check_src/dst. ```
A few stats with this change compared to devel and this PR (100 hosts and 1 debug using jinja2): ``` ==> devel.txt <== 765719 function calls (758704 primitive calls) in 4.990 seconds ==> 45568.txt <== 651530 function calls (644525 primitive calls) in 4.862 seconds ==> glob_get_paths.txt <== 651709 function calls (644704 primitive calls) in 4.881 seconds ``` ``` devel.txt 11: 3648 0.104 0.000 1.195 0.000 loader.py:423(all) 174: 2 0.000 0.000 0.030 0.015 loader.py:546(all) 45568.txt 16: 3648 0.069 0.000 0.734 0.000 loader.py:423(all) 218: 2 0.000 0.000 0.016 0.008 loader.py:549(all) glob_get_paths.txt 17: 3648 0.051 0.000 0.724 0.000 loader.py:423(all) 211: 2 0.000 0.000 0.017 0.009 loader.py:549(all) ``` ``` devel.txt 18: 2850 0.015 0.000 0.724 0.000 glob.py:9(glob) 45568.txt 451: 38 0.000 0.000 0.002 0.000 glob.py:9(glob) glob_get_paths.txt 426: 38 0.000 0.000 0.002 0.000 glob.py:9(glob) ```
Append outside the loop.
nitpick: I think this could have less nesting. ```suggestion if finder is None: return None if toplevel_pkg == 'ansible_collections': return finder.find_spec(fullname, path=[self._pathctx]) return finder.find_spec(fullname) ```
This line is too long. Max line length allowed in Ansible is 120 characters.
No, this should not be global at least due to presence of potentially case sensitive parts and every regexp should not be touched either. Only those seen to be case insensitive in the wild should do.
So the suggestion I added above (copied below) works around this, if we add the following change we don't need to add the `ensure_required_libs` function or make any changes to `ensure_libs`. ```suggestion try: ensure_libs(sslrootcert=module.params.get('ca_cert')) except LibraryError as e: module.fail_json(msg=str(e)) ```
`acodec == 'none'`.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Array ellipsis is an obscure feature and not necessary here. It hinders readability
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
`'id'` is required.
Then use `enumerate()` instead.
You could replace this entire block with: ``` from distutils.version import StrictVersion return StrictVersion(host_version) >= StrictVersion('.'.join(map(str,version))) ```
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
better to move this line in else part. something like ``` if hasattr(resp, 'data_xml') or hasattr(resp, 'data_ele'): result = resp.data_xml else: result = resp.xml ```
There should be fallbacks for these values since they are more or less static.
Remove "a non-blank"
Remove "a non-blank"
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
I'm not sure about these defaults - a delay of 3 and backoff of 2 for 10 tries would mean that, to fail, this retry decorator would wait for 3069 seconds (`3 + 3*2 + 3*2*2 ....`, or `sum([3 * 2**i for i in range(10)])`) or about 50 minutes. That seems like a really long time, especially since most modules make several calls. A better default might be 4 tries, for a total default wait time of 45 seconds and having a max of, say, a minute between tries. That way, if someone wanted 10 tries it would only take about 7.5 minutes to fail.
You are correct, I didn't look at all the code and assumed assumed there was a break on match, its last, not first, found wins ... which makes me want to rewrite this section. Not only can we have multiple package managers (add fact with list), but the traversal can be reversed + break to make it perform better. Another 'optimization' would be to create diff lists for OS families.
camel2snake should indeed handle NotificationARNs properly (#25105)
~~typo result~~ fixed
~~typo result~~ fixed
remove un-used variable.
remove un-used variable.
remove un-used variable.
`(?P<id>[^/]+)` should not be mandatory, the information needed for extraction rely only on `show_id`(for API calls).
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
`(?P<id>[^/]+)` should not be mandatory, the information needed for extraction rely only on `show_id`(for API calls).
blank line after your import
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Just use `replace` or `re.sub`.
Trailing whitespace on a blank line is failing the PEP8 checks.
Breaks if not arr.
I'm glad I could help :)
Must be `int`.
Probably the same with `--label` instead of `--uuid` here.
@willthames bcoca asked me to look at your problem. I think that we want to use to_native() here and we probably want to use errors='surrogate_or_strict' as well. to_native() converts the string into the type which an undecorated string literal has on that version of python. That type is called "str" on both python2 and python3 but it's a byte string on python2 and a text string on python3. It will have the following benefits: * It's the most compatible since it's the same type as str on both platforms. (It just has better defaults and more flexible error handling than using str()). * For most module_utils code, we use native string types right now so that a module author can mostly write idiomatic python and it mostly just works. They don't run into a problem combining byte and text type. (They do have to worry about it when they deal with an external API which needs a specific type but those are not as common so it's easier to deal with those when the time comes and not worry the rest of the time).
move this into main so you only need to define on load instead on every call
For clarity -- in this PR, currently int(1.9) ==> 1 and int("1.9") ==> TypeError
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
I believe the plan is to do a single PR to address this in all Postgres modules
That makes perfect sense to me.
In validation or test, there is no concept of epoch, so that seems OK to me.
> Speaking of which, I should submit a PR to add Python 3.5 to tox.ini and .travis.yml #12627.
Just leave it out, we'll think of something later.
Just leave it out, we'll think of something later.
Just leave it out, we'll think of something later.
Typo in the help message
You could append the `name` parameter here (using something like `in module.params['member'] + [module.params['name']]`).
Typo in the help message
Ok, not sure why this one is still open.
```suggestion assert expected == "exception" ```
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
fixture with load_json
Not critical, but `for num_started, node in enumerate(consumer.nodes, 1)` would probably be more idiomatic.
I think adding a timestamp field would be nice.
No longer used.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Please raise a `NotIplementedError` when the use case is not supported yet.
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Please raise a `NotIplementedError` when the use case is not supported yet.
Right, better to use `then_expression` etc.
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
Please remove this example, since I would consider this usage as not recommended.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
` // <1>` is unnecessary.
~~typo result~~ fixed
Is this function used to retrieve large files? If so, I suggest redirecting directly to the file, instead of using PIPE -> 'stdout' variable and writing to the file only then.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
The security group rule and the trunk are not present in any of the resources' contents here: https://github.com/openstack/openstacksdk/tree/master/openstack/cloud, consequently using the `cloud.get_<resource>` call fails. Instead the `could.network` call can be used.
```suggestion content_library_info: ``` or `library_info` would be more apt.
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
Is this function used to retrieve large files? If so, I suggest redirecting directly to the file, instead of using PIPE -> 'stdout' variable and writing to the file only then.
This doesn't allow the caller to cancel downtime by scope. _get_downtime returns an empty dictionary when id is not specified. It'd be great if this was changed to require id or scope instead of just id.
IIRC should be just `raise` to re-raise the existing error
IIRC should be just `raise` to re-raise the existing error
If VMM domain, add support for "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
```suggestion # just get value from attribute itself as normal ```
Please remove this example, since I would consider this usage as not recommended.
```suggestion # just get value from attribute itself as normal ```
s/run the/run in the/
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
Not sure if it would be useful for something later, but should we have a class attr with the name of the plugin in it? Some plugin types do this others don't.
both are valid tests, i don't see why you need to eliminate the existing one
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Why not just use ``` video_id = self._match_id(url) player_page = self._download_webpage(url, video_id) ```
Why not just use ``` video_id = self._match_id(url) player_page = self._download_webpage(url, video_id) ```
Why not just use ``` video_id = self._match_id(url) player_page = self._download_webpage(url, video_id) ```
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
These 2 lines could be replaced by: ```python uploader_url, uploader_id = uploader_data[0][0:2] ```
What if some apps in the list `name` start with `https://` and some don't, with the `use_remote=False` case those that don't start with `https://` to fail installation? If so, there should be some book keeping done here to handle that.
What if some apps in the list `name` start with `https://` and some don't, with the `use_remote=False` case those that don't start with `https://` to fail installation? If so, there should be some book keeping done here to handle that.
What if some apps in the list `name` start with `https://` and some don't, with the `use_remote=False` case those that don't start with `https://` to fail installation? If so, there should be some book keeping done here to handle that.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
You don't need to specify this field if there is no return output
You don't need to specify this field if there is no return output
```suggestion matches = [re.search(r'^[ #]+- env: T=(?P<group>[^/]+)/(?P<params>.+)/(?P<number>[1-9][0-9]?)$', line) for line in self.shippable_yml_lines] ```
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
Is the support for multiple pids only for clean up? Since the code checks for a fixed control file, I was thinking we expect only one process at a time.
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
Why don't you just encode suffix like `u'-\u00c5\u00d1\u015a\u00cc\u03b2\u0141\u00c8'.encode('utf-8')` and for the no_temp_unicode override just do `suffix = b'-ansible'`? No need for this check which is arguably more confusing.
task_uuid seems unused
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
Some more: avc2, avc3, avc4. These would be enough.
Some more: avc2, avc3, avc4. These would be enough.
`dynamic` is not a very descriptive name. It looks like what you want is to pass the output both to a file and to stdout. In general, this problem has already been solved by `tee`.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Please remove this example, since I would consider this usage as not recommended.
I don't think this is appropriate here. check_mode for this module should check what the setting is currently and return changed=True or changed=False depending on whether it matches what was specified in the option value.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Instead of equality, I think you want to check for `isinstance` here.
This means that if the first line fails, `view_count` is not a declared variable and therefore the following will fail - exactly the opposite of what you want.
In this case `quality` is determined from other attributes, like the bitrate or the resolution. There's no need to specify `quality` values explicitly.
The method does nothing, should not this method be removed ? * [X] Done
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
The method does nothing, should not this method be removed ? * [X] Done
[Correct extraction delegation](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/lcp.py#L76).
The method does nothing, should not this method be removed ? * [X] Done
Why not simply compare contents, instead of computing sha1 of both first? Since you read both into memory, that's more efficient :) Also: it currently fails under Python 3: ``` Traceback (most recent call last): File "../bin/dump_config.py", line 84, in <module> sys.exit(main(sys.argv[:])) File "../bin/dump_config.py", line 72, in main sha1_old = sha1(open(output_name).read()).hexdigest() TypeError: Unicode-objects must be encoded before hashing ```
Why not simply compare contents, instead of computing sha1 of both first? Since you read both into memory, that's more efficient :) Also: it currently fails under Python 3: ``` Traceback (most recent call last): File "../bin/dump_config.py", line 84, in <module> sys.exit(main(sys.argv[:])) File "../bin/dump_config.py", line 72, in main sha1_old = sha1(open(output_name).read()).hexdigest() TypeError: Unicode-objects must be encoded before hashing ```
This needs to pass `return_docs=True` for return docs.
Shouldn't this be using `.get()` ```suggestion inventory = self._cache.get(self.cache_key)[url] ```
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
colors should all be configurable
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
This will fail if `len(data) == 1`, which you explicitly allow above.
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
```not (foo is None)``` => ```foo is not None```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
*be a string
*be a string
Lists also have .extend() which might be what you need here
```suggestion - name: Install python package using a proxy # Pip doesn't use the standard environment variables, please use the CAPITALIZED ones below ```
Don't do this manually use `_download_webpage_handle`
Not catching non-200 responses.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
you could use `scriptRequest.setJsonEntity`
Don't do this manually use `_download_webpage_handle`
Ah never mind, I forgot that the `if response` handles when the recursive URL lookup might have ended.
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
I really hate that is the case, we never got a real good standard around 'number of v' to use for each case, most connections print all output at 3, winrm is one of the few that goes higher
I really hate that is the case, we never got a real good standard around 'number of v' to use for each case, most connections print all output at 3, winrm is one of the few that goes higher
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
use ```from ansible.module_utils.vmware import get_cluster```
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I think this should be hostname, since hostname defaults to dest ([line 825](https://github.com/ansible/ansible/pull/14246/files#diff-c2e371537339bbab5d9d0cc5d6cb7adcL825)) if it isn't defined. That way this maintains consistency with the surrounding code. Should hostname be defined, I think it might be confusing. That was my only feedback though, this looks good.
Please keep 0 return code. This is a way of communicating success to an OS
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
You should use `AnsibleAWSModule`, it has a lot of helpers around boto3
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
My bad. Could you please add this to vmware.py
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
Unclear why we're mixing some parameter substitution inline, and leaving others to the final substitution with the `args`. Made it confusing to figure out what was going on with the `JMX_PORT`, which looked like it had been lost since it wasn't in `args` any longer.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
same here, we really dont want to test the particular setting, just that both the default (dynamic template) and the nii entry are correctly parsed.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
1. Single quotes. 2. `expected`.
1. Single quotes. 2. `expected`.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Do not change the order of extraction scenarios.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
@bcoca noted the use of state=info in today's meeting... I think a year ago, or so, we discussed using a separate module named with an _info suffix (like sophos_utm_info.py) for things that are just for gathering info about something which doesn't relate to the host it is run on. (You also thought you might turn that portion into a lookup plugin. That would also be fine. The difference is just that a lookup can only be run o nthe controller whereas a module can be used on either the controller or a remote host).
If we're just testing broker compatibility I don't think we even need this part of the test.
Use `self.url_result(inner_url, 'Generic')` instead.
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Simplest backward compatible fix is (untested): ``` aws_session_token = config.get('credentials', 'aws_session_token', config.get('credentials', 'aws_security_token')) ``` I can't find any evidence that boto (as opposed to boto3) supports aws_session_token, so best to support both for people using the session token with boto.
Simplest backward compatible fix is (untested): ``` aws_session_token = config.get('credentials', 'aws_session_token', config.get('credentials', 'aws_security_token')) ``` I can't find any evidence that boto (as opposed to boto3) supports aws_session_token, so best to support both for people using the session token with boto.
this should use the new API without hardcoded id now
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
As exclude_tags could be an empty set, I would directly check `if exclude_tags and set(server_tags).intersection(exclude_tags)`. This way, it should also work when exclude_tags and server_tags are empty.
Please add our boilerplate to the top of this file. One of those pieces of boilerplate makes all classes defined in the file new-style classes. Without it, a class definition which doesn't inherit from object is an old-style class. ``` from __future__ import (absolute_import, division, print_function) __metaclass__ = type ```
@bcoca noted the use of state=info in today's meeting... I think a year ago, or so, we discussed using a separate module named with an _info suffix (like sophos_utm_info.py) for things that are just for gathering info about something which doesn't relate to the host it is run on. (You also thought you might turn that portion into a lookup plugin. That would also be fine. The difference is just that a lookup can only be run o nthe controller whereas a module can be used on either the controller or a remote host).
Please add our boilerplate to the top of this file. One of those pieces of boilerplate makes all classes defined in the file new-style classes. Without it, a class definition which doesn't inherit from object is an old-style class. ``` from __future__ import (absolute_import, division, print_function) __metaclass__ = type ```
Recursion should be replaced with plain loop.
Where did you get this construction from? It's quite outdated, and we'd be happy to update it ;)
Recursion should be replaced with plain loop.
Recursion should be replaced with plain loop.
Recursion should be replaced with plain loop.
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
Ah, i'd expect a bool to always be True/False, if that is not the case (no time to test really right now :)), then indeed, this needs to stay (and this goes for my other bool remarks)
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
probably inside the `if` instead of before since it's kind of confusing to see this for a test that isn't going to actually read the DLQ
Simplier: ```python password.os.path.exists = lambda x: x == to_bytes('/path/to/somewhere') ```
required=False, default=None is default for an argument
Since changed will always be True to get here you can return True and remove the changed variable assignments.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Please remove this example, since I would consider this usage as not recommended.
We generally call it "KTF"
Raise `AnsibleCallbackError`, which can be imported from `ansible.errors`.
Move flags into regex.
If VMM domain, add support for "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
This is not true at the moment.
`merge_dictionaries` is called twice and each time with 2 dictionaries, this method could be removed and `dict.update` could be used directly.
Isn't `raise` missing there ? Calls to `str` are useless.
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('Europe/Helsinki')), '2019-06-15T14:45:00+01:40'), ```
`findGroup` and `findProject` are repeated in a few places, worth moving out into `module_utils`? There's a `gitlab` library out there already that won't be needed anymore, you could use that for generic stuff.
You should be able to use `self.vmware_test_platform` here.
If you use to_text(xxx, errors='surrogate_or_strict') it won't throw exceptions.
My only suggestion is that I think it could be easier in the long run to do the following instead of duplicating the transaction logic, but at the same time the current code is saving cycle by not evaluating the `if module.check_mode` conditional multiple times so it's purely preference and I don't care to block the PR on it. ð ```python if state == "present": if not shard_find(client, shard): if not module.check_mode: shard_add(client, shard) changed = True else: changed = False elif state == "absent": if shard_find(client, shard): if not module.check_mode: shard_remove(client, shard) changed = True else: changed = False ```
My only suggestion is that I think it could be easier in the long run to do the following instead of duplicating the transaction logic, but at the same time the current code is saving cycle by not evaluating the `if module.check_mode` conditional multiple times so it's purely preference and I don't care to block the PR on it. ð ```python if state == "present": if not shard_find(client, shard): if not module.check_mode: shard_add(client, shard) changed = True else: changed = False elif state == "absent": if shard_find(client, shard): if not module.check_mode: shard_remove(client, shard) changed = True else: changed = False ```
I think it's confusing having enabled and present
Please fix: '... if it doesn't exist:'
'exists' -> 'exist'
Please fix: '... if it doesn't exist:'
I think it's confusing having enabled and present
Note that if all tower modules use this same idiom... Many of those should probably remove claims of check mode support from their arg spec until they implement it as well... But that would definitely be a different PR ;-)
These calls too.
Tests shouldn't be invoked directly, so this isn't needed.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Tests shouldn't be invoked directly, so this isn't needed.
Tests shouldn't be invoked directly, so this isn't needed.
Note that if all tower modules use this same idiom... Many of those should probably remove claims of check mode support from their arg spec until they implement it as well... But that would definitely be a different PR ;-)
```suggestion Test that the returned value for timezone consists of only uppercase ```
Probably we need something similar for all the `module.run_command()` stuff. As I don't know if they fail gracefully by themselves. Easy to test though.
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
Check from line 177-181 is taken care of in cliconf run_command api. I think these lines can be replaced with `item['output'] = 'text'`
both are valid tests, i don't see why you need to eliminate the existing one
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
If `display.verbosity` is falsy, this results in `python anisble_connection '' <pid> <uuid>` and the extra parameter isn't understood to be intended as a flag. I think this (and the above change to verbosity) should fix the issue? ```suggestion [python, ansible_connection, *verbosity, to_text(os.getppid()), to_text(task_uuid)], ```
This won't work as expected in case of `fatal=True` and `_json_ld` failure.
no, if the variable is set but empty, you should empty out the options
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
``` pbm_object_ref = pbm.ServerObjectRef(key=str(virtual_machine._moId), objectType="virtualMachine", serverUuid=self.vc_si.content.about.instanceUuid) ```
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
Also, you don't actually need these error messages after `assert` since this is a unit test
option should deal with the case the dependencies are not avaiable and give a warning.
option should deal with the case the dependencies are not avaiable and give a warning.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
This should probably just be done with a mutually exclusive group in the CLI argparse declaration.
I don't think this is useful in this example. Please remove.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
No need for this check, this is already checked in `_sort_formats`.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
this could just return ```suggestion return not self._raising ```
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Initialized must go first.
Another regex that can be precompiled.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Initialized must go first.
Another regex that can be precompiled.
Another regex that can be precompiled.
Another regex that can be precompiled.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
If we're just testing broker compatibility I don't think we even need this part of the test.
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
This is pre-existing in the code but there should be a check whether module_args is None otherwise this loop will traceback. I think it should be fixed in the argument_spec, I'll make a note there.
We'll keep this format around not only for backward compatibility, the array form is just another format.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
do not use the program title as a description.
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
This is not unicode frienly, see `INVALID_VARIABLE_NAMES` in `lib/ansible/constants.py` , we had to update to allow for unicode chars .. also you should be able to reuse
Should check for a list.
This is not unicode frienly, see `INVALID_VARIABLE_NAMES` in `lib/ansible/constants.py` , we had to update to allow for unicode chars .. also you should be able to reuse
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
Check for `compat_str` also.
Should check for a list.
Lines don't need to be wrapped so short since we allow up to 160 characters.
Lines don't need to be wrapped so short since we allow up to 160 characters.
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
Just assign the correct value to `video_id` later.
failed POST operation against ...
Just assign the correct value to `video_id` later.
This makes no sense - you already have it in `url`.
Please consider the same for `manifest_url`. See my explanation in #30703.
Please consider the same for `manifest_url`. See my explanation in #30703.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Use literals rather than constructors. ```suggestion set_commands, delete_commands, invalid_commands = [], [], [] updates, unmanaged_config = [], [] ```
Remove excessive verbosity. This fits well on a single line.
this might change in the future, this is not necessary as you're checking for error in response page.
Remove excessive verbosity. This fits well on a single line.
`title` is required, so use the original pattern `item.get('title') or item['alias']` Or if you want to make the ensuing crash report clearer, `dict_get(item, ('title', 'alias')) or item['title']`
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
Playlist title is optional, description breaks.
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
try not to break the extraction when some info is missing(ex: if a `season` doesn't have `episodes`).
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
Part in the middle should not be greedy. Also use `_parse_html5_media_entries` as main path.
We generally call it "KTF"
Never mind, I now see the change to galaxy further down.
Should likely be `prefix, sep, key`
we should not be adding a python dependency on ordereddict here, as python2.7 can also use ordereddict from collections: https://docs.python.org/2/library/collections.html#collections.OrderedDict This also means, that python2.7 users now need an additional python dependency installed.
This method definition shares most of its functionality with `get_request` method, which indicates that the common functionality (common parameters, error handling, etc.) should be extracted into private method.
This method definition shares most of its functionality with `get_request` method, which indicates that the common functionality (common parameters, error handling, etc.) should be extracted into private method.
Remove useless code.
Missing `"..."` `set_fact: pubkey_string="{{ pubkeys.results | map(attribute='ansible_facts.pubkey_list') | join('\n') }}"`
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Did you even bother to run your code? `self.params.get('date_playlist_order')` will always be `None` thus `break` will never trigger since [you did not forward it to `params`](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/__init__.py#L310-L429). Even if you did, it **won't work** (repeating this 3rd time already) if `daterange` is an **inner interval** inside `daterange`. In such case if the first/last video (depending on the order) does not belong to `daterange` extraction will stop on it and won't process further items that may belong to `daterange`.
boto_profile should be aws_profile, but rather than passing these explicitly, it seems like other lookups use **kwargs instead. If you change that to **kwargs and if you use the doc fragment for credentials, then you'd need: `self.set_options(var_options=variables, direct=kwargs)` below and then you can access any of the options with `self.get_option(optionname)`.
Did you even bother to run your code? `self.params.get('date_playlist_order')` will always be `None` thus `break` will never trigger since [you did not forward it to `params`](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/__init__.py#L310-L429). Even if you did, it **won't work** (repeating this 3rd time already) if `daterange` is an **inner interval** inside `daterange`. In such case if the first/last video (depending on the order) does not belong to `daterange` extraction will stop on it and won't process further items that may belong to `daterange`.
Please add spaces around the equal sign.
```suggestion assert ansible_json_encoder.default(m) == expected ```
Please add spaces around the equal sign.
deepcopy only if required, move it inside the conditional.
Again, this doesn't look like an availability check.
Again, this doesn't look like an availability check.
Again, this doesn't look like an availability check.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Again, this doesn't look like an availability check.
I wouldn't exactly call a dictionary `list`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Also, please don't use `\` to break up lines
Please use `msg` instead of `result`. Also the standard casing for both parameters as well as return values is snail_case. So it would become `deploy_key` instead of `deployKey`.
PEP8: spaces around operators
Please use `msg` instead of `result`. Also the standard casing for both parameters as well as return values is snail_case. So it would become `deploy_key` instead of `deployKey`.
`del` is a builtin, not a function. These parens don't have to be here
Use code markers around `put()`
Wrong. Extractor key is `Vier`.
`compat_urlparse.urlparse` to extract query from original url. `update_url_query` to pack into new URL. Do not pack if original URL is used.
small typo ```suggestion # table availability in check_src/dst. ```
`raise` is missing. Call to `str` is useless there.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
self.act_fn => self.activation (unless self.activation is reserved already)
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I'd go for underlining.
Use `idx, html_entry`.
looks like there are common options for all graylog modules, Shared code are located in lib/ansible/module_utils (note that this must not be GPL here). But this can be done later on. Not a blocker, just a hint.
here's the definition of changed: https://github.com/ansible/tower-cli/blob/master/tower_cli/resources/setting.py#L136 I might have to come back to look at this later for the deeper questions here
*be a string
-1 to ignoring this. There is a simple way to fix this for review process, though... Disable check mode in the argument spec. Then you can fix the module so that check mode does the right thing later.
@wwitzel3 started this pattern. Check mode for tower modules doesn't do anything action-specific. We should track this in another issue.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
both are valid tests, i don't see why you need to eliminate the existing one
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Single quotes. `item` is already a string.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
so this assertion looks incorrect, i would expect and empty string as the ssh args
so this assertion looks incorrect, i would expect and empty string as the ssh args
so this assertion looks incorrect, i would expect and empty string as the ssh args
B is added in the constructor if we remove the NT check.
```suggestion return b'\r\n'.join(to_bytes(line, nonstring='passthru') for line in result) ``` (and import `to_bytes`)
```suggestion return b'\r\n'.join(to_bytes(line, nonstring='passthru') for line in result) ``` (and import `to_bytes`)
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Fair engough. Then, if I haven't overlooked anything, there is no need to pass `privatekey` to `_check_signature()` as you can call `csr.verify(self.privatekey)` directly.
```suggestion - name: Install python package using a proxy # Pip doesn't use the standard environment variables, please use the CAPITALIZED ones below ```
i've seen plenty of 'dummies', i just have not seen a pattern to them.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
Please consider the same for `manifest_url`. See my explanation in #30703.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
```suggestion return ['%s=%s' % (k, v if v is not None else "") for k, v in options.items()] if options else [] ```
```suggestion return ['%s=%s' % (k, v if v is not None else "") for k, v in options.items()] if options else [] ```
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
self.act_fn => self.activation (unless self.activation is reserved already)
215-216 can be changed into `elif self.state == 'present':`
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
222, 223 and 224 can be changed into `elif self.state == 'present' and not snapshot_exists:`
222, 223 and 224 can be changed into `elif self.state == 'present' and not snapshot_exists:`
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```suggestion return ['%s=%s' % (k, v if v is not None else "") for k, v in options.items()] if options else [] ```
```suggestion return ['%s=%s' % (k, v if v is not None else "") for k, v in options.items()] if options else [] ```
Just leave it out, we'll think of something later.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Wrapping the entire `display` method feels like a pretty long lock duration if the only thing we really care about is preventing concurrent/overlapping writes to the underlying FDs- it's probably not a huge deal in practice today, but it does increase the likelihood of a re-entrant deadlock if code in this method ends up triggering another display write.(esp since it's not an rlock). It's definitely possible, since we're calling our `to_bytes` et al, which can end up calling a custom `__repr__` on a non-string object among other things. Any reason not to just move the lock to explicitly surround the actual FD write? That also eliminates the need for the `nullcontext` moving parts, and most potential future weirdness during the worker setup if the lock were held by another thread when a fork occurred, then something in the worker object setup (ie pre `run` code, imports, etc) tried to call `display` (which would hang with the code as-is since it would block acquiring the lock). If you wanted to be *really* tinfoil-hat about it, you could change it to either an `RLock` or a `multiprocessing.Lock` instead, which would make it (IIRC) a shared semaphore and actually allow it to function during that setup window if it needed to, but just shortening the lock duration to the write itself cuts way down on the problem surface area.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
I do think this could be useful for any module (not just cloud modules).
It's already stripped: ```suggestion (PODMAN_OUTPUT, ''), ```
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
we really need something generic.... getting complex :-)
```suggestion query=dict(type='list', elements='str'), ```
There is always only one video on the page thus you should take first entry and return as regular info dict.
There is always only one video on the page thus you should take first entry and return as regular info dict.
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
I know this is what it done in `load_platform_subclass()` but that looks incorrect as well.
This produces invalid results when being called in a non-english speaking country. At least for me, in germany, titles will have `, - Anschauen auf Crunchyroll` appended (which is the same phrase being cut off here, just in german) This was not the case before
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
you need to skip value from parent if include_tasks/include_role, but still inherit
you need to skip value from parent if include_tasks/include_role, but still inherit
you need to skip value from parent if include_tasks/include_role, but still inherit
There is a missing `os.path.join()` otherwise you get `TypeError: append() takes exactly one argument (2 given)`.
There is a missing `os.path.join()` otherwise you get `TypeError: append() takes exactly one argument (2 given)`.
you need to skip value from parent if include_tasks/include_role, but still inherit
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
Also, let's continue the discussion in #51939.
It's more about readability. When you see two if-branches it's different than just one and then following scenario. Plus it's less indentation, which is less important in this simple case, but in general helps to have such habit :)
I have just been told that new unit tests must use pytest and not unittest. (That should also solve the Python 2.6 problems...)
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Remove the portion that adds message as a special key. If there's modules returning message expecting it to be treated specially, change then to return msg instead
Use `'` as the quote character for consistency with the rest of the file
I'm not super comfortable making this. I think maybe instead we should add the match skipping at the `FieldParser` level. Maybe some kind of subclass that skips or something. Not sure.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
```suggestion module.fail_json_aws(e, msg="Boto failure") ``` Boto/API exceptions should use fail_json_aws
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
The convention in other connection plugins seems to be to raise an `AnsibleError` instead of `IOError`.
```suggestion module.fail_json_aws(e, msg="Boto failure") ``` Boto/API exceptions should use fail_json_aws
Omit these lines please.
This method isn't necessary.
Omit these lines please.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion Kwargs: ```
small typo ```suggestion # table availability in check_src/dst. ```
Just an empty line, could be removed for cleaner code
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
small typo ```suggestion # table availability in check_src/dst. ```
Just an empty line, could be removed for cleaner code
This can instead be `continue` and let the `else` unnest.
Please remove the `__init__` docstrings and move the `arguments` sections to the class-level docstring (applicable everywhere)
Use `'` as the quote character for consistency.
Usually we don't use the URL as `video_id`. If `video_id` is unknown yet, it's OK to use part of the URL, for example "a-housecat-a-stray-god-and-a-tail".
The user may have several hosts and only one with the datastore mounted RO. In this case, the datastore will never be picked. Could you add a not to make clear this is not the best approach.
`False` is not a valid note.
```suggestion self.module.fail_json(msg='One of vm_obj or host_name must be set when calling host_version_at_least.') ```
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Without all those connection arguments, this goes away, too
This will fail if `len(data) == 1`, which you explicitly allow above.
What happens if you have something like `a=b=c`? Then you will init the dictionary with the tuple `(a, b, c)`, which will fail. Usually you want to interpret `a=b=c` as key `a` with value `b=c`; for that, you need `metric.split("=", maxsplit=1)`.
```suggestion if 'name' in self.params: ```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Last three instance members are not used anywhere in the code and should probably be removed.
f is already at 0, the `truncate()` is uselesss.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
We usually prefer dict literals `{}` over `dict()` constructors/factories. (Although it's a holywar topic)
We usually prefer dict literals `{}` over `dict()` constructors/factories. (Although it's a holywar topic)
unused variable `input_length`
This should be regular text. ```suggestion - Creates or destroys a data migration services subnet group. ```
Please remove this example, since I would consider this usage as not recommended.
Playlist metadata must not be fatal.
Playlist metadata must not be fatal.
Playlist metadata must not be fatal.
Please remove the `__init__` docstrings and move the `arguments` sections to the class-level docstring (applicable everywhere)
This won't work as expected in case of `fatal=True` and `_json_ld` failure.
It seems there is four spaces missing (unrelated to your changes).
It seems there is four spaces missing (unrelated to your changes).
This won't work as expected in case of `fatal=True` and `_json_ld` failure.
Please add `type="str"`
(Additional whitespaceânumber of spaces not multiple of 4.)
```suggestion updates.extend(line for line in set_commands if line not in config) ```
The return value is not strictly cookies. The return value is a dictionary of headers
If data is binary and not textual, then there is a good chance that passing this through to_text will mangle the binary data. I just tested this with a wav file, and it seems to mangle it - the textual headers are intact, but the audio content is garbled. I'll try to think of an alternative for this.
no, as i said you would extract the metadata and return immediately.
To apply the side effect, use this: ```suggestion mocker.patch('ansible.module_utils.network.meraki.meraki.fetch_url', side_effect=mocked_fetch_url) ``` You'll also need to update `mocked_fetch_url` to accept args, like: ```python def mocked_fetch_url(*args, **kwargs): ```
should not break the extraction if it wasn't able to parse json data.
no, as i said you would extract the metadata and return immediately.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
The return value is not strictly cookies. The return value is a dictionary of headers
this might change in the future, this is not necessary as you're checking for error in response page.
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
~~typo result~~ fixed
1. Single quotes. 2. `expected`.
```suggestion message_text = self.get_deprecation_message(msg, version=version, removed=removed, date=date, collection_name=collection_name, warn_change=warn_change) ```
```suggestion self.module.fail_json(msg="The hostname you have set it not valid for use with vmware guest customization for Linux." ```
I'd want to see the role stay atomic and have either everything or nothing change. If the module fails, nothing should change on the system. That might either mean moving the loop into the `semanage_boolean_value` function, or supporting externally-triggered commit for the function.
```list_streaming_distributions(self, keyed=True)``` function seems to be returning dict. Shouldn't returning `list` be the erorr.
This should probably just be done with a mutually exclusive group in the CLI argparse declaration.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Your logic from the code above is: if `accept_terms` is `True`, `plan` must be specified. (That can also be modelled by `required_if`.) If you want the logic the other way around, you have to change your code (and you can't use `required_if` AFAIK).
Your logic from the code above is: if `accept_terms` is `True`, `plan` must be specified. (That can also be modelled by `required_if`.) If you want the logic the other way around, you have to change your code (and you can't use `required_if` AFAIK).
Your logic from the code above is: if `accept_terms` is `True`, `plan` must be specified. (That can also be modelled by `required_if`.) If you want the logic the other way around, you have to change your code (and you can't use `required_if` AFAIK).
If there's no reason not to, I don't mind. But a dictionary with the name as key is easier to use it in Ansible.
Your logic from the code above is: if `accept_terms` is `True`, `plan` must be specified. (That can also be modelled by `required_if`.) If you want the logic the other way around, you have to change your code (and you can't use `required_if` AFAIK).
Better to put the activation as the `activation` keyword of the layer below
Code duplication 173, 213. There is no sense to extract fields explicitly.
Please split into under 160 character length lines
`{}` doesn't work in python 2.6.
Again, this doesn't look like an availability check.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
dict comprehensions don't work in python 2.6.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
It would be awesome if buildah supported copying from a container.
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
We should probably do more here than just reraise the exception with a different type. Add a message here so it gives context about the failure. The same with the next one too.
We should probably do more here than just reraise the exception with a different type. Add a message here so it gives context about the failure. The same with the next one too.
It would be awesome if buildah supported copying from a container.
1. Single quotes. 2. `expected`.
Device id is not escaped.
Login should be in `_real_initialize`.
No. You should not shadow the original explicitly provided password.
Should this be `num_lines=2` (cf. L120)
This branch is never reached.
you should not need to checked disabled, as the plugin itself wont be called at all if true
you should not need to checked disabled, as the plugin itself wont be called at all if true
you should not need to checked disabled, as the plugin itself wont be called at all if true
```suggestion parent_ous = paginator.paginate(ParentId=parent_id).build_full_result().get('OrganizationalUnits', []) for child_ou in parent_ous: ``` You could remove the outer loop here by using the paginator's `.build_full_result()` method and retrieving the OrganizationalUnits from it.
you should not need to checked disabled, as the plugin itself wont be called at all if true
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
`False` is default.
For these 3, add expected_type `int`, eg: ```py 'width': try_get(item, lambda x: x['video']['width'], int), ``` (equivalent in effect to wrapping in `int_or_none()`).
So what? If `not enclosure_nodes` is `False` it does not mean `next_url` was obtained.
Potential reference before assignment error.
Refer https://github.com/ansible/ansible/pull/49414#pullrequestreview-180616762 The capability dict in onyx cliconf plugin can store version and other product releated information at time of connection initilaization instead of executing `show version` for every task run.
```suggestion expected_type = dict if six.PY2 else DictProxy assert type(ACTION_WRITE_LOCKS) == expected_type ```
```suggestion expected_type = dict if six.PY2 else DictProxy assert type(ACTION_WRITE_LOCKS) == expected_type ```
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Use `'` as the quote character for consistency with the rest of the file
Code markers around tuples
```suggestion NO_LOG_REGEX = re.compile(r'(?:pass(?!ive)|secret|token|key)', re.I) ``` That part wasn't used anymore anyway...
Should the default be https, if so update docs
Currently IEs are randomly sorted. I guess sorted IE names make `lazy_extractors.py` look better.
This should be a warning. Also, please use single quotes. And "backend" in one word.
Just assign the correct value to `video_id` later.
Just assign the correct value to `video_id` later.
Just assign the correct value to `video_id` later.
Mandatory data must be accessed with `[]` not `get`.
No need to escape `\`.
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
self.cache contains function `get_all_objs` which already does this, so we can reuse it directly rather than modifying `find_obj`
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
This won't work at all if starting playlist entry is not in `daterange`.
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
i've seen plenty of 'dummies', i just have not seen a pattern to them.
Breaks. Read coding conventions.
```suggestion course, video_id = re.match(self._VALID_URL, url).group('course_name', 'id') ```
Better to use `unified_strdate()`.
I would also do `not host` as `''` is both a string and not None, but i would argue still an invalid host
The Shippable CI failure is due to: ``` 2016-12-19 16:09:41 Run command: python2.4 -m compileall -fq ./lib/ansible/modules/infrastructure/stacki/stacki_host.py 2016-12-19 16:09:41 Compiling ./lib/ansible/modules/infrastructure/stacki/stacki_host.py ... 2016-12-19 16:09:41 File "./lib/ansible/modules/infrastructure/stacki/stacki_host.py", line 174 2016-12-19 16:09:41 rc = stack_r.status_code if stack_r.status_code != 200 else stack_r.status_code 2016-12-19 16:09:41 ^ 2016-12-19 16:09:41 SyntaxError: invalid syntax ``` This may also apply to line 210
`not source_url` implies `source_url == ''`.
Another (and possibly cleaner) way to do this is to use `pytest-mock`: ```python class SpiedOnTarget: @staticmethod def do_a_thing(): return None def test_empty_retry_iterator(mocker): decorate_with_no_retries = retry_with_delays_and_condition(backoff_iterator=[]) spyable = mocker.spy(SpiedOnTarget, do_a_thing) invoke_retriable = decorate_with_no_retries(SpiedOnTarget.do_a_thing) invoke_retriable() assert spyable.call_count == 0 ```
I guess this can be removed. You import sha1 locally below.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Weird. Yesterday it was working: ``` python -m youtube_dl http://mobile-ondemand.wdr.de/CMS2010/mdb/ondemand/weltweit/fsk0/75/752868/752868_8108527.mp4 [download] Destination: 8108527-752868.mp4 [download] 1.4% of 291.34MiB at 8.53MiB/s ETA 00:33 ERROR: Interrupted by user ``` But not now.
```not (foo is None)``` => ```foo is not None```
It seems like no_log and deprecation are separate things and should be handled in separate functions.
Lists also have .extend() which might be what you need here
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Prefer "standardize" (also used elsewhere) since "normalize" has a specific meaning elsewhere.
do we also want `**camel_dict_to_snake_dict(err.response)`
```suggestion if self._run_is_verbose(result): ```
ditto on removing before/after.
both are valid tests, i don't see why you need to eliminate the existing one
is it important to have 3 brokers for this test? I'm wondering if the tests would be more resilient and faster with just one broker and replica of each topic.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
```suggestion - This lookup can perform an initial login by providing C(subdomain), C(username), C(secret_key) and C(master_password). ```
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
Thanks for that note ewen. I learned something!
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
You may be able to modify sys.path, perform an import, and then restore sys.path. That will probably prevent it from causing issues for other unit tests, but I haven't verified that.
If this is not required it can be removed
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
1. What's the motivation for a wait time? Can the user just call sleep themselves? Perhaps just remove wait_time entirely. Otherwise: 2. I suggest default 0 wait time 3. don't always set wait time to 0
Looks like dead code here
We can ditch this logic block since it is not relevant to your test - it was a very specific check on the correctness of the ConsoleConsumer start command to ensure the log4j settings were correct.
It would be awesome if buildah supported copying from a container.
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
we normally use display instead of print
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
we normally use display instead of print
```suggestion query=dict(type='list', elements='str'), ```
```suggestion query=dict(type='list', elements='str'), ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Just an empty line, could be removed for cleaner code
Hmm I think this can be simpler, something like this: ```python if module.params.get('template'): entity_name = module.params.get('template') collection_service = connection.system_service().templates_service() elif module.params.get('vm'): entity_name = module.params.get('vm') collection_service = connection.system_service().vms_service() # TODO: We have to modify the search_by_name function to accept raise_error=True/False, entity = search_by_name(collection_service, entity_name) if entity is None: raise Exception("Vm/Template '%s' was not found." % entity_name) service = collection_service.service(entity.id) cluster_id = entity.cluster ```
Note though, I wouldn't add to other scripts in this PR.... it's a separate code cleanup from the main purpose of this one (to stop rebuilding already-built docs)
Note though, I wouldn't add to other scripts in this PR.... it's a separate code cleanup from the main purpose of this one (to stop rebuilding already-built docs)
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
We generally call it "KTF"
Similarly, ```if tc['skip'].get('i')```
Similarly, ```if tc['skip'].get('i')```
Use the six module that we bundle instead: ``` from ansible.module_utils.six.moves import StringIO ```
I'd lose the space here, between `%s:` and `%s`, so that we get precisely what is sent.
I'd lose the space here, between `%s:` and `%s`, so that we get precisely what is sent.
I'd lose the space here, between `%s:` and `%s`, so that we get precisely what is sent.
I'd lose the space here, between `%s:` and `%s`, so that we get precisely what is sent.
This check doesn't work as-is and raises issues when running the following playbook two times in a row: ``` --- - hosts: localhost tasks: - openssl_privatekey: path: /tmp/private.key - openssl_csr: path: /tmp/csr.csr privatekey_path: /tmp/private.key commonName: www.ansible.com ``` This is due to the fact thatthe current code relies on `expected` being an array when it could be actually None, hence raising: ``` TypeError: 'NoneType' object is not iterable ``` Here is an alternative implentation that did what was expected, feel free to modify adapt/modify/get ideas from it: ``` usages_ext = [str(ext) for ext in extensions if ext.get_short_name() == extName] if (not usages_ext and expected) or (usages_ext and not expected): return False elif not usages_ext and not expected: return True else: current = [usage.strip() for usage in usages_ext[0].split(',')] expected = [long[usage] for usage in expected] return current == expected ```
Code duplication 173, 213. There is no sense to extract fields explicitly.
```suggestion self.module.fail_json(msg='One of vm_obj or host_name must be set when calling host_version_at_least.') ```
```suggestion + to_text(err))) ```
hi Luke, I see from the code, you query the lock info and try to unlock the adoms upon logging out. however, I don't see any places where lock_adom() is called to lock a domain. if we don't explicitly lock the domain in our plugin, is it required to unlock it every time when the plugin is logging out? + @frankshen01 thanks, Link
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
The code that gets replaced by this method (in crc32 for ex), the url is downloaded to a dir local to the module source. Here, a new temp dir is created. Afaict, those could have different permissions. If the mkdtemp() result is more open than the __file__/* path, a downloaded file may be readable with different permissions. Haven't tested to see if that is a problem so would like some clarification.
Going through itertools here ends up creating both a list and a generator so it's likely slower than just returning a list. If the list is very large and your goal is to reduce memory consumption, you can use a generator expresssion instead of a list comprehension on line 322: ``` python expanded_excludes = (self._pattern_to_pkgname(self.base, p) for p in self.base.conf.exclude) ``` However, for iteration over most data, lists are faster than other iterables so it is a time-space tradeoff.
`urljoin` already does these checks.
I'd rather see this part for all extractor errors.
it is not required for the bot, there is a separate config for the bot handling. Thanks for the credit, but I didn't write a single line. Please remove me from the author list.
I think, guard-expression style would fit better here: ```python if not import_name in module_utils: display.warning('%s:%d Invalid module_utils import: %s' % (path, line_number, import_name)) continue imports.add(import_name) ```
This should be more relaxed.
```suggestion - name: Install python package using a proxy # Pip doesn't use the standard environment variables, please use the CAPITALIZED ones below ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
`return not owner or owner == publication_info['owner']` could be used.
You should be able to use `self.vmware_test_platform` here.
You should be able to use `self.vmware_test_platform` here.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
unused variable `input_length`
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
You are later multiplying with a float. This has no effect on the output
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Why don't you just encode suffix like `u'-\u00c5\u00d1\u015a\u00cc\u03b2\u0141\u00c8'.encode('utf-8')` and for the no_temp_unicode override just do `suffix = b'-ansible'`? No need for this check which is arguably more confusing.
this should be moved into the run method, as we only want this to error on running, not on loading, which will always happen if this is included in ansible. or in the hasivault class init, which gets called from run.
You should indent all the lists in this file by two more spaces to keep it the same like in all other files.
What are the plans for this class? Upon further inspection, I don't see it being used.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
Why don't you just encode suffix like `u'-\u00c5\u00d1\u015a\u00cc\u03b2\u0141\u00c8'.encode('utf-8')` and for the no_temp_unicode override just do `suffix = b'-ansible'`? No need for this check which is arguably more confusing.
Why don't you just encode suffix like `u'-\u00c5\u00d1\u015a\u00cc\u03b2\u0141\u00c8'.encode('utf-8')` and for the no_temp_unicode override just do `suffix = b'-ansible'`? No need for this check which is arguably more confusing.
they always were, most lookups don't take a dict as argument, older lookups, like this one, had created their own interfaces, most others use a 'single string' k=v space separated options (also something we are moving away from)
Not required after above `load_provider()` change
To use Constructable options you can add something like ``` self._set_composite_vars(self.get_option('compose'), item, hostname) self._add_host_to_composed_groups(self.get_option('groups'), item, hostname) self._add_host_to_keyed_groups(self.get_option('keyed_groups'), item, hostname) ``` to this method.
Could you include an integration test for the parsing failure? I know it's not a new code path, but it should be tested.
Space (" ") instead of period(" ")
`User has been created`
This line is unnecessary.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
`User has been deleted`
Something like: ``` patch --- test/units/module_utils/facts/test_collectors.py +++ test/units/module_utils/facts/test_collectors.py @@ -258,12 +258,8 @@ class TestPkgMgrFactsAptFedora(BaseFactsTest): "ansible_pkg_mgr": "apt" } - import ansible.module_utils.facts.system.pkg_mgr - ansible.module_utils.facts.system.pkg_mgr.os = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path.exists = Mock(side_effect=_sanitize_os_path_apt_get) - - def test_collect(self): + @patch('ansible.module_utils.facts.system.pkg_mgr.os.path.exists', side_effect=_sanitize_os_path_apt_get) + def test_collect(self, mock_os_path_exists): module = self._mock_module() fact_collector = self.collector_class() facts_dict = fact_collector.collect(module=module, collected_facts=self.collected_facts) ```
I think this should be using mock.patch? iirc, this can leave ansible.module_utils.facts.system.pkg_mgr monkeypatched to be a mock for the rest of the tests.
This makes no sense - you already have it in `url`.
A lot of extractors use the format "{extractor} says: {error_message}", which may be clearer to the user.
This makes no sense - you already have it in `url`.
A lot of extractors use the format "{extractor} says: {error_message}", which may be clearer to the user.
Maybe we could avoid relying a shared instance attribute? ```suggestion def login_database(): login_database.counter += 1 login_database.counter = 0 ```
What if some apps in the list `name` start with `https://` and some don't, with the `use_remote=False` case those that don't start with `https://` to fail installation? If so, there should be some book keeping done here to handle that.
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
`self._options_context` stores the context of parent options in case of nested suboptions. As the `elif` block does not have a recursive call to `_handle_options` context handling is not required here. However, context information can be added as part of error message in case this argument is part of nested sub-options (similar to other error messages in sub-option handling).
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
oh tricky i didn't noticed this typo
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
No it's part of python and should be available.
No it's part of python and should be available.
No it's part of python and should be available.
No it's part of python and should be available.
No it's part of python and should be available.
use join or print formatting, much efficient than addition: ```python required_str = '%s %s' % (required_str, route_distance) ```
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
`target_string` is missing.
`target_string` is missing.
Some more: avc2, avc3, avc4. These would be enough.
Ah, right, got it :+1:
Ah, right, got it :+1:
this creates race condition. there is a time between remove and move that the file is unavailable. I see original code did same, but we should just allow move to work as it will be an atomic operation
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
you already have `pgm_id` and `pgm_no` variables now.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
You don't need a lambda here. Also, don't break lines with `\`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
This method isn't necessary.
```suggestion elif isinstance(value, (datetime.datetime, datetime.date)): ```
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
I'd rename this and the associated CLI option to `artifacts`, since not all artifacts are coverage artifacts.
```suggestion msg_format="Error stopping project - %s") ```
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
Why not leverage .setdefault here ? ``` kwargs.setdefault('url', os.environ.get('OVIRT_URL')) kwargs.setdefault('username', os.environ.get('OVIRT_USERNAME')) kwargs.setdefault('password', os.environ.get('OVIRT_PASSWORD')) ``` ï¿¼
`if not check_rc` is not required. It can go in else part
I don't have a problem with _check_type_bytes simply calling the toplevel string_to_bytes(); no need for this method. (Wish we could do the same with pretty_bytes() but backwards compat... )
<nod> to_native() should make it be str on both Python2 and Python3.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
```suggestion # just get value from attribute itself as normal ```
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it would make the operation clearer.
should be `wrong_size`
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
you can just return from inside these cases and avoid the local var / null initializer problem.
should be self.forward.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
+1 this isn't used anywhere
CI failure due to missing newline at end of file: ``` 2017-02-02 22:37:29 ERROR: PEP 8: lib/ansible/modules/windows/win_git.py:72:2: W292 no newline at end of file (current) ```
I'm ok with this change, however the additional formatting changes should be reverted. The current formatting meets our code standards.
CI failure due to missing newline at end of file: ``` 2017-02-02 22:37:29 ERROR: PEP 8: lib/ansible/modules/windows/win_git.py:72:2: W292 no newline at end of file (current) ```
Use markdown format for links
just return pm.encrypt(password, user) != current_role_attrs['rolpassword']:
just return pm.encrypt(password, user) != current_role_attrs['rolpassword']:
Break the line after the `(` to unify the style across the file.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
just return pm.encrypt(password, user) != current_role_attrs['rolpassword']:
Please use lowercase variable names.
This adds a lot of complexity. If we wait for the queue to be empty, then there is no batch getting computed so it is safe to modify.
Note that this line was only added recently (https://github.com/ansible/ansible/pull/41846/files) for Ansible 1.7 development branch, i.e. it has not been added to a release. So your change should be safe.
Cause it's an **utility function** and it's used in other places you've broken with this change.
If you use to_text(xxx, errors='surrogate_or_strict') it won't throw exceptions.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
This should be a `ValueError` (never raise `Exception`).
When you don't refer to the fixture return value, it's better to inject it via `usefixtures` so that there's no unused argument in the function. Also, the name is misleading. It's being injected into the test functions and it looks like the returned object is an instance of `BaseFactCollector` while in fact, it's a dict. You could improve this as follows: ```suggestion @pytest.mark.usefixtures('fake_now') def date_facts(monkeypatch): """Return a predictable instance of collected date facts.""" ```
```suggestion assert isinstance(wrap_var(['foo']), list) ```
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Will's new hit song, "99 problems and I *thought* I committed a fix to some of them". Thanks!
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
This will throw an exception every time when a server is down. When glusterfsd is down the output looks like this: Brick 10.70.43.200:/mnt/engine Status: Transport endpoint is not connected Number of entries: - And you'll be trying to do int('-') which will throw ValueError. And the module throws error: fatal: [10.70.42.25]: FAILED! => {"changed": false, "msg": "Invalid heal status option."} in the function main.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This will throw an exception every time when a server is down. When glusterfsd is down the output looks like this: Brick 10.70.43.200:/mnt/engine Status: Transport endpoint is not connected Number of entries: - And you'll be trying to do int('-') which will throw ValueError. And the module throws error: fatal: [10.70.42.25]: FAILED! => {"changed": false, "msg": "Invalid heal status option."} in the function main.
```suggestion possible_names.extend([context.redirect_list[-1], context.plugin_resolved_name]) ```
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
Could you clarify what's happening by adding an example 2-line CSV file? I think that would improve the docs.
we really need something generic.... getting complex :-)
should be self.forward.
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
This should not be moved. They're libraries from the current project so go below the imports for stdlib and third party libraries.
Now this can just point to the new FAQ entry.
Please use 'msg' for returned messages, this is a standardized return value.
Please remove this example, since I would consider this usage as not recommended.
There are added empty lines. Please remove them.
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
There are added empty lines. Please remove them.
Please remove this example, since I would consider this usage as not recommended.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
Py2.6 compat (!): ```suggestion 'requestId': '{0}_{1:04}'.format(now, rand), ```
Hmm, doesn't seem like this is correct. >version ['1', '0', '0-SNAPSHOT'] major_minor ['1', '0'] Extracting ['tar', 'xf', '/Users/ijuma/src/kafka/core/build/distributions/kafka_2.11-1.0.0-SNAPSHOT-site-docs.tgz', '--strip-components', '1'] Traceback (most recent call last): File "./release.py", line 235, in <module> command_stage_docs() File "./release.py", line 227, in command_stage_docs cmd('Extracting ', 'tar xf %s --strip-components 1' % docs_tar, cwd=os.path.join(kafka_site_repo_path, docs_version(version))) File "./release.py", line 108, in cmd output = subprocess.check_output(cmd, *args, stderr=subprocess.STDOUT, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 566, in check_output process = Popen(stdout=PIPE, *popenargs, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 710, in __init__ errread, errwrite) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 1335, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory: '/Users/ijuma/src/kafka/../kafka-site/10'
Please remove this example, since I would consider this usage as not recommended.
Hmm, doesn't seem like this is correct. >version ['1', '0', '0-SNAPSHOT'] major_minor ['1', '0'] Extracting ['tar', 'xf', '/Users/ijuma/src/kafka/core/build/distributions/kafka_2.11-1.0.0-SNAPSHOT-site-docs.tgz', '--strip-components', '1'] Traceback (most recent call last): File "./release.py", line 235, in <module> command_stage_docs() File "./release.py", line 227, in command_stage_docs cmd('Extracting ', 'tar xf %s --strip-components 1' % docs_tar, cwd=os.path.join(kafka_site_repo_path, docs_version(version))) File "./release.py", line 108, in cmd output = subprocess.check_output(cmd, *args, stderr=subprocess.STDOUT, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 566, in check_output process = Popen(stdout=PIPE, *popenargs, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 710, in __init__ errread, errwrite) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 1335, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory: '/Users/ijuma/src/kafka/../kafka-site/10'
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
Py2.6 compat (!): ```suggestion 'requestId': '{0}_{1:04}'.format(now, rand), ```
I'd rather see this part for all extractor errors.
Yeah, I think one squashed commits makes the most sense here.
I'd rather see this part for all extractor errors.
I'd rather see this part for all extractor errors.
Note: you don't have to use set explicitly here. The set methods can work with an iterable (which tuple is)
I'd rather see this part for all extractor errors.
Note: you don't have to use set explicitly here. The set methods can work with an iterable (which tuple is)
Note: you don't have to use set explicitly here. The set methods can work with an iterable (which tuple is)
CI failure due to missing conditional when calling main: ```python if __name__ == '__main__': main() ```
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
both are valid tests, i don't see why you need to eliminate the existing one
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
What's the reason for using the shell here? There's no redirection, pipes, or other needs for the shell that I can see.
Code duplication. This is already implemented in `CeskaTelevizeIE`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I would prefer mimic the original nova.cz player's behavior instead of letting rtmpdump to parse the URL as it may not always work.
Breaks. Read coding conventions on optional metadata.
Use relative imports.
fixture with load_json
Use relative imports.
This should not be fatal.
Possibly referenced before assignment.
`pzuid` does not look to be used anywhere.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Missing space after comma.
May be None.
I would prefer to reuse
This should not be fatal.
`pzuid` does not look to be used anywhere.
I would prefer to reuse
I would prefer to reuse
Use built-in method? Also, should it crash (raise) if `json.loads()` fails, or just return an empty dict again? ```suggestion try: return self._download_json( url, song_id, data=data.encode('ascii'), headers=headers) except ExtractorError as e: if type(e.cause) in (ValueError, TypeError): # JSON load failure raise except Exception: pass return {} ```
Possibly referenced before assignment.
Possibly referenced before assignment.
Possibly referenced before assignment.
May be None.
May be None.
May be None.
May be None.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Missing space after comma.
May be None.
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
May be None.
I would prefer to reuse
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
Currently we could just use a local variable in the filter function that has a list of filesystems whose mounts don't always start with `/` that we would like to include. That could _potentially_ be a user configurable list of filesystem types to include in fact gathering, but let's just keep it hard coded for now.
May be None.
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
Possibly referenced before assignment.
You don't need `required=False`, it's the default. And we tend to start with the parameter type.
Hmm I think this can be simpler, something like this: ```python if module.params.get('template'): entity_name = module.params.get('template') collection_service = connection.system_service().templates_service() elif module.params.get('vm'): entity_name = module.params.get('vm') collection_service = connection.system_service().vms_service() # TODO: We have to modify the search_by_name function to accept raise_error=True/False, entity = search_by_name(collection_service, entity_name) if entity is None: raise Exception("Vm/Template '%s' was not found." % entity_name) service = collection_service.service(entity.id) cluster_id = entity.cluster ```
Hmm I think this can be simpler, something like this: ```python if module.params.get('template'): entity_name = module.params.get('template') collection_service = connection.system_service().templates_service() elif module.params.get('vm'): entity_name = module.params.get('vm') collection_service = connection.system_service().vms_service() # TODO: We have to modify the search_by_name function to accept raise_error=True/False, entity = search_by_name(collection_service, entity_name) if entity is None: raise Exception("Vm/Template '%s' was not found." % entity_name) service = collection_service.service(entity.id) cluster_id = entity.cluster ```
Why not simply compare contents, instead of computing sha1 of both first? Since you read both into memory, that's more efficient :) Also: it currently fails under Python 3: ``` Traceback (most recent call last): File "../bin/dump_config.py", line 84, in <module> sys.exit(main(sys.argv[:])) File "../bin/dump_config.py", line 72, in main sha1_old = sha1(open(output_name).read()).hexdigest() TypeError: Unicode-objects must be encoded before hashing ```
`expected_status` to `_download_json` instead.
```suggestion Kwargs: ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
`del` is a builtin, not a function. These parens don't have to be here
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Actually, it's an opposite. It's a check for successful login.
This branch is never reached.
This branch is never reached.
This does not necessarily mean that. There is a clear captured error message that should be output.
This branch is never reached.
Should be delegated via `url_result`.
Should be delegated via `url_result`.
This means that if the first line fails, `view_count` is not a declared variable and therefore the following will fail - exactly the opposite of what you want.
Move data and query into `_download_webpage` call.
Actually, it's an opposite. It's a check for successful login.
This branch is never reached.
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
Possibly referenced before assignment.
Possibly referenced before assignment.
Move on a single line.
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
May be None.
Move on a single line.
Move on a single line.
Possibly referenced before assignment.
Possibly referenced before assignment.
Possibly referenced before assignment.
May be None.
It might also be useful to print login response code to supplement earlier login method debug. white testing this patch I felt login did not go through
Since #29201 is not merged, youtube-dl does not have any need for gcm
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
not for this PR, but we might want a 'configurable ignore facility' ala gitignore in the future
another newline removal
Please remove this example, since I would consider this usage as not recommended.
Docstring doesn't match the class
Similarly, ```if tc['skip'].get('i')```
not for this PR, but we might want a 'configurable ignore facility' ala gitignore in the future
I believe selinux uses native strings (byte strings in python2 and text strings in python3) rather than always using byte strings. So that's why we weren't using to_bytes here earlier. We may need to move the to_native call earlier, though. I'm not sure if it was all selinux functions or only some of them which had bugs if the wrong type of string was passed to them.
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
Also, please don't use `\` to break up lines
1. Single quotes. 2. `expected`.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
Isn't it the alternate syntax for the next if-block? `or ` part is only evaluated if the first expression in the chain is falsy. Am I missing something? I'm just suggesting an alternate/shorter conditional syntax...
255 is the way ssh notifies that the error was on the command being executed, not the connection
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
Please remove and add the suggested line in the arg spec
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
**Do not remove** `_search_regex` part.
lookup plugins inherit a flatten method: `total_search = self._flatten(terms)` should work here
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
It's better to sort imported items alphabetically.
It's better to sort imported items alphabetically.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
We generally call it "KTF"
We generally call it "KTF"
We generally call it "KTF"
We generally call it "KTF"
We generally call it "KTF"
We generally call it "KTF"
We generally call it "KTF"
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
On python 3, `izip` is just `zip`. This is causing the unit test and integration test failures.
Please make this method private (unless there is a rationale for making it part of the public API).
Maybe add "ansible versions below 2.10" or something so it's clear this is a one-time problem, not that they can never upgrade `ansible` again...
%s is not UP"
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
We used dd rather than cat in the jail, chroot, and zone plugins. Can use similar code here. I believe that code also does this without a shell which could be nice for making this more generic (not that most installs will be lacking bash but it's always nice to avoid) and potentially avoiding shell quoting issues.
We should be able to merge the two cases with something like this? ``` if collections is None and collection_from_task: collections = [collection_from_task] ``` Now `collections` is either the non-None contents of `collections`, or the task's collection, or `None` if neither exist, which means we can drop the `collections` check from the `all()`s and just use `collections` regardless
I think the signature of exec_command has changed in v2. If you take a look at local.py or the ConnectionBase class you'll see: ``` python def exec_command(self, cmd, tmp_path, in_data=None, sudoable=True): ```
This example will not work. Use loop with lookup/query/q instead. Any of the following will be fine: ``` loop: '{{ lookup("aws_ssm", "/TEST/test-list", region="ap-southeast-2", bypath=true, wantlist=true) }}' loop: '{{ query("aws_ssm", "/TEST/test-list", region="ap-southeast-2", bypath=true) }}' loop: '{{ q("aws_ssm", "/TEST/teset-list", region="ap-southeast-2", bypath=true) }}' ```
How about ```suggestion error = error_tuple[0] ``` That makes it look less like a typo :)
How about ```suggestion error = error_tuple[0] ``` That makes it look less like a typo :)
Prefer "standardize" (also used elsewhere) since "normalize" has a specific meaning elsewhere.
ð, this is a nice little refactor.
ð, this is a nice little refactor.
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
It's a good practice to have a trailing comma after the last sequence item as well. This way, when someone will add or remove an item it will generate only one line of diff, as opposed to two lines: one for the logical change and one for editing comma next to unrelated item. This practice makes doing reviews easier and more joyful :)
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
You don't need a lambda here. Also, don't break lines with `\`.
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
If either of these attrs is missing whole playlist extraction is broken.
Oh, and `args[0]` is the module, so you want to look at `args[1]` for the url.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
`default=None` is the default, can be omitted
```suggestion ``` I don't think you should do this, case is meaningful: ``` max@mde-oxalide % pacman -Q libreoffice-en-US libreoffice-fresh 6.1.3-1 max@mde-oxalide % pacman -Q libreoffice-en-us error: package 'libreoffice-en-us' was not found ```
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
Please remove the `__init__` docstrings and move the `arguments` sections to the class-level docstring (applicable everywhere)
Ah, I hadn't noticed `collections` isn't added here. And yeah, we should probably be using something like `collection_list=[collection_from_task] + collections` to look up the action plugin (resolving appropriately when one or both don't exist). The two paths are just so similar to each other I'd really rather avoid keeping them separate unless there's a good reason to
Ah, I hadn't noticed `collections` isn't added here. And yeah, we should probably be using something like `collection_list=[collection_from_task] + collections` to look up the action plugin (resolving appropriately when one or both don't exist). The two paths are just so similar to each other I'd really rather avoid keeping them separate unless there's a good reason to
Ah, I hadn't noticed `collections` isn't added here. And yeah, we should probably be using something like `collection_list=[collection_from_task] + collections` to look up the action plugin (resolving appropriately when one or both don't exist). The two paths are just so similar to each other I'd really rather avoid keeping them separate unless there's a good reason to
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
> They can't be multiline, can they? Yep. According to [ECMA 262 5.1](http://www.ecma-international.org/ecma-262/5.1/), CR (U+000D), LF (U+000A), LS (U+2028) and PS (U+2029) are not allowed in RegExp literals
Array ellipsis is an obscure feature and not necessary here. It hinders readability
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
Do not match by plain text.
duh :-) Something like ``dict with `msg` and `changed`.`` would be more informative
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
no, if the variable is set but empty, you should empty out the options
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
f is already at 0, the `truncate()` is uselesss.
`**{'Bucket': bucket}` is equivalent to `Bucket=bucket`. Please use the latter :)
I would do something like local.py does here: ``` python if not self._connected: self._display.vvv("ESTABLISH DOCKER CONNECTION FOR USER: {0}".format(self._play_context.remote_user, host=self._play_context.remote_addr)) self._connected = True return self ``` It adds logging which is a good thing to have when things go wrong. Setting self._connected is unnecessary for docker but it is nice if someone later decides to cargo-cult from the docker module and their connection plugin does need to set the _connected attribute.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Yeah we need to handle all exceptions that would be otherwise handled in `TaskExecutor` (`_execute()`, `run()`) and `Worker.run()`.
Is this even needed, we will be dropping py2 and `to_text` does not call `__unicode__`. You may as well just put this in `__str__`.
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
please reuse the code, it's very same
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
please reuse the code, it's very same
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
The next `if` should come first. The module should die if not all DBs exists no matter whether it's in check mode or not.
Break the line after the `(` to unify the style across the file.
I think this should be 'exit' instead of 'abort'
Break the line after the `(` to unify the style across the file.
I think this should be 'exit' instead of 'abort'
I know this is preexisting issue, but the condition should be checking the boolean value, not just the existence
Need a colon at the end here
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
This condition is not needed, t is always None here.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
This condition is not needed, t is always None here.
Breaks. Read coding conventions on optional data.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
`current_version` could be mentioned in the error message.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Just leave it out, we'll think of something later.
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
Call out default? If you set a default here, don't forget to update the spec above.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Call out default? If you set a default here, don't forget to update the spec above.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
as discussed previously, no such thing "alert policies". every mention of "policy/ies" should be renamed...
as discussed previously, no such thing "alert policies". every mention of "policy/ies" should be renamed...
Read coding conventions on optional fields.
According to pep8, there's a missing space after `+` in here.
Don't assign a lambda function, use def
Do not assign lambda, use def instead
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
I'd probably prefer a single assignment with a conditional only for the argument. It would probably look cleaner this way: ```suggestion is_openbsd = u"OpenBSD" == to_text(platform.system(), errors='surrogate_or_strict') bcrypt_crypt_id = '2b' if is_openbsd else '2a' algorithms['bcrypt'] = algo(crypt_id=bcrypt_crypt_id, salt_size=22, implicit_rounds=None) ```
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
Throwing a exception do not seems like great UX for users.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
CTR mode doesn't actually require padding, so this is unnecessary. That said, I assume you're staying compatible with existing vault implementations which already do this. It's not a security thing, just a few wasted bytes/CPU cycles.
Don't assign a lambda function, use def
You can import `try_rm` from helper
Matching empty string is senseless.
You can import `try_rm` from helper
it should show that we failed to get this value, not ignore and not set it at all
I was thinking` 'N/A'` .. but` None `seems good enough to test against, we don't currently have a clear rule and many facts do different things.
```suggestion result['last_modified'] = mtime = date_to_timestamp(info['last-modified']) ```
```suggestion result['last_modified'] = mtime = date_to_timestamp(info['last-modified']) ```
I don't think the `or []` is needed here. If there are no server groups defined, the API already returns an empty list.
`u` prefix is not necessary as `from __future__ import unicode_literals` has the same effect, and such a syntax is not available in Python 3.2.
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
Should check for a list.
Good catch! yeah there should be a warning.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Plz also use `match` arg here
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Looks like this is used now, yay :-)
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
Need a colon at the end here
`load_fixture()` takes the module name as the first parameter now, so you can lose the `os.path.join()` above and just have `load_fixture('nxos_switchport', filename)`
`load_fixture()` takes the module name as the first parameter now, so you can lose the `os.path.join()` above and just have `load_fixture('nxos_switchport', filename)`
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
No. In this case the whole new notion of embeddable metadata meta fields should be introduced.
Could you use `output = Dense(2, name='dense_B')(c1)` instead? Using a temporary variable make the reader believe that you are going to reuse this layer in the test or in the network.
The use of `AnsibleOptionsError` is to make in consistent with other sub commands. It looks like the help and `{}` will be it stdout. The error message is in `stderr`.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
Looks like dead code here
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
f is already at 0, the `truncate()` is uselesss.
I suggest `for x_shape, y_shape, axes, z_shape in test_cases:` to improve readability.
enumerate is not needed here. i is not used
Please add a note saying that the learning_phase should be added by `fit_generator`, otherwise it's a little confusing.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
request "got" re-sent to the control
I think it would be better to rename the extractor to `VVVVIDShowIE`.
By removing the `not` and turning the conditions around, this code can be simplified.
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_PROFILE') ```
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
Please change these vars to ansible Host vars rather OS env vars.
Should this have some exception handling? (I suggest here rather than paginated_list as paginated_list might not be able to handle exceptions if it does the retry)
Should this have some exception handling? (I suggest here rather than paginated_list as paginated_list might not be able to handle exceptions if it does the retry)
same here with the collapse
a leftover here which can be removed
Shouldn't this be using `.get()` ```suggestion inventory = self._cache.get(self.cache_key)[url] ```
Note: Our modules usually take credentials as parameters and fall back to files and environment variables if the credentials aren't present in the parameters. There's multiple ways to implement that, though, with processing the parameters first or the library function processing the parameters in addition to the config files and env vars. Not sure which way you'd want to fix this.
There should be fallbacks for these values since they are more or less static.
Please make this method private.
Please make this method private (unless there is a rationale for making it part of the public API).
I assume you meant to say `Unable to decrypt value using KMS`
nit: maybe use meaningful names? e.g. `topic_creation_start` Even better would be to add some kind of `timed` function
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
nit: maybe use meaningful names? e.g. `topic_creation_start` Even better would be to add some kind of `timed` function
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
If providing code examples in a docstring, it should use the MarkDown syntax for code snippets (as used elsewhere in docstring code snippets in the codebase) and the code should follow PEP8 syntax. Alternatively, you could simply remove the code example, remove the mention of "lazy evaluated arrays", and simply state that the data should be picklable.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
Break the line after the `(` to unify the style across the file.
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
You can use `update_url_query()`: ```suggestion asset = self._download_json( update_url_query('https://www.veejoy.de/api/service/get-media-summary', { 'mediaIri': self.get_asset_ref(video_data), 'locale': 'en', }), video_id) ```
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
Need to `return bind_mounts` here
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
small typo ```suggestion # table availability in check_src/dst. ```
(Similarly, mark any string that you are going to call decode on with as a b"string".)
```suggestion if not has_migrations: ```
Looks like dead code here
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
Please remove this example, since I would consider this usage as not recommended.
A simpler fix would be to do `join(to_install + to_upgrade)`
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
Looks like dead code here
A simpler fix would be to do `join(to_install + to_upgrade)`
What happens if you have something like `a=b=c`? Then you will init the dictionary with the tuple `(a, b, c)`, which will fail. Usually you want to interpret `a=b=c` as key `a` with value `b=c`; for that, you need `metric.split("=", maxsplit=1)`.
Looks like dead code here
Looks like dead code here
Looks like dead code here
Ok, how does this look? 85164a272274514877a6369877e851461a5acf0b
One last thing I thought of: it may be good to catch `AttributeError` and `ValueError` if an invalid value is passed for `namespace`. Otherwise we get a stacktrace. ```suggestion try: uuid_namespace = uuid.UUID(namespace) except (AttributeError, ValueError) as e: raise AnsibleFilterError("Invalid value '%s' for 'namespace': %s" % (to_native(namespace), to_native(e))) ```
Please remove this example, since I would consider this usage as not recommended.
A simpler fix would be to do `join(to_install + to_upgrade)`
Please remove this example, since I would consider this usage as not recommended.
Looks like dead code here
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Breaks if `node_views_class` is `None`.
this regex also isn't working for me, and I couldn't find a main.js that seemed relevant today
We have an `AnsibleAssertionError` for use here. It inherits from `AnsibleError` so that it is handled accordingly
I assume this should also be added to put_bucket_acl. The only thing I'm wondering about is if we should handle this for other S3 drop-ins as well. I assume most of them will fail for these two calls and all have their own special exception that they raise. Minio, for instance, raising a `NotImplemented` error.
You should write `if key not in self.healthcheck:` to avoid confusing falsish values with non-specified values.
As already said: parse as JSON not with regexes.
Also, I'm not sure if it matters but you could use ```to_native()``` instead of ```to_text()``` if container_config should be byte strings on python2 and text strings on python3. In a quick look at the following code I didn't see anything that would be a problem with text strings on python2 but I put that out there in case @cloudnull does see something.
Also, I'm not sure if it matters but you could use ```to_native()``` instead of ```to_text()``` if container_config should be byte strings on python2 and text strings on python3. In a quick look at the following code I didn't see anything that would be a problem with text strings on python2 but I put that out there in case @cloudnull does see something.
Can we calculate that beforehand? Also `os.environ.get` could make this much more readable.
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
so this assertion looks incorrect, i would expect and empty string as the ssh args
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
Good practice since the `%` operator can be ambiguous: ```suggestion return self._extract_videos(model_id, self._BASE_URL_TEMPL % (model_id, )) ```
Remove this flush, it is doing nothing just before the closing of the file.
Remove this flush, it is doing nothing just before the closing of the file.
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
```not (foo is None)``` => ```foo is not None```
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Hm... How about then introducing a prefix for such settings at least for this module? So, if user wants to provide binary data to be stored in property, they'd have to say, e.g. 'B64:blah' (where blah would be base64-encoded data). Caveat being that if users wants to store string which starts with B64:, they'd have to do something along the lines of B64:QjY0Og== (QjY0Og== being base64-encoded B64:, I think you get the picture :) Now, truth be told, not sure if this would be more acceptable for Ansible as project, but I'd see it as more consistent. Maybe second opinions on this could be useful too :)
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
use basic.py's `missing_required_lib` function as it gives details on host and python to avoid user confusion
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
I think, guard-expression style would fit better here: ```python if not import_name in module_utils: display.warning('%s:%d Invalid module_utils import: %s' % (path, line_number, import_name)) continue imports.add(import_name) ```
```suggestion fallback=(env_fallback, ['ANSIBLE_HWC_USER']), ```
use basic.py's `missing_required_lib` function as it gives details on host and python to avoid user confusion
Anytime I reach for map or filter, I like to use a list comprehension of generator exception instead as it is faster and considered more pythonic. ``` python return [p.name for p in q] ```
No such meta field.
No such meta field.
Forward slash does not need escaping.
Similarly, ```if tc['skip'].get('i')```
`note` and `errnote` of `_download_json` instead.
Similarly, ```if tc['skip'].get('i')```
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
* Since you fixed the unicode_literals import, remove all u from explicit u'...', here and anywhere else. * relax the RE. ```suggestion video_url = self._html_search_regex(r'''<source\b[^>]+\bsrc\s*=\s*("|')(?P<src>(?:(?!\1).)+)\1''', webpage, 'video URL') ```
`get_element_by_attribute()` may be useful.
<nod> to_native() should make it be str on both Python2 and Python3.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
This seems like it would break passwords with leading/trailing whitespace.
At first I thought this might be overkill, but all hosts need to rebuild their groups vars to remove this host from them. Making note in case someone else goes down same road.
You may be able to modify sys.path, perform an import, and then restore sys.path. That will probably prevent it from causing issues for other unit tests, but I haven't verified that.
Move to base class.
Like above, I think this should be `userid, name, password, group, email`
Like above, I think this should be `userid, name, password, group, email`
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Like above, I think this should be `userid, name, password, group, email`
Like above, I think this should be `userid, name, password, group, email`
How are the `user_details` used by the caller here? It looks like it's embedded in a string.
The format ID looks like the bitrate. Is it? If so, we should add a `tbr` or `vbr` entry here.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
```suggestion from ansible.module_utils._text import to_native ... module.fail_json(msg='Vexata API access failed: {0}'.format(to_native(e))) ```
Like above, I think this should be `userid, name, password, group, email`
How are the `user_details` used by the caller here? It looks like it's embedded in a string.
no need to specify required=False or type=str as these are defaults
this is not good way to set 'changed', if user does not exist you are erroring out instead of returning 'ok' and `changed=False`
this is not good way to set 'changed', if user does not exist you are erroring out instead of returning 'ok' and `changed=False`
this is not good way to set 'changed', if user does not exist you are erroring out instead of returning 'ok' and `changed=False`
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
this is not good way to set 'changed', if user does not exist you are erroring out instead of returning 'ok' and `changed=False`
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
```suggestion help='Specify webdriver type when you want to use Selenium to execute YouTube's "n_function" in order to avoid throttling: "firefox", "chrome", "edge", or "safari"') ```
```suggestion help='Specify webdriver type when you want to use Selenium to execute YouTube's "n_function" in order to avoid throttling: "firefox", "chrome", "edge", or "safari"') ```
I think we should add an `allow_overwrite` or similar param.
```suggestion help='Specify webdriver type when you want to use Selenium to execute YouTube's "n_function" in order to avoid throttling: "firefox", "chrome", "edge", or "safari"') ```
```suggestion help='Specify webdriver type when you want to use Selenium to execute YouTube's "n_function" in order to avoid throttling: "firefox", "chrome", "edge", or "safari"') ```
```suggestion help='Specify webdriver type when you want to use Selenium to execute YouTube's "n_function" in order to avoid throttling: "firefox", "chrome", "edge", or "safari"') ```
And the same here
Don't use this pattern. No try/except block here.
```suggestion warning_text_res = '{0} has been deprecated and will be removed in a future release of {1}'.format( ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
This method is unused and must be removed.
we want want -> we want
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
nit: this doesn't need to be a field, you can just use a local variable
nit: this doesn't need to be a field, you can just use a local variable
nit: this doesn't need to be a field, you can just use a local variable
```suggestion Test that the returned value for timezone consists of only uppercase ```
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Most of this stuff is included in the config of `super` and thus does not need to figure here.
`return not owner or owner == publication_info['owner']` could be used.
`get_element_by_attribute()` may be useful.
`get_element_by_attribute()` may be useful.
`get_element_by_attribute()` may be useful.
`get_element_by_attribute()` may be useful.
`get_element_by_attribute()` may be useful.
`get_element_by_attribute()` may be useful.
`get_element_by_attribute()` may be useful.
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
"Post the tags" is not very clear (and the fact it uses POST not interesting). "Perform assign/unassign action" ? More importantly I'd say a few words about what `tags` is.
No `(?i)`, no `$`. Dots must be escaped.
You are missing that it's a metadata provided by a 3dparty and there can by anything. So that you must ensure it's `int` before returning its value in info dict.
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
It'd be interesting to see a test case for something inheriting a `BaseException` too.
You are missing that it's a metadata provided by a 3dparty and there can by anything. So that you must ensure it's `int` before returning its value in info dict.
To apply the side effect, use this: ```suggestion mocker.patch('ansible.module_utils.network.meraki.meraki.fetch_url', side_effect=mocked_fetch_url) ``` You'll also need to update `mocked_fetch_url` to accept args, like: ```python def mocked_fetch_url(*args, **kwargs): ```
To apply the side effect, use this: ```suggestion mocker.patch('ansible.module_utils.network.meraki.meraki.fetch_url', side_effect=mocked_fetch_url) ``` You'll also need to update `mocked_fetch_url` to accept args, like: ```python def mocked_fetch_url(*args, **kwargs): ```
To apply the side effect, use this: ```suggestion mocker.patch('ansible.module_utils.network.meraki.meraki.fetch_url', side_effect=mocked_fetch_url) ``` You'll also need to update `mocked_fetch_url` to accept args, like: ```python def mocked_fetch_url(*args, **kwargs): ```
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
This is ambiguous since regex matches multiple ids. Parse correct id from JSON matching by slug and only if it fails fallback to this regex pattern.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
s/write target file {0}/put_file to {0}/
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
Yeah, a list is fine.
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Put these inside the `call` method, they shouldn't be class methods.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
check_output is not python2.6 compatible
Wrap `then` and `else` with ` to make the sentence easier to parse.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
nvm, I figured it out
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
check_output is not python2.6 compatible
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
Yeah, a list is fine.
It should always return a list.
It should always return a list.
```suggestion query=dict(type='list', elements='str'), ```
You don't need to specify this field if there is no return output
```suggestion query=dict(type='list', elements='str'), ```
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
no need for this line as None is already a False value
nit: lower_case_with_underscores preferred over CamelCase per PEP8 (cur_value, set_value).
no need for this line as None is already a False value
Missing HostedZoneId here which is important if you want to set a route53 ALIAS record later
This variable is never assigned ```suggestion api.get_collection_versions('namespace', 'collection') ```
Unite in single list comprehension.
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
Should check for a list.
Should check for a list.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Should check for a list.
self.act_fn => self.activation (unless self.activation is reserved already)
I usually pre-compile regexes into a global variable so that it only has to be done once. ``` _VCS_RE = re.compile(r'(svn|git|hg|bzr)\+') [...] def _is_vcs_url(name): """Test whether a name is a vcs url or not.""" return re.match(_VCS_RE, name) ```
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
This needs to be a failure, the `OrderedDict` object is used. Maybe just do a straight import with the try / except ``` python try: from collections import OrderedDict except ImportError: from ordereddict import OrderedDict ```
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
IMO no need to. Each step is idempotent, we failed to reach desired state but we got closer. But mostly, it's just easier ;-)
```suggestion # just get value from attribute itself as normal ```
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
IIRC should be just `raise` to re-raise the existing error
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
This method isn't necessary.
i don't think we want roles in roles
no need to specify required=False or type=str as these are defaults
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
This check is redundant since we have `if 'name'...` on previous line.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
You can add this^ line before `if` statement, and remove the exactly same code from line 135.
Playlist title is optional, description breaks.
Use dict literals: ```suggestion return {} ```
Bravo on tackling one of the gnarlier test setups ;-> :+1:
f is already at 0, the `truncate()` is uselesss.
f is already at 0, the `truncate()` is uselesss.
so this assertion looks incorrect, i would expect and empty string as the ssh args
Bravo on tackling one of the gnarlier test setups ;-> :+1:
This return is useless.
> Well, as I state in PR description, version in trunk practically disables ec2.py cache when using python 3. The idea was to replaces `hash()` call with any hashing function that gives stable results between script runs. Anything from hashlib module will do, `md5` does not have any advantage. One important note: `md5` will not be available on some systems (such as FIPS compliant systems). It's probably better to use `sha256` (as `sha1` could also be removed). > hashlib functions require byte string as input. Python 2 and 3 differ in what is stored in `__file__` variable: python 2 has simple string and in python 3 all strings are unicode. You could do ```.py from ansible.module_utils._text import to_bytes ``` and then ```.py cache_name += '-' + hashlib.sha256(to_bytes(__file__)).hexdigest()[:6] ``` This will work for both Python 2 and Python 3.
If we're just testing broker compatibility I don't think we even need this part of the test.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
f is already at 0, the `truncate()` is uselesss.
There is no point to use `remove_start` since line is always a string.
Could you clarify what's happening by adding an example 2-line CSV file? I think that would improve the docs.
doesn't this overlap a lot with fileglob/filetree> ... just like using w/o the *
yt-dlp's `--print` is a bit more complex, allowing printing data at multiple stages. Eg: `-O "after_move:%(filepath)s" will print the final file path. This function is needed to (easily) support that syntax, (and also other similar options)
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Could you clarify what's happening by adding an example 2-line CSV file? I think that would improve the docs.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
There is no point to use `remove_start` since line is always a string.
Got it. But this is very confusing error message. anyways, not a blocker as such.
Got it. But this is very confusing error message. anyways, not a blocker as such.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
Maybe if it's only one line to create a function (and the call is not really complicated), you can remove this function and use directly `nb_enpoint.create()` instead, like you do with `nb_endpoint.delete()`.
With this you drop 720p.
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
Please remove this example, since I would consider this usage as not recommended.
`return not owner or owner == publication_info['owner']` could be used.
1. No. 2. This won't have any effect anyway since post processors operate on info dict copy.
1. No. 2. This won't have any effect anyway since post processors operate on info dict copy.
You don't need a lambda here. Also, don't break lines with `\`.
```suggestion if not all([hostname, username, password]): ```
Optimizers have a `get_config` method precisely for this purpose.
terms can be a list, not sure if this is being handled correctly
You don't need a lambda here. Also, don't break lines with `\`.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
terms can be a list, not sure if this is being handled correctly
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
` // <1>` is unnecessary.
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
Not a must fix. We could remove 2 lines of code and logical branch for ```if not ignore_errors:``` The Core reviewers might like it more direct and declarative.
Not a must fix. We could remove 2 lines of code and logical branch for ```if not ignore_errors:``` The Core reviewers might like it more direct and declarative.
No need to parametrize with just one case.
docstrings go below the class (unlike every other language). same with other changes in this patch
The whole code until here can be simplified to `page_id = self._match_id(url)`
You're checking two separate properties here. This should be in a separate test.
No need to parametrize with just one case.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
You're checking two separate properties here. This should be in a separate test.
You're checking two separate properties here. This should be in a separate test.
Adding the exception string to the error would help the user narrow down what the issue is.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
Please remove this example, since I would consider this usage as not recommended.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Also, why do you compute `data.split(delimiter)` again instead of using `data_arr`? ```suggestion metric.split("=", maxsplit=1) for metric in data_arr) ```
```suggestion module.fail_json(msg="The following packages are absent in the currently booted rpm-ostree commit: %s" % ' '.join(pkgs)) ```
```suggestion module.fail_json(msg="The following packages are absent in the currently booted rpm-ostree commit: %s" % ' '.join(pkgs)) ```
I feel like this should be moved to `else:`
```suggestion module.fail_json(msg="The following packages are absent in the currently booted rpm-ostree commit: %s" % ' '.join(pkgs)) ```
boto3_conn() now handles NoRegionError and ClientError so you can remove that here.
Group names are supposed to be named similar to variables, i.e. alphanumeric and underscore. So at least the prefix should adhere to that. Besides that, look at this PR: https://github.com/ansible/ansible/pull/52748
Optimizers have a `get_config` method precisely for this purpose.
Optimizers have a `get_config` method precisely for this purpose.
Optimizers have a `get_config` method precisely for this purpose.
You want `changed` to be `True` here if *at least* one DB was created, not if *all* DBs in `non_existence_list` were created (and there has been at least one).
terms can be a list, not sure if this is being handled correctly
is it important to have 3 brokers for this test? I'm wondering if the tests would be more resilient and faster with just one broker and replica of each topic.
is it important to have 3 brokers for this test? I'm wondering if the tests would be more resilient and faster with just one broker and replica of each topic.
we need a consolidation of all the score mode / type we have at some point, not here though
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
is it important to have 3 brokers for this test? I'm wondering if the tests would be more resilient and faster with just one broker and replica of each topic.
Similarly, ```if tc['skip'].get('i')```
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
You could replace this entire block with: ``` from distutils.version import StrictVersion return StrictVersion(host_version) >= StrictVersion('.'.join(map(str,version))) ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
ditto `s/client/realm` :wink:
```suggestion help='Specify webdriver type when you want to use Selenium to execute YouTube's "n_function" in order to avoid throttling: "firefox", "chrome", "edge", or "safari"') ```
I think we should add an `allow_overwrite` or similar param.
`in()` looks like a function call, extra list creation not needed (generator expression should be fine) and it's better readable when multiline: ```suggestion return dict( (obj.__name__.lower(), obj) for obj in get_all_subclasses(PkgMgr) if obj not in (CLIMgr, LibMgr) ) ```
last loaded wins, but iirc, we reverse search on handlers list
I think we should add an `allow_overwrite` or similar param.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
The locale should be set to C if we do string matching.
it might not be relevant in this particular case but be aware to better handle LANG when searching in output. use `module.run_command_environ_update = dict(LANG='C', LC_ALL='C', LC_MESSAGES='C', LC_CTYPE='C')` early after `module` has been instantiated to get that covered.
I think we should add an `allow_overwrite` or similar param.
I think we should add an `allow_overwrite` or similar param.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
~~1. This won't work for UTF-8.~~ Nevermind, `BaseCookie.__ParseString` does not seem to be capable of UTF-8. 2. This will produce `"None"` string if there is no cookies, i.e. `cookie_header` is `None` that is completely wrong. 3. Also this should only taken place when `cookie_header` is a not a bytestring already.
Is 'http://res.infoq.com/downloads/mp3downloads/' hardcoded somewhere? If so it's better to point out where it is. (for example, xyz.html or abc.js)
```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('Europe/Helsinki')), '2019-06-15T14:45:00+01:40'), ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Probably fine currently given max number of retries we specify, but would really be preferable to do this iteratively (which also doesn't require copying/mgmt of kwargs like this).
Can get rid of required=False.
This would also match version 10.x. Also, `4.[0-2]` will also match `421` (an unescaped dot matches anything). You probably want: ```suggestion if re.search('^([0-3]\\.|4\\.[0-2])', min(self._build_list)): ``` Or (using raw strings, to avoid double escaping): ```suggestion if re.search(R'^([0-3]\.|4\.[0-2])', min(self._build_list)): ```
also worthy noting, -G won't show actual ssh options used, just those configured
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
If we're just testing broker compatibility I don't think we even need this part of the test.
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
New unit tests should be written to use pytest instead of unittest.
i mean the entry in the default that check encrypted, now that it is in encode, it should never get there.
If we're just testing broker compatibility I don't think we even need this part of the test.
Shapes mentioned in the docstring are generally 2D; should be 3D
Please use the same formatting as we do in e.g. the `Conv2D` docstring.
i mean the entry in the default that check encrypted, now that it is in encode, it should never get there.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
check_output is not python2.6 compatible
This is what `urlencode()` is already doing for you., so the function would be: ```python def encode_url_params(self, params): """Encodes key value pairs for URL""" return '?' + urlencode(params.items())
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
When reducing the replica count, the force option is mandatory. This will fail if force is not set. Also for remove brick can you check there are not pending heals. If we are removing a brick from a volume which has pending heals and if that brick had the only good copy, we have data loss.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Please remove the `__init__` docstrings and move the `arguments` sections to the class-level docstring (applicable everywhere)
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I'd go for underlining.
The paragraph above can be replaced with `layer.weights`, which is always implemented.
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
We already have that function as well, it's called `str_to_int`.
You can import `try_rm` from helper
I think either name should be mandatory or this should take a label selector.
I think that would be helpful.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
`if not check_rc` is not required. It can go in else part
I wouldn't exactly call a dictionary `list`.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
I wouldn't exactly call a dictionary `list`.
i would just add 'meta' here and do 1 join vs 2 of em
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
I'm pretty sure this can use `is_sequence()`.
both are valid tests, i don't see why you need to eliminate the existing one
I would split these ('install' and 'install --offline -p -r etc') into two separate tests so any failures are more specific and granular.
All debug garbage must be removed.
I would split these ('install' and 'install --offline -p -r etc') into two separate tests so any failures are more specific and granular.
@samdoran It probably won't but you could do this: ``` python cli = cli_klass([cli_name]) ``` which is probably "more right" ;-)
@samdoran It probably won't but you could do this: ``` python cli = cli_klass([cli_name]) ``` which is probably "more right" ;-)
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
I'm not fully sure what this is yet, but I would recommend renaming this function, as it is likely to cause confusion for devs/user due to ansible already calling something an "argument_spec"
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
I guess this might raise an `OSError`
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
In py3 this is mitigated by the subproccess methods having a timeout, but this is not available on py2
This might shadow built-in `format`
Looks like `@contextlib.contextmanager` embeds this behavior and this would be enough: ```python @contextlib.contextmanager def timeout(timeout, raising=False): signal.signal(signal.SIGALRM, _raise_timeout) signal.alarm(timeout) try: yield except TimeoutError: if raising: raise finally: signal.signal(signal.SIGALRM, signal.SIG_IGN) ```
```suggestion # just get value from attribute itself as normal ```
`**{'Bucket': bucket}` is equivalent to `Bucket=bucket`. Please use the latter :)
Please remove the `__init__` docstrings and move the `arguments` sections to the class-level docstring (applicable everywhere)
`if not check_rc` is not required. It can go in else part
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
It's in the patch if gave to you. Of course your code works, but this can be handled by other functions to simplify things.
Like above, I think this should be `userid, name, password, group, email`
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Use `query` for query.
Space missing between `}` and `is`.
This should not be fatal.
Prefer consistent using of single quotes when possible.
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
Use `'` as the quote character for consistency with the rest of the file
Change to `class Ec2EcsInstance(object):`
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Thanks for that note ewen. I learned something!
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
i mean the entry in the default that check encrypted, now that it is in encode, it should never get there.
Change to `class Ec2EcsInstance(object):`
Optimizers have a `get_config` method precisely for this purpose.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I'm not a big fan of this self recursion. We're a bit limited since boto doesn't give any way to get the entire tree, but it would be nice if this could be broken out differently.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
we want want -> we want
```suggestion if self.node_attrs['Spec'].get('Labels'): ``` This will prevent a crash when `'Labels' in self.node_attrs['Spec']`, but `self.node_attrs['Spec']['Labels']` is `None`.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
This line is unnecessary.
Change to `class Ec2EcsInstance(object):`
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
If nothing matches `None` will be returned.
Playlist title is optional.
If data is binary and not textual, then there is a good chance that passing this through to_text will mangle the binary data. I just tested this with a wav file, and it seems to mangle it - the textual headers are intact, but the audio content is garbled. I'll try to think of an alternative for this.
reduce the indentation. ```suggestion episodes = season.get('episodes') or [] for episode in episodes: ```
Optimizers have a `get_config` method precisely for this purpose.
reduce the indentation. ```suggestion episodes = season.get('episodes') or [] for episode in episodes: ```
You could replace this entire block with: ``` from distutils.version import StrictVersion return StrictVersion(host_version) >= StrictVersion('.'.join(map(str,version))) ```
`url` is not a video id.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
Extract id once before the loop.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
If nothing matches `None` will be returned.
If nothing matches `None` will be returned.
Change to `class Ec2EcsInstance(object):`
reduce the indentation. ```suggestion episodes = season.get('episodes') or [] for episode in episodes: ```
```suggestion data ```
Code duplication 173, 213. There is no sense to extract fields explicitly.
This is not used in single video extractor thus should not be here.
@annikulin it needed more work than I initially thought to get httpapi plugin host var working. Probably we can commit this code as is and I will commit a followup PR to make it configurable using ansible host vars
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
You don't need to specify this field if there is no return output
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
Thanks for that note ewen. I learned something!
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Thanks for that note ewen. I learned something!
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Extract id once before the loop.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
It'd be cleaner to have only kwargs conditional: ```suggestion optional_kwargs = {'ExtraArgs': {'VersionId': version}} if version else {} s3.download_file(bucket, obj, dest, **optional_kwargs) ```
Change to `class Ec2EcsInstance(object):`
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
reduce the indentation. ```suggestion episodes = season.get('episodes') or [] for episode in episodes: ```
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
This code is not required anymore (it used to - where did you still find it) - `_real_extract` only gets called when th eURL is suitable, and being suitable is defined as `re.match(self._VALID_URL, url)`.
I would prefer mimic the original nova.cz player's behavior instead of letting rtmpdump to parse the URL as it may not always work.
`get_element_by_attribute()` may be useful.
I would prefer mimic the original nova.cz player's behavior instead of letting rtmpdump to parse the URL as it may not always work.
this should raise an exception telling the user they need the required library
this should raise an exception telling the user they need the required library
Don't override built-in symbol ```format```. Also, just use {'url': ..., 'format_id': ..., ...}
10 is default.
`get_element_by_attribute()` may be useful.
I would prefer mimic the original nova.cz player's behavior instead of letting rtmpdump to parse the URL as it may not always work.
Must be int.
fixture with load_json
filename should already be a unicode object. Does cgi.parse_header return bytes-like objects? If so a wrapper is necessary.
filename should already be a unicode object. Does cgi.parse_header return bytes-like objects? If so a wrapper is necessary.
a leftover here which can be removed
Doesn't look like this got merged intime, so `2.8` here (and other places
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
```suggestion _VALID_URL = r'(?P<base>https?://(?:www\.)?raiplay\.it/programmi/(?P<id>[^/?#&]+))' ```
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
This is already validated in the constructor, no need.
This is already validated in the constructor, no need.
Also, it seems like our convention for docs versions is quite bad. If we didn't want to use `.`, we could use something else like `_`.
Hmm, doesn't seem like this is correct. >version ['1', '0', '0-SNAPSHOT'] major_minor ['1', '0'] Extracting ['tar', 'xf', '/Users/ijuma/src/kafka/core/build/distributions/kafka_2.11-1.0.0-SNAPSHOT-site-docs.tgz', '--strip-components', '1'] Traceback (most recent call last): File "./release.py", line 235, in <module> command_stage_docs() File "./release.py", line 227, in command_stage_docs cmd('Extracting ', 'tar xf %s --strip-components 1' % docs_tar, cwd=os.path.join(kafka_site_repo_path, docs_version(version))) File "./release.py", line 108, in cmd output = subprocess.check_output(cmd, *args, stderr=subprocess.STDOUT, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 566, in check_output process = Popen(stdout=PIPE, *popenargs, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 710, in __init__ errread, errwrite) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 1335, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory: '/Users/ijuma/src/kafka/../kafka-site/10'
It would be awesome if buildah supported copying from a container.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
This is never reached if Content-length is not set.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
#11205 already adds the `tile` op. So I don't think it's necessary to add it in this PR.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Maybe simplify with: ``` decoded_url.translate(None, '"\',').decode('utf-8') ``` Or in case there could be spaces in `['"cod", "ed ", "URL"]`: ``` re.sub(r'[\s"\',]', '', decoded_url).decode('utf-8') ```
Passing `sys.argv[:]` here is useless wrt current implementation. If you look at the `main()`'s first three lines there's: ```python def main(args): ... (options, args) = parser.parse_args() # <-- immediatelly rewrites args variable ``` It looks like the initial implementation has been written by the person with some C-like background, where main accepts args data and returns 0. But in fact in this case it's not needed. Please remove this arg.
`'http:' + None = TypeError`
use single quotes consistently, check for the availability of value before using them(`season_id` and `video_id`). `/title` part is not needed, can be simplified into(after checking for the values): ```suggestion video_url = '/'.join([url, season_id, video_id]) ```
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` python try: webpage = self._download_webpage(request, url) except ExtractorError as e: if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403: raise ExtractorError('%s is not available in your region.' % self.IE_NAME, expected=True) raise ```
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Exact error should be stored here, since debugging any potential issues in the future will be next to impossible without having the error. Something like `"Unknown error: %s" % str(e)` should be enough.
Exact error should be stored here, since debugging any potential issues in the future will be next to impossible without having the error. Something like `"Unknown error: %s" % str(e)` should be enough.
Nothing to do with RFC 3986.
Have you even read it? Percent encoding is a plain mapping of characters to `%XX` representation per se. RFC 3989 determines the set of rules for applying this mapping to URIs, roughly speaking it determines the set of characters that should not be percent encoded so that this set is used in `escape_rfc3986` to fix some invalid URIs to meet the requirements. What `compat_urllib_parse.unquote` does is simply mapping `%XX` back to character representation for a plain string. This have nothing to do with URIs and with rules determined in RFC 3989.
Please remove this example, since I would consider this usage as not recommended.
What happens if you have something like `a=b=c`? Then you will init the dictionary with the tuple `(a, b, c)`, which will fail. Usually you want to interpret `a=b=c` as key `a` with value `b=c`; for that, you need `metric.split("=", maxsplit=1)`.
Are these put/post/delete/patch/update methods used anywhere? I don't see uses of them.
Query should go as `query` to `_download_webpage`.
this seems to do the reverse of what you want
Please add `s` for seconds.
Please add `s` for seconds.
Move this line after 261. You won't need to deepcopy unless you are actually creating a request.
a try/except LookupError with a fail_json around this should be sufficient to handle any potential api response data changes gracefully.
This is not used in single video extractor thus should not be here.
This could be done in the logging Formatter (and/or a logging.Filter). And then the modules could just pass objects to self.debug_logger.debug(), and the handler/formatter decides how to pretty print.
this is already done by argspec when param is defined as boolean, all redundant
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
`if not check_rc` is not required. It can go in else part
not for this PR, but we might want a 'configurable ignore facility' ala gitignore in the future
Minor: if the test fails, the value of `basic.has_journal` won't be restored. This probably doesn't matter.
I don't think this line should be modified.
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
```suggestion if gql_auth: ```
You can import `try_rm` from helper
could create a function that take a tag_name entry (so, dict, or string). and return `(category_obj, tag_obj)`. This way we can simplify the loop. Basically line 239 to 265 should move in the function.
This check is redundant since we have `if 'name'...` on previous line.
It doesn't make sense to turn a unicode string into a unicode string. It's just `str(str(''))`, which is probably not what you want. Maybe you wanted to turn bytes into text here? In such case check'd be against `binary_type` and the translation should use `to_text()` shim.
could create a function that take a tag_name entry (so, dict, or string). and return `(category_obj, tag_obj)`. This way we can simplify the loop. Basically line 239 to 265 should move in the function.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Unnecessary blank lines here, removing these blank lines is preferable.
Does the order matter? If yes, it's probably better to use ```suggestion return '/'.join(sorted(priv_list)) ```
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
same here for arg bools vs strings- this needn't exist
0 is technically valid, so this should be `self.prefix_length is not None`
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
0 is technically valid, so this should be `self.prefix_length is not None`
It likely makes sense to add the remaining psycopg2 parameters including host and port.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
In that case, I think this error and the corresponding test should be kept.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
How can we hardcode this here? This means that ansible.netcommon namespace is now locked into our codebase.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
should be self.forward.
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
self.act_fn => self.activation (unless self.activation is reserved already)
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
self.act_fn => self.activation (unless self.activation is reserved already)
should not break the extraction if it wasn't able to parse json data.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
No need to parametrize with just one case.
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
No, catch exception.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
No, catch exception.
Some more: avc2, avc3, avc4. These would be enough.
this will fail if `type` is not present.
```suggestion class VMwareExportVmOvf(PyVmomi): ```
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
Hmm... I saw Alan's note that the API supports changing a setting to it's default value below. If that's the case you might want to think about whether that's a useful thing to expose to the user here as well (it feels like it is but I'm not entirely sure). If so, you should consider how it fits into these parameters. None might be the best value to mean reset to default. In which case the way to specify "show me the current value" would need to be something different.
Some more: avc2, avc3, avc4. These would be enough.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
option should deal with the case the dependencies are not avaiable and give a warning.
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
Don't shadow built-in names.
Not a must fix. We could remove 2 lines of code and logical branch for ```if not ignore_errors:``` The Core reviewers might like it more direct and declarative.
`0o600` is more readable than `384`.
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
No need for get(key, None) as None is the default fix also for following get()
I'm pretty sure PEP8 mandates the `break` to be in a new line, but that's not that important.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
at this point, just use a playbook
I'm pretty sure PEP8 mandates the `break` to be in a new line, but that's not that important.
Code duplication. Prepare message and then throw only once.
at this point, just use a playbook
I would remove the previous and the current line. If you write `persist_only`, you want to make sure that the variable is set in he `mysqld_auto` config. If it is not set there (but it is set in the running instance), you still want to execute the query.
I would remove the previous and the current line. If you write `persist_only`, you want to make sure that the variable is set in he `mysqld_auto` config. If it is not set there (but it is set in the running instance), you still want to execute the query.
also, this should not be by default as it changes current operations and might surprise users that expect it to fail when the path is 'polluted'.
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_API_VERSION') ``` Will not work for azure-mgmt-resource before 1.3.0 if you want multi-api support there as well.
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_API_VERSION') ``` Will not work for azure-mgmt-resource before 1.3.0 if you want multi-api support there as well.
It should always return a list.
Since you're rewriting the arg spec, do you mind removing the cases of `default=None`, `required=False`, and `type='str'`? Not necessary, but those are the defaults and keeping it minimal makes it easier to read.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
A flush is missing either here, or at the end of _save_model itself.
I mean `RuntimeError`.
I mean `RuntimeError`.
Remove this flush, it is doing nothing just before the closing of the file.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
just return pm.encrypt(password, user) != current_role_attrs['rolpassword']:
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
```suggestion for _iteration in range(1, iterations): ```
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
These examples are confusing. dim ordering should be referred to as "th dim ordering / tf dim ordering". Please pick one of them and have the entire example use the same convention. You may then follow up with the same example in the alternative dim ordering.
should be self.forward.
You're using the result object to smuggle this around, but it should probably be an instance field instead, since we don't actually want it in the results. Probably the same for the other cases where we're using the result dict as intermediate storage- put them in fields and just construct the result object at the end before it's returned.
If it's not found you will try extracting from 404 page. Remove all this 404 mess.
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
Also add a `# Arguments` section for `*args`
`del` is a builtin, not a function. These parens don't have to be here
Breaks once `userData` is not first.
You should not throw everything under try/except. Also read coding conventions.
no, if the variable is set but empty, you should empty out the options
"loss". In the case of a Graph it can be named explicitly (by the name of the output node); in the case of Sequential just "loss" should be fine. Even better would be to name the type of the loss explicitly, e.g. "binary_crossentropy" (but I'm not sure that's possible).
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
this is not good way to set 'changed', if user does not exist you are erroring out instead of returning 'ok' and `changed=False`
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Same, mention this is spatial cropping.
This doesn't allow the caller to cancel downtime by scope. _get_downtime returns an empty dictionary when id is not specified. It'd be great if this was changed to require id or scope instead of just id.
This doesn't allow the caller to cancel downtime by scope. _get_downtime returns an empty dictionary when id is not specified. It'd be great if this was changed to require id or scope instead of just id.
```suggestion ``` I don't believe you actually mean to remove the reference to your parent connection plugin. If you ever attempt to reuse the plugin after logging out, `send_request` will throw an AttributeError, and if you don't, then the connection plugin's `close()` method will be disposing of this object anyway.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
`client.nodes.get()` can also raise `APIError`s on failure.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Please raise a `NotIplementedError` when the use case is not supported yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
for a future enhancement, you could check `workflow['summary_fields']['user_capabilities']['start']`, and then give them a custom error message if it returns False, meaning they don't have permission to launch.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
for a future enhancement, you could check `workflow['summary_fields']['user_capabilities']['start']`, and then give them a custom error message if it returns False, meaning they don't have permission to launch.
for a future enhancement, you could check `workflow['summary_fields']['user_capabilities']['start']`, and then give them a custom error message if it returns False, meaning they don't have permission to launch.
for a future enhancement, you could check `workflow['summary_fields']['user_capabilities']['start']`, and then give them a custom error message if it returns False, meaning they don't have permission to launch.
for a future enhancement, you could check `workflow['summary_fields']['user_capabilities']['start']`, and then give them a custom error message if it returns False, meaning they don't have permission to launch.
for a future enhancement, you could check `workflow['summary_fields']['user_capabilities']['start']`, and then give them a custom error message if it returns False, meaning they don't have permission to launch.
for a future enhancement, you could check `workflow['summary_fields']['user_capabilities']['start']`, and then give them a custom error message if it returns False, meaning they don't have permission to launch.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
In case this pattern is used in other modules as well, moving it into `exec_sql` is probably a good idea. Also, adding a new argument to `exec_sql` with a default value shouldn't affect the other users.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
```suggestion Kwargs: ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
iirc we had specifically stated that .yaml was an invalid extension for galaxy file.
Could you please dedent everything below including this line? There's no point in keeping it inside of context manager block, which _may_ swallow some types of exceptions.
Instead of 'string'.encode() (or str('string') or bytes('string') ), use these ansible functions which are safer: ``` python from ansible.module_utils._text import to_bytes config_file = os.path.join(to_bytes(playbook._basedir, errors='surrogate_or_strict'), b'slack.json') ``` Some additional notes on that: * to_bytes uses 'utf-8' by default which will handle more cases than 'ascii'. * 'ignore' is not safe to use with filesystem paths. A path is a sequence of bytes. if you leave some of those bytes out then you end up with the name of a different file. 'surrogate_or_strict' will raise an exception if the bytes are not valid utf-8 which is unfortunate but better than using the wrong file. * I marked the second string, 'slack.json' explicitly as a byte string. On python3, string literals which are unmarked are text strings so you need to be explicit when writing most string literals.
`url` is not a video id.
self.current_feed_dict = {} if self.feed_dict is None else self.feed_dict Clearer
self.current_feed_dict = {} if self.feed_dict is None else self.feed_dict Clearer
I'd argue that it'd look cleaner and would better correspond to the fixture name that implies that it returns only the date-related subset of facts.
Use ` around **kwargs
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
No need to parametrize with just one case.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
you can move it to before `if` as just `docs = {}` line, this should read better.
you can move it to before `if` as just `docs = {}` line, this should read better.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Also, you don't actually need these error messages after `assert` since this is a unit test
No need for this line
to_text and u prefix on string.
`limitedTo(long bytes)`? Clone is kinda non-specific.
`limitedTo(long bytes)`? Clone is kinda non-specific.
Should be `inputs` and `mask`.
filters //= 2
maybe just ```suggestion part_boundary, b"--", ```
https://github.com/ansible/ansible/blob/devel/lib/ansible/parsing/splitter.py also, you probably want to add these in a collection, not core
Use ansible. module_utils.to_native or to_text here. To_Native converts to the str type (which is bytes on Python2 and text on python3). To_text converts to text type (Unicode on Python2. Str on python 3). Which you choose depends on what the rest of the module uses..
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
I am split on my feelings about this function. It doesn't work the same as it did as part of `AnsibleModule`. Before, it would error on the first time that `count > 1`, whereas we aren't doing so now, we are collecting them all, but then not using them all. Additionally, this is more like `list_mutually_exclusive`. I think this function should raise some form of Exception, instead of just returning a list of the mutually exclusive args that were provided by the user.
```suggestion return b'\r\n'.join(to_bytes(line, nonstring='passthru') for line in result) ``` (and import `to_bytes`)
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
looks like there are common options for all graylog modules, Shared code are located in lib/ansible/module_utils (note that this must not be GPL here). But this can be done later on. Not a blocker, just a hint.
I would also default children list to `[]`
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
You have some syntax errors in this `if` statement.
Please remove `module.fail_json` and use `ModuleFailException`.
You have some syntax errors in this `if` statement.
You have some syntax errors in this `if` statement.
What if some apps in the list `name` start with `https://` and some don't, with the `use_remote=False` case those that don't start with `https://` to fail installation? If so, there should be some book keeping done here to handle that.
Why don't you just encode suffix like `u'-\u00c5\u00d1\u015a\u00cc\u03b2\u0141\u00c8'.encode('utf-8')` and for the no_temp_unicode override just do `suffix = b'-ansible'`? No need for this check which is arguably more confusing.
I'm fine with the change in message, just noting that this test needs to be fixed up to check the new assertion https://github.com/ansible/ansible/blob/cf39d9de258cb9c47de9043e1a85e327e177dba7/test/integration/targets/ansible-galaxy-collection/tasks/install.yml#L43.
You have some syntax errors in this `if` statement.
You have some syntax errors in this `if` statement.
I suspect this will work even in Python-2.6: ``` python tmp_file = RoleRequirement.scm_archive_role(keep_scm_meta=self.options.keep_scm_meta, **self.spec) ```
`default` is not used with `fatal`.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
`default` is not used with `fatal`.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Course extraction must be in a separate extractor.
Most likely you don't need this.
Read coding conventions on optional and mandatory data extraction.
```python if 'name' in self.params and self.params['name']: ```
No such meta field.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Please remove this example, since I would consider this usage as not recommended.
Read code conventions on optional fields.
Error handling broken.
`pzuid` does not look to be used anywhere.
Looks like defining args is missing in the fetch_file method.
This can be more PEP8 with a '\n': ``` Python class YahooSearchIE(LazyLoadExtractor): _VALID_URL = None _module = 'youtube_dl.extractor.yahoo' @classmethod def suitable(cls, url): return re.match(cls._make_valid_url(), url) is not None @classmethod def _make_valid_url(cls): return 'yvsearch(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
`current_version` could be mentioned in the error message.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
`current_version` could be mentioned in the error message.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
```suggestion Kwargs: ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Prefer "standardize" (also used elsewhere) since "normalize" has a specific meaning elsewhere.
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
```suggestion Kwargs: ```
Prefer "standardize" (also used elsewhere) since "normalize" has a specific meaning elsewhere.
`current_version` could be mentioned in the error message.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
`current_version` could be mentioned in the error message.
```suggestion Kwargs: ```
`current_version` could be mentioned in the error message.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Grammar nitpick... Quick fix here would be to swap the comma for a semi-colon. The more detailed version is that this forms an invalid dependent clause the way it is written right now. A semi-colon would fix that, as would splitting off the `use the ...` content into its own sentence.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
This syntax is not supported in python2.6. You will need to index your format like `{0}`
should be exception=last_traceback
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
This syntax is not supported in python2.6. You will need to index your format like `{0}`
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Should not break if no `type`.
Please remove this example, since I would consider this usage as not recommended.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
This could be done in the logging Formatter (and/or a logging.Filter). And then the modules could just pass objects to self.debug_logger.debug(), and the handler/formatter decides how to pretty print.
This isn't compatible with Python 2.4, which is causing it to fail the py24 tests: ``` 2016-08-11 20:25:51 + python2.4 -m compileall -fq -x 'module_utils/(a10|rax|openstack|ec2|gce|docker_common|azure_rm_common|vca|vmware|gcp|gcdns).py' lib/ansible/module_utils 2016-08-11 20:25:51 Compiling lib/ansible/module_utils/cloud.py ... 2016-08-11 20:25:51 File "lib/ansible/module_utils/cloud.py", line 86 2016-08-11 20:25:51 except Exception as e: 2016-08-11 20:25:51 ^ 2016-08-11 20:25:51 SyntaxError: invalid syntax ``` You can use this instead: ``` python except Exception: e = get_exception() ```
This line fails for me trying to run Ansible under Python3 - `response.headers` is there, but there is no `getheader` method. I don't know the internals of what is returned from `open_url` but I can call `get` on it and it works for both Python2 and Python3: ``` fatal: [127.0.0.1]: FAILED! => { "msg": "An unhandled exception occurred while running the lookup plugin 'manifold'. Error was a <class 'ansible.errors.AnsibleError'>, original message: ['Traceback (most recent call last):\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 226, in run\\n team_data = client.get_teams(team)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 166, in get_teams\\n data = self.request(api, endpoint)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 113, in request\\n if response.headers.getheader(\\'content-type\\') == \\'application/json\\':\\n', \"AttributeError: 'HTTPMessage' object has no attribute 'getheader'\\n\"]" } ```
should be exception=last_traceback
This line fails for me trying to run Ansible under Python3 - `response.headers` is there, but there is no `getheader` method. I don't know the internals of what is returned from `open_url` but I can call `get` on it and it works for both Python2 and Python3: ``` fatal: [127.0.0.1]: FAILED! => { "msg": "An unhandled exception occurred while running the lookup plugin 'manifold'. Error was a <class 'ansible.errors.AnsibleError'>, original message: ['Traceback (most recent call last):\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 226, in run\\n team_data = client.get_teams(team)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 166, in get_teams\\n data = self.request(api, endpoint)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 113, in request\\n if response.headers.getheader(\\'content-type\\') == \\'application/json\\':\\n', \"AttributeError: 'HTTPMessage' object has no attribute 'getheader'\\n\"]" } ```
This isn't compatible with Python 2.4, which is causing it to fail the py24 tests: ``` 2016-08-11 20:25:51 + python2.4 -m compileall -fq -x 'module_utils/(a10|rax|openstack|ec2|gce|docker_common|azure_rm_common|vca|vmware|gcp|gcdns).py' lib/ansible/module_utils 2016-08-11 20:25:51 Compiling lib/ansible/module_utils/cloud.py ... 2016-08-11 20:25:51 File "lib/ansible/module_utils/cloud.py", line 86 2016-08-11 20:25:51 except Exception as e: 2016-08-11 20:25:51 ^ 2016-08-11 20:25:51 SyntaxError: invalid syntax ``` You can use this instead: ``` python except Exception: e = get_exception() ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
When running as `youtube-dl.exe` build with python 2 from path containing non-ASCII `find_file_in_root` ends up returning `None`. When `localedir=None` is passed to `gettext.translation` it picks up `_default_localedir` constructed using `os.path.join` with mixture of byte strings and unicode strings that results in similar problem: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "gettext.pyo", line 468, in translation File "gettext.pyo", line 451, in find File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` We can workaround be skipping it completely when we found no locale dir: ``` python locale_dir = find_file_in_root('share/locale/') if locale_dir: try: ... ``` Or we can mimic what `gettext` do by appending extra path in `get_root_dirs`: ``` python ret.append(os.path.join(decodeFilename(sys.prefix), 'share', 'locale')) ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This should be removed.
This should be removed.
```suggestion # just get value from attribute itself as normal ```
I know this is what it done in `load_platform_subclass()` but that looks incorrect as well.
(Additional whitespaceânumber of spaces not multiple of 4.)
Probably need a third clause on this for `aws_security_token`- IIRC that can be specified alone.
```python if 'name' in self.params and self.params['name']: ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Cosmetic: ```suggestion ''' Alternate constructor to instantiate class with sources ''' ``` A bit more informative about what the method is intended to be used for.
`del` is a builtin, not a function. These parens don't have to be here
(Additional whitespaceânumber of spaces not multiple of 4.)
Probably need a third clause on this for `aws_security_token`- IIRC that can be specified alone.
`del` is a builtin, not a function. These parens don't have to be here
```suggestion # just get value from attribute itself as normal ```
Cosmetic: ```suggestion ''' Alternate constructor to instantiate class with sources ''' ``` A bit more informative about what the method is intended to be used for.
Probably need a third clause on this for `aws_security_token`- IIRC that can be specified alone.
Cosmetic: ```suggestion ''' Alternate constructor to instantiate class with sources ''' ``` A bit more informative about what the method is intended to be used for.
Do not change the order of extraction scenarios.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
Currently this file is created in the folder that you are running the playbook from. I can make the opt-in feature.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Also, please don't use `\` to break up lines
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
This should be checked before training, at the model setting stage. Also this is not style compliant (use `if / raise ValueError` instead).
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
```suggestion response, info = fetch_url(module=module, url=base_url, headers=json.loads(headers), method='GET') ```
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
Just an empty line, could be removed for cleaner code
I believe the plan is to do a single PR to address this in all Postgres modules
I think either name should be mandatory or this should take a label selector.
Keep the regex on a single line.
I think this should be `_return_if_object` since it isn't part of the public API.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
Just an empty line, could be removed for cleaner code
Keep the regex on a single line.
I think either name should be mandatory or this should take a label selector.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
I just realized that I missed something important. These `indexes` are not the indexes of individual samples. These are indexes of batches. It means that forever you will have the same samples in the same batch, even if you shuffle the indexes. It takes the edge out of some important operations (i.e. batch-normalization). I find this a bit confusing. What I would expect is that the Dataset will store samples, not batches, and that `getitem` would return a single sample. I don't think that a Dataset should know about the `batch_size`. It makes more sense to me that the packaging of the samples into batches would happen on the fly, in the `DatasetEnqueuer.get()` method. If the `batch_size` is 32, then Enqueuer should pop out 32 elements from the queue (or less if there is a StopIteration), and call a `batcher` function (perhaps it can be provided by `Dataset`) that turns a list of samples into a batch.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
and then remove the parts Glandos point you.
```suggestion response, info = fetch_url(module=module, url=base_url, headers=json.loads(headers), method='GET') ```
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
Prefix it with `is_` to indicate a boolean check.
Prefix it with `is_` to indicate a boolean check.
Should check for a list.
Should check for a list.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
This is already validated in the constructor, no need.
connection plugins should not have their own python logic. If distros are using different python/missing python it is up to user to add (plenty of examples with raw and ansible_python_interpreter).
This is already validated in the constructor, no need.
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
This check doesn't work as-is and raises issues when running the following playbook two times in a row: ``` --- - hosts: localhost tasks: - openssl_privatekey: path: /tmp/private.key - openssl_csr: path: /tmp/csr.csr privatekey_path: /tmp/private.key commonName: www.ansible.com ``` This is due to the fact thatthe current code relies on `expected` being an array when it could be actually None, hence raising: ``` TypeError: 'NoneType' object is not iterable ``` Here is an alternative implentation that did what was expected, feel free to modify adapt/modify/get ideas from it: ``` usages_ext = [str(ext) for ext in extensions if ext.get_short_name() == extName] if (not usages_ext and expected) or (usages_ext and not expected): return False elif not usages_ext and not expected: return True else: current = [usage.strip() for usage in usages_ext[0].split(',')] expected = [long[usage] for usage in expected] return current == expected ```
Shouldn't this use the value of ansible_python_interpreter? There is a mechanism (winrm.py uses it) to pass in some host variables to connection plugins, so this should probably implement that.
this might change in the future, this is not necessary as you're checking for error in response page.
IMHO this is not python 2.6 compatible (https://docs.python.org/2/library/string.html#format-string-syntax). I usually avoid format at all and use the % syntax.
Just use `replace` or `re.sub`.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
``` if self.params.get('principal', None) is not None: ```
check results before split and getting first item
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Lock Info. Error: " + to_text(resp_obj))) ```
Not really sure what the desired behavior for this bit is. If I run a task with ``` launch_permissions: group_names: ['all'] user_ids: ['123456789012'] ``` and a subsequent task removes the group_name 'all': ``` launch_permissions: group_names: [] ``` should that also remove the user_ids? That is what happens now.
The user may have several hosts and only one with the datastore mounted RO. In this case, the datastore will never be picked. Could you add a not to make clear this is not the best approach.
This is not used in single video extractor thus should not be here.
hi Luke, I see from the code, you query the lock info and try to unlock the adoms upon logging out. however, I don't see any places where lock_adom() is called to lock a domain. if we don't explicitly lock the domain in our plugin, is it required to unlock it every time when the plugin is logging out? + @frankshen01 thanks, Link
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
This is missing a `cwd=` spec at the latest. If we need a git revision number, we should really think about releasing more often instead.
This is not used in single video extractor thus should not be here.
deepcopy only if required, move it inside the conditional.
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
Breaks all videos embedded with exact `<ul class="media-list items" id="media-related-items"><li data-video-info`.
This is missing a `cwd=` spec at the latest. If we need a git revision number, we should really think about releasing more often instead.
```suggestion self.module.fail_json(msg="The role ID isn't valid %s" % to_native(not_found)) ```
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
variable names like ```json_obj``` is not good. It doesn't describe what's the purpose of this variable.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
This is already validated in the constructor, no need.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
You are right, looking at kernel source, 'unknown' is a valid option for duplex (http://elixir.free-electrons.com/linux/v4.12-rc6/source/net/core/net-sysfs.c#L236 for example)
Booleans should be checked using is instead of ==. ```suggestion if ci is True: ```
Note that str() can fail if the object's __str__ method returns non-ascii characters. You probably control the objects being used here so you know whether that's the case or not. I usually use ```to_native(self.change_relelvant_keys, nonstring='simplerepr')``` in similar situations so I don't have to worry about it.
```suggestion "on the root node: %s" % to_native(admin_permission) ```
This does not look to be possible on a clean session.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Should check for a list.
This is already validated in the constructor, no need.
Breaks all videos embedded with exact `<ul class="media-list items" id="media-related-items"><li data-video-info`.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
You probably should do the opposite here. Set self.changed = False on object instantiation and then set self.changed = True when a change is performed.
```suggestion performed an initial sign in (meaning C(~/.op/config) exists), then only the C(master_password) is required. ```
'+' is redundant here.
'+' is redundant here.
This is unreachable code, as module.fail_json will be exit point the module.
You can import `try_rm` from helper
I think this should be false (not a string)
```suggestion Test that the returned value for timezone consists of only uppercase ```
```suggestion Test that the returned value for timezone consists of only uppercase ```
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
This line is too long. Max line length allowed in Ansible is 120 characters.
Too long line.
It could be just plain `return not ...startswith...`
I guess it's ok to always return stable float here.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Constant names should be in uppercase.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
Please remove this example, since I would consider this usage as not recommended.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
1. Single quotes. 2. `expected`.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
We should be able to merge the two cases with something like this? ``` if collections is None and collection_from_task: collections = [collection_from_task] ``` Now `collections` is either the non-None contents of `collections`, or the task's collection, or `None` if neither exist, which means we can drop the `collections` check from the `all()`s and just use `collections` regardless
We should be able to merge the two cases with something like this? ``` if collections is None and collection_from_task: collections = [collection_from_task] ``` Now `collections` is either the non-None contents of `collections`, or the task's collection, or `None` if neither exist, which means we can drop the `collections` check from the `all()`s and just use `collections` regardless
Please remove this example, since I would consider this usage as not recommended.
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
data_len is a string so it's wrong to compare it with an integer, and it can't be done on python 3.x
data_len is a string so it's wrong to compare it with an integer, and it can't be done on python 3.x
oops yeah I can't read apparently. Disregard!
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Ok, this shortening of the record parameter is both broken and unnecessary. I assume it is to deal with the scenario of the record being in the form of `foo.example.com`? That is, full enough to allow for the zone lookup, but still a relative name. I think it would make much more sense to depend on that the full name is an absolute name in the form of `foo.example.com.`. Not only will that work out of the box without any shortening, it's also much more in line with how the nsupdate module works, as well as with general DNS conventions. Preferably there should be a separate previous check which ensure that when the zone parameter is None then the record parameter must be an absolute name. It could be something as simple as requiring that the record name ends in a dot. Also, the current shortening actually breaks absolute record names, turning `foo.example.com.` into `foo.`.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
please add `type: bool`
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Do this as a oneline instead: `return camel_dict_to_snake.....` no need to assign.
- Slicing creates a copy so it might be better to avoid doing that inside of the inner loop - We can move some calculations outside the loop (although it probably won't make much difference with just 3 passes). - Instead of assert, we probably want to write a unittest to check that this does the right thing. I'm okay with leaving the assert in until we write a unittest, though. So it would look something like this: ``` python chunk_len = min(1024 * 1024 * 2, file_len) with open(tmp_path, "wb") as fh: for _ in range(passes): fh.seek(0, 0) # get a random chunk of data data = os.urandom(chunk_len) for _ in range(0, file_len // chunk_len): fh.write(data) fh.write(data[:file_len % chunk_len]) assert(fh.tell() == file_len) # Remove this assert once we have unittests to check its accuracy os.fsync(fh) ``` Hopefully that's right and I'm not off by one byte :-)
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
Please break line into 2, for length ```python if (isinstance(min_value, (int, float)) and isinstance(max_value, (int, float))): ``` (same below)
You only need one leading underscore to make a method private.
We generally call it "KTF"
var is a reserved keyword, use `v` or something like that.
```python if state == "disabled": if current_state == "enabled": self._commands.append('interface {0} {1} no traffic-class {2} congestion-control'.format(if_type, if_id, tc)) continue ```
```python if state == "disabled": if current_state == "enabled": self._commands.append('interface {0} {1} no traffic-class {2} congestion-control'.format(if_type, if_id, tc)) continue ```
the -> they
Please raise a `NotIplementedError` when the use case is not supported yet.
the -> they
We try to avoid using "_" as an identifier so as not to conflict with gettext should we find a way to localize our code in the future.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
I think it's nicer to have trailing commas: ```suggestion ], indirect=['mapping'], ```
Great! The whole point of this is that you can skip all those silly `u` prefixes in your file though ;)
it might not be relevant in this particular case but be aware to better handle LANG when searching in output. use `module.run_command_environ_update = dict(LANG='C', LC_ALL='C', LC_MESSAGES='C', LC_CTYPE='C')` early after `module` has been instantiated to get that covered.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
netrics => metrics
Prefer consistent using of single quotes when possible.
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
I think this needs to be "unidented" by 4 spaces. Also just for the "beauty" of things you can move the leading whitespace char to the prev line.
Prefer consistent using of single quotes when possible.
`current_version` could be mentioned in the error message.
It would be useful to tell the user which `key` is invalid.
you can avoid the try/except if you just test `response_data`: ``` if not response_data.get('value'): raise ConnectionE.... ```
Remove superfluous verbosity.
Move into `_download_json`.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
This can instead be `continue` and let the `else` unnest.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
This can instead be `continue` and let the `else` unnest.
I'm pretty sure this can use `is_sequence()`.
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
Could you please replace this `with `
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Same here (and further below).
Returning would close the file (I think) since you're already in a 'with' statement.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
```suggestion if not (season_id and video_id): ```
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
shouldn't this be like the following? ~~~python if rule == _rule['rule'] or rule == _rule['id']: ~~~
shouldn't this be like the following? ~~~python if rule == _rule['rule'] or rule == _rule['id']: ~~~
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
shouldn't this be like the following? ~~~python if rule == _rule['rule'] or rule == _rule['id']: ~~~
shouldn't this be like the following? ~~~python if rule == _rule['rule'] or rule == _rule['id']: ~~~
if self.state == "absent" should be explicitly checked before unregistering the VM, just to be safe.
if self.state == "absent" should be explicitly checked before unregistering the VM, just to be safe.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
this docstring now wrong
Took another look at the logic setting delegated_vars -- I think this check needs to be ``` if task.delegate_to is not None ``` Otherwise if the delegated_to host has no vars, I think it would still end up with an empty dict on Line 318 and therefore this condition won't be triggered.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
I suggest: if parser.get('DEFAULT', 'vmware_validate_certs').lower() in ('no', 'false'):
There should be a hardcoded fallback since it's always the same.
Please add spaces around the equal signs.
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
Hmmm, I do see what you mean. Personally I would still prefer the register method in the registry but I think this is a personal preference thing rather than a substantial concern so I'm happy to yield on it :smile:
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
`u` prefix is not necessary as `from __future__ import unicode_literals` has the same effect, and such a syntax is not available in Python 3.2.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
```suggestion Test that the returned value for timezone consists of only uppercase ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Use `self._search_regex` and `utils.unified_strdate` instead.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Get rid of `dim_ordering`, as it isn't doing anything anymore.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Get rid of `dim_ordering`, as it isn't doing anything anymore.
No such meta field.
stdout and stderr are being returned by suprocess.Popen().communicate() so they should be bytes already, I think.
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
AnsibleAWSModule checks this for you. You can remove the import too.
Personally i'd like it better if this was `changed_state`, for instance, as that better indicates the purpose of this variable, looking at the code
Playlist metadata must not be fatal.
AnsibleAWSModule checks this for you. You can remove the import too.
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
This message needs to be removed, as `validation_data` is no longer passed to the callback.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
Instead, please set `self.index = json.load(f)`. The JSON library uses the `.load` function to stream straight from files without needing to `.read()` first. This also avoids pesky encoding issues with Python2/3.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
This is wrong, already explained.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
Note that str() can fail if the object's __str__ method returns non-ascii characters. You probably control the objects being used here so you know whether that's the case or not. I usually use ```to_native(self.change_relelvant_keys, nonstring='simplerepr')``` in similar situations so I don't have to worry about it.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
traditionally, variables is a keyword arg. I don't think it matters in our paticular code base but we should keep it consistent with other lookup plugins.
You don't need to add this extra call ```dict()``` call. (Nor is it needed in the devel version either). The current version of merge_dicts in both branches returns a new dictionary so there's no need to turn it into a dictionary in the caller. Since this 2.8 branch didn't have a dict() call to begin with, I woiuldn't add it now (and you should try to merge removal of the extraneous dict() call to devel too): ```suggestion definition = KubeVirtRawModule.merge_dicts(definition, self.resource_definitions[0]) ``` ```
You've forgot to pass `info_dict` to `supports()`.
If we do go with this approach, I feel like `VMDB_PATH` should be user-configurable
Same here (and the other two missing).
Same here (and the other two missing).
Please draft a PR. I think we should keep a UX-friendly way of handling python generators. (ie. a good clear message stating that they should set workers=1)
` // <1>` is unnecessary.
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
The Base64 decoding can be hoisted out of the loop
```suggestion Kwargs: ```
```suggestion Kwargs: ```
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
```suggestion if vm.summary.runtime.powerState.lower() in ['poweredon', 'powered-on']: ```
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
```suggestion # just get value from attribute itself as normal ```
local_action has same issue as it is an alias to `delegate_to: localhost`
this might change in the future, this is not necessary as you're checking for error in response page.
This should contain the copy-and-pastable code of the call layer (like we do for the Dense layer).
There should be an `id` group.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
Ah -- I see you want to use a user name for the ESTABLISH DOCKER CONNECTION line later... we can save docker_remote_user for that purpose as well.
Title is mandatory.
Title is mandatory.
Title is mandatory.
should be list(attr.items())[0] to work with python3 too. ``` An exception occurred during task execution. The full traceback is: Traceback (most recent call last): File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 310, in <module> main() File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 280, in main attrs = EcsAttributes(module, attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 131, in __init__ self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 151, in _parse_attrs name, value = attr.items()[0] TypeError: 'dict_items' object does not support indexing fatal: [localhost]: FAILED! => { "changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 310, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 280, in main\n attrs = EcsAttributes(module, attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 131, in __init__\n self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 151, in _parse_attrs\n name, value = attr.items()[0]\nTypeError: 'dict_items' object does not support indexing\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0 } PLAY RECAP ********************************************************************* localhost : ok=0 changed=0 unreachable=0 failed=1 ```
should be list(attr.items())[0] to work with python3 too. ``` An exception occurred during task execution. The full traceback is: Traceback (most recent call last): File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 310, in <module> main() File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 280, in main attrs = EcsAttributes(module, attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 131, in __init__ self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 151, in _parse_attrs name, value = attr.items()[0] TypeError: 'dict_items' object does not support indexing fatal: [localhost]: FAILED! => { "changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 310, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 280, in main\n attrs = EcsAttributes(module, attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 131, in __init__\n self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 151, in _parse_attrs\n name, value = attr.items()[0]\nTypeError: 'dict_items' object does not support indexing\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0 } PLAY RECAP ********************************************************************* localhost : ok=0 changed=0 unreachable=0 failed=1 ```
Do not capture empty strings.
It's possible to specify a username on the query string to the GET /users API call. The server will do filtering and return a reduced list of users. Could we use that instead of fetching down the full list to convert username to UUID? It will save us bringing down large lists of users when we only need to select one. This is something I need to implement in the keycloak_group module as well.
Please remove this example, since I would consider this usage as not recommended.
It should always return a list.
This check isn't quite right since it would just check lexicographically (e.g. `'2.9.0' > '2.11.0'`, but the former is a smaller version than the latter). For now this will probably work fine since we don't hit minor version numbers that large, but eventually this won't work (e.g. major version numbers go > 9). (Similarly, the sort of tags isn't quite right either.)
Use `assert_allclose`` instead
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
I guess it a typo? now -> not
How are the `user_details` used by the caller here? It looks like it's embedded in a string.
The removal of this final raising of `HTTPError` means that there are some scenarios that can succeed, such as when given invalid redirection options. ``` RedirectHandlerFactory(follow_redirects='invalid', validate_certs=True) ``` Previous behavior was to raise an `HTTPError` in this situation, somewhat similar to `follow_redirects='none'`
You have some syntax errors in this `if` statement.
`pzuid` does not look to be used anywhere.
Hm, given those 15(?) other tests that failed on Python 3 in calls to syslog.syslog(), could we monkey-patch the rest of the tests so this is the only test that actually writes to the real syslog/journal? (EDIT: when I say "the rest of the tests", I mean in test_basic.py.)
Also, please don't use `\` to break up lines
It also looks you you are missing the variable to be inserted for the `%s`.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Here be dragons. I don't see check-mode being tested anywhere in the module. So I expect the module to perform a reboot in check-mode. Probably not what people expect.
Here be dragons. I don't see check-mode being tested anywhere in the module. So I expect the module to perform a reboot in check-mode. Probably not what people expect.
Hm, given those 15(?) other tests that failed on Python 3 in calls to syslog.syslog(), could we monkey-patch the rest of the tests so this is the only test that actually writes to the real syslog/journal? (EDIT: when I say "the rest of the tests", I mean in test_basic.py.)
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Code duplication 173, 213. There is no sense to extract fields explicitly.
(C(present) -> C(present) (C(absent) -> C(absent)
For backporting to 6.3, I think this needs to be changed to 7.
Would this ever return false under normal circumstances? Seems like we'd lose items if it did...
Remove the portion that adds message as a special key. If there's modules returning message expecting it to be treated specially, change then to return msg instead
Remove the portion that adds message as a special key. If there's modules returning message expecting it to be treated specially, change then to return msg instead
Got it. But this is very confusing error message. anyways, not a blocker as such.
Instead of changing the regex to a byte regex, I think it's better to convert the lines into text. The current code won't fail because it never touches the string that's been matched. However, it will quickly produce mangled output on Pyhton3 if we were to use the matched text in and update to this code. However, in some cases, that does have a knock on effect (making a text version of path to use in the print(). Changing the print format string to u"%s:%d:%d") So this depends on whether mattclay is doing unicode sandwich for ansible-test code or not.
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
Don't capture unused groups
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
There still are some references to `ampq`
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
when using dict you can just do `dict(msg=to_text(body), message_count=....`.
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
so this assertion looks incorrect, i would expect and empty string as the ssh args
so this assertion looks incorrect, i would expect and empty string as the ssh args
hi Luke, I see from the code, you query the lock info and try to unlock the adoms upon logging out. however, I don't see any places where lock_adom() is called to lock a domain. if we don't explicitly lock the domain in our plugin, is it required to unlock it every time when the plugin is logging out? + @frankshen01 thanks, Link
In addition to type, I think you should also check the value after clipping by placeholder variable.
This will break unicode strings under python 2.
Note that this is also being removed in https://github.com/ansible/ansible/pull/68560
connection plugins should not have their own python logic. If distros are using different python/missing python it is up to user to add (plenty of examples with raw and ansible_python_interpreter).
I think we should just let this exception propagate. We aren't adding any value by catching it here (and might be removing value if the traceback were useful). This isn't code in ansible itself so we don't have to create a nicer error message either.
`close` isn't called when `fail_json` is called.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
Needs to be `run_commands(module, ['show vlan brief'])[0]`.
`close` isn't called when `fail_json` is called.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
`close` isn't called when `fail_json` is called.
`close` isn't called when `fail_json` is called.
> Speaking of which, I should submit a PR to add Python 3.5 to tox.ini and .travis.yml #12627.
disk_params['zones'] = [self.zones] if self.zones and self.zones != 'None'
A flush is missing either here, or at the end of _save_model itself.
Best to not link to a versioned doc but the stable/latest branch https://pika.readthedocs.io/en/stable/.
This is not unicode frienly, see `INVALID_VARIABLE_NAMES` in `lib/ansible/constants.py` , we had to update to allow for unicode chars .. also you should be able to reuse
Do not capture empty strings.
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
If nothing matches `None` will be returned.
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
You don't need to specify this field if there is no return output
This breaks the general philosophy of `keras-team/keras`, which is to have a shared codebase across different backends (which is possible as long as each backend implements the Keras backend API). Why do you think this is necessary? We've managed to do it across Theano and TF without much issues, even though they work quite differently (e.g. sessions, graphs, etc). Surely you can manage any custom functionality you need at the level of `K.Function()`.
`id` should be extracted via `_VALID_URL` when present.
there's no such thing as dnf package, there's python-dnf. But honestly, I still don't like this solution
You can import `try_rm` from helper
You could also just return `credentials` rather than the three attributes
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
You can import `try_rm` from helper
You could also just return `credentials` rather than the three attributes
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
```suggestion Test that the returned value for timezone consists of only uppercase ```
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Thanks for that note ewen. I learned something!
Something like: ``` patch --- test/units/module_utils/facts/test_collectors.py +++ test/units/module_utils/facts/test_collectors.py @@ -258,12 +258,8 @@ class TestPkgMgrFactsAptFedora(BaseFactsTest): "ansible_pkg_mgr": "apt" } - import ansible.module_utils.facts.system.pkg_mgr - ansible.module_utils.facts.system.pkg_mgr.os = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path.exists = Mock(side_effect=_sanitize_os_path_apt_get) - - def test_collect(self): + @patch('ansible.module_utils.facts.system.pkg_mgr.os.path.exists', side_effect=_sanitize_os_path_apt_get) + def test_collect(self, mock_os_path_exists): module = self._mock_module() fact_collector = self.collector_class() facts_dict = fact_collector.collect(module=module, collected_facts=self.collected_facts) ```
Something like: ``` patch --- test/units/module_utils/facts/test_collectors.py +++ test/units/module_utils/facts/test_collectors.py @@ -258,12 +258,8 @@ class TestPkgMgrFactsAptFedora(BaseFactsTest): "ansible_pkg_mgr": "apt" } - import ansible.module_utils.facts.system.pkg_mgr - ansible.module_utils.facts.system.pkg_mgr.os = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path = Mock() - ansible.module_utils.facts.system.pkg_mgr.os.path.exists = Mock(side_effect=_sanitize_os_path_apt_get) - - def test_collect(self): + @patch('ansible.module_utils.facts.system.pkg_mgr.os.path.exists', side_effect=_sanitize_os_path_apt_get) + def test_collect(self, mock_os_path_exists): module = self._mock_module() fact_collector = self.collector_class() facts_dict = fact_collector.collect(module=module, collected_facts=self.collected_facts) ```
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
nvm, I figured it out
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
Similarly, ```if tc['skip'].get('i')```
nvm, I figured it out
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
You might want to use `six.raise_from`
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
1. What's the motivation for a wait time? Can the user just call sleep themselves? Perhaps just remove wait_time entirely. Otherwise: 2. I suggest default 0 wait time 3. don't always set wait time to 0
Add a `# Arguments` section to the docstring.
Add a `# Arguments` section to the docstring.
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
imho, you can keep your message KISS and more straighforward: e.g. "pymongo library is required for this module"
Add a `# Arguments` section to the docstring.
Add a `# Arguments` section to the docstring.
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Put these inside the `call` method, they shouldn't be class methods.
Put these inside the `call` method, they shouldn't be class methods.
Put these inside the `call` method, they shouldn't be class methods.
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
Wrap calls to self.client.X in try/except block. On APIError call self.client.fail() with an error message and exception details.
No space before and after operator in `dict()`
f is already at 0, the `truncate()` is uselesss.
should be self.forward.
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
I don't think this is useful in this example. Please remove.
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
`return not owner or owner == publication_info['owner']` could be used.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
Well, this is also very boilerplate, which you could deduplicate.
`(?P<id>[^/]+)` should not be mandatory, the information needed for extraction rely only on `show_id`(for API calls).
This seems to indicate that there may be issues with anyone else using `get_distribution` outside of us. I feel like we might need to normalize this to match previous values.
This seems to indicate that there may be issues with anyone else using `get_distribution` outside of us. I feel like we might need to normalize this to match previous values.
To be honest, this feels very much unsafe.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
```suggestion return to_text(v.ip) ```
```suggestion NO_LOG_REGEX = re.compile(r'(?:pass(?!ive)|secret|token|key)', re.I) ``` That part wasn't used anymore anyway...
No sure there: why should databases with `_` in their names should be escaped ? I'd understand for `-` but not for `_`
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
Breaks on https://www.zouzous.fr/heros/simon?abc. Single quotes.
Breaks on https://www.zouzous.fr/heros/simon?abc. Single quotes.
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
No sure there: why should databases with `_` in their names should be escaped ? I'd understand for `-` but not for `_`
Ewww, `++a` doesn't do what you think it does. It's the same as `a` or `+a` or `+++++a`, it just does nothing in this case. There is no increment operator in Python, you have to use `a += 1`. Thus this loop may be infinite because you never increment `download_tries`
This branch is never reached.
Ewww, `++a` doesn't do what you think it does. It's the same as `a` or `+a` or `+++++a`, it just does nothing in this case. There is no increment operator in Python, you have to use `a += 1`. Thus this loop may be infinite because you never increment `download_tries`
Shouldn't this be using `.get()` ```suggestion inventory = self._cache.get(self.cache_key)[url] ```
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
This method definition shares most of its functionality with `get_request` method, which indicates that the common functionality (common parameters, error handling, etc.) should be extracted into private method.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
You don't need to specify this field if there is no return output
You don't need to specify this field if there is no return output
I'd argue that it'd look cleaner and would better correspond to the fixture name that implies that it returns only the date-related subset of facts.
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
please add wait_for_vm_ip
Same here, default parameter is **validate_certs**, the aliases should be removed. We also simplify this by *not* adding `required=False`, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
This should not be fatal.
`del` is a builtin, not a function. These parens don't have to be here
```suggestion query=dict(type='list', elements='str'), ```
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
Lists also have .extend() which might be what you need here
```suggestion query=dict(type='list', elements='str'), ```
`del` is a builtin, not a function. These parens don't have to be here
```suggestion query=dict(type='list', elements='str'), ```
parse json data and extract `versionID` from there.
New unit tests should be written to use pytest instead of unittest.
```suggestion query=dict(type='list', elements='str'), ```
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
Braces in non inline dicts **should** be carried. Parentheses != braces.
Move data and query into `_download_webpage` call.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
I'd like to not pull SEQUENCETYPE into this file but this one is a little tricky. A Mapping is an iterable and we have a separate conditional block to work with those. If we just check for collections.abc.Sequence then we wouldn't catch things like sets and keyview.... I think what we can do is put the Mapping conditional before this one and then change this one to ```if is_iterable(obj)```.
doc typo, s/funcition/function
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
unused variable `input_length`
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Please remove this example, since I would consider this usage as not recommended.
Line is too long.
I'm not fully sure what this is yet, but I would recommend renaming this function, as it is likely to cause confusion for devs/user due to ansible already calling something an "argument_spec"
Line is too long.
Line is too long.
required=False is default so no need to add.
OK, I feel like it makes sense for the modules that are using screen scraping via SSH, but I see a lot of value of treating API calls as generic as possible. I'll hold off on making any changes to the module until the core members provide feedback. I'll be happy to attend the meeting to explain my point of view to the core developers.
Due to this, at the moment I am denying acceptance of this PR. I'll ask to get additional feedback from some other core developers, but we have explicitly denied modules that attempted to address arbitrary API functionality like this in the past. The recommended way would be to write individual modules for individual parts of functionality.
I'd go for underlining.
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
I like it!
Nesting generator expressions and list comprehensions like this is bad style. It has the same problems as a run-on sentence in natural languages (Making it hard for other people to read and keep the entirety of the clause in their memory. Easy to misinterpret the meaning because of misreading one small piece of the grammar). In most cases, using a ```for``` loop with indentation for at least one of the loops is better. If I understand this correctly, You are trying to take input of this form: ``` names = ['one >1.0,<2.0', 'two', '>3.0', '<4.0'] ``` and flatten it so that it is in this form: ``` names = ['one', '>1.0', '<2.0', 'two', '>3.0', '<4.0'] ``` ? If so, it's not quite right as it will currently return ``` ['one >1.0', '<2.0', 'two', '>3.0', '<4.0'] ```
doesn't this overlap a lot with fileglob/filetree> ... just like using w/o the *
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
When hitting an error you must exit with module.fail_json
Maybe we should only look for "explicit partition assignment" in the message.
I'd go for `try/except IOError` in order to make a point that variable initialized above is in fact a fallback.
When hitting an error you must exit with module.fail_json
Almost all modules use `dict()` constructor here. `required: False`, `default: None`, and `type: 'str'` are defaults and not required. Not really a blocker, more advisory.
Breaks all videos embedded with exact `<ul class="media-list items" id="media-related-items"><li data-video-info`.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
1. Code duplication. 2. Each should be non fatal.
Are these put/post/delete/patch/update methods used anywhere? I don't see uses of them.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
a try/except LookupError with a fail_json around this should be sufficient to handle any potential api response data changes gracefully.
a try/except LookupError with a fail_json around this should be sufficient to handle any potential api response data changes gracefully.
If it's not found you will try extracting from 404 page. Remove all this 404 mess.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
no, if the variable is set but empty, you should empty out the options
should be self.forward.
should be self.forward.
I don't know whether you changed it when you wrote this, but now it's correct ;-)
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
Tests shouldn't be invoked directly, so this isn't needed.
```suggestion assert wrap_var([None])[0] is None ```
Some more: avc2, avc3, avc4. These would be enough.
Good catch! yeah there should be a warning.
This syntax is not supported on Python 2.6.
We should really provide a better interface to test against, something along the lines of `download(url)`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Similarly, ```if tc['skip'].get('i')```
Bravo on tackling one of the gnarlier test setups ;-> :+1:
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
Extraction should be tolerate to missing fields.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
```suggestion # just get value from attribute itself as normal ```
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Useless return, should be removed.
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Tests shouldn't be invoked directly, so this isn't needed.
Useless return, should be removed.
Unclear why we're mixing some parameter substitution inline, and leaving others to the final substitution with the `args`. Made it confusing to figure out what was going on with the `JMX_PORT`, which looked like it had been lost since it wasn't in `args` any longer.
Unclear why we're mixing some parameter substitution inline, and leaving others to the final substitution with the `args`. Made it confusing to figure out what was going on with the `JMX_PORT`, which looked like it had been lost since it wasn't in `args` any longer.
Unclear why we're mixing some parameter substitution inline, and leaving others to the final substitution with the `args`. Made it confusing to figure out what was going on with the `JMX_PORT`, which looked like it had been lost since it wasn't in `args` any longer.
The regexp can be problematic when the json payload contains ";", for example the anime title can be "Dat Girl;ï¼". In this case the matched result is not a valid json string.
Optimizers have a `get_config` method precisely for this purpose.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
This is also not properly idempotent- you're not comparing to the existing port list, so always returning "changed: True" even if it's already in the right state.
Optimizers have a `get_config` method precisely for this purpose.
This could be problematic. If you set the seed to a constant and use multi-processing then all children processes would share the same seed and you'll get batches with repeated samples.
This could be problematic. If you set the seed to a constant and use multi-processing then all children processes would share the same seed and you'll get batches with repeated samples.
This line is too long. Max line length allowed in Ansible is 120 characters.
Optimizers have a `get_config` method precisely for this purpose.
self.act_fn => self.activation (unless self.activation is reserved already)
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
`self.base_command` is already list so I think this is useless.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
both are valid tests, i don't see why you need to eliminate the existing one
Could try running the command with the env setup to use LANG=C You can specify the env for the command either with the 'environ_update' arg to run_command() or by setting module.run_command_environ_update before the run command.
If you could wrap an `awsretry` around this, that would be great, but not going to block on it.
Isn't `raise` missing there ? Calls to `str` are useless.
```suggestion file_name, file_exts = os.path.splitext(str(url.rsplit('/', 1)[1])) # Preserving double filename extensions like .tar.gz _, double_ext = os.path.splitext(file_name) if double_ext: file_exts = double_ext + file_exts: ```
If these `,`s are thousands separators, might they be `.`s for some locales (plainly not a decimal point for a count)? ```suggestion view_count = str_to_int(self._html_search_regex( (r'<strong>([\d,.]+)</strong> views', r'Views\s*:\s*<strong>([\d,.]+)</strong>'), webpage, 'view count', fatal=False)) ``` (and `from ..utils import str_to_int` at the top).
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You don't need to specify this field if there is no return output
use ```from ansible.module_utils.vmware import get_cluster```
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
This can be converted to return True. No need of new variable retry_request
For examples we are standardizing on `key: value` Rather than key=value
This can be converted to return True. No need of new variable retry_request
For examples we are standardizing on `key: value` Rather than key=value
an exception for when they are not a list of tuples 'invalide plugin property, contact plugin author ...'
I would simply do: ```python if response.length > 0: return json.loads(response.read()) return {} ```
Use `query` for query.
You should be able to use `self.vmware_test_platform` here.
it absolutely is but "New in version 2.3." so I didn't make use of it yet.
I think it should be on line 284 as well.
Add condition here to check if role_id is `None` or not. If I specify `admin` as `local_user_role` then I get ``` fatal: [localhost]: FAILED! => { "changed": false, "invocation": { "module_args": { "hostname": "10.76.33.226", "local_user_description": null, "local_user_name": "aa", "local_user_password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER", "local_user_role": "admin", "password": "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER", "port": 443, "propagate": true, "state": "present", "update_password": false, "username": "root", "validate_certs": false } }, "msg": "Required field \"roleId\" not provided (not @optional)" } ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
I think if you import this here, it will solve the CI problem.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Just an empty line, could be removed for cleaner code
How are the `user_details` used by the caller here? It looks like it's embedded in a string.
```suggestion description: Can be used to request certificates from ECS, with C(provider=entrust). ```
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
you don't need to say `testcase failed`, it's obvious from testrunner's indication
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
```suggestion # require that the final recorded stack state was DELETE_COMPLETE ```
```suggestion assert wrap_var(dict(foo=None))['foo'] is None ```
1. `@property`. 2. It's not an installation command, it's a version spec. 3. You don't need it, as it's stringified automatically during string interpolation, under 3.6.5: ```python In [3]: from pkg_resources import Requirement In [5]: rqc = Requirement('cherrypy') In [11]: '%s ' % rqc Out[11]: 'cherrypy ' ``` 2.6.9: ```python $ python Python 2.6.9 (unknown, Apr 10 2018, 17:32:50) [GCC 7.3.0] on linux4 Type "help", "copyright", "credits" or "license" for more information. >>> from pkg_resources import Requirement /home/wk/.pyenv/versions/2.6.9/lib/python2.6/site-packages/pkg_resources.py:17: DeprecationWarning: the sets module is deprecated from sets import ImmutableSet >>> rqc = Requirement('cherrypy') Traceback (most recent call last): File "<stdin>", line 1, in <module> TypeError: __init__() takes exactly 4 arguments (2 given) >>> rqc = Requirement.parse('cherrypy') >>> '%s ' % rqc 'cherrypy ' >>> ```
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
`delay_min_macos = delay_min | 1`
- does not match the correct image. - you're not following the coding conventions.
Do note that this does not take `self.principal` into account, neither is that being checked. So you might return with `changed=False` if there's a tgt for a totally different principal.
`delay_min_macos = delay_min | 1`
this is already done by argspec when param is defined as boolean, all redundant
1. Single quotes. 2. `expected`.
This function checks whether input does not start with an operator, not that it's a package name at all. Let's invent a better name.
This function checks whether input does not start with an operator, not that it's a package name at all. Let's invent a better name.
```suggestion query=dict(type='list', elements='str'), ```
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
Format your docstrings like other docstrings in the codebase
This should be literally what the function call should look like. So the user can just copy and paste it.
Prefix it with `is_` to indicate a boolean check.
It'd be interesting to see a test case for something inheriting a `BaseException` too.
Again self_host is not defined for winrm.
Ok, how does this look? 85164a272274514877a6369877e851461a5acf0b
This should be literally what the function call should look like. So the user can just copy and paste it.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
Unnecessary whitespace. Please install a PEP8 linter to spot these issues during development.
Can't be None.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Can you style the dict the following way? ``` payload = { 'method': 'login', 'params': {'user': user, 'passwd': passwd} } ```
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
`urljoin` already does these checks.
at this point, just use a playbook
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
at this point, just use a playbook
No need to parametrize with just one case.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Please remove this example, since I would consider this usage as not recommended.
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
Just an empty line, could be removed for cleaner code
`foo`-> `{@code foo}`
`foo`-> `{@code foo}`
`foo`-> `{@code foo}`
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
We call it "batch axis"
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Are both lolcube and bsod your github accounts? If not, please only use lolcube, as otherwise bsod will be informed for every issue and PR related to this module.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
In python we tend to add a trailing comma, also for the last item in a multi-line dict or list. This is explicitly allowed by PEP8 and ensures that if any items are added, only one new line is added (and not the previous line needs a change). So it keeps the origin of lines (blame) clean. And it's also much more convenient.
you need to skip value from parent if include_tasks/include_role, but still inherit
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
use ```from ansible.module_utils.vmware import get_cluster```
CF detection and solving should happen centrally and automatically in `_webpage_read_content`. Otherwise it does not make much sense.
Better to put the activation as the `activation` keyword of the layer below
Better to put the activation as the `activation` keyword of the layer below
use ```from ansible.module_utils.vmware import get_parent_datacenter```
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
Simplify, harmonise with yt-dlp pt5: ```suggestion if try_get(data, lambda x: x['viewCam']['show'], dict): raise ExtractorError('Model is in private show', expected=True) elif not try_get(data, lambda x: x['viewCam']['model']['isLive'], bool): raise ExtractorError('Model is offline', expected=True) ```
use ```from ansible.module_utils.vmware import get_cluster```
```suggestion new_item['aliases'] = sorted(new_item['aliases']) ```
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
use ```from ansible.module_utils.vmware import get_cluster```
Maybe this line and the one below could be moved into `start_jmx_tool`? If we go that far, we could do the locking in there as well.
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
use ```from ansible.module_utils.vmware import get_cluster```
like above, no need for security protocol here
Carry long lines. Bother to finally read coding conventions.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
we really need something generic.... getting complex :-)
we really need something generic.... getting complex :-)
we really need something generic.... getting complex :-)
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
Are sure it's efficient to go via numpy here? I should suspect it adds overhead. Let's try to time it
This could be clearer as two tests. Re-using the 'model' variable like this was something I didn't immediately follow when trying to understand exactly what the test was checking for.
You could also just return `credentials` rather than the three attributes
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
The return value is not strictly cookies. The return value is a dictionary of headers
I don't know, this seems too clever (and not hugely readable). Prefer `desired_state = 'Enabled' if enabled else 'Disabled'`
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Lists also have .extend() which might be what you need here
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
Not a real issue, but we recommend to sort the order of lists if the order is not of importance.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
```suggestion - For tracking function statistics the PostgreSQL C(track_functions) parameter must be enabled. ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
I thought 0 is allowed as well? (0 is not a positive number.)
it should also check if it can write there
Similarly, ```if tc['skip'].get('i')```
```suggestion - For tracking function statistics the PostgreSQL C(track_functions) parameter must be enabled. ```
In case this pattern is used in other modules as well, moving it into `exec_sql` is probably a good idea. Also, adding a new argument to `exec_sql` with a default value shouldn't affect the other users.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
I thought 0 is allowed as well? (0 is not a positive number.)
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
this URL you have provided is not related to this part of the code(`RaiPlayLiveIE`).
I thought 0 is allowed as well? (0 is not a positive number.)
`expected_status` to `_download_json` instead.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
The place where the `main()` function is called explicitly does `sys.exit(main(sys.argv[:]))`. So `return 0` should really be here. (And yes, returning nothing is equivalent to `return None`, and `sys.exit(None)` is equivalent to `sys.exit(0)`, but it's still nicer to have an explicit `return 0` IMO.)
Let's rather implement a `@property` for these attributes. Much safer and more readable.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
Let's rather implement a `@property` for these attributes. Much safer and more readable.
This should be extracted first.
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
This message needs to be removed, as `validation_data` is no longer passed to the callback.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Better to put the activation as the `activation` keyword of the layer below
f is already at 0, the `truncate()` is uselesss.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Should not break if no `type`.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Actually, it's an opposite. It's a check for successful login.
It seems like the above 5 lines or so could just be replaced with a call to `self._clear_caches()`
You should be able to use `self.vmware_test_platform` here.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
```suggestion msg_format="Error stopping project - %s") ```
last loaded wins, but iirc, we reverse search on handlers list
Put these inside the `call` method, they shouldn't be class methods.
another case where it functions properly as-is, but an explicit `else: return None` is probably apropos just in case.
Technically this sets the proper value for `url` but it's doing so twice. s/url = url/url/
Technically this sets the proper value for `url` but it's doing so twice. s/url = url/url/
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Couple of typos: remporary & copites
You should be able to use `self.vmware_test_platform` here.
```suggestion result = self._run_command([self._blkid_bin, '--uuid', uuid]) ``` According to `man blkid` on my system, it is `--uuid` and not `--uid`.
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
The other unit test failure is due to a difference between `uuid5` on Python 2 and Python 3. In Python 2, `uuid5()` needs `bytes`: ```python def uuid5(namespace, name): """Generate a UUID from the SHA-1 hash of a namespace UUID and a name.""" from hashlib import sha1 hash = sha1(namespace.bytes + name).digest() return UUID(bytes=hash[:16], version=5) ``` In Python 3, it converts to `bytes` so you can pass in `bytes` or text: ```python def uuid5(namespace, name): """Generate a UUID from the SHA-1 hash of a namespace UUID and a name.""" from hashlib import sha1 hash = sha1(namespace.bytes + bytes(name, "utf-8")).digest() return UUID(bytes=hash[:16], version=5) ``` ```suggestion # uuid.uuid5() requires bytes on Python 2 and bytes or text or Python 3 return to_text(uuid.uuid5(uuid_namespace, to_native(string, errors='surrogate_or_strict'))) ```
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
`default` is not used with `fatal`.
`default` is not used with `fatal`.
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
You don't need a lambda here. Also, don't break lines with `\`.
Various modules allow to specify the name of the executable in order to use a binary from a non-standard location (i.e. a binary not located in the PATH). Look at e.g. the isoextract on how to do this.
instead of 'starting connection' here we might want to 'reserve socket path', to create it if it doesn't exist and to 'touch it' if it does (making a-connection timeout reset so we avoid a race condition)
could be just `if module.params['dns_domain'] is not None:`
Extra space in error message.
No, we don't, we only have copies of the publish lists. The elements of these lists say the same (though they appear in different order in the lists).
It should not match `h|`.
Please use lowercase variable names.
Please make this method private.
It probably makes sense to test that the exception reason also matches expectations
Please make this method private.
This should be more relaxed.
This is determined automatically.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You should check if the options actually changed before reconfiguring the plugin. It only makes sense to reconfigure if this actually changes something.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
```suggestion for b_path in b_colldirs: ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Please remove this example, since I would consider this usage as not recommended.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
```suggestion from ansible.module_utils import six urlparse = six.moves.urllib.parse.urlparse ```
1) No need to inherit from object explicitly due to `__metaclass__ = type` set above 2) It's nice to properly support all stringifications ```suggestion @six.python_2_unicode_compatible class CollectionRequirement: ```
When there is no `topicTitle`, `categories` will be `[None]` that does not make any sense.
@jainnikhil30 and I took a look at the tower_cli code which is backing this tonight and decided that tower_cli is trying to coerce the types from a schema that it retrieves from the tower server. So it looks like the module code does not have to worry about this conversion.
@jainnikhil30 and I took a look at the tower_cli code which is backing this tonight and decided that tower_cli is trying to coerce the types from a schema that it retrieves from the tower server. So it looks like the module code does not have to worry about this conversion.
@jainnikhil30 and I took a look at the tower_cli code which is backing this tonight and decided that tower_cli is trying to coerce the types from a schema that it retrieves from the tower server. So it looks like the module code does not have to worry about this conversion.
1) No need to inherit from object explicitly due to `__metaclass__ = type` set above 2) It's nice to properly support all stringifications ```suggestion @six.python_2_unicode_compatible class CollectionRequirement: ```
1) No need to inherit from object explicitly due to `__metaclass__ = type` set above 2) It's nice to properly support all stringifications ```suggestion @six.python_2_unicode_compatible class CollectionRequirement: ```
At this point `iteminfo` isn't known to be a dict. If it isn't, or it has no key `status_code`, this will crash, when it might be preferable to catch all these potential failures in the ExtractorError. ``` ... iteminfo = self._download_json('https://www.douyin.com/web/api/v2/aweme/iteminfo', video_id, query={'item_ids': video_id}) or {} status_code = iteminfo.get('status_code', 'status_code missing') if status_code: raise ExtractorError('%s (%s)' % (iteminfo.get('status_msg', 'status_msg missing'), status_code), video_id=video_id) ... ```
Simpler: ```suggestion series_id, season_id, episode_id = video_id.split('-') ```
Simpler: ```suggestion series_id, season_id, episode_id = video_id.split('-') ```
Please remove this example, since I would consider this usage as not recommended.
Simpler: ```suggestion series_id, season_id, episode_id = video_id.split('-') ```
Videos formats are not handled.
`urljoin` already does these checks.
should be self.forward.
Escape dot. No need to split URL.
`urljoin` already does these checks.
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
Simpler: ```suggestion series_id, season_id, episode_id = video_id.split('-') ```
no, if the variable is set but empty, you should empty out the options
Bonus points for a link to the `re` man page ð
Videos formats are not handled.
For these 2, add expected_type `int`, eg: ```py 'width': try_get(item, lambda x: x['video']['width'], compat_str), ``` (equivalent in effect to wrapping in `str_or_none()`). Add `from ..compat import compat_str` after line 4.
Breaks if no URLs extracted.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Breaks if no URLs extracted.
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
According to pep8, there's a missing space after `+` in here.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
```suggestion url_json = self._parse_json(self._html_search_regex(r'''<div\b[^>]+\bdata-item\s*=\s*(["'])(?P<videourls>\{.*})\1''', webpage, 'videourls', group='videourls', default='{}'), video_id, fatal=False) or {} ```
And `audio_selector` as well to catch `-f 'bestvideo+'`.
Please add spaces around the equal sign.
`formats` can be filtered out completely. ``` python -m youtube_dl nVlEpd92MJo -f "best[height<40]" [youtube] nVlEpd92MJo: Downloading webpage [youtube] nVlEpd92MJo: Downloading video info webpage [youtube] nVlEpd92MJo: Extracting video information [youtube] nVlEpd92MJo: Downloading DASH manifest [youtube] nVlEpd92MJo: Downloading DASH manifest Traceback (most recent call last): File "c:\Python\Python279\lib\runpy.py", line 162, in _run_module_as_main "__main__", fname, loader, pkg_name) File "c:\Python\Python279\lib\runpy.py", line 72, in _run_code exec code in run_globals File "C:\Dev\git\youtube-dl\master\youtube_dl\__main__.py", line 19, in <modul e> youtube_dl.main() File "youtube_dl\__init__.py", line 406, in main _real_main(argv) File "youtube_dl\__init__.py", line 396, in _real_main retcode = ydl.download(all_urls) File "youtube_dl\YoutubeDL.py", line 1614, in download url, force_generic_extractor=self.params.get('force_generic_extractor', Fals e)) File "youtube_dl\YoutubeDL.py", line 667, in extract_info return self.process_ie_result(ie_result, download, extra_info) File "youtube_dl\YoutubeDL.py", line 713, in process_ie_result return self.process_video_result(ie_result, download=download) File "youtube_dl\YoutubeDL.py", line 1273, in process_video_result formats_to_download = list(format_selector(formats)) File "youtube_dl\YoutubeDL.py", line 991, in selector_function for format in f(formats): File "youtube_dl\YoutubeDL.py", line 1022, in selector_function yield formats[format_idx] IndexError: list index out of range ```
Please add spaces around the equal sign.
Also, for posterity: ``` $ ipa --version VERSION: 4.4.0, API_VERSION: 2.213 ```
Here's something wrong. If you want to continue a line, you shouldn't start it with a dash.
Anyway, removal of `return 0` was not related to the purpose of the PR, but related to my refactoring suggestion. So it fits next to your change :)
And `audio_selector` as well to catch `-f 'bestvideo+'`.
Why not sort these as well? Would require adjusting `test_laps_password.py` as well, though.
User of this inventory plugin should be able to use `v6_main_ip` for value of `ansible_host` (i don't know if it makes sens to be able to use `internal_ip`) or no `ansible_host` at all (meaning that `server['label']` will be used instead).
Same function in `docker_swarm` module. It will be better to create a new module `docker_swarm_common` to assemble common code.
And `audio_selector` as well to catch `-f 'bestvideo+'`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
no, as i said you would extract the metadata and return immediately.
Unnecessary whitespace change.
With not mask, how do you handle a batch with different sequence lengths? Said a batch of 2, with first input have lenght 2 and the 2nd has a lenght 4. Then you would do a right padding on the 1st sequence to make it have length 4. In you implementation without mask, for the 1st input, the **true** energy should be `b_start + x1' y1 + x2' y2 + y1' U y2 + b_end` but in your implementation, there isn't a `b_end`, but with an additional `x3' y3' + x4' y4 + y2' U y3 + y3' U y4`, where `y3 = y4 = 0`. The consequence is, the above two formulations are not equivalent, at least when you take derivative with respect to `U_00` (top-left element in matrix `U`), the derivative isn't the same. Right? (also, `U_00` and `U_11` are not `exchangable`, but why we treat label 0 and label 1 differently?) Also when you compute the normalization constance (free energy in your code), you have to integrate over `y3, y4` (which are paddings). I guess that's what you mean by "padding elements act as a virtual end label". However, if when you think about taking derivative with respect to `U` or `b_end`, your approach is not equivalent to a real CRF. One very obvious observation is, `y3, y4`, the padding, affects the derivative with respect to `U`, and therefore, the paddings plays a role on the final outcome. The more paddings you have, the more impact the paddings affects the outcome. This is unexpected from my point of view. Lastly, another simple observation, a model with and without the end energy (`b_end`), the numbers of trainable parameters are not the same. So the two models are not the same.
wouldn't \w regex be more efficient here? also unicode 'friendlier'
Why not: ```suggestion elem = str(elem)[1:-1] ```
Why not: ```suggestion elem = str(elem)[1:-1] ```
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
this could just return ```suggestion return not self._raising ```
In py3 this is mitigated by the subproccess methods having a timeout, but this is not available on py2
this could just return ```suggestion return not self._raising ```
double space between `and` and `self.options.subset`
Not tested, though this may lead to a similar issue as https://github.com/ansible/ansible/issues/20391 due to `timeout` having a default value
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Should `args[1:]` here (the first entry in `args` is `self`).
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
Is there a particular reason for this change in behaviour? More just curious because I see the other `auth_*` methods have a default mount_point as well.
Is there a particular reason for this change in behaviour? More just curious because I see the other `auth_*` methods have a default mount_point as well.
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
ð, this is a nice little refactor.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
@agavra I don't think these should be public API.
ð, this is a nice little refactor.
this is one of the pep8 rules we don't need to follow
return dict((key, self.get(key)) for key in self.keys())
Looks like you have already done this TODO
return dict((key, self.get(key)) for key in self.keys())
Any reason this isn't in `setUp` since it's needed for every test? Also, is there a reason `MirrorMaker.start()` isn't using the `wait_until` to wait until the node comes up? Seems like all callers of `start()` would want this functionality.
return dict((key, self.get(key)) for key in self.keys())
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
return dict((key, self.get(key)) for key in self.keys())
Looks like you have already done this TODO
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
`_search_regex`. Read coding conventions.
`_search_regex`. Read coding conventions.
`_search_regex`. Read coding conventions.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
Here, `self.count_upgrade` is an int, and `outdated` (as above) a `dict` resp. `list`.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
maybe also should be described
just don't know exactly what's in the properties :-)
`no_log=True` is argument spec will handle this.
just don't know exactly what's in the properties :-)
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
`no_log=True` is argument spec will handle this.
You are right! Fixed it in https://github.com/mheap/ansible/pull/3.
You are right! Fixed it in https://github.com/mheap/ansible/pull/3.
```suggestion for app in sorted(set(apps)): ``` This way, you won't have trouble if apps show up more than once in the list (in which case `is_installed` and `is_outdated` can return wrong information), and the order is still deterministic also for older Python versions.
This will fail if `len(data) == 1`, which you explicitly allow above.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I think either name should be mandatory or this should take a label selector.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You calculate `os.path.abspath(separate_git_dir)` in more than two places. Save it to a variable and reuse, please.
please add wait_for_vm_ip
```suggestion # require that the final recorded stack state was DELETE_COMPLETE ```
You calculate `os.path.abspath(separate_git_dir)` in more than two places. Save it to a variable and reuse, please.
@gundalow I'm not sure what that does - I updated it (from 2.6) as part of the 2.7 release, thinking perhaps the `VERSION` setting in the Sphinx config should match the `latest` setting on the docsite. We could experiment . . .
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
Parens not necessary here
```suggestion # require that the final recorded stack state was DELETE_COMPLETE ```
```suggestion # require that the final recorded stack state was CREATE_FAILED ```
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
last loaded wins, but iirc, we reverse search on handlers list
```suggestion # require that the final recorded stack state was DELETE_COMPLETE ```
task_uuid seems unused
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I suggested `alive` to be consistent with the method being called on the consumer. The main reason is that `init` and `start` are a bit too similar and it's a bit difficult to distinguish between the two. Anyway, ok to leave as is if you feel strongly about it.
task_uuid seems unused
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
small typo ```suggestion # table availability in check_src/dst. ```
i think it would be better to add support for this embed urls and return a url result instead of inline handling of the embed url.
`return not owner or owner == publication_info['owner']` could be used.
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
This can instead be `continue` and let the `else` unnest.
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
`collection_from_task, _, module_name = self._task.action.rpartition(".")` will always work regardless of whether a collection is present or not. So: `"ansible.builtins.eos_config"` returns `("ansible.builtins", ".", "eos_config")` `"eos.eos_vlans"` returns `("eos", ".", "eos_vlans")` but also `"eos_l3_interfaces"` returns `("", "", "eos_vlans")` which avoids the weirdness with `split`
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
`configured on the trunk, i.e. C(2-10,15).`
`configured on the trunk, i.e. C(2-10,15).`
Read coding conventions on optional fields.
If we're just testing broker compatibility I don't think we even need this part of the test.
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
Ok, it shouldn't be needed unless the extractor accepts different types of urls (like the youtube extractor).
else is unnecessary here because we raise an exception before
use python bool for the default `default=False`
You want `changed` to be `True` here if *at least* one DB was created, not if *all* DBs in `non_existence_list` were created (and there has been at least one).
Line is too long.
else is unnecessary here because we raise an exception before
else is unnecessary here because we raise an exception before
else is unnecessary here because we raise an exception before
This condition is not needed, t is always None here.
default=None is the default
Currently this file is created in the folder that you are running the playbook from. I can make the opt-in feature.
This file will be kept locally and will not be deleted. It's to reduce amount of API calls during the execution.
Line is too long.
```suggestion 'md5': '048dab5c2f8ab97f2bd75ab4cf3f463a', ``` Maybe this video was changed, this now seems to be the correct hash.
default=None is the default
default=None is the default
Should check for a list.
```suggestion 'md5': '048dab5c2f8ab97f2bd75ab4cf3f463a', ``` Maybe this video was changed, this now seems to be the correct hash.
Line is too long.
Here be dragons. I don't see check-mode being tested anywhere in the module. So I expect the module to perform a reboot in check-mode. Probably not what people expect.
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
1. What's the motivation for a wait time? Can the user just call sleep themselves? Perhaps just remove wait_time entirely. Otherwise: 2. I suggest default 0 wait time 3. don't always set wait time to 0
1. What's the motivation for a wait time? Can the user just call sleep themselves? Perhaps just remove wait_time entirely. Otherwise: 2. I suggest default 0 wait time 3. don't always set wait time to 0
1. What's the motivation for a wait time? Can the user just call sleep themselves? Perhaps just remove wait_time entirely. Otherwise: 2. I suggest default 0 wait time 3. don't always set wait time to 0
Formats in webpage are still available and should be extracted.
traditionally, variables is a keyword arg. I don't think it matters in our paticular code base but we should keep it consistent with other lookup plugins.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('Europe/Helsinki')), '2019-06-15T14:45:00+01:40'), ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
It probably makes sense to test that the exception reason also matches expectations
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
ð, this is a nice little refactor.
ð, this is a nice little refactor.
ð, this is a nice little refactor.
ð, this is a nice little refactor.
ð, this is a nice little refactor.
ð, this is a nice little refactor.
Please remove this example, since I would consider this usage as not recommended.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
In validation or test, there is no concept of epoch, so that seems OK to me.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Looks like `@contextlib.contextmanager` embeds this behavior and this would be enough: ```python @contextlib.contextmanager def timeout(timeout, raising=False): signal.signal(signal.SIGALRM, _raise_timeout) signal.alarm(timeout) try: yield except TimeoutError: if raising: raise finally: signal.signal(signal.SIGALRM, signal.SIG_IGN) ```
Looks like `@contextlib.contextmanager` embeds this behavior and this would be enough: ```python @contextlib.contextmanager def timeout(timeout, raising=False): signal.signal(signal.SIGALRM, _raise_timeout) signal.alarm(timeout) try: yield except TimeoutError: if raising: raise finally: signal.signal(signal.SIGALRM, signal.SIG_IGN) ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
I don't think this line should be modified.
`User has been updated`
`User has been updated`
Login should be in `_real_initialize`.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
I think this can be simplified to just: ``` if not section: ```
There should be an `id` group.
Nowadays, we list the imported functionality at the top of the module, and we explicitly list all the functionality we import. So in your case it would likely become: ```python from ansible.module_utils.basic import AnsibleModule from ansible.module_utils.urls import fetch_url ```
I'm not sure if making this and lock_file conditional upon check_mode is the right thing to do. A module might need to lock a file in order to read it and decide if changes should be made.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Do this as a oneline instead: `return camel_dict_to_snake.....` no need to assign.
The class docstring should explain the meaning of the arguments.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
No need to parametrize with just one case.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
No need to parametrize with just one case.
No warning should occur with default settings. It is safe to remove this.
This is expected behavior, you named it preferredinfo not preferredmetadatatoembed. `track` from info must be preferred over `title` from preferredinfo. Again: you merge `_preferredinfo` with `info` into separate merged info **not touching** the initial dicts then operate with old code on merged info instead of `info`.
This is not used in single video extractor thus should not be here.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Change to 0.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Array ellipsis is an obscure feature and not necessary here. It hinders readability
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
This should be max.
Get rid of `dim_ordering`, as it isn't doing anything anymore.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Get rid of `dim_ordering`, as it isn't doing anything anymore.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
return dict((key, self.get(key)) for key in self.keys())
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
Please raise a `NotIplementedError` when the use case is not supported yet.
just call scaleway.ini we are in ansible conflict should not occur
return dict((key, self.get(key)) for key in self.keys())
Now you need to update `self.public_key` another time.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
Now you need to update `self.public_key` another time.
You should scope this to `ClientError`, otherwise you might be masking issues that should be propagated.
return dict((key, self.get(key)) for key in self.keys())
Please raise a `NotIplementedError` when the use case is not supported yet.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
return dict((key, self.get(key)) for key in self.keys())
I would split these ('install' and 'install --offline -p -r etc') into two separate tests so any failures are more specific and granular.
Preference would be for a unit test to be mocked sufficiently that a cleanup like this is not required. However, in this case if that involves a large amount of fragile mocking, I wouldn't worry about it now as having test coverage is better than not having it, even if it is a little messy.
I would split these ('install' and 'install --offline -p -r etc') into two separate tests so any failures are more specific and granular.
this should look like this instead: ``` result = super(ActionModule, self).run(tmp, task_vars) if result.get('skipped', False) or result.get('failed', False): return result ```
just call scaleway.ini we are in ansible conflict should not occur
I would split these ('install' and 'install --offline -p -r etc') into two separate tests so any failures are more specific and granular.
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
You're checking two separate properties here. This should be in a separate test.
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
Lists also have .extend() which might be what you need here
Sounds good. But it needs to be serializable.
You should probably expect unicode strings
You don't need to specify this field if there is no return output
No need for this line
```suggestion except (AttributeError, KeyError): ```
Also, you don't actually need these error messages after `assert` since this is a unit test
This version downgrade is not acceptable. This module can call update_stack(), which is was added in 1.8.0, so you'd be breaking others by allowing an older version. Please don't change required versions.
```suggestion result = super(Cliconf, self).get_capabilities() ```
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
This should be `b_output_path` to indicate it is a series of bytes. Even if the caller is sending in bytes, this function should convert it to bytes just like `b_collection_path` at the beginning. That allows our `b_` naming convention to hold, making this code look incorrect (trying to join `bytes` and `str`).
not that, i'm talking about `become_methods` list class variable.
not that, i'm talking about `become_methods` list class variable.
Name as per convention can be `lag_itnerfaces_facts`
If `self._module.params['name'] is None`, this will never match and the module fails.
You're checking two separate properties here. This should be in a separate test.
Duration calculation is incorrect.
You're checking two separate properties here. This should be in a separate test.
You're checking two separate properties here. This should be in a separate test.
You're checking two separate properties here. This should be in a separate test.
Having a class for just one test method is unnecessary.
Having a class for just one test method is unnecessary.
Having a class for just one test method is unnecessary.
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
You're checking two separate properties here. This should be in a separate test.
Having a class for just one test method is unnecessary.
You don't need to specify this field if there is no return output
not a list of dicts, just pass a dict to the with: ```yaml with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ```
I'm totally fine with your explanation and it was just a starting point by my side. And you are right, that the usage in your module in this case is simpler, so no change needed.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
Use `'` as the quote character for consistency with the rest of the file
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
You should probably expect unicode strings
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
You're checking two separate properties here. This should be in a separate test.
still: https://github.com/ansible/ansible/pull/44070#discussion_r212981844 https://github.com/ansible/ansible/pull/44070#discussion_r213508181
You don't need to specify this field if there is no return output
```suggestion result = super(Cliconf, self).get_capabilities() ```
so this assertion looks incorrect, i would expect and empty string as the ssh args
Sounds good. But it needs to be serializable.
Theano -> Theano/TensorFlow
Should have been module.fail_json
You don't need to specify this field if there is no return output
Duration calculation is incorrect.
`start_time` may be `None` at this point.
`start_time` may be `None` at this point.
Since these modules are new in 2.4, do you need to add them at all? If this is needed then you can use `removed_in_version`
It likely makes sense to add the remaining psycopg2 parameters including host and port.
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
remove 116 and 117 as dupes
Duration calculation is incorrect.
Having a class for just one test method is unnecessary.
Having a class for just one test method is unnecessary.
You can replace this with `pass`.
Duration calculation is incorrect.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
Breaks on https://www.zouzous.fr/heros/simon?abc. Single quotes.
Name as per convention can be `lag_itnerfaces_facts`
Style note, I finally convinced people a year or so ago that ```{}``` is superior to ```dict()```. So new code should use the literal syntax.
Style note, I finally convinced people a year or so ago that ```{}``` is superior to ```dict()```. So new code should use the literal syntax.
not that, i'm talking about `become_methods` list class variable.
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
check_output is not python2.6 compatible
If `self._module.params['name'] is None`, this will never match and the module fails.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
Duration calculation is incorrect.
`start_time` may be `None` at this point.
Duration calculation is incorrect.
Drop the `as e` since it's not used, and is not compatible with python 2.4.
This should be `b_output_path` to indicate it is a series of bytes. Even if the caller is sending in bytes, this function should convert it to bytes just like `b_collection_path` at the beginning. That allows our `b_` naming convention to hold, making this code look incorrect (trying to join `bytes` and `str`).
Duration calculation is incorrect.
Duration calculation is incorrect.
This code block is redundant with the logic of `save_weights_to_hdf5_group`. I would recommend extracting an abstract function that can be reused in both locations.
I'd rather see this part for all extractor errors.
Duration calculation is incorrect.
```suggestion raise AnsibleParserError("the field '%s' should be a list, but is a %s" % (value, type(value))) ```
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Oh, we should `%s/conig/config/`
`delete` and `create` are not valid states
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Oh, we should `%s/conig/config/`
Most of this stuff is included in the config of `super` and thus does not need to figure here.
You've forgot to pass `info_dict` to `supports()`.
This should be checked before training, at the model setting stage. Also this is not style compliant (use `if / raise ValueError` instead).
Better to leave this part of the code unchanged and implement a property setter on the wrapper.
Oh, we should `%s/conig/config/`
boto3_conn handles this for you. You can remove this, as well as the try/except around boto3_conn. It handles ProfileNotFound. Since you're using AnsibleAWSModule you can replace this entire try/except with: `connection = module.client('application-autoscaling')`.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
and then remove the parts Glandos point you.
You've forgot to pass `info_dict` to `supports()`.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Better to leave this part of the code unchanged and implement a property setter on the wrapper.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Just use ` and ...` instead of nesting. Less indentation == better readable.
Remove all garbage.
Just use ` and ...` instead of nesting. Less indentation == better readable.
Don't touch code formatting.
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Is `user_id` something secret, just wondering why it has `no_log`
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
`pzuid` does not look to be used anywhere.
`False` is not a valid note.
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Remove all garbage.
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
On python 2.6, you must specify the position of the arguments: `url = 'http://x-minus.org/dwlf/{0}/{1}.mp3'.format(video_id, token)`
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
On python 2.6, you must specify the position of the arguments: `url = 'http://x-minus.org/dwlf/{0}/{1}.mp3'.format(video_id, token)`
On python 2.6, you must specify the position of the arguments: `url = 'http://x-minus.org/dwlf/{0}/{1}.mp3'.format(video_id, token)`
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
@davidharrigan Nice spot, thanks. From a quick Google I've found * https://github.com/TAXIIProject/libtaxii/commit/59e18912e90550e2248779518fb63fac77d2f5a1 * https://bugs.python.org/issue4773
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
I would prefer mimic the original nova.cz player's behavior instead of letting rtmpdump to parse the URL as it may not always work.
Isn't `raise` missing there ? Calls to `str` are useless.
this should use the new API without hardcoded id now
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
f is already at 0, the `truncate()` is uselesss.
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
The same thing.
The same thing.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
I think it's worth looking into, but in the meantime this will already be an improvement.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
Looks like this is used now, yay :-)
both are valid tests, i don't see why you need to eliminate the existing one
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
These should be replaced along the lines of your existing imports earlier in the file (you'll need to add `get_aws_connection_info`, `ec2_argument_spec`, `camel_dict_to_snake_dict` and any others to the explicit import list)
These should be replaced along the lines of your existing imports earlier in the file (you'll need to add `get_aws_connection_info`, `ec2_argument_spec`, `camel_dict_to_snake_dict` and any others to the explicit import list)
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
no, if the variable is set but empty, you should empty out the options
so this assertion looks incorrect, i would expect and empty string as the ssh args
Then use `enumerate()` instead.
Then use `enumerate()` instead.
both are valid tests, i don't see why you need to eliminate the existing one
Please remove this example, since I would consider this usage as not recommended.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
No need to parametrize with just one case.
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
Would be good change this line to explain a bit about what this is done. No need to detail the supported operations, that's what `choices:` is for, so the following line can be removed.
`del` is a builtin, not a function. These parens don't have to be here
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
just don't know exactly what's in the properties :-)
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
Typo? ```suggestion msg="Argument 'state' includes the value '%s' as an invalid choice" % bad_state) ```
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
`, no_log = True`
No need to escape `\`.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
New connection plugins should be using the recently added `self._play_context.executable` for executable. Take a look at the lxd plugin for an example.
no, if the variable is set but empty, you should empty out the options
`no_log=True` is argument spec will handle this.
Add a `# Arguments` section to the docstring.
`no_log=True` is argument spec will handle this.
It seems like the above 5 lines or so could just be replaced with a call to `self._clear_caches()`
No. youtube-dl should not store passwords.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
`Could not recursively set attri...`
You are setting this to True but don't seem to be using the learning phase in the code.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
>also `data-brightcove-video-id` is not used by the standard embeds https://docs.brightcove.com/en/perform/brightcove-player/guides/in-page-embed-player-implementation.html. You should add separate extractor instead. Or should provide another example URLs across web to prove this pattern is used not only on this site.
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
I think this approach might read simpler: ```suggestion new_galaxy_yml = dict.from_keys(optional_strings) new_galaxy_yml.update(dict.from_keys(optional_lists), []) new_galaxy_yml.update(dict.from_keys(optional_dicts), {}) new_galaxy_yml.update(galaxy_yml) ```
`{}` doen't work in python 2.6.
Yeah, I think one squashed commits makes the most sense here.
The use of the '.' as a separator sounds a bit weird to me. It sounds like "name" is a domain and namespace is hostname. I suggest to add a new parameter `name_format`, with something like that by default: ```python name_format='{namespce}-{name}' ``` And use it here: ```python vm_name = name_format.format(namespace=vm.metadata.namespace, name=vm.metadata.name, uid=vm.metadata.uid) ```
The use of the '.' as a separator sounds a bit weird to me. It sounds like "name" is a domain and namespace is hostname. I suggest to add a new parameter `name_format`, with something like that by default: ```python name_format='{namespce}-{name}' ``` And use it here: ```python vm_name = name_format.format(namespace=vm.metadata.namespace, name=vm.metadata.name, uid=vm.metadata.uid) ```
`add_group` returns a sanitized name, to ensure the `add_child` below doesn't error out either use that name or sanitize `name` beforehand. You can use `self._sanitize_group_name()`
`{}` doen't work in python 2.6.
Yeah, I think one squashed commits makes the most sense here.
`add_group` returns a sanitized name, to ensure the `add_child` below doesn't error out either use that name or sanitize `name` beforehand. You can use `self._sanitize_group_name()`
This should be extracted first.
I'm not sure ret/responses are in the correct scope, it looks like you wanted responses inside a for loop (terms one?) in which case indentation is wrong.
Can you add a reference to the boto bug this patches.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
You should capture a part of URL that represents a video in unique way...
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
Similarly, ```if tc['skip'].get('i')```
Just an empty line, could be removed for cleaner code
121, 124 - DRY.
Going through itertools here ends up creating both a list and a generator so it's likely slower than just returning a list. If the list is very large and your goal is to reduce memory consumption, you can use a generator expresssion instead of a list comprehension on line 322: ``` python expanded_excludes = (self._pattern_to_pkgname(self.base, p) for p in self.base.conf.exclude) ``` However, for iteration over most data, lists are faster than other iterables so it is a time-space tradeoff.
Must be extracted first.
Must be extracted first.
I think this should be `_return_if_object` since it isn't part of the public API.
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
Nonblocking/doesn't matter: I like to use frozenset and tuples for immutables. Since these sets are never updated you can do: ``` python BASE = frozenset(('name', 'role')) FROM_ARGS = frozenset(('tasks_from', 'vars_from', 'defaults_from')) OTHER_ARGS = frozenset(('private', 'allow_duplicates')) VALID_ARGS = frozenset(BASE.union(FROM_ARGS.union(OTHER_ARGS)))
self.cache contains function `get_all_objs` which already does this, so we can reuse it directly rather than modifying `find_obj`
su requires a tty, that is why most 'subprocess' plugins don't support it.
It should contain the same thing as what the user wrote, but converted to the new API.
self.cache contains function `get_all_objs` which already does this, so we can reuse it directly rather than modifying `find_obj`
`module` isn't valid in this scope, you need to use the `cert_chain` parameter.
Might want to replace this with help message.
you may want Y_rev = K.permute_dimensions(Y_rev, (1, 0, 2)) Y_rev = Y_rev[::-1]
use the `flatten_dict` method from module_utils.network.nxos.utils.utils.py
does not resolve inheritance https://github.com/ansible/ansible/issues/25097
I think this should have a `raise` after this loop to raise an exception if none of the user-provided hostname preferences match, so we don't add hosts with the hostname `None` which would be the default return.
is_map should be done using global re 'MAP_RE' so we have one way to identify map in a column value.
I think this should be: ``` python values = map(lambda x: x.strip(), tags['Value'].split(',')) ``` Basically the same as it was before this change but with `tags['Value']` instead.
you may want Y_rev = K.permute_dimensions(Y_rev, (1, 0, 2)) Y_rev = Y_rev[::-1]
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
`return not owner or owner == publication_info['owner']` could be used.
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
Code duplication. Prepare message and then throw only once.
`int_or_none` for all int fields.
```suggestion for key, value in self.parameters.plugin_options.items(): ```
You are right! Fixed it in https://github.com/mheap/ansible/pull/3.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
AnsibleAWSModule has a function to check boto3/botocore versions you can use here. ```suggestion return len(load_balancers) > 0 and self.module.botocore_at_least('1.9.0') ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Might be worth validating that zones is a list rather than a single zone provided as a string.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Would be nice to warn the user their configuration is being ignored because the specified value wasn't recognized.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Use `self._search_regex` and `utils.unified_strdate` instead.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
You have some unmerged lines here
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
`current_version` could be mentioned in the error message.
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
Rename to something else. This extractor must delegate to embed extractor.
No need to parametrize with just one case.
Sorry, I think the current logic will only fall back to module if environment variable has not been specified: https://github.com/ansible/ansible/pull/17604/files/6c412fbeefa07e4296b33ec7544c5b1a69a6dcd8..85164a272274514877a6369877e851461a5acf0b#diff-0b1c579a3ccbeed5e582e7693e046cb6R112 I'll change the order, though, to put module first. Give me 5 mins.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
I added 4d4553bbb035ee1d49bff7925876c1dd88282bb6 so you can remove the try/except and just keep the contents of the try.
```suggestion {% if no_proxy | regex_search('\/') and ```
It likely makes sense to add the remaining psycopg2 parameters including host and port.
Use `self._search_regex` and `utils.unified_strdate` instead.
Use `self._search_regex` and `utils.unified_strdate` instead.
Use `self._search_regex` and `utils.unified_strdate` instead.
Use `self._search_regex` and `utils.unified_strdate` instead.
note: the 'startswith' _ is still needed for deprecations (but that is handled elsewhere), so we only skipped when it was a symlink (rename deprecating old name, not module itself) so this should 'work'tm as it is now
Don't re-invent URL parsing. Also, why `sub = sub.replace(';', '&')? ```suggestion parsed_url = compat_urlparse.urlparse(url) qs = compat_parse_qs(parsed_url.query) lang = qs.get('lang', [None])[-1] if not lang: continue ``` A URL query string might in principle have several `lang=xx` elements. The URL is parsed; the query string is returned as a `dict` of `list`s. We assume that, when it only makes sense for a query parameter to have one value, the last one in the list (-1) is meant. In this case it's probably the first as well.
Don't re-invent URL parsing. Also, why `sub = sub.replace(';', '&')? ```suggestion parsed_url = compat_urlparse.urlparse(url) qs = compat_parse_qs(parsed_url.query) lang = qs.get('lang', [None])[-1] if not lang: continue ``` A URL query string might in principle have several `lang=xx` elements. The URL is parsed; the query string is returned as a `dict` of `list`s. We assume that, when it only makes sense for a query parameter to have one value, the last one in the list (-1) is meant. In this case it's probably the first as well.
Wrong module names in examples.
1. I think it would make sense to pass the error message on. This can help a lot debugging when it doesn't work. 2. There might be other errors, for example when docker is not in swarm mode. In general, `client.nodes.list()` raises exceptions of type `docker.errors.APIError`.
We try to avoid defining ```_``` in case we ever decide to i18n the code. gettext traditionally uses ```_()``` to mark strings for translation and we wouldn't want to overwrite that.
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
Same question here about unsafe_shell as in get_default_interfaces()
Same question here about unsafe_shell as in get_default_interfaces()
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
Same question here about unsafe_shell as in get_default_interfaces()
It'd be interesting to see a test case for something inheriting a `BaseException` too.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
I realized last night my suggestion to make this an error is inconsistent with how the other sanity tests handle missing requirements. To maintain consistency it should be a warning instead: ```python display.warning("Skipping sanity test '%s' due to missing libyaml support in PyYAML." % self.name) return SanitySkipped(self.name) ``` I still see value in making missing test requirements an error, at least under some circumstances. We'll need to think more about how that should behave, and make sure it's consistent for all the tests.
As @flowerysong mentioned on IRC, this should have three choices and a default value.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
```suggestion query=dict(type='list', elements='str'), ```
I would remove the emoji here ;o)
I would remove the emoji here ;o)
Below change will fix the ` TypeError: the JSON object must be str, not 'dict'` error ``` try: obj = json.loads(item) command = obj['command'] except (ValueError, TypeError): command = item['command'] ```
Below change will fix the ` TypeError: the JSON object must be str, not 'dict'` error ``` try: obj = json.loads(item) command = obj['command'] except (ValueError, TypeError): command = item['command'] ```
This doesn't remove any orphan, it only checks whether there are any.
I think this should be 'exit' instead of 'abort'
I would remove the emoji here ;o)
I think this should be 'exit' instead of 'abort'
I think this should be 'exit' instead of 'abort'
Below change will fix the ` TypeError: the JSON object must be str, not 'dict'` error ``` try: obj = json.loads(item) command = obj['command'] except (ValueError, TypeError): command = item['command'] ```
I think this should be 'exit' instead of 'abort'
I would remove the emoji here ;o)
I would remove the emoji here ;o)
`not_data_actions` + tests (same as above)
`not_data_actions` + tests (same as above)
Below change will fix the ` TypeError: the JSON object must be str, not 'dict'` error ``` try: obj = json.loads(item) command = obj['command'] except (ValueError, TypeError): command = item['command'] ```
I would remove the emoji here ;o)
i don't think we want roles in roles
@jainnikhil30 and I took a look at the tower_cli code which is backing this tonight and decided that tower_cli is trying to coerce the types from a schema that it retrieves from the tower server. So it looks like the module code does not have to worry about this conversion.
Are both lolcube and bsod your github accounts? If not, please only use lolcube, as otherwise bsod will be informed for every issue and PR related to this module.
i don't think we want roles in roles
*be a string
-1 to ignoring this. There is a simple way to fix this for review process, though... Disable check mode in the argument spec. Then you can fix the module so that check mode does the right thing later.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
I think we want to deprecate NUMBERTYPES so instead of moving it, just use its definition here (list(ansible.module_utils.six.integer_types) + [float])
Please prefix this parameter with `rtmp_` so it's clear it's for RTMP only, unless it makes sense to return a result with `real_time` that does not use RTMP.
Great! The whole point of this is that you can skip all those silly `u` prefixes in your file though ;)
`default=None` for the first.
`default=None` for the first.
`compat_urlparse.urlparse` to extract query from original url. `update_url_query` to pack into new URL. Do not pack if original URL is used.
Check for `embed_code` instead.
Why not just pass the target directory? This is all your need to perform this task.
Same here. `self.api_client` instead of `client`
We have been using sphinx format for docstrings. In sphinx format, this would be: ``` :arg terms: a list of lookups to run. e.g. ['parameter_name', 'parameter_name_too' ] :kwarg variables: ansible variables active at the time of the lookup :kwarg aws_secret_key: One part of AWS credentials :kwarg aws_access_key: The second part of AWS credentials :kwarg aws_security_token: Third part of the AWS credentials :kwarg region: AWS region in which to do the lookup :kwarg bypath: Set to True to do a lookup of variables under a path :kwarg recursive: Set to True to recurse into paths below the path (requires bypath=True) :returns: A list of parameter values or a list of dictionaries if bypath=True. ```
He meant to evaluate if `thumb_list` is true in a boolean check, not to run `eval` with its content. ``` python if thumb_list: ... ``` Is equivalent to: ``` python if len(thumb_list) > 0: ... ```
Should this be `num_lines=3` for all three (cf. L140-L142)
Use `self._search_regex` and `utils.unified_strdate` instead.
Never ever do that. You must handle it at the place of the actual method call.
Nit: You have an extra period after 'example'
Please change this to ```python for current_line, next_line in zip(lines, lines[1:]): ```
Use `self._download_json` instead.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
This can be simplified to `[None] * 5` or `(None, ) * 5`.
To not mutate original dict by reference
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
ð, this is a nice little refactor.
Playlist title is optional.
The way this is done is going to lead to unicode errors eventually. This is probably the least messy way to handle that: ``` python msg = u"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s" % (name, type(e), to_text(e)) if errors == 'warn': display.warning(msg) elif errors == 'ignore': display.log(msg) else: raise AnsibleError(to_native(msg)) ```
The way this is done is going to lead to unicode errors eventually. This is probably the least messy way to handle that: ``` python msg = u"An unhandled exception occurred while running the lookup plugin '%s'. Error was a %s, original message: %s" % (name, type(e), to_text(e)) if errors == 'warn': display.warning(msg) elif errors == 'ignore': display.log(msg) else: raise AnsibleError(to_native(msg)) ```
Use built-in method? Also, should it crash (raise) if `json.loads()` fails, or just return an empty dict again? ```suggestion try: return self._download_json( url, song_id, data=data.encode('ascii'), headers=headers) except ExtractorError as e: if type(e.cause) in (ValueError, TypeError): # JSON load failure raise except Exception: pass return {} ```
Tests shouldn't be invoked directly, so this isn't needed.
Just assign the correct value to `video_id` later.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
What's the reason for using the shell here? There's no redirection, pipes, or other needs for the shell that I can see.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
That part of basic.py is there for backwards compatibility. Using six is the current way we do things.
Playlist title is optional.
Playlist title is optional.
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
I would suggest we at least display a message for this exception...
Space after #
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Plz also use `match` arg here
No. You should not shadow the original explicitly provided password.
Actually, we had some discussions about group names the previous days on IRC. Apparently dashes have been not allowed in group names from Ansible 2.4 on; this hasn't been enforced so far, but now (with Ansible 2.8) it will be. It's still possible to disallow it, but every group with a dash (or other invalid chars) in them will trigger a big fat warning. So please get rid of the dashes here so users of this inventory plugin won't automatically get a list of warnings, even if they don't have invalid chars in their labels.
ð, this is a nice little refactor.
This is actually one reason you want to use `MutableMapping` over subclassing `dict`. `.get()` does not use `.__getitem__()` in `dict`. Both methods duplicate code for performance: ```pycon >>> class VarsWithSources(dict): ... def __getitem__(self, key): ... val = super(VarsWithSources, self).__getitem__(key) ... print(('__getitem__', val)) ... return val ... >>> v = VarsWithSources() >>> v['foo'] = 'bar' >>> v['foo'] ('__getitem__', 'bar') 'bar' >>> v.get('foo') 'bar' ``` Notice that `.get()` doesn't cause the print to happen. As such, your implementation as is will only work with some accesses of keys, and not others.
terms can be a list, not sure if this is being handled correctly
While we may have done it in the past we don't want to be adding non host based facts to the `ansible_facts` return value. It's a bit confusing as this is technically a "facts" module but because we are getting facts on something that isn't the host we are running on, this should just be returning a dict. This is mainly because we can run this module on multiple SQL servers to get facts for different resources and we don't want to overwrite existing calls to this module. This is similar to the `stat` module where we can call stat on multiple objects and save the results in a variable using `register`
Can the native ElementTree api be used here. ```from xml.etree.ElementTree import fromstring``` This will reduce module dependency on `lxml`.
Use [`fetch_url`](https://github.com/ansible/ansible/blob/240d1a6afb43982f16acebef16778d17aab58160/lib/ansible/module_utils/urls.py#L1197) instead of `requests.get`
Have you even read it? Percent encoding is a plain mapping of characters to `%XX` representation per se. RFC 3989 determines the set of rules for applying this mapping to URIs, roughly speaking it determines the set of characters that should not be percent encoded so that this set is used in `escape_rfc3986` to fix some invalid URIs to meet the requirements. What `compat_urllib_parse.unquote` does is simply mapping `%XX` back to character representation for a plain string. This have nothing to do with URIs and with rules determined in RFC 3989.
No direct URLs in tests.
This should not be moved. They're libraries from the current project so go below the imports for stdlib and third party libraries.
<nod> to_native() should make it be str on both Python2 and Python3.
Lots of codes in this method duplicates swfinterp.py. Re-use existing codes instead.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Right, but the order in which you're doing things would at a glance result in the not-uncommon case of, eg `foo (cr)(lf)` not being properly treated, since the break `sub` wouldn't see that, but the char drop would remove the (cr), leaving a line ending that wouldn't format the right way.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Right, but the order in which you're doing things would at a glance result in the not-uncommon case of, eg `foo (cr)(lf)` not being properly treated, since the break `sub` wouldn't see that, but the char drop would remove the (cr), leaving a line ending that wouldn't format the right way.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
Please explain this in doc.
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
```suggestion for b_path in b_colldirs: ```
I think it makes sense to fail here instead. (Or return `[]`.)
This argument is only accepted in Python 3, it would not work with Python 2.
This argument is only accepted in Python 3, it would not work with Python 2.
You don't need a lambda here. Also, don't break lines with `\`.
s/Satellite/Foreman/g please ð
You appear to have dropped `Element`
@samdoran then, I'd say that there's something wrong with the setup and TZ should be adjusted somewhere.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
this won't always give the same result, it depends on env vars, that can vary by user and even task .. or task loop: ``` loop: [1,2,3] envioronment: '{{ difftempvar[item]}}' ```
Can you give an example for the error message coming from this? As stated above I would rather remove support for construtcs, which can raise exceptions here.
Note that this is also being removed in https://github.com/ansible/ansible/pull/68560
Cross-compability, backwards compatibility, command line compatibility, ease of discovery. * Other packaging modules support comma separated package entries. * The pip module itself supports comma separated package entries * pip supports single string entries as valid packages * comma separated list entries are the natural way to write lists on the commandline. * error messages if people were to violate these rules (for instance: ```ansible localhost -m pip -a 'names=django>=1.11.0,<1.12.0'``` wonn't point to the actual solution unless we implement this sort of detection for creating the error message... in which case we might as well do the right thing.
As far as I understand this is only necessary to support stuff like `djang>1.11.0,<1.12.0,bottle>0.10,<0.20,!=0.11`. Why should we support this? Using a list is to me the obviously better API and support this structure adds a lot of (to me unnecessary) complexity.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
May be true but this is general speaking. What behavior specific changes would you expect? Can we possibly test against those? I don't think it is meaningful to duplicate code in n modules when using OOP style.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
Nit: Almost ;-) To be or not to be, and also where, that is the question.
~take no_log from task~ nvmd, task failed to template ...
I like this simplification but I believe that it should done somewhere in the core (suggestion for another PR) and not on per-module bases.
Please fix url to` 'https://api.telegram.org/bot' + token + '/sendMessage?text='` and examples descriptions to `token: '9999999:XXXXXXXXXXXXXXXXXXXXXXX'` Because BotFather return token without "bot" string
Hm, given those 15(?) other tests that failed on Python 3 in calls to syslog.syslog(), could we monkey-patch the rest of the tests so this is the only test that actually writes to the real syslog/journal? (EDIT: when I say "the rest of the tests", I mean in test_basic.py.)
This seems wrong. Won't this end up being the equivalent of: ``` /bin/sh -c if [ x"test" = x"test" ] ; then printf "hi" ; fi ``` When what we really want is the former which is the equivalent of: ``` /bin/sh -c 'if [ x"test" = x"test" ] ; then printf "hi" ; fi' ```
This check doesn't work as-is and raises issues when running the following playbook two times in a row: ``` --- - hosts: localhost tasks: - openssl_privatekey: path: /tmp/private.key - openssl_csr: path: /tmp/csr.csr privatekey_path: /tmp/private.key commonName: www.ansible.com ``` This is due to the fact thatthe current code relies on `expected` being an array when it could be actually None, hence raising: ``` TypeError: 'NoneType' object is not iterable ``` Here is an alternative implentation that did what was expected, feel free to modify adapt/modify/get ideas from it: ``` usages_ext = [str(ext) for ext in extensions if ext.get_short_name() == extName] if (not usages_ext and expected) or (usages_ext and not expected): return False elif not usages_ext and not expected: return True else: current = [usage.strip() for usage in usages_ext[0].split(',')] expected = [long[usage] for usage in expected] return current == expected ```
Maybe you could use a CM here as well.
Maybe you could use a CM here as well.
This seems like it will make for a hard API to use because it will fail when the lock_file is owned by another user (so playbooks run by different users or async with tasks that become different users will raise Permission denied errors). It seems like problems opening the lock_file should be part of the timeout.
This seems like it will make for a hard API to use because it will fail when the lock_file is owned by another user (so playbooks run by different users or async with tasks that become different users will raise Permission denied errors). It seems like problems opening the lock_file should be part of the timeout.
This seems like it will make for a hard API to use because it will fail when the lock_file is owned by another user (so playbooks run by different users or async with tasks that become different users will raise Permission denied errors). It seems like problems opening the lock_file should be part of the timeout.
~~why stat and return the data when you are dropping it on caller?~~ 2nd caller does use
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
```suggestion iterator.host_not_in_inventory(host_name) ```
```suggestion iterator.host_not_in_inventory(host_name) ```
You're checking two separate properties here. This should be in a separate test.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
connection plugins should not have their own python logic. If distros are using different python/missing python it is up to user to add (plenty of examples with raw and ansible_python_interpreter).
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
That's not a place for essays and repeating the code itself.
That's not a place for essays and repeating the code itself.
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
Matching empty string is senseless.
Use `\s*` instead.
This extracts mess instead of download URL: ``` >youtube-dl http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/ -f 720p-1500k-cdn2b-0 -g http://cdn2b.download.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500 &s=1445177200&e=1445350800&h=178da8509b9b869e9ad12809e016f078' title='Download Video'>MP4 HD - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(37 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/480p_370k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=e5b5291f1ade3a2ea66af312daf37a04' title='Download Video'>MP4 - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(9 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=7b1ceb68fd3affe8f2308a6501cbb218' title='Download Video'>MP4 - For iPhone/iPod</a> <span class='downloadsize'>(6 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/180p_150k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.3gp?rs=150 &ri=1000&s=1445177200&e=1445350800&h=c8ce8aa7f320c8c9253a1a3a6817539c ```
You can use `random.choice` instead
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
This extracts mess instead of download URL: ``` >youtube-dl http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/ -f 720p-1500k-cdn2b-0 -g http://cdn2b.download.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500 &s=1445177200&e=1445350800&h=178da8509b9b869e9ad12809e016f078' title='Download Video'>MP4 HD - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(37 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/480p_370k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=e5b5291f1ade3a2ea66af312daf37a04' title='Download Video'>MP4 - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(9 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=7b1ceb68fd3affe8f2308a6501cbb218' title='Download Video'>MP4 - For iPhone/iPod</a> <span class='downloadsize'>(6 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/180p_150k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.3gp?rs=150 &ri=1000&s=1445177200&e=1445350800&h=c8ce8aa7f320c8c9253a1a3a6817539c ```
Good catch! yeah there should be a warning.
This extracts mess instead of download URL: ``` >youtube-dl http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/ -f 720p-1500k-cdn2b-0 -g http://cdn2b.download.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500 &s=1445177200&e=1445350800&h=178da8509b9b869e9ad12809e016f078' title='Download Video'>MP4 HD - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(37 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/480p_370k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=e5b5291f1ade3a2ea66af312daf37a04' title='Download Video'>MP4 - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(9 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=7b1ceb68fd3affe8f2308a6501cbb218' title='Download Video'>MP4 - For iPhone/iPod</a> <span class='downloadsize'>(6 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/180p_150k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.3gp?rs=150 &ri=1000&s=1445177200&e=1445350800&h=c8ce8aa7f320c8c9253a1a3a6817539c ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Some more: avc2, avc3, avc4. These would be enough.
This extracts mess instead of download URL: ``` >youtube-dl http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/ -f 720p-1500k-cdn2b-0 -g http://cdn2b.download.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500 &s=1445177200&e=1445350800&h=178da8509b9b869e9ad12809e016f078' title='Download Video'>MP4 HD - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(37 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/480p_370k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=e5b5291f1ade3a2ea66af312daf37a04' title='Download Video'>MP4 - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(9 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=7b1ceb68fd3affe8f2308a6501cbb218' title='Download Video'>MP4 - For iPhone/iPod</a> <span class='downloadsize'>(6 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/180p_150k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.3gp?rs=150 &ri=1000&s=1445177200&e=1445350800&h=c8ce8aa7f320c8c9253a1a3a6817539c ```
This extracts mess instead of download URL: ``` >youtube-dl http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/ -f 720p-1500k-cdn2b-0 -g http://cdn2b.download.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500 &s=1445177200&e=1445350800&h=178da8509b9b869e9ad12809e016f078' title='Download Video'>MP4 HD - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(37 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/480p_370k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=e5b5291f1ade3a2ea66af312daf37a04' title='Download Video'>MP4 - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(9 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=7b1ceb68fd3affe8f2308a6501cbb218' title='Download Video'>MP4 - For iPhone/iPod</a> <span class='downloadsize'>(6 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/180p_150k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.3gp?rs=150 &ri=1000&s=1445177200&e=1445350800&h=c8ce8aa7f320c8c9253a1a3a6817539c ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
This extracts mess instead of download URL: ``` >youtube-dl http://www.youporn.com/watch/505835/sex-ed-is-it-safe-to-masturbate-daily/ -f 720p-1500k-cdn2b-0 -g http://cdn2b.download.youporn.phncdn.com/201012/17/505835/720p_1500k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=200&ri=2500 &s=1445177200&e=1445350800&h=178da8509b9b869e9ad12809e016f078' title='Download Video'>MP4 HD - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(37 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/480p_370k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=e5b5291f1ade3a2ea66af312daf37a04' title='Download Video'>MP4 - For Windows 7/8, Mac and iPad</a> <span class='downloadsize'>(9 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/240p_240k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.mp4?rs=150 &ri=1000&s=1445177200&e=1445350800&h=7b1ceb68fd3affe8f2308a6501cbb218' title='Download Video'>MP4 - For iPhone/iPod</a> <span class='downloadsize'>(6 MB)</span> </div> <div class='downloadOption'> <i class='icon icon-download to-text-green'></i> <a href='http://cdn2b.download.youporn.phncdn.com/201012/17/505835/180p_150k_505835/YouPorn%20-%20Sex%20Ed%20Is%20It%20Safe%20To%20Masturbate%20Daily.3gp?rs=150 &ri=1000&s=1445177200&e=1445350800&h=c8ce8aa7f320c8c9253a1a3a6817539c ```
Some more: avc2, avc3, avc4. These would be enough.
This is usually not needed
Ok, there's one thing we forgot: a `timedelta` object also has `days`, and seconds are up to one day. Fortunately, there's an easier way to do this all: ```suggestion time_in_nanoseconds = int(time.total_seconds() * 1000000000) ```
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
so this assertion looks incorrect, i would expect and empty string as the ssh args
It's a good practice to have a trailing comma after the last sequence item as well. This way, when someone will add or remove an item it will generate only one line of diff, as opposed to two lines: one for the logical change and one for editing comma next to unrelated item. This practice makes doing reviews easier and more joyful :)
It's a good practice to have a trailing comma after the last sequence item as well. This way, when someone will add or remove an item it will generate only one line of diff, as opposed to two lines: one for the logical change and one for editing comma next to unrelated item. This practice makes doing reviews easier and more joyful :)
community.general also contains some of the modules of the `k8s` module defaults group (the `kubevirt` modules), and some modules of the `ovirt` module defaults group (the deprecated `_facts` modules).
ERROR rather than BLAH :)
- Slicing creates a copy so it might be better to avoid doing that inside of the inner loop - We can move some calculations outside the loop (although it probably won't make much difference with just 3 passes). - Instead of assert, we probably want to write a unittest to check that this does the right thing. I'm okay with leaving the assert in until we write a unittest, though. So it would look something like this: ``` python chunk_len = min(1024 * 1024 * 2, file_len) with open(tmp_path, "wb") as fh: for _ in range(passes): fh.seek(0, 0) # get a random chunk of data data = os.urandom(chunk_len) for _ in range(0, file_len // chunk_len): fh.write(data) fh.write(data[:file_len % chunk_len]) assert(fh.tell() == file_len) # Remove this assert once we have unittests to check its accuracy os.fsync(fh) ``` Hopefully that's right and I'm not off by one byte :-)
remove unused keyword `args`
remove unused keyword `args`
No really necessary but if you want to keep it I would capitalise it and add a full stop.
No really necessary but if you want to keep it I would capitalise it and add a full stop.
No really necessary but if you want to keep it I would capitalise it and add a full stop.
```suggestion # just get value from attribute itself as normal ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
It'd be interesting to see a test case for something inheriting a `BaseException` too.
Do note that this only looks at the primary credential cache. This means that if you use a collection credential cache such as DIR, KEYRING or KCM (default in most distributions these days), you might not see a ticket that exists in a non-primary credential cache. Maybe consider using `klist -A`, or try a `kswitch -p <principal>`? The latter is easier to parse, but might break stuff if people are still using the old krb5 APIs (rather than GSSAPI) and were using the primary credential that you just made secondary.
Don't re-invent URL parsing. Also, why `sub = sub.replace(';', '&')? ```suggestion parsed_url = compat_urlparse.urlparse(url) qs = compat_parse_qs(parsed_url.query) lang = qs.get('lang', [None])[-1] if not lang: continue ``` A URL query string might in principle have several `lang=xx` elements. The URL is parsed; the query string is returned as a `dict` of `list`s. We assume that, when it only makes sense for a query parameter to have one value, the last one in the list (-1) is meant. In this case it's probably the first as well.
Is the `sorted()` actually useful here? You're adding the keys to a standard python dict, which is unsorted by nature.
Use character set instead.
i would just add 'meta' here and do 1 join vs 2 of em
It's possible to get a `jenkins.JenkinsException: job[your_job] number[1] does not exist` here. Maybe adding a try/catch for this? ```python try: if self.server.get_build_info(self.name, self.build_number)['building']: time.sleep(1) else: return except jenkins.JenkinsException as e: time.sleep(1) ```
use `str(e)` (this is not the optimal, but that is true for most of this file) cc @abadger
Breaks if `node_views_class` is `None`.
Move before like youtube embed.
i would just add 'meta' here and do 1 join vs 2 of em
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
No. You should not shadow the original explicitly provided password.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
`acodec == 'none'`.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
can delete this line now I think.
1. Breaks if div is not found. 2. `re.finall`.
You don't need a lambda here. Also, don't break lines with `\`.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Please remove this example, since I would consider this usage as not recommended.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
And remove this afterwards.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
syntax error here too.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
syntax error here too.
*nit* `/play.For/playbook. For /`
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Lists also have .extend() which might be what you need here
This is what `urlencode()` is already doing for you., so the function would be: ```python def encode_url_params(self, params): """Encodes key value pairs for URL""" return '?' + urlencode(params.items())
Move data and query into `_download_webpage` call.
If the line would be `cmd = self.docker_cmd`, the original value of `self.docker_cmd` (which is a list) would be modified by the `cmd += ...`'s below. That's why a copy must be created.
`display` won't work in module code, hence this line should be removed
nvm, I figured it out
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
Are we guaranteed to only receive ascii text via self.client.recv? If not, then this could fail if we get the first half of a multi-byte character in buf and the second half is coming in the next chunk. Encoding and decoding is also faster when you do it a single time on a larger buffer rather than multiple times on smaller buffers. Between those two thoughts, perhaps it would be better to code this like: ``` python self.client.sendall(to_bytes('%s\n' % cmd)) result = b'' buf = b'' buf = self.client.recv(RECV_SIZE) while buf: result += buf buf = self.client.recv(RECV_SIZE) result = to_text(result, errors='surrogate_or_strict') if capture_output: [...] ```
`display` won't work in module code, hence this line should be removed
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Could you please keep the same string quoting style across the module? ```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('UTC')), '2019-06-15T14:45:00+00:00'), ```
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
There is no guarantee something was changed here. So this would mean the module can only either fail or report changes.
Don't you need `migrations` (from three lines below) here? Otherwise you cannot use that object.
I don't think you need to return this fixed string on success. Just not returning anything should be fine.
There is no guarantee something was changed here. So this would mean the module can only either fail or report changes.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
looks good, thanks
If either of these attrs is missing whole playlist extraction is broken.
If we're just testing broker compatibility I don't think we even need this part of the test.
Looks like this is used now, yay :-)
I'd keep the original style here: ```suggestion version_schema = { Required('removed_in'): deprecation_versions(), } ```
Array ellipsis is an obscure feature and not necessary here. It hinders readability
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
```suggestion print('hijacked sys.path to use ansible-vendored files, bwahaha', file=sys.stderr) ``` (because this log entry is added after the fact)
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
```suggestion print('hijacked sys.path to use ansible-vendored files, bwahaha', file=sys.stderr) ``` (because this log entry is added after the fact)
You should probably expect unicode strings
You're checking two separate properties here. This should be in a separate test.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
use `_html_search_regex` and get rid of `unescapeHTML`.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Please introduce line breaks in the docstring to avoid very long lines.
This one is fine too
format is python2.6+ So keep using %. If you want to you can also switch from str(e) to to_native(e) where you to_native by doing from ansible.module_utils._text import to_native. (to_native will be more resistant to tracebacks than str).
See `unified_strdate()` in `utils.py`.
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
See `unified_strdate()` in `utils.py`.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Please remove this example, since I would consider this usage as not recommended.
No need to parametrize with just one case.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
`None` is not an id.
I would split these ('install' and 'install --offline -p -r etc') into two separate tests so any failures are more specific and granular.
This is never reached cause sort formats will throw on `not formats`.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
This will fail if `len(data) == 1`, which you explicitly allow above.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
you cannot pass 2 commands to command, argv is not for that, it is to pass the command and the arguments to the command
.message doesn't exist at all when running Python 3. The exception handling guidelines have also added BotoCoreError to exceptions that should be caught (which do not have a .response attribute). https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-1
Do not need the enumerate here. i is not used.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
If the line would be `cmd = self.docker_cmd`, the original value of `self.docker_cmd` (which is a list) would be modified by the `cmd += ...`'s below. That's why a copy must be created.
we use -o for output file elsewhere, it is not good to overload options with diff meanings
So this class can be initialized with both format we send and format we receive? Neat! :heart: Worth mentioning in docstring IMHO.
So this class can be initialized with both format we send and format we receive? Neat! :heart: Worth mentioning in docstring IMHO.
This should be checked before training, at the model setting stage. Also this is not style compliant (use `if / raise ValueError` instead).
This isn't used anywhere
This isn't used anywhere
This isn't used anywhere
This isn't used anywhere
The same thing.
The exception needs to be re-raised if `skip_broken` is not set, otherwise it's lost.
1. Single quotes. 2. `expected`.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
The exception needs to be re-raised if `skip_broken` is not set, otherwise it's lost.
fixture with load_json
you might want to get the module/action as the include can be given a name that does not match `include:`
Lots of codes in this method duplicates swfinterp.py. Re-use existing codes instead.
Returning would close the file (I think) since you're already in a 'with' statement.
Would be good change this line to explain a bit about what this is done. No need to detail the supported operations, that's what `choices:` is for, so the following line can be removed.
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
Returning would close the file (I think) since you're already in a 'with' statement.
We might want to introduce new/old git dir path in the result.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
This change breaks MTVServicesEmbeddedIE
Typo in the help message
Must be numeric.
Must be numeric.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
```suggestion module.fail_json(msg="Cannot dump database(s) %r - not found" % (', '.join(non_existence_list))) ```
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
Right, better to use `then_expression` etc.
This is not used in single video extractor thus should not be here.
There's no need to wrap this in a `try`/`except`.
this might end up confusing users as to which error produced the failure, i suggest pushing the conditional error into a debug statement
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
This is error prone, `len` of the actual string should be used instead.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
This is error prone, `len` of the actual string should be used instead.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
There's no need to wrap this in a `try`/`except`.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
There's no need to wrap this in a `try`/`except`.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
In BSD, this is stored as seconds since epoch, so no need to multiply by 86400. ``` 0.0s modify_user: current_expires=2529878400 ```
we should not be adding a python dependency on ordereddict here, as python2.7 can also use ordereddict from collections: https://docs.python.org/2/library/collections.html#collections.OrderedDict This also means, that python2.7 users now need an additional python dependency installed.
.message doesn't exist at all when running Python 3. The exception handling guidelines have also added BotoCoreError to exceptions that should be caught (which do not have a .response attribute). https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-1
ð, this is a nice little refactor.
No need to use a backslash before the single quotes.
You can import `try_rm` from helper
You can import `try_rm` from helper
.message doesn't exist at all when running Python 3. The exception handling guidelines have also added BotoCoreError to exceptions that should be caught (which do not have a .response attribute). https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-1
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
ð, this is a nice little refactor.
You can import `try_rm` from helper
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
You can import `try_rm` from helper
You can import `try_rm` from helper
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
ð, this is a nice little refactor.
@jimi-c is the intention that "nothing *should* be using this, but just in case someone out in the ether *is* using then we're not going to break them"? .... that's how I understood it but would like to clarify given @abadger's question.
Tests shouldn't be invoked directly, so this isn't needed.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
Is there a reason we are `pop`ing these? In fact, looking at it, these should be legit keywords in method, rather than just doing `**kwargs`. It could still be: ``` def __init__(self, appid=None, query=None, output=None, **kwargs): ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
```suggestion module.fail_json(msg="Cannot dump database(s) %r - not found" % (', '.join(non_existence_list))) ```
is it important to have 3 brokers for this test? I'm wondering if the tests would be more resilient and faster with just one broker and replica of each topic.
the second parameter for `_download_*` methods is `video_id`, use the `note` parameter for the message.
For consistency, use `'` as the quote character
eliminate intermediate list ```suggestion new_versions = set(v for v in self.versions if self._meets_requirements(v, requirement)) ```
Are you only doing this to support Python 2.6? Those keys are already unique.
Are you only doing this to support Python 2.6? Those keys are already unique.
There is no `getheader` in python 2.
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
so this assertion looks incorrect, i would expect and empty string as the ssh args
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
`pool_size` would be commonly used as positional argument.
```suggestion Kwargs: ```
I completely missed that, apologies
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
No need to parametrize with just one case.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
I don't think this line should be modified.
`/?` is senseless at the end.
3. seems to be not working as expected. It should be the 'same handler', the new one should override the old one since they share the same name, so its not first found, but 'only found' which should be the 'last one with the same name'. If the behaviour is as described above, it seems we are not doing the update correctly and this is what we should fix. We probably avoiding a re-import of handlers not realizing the 'signature' of the role is different, death by optimization ...
```suggestion query=dict(type='list', elements='str'), ```
Use `assert_allclose`` instead
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
both are valid tests, i don't see why you need to eliminate the existing one
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
And remove this afterwards.
And remove this afterwards.
If 'plflag' is not in `video_info`, this line crashes. This should work: (not tested) `.get('plflag')` => `.get('plflag', '')`
you can move it to before `if` as just `docs = {}` line, this should read better.
Matching empty string is senseless.
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
Matching empty string is senseless.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
This should be extracted first.
There are some options to `AnsibleModule` which you may be able to use to validate options passed in. Look at existing modules for examples: ``` mutually_exclusive ```
fixture with load_json
There are some options to `AnsibleModule` which you may be able to use to validate options passed in. Look at existing modules for examples: ``` mutually_exclusive ```
both are valid tests, i don't see why you need to eliminate the existing one
Valid JS could include white space around `.`, `(`, `)`, `[`, `]`, and `,`, though it makes the RE a bit messier, something like this: ``` r'Page\s*\.\s*messaging_box_controller\s*\.\s*addItems\s*\(\s*\[\s*(?P<msg>{(?!.*}\s*,\s*{).+?})\s*\]\s*\)' ```
Use `\s*` instead.
Yes, present usually is the default state. In some cases there is no default state (which means the user is expected to provide it explicitly).
Yes, present usually is the default state. In some cases there is no default state (which means the user is expected to provide it explicitly).
Ah never mind, I forgot that the `if response` handles when the recursive URL lookup might have ended.
Ah never mind, I forgot that the `if response` handles when the recursive URL lookup might have ended.
Ah never mind, I forgot that the `if response` handles when the recursive URL lookup might have ended.
Probably this will work instead? `urllink = ''.join([str(urlcode[key]) for key in sorted(urlcode.keys())])`
I've already pointed out: replacing one time-proven working data extraction approach with another is not an improvement and I will reject all such further PRs. All additional scenarios should be added as fallbacks. Again, this code is not PEP 8 compliant.
Use single quotes consistently whenever possible. If this is expected error pass `expected=True`.
Technically since we're doing this in a fixture, either `monkeypatch` should be used to insert these into `globals()`, or you should return `mod`, and then just use `mod.Template` and `mod.AnsibleNativeEnvironment` in your tests.
It probably makes sense to create a new `utils.py` module which has a function `write_to_file_if_different(filename, data)` which does the heavy lifting (and where this is done cleanly), so that all the details are only repeated once.
use ```from ansible.module_utils.vmware import get_cluster```
use ```from ansible.module_utils.vmware import get_cluster```
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
you should use `loop`, `with_items` is deprecated :)
Bravo on tackling one of the gnarlier test setups ;-> :+1:
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
s/write target file {0}/put_file to {0}/
there is a helper in `AnsibleModule` for mutually exclusive params: ~~~diff module = AnsibleModule( argument_spec=argument_spec, + mutually_exclusive=(('positional_args', 'named_args'),), supports_check_mode=True, ) ~~~
I think this should be `_return_if_object` since it isn't part of the public API.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
It seems like no_log and deprecation are separate things and should be handled in separate functions.
This ignores additional keyword arguments possibly passed by the user.
This ignores additional keyword arguments possibly passed by the user.
'p' is already removed when, kwargs.pop('p')
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
Could you clarify what's happening by adding an example 2-line CSV file? I think that would improve the docs.
This doesn't match because your test uses `http://` instead of `https://`.
should we ask for a file name? (default to stdout is fine)
This doesn't match because your test uses `http://` instead of `https://`.
You should add a coding cookie on top of the file instead.
this should probably be reworded without using API-isms- it's basically the thing discussed before on other list types, where you're accepting the absolute list, not a set to be merged with the existing list.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
You may try
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
this is a setting 'resolved' not the definition, you are mixing the concepts here.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
If we're just testing broker compatibility I don't think we even need this part of the test.
You should add a coding cookie on top of the file instead.
Should the `continue` be here? The following 3 lines will never get evaluated.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
f is already at 0, the `truncate()` is uselesss.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Can we detect if this is not a json and fallback to print it directly
```suggestion action: add ```
I expected an example URL for > more time in one line
Tests shouldn't be invoked directly, so this isn't needed.
Tests shouldn't be invoked directly, so this isn't needed.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Sorry, it's been some time since I was faced with this issue, thank you for clarifying.
Sorry, it's been some time since I was faced with this issue, thank you for clarifying.
check_output is not python2.6 compatible
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Please make this method private.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
Returning would close the file (I think) since you're already in a 'with' statement.
Please make this method private.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
Please make this method private.
Returning would close the file (I think) since you're already in a 'with' statement.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
The return value is not strictly cookies. The return value is a dictionary of headers
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
Returning would close the file (I think) since you're already in a 'with' statement.
Please make this method private.
Use markdown format for links
Please make this method private.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
Returning would close the file (I think) since you're already in a 'with' statement.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
Please make this method private.
Please make this method private.
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
Space after `,`.
Space after `,`.
Space after `,`.
Something like this instead: ``` python def _get_vm_prop(vm, attributes): result = vm for attribute in attributes: try: result = getattr(result, attribute) except AttributeError: return None return result _get_vm_props(vm, ('guest', 'toolsRunningStatus')) ```
Do not remove old patterns.
We use `pytest` to run tests and the helpers from `unittest.TestCase` should be avoided (ideally, `unittest.TestCase` should never be used because it limits the compatibility with `pytest`). Instead, use `pytest.raises()`: ```suggestion expected_error_msg = ( r'^The --prompt option is not supported if ' r'also reading input from stdin$' ) with pytest.raises(errors.AnsibleOptionsError, match=expected_error_msg): cli.parse() ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
It is blocking, but that's not the problem - `parser.error` is guaranteed to terminate the program, so this line is indeed superfluous
`skip_download` is needed for the test to pass similar to the first test.
Are you sure you want to reset `self._pos` here? Normally `__iter__(self)` should be non-destructive so that you may write: `iter(iter(iter(my_value_iterator)))`
Here you ignore the fractional parts (milliseconds, microseconds). You need to add `1000 * timedelta(**time_params).microseconds`. (Also, you should store `timedelta(**time_params)` in a variable, instead of `time_in_seconds`, and work with that one.) I.e. something like: ``` .py time = timedelta(**time_params) time_in_nanoseconds = (time.seconds * 1000000 + time.microseconds) * 1000 ```
So removed `required=False` and add `type='str' instead. Do this for the others as well.
Put the object creation out of this function in the `main` to be more readable. Then only pass the gitlab object to your function.
no need to specify required=False or type=str as these are defaults
This branch is never reached.
Thanks for your work on this! It works as expected (although I wish describe_db_instances() could filter by tags as it would be simpler not to filter out the results while retrieving them).
Recursion should be replaced with plain loop.
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
This should be deduced from class name in `PostProcessor.PP_NAME` similarly to `InfoExtractor.IE_NAME`.
we really need something generic.... getting complex :-)
```suggestion query=dict(type='list', elements='str'), ```
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
Line is too long.
This line is too long. Max line length allowed in Ansible is 120 characters.
Well, basically that's the problem of these people not us. We don't care whether one can read regexp or not. Moreover most likely next time this code is read by someone is when extractor breaks due to layout change. Chances are this snippet is already irrelevant by that time.
same as others, return directly test
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
same as others, return directly test
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
is there a convention for this? I'm wondering if this could be more than binary (present / absent / disabled)
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
Is`atexit` is the right approach here? The registered function will only run when the entire ducktape process finishes (i.e. _after_ all ~215 tests finish). Use of the `tempfile.mkdtemp` will still avoid path collisions from concurrent processes, so maybe it's good enough. Another possibility that at least results in immediate cleanup: put directory removal into `clean_node` (but check the containing directory is present before removing to avoid errors)
You don't need a lambda here. Also, don't break lines with `\`.
Remove superfluous verbosity.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
again, use `_download_json` `query` argument.
How about: ```suggestion if not os.path.exists(file_path): continue ```
Adding the exception string to the error would help the user narrow down what the issue is.
Adding the exception string to the error would help the user narrow down what the issue is.
again, use `_download_json` `query` argument.
self.cache contains function `get_all_objs` which already does this, so we can reuse it directly rather than modifying `find_obj`
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Good catch, thanks for cleaning this up!
even hardcoding /tmp is not a good option, some systems create a per user /tmp mount .. aside from other more restricted permissions and file system types that might not work well with locks. if i had an easy answer to this, i would have already done it, but it is much harder than you would think at first approach.
```suggestion query=dict(type='list', elements='str'), ```
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
Are you sure it isn't Javascript code instead of JSON? If so, you can use `js_to_json`
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
missing from docs fragment
This will throw an exception every time when a server is down. When glusterfsd is down the output looks like this: Brick 10.70.43.200:/mnt/engine Status: Transport endpoint is not connected Number of entries: - And you'll be trying to do int('-') which will throw ValueError. And the module throws error: fatal: [10.70.42.25]: FAILED! => {"changed": false, "msg": "Invalid heal status option."} in the function main.
`ipv4_addrs` is a misleading name since ip version depends on `filter_for` and not necessarily equals v4.
missing from docs fragment
missing from docs fragment
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
`InvalidInternetID` doesn't seem to exist according to botocore's source
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
please remove the extra space at the start of the line to fix the failing tests
this should probably use the BOOLEAN tests from module_utils
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
Should be `mp4`.
Should be `mp4`.
Don't need to import HAS_BOTO3 now.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
here you should not need to check for deprecated if we are going to mandate deprecated_version
Returning would close the file (I think) since you're already in a 'with' statement.
My next question was going to be if the random boot ID is widely available. I guess I'll have to do some research to see when it was added. I created a WIP PR (#45656) exploring what it would look like to add platform and dist to the plugin. I'm not terribly happy with it, but it's a start (and it accounts for Alpine, which is particularly annoying since it lacks both `who` and `uptime` for no good reason (IMO)). That PR also changes to using the random boot ID by default rather than `who -b`. That has the nice side effect of being able to remove the `uptime -s` command for systems that lack a RTC, but at the cost of all the added complexity of platfrom and dist checking.
There are added empty lines. Please remove them.
In that case, we'd also better drop it, otherwise we'll get idempotency problems...
My next question was going to be if the random boot ID is widely available. I guess I'll have to do some research to see when it was added. I created a WIP PR (#45656) exploring what it would look like to add platform and dist to the plugin. I'm not terribly happy with it, but it's a start (and it accounts for Alpine, which is particularly annoying since it lacks both `who` and `uptime` for no good reason (IMO)). That PR also changes to using the random boot ID by default rather than `who -b`. That has the nice side effect of being able to remove the `uptime -s` command for systems that lack a RTC, but at the cost of all the added complexity of platfrom and dist checking.
Can we print entire error rpc. In case of error `message` alone is not very helpful.
should be list(attr.items())[0] to work with python3 too. ``` An exception occurred during task execution. The full traceback is: Traceback (most recent call last): File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 310, in <module> main() File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 280, in main attrs = EcsAttributes(module, attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 131, in __init__ self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 151, in _parse_attrs name, value = attr.items()[0] TypeError: 'dict_items' object does not support indexing fatal: [localhost]: FAILED! => { "changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 310, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 280, in main\n attrs = EcsAttributes(module, attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 131, in __init__\n self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 151, in _parse_attrs\n name, value = attr.items()[0]\nTypeError: 'dict_items' object does not support indexing\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0 } PLAY RECAP ********************************************************************* localhost : ok=0 changed=0 unreachable=0 failed=1 ```
Move flags into regex.
Probably the same with `--label` instead of `--uuid` here.
should be list(attr.items())[0] to work with python3 too. ``` An exception occurred during task execution. The full traceback is: Traceback (most recent call last): File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 310, in <module> main() File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 280, in main attrs = EcsAttributes(module, attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 131, in __init__ self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 151, in _parse_attrs name, value = attr.items()[0] TypeError: 'dict_items' object does not support indexing fatal: [localhost]: FAILED! => { "changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 310, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 280, in main\n attrs = EcsAttributes(module, attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 131, in __init__\n self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 151, in _parse_attrs\n name, value = attr.items()[0]\nTypeError: 'dict_items' object does not support indexing\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0 } PLAY RECAP ********************************************************************* localhost : ok=0 changed=0 unreachable=0 failed=1 ```
`del` is a builtin, not a function. These parens don't have to be here
please add `type: bool`
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
It seems like no_log and deprecation are separate things and should be handled in separate functions.
You have some syntax errors in this `if` statement.
Breaks. Read coding conventions on optional data.
extract mandatory information before optional information.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
`current_version` could be mentioned in the error message.
Just an empty line, could be removed for cleaner code
These imports need to be moved back to where they were. As you can see moving it has caused CI to fail.
I think this should be replaced with `K.epsilon()`.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Move flags into regex.
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
`expected_status` to `_download_json` instead.
We should disable pylint's check for this one line rather than doing this. doing this defeats part of the purpose of having a compatibility library.
check_output is not python2.6 compatible
check_output is not python2.6 compatible
please use here: ```python self.changed = True if not self._module.check_mode: auth_keys_service.key_service(key).remove() ```
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
ð, this is a nice little refactor.
ð, this is a nice little refactor.
No need to escape `\`.
No need to escape `\`.
Please add our boilerplate to the top of this file. One of those pieces of boilerplate makes all classes defined in the file new-style classes. Without it, a class definition which doesn't inherit from object is an old-style class. ``` from __future__ import (absolute_import, division, print_function) __metaclass__ = type ```
Please add our boilerplate to the top of this file. One of those pieces of boilerplate makes all classes defined in the file new-style classes. Without it, a class definition which doesn't inherit from object is an old-style class. ``` from __future__ import (absolute_import, division, print_function) __metaclass__ = type ```
Please add our boilerplate to the top of this file. One of those pieces of boilerplate makes all classes defined in the file new-style classes. Without it, a class definition which doesn't inherit from object is an old-style class. ``` from __future__ import (absolute_import, division, print_function) __metaclass__ = type ```
```suggestion # just get value from attribute itself as normal ```
It might also be no IGWs found here.
```suggestion # just get value from attribute itself as normal ```
It might also be no IGWs found here.
again, this syntax we should phase out ``` asks_file: "{{ lookup('first_found', files=['tasks.yaml', 'other_tasks.yaml'], errors='ignore') }}" ```
again, this syntax we should phase out ``` asks_file: "{{ lookup('first_found', files=['tasks.yaml', 'other_tasks.yaml'], errors='ignore') }}" ```
I'd suggest update the existing test directly in this PR.
Also, you don't actually need these error messages after `assert` since this is a unit test
nvm, I figured it out
Also, you don't actually need these error messages after `assert` since this is a unit test
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
when you opt-in to using a CM like this, make sure you only patch lines that you really need to patch. and put any assertions outside, whenever possible: ```suggestion assert ret == [] ```
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
URIs do not need an non-empty netloc. That's only a requirement for URLs as far as I understand it.
`size` is optional parameter so adding check against `None` would help here. ```python if not module.params.get('size', False): module.fail_json(msg="Size is required to update volume")
Is it necessary to make `TASK_DELIMITER` configurable? I feel it is unnecessarily complicating the setup..
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Please break line into 2, for length ```python if (isinstance(min_value, (int, float)) and isinstance(max_value, (int, float))): ``` (same below)
@willthames bcoca asked me to look at your problem. I think that we want to use to_native() here and we probably want to use errors='surrogate_or_strict' as well. to_native() converts the string into the type which an undecorated string literal has on that version of python. That type is called "str" on both python2 and python3 but it's a byte string on python2 and a text string on python3. It will have the following benefits: * It's the most compatible since it's the same type as str on both platforms. (It just has better defaults and more flexible error handling than using str()). * For most module_utils code, we use native string types right now so that a module author can mostly write idiomatic python and it mostly just works. They don't run into a problem combining byte and text type. (They do have to worry about it when they deal with an external API which needs a specific type but those are not as common so it's easier to deal with those when the time comes and not worry the rest of the time).
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
@willthames bcoca asked me to look at your problem. I think that we want to use to_native() here and we probably want to use errors='surrogate_or_strict' as well. to_native() converts the string into the type which an undecorated string literal has on that version of python. That type is called "str" on both python2 and python3 but it's a byte string on python2 and a text string on python3. It will have the following benefits: * It's the most compatible since it's the same type as str on both platforms. (It just has better defaults and more flexible error handling than using str()). * For most module_utils code, we use native string types right now so that a module author can mostly write idiomatic python and it mostly just works. They don't run into a problem combining byte and text type. (They do have to worry about it when they deal with an external API which needs a specific type but those are not as common so it's easier to deal with those when the time comes and not worry the rest of the time).
@willthames bcoca asked me to look at your problem. I think that we want to use to_native() here and we probably want to use errors='surrogate_or_strict' as well. to_native() converts the string into the type which an undecorated string literal has on that version of python. That type is called "str" on both python2 and python3 but it's a byte string on python2 and a text string on python3. It will have the following benefits: * It's the most compatible since it's the same type as str on both platforms. (It just has better defaults and more flexible error handling than using str()). * For most module_utils code, we use native string types right now so that a module author can mostly write idiomatic python and it mostly just works. They don't run into a problem combining byte and text type. (They do have to worry about it when they deal with an external API which needs a specific type but those are not as common so it's easier to deal with those when the time comes and not worry the rest of the time).
Please break line into 2, for length ```python if (isinstance(min_value, (int, float)) and isinstance(max_value, (int, float))): ``` (same below)
@jacquerie I believe this is the right way to do it.
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
Same as https://github.com/ansible/ansible/pull/21849#discussion_r103172035, `timeout` isn't `username`.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
This can instead be `continue` and let the `else` unnest.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Not a real issue, but we recommend to sort the order of lists if the order is not of importance.
We used dd rather than cat in the jail, chroot, and zone plugins. Can use similar code here. I believe that code also does this without a shell which could be nice for making this more generic (not that most installs will be lacking bash but it's always nice to avoid) and potentially avoiding shell quoting issues.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
terms can be a list, not sure if this is being handled correctly
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
All methods only used once should be explicitly inlined.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
do not use the program title as a description.
This seems like it would break galaxy which needed expand_paths
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Just use `replace` or `re.sub`.
No warning should occur with default settings. It is safe to remove this.
maybe this can help you https://github.com/philipperemy/keras-visualize-activations/blob/master/read_activations.py I used something similar to get internal activations for my own project (in non Sequential models).
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
No warning should occur with default settings. It is safe to remove this.
```suggestion def state_update_library(self): ```
I would recommend to add `check_mode` for this module. You can check other modules in VMware space to see how it works for them.
return status from this and handle accordingly in `module.exit_json`
```suggestion # just get value from attribute itself as normal ```
It'd be nice to hint users about what version is not old.
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
I'm also learning this as I go :smile:
CI failure due to PEP 8 issue: ``` 2017-02-16 00:21:02 ERROR: PEP 8: lib/ansible/modules/cloud/docker/docker_service.py:525:59: W291 trailing whitespace (current) ```
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
`0o600` is more readable than `384`.
I'm also learning this as I go :smile:
CI failure due to PEP 8 issue: ``` 2017-02-16 00:21:02 ERROR: PEP 8: lib/ansible/modules/cloud/docker/docker_service.py:525:59: W291 trailing whitespace (current) ```
That's required. `0o600` works starting python 2.6. If authorized_key still wants to support 2.4 (not sure when this will die) one can do `int('600', 8)`, but that's probably not more readable than your suggestion.
That's required. `0o600` works starting python 2.6. If authorized_key still wants to support 2.4 (not sure when this will die) one can do `int('600', 8)`, but that's probably not more readable than your suggestion.
LANG should not be involved as we are making a system call, so answers should always be in POSIX/C locale, even if we were using the command line tools we do have the ability to force the locale/lang setting to enable parsing the output.
I'm also learning this as I go :smile:
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
I'm curious if this should be a `BaseException` so that it'd work on `Ctrl+C` (`SIGINT`) or `SystemExit` (`SIGTERM`).
That's required. `0o600` works starting python 2.6. If authorized_key still wants to support 2.4 (not sure when this will die) one can do `int('600', 8)`, but that's probably not more readable than your suggestion.
Just an empty line, could be removed for cleaner code
No need to escape whitespace.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Just an empty line, could be removed for cleaner code
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
`# Returns `
we really need something generic.... getting complex :-)
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Couldn't these just be methods of TestMirrorMakerService and then you could just pass `core_test_action=self.hard_bounce`? Seems more intuitive to me to keep it as a method since it only seems to be used with the one class.
I think it would be good to include a message giving context before we start listing unresolved issues.
Move inside a loop.
Please don't use leading double underscores. It's dangerous.
```suggestion [datastore_name] path/to/file.vmdk ```
If you use to_text(xxx, errors='surrogate_or_strict') it won't throw exceptions.
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
If you use to_text(xxx, errors='surrogate_or_strict') it won't throw exceptions.
```python $ python2.6 Python 2.6.9 (unknown, Apr 10 2018, 17:32:50) [GCC 7.3.0] on linux4 Type "help", "copyright", "credits" or "license" for more information. >>> import pkg_resources /home/wk/.pyenv/versions/2.6.9/lib/python2.6/site-packages/pkg_resources.py:17: DeprecationWarning: the sets module is deprecated from sets import ImmutableSet >>> stdst = pkg_resources.get_distribution('setuptools') >>> stdst setuptools 0.6b4dev-r0 (/home/wk/.pyenv/versions/2.6.9/lib/python2.6/site-packages) >>> stdst.as_requirement() Requirement.parse('setuptools==0.6b4dev-r0') >>> stdst.as_requirement().specs [('==', '0.6b4dev-r0')] ```
The `title` _should_ be mandatory
Line is too long.
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
Line is too long.
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
And the same here
I think it would be best to refactor `use_old_user_mgmt` to handle all versions manipulation (ie returning a clear string stating which kind of user management we should use, for example `PASSWORD_ONLY` or `LEGACY`, `PASSWORD_OR_AUTH_STRING`, `MYSQL_8_PLUS` ...)
Move this outside the loop.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
This is no-go imo. `Game` string is localized and this regex will work only on English YouTube page. Also don't capture groups you don't use.
You should be able to use `self.vmware_test_platform` here.
Format your docstrings like other docstrings in the codebase
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
Can you make this into a couple statements for easier readability? Something like: ``` invalid_entries = [x for x in statement['Principal']['AWS'] if not x.startswith('arn:aws:iam::)] if clean_invalid_entries and len(invalid_entries): for entry in invalid_entries: statement['Principal']['AWS'].remove(entry) ``` Or there's always: ``` original_size = len(statement['Principal']['AWS']) statement['Principal']['AWS'] = [x for x in statement['Principal']['AWS'] if x.startswith('arn:aws:iam::)] have_invalid_entries = (original_size == len(statement['Principal']['AWS'])) ```
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
I meant `validate_certs=dict(type='bool', default=True),` which is missing,
The removal of this final raising of `HTTPError` means that there are some scenarios that can succeed, such as when given invalid redirection options. ``` RedirectHandlerFactory(follow_redirects='invalid', validate_certs=True) ``` Previous behavior was to raise an `HTTPError` in this situation, somewhat similar to `follow_redirects='none'`
I don't like this. You should pass the `module.params` to the functions instead of making variables global.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
when you opt-in to using a CM like this, make sure you only patch lines that you really need to patch. and put any assertions outside, whenever possible: ```suggestion assert ret == [] ```
I would name the method `passwd_set`.
you need to skip value from parent if include_tasks/include_role, but still inherit
you need to skip value from parent if include_tasks/include_role, but still inherit
you need to skip value from parent if include_tasks/include_role, but still inherit
need to change this for python3 compatibility. We've imported the iteritems function from six earlier so we can just do this:: ``` python for suffix, limit in sorted(iteritems(SIZE_RANGES), key=lambda item: -item[1]): ```
With this simplification, the pythonic way of generating a list is to use list comprehension. You can replace the whole function body with: ```python return [parse_to_obj(r) for r in parse_to_logical_rows(vlan_out)] ```
First 2 references should be formatted as markdown links
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
This line does not need quotes. (nitpick)
This should be a character string (prefixed with `u`)
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
Line is not PEP8, please fix indent and insert spaces around operators.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
That's a good point. Just fix the indentation in that part of the code, then.
`'id'` is required.
```suggestion file_name, file_exts = os.path.splitext(str(url.rsplit('/', 1)[1])) # Preserving double filename extensions like .tar.gz _, double_ext = os.path.splitext(file_name) if double_ext: file_exts = double_ext + file_exts: ```
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
both are valid tests, i don't see why you need to eliminate the existing one
Put these inside the `call` method, they shouldn't be class methods.
both are valid tests, i don't see why you need to eliminate the existing one
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Carry long lines. Bother to finally read coding conventions.
each plugin can initialize prompt in diff ways, this will not work for all plugins,`su` for example. Tempted to say that we match if existing plugin is same as the requested become info and reinitialize per loop, since even `become_method: '{{ item["method"] }}' ` is possible
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
121, 124 - DRY.
121, 124 - DRY.
don't make unrelated changes.
Query should be passed as `query` parameter.
This breaks the general philosophy of `keras-team/keras`, which is to have a shared codebase across different backends (which is possible as long as each backend implements the Keras backend API). Why do you think this is necessary? We've managed to do it across Theano and TF without much issues, even though they work quite differently (e.g. sessions, graphs, etc). Surely you can manage any custom functionality you need at the level of `K.Function()`.
```not (foo is None)``` => ```foo is not None```
The convention in other connection plugins seems to be to raise an `AnsibleError` instead of `IOError`.
use ```from ansible.module_utils.vmware import get_parent_datacenter```
Fix code duplication, use single quotes and squash commits.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Just an empty line, could be removed for cleaner code
When running check mode and a stack does not yet exist, this call fails. If you catch botocore.exceptions.ClientError in a separate `except` you can check if the error is that the stack doesn't exist, then return None and show the state as "changed"
just don't know exactly what's in the properties :-)
just don't know exactly what's in the properties :-)
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
so this assertion looks incorrect, i would expect and empty string as the ssh args
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
This is not used in single video extractor thus should not be here.
You can import `try_rm` from helper
so this assertion looks incorrect, i would expect and empty string as the ssh args
You don't need to create a `list()` and then mutate it. Instead, you can turn it into a list comprehension, making the whole function shorter and better readable: ```python try: return [Package(name) for name in _recover_package_names(names)] except Exception as e: # includes RequirementParseError, but also other errors, which might occur, and would need fail_json anyway module.fail_json(msg=str(e)) ```
You don't need to create a `list()` and then mutate it. Instead, you can turn it into a list comprehension, making the whole function shorter and better readable: ```python try: return [Package(name) for name in _recover_package_names(names)] except Exception as e: # includes RequirementParseError, but also other errors, which might occur, and would need fail_json anyway module.fail_json(msg=str(e)) ```
You don't need to create a `list()` and then mutate it. Instead, you can turn it into a list comprehension, making the whole function shorter and better readable: ```python try: return [Package(name) for name in _recover_package_names(names)] except Exception as e: # includes RequirementParseError, but also other errors, which might occur, and would need fail_json anyway module.fail_json(msg=str(e)) ```
You don't need to create a `list()` and then mutate it. Instead, you can turn it into a list comprehension, making the whole function shorter and better readable: ```python try: return [Package(name) for name in _recover_package_names(names)] except Exception as e: # includes RequirementParseError, but also other errors, which might occur, and would need fail_json anyway module.fail_json(msg=str(e)) ```
I prefer that the module would check the connection itself as well, without actually sending the message. If the API supports stub messages (or empty messages?), use that. Otherwise just test the authentication/connection some other way.
Same question here about unsafe_shell as in get_default_interfaces()
Same question here about unsafe_shell as in get_default_interfaces()
Same question here about unsafe_shell as in get_default_interfaces()
Same question here about unsafe_shell as in get_default_interfaces()
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
Please use lowercase variable names.
As above; Separate log exception method for the normal situation where the RT does not exists VS all other errors.
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
It would be awesome if buildah supported copying from a container.
You can use self._download_json() here
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
`try_get`, single quotes.
Use a tuple as a the cache key instead of stringifying this. This will likely result in a performance problem later if not resolved now. ```suggestion key = tuple(groups) + (b_opath,) ```
I did not suggest moving `subtitle_original_lang_code` into loop.
Don't lookup `lang_code` twice.
Move into loop.
Don't lookup `lang_code` twice.
I just want to emphasize that assigning different types of data to the same variable is usually error-prone and should be avoided.
```suggestion self._display.debug("recursive_group_vars - Traversing dir : %s with groups : %s" % (path, to_text(groups))) ```
```suggestion file_name, file_exts = os.path.splitext(str(url.rsplit('/', 1)[1])) # Preserving double filename extensions like .tar.gz _, double_ext = os.path.splitext(file_name) if double_ext: file_exts = double_ext + file_exts: ```
Don't lookup twice.
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
This should not be fatal.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
`acodec == 'none'`.
`expected_status` to `_download_json` instead.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
`acodec == 'none'`.
I would switch the statements, test for dict, test for list, else raise error.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
Okay I think this makes sense, let's just follow this pattern then.
Okay I think this makes sense, let's just follow this pattern then.
I suggest: if parser.get('DEFAULT', 'vmware_validate_certs').lower() in ('no', 'false'):
Just want to verify - will it be possible to apply these environment variables per host in the inventory file? The idea is that you may have multiple firewalls, some of which need proxy (or even different proxies) to be managed and others don't.
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
What kinds of failures are we trying to mask here? Frequently retries also require delays between retries.
Tests shouldn't be invoked directly, so this isn't needed.
Tests shouldn't be invoked directly, so this isn't needed.
Single quotes. `item` is already a string.
does not resolve inheritance https://github.com/ansible/ansible/issues/25097
`return not owner or owner == publication_info['owner']` could be used.
this should use the config system instead
`return not owner or owner == publication_info['owner']` could be used.
This restricts password to the only single one while it should be on per extractor basis. As a result this breaks credentials input mechanism completely, one are unable to have different credentials per extractor anymore.
These examples are confusing. dim ordering should be referred to as "th dim ordering / tf dim ordering". Please pick one of them and have the entire example use the same convention. You may then follow up with the same example in the alternative dim ordering.
And the same here
I don't have a problem with _check_type_bytes simply calling the toplevel string_to_bytes(); no need for this method. (Wish we could do the same with pretty_bytes() but backwards compat... )
and convert filename to bytes again.
and convert filename to bytes again.
and convert filename to bytes again.
Some more: avc2, avc3, avc4. These would be enough.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Basically @gundalow's point is that you don't need to repeat the work that Ansible is already doing enforcing required parameters
You don't need a lambda here. Also, don't break lines with `\`.
Basically @gundalow's point is that you don't need to repeat the work that Ansible is already doing enforcing required parameters
You don't need a lambda here. Also, don't break lines with `\`.
Basically @gundalow's point is that you don't need to repeat the work that Ansible is already doing enforcing required parameters
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
Use `self._search_regex` and `utils.unified_strdate` instead.
It would be nice to return the object you created too: `res['provider'] = self._get_saml_provider(self._get_provider_arn(name))`
I think this should be 'exit' instead of 'abort'
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Info. Error: " + to_text(resp_obj))) ```
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Lock Info. Error: " + to_text(resp_obj))) ```
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
`not source_url` implies `source_url == ''`.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
Removal of this line broke one of my scripts, which was relying on the field "name" to contain the portgroup name.
Can you give an example for the error message coming from this? As stated above I would rather remove support for construtcs, which can raise exceptions here.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
It likely makes sense to add the remaining psycopg2 parameters including host and port.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
if datastore already exists
if datastore already exists
if datastore already exists
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Simplest backward compatible fix is (untested): ``` aws_session_token = config.get('credentials', 'aws_session_token', config.get('credentials', 'aws_security_token')) ``` I can't find any evidence that boto (as opposed to boto3) supports aws_session_token, so best to support both for people using the session token with boto.
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Use same `env_fallback` as `X_AUTH_TOKEN`
so this assertion looks incorrect, i would expect and empty string as the ssh args
```suggestion elif len(group_numbers) > 1: ```
Read coding conventions on optional meta fields.
I'd recommend changing `'{0}'` and `'{2}'` to use double quotes instead of single. `repr` usually gives single quotes, and as such you end up with something like: ``` was converted to 'password: '********'' (type string) ```
both are valid tests, i don't see why you need to eliminate the existing one
```suggestion msg = "" ```
Now you need to update `self.public_key` another time.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
The return value is not strictly cookies. The return value is a dictionary of headers
Please add spaces around the equal sign.
I think the `disable_healthcheck` is redundant, we can leave the logic to `comparisons` and users to handle it. Introducing this logic might also conflict with `docker`'s original logic, as `docker run --health-cmd ANYTHING` will always generate a "CMD-SHELL" entry in `HealthCheck.Test`(tested on CentOS with docker 1.13).
This is not needed, the 'in_data' is written to the pipe when provided. This just creates another way of doing the same thing. Also this makes it ssh specific, it should be cross connection plugin (for those that support inline data aka pipes).
You may be able to modify sys.path, perform an import, and then restore sys.path. That will probably prevent it from causing issues for other unit tests, but I haven't verified that.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
You can import `try_rm` from helper
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
This limits you to 1000 hosts where previously it iterated all the pages.
This limits you to 1000 hosts where previously it iterated all the pages.
Capture between tags.
Simplify, harmonise with yt-dlp pt5: ```suggestion if try_get(data, lambda x: x['viewCam']['show'], dict): raise ExtractorError('Model is in private show', expected=True) elif not try_get(data, lambda x: x['viewCam']['model']['isLive'], bool): raise ExtractorError('Model is offline', expected=True) ```
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Sure, a separate PR sounds good.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Unclear why this needed to move upfront, since things like the implicit `Display` setup should have occurred with the implicit entrypoint import already...
I think `if props is not None` is more conventional :smile:
I think this is acceptable for now, but for the future, I think we should see if we can make use of post validating to cover all arguments in a single standard way.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Worth wrapping all these long fail_json calls at the comma before exception - otherwise it goes off the side at PR (I know there are lots of lines that are already too long but let's not add more)
Default type is `str` so you don't have to set it explicitly. Just use `size=dict(),` instead. The same bellow.
```suggestion with open('/var/run/secrets/kubernetes.io/serviceaccount/token') as file: ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Make `verify_cert` configurable. You can take a look at [this](https://github.com/ansible/ansible/blob/959395f4b40a4f9e44a4bce890f633f8364c43a6/lib/ansible/module_utils/vmware.py#L466)
Mind putting this magic value into a constant with a descriptive name? I'd read much better if it was ```suggestion sys.exit(RC_CLI_INIT_FAILURE) ``` or something like that.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
Shouldn't this use the value of ansible_python_interpreter? There is a mechanism (winrm.py uses it) to pass in some host variables to connection plugins, so this should probably implement that.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
Seems close enough, so I'll take that test as good as the 'unkillable' status is the main issue once the problem surfaces. I still have not been able to reproduce the problem i saw reliably, it just has happens a few time across the many times I've tested the gathering threaded code. It seems to happen less with Py3 versions, but since I'm not sure about how to trigger it, that is just anecdotal data. I was thinking of downgrading to nfsv3 since that was a lot more prone to this kind of issue ... but its probably not worth it.
Make `verify_cert` configurable. You can take a look at [this](https://github.com/ansible/ansible/blob/959395f4b40a4f9e44a4bce890f633f8364c43a6/lib/ansible/module_utils/vmware.py#L466)
You can save some indentation by reverting this clause: ```suggestion if not os.path.isdir(collection_path): continue ```
It's actually missing `--ignore-certs` CLI arg that implies `validate_certs=True` according to the code I saw...
This looks like a good change, however, for consistency with the rest of the code, I think we should use `self._play_context.ssh_executable` until we decide to switch the connection plugin in full over to using `get_option`.
We don't need the logging import anymore
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
I'd do ```suggestion if not ignore_errors: raise ```
I'd do ```suggestion if not ignore_errors: raise ```
I missed this one in my last review: ```suggestion raise SystemExit('ERROR: Ansible requires the filesystem encoding to be UTF-8; Detected %s.' % fs_enc) ```
see my loop over waiting on threads here #49398 to get a py2/py3 compatible way
see my loop over waiting on threads here #49398 to get a py2/py3 compatible way
This should not be here as done by downloader.
Read coding conventions on optional and mandatory data extraction.
This doesn't allow the caller to cancel downtime by scope. _get_downtime returns an empty dictionary when id is not specified. It'd be great if this was changed to require id or scope instead of just id.
```suggestion - Required for C(type=DS) when C(state=present). ```
you could just use `get_elb_listeners` for this section of code, it seems to be identical.
Use single quotes consistently whenever possible. If this is expected error pass `expected=True`.
Use single quotes consistently whenever possible. If this is expected error pass `expected=True`.
Are you sure you want to reset `self._pos` here? Normally `__iter__(self)` should be non-destructive so that you may write: `iter(iter(iter(my_value_iterator)))`
Are you sure you want to reset `self._pos` here? Normally `__iter__(self)` should be non-destructive so that you may write: `iter(iter(iter(my_value_iterator)))`
Are you sure you want to reset `self._pos` here? Normally `__iter__(self)` should be non-destructive so that you may write: `iter(iter(iter(my_value_iterator)))`
I think we should not expect only a list, but also allow for tuples. In which case this comparison won't work; better to compare each member: `zoom_range[0] == 1 and zoom_range[1] == 1` . Also, since we make the assumption that `zoom_range` is going to be a 2-element list/tuple, better check first and raise a helpful error message if it's not the case.
I think we should not expect only a list, but also allow for tuples. In which case this comparison won't work; better to compare each member: `zoom_range[0] == 1 and zoom_range[1] == 1` . Also, since we make the assumption that `zoom_range` is going to be a 2-element list/tuple, better check first and raise a helpful error message if it's not the case.
I think we should not expect only a list, but also allow for tuples. In which case this comparison won't work; better to compare each member: `zoom_range[0] == 1 and zoom_range[1] == 1` . Also, since we make the assumption that `zoom_range` is going to be a 2-element list/tuple, better check first and raise a helpful error message if it's not the case.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
small typo ```suggestion # table availability in check_src/dst. ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
please add `type: bool`
You've forgot to pass `info_dict` to `supports()`.
You've forgot to pass `info_dict` to `supports()`.
`del` is a builtin, not a function. These parens don't have to be here
You've forgot to pass `info_dict` to `supports()`.
You've forgot to pass `info_dict` to `supports()`.
This is not used in single video extractor thus should not be here.
Currently with this input: ``` names = ['one >1.0,<2.0', 'two', '>3.0', '<4.0'] ``` You would get this output: ``` distribution_names = ['one >1.0,<2.0', 'two,>3.0,<4.0'] ``` Note that one does not have a comma before the first version while two does.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Move it down the stack.
Thanks for that note ewen. I learned something!
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('Europe/Helsinki')), '2019-06-15T14:45:00+01:40'), ```
```suggestion module.fail_json(msg='The following volume names were not found: ' ```
This is not used in single video extractor thus should not be here.
Thanks for that note ewen. I learned something!
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
If that's the case, then we may need a separate PR to go back further than 2.1. I'd say we'd want to correct this issue (which has irked quite a few people) as far back as 1.0.
Adding the exception string to the error would help the user narrow down what the issue is.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
Query should go as `query` to `_download_webpage`.
Cause it's an **utility function** and it's used in other places you've broken with this change.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
The paragraph above can be replaced with `layer.weights`, which is always implemented.
Query should go as `query` to `_download_webpage`.
Are you sure you want to reset `self._pos` here? Normally `__iter__(self)` should be non-destructive so that you may write: `iter(iter(iter(my_value_iterator)))`
Are you sure you want to reset `self._pos` here? Normally `__iter__(self)` should be non-destructive so that you may write: `iter(iter(iter(my_value_iterator)))`
you can move it to before `if` as just `docs = {}` line, this should read better.
you can move it to before `if` as just `docs = {}` line, this should read better.
you can move it to before `if` as just `docs = {}` line, this should read better.
@farizrahman4u Isn't `ndim` always going to be 1 for `n`, I think you meant the equivalent of `len(n)`
Are you sure you want to reset `self._pos` here? Normally `__iter__(self)` should be non-destructive so that you may write: `iter(iter(iter(my_value_iterator)))`
you can move it to before `if` as just `docs = {}` line, this should read better.
```suggestion # just get value from attribute itself as normal ```
I'm not sure about these defaults - a delay of 3 and backoff of 2 for 10 tries would mean that, to fail, this retry decorator would wait for 3069 seconds (`3 + 3*2 + 3*2*2 ....`, or `sum([3 * 2**i for i in range(10)])`) or about 50 minutes. That seems like a really long time, especially since most modules make several calls. A better default might be 4 tries, for a total default wait time of 45 seconds and having a max of, say, a minute between tries. That way, if someone wanted 10 tries it would only take about 7.5 minutes to fail.
you need to do `get_credentials` even if `profile` is not set (IAM instance profiles mean that neither environment variables, module parameters nor profile contain the keys)
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
This is failing because `match` takes a regular expression, which is interpreting the `()` as grouping characters, not as literal parenthesis. Another issue here is the error message can be two different values. ```suggestion with pytest.raises(TypeError, match=r'(no ordering relation is defined for complex numbers)|(unsupported operand type\(s\) for /)'): ```
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
```suggestion # require that the final recorded stack state was DELETE_COMPLETE ```
This would need `results['changed'] = True` in the create scenario. We really need a way to checking if we need to update the database instead of doing the operation and checking if it changed there as well.
Nitpick - the term `The value` is used twice here with different meanings each time. I suggest changing `...if IE changes the values...` to something like `...if the IE configuration changes...` to resolve the ambiguity.
This try-except block should be reduce to the actual calls made.
`return not owner or owner == publication_info['owner']` could be used.
From our triage meeting, we all found we were confused by this line. Making it more verbose will likely make it easier to understand.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
You don't need this, `Conv2DTranspose` with strides should work better
Yeah -- just for info, to_native() is preferable because, with default arguments, it won't traceback if non-ascii values end up in the exception message. In some cases, non-ascii will traceback with str() and with ```'%s' % e```.
This currently does not handle lists of items. We need to support it here.
Can we also add the ability to traverse a list of dicts? ``` def generate_final_config(self, cfg_dict): """ Generate final config dictionary :param cfg_dict: A dictionary parsed in the facts system :rtype: A dictionary :returns: A dictionary by eliminating keys that have null values """ final_cfg = {} if not cfg_dict: return final_cfg for key, val in iteritems(cfg_dict): dct = None if isinstance(val, dict): child_val = self.generate_final_config(val) if child_val: dct = {key: child_val} elif (isinstance(val, list) and val and all([isinstance(x, dict) for x in val])): child_val = [self.generate_final_config(x) for x in val] if child_val: dct = {key: child_val} elif val not in [None, [], {}, (), '']: dct = {key: val} if dct: final_cfg.update(dct) return final_cfg ``` something like this ^^^
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Just assign the correct value to `video_id` later.
1. Single quotes. 2. `expected`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Get rid of `dim_ordering`, as it isn't doing anything anymore.
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
An error should be reported if neither `audio-preview-url` nor `video-preview-url` is present. `dict_get()` may be useful here.
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
Same question here about unsafe_shell as in get_default_interfaces()
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
no, if the variable is set but empty, you should empty out the options
so this assertion looks incorrect, i would expect and empty string as the ssh args
so this assertion looks incorrect, i would expect and empty string as the ssh args
so this assertion looks incorrect, i would expect and empty string as the ssh args
Same question here about unsafe_shell as in get_default_interfaces()
Code duplication 165, 176.
I would think to rephrase the message since it suggests that the storage domain is not attached although we search for an active storage, but storage domain can also be in maintenance mode or inactive and still be attached to a DC. maybe something like "Can't bring storage to state `%s`, because no active storage domain found in DC"
You should always have `type='str'` (or whatever type you have) in all of argument spec.
IIRC should be just `raise` to re-raise the existing error
need to catch BotoCoreError here too.
may be blind, but think this will never get fired if v is empty. you create an empty list, which will be skipped in the for loop.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Need a colon at the end here
Better to add `rank` here
Do note that this only looks at the primary credential cache. This means that if you use a collection credential cache such as DIR, KEYRING or KCM (default in most distributions these days), you might not see a ticket that exists in a non-primary credential cache. Maybe consider using `klist -A`, or try a `kswitch -p <principal>`? The latter is easier to parse, but might break stuff if people are still using the old krb5 APIs (rather than GSSAPI) and were using the primary credential that you just made secondary.
Better to add `rank` here
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
Break up long line
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
`validate_config` call is missing
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
The leading underscore in the '_meta' key is missing here.
facts modules can trivially support check mode (#23107)
facts modules can trivially support check mode (#23107)
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
This is unreachable code, as module.fail_json will be exit point the module.
Should be `fatal=False`. Use `utils.int_or_none`. It must be in seconds.
Put these inside the `call` method, they shouldn't be class methods.
should be self.forward.
Returning would close the file (I think) since you're already in a 'with' statement.
@wmedlar Sorry for delay, I will take a look.
Line too long. Prefer raising a `ValueError`. Use a consistent quote char (`'`).
Some more: avc2, avc3, avc4. These would be enough.
Don't use `;` unless you need to write more than 1 statement per line (personally, I would also avoid doing that)
1. Single quotes. 2. `expected`.
1. Single quotes. 2. `expected`.
> Did you read the stacktrace mentioned in the description of this PR and in the first commit ? Sure, but I did not understand how this is related, but with your additional exlaination, I understand now. The commit message could be improved by writing something like "`openstack.version.__version__` expression raises an AttributeError exception when openstacksdk < 0.10.0 is used. openstack.version is now imported as a module, which works for all openstacksdk versions.
Aren't we losing some good "text" here? Shouldn't probably do more than just `to_native(e)`
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
If nothing matches `None` will be returned.
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Change to `class Ec2EcsInstance(object):`
Similarly, ```if tc['skip'].get('i')```
Actually, we had some discussions about group names the previous days on IRC. Apparently dashes have been not allowed in group names from Ansible 2.4 on; this hasn't been enforced so far, but now (with Ansible 2.8) it will be. It's still possible to disallow it, but every group with a dash (or other invalid chars) in them will trigger a big fat warning. So please get rid of the dashes here so users of this inventory plugin won't automatically get a list of warnings, even if they don't have invalid chars in their labels.
default of none allows us to know if user set or not, unsure if it is currently needed but JIC we want to make distinction in the future.
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
Similarly, ```if tc['skip'].get('i')```
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
Add condition to check like, because we don't want resource pool which is different than the user specified name. ``` if resource_pool.name != resource_pool_name: continue ```
You could `mock.patch` it to do so :)
10 is default.
10 is default.
When using pytest, create top-level functions without using a class.
I think this should be `_return_if_object` since it isn't part of the public API.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
update the author
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
py3.x-only code; can safely ditch the args to `super()`
When using pytest, create top-level functions without using a class.
update the author
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
py3.x-only code; can safely ditch the args to `super()`
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
You should capture a part of URL that represents a video in unique way...
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
```suggestion msg="A required Python library was not found. This module" + ``` That's more precise :) Also, you can assume that the `time` and `re` modules are installed; if not, a lot of other modules will also break and the user has a really broken Python installation, which should happen so seldomly that an extra error message for that should be unnecessary.
update the author
Don't assign a lambda function, use def
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
I'd rephrase: 'Obtain data of `vm_name` if specified, ...'
`raise` is missing. Call to `str` is useless there.
same as others, return directly test
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Since this extractor by itself can't provide too much info, maybe it would be better to remove the _real_extract and _VALID_URL, don't import it in `__init__`and do something similar to`MTVServicesInfoExtractor`, which is the base class for the extractors that need it.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
```suggestion - Will not be set for an existing user unless I(update_password) is set to C(always), which is the default. ``` (or ``I(update_password=always)``)
```suggestion - Will not be set for an existing user unless I(update_password) is set to C(always), which is the default. ``` (or ``I(update_password=always)``)
Ah, I hadn't noticed `collections` isn't added here. And yeah, we should probably be using something like `collection_list=[collection_from_task] + collections` to look up the action plugin (resolving appropriately when one or both don't exist). The two paths are just so similar to each other I'd really rather avoid keeping them separate unless there's a good reason to
I think this should be `if tags and tags != igw.tags:`. Otherwise if we're creating a gateway with no tags this condition will be met and it will crash later since there are no tags. On second thought, just make the default of tags be an empty dict instead of None, [here](https://github.com/ansible/ansible/pull/23782/files#diff-7c7439a69b0a017fb8e03a769c5ef29bR179) and it will fix the problem.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
I think this should be `if tags and tags != igw.tags:`. Otherwise if we're creating a gateway with no tags this condition will be met and it will crash later since there are no tags. On second thought, just make the default of tags be an empty dict instead of None, [here](https://github.com/ansible/ansible/pull/23782/files#diff-7c7439a69b0a017fb8e03a769c5ef29bR179) and it will fix the problem.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
print statement can be removed
Tell people where we are looking `CONFIG_FILES`
`/`, `:`, `\`, `|`, `<`, `>`, `"`, `?` and `*` are already always stripped.
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
Use `self._html_search_meta` or `self._og_search_title` instead.
This must be checked **before** any processing.
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
I'm totally fine with your explanation and it was just a starting point by my side. And you are right, that the usage in your module in this case is simpler, so no change needed.
not a list of dicts, just pass a dict to the with: ```yaml with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ```
The security group rule and the trunk are not present in any of the resources' contents here: https://github.com/openstack/openstacksdk/tree/master/openstack/cloud, consequently using the `cloud.get_<resource>` call fails. Instead the `could.network` call can be used.
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
No `url` and `formats` at the same time.
Just an empty line, could be removed for cleaner code
I would recommend changing all the find calls to use FindAll and to throw an exception on ambiguity. That can be a separate PR covering #47360 however.
I could swear i created a `get_variables` method to avoid using the internal dict directly, but cannot find it now ...
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
ah, was part of become plugins but others decided to drop that method ...
All methods only used once should be explicitly inlined.
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
All methods only used once should be explicitly inlined.
check_output is not python2.6 compatible
Use `'` as the quote character for consistency with the rest of the file
I'm totally fine with your explanation and it was just a starting point by my side. And you are right, that the usage in your module in this case is simpler, so no change needed.
Should not be fatal.
Since we don't do any network requests after this line, it's not really needed, and does not contribute to the user's experience. Nowadays, our helper methods will already output status reports when it's needed. Formally deprecating or removing all of this is on my TODO list.
Since we don't do any network requests after this line, it's not really needed, and does not contribute to the user's experience. Nowadays, our helper methods will already output status reports when it's needed. Formally deprecating or removing all of this is on my TODO list.
Are you sure it isn't Javascript code instead of JSON? If so, you can use `js_to_json`
ack. merging this in since this isn't a blocker.
Since we don't do any network requests after this line, it's not really needed, and does not contribute to the user's experience. Nowadays, our helper methods will already output status reports when it's needed. Formally deprecating or removing all of this is on my TODO list.
Duration calculation is incorrect.
Since we don't do any network requests after this line, it's not really needed, and does not contribute to the user's experience. Nowadays, our helper methods will already output status reports when it's needed. Formally deprecating or removing all of this is on my TODO list.
Better to add `rank` here
Just an empty line, could be removed for cleaner code
This has no effect. Postprocessors work on info dict copy.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
the second parameter for `_download_*` methods is `video_id`, use the `note` parameter for the message.
f is already at 0, the `truncate()` is uselesss.
Check for `embed_code` instead.
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
I think you can get rid of the rstrip('\n') here for the same reason as you got rid of it in _find_bind_mounts() (or alternatively, if rstrip is necessary here, then it's probably still needed in _find_bind_mounts() as well).
Just in case it's probably a good idea to use `.get()` instead of dict access syntax in case the key is unset.
I think you can get rid of the rstrip('\n') here for the same reason as you got rid of it in _find_bind_mounts() (or alternatively, if rstrip is necessary here, then it's probably still needed in _find_bind_mounts() as well).
Right -- it shouldn't be needed because splitlines() will remove all "\n".
I think you can get rid of the rstrip('\n') here for the same reason as you got rid of it in _find_bind_mounts() (or alternatively, if rstrip is necessary here, then it's probably still needed in _find_bind_mounts() as well).
Right -- it shouldn't be needed because splitlines() will remove all "\n".
Just in case it's probably a good idea to use `.get()` instead of dict access syntax in case the key is unset.
FTR According to https://github.com/python/mypy/issues/4707 / https://github.com/python/mypy/pull/6896, your first hunch to use an `Iterator` for the return annotation was more correct. It just needs an import.
Small nit pick here - Do not remove `msg` attribute from `exc`, it is helpful in debugging. Rest LGTM
There is no `imap` in `itertools` in python 3: http://stackoverflow.com/questions/30271712/i-cant-find-imap-in-itertools-in-python
`start_time` may be `None` at this point.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
`start_time` may be `None` at this point.
What is the need here for writing and reading from a JSON file? Seems this file would be created during execution, but in a temporary directory, and deleted immediately. Not sure what benefit there is to doing this, as opposed to just storing in a variable for use.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
Is this even needed, we will be dropping py2 and `to_text` does not call `__unicode__`. You may as well just put this in `__str__`.
@samdoran It probably won't but you could do this: ``` python cli = cli_klass([cli_name]) ``` which is probably "more right" ;-)
Haven't dug into the details of the PR yet, but at first glance, this section raised both eyebrows. First impression is that I have no idea what to expect this code to do. I can only assume that either: a) there is some unusual magic going on somewhere, or b) this code is wrong. Gut reaction is this is too much magic, but I haven't dive into the requirement or the rest of the implementation yet. But figured I should mention it before I acclimate.
It seems like no_log and deprecation are separate things and should be handled in separate functions.
Is this even needed, we will be dropping py2 and `to_text` does not call `__unicode__`. You may as well just put this in `__str__`.
No need to parametrize with just one case.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Won't work. See how this is done for output template.
since force-push ate my previous commit to fix this: s/coloon separated path(s)/path(s) (colon-separated)/
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
small typo ```suggestion # table availability in check_src/dst. ```
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
Why not just pass the target directory? This is all your need to perform this task.
Why not just pass the target directory? This is all your need to perform this task.
Possibly referenced before assignment.
`pzuid` does not look to be used anywhere.
This should actually be just `self.url_result(embedded_url)`.
Move on a single line.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
You should be able to use `self.vmware_test_platform` here.
ð, this is a nice little refactor.
I'm totally fine with your explanation and it was just a starting point by my side. And you are right, that the usage in your module in this case is simpler, so no change needed.
Please remove this example, since I would consider this usage as not recommended.
Yeah, all the referrer logic here should be automatic. ... Is there a reason we don't have the original url stored in the info_dict, @phihag? Like in `info_dict['webpage_url']` or `info_dict['page_url']` (that we use for RTMP support, and could then avoid to set)
no, if the variable is set but empty, you should empty out the options
so this assertion looks incorrect, i would expect and empty string as the ssh args
Gotcha. I'm glad you've thought it through. There's a slight advantage to the last suggestion you gave- if the describe_stacks wrapper init was kept inside `some_method`, it's very clear what was wrapped and reduces the chance of "hey, my Ansible module method doesn't retry even though other parts of the module do". Up to you though, since it's a bigger issue than the few modules I try to own.
so this assertion looks incorrect, i would expect and empty string as the ssh args
Ah, ok. As I said, I've never used docker-machine, so I assumed that it actually connects to the machine (using that shell) and exports the environment from there. If that's just the format, then yes, it really doesn't matter (as long as it is a format you can parse :) ). Both `bash` and `sh` are fine for me, use whatever you want then.
How is that? ``` self._arg_spec_filename = "FortiosAPIArgSpecs.json" ``` That defines the path to that filename as relative, which will be relative to the executing script. modules are executed in a temp dir that is then deleted, so this file should be deleted. If the file is kept around, I would be concerned with that. This is force creating a cache file without telling the user you are doing it, or giving them a way to opt out. The default should be no cache, and a user must opt-in, should this feature really need to exist.
This does not make any sense.
This does not make any sense.
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
```not (foo is None)``` => ```foo is not None```
Add support if VMM domain parameters: "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
you need to skip value from parent if include_tasks/include_role, but still inherit
Braces in non inline dicts **should** be carried. Parentheses != braces.
No direct URLs in tests.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
The leading underscore in the '_meta' key is missing here.
ignore it then, I stopped reading at import ssl, did not realize it is an encrypted tcp socket connection and assumed http/s
ignore it then, I stopped reading at import ssl, did not realize it is an encrypted tcp socket connection and assumed http/s
That's not needed, it's automatically detected.
this changed from a list to a string. Perhaps this is related to the "h" message in the error.
Avoid shadowing built-in names.
This is fatal.
this changed from a list to a string. Perhaps this is related to the "h" message in the error.
Must be `int`.
both are valid tests, i don't see why you need to eliminate the existing one
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
Couple of typos: remporary & copites
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
These are the values suggested by docker-machine to be used to contact the VMs / machines via SSH, so in general I don't think it makes sense to use other values.
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
`fatal=False` will print error wen failed. Instead it should be optional and not print any error.
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
`vmware_host_config_facts` â `vmware_host_config_manager`
Breaks on uninitialized `h`. Breaks on None width and height.
This is a bad API: you indicate failure/success by both raising exceptions and adding metadata via return value. It's common in C or Go to use return status codes, but in Python it's just fine to raise exceptions for failures and then return ready-to-use values for successful outcome. It's pointless to always return static `True` additionally to useful payload. I suggest you to simplify this by wiping out this boolean part and returning just useful result, not a tuple.
`vmware_host_config_facts` â `vmware_host_config_manager`
As `title` is not a required field for playlists, add `default=None`. Similarly for `uploader_id` below.
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
as discussed previously, no such thing "alert policies". every mention of "policy/ies" should be renamed...
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
It would be awesome if buildah supported copying from a container.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
+1 this isn't used anywhere
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
You don't need a lambda here. Also, don't break lines with `\`.
you can just use `item.get('title')` in this case.
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
For now this should not be printed or only printed in `verbose` mode.
Match the error message
Just an empty line, could be removed for cleaner code
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
It probably makes sense to test that the exception reason also matches expectations
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
nothing outside the fail_json/exit_json should write to stdout/stderr
This can instead be `continue` and let the `else` unnest.
Code should utilize `ansible.module_utils._text.to_native` here instead.
Code should utilize `ansible.module_utils._text.to_native` here instead.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
Alright, after a deep dive into what `__new__()` is actually doing, this change is correct. `__new__()` happens before `__init__()` and simply returns the instantiated but not initialized object. `args, kwargs` would be passed to `__new__()` in order to affect the object selection logic. They would not affect object initialization. Since they are not used by our `__new__()` method, they can be omitted from the `super().__new_()` call.
I think either name should be mandatory or this should take a label selector.
Alright, after a deep dive into what `__new__()` is actually doing, this change is correct. `__new__()` happens before `__init__()` and simply returns the instantiated but not initialized object. `args, kwargs` would be passed to `__new__()` in order to affect the object selection logic. They would not affect object initialization. Since they are not used by our `__new__()` method, they can be omitted from the `super().__new_()` call.
Alright, after a deep dive into what `__new__()` is actually doing, this change is correct. `__new__()` happens before `__init__()` and simply returns the instantiated but not initialized object. `args, kwargs` would be passed to `__new__()` in order to affect the object selection logic. They would not affect object initialization. Since they are not used by our `__new__()` method, they can be omitted from the `super().__new_()` call.
If that's the case, then we may need a separate PR to go back further than 2.1. I'd say we'd want to correct this issue (which has irked quite a few people) as far back as 1.0.
Ah, my bad. This doesn't work on fixtures.
I'd argue that it'd look cleaner and would better correspond to the fixture name that implies that it returns only the date-related subset of facts.
Mind putting this magic value into a constant with a descriptive name? I'd read much better if it was ```suggestion sys.exit(RC_CLI_INIT_FAILURE) ``` or something like that.
Require n-n-n in `id` field; no need to match the tail: ```suggestion _VALID_URL = r'(?:https?://[^/]+\.duboku\.co/vodplay/)(?P<id>(?:[0-9]+-){2}[0-9]+)\.html' ```
It's a list of elements not the first element.
Require n-n-n in `id` field; no need to match the tail: ```suggestion _VALID_URL = r'(?:https?://[^/]+\.duboku\.co/vodplay/)(?P<id>(?:[0-9]+-){2}[0-9]+)\.html' ```
`/`, `:`, `\`, `|`, `<`, `>`, `"`, `?` and `*` are already always stripped.
Add a `# Arguments` section to the docstring.
I think this is not required, name may not contain `/`
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
I think this is not required, name may not contain `/`
I think this is not required, name may not contain `/`
I think this is not required, name may not contain `/`
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
I think this is not required, name may not contain `/`
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
should be `b_path = os.path.expanduser(os.path.expandvars(path))`
I think this should be replaced with `K.epsilon()`.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
terms can be a list, not sure if this is being handled correctly
same as others, return directly test
`self.client` is already derived from `DockerClient` (and ready to use), there's no need for `self.dclient`.
That's **not** how a module should return differences. Some docker_* modules have done this in the past (and some might still do that), but it's simply wrong (and won't show up when the user runs `ansible-playbook --diff`).
You don't need to re-include some of these fixtures, as they are used in the `elb` fixture but never called in this test.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
It's probably not a good long-term solution, but currently it's fine, especially because docker-py's `DockerClient` at the moment simply creates `self.api = APIClient(...)` and does nothing else. Once this PR is merged, we can improve this behavior in a bugfix PR (which can also be merged after next Thursday).
While working on #53906, I explored the docker client creation process a bit more in detail. You can use `self.dclient = DockerClient(**self.client._connect_params)` to initialize the client with the same arguments as `self.client` is initialized. Relying on a Ansible docker internal API should be safer than relying on docker-py internal API.
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
terms can be a list, not sure if this is being handled correctly
That's **not** how a module should return differences. Some docker_* modules have done this in the past (and some might still do that), but it's simply wrong (and won't show up when the user runs `ansible-playbook --diff`).
While working on #53906, I explored the docker client creation process a bit more in detail. You can use `self.dclient = DockerClient(**self.client._connect_params)` to initialize the client with the same arguments as `self.client` is initialized. Relying on a Ansible docker internal API should be safer than relying on docker-py internal API.
`delay_min_macos = delay_min | 1`
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
I think we should just let this exception propagate. We aren't adding any value by catching it here (and might be removing value if the traceback were useful). This isn't code in ansible itself so we don't have to create a nicer error message either.
Please remove this example, since I would consider this usage as not recommended.
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
While working on #53906, I explored the docker client creation process a bit more in detail. You can use `self.dclient = DockerClient(**self.client._connect_params)` to initialize the client with the same arguments as `self.client` is initialized. Relying on a Ansible docker internal API should be safer than relying on docker-py internal API.
It's probably not a good long-term solution, but currently it's fine, especially because docker-py's `DockerClient` at the moment simply creates `self.api = APIClient(...)` and does nothing else. Once this PR is merged, we can improve this behavior in a bugfix PR (which can also be merged after next Thursday).
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
`{}` won't work in python 2.6.
Won't this just get the contents of the first page? I think you need to flatten this out by extending all `contents` to one list.
```suggestion possible_names.extend([context.redirect_list[-1], context.plugin_resolved_name]) ```
Move data and query into `_download_webpage` call.
> return it directly ``` python return self.url_result('http://imgur.com/%s' % album_id) ```
You can just use 'playlist_count'
You can just use 'playlist_count'
Move data and query into `_download_webpage` call.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
use ```from ansible.module_utils.vmware import get_cluster```
`and not info_dict.get('requested_formats')` part should be removed here since it blocks ffmpeg from choosing as downloader via `--external-downloader` when single video/audio media file is requested.
```python # warn when failing to skip due to lack of support for skipping only some versions display.warning('Including test "%s" which was marked to skip for --windows %s but not %s.' % (target, ', '.join(skip_valid), ', '.join(skip_missing))) ```
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
I don't believe this is correct. `args` and `kwargs` need to be passed to class when it is instantiated. This should probably be `*args, **kwargs`, though.
This is not used in single video extractor thus should not be here.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
```suggestion ceph_bin = module.get_bin_path('ceph-volume', True) ```
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
Does the data model / json of the scaleways api ever change? A chained set of accessors like that tends to be a little fragile if the server response change. Could potentially use some defense against that. Afaict, KeyErrors or IndexErrors here would not be caught elsewhere and would cause a fatal error instead of a semi-graceful json_fail.
```suggestion if name in ('PRIORITY',): ```
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
This can just be `return set(hashable_policy(new_policy, [])) != set(hashable_policy(current_policy, []))`
Good catch! yeah there should be a warning.
indentation of the end of the string should match with the beginning (I see this in a few other places as well)
This can just be `return set(hashable_policy(new_policy, [])) != set(hashable_policy(current_policy, []))`
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
`re.sub` part can be put in `transform_source` parameter of `_parse_json`.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
```suggestion sample: false ```
```suggestion Kwargs: ```
Just an empty line, could be removed for cleaner code
@farizrahman4u this is still not fixed.
If we're just testing broker compatibility I don't think we even need this part of the test.
These looks like mandatory fields.
These looks like mandatory fields.
These looks like mandatory fields.
We used dd rather than cat in the jail, chroot, and zone plugins. Can use similar code here. I believe that code also does this without a shell which could be nice for making this more generic (not that most installs will be lacking bash but it's always nice to avoid) and potentially avoiding shell quoting issues.
What's the point of lines 104-108? `ext` is already flv.
What's the point of lines 104-108? `ext` is already flv.
What's the point of lines 104-108? `ext` is already flv.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
I believe the plan is to do a single PR to address this in all Postgres modules
This is a bad change. self is not used inside of this method at all. I'm not sure which pylint warning you're seeing but the answer for it is probably to make this a toplevel function, private to this python module, not a regular method.
Good point for handling the `_` char, but have you tested the `-` char ? I know some devs use it ð in the db name, as long as they quote the db name.
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
I think it makes sense to fail here instead. (Or return `[]`.)
I think it makes sense to fail here instead. (Or return `[]`.)
[PEP 8](https://www.python.org/dev/peps/pep-0008/#blank-lines): There should be two blank lines before a function.
Rather than str, use to_text from ansible.module_utils._text to ensure compatibility with python 2 and 3: `to_text(option, errors='surrogate_or_strict')` Looks good to me besides that.
It'd be interesting to see a test case for something inheriting a `BaseException` too.
Always use raises with `match=` or you'll catch false positives. Especially because almost any exception is a subclass of `Exception`. ```suggestion with pytest.raises(Exception, match='Error'): ```
Maybe we could avoid relying a shared instance attribute? ```suggestion def login_database(): login_database.counter += 1 login_database.counter = 0 ```
It'd be interesting to see a test case for something inheriting a `BaseException` too.
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
>besides the test is there to make sure that breakage in this part of code will be detected That's a doubtful argument considering broken core tests at the beginning of this PR. The length of this string is const until one decides to refactor here something. Using 10 is a variation of code duplication since the length is already implicitly defined in the string literal itself. Also using 10 indicates no relation to the string literal so that one unfamiliar with code who decides to refactor it may forgot to change the number and may be unaware of the tests at all.
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
Please remove this example, since I would consider this usage as not recommended.
Wouldn't it be better to let `openssl dhparam` write into a temp file, and on success move the temp file to the real file (with `module.atomic_move()`)? Then in case of interruptions or errors, existing destinations wouldn't be trashed (except of course if `atomic_move` itself goes terribly wrong).
Wouldn't it be better to let `openssl dhparam` write into a temp file, and on success move the temp file to the real file (with `module.atomic_move()`)? Then in case of interruptions or errors, existing destinations wouldn't be trashed (except of course if `atomic_move` itself goes terribly wrong).
Move it down the stack.
Wouldn't it be better to let `openssl dhparam` write into a temp file, and on success move the temp file to the real file (with `module.atomic_move()`)? Then in case of interruptions or errors, existing destinations wouldn't be trashed (except of course if `atomic_move` itself goes terribly wrong).
Move it down the stack.
You need to make sure `tf` doesn't write a unicode string. tf.write(u("#!/bin/sh/\necho %s" % quote(self.passphrase)).encode("utf-8")) Ansible may have a utility function to do this.
Wouldn't it be better to let `openssl dhparam` write into a temp file, and on success move the temp file to the real file (with `module.atomic_move()`)? Then in case of interruptions or errors, existing destinations wouldn't be trashed (except of course if `atomic_move` itself goes terribly wrong).
And this `self._cache.set(self.cache_key, {url: ''})`
Oh sorry, I didn't see the full diff (I really shouldn't have continued on my phone). I see the `if/else` is still there but much earlier. Looks good =]
use basic.py's `missing_required_lib` function as it gives details on host and python to avoid user confusion
use basic.py's `missing_required_lib` function as it gives details on host and python to avoid user confusion
use basic.py's `missing_required_lib` function as it gives details on host and python to avoid user confusion
Use fail_json_aws for AWS exceptions as the messages contain a lot more info
the playlist description is not mandatory, if it's not supplied by the website, then do not fill it.
Plain `for` is enough.
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
```suggestion description: List of retrieved objects, the object is a dictionary containing the `I(properties)` specified. ```
```suggestion description: List of retrieved objects, the object is a dictionary containing the `I(properties)` specified. ```
`ansible.module_utils.basic` already declares `basestring` this way. If the import in this module were updated to include the variable or `*` that would also address the issue. Ref: https://github.com/ansible/ansible/blob/631a10745d344c85817ab504f678d2c40ec8ae4b/lib/ansible/module_utils/basic.py#L195-L200
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
Not sure why we've wrapped here and 1118, decreasing readability, while not wrapping longer lines.
Can we resolve these IDs? There may also be a time encoded in there.
not for this PR, but we might want a 'configurable ignore facility' ala gitignore in the future
Just change this to `==` since it's a single-layer dictionary of hashable types.
Just change this to `==` since it's a single-layer dictionary of hashable types.
Just change this to `==` since it's a single-layer dictionary of hashable types.
Use `missing_required_lib` from `ansible.module_utils.basic`
When running check mode and a stack does not yet exist, this call fails. If you catch botocore.exceptions.ClientError in a separate `except` you can check if the error is that the stack doesn't exist, then return None and show the state as "changed"
Please add spaces around the equal sign.
Got it. In that case, prefer using `evaluate` and check that the resulting losses are the same (on the same data) with both data formats.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Could you please use Python regex instead of external egrep command ? egrep command may not be installed on given system.
redundant parens `% (names)`
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Glancing over the code, `packages_to_remove` might be a clearer name here- I saw the `packages.remove('setuptools')` below and was like, "wait, I thought we wanted to keep it?!" until I realized what was happening...
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
Glancing over the code, `packages_to_remove` might be a clearer name here- I saw the `packages.remove('setuptools')` below and was like, "wait, I thought we wanted to keep it?!" until I realized what was happening...
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
This could be moved inside the conditional that follows to avoid checking when there are no vendored modules.
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
small typo ```suggestion # table availability in check_src/dst. ```
Not a real issue, but we recommend to sort the order of lists if the order is not of importance.
Not a real issue, but we recommend to sort the order of lists if the order is not of importance.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Ah, I just saw you already mentioned the return value docs :)
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
What are you even trying to do?! There is only **one single** valid tmpl, leave this code as it was.
Most modules use the `result` variable for storing the result information for fail_json() or exit_json(). Only one module is using `rekwargs`: netconf_config. 262 using `result`, 27 using `ret`. So up to you, but it's easier if people would use the same standard IMO.
This argument is only accepted in Python 3, it would not work with Python 2.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
```suggestion parts = to_native(date.strip()).split(':', 1) ```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
```suggestion parts = to_native(date.strip()).split(':', 1) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```/tv/tags/[^/]*?``` => ```/tv/tags/[^/]+```
```/tv/tags/[^/]*?``` => ```/tv/tags/[^/]+```
```/tv/tags/[^/]*?``` => ```/tv/tags/[^/]+```
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
I think this two lines are better using compat_urllib_parse_urlparse and the `_replace` method: - It's not immediately clear clear why you use `video_url[:10]`, it's better if you explicitly change the path - `rendition_url.rindex('.')` won't works as expected if the query contains a dot, and normal `index` will match the dot from the domain.
Since you return above, unnest the `raise` here.
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
```suggestion where timespec can be an integer C(+ [w | d | h | m | s]) (e.g. C(+32w1d2h)). ```
Probably the same with `--label` instead of `--uuid` here.
Probably the same with `--label` instead of `--uuid` here.
same here, we really dont want to test the particular setting, just that both the default (dynamic template) and the nii entry are correctly parsed.
Mind putting this magic value into a constant with a descriptive name? I'd read much better if it was ```suggestion sys.exit(RC_CLI_INIT_FAILURE) ``` or something like that.
This is missing a `cwd=` spec at the latest. If we need a git revision number, we should really think about releasing more often instead.
Debugging, I assume, but should be limited before merging.
When running as `youtube-dl.exe` build with python 2 from path containing non-ASCII `find_file_in_root` ends up returning `None`. When `localedir=None` is passed to `gettext.translation` it picks up `_default_localedir` constructed using `os.path.join` with mixture of byte strings and unicode strings that results in similar problem: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "gettext.pyo", line 468, in translation File "gettext.pyo", line 451, in find File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` We can workaround be skipping it completely when we found no locale dir: ``` python locale_dir = find_file_in_root('share/locale/') if locale_dir: try: ... ``` Or we can mimic what `gettext` do by appending extra path in `get_root_dirs`: ``` python ret.append(os.path.join(decodeFilename(sys.prefix), 'share', 'locale')) ```
Sorry, I think we had a misunderstanding when we talked earlier. I don't think we should be raising unless we add more exceptions so that we can tell why an exception occurred (right now, we'd have to catch the AnsibleError and then parse the message to tell why we failed.) raise_on_error is bad API. The API should either raise whenever there is an error or let the caller discriminate. Passing in a flag to tell the function to raise isn't meaningful. If we start raising an error, then we have to audit the code and decide what the failure case means in the present code. If the code doesn't depend on it (or works in some scenarios) then we probably have to replicate that behaviour instead of changing to always failing.
I don't know whether you changed it when you wrote this, but now it's correct ;-)
Better to put the activation as the `activation` keyword of the layer below
Better to put the activation as the `activation` keyword of the layer below
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Sorry - dismiss that
The current working directory is not always writable.
`current_version` could be mentioned in the error message.
Don't assign a lambda function, use def
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
Playlist metadata must not be fatal.
Use `self._search_regex` and `utils.unified_strdate` instead.
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
`u` prefix is not necessary as `from __future__ import unicode_literals` has the same effect, and such a syntax is not available in Python 3.2.
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
Use `'` as the quote character for consistency with the rest of the file
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
aws_ip_ranges -> aws_service_ip_ranges
should be self.forward.
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
aws_ip_ranges -> aws_service_ip_ranges
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
I suggest handling the response failure would yield better error messages. ``.json()`` will always raise a ``JSONDecodeError`` Example: ```python r = requests.get(...) r.raise_for_status() # if 404, 401, 500 etc ... hosts_list = r.json() ```
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
Please remove this example, since I would consider this usage as not recommended.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
`return not owner or owner == publication_info['owner']` could be used.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
This looks like it would throw an exception on Python3 (because yaml.dump will return a text string and you can't decode a text string on Python3). Since what we want to do is make sure that it is a text string on both Python2 and Python3, what we should do is use to_text here to transform it into a text string: ``` python from ansible.module_utils._text import to_text [....] dumped += yaml.dump(to_text(abridged_result, allow_unicode=True, width=1000, Dumper=AnsibleDumper, default_flow_style=False)) ```
Shapes mentioned in the docstring are generally 2D; should be 3D
Make more relaxed and add title regex as fallback.
Do not change the order of extraction.
Similarly, ```if tc['skip'].get('i')```
I don't see why `default: false` should not be there. At least here :) Depends a bit on what kind of option it is... What definitely shouldn't be there is `required: false`, but that's another option...
You're right. I also checked the source at tag `2.1.0`, and it contains that parameter. I guess they did some refactoring between 2.2.x and 2.3.0 which resulted in that commit...
Use `'` as the quote character for consistency with the rest of the file
use ```from ansible.module_utils.vmware import get_cluster```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
So we will remove it, and add it back? Okay :)
nvm, I figured it out
To match the previous behavior, we should have `connection='smart'` instead of `local`
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
To match the previous behavior, we should have `connection='smart'` instead of `local`
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
I think we should keep this for user, mainly in this early stage.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
we really need something generic.... getting complex :-)
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
we really need something generic.... getting complex :-)
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
You can add this^ line before `if` statement, and remove the exactly same code from line 135.
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
You don't need a lambda here. Also, don't break lines with `\`.
Set default `batch_size` to None, like in `fit`.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
You don't need a lambda here. Also, don't break lines with `\`.
This bit of metadata should also be added to each dataset in the "both" case.
Set default `batch_size` to None, like in `fit`.
Set default `batch_size` to None, like in `fit`.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Set default `batch_size` to None, like in `fit`.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
supporting snapmirror-label would affect this logic, are only one of the two could be present, or both of them.
filters //= 2
Don't use this pattern. No try/except block here.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Shouldn't this use the value of ansible_python_interpreter? There is a mechanism (winrm.py uses it) to pass in some host variables to connection plugins, so this should probably implement that.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
How about: ```suggestion from ansible.module_utils.parsing.convert_bool import boolean as to_bool try: verify = to_bool(option) except TypeError: # it wasn't a boolean value verify = option # Set to a CA bundle: finally: if verify is False: # is only set to bool if try block succeeds requests.packages.urllib3.disable_warnings() self._display.warning( u"SSL verification of %s disabled" % self.foreman_url, ) return verify ```
We should probably explicitly `to_text` it ```suggestion self._display.warning(to_text(msg) + u' Disabling the Foreman callback plugin.') ```
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
@pilou-, cyberark-bizdev I had a chance to talk to bcoca today and he said the best way to do this is to pass a list of dicts to the lookup. Then either of these playbook constructs can be valid: ``` with_cyberaskpassword: - {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - {'appid': 'Application2', 'query': 'safe=Safe2;Folder=root;Object=User2', 'output': 'password,passprops.username,passprops.address'} with_cyberarkpassword: {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - debug: msg='{{ lookup('cyberark_password', {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'}) }}' ``` Implementing that will take a little restructuring. I'll go into that in the run method below.
@pilou-, cyberark-bizdev I had a chance to talk to bcoca today and he said the best way to do this is to pass a list of dicts to the lookup. Then either of these playbook constructs can be valid: ``` with_cyberaskpassword: - {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - {'appid': 'Application2', 'query': 'safe=Safe2;Folder=root;Object=User2', 'output': 'password,passprops.username,passprops.address'} with_cyberarkpassword: {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'} - debug: msg='{{ lookup('cyberark_password', {'appid': 'Application1', 'query': 'safe=Safe1;Folder=root;Object=User1', 'output': 'password,passprops.username,passprops.address'}) }}' ``` Implementing that will take a little restructuring. I'll go into that in the run method below.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
not a list of dicts, just pass a dict to the with: ```yaml with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ```
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
This method isn't necessary.
Okay, so @cyberark-bizdev take out my first example. The last two are what we're shooting for. (The middle one is the same as bcoca's example, just in compact yaml instead of "readable" yaml ;-)
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Style nitpick, but please insert spaces around operators (`*`, `+`, etc).
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
No, catch exception.
ð, this is a nice little refactor.
```/tv/tags/[^/]*?``` => ```/tv/tags/[^/]+```
I would like this hunk in a separate PR.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
What's the reason for using the shell here? There's no redirection, pipes, or other needs for the shell that I can see.
this should use the new API without hardcoded id now
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
this code is almost the same as the one `VVVVIDIE`, move into a seperate method in base class, and use it in both extractors.
this code is almost the same as the one `VVVVIDIE`, move into a seperate method in base class, and use it in both extractors.
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
skip a line to be consistent
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
As exclude_tags could be an empty set, I would directly check `if exclude_tags and set(server_tags).intersection(exclude_tags)`. This way, it should also work when exclude_tags and server_tags are empty.
I think we should fix what modules are returning rather than adding more to this list.
As exclude_tags could be an empty set, I would directly check `if exclude_tags and set(server_tags).intersection(exclude_tags)`. This way, it should also work when exclude_tags and server_tags are empty.
It'd be good to include a default sleep here so this loop doesn't continuously hit the oVirt endpoint. Even just a one or two second sleep would be fine between tries.
```suggestion fallback=(env_fallback, ['ANSIBLE_HWC_PASSWORD']), ```
Talked about this in slack. I believe we should use "VALUE_SPECIFIED_IN_NO_LOG_PARAMETER" instead of content as we considered display of content a security problem waaay back in 1.2.0 (the first release after content was introduced) https://github.com/ansible/ansible/issues/2884 This was the fix proposed by mpdehaan. I'm not sure that it worked then, but at some point (maybe 2.0 or 2.1) we started getting the displayed arguments from invocation which would have fixed that if it had been broken before. So I think that the issue history shows that the module has a policy of consciously hiding the value of the content parameter for security reasons. We *can* decide that we want to change that policy (content is really no different in this regard than lineinfile, for instance) but since it was introduced as a security fix we need to subject the change to a deprecation cycle, prominent release notes of the change, and possibly a toggle.
```suggestion fallback=(env_fallback, ['ANSIBLE_HWC_PASSWORD']), ```
We're in the controller and this isn't something we're passing to an exception constructor. Therefore use to_text() here.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I suggest: if parser.get('DEFAULT', 'vmware_validate_certs').lower() in ('no', 'false'):
We're in the controller and this isn't something we're passing to an exception constructor. Therefore use to_text() here.
It would be easier if RPM and DEB were to give the same structured reply, or having an agnostic module would not be very useful (in cases like "if upstream version is greater than x.y"). Comparing versions is a complex operation and there is no filter around `dpkg --compare-versions`. Also having the full version (epoch+upstream+release, following the standard distro notation) along with the upstream version would be useful I think.
There are 3 AWS partitions: aws, aws-cn, and aws-us-gov. Organizations is not yet available in China but it is in GovCloud, so we should also check for `arn:aws-us-gov:organizations:`.
It would be easier if RPM and DEB were to give the same structured reply, or having an agnostic module would not be very useful (in cases like "if upstream version is greater than x.y"). Comparing versions is a complex operation and there is no filter around `dpkg --compare-versions`. Also having the full version (epoch+upstream+release, following the standard distro notation) along with the upstream version would be useful I think.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Can you move this function above main() as per ansible guildelines: " Ansible follows C-style code flow where the caller functions/methods are towards the bottom of the file and the callee implementations are above them. "
In the future it might be nice to add the `file` as an argument to these `tower-cli` modules. That way, you could just pass a `StringIO` in directly instead of having to monkey-patch `sys.stdout` in this way: https://github.com/pallets/click/blob/67f39e4ff9093ee347207d1cc1abe0130c21268e/click/utils.py#L206
If this is retained, use `url_or_none()` from `utils.py` to condition the values: ```suggestion video_url = url_or_none(url_json.get('sources')[0].get('src')) or self._og_search_video_url(webpage) # Get the video url video_type = url_json.get('sources')[0].get('type') # Get the video type -> 'video/mp4' video_thumbnail = url_or_none(url_json.get('splash')) or self._og_search_thumbnail(webpage) # Get the thumbnail ``` (and `from ..utils import url_or_none` at the top).
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
This line is unnecessary.
This line is unnecessary.
1. Single quotes. 2. `expected`.
1. Single quotes. 2. `expected`.
This line is unnecessary.
Actually, it's an opposite. It's a check for successful login.
1. Single quotes. 2. `expected`.
Move data and query into `_download_webpage` call.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
This code block is redundant with the logic of `save_weights_to_hdf5_group`. I would recommend extracting an abstract function that can be reused in both locations.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
This code block is redundant with the logic of `save_weights_to_hdf5_group`. I would recommend extracting an abstract function that can be reused in both locations.
Please remove this example, since I would consider this usage as not recommended.
That's something we should fix in the Keras backend.
Indent isn't really necessary here: ```suggestion if already_loaded_vendored_modules: print( 'doh, some vendored stuff was already loaded: {0}'. format(already_loaded_vendored_modules), file=sys.stderr, ) ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Do note that this only looks at the primary credential cache. This means that if you use a collection credential cache such as DIR, KEYRING or KCM (default in most distributions these days), you might not see a ticket that exists in a non-primary credential cache. Maybe consider using `klist -A`, or try a `kswitch -p <principal>`? The latter is easier to parse, but might break stuff if people are still using the old krb5 APIs (rather than GSSAPI) and were using the primary credential that you just made secondary.
Read coding conventions on optional fields.
Read coding conventions on optional fields.
No such field.
Make this error more specific to cyberark. A lookup is often used in conjunction with other modules and features, this sounds too generic.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Please remove this example, since I would consider this usage as not recommended.
For consistency path pruning should be done the same as in the boilerplate test: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L13-L14 https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L41-L42
For consistency path pruning should be done the same as in the boilerplate test: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L13-L14 https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L41-L42
This debug message seems like it would appear _before_ we actually attempt to do any checking. It's probably worth keeping the old message (or something similar) _after_ the checking has been completed.
For consistency path pruning should be done the same as in the boilerplate test: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L13-L14 https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L41-L42
For consistency path pruning should be done the same as in the boilerplate test: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L13-L14 https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L41-L42
*nit* `/play.For/playbook. For /`
Same question for dropping lambda here as well.
No need for this line
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
Can you factorize this over `test_EarlyBaselineStopping_baseline_met`? The codes look a little redundant.
This line fails for me trying to run Ansible under Python3 - `response.headers` is there, but there is no `getheader` method. I don't know the internals of what is returned from `open_url` but I can call `get` on it and it works for both Python2 and Python3: ``` fatal: [127.0.0.1]: FAILED! => { "msg": "An unhandled exception occurred while running the lookup plugin 'manifold'. Error was a <class 'ansible.errors.AnsibleError'>, original message: ['Traceback (most recent call last):\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 226, in run\\n team_data = client.get_teams(team)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 166, in get_teams\\n data = self.request(api, endpoint)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 113, in request\\n if response.headers.getheader(\\'content-type\\') == \\'application/json\\':\\n', \"AttributeError: 'HTTPMessage' object has no attribute 'getheader'\\n\"]" } ```
Add a `# Arguments` section to the docstring.
This condition is not needed, t is always None here.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
Never ever do that. You must handle it at the place of the actual method call.
Never ever do that. You must handle it at the place of the actual method call.
Never ever do that. You must handle it at the place of the actual method call.
f is already at 0, the `truncate()` is uselesss.
I'd like to see here something like a `ResourceWarning` reported using the default Python warnings infra.
It might also be no IGWs found here.
This is error prone, `len` of the actual string should be used instead.
Space after `,`.
Use `'` as the quote character for consistency with the rest of the file
This is more efficient: ```suggestion key = next(iter(old[0]) ```
connection plugins should not have their own python logic. If distros are using different python/missing python it is up to user to add (plenty of examples with raw and ansible_python_interpreter).
```suggestion query=dict(type='list', elements='str'), ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
please don't import here, import globally
please don't import here, import globally
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
If both of these operations fail, it's going to be unclear what actually happened.
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
Use `'` as string delimiter for consistency
dont do this, now we have 3 parsers, we shoudl move parsing/json to module_utils and use from there
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Read: coding conventions, mandatory fields.
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
Nitpick, you can use a list comprehension here instead of calling list on a generator expression.
var is a reserved keyword, use `v` or something like that.
`enable_3D` is a bool, so it will always be set, i think this can be a little simplified as well ```suggestion video_spec.device.enable3DSupport = self.params['enabled_3D'] enabled_3d = self.params['enabled_3D'] if self.params['enable_3D'] != video_card_facts['enable_3D_support']: self.change_detected = True ```
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
I would rather see ValueError instead of general exception
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
```suggestion return b'\r\n'.join(to_bytes(line, nonstring='passthru') for line in result) ``` (and import `to_bytes`)
I think this should be 'exit' instead of 'abort'
The other option is to strip the arguments and keep it as a list
I think this should be 'exit' instead of 'abort'
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
~~1. This won't work for UTF-8.~~ Nevermind, `BaseCookie.__ParseString` does not seem to be capable of UTF-8. 2. This will produce `"None"` string if there is no cookies, i.e. `cookie_header` is `None` that is completely wrong. 3. Also this should only taken place when `cookie_header` is a not a bytestring already.
`shlex.join` was added in Python 3.8, so an alternative is needed here.
There should be fallbacks for these values since they are more or less static.
Please fix docstring typos
please don't import here, import globally
```suggestion query=dict(type='list', elements='str'), ```
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
to_text here is good practice: ```suggestion return to_text(out, errors='surrogate_or_strict'), to_text(err, errors='surrogate_or_strict') ```
Then the serializer should be updated, and metrics classes should have a `get_config`/`from_config` method
```suggestion query=dict(type='list', elements='str'), ```
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
```suggestion query=dict(type='list', elements='str'), ```
```suggestion query=dict(type='list', elements='str'), ```
Rename to something else. This extractor must delegate to embed extractor.
Can we print entire error rpc. In case of error `message` alone is not very helpful.
Can we print entire error rpc. In case of error `message` alone is not very helpful.
It would be useful to tell the user which `key` is invalid.
Can we print entire error rpc. In case of error `message` alone is not very helpful.
That makes perfect sense to me.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
No it's part of python and should be available.
You've forgot to pass `info_dict` to `supports()`.
You've forgot to pass `info_dict` to `supports()`.
This code block is redundant with the logic of `save_weights_to_hdf5_group`. I would recommend extracting an abstract function that can be reused in both locations.
super nit: the string is slightly malformatted. The script displays: Enter reviewers in the format of "name1 <email1>", "name2 <email2>: Also, Its not clear if I should actually type the quotes when entering reviewers.
super nit: the string is slightly malformatted. The script displays: Enter reviewers in the format of "name1 <email1>", "name2 <email2>: Also, Its not clear if I should actually type the quotes when entering reviewers.
Don't add `required=False` because that is the default. The required parameters will stand out.
Don't add `required=False` because that is the default. The required parameters will stand out.
You can import `try_rm` from helper
You can import `try_rm` from helper
You can just use 'playlist_count'
Should not break if no `type`.
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
Should not break if no `type`.
`expected_status` to `_download_json` instead.
Query should go as `query` to `_download_webpage`.
Can you explain what this option does and why it is needed? From the implementation, it looks like this can be used to overwrite arbitrary module options, without any type checks or other sanity checks. I don't think modules should have such options.
DRY 105, 107.
Can you explain what this option does and why it is needed? From the implementation, it looks like this can be used to overwrite arbitrary module options, without any type checks or other sanity checks. I don't think modules should have such options.
Query should go as `query` to `_download_webpage`.
bcoca has said he's happy with this bit
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
```suggestion query=dict(type='list', elements='str'), ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
```suggestion query=dict(type='list', elements='str'), ```
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
This should be a character string (prefixed with `u`)
`return not owner or owner == publication_info['owner']` could be used.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
This check is redundant since we have `if 'name'...` on previous line.
Similarly, ```if tc['skip'].get('i')```
Similarly, ```if tc['skip'].get('i')```
Similarly, ```if tc['skip'].get('i')```
@s-hertel that would be really nice for vanilla pulp ansible installations, which don't currently have token auth.
Code markers around `put()`
Code markers around `put()`
Is there a way to format the stdout? When applying it gets hard to read: ``` "sdtout": "aws_instance.example: Creating...\n ami: \"\" => \"ami-ff4ea59d\"\n associate_public_ip_address: \"\" => \"<computed>\"\n availability_zone: \"\" => \"<computed>\"\n ebs_block_device.#: \"\" => \"<computed>\"\n ephemeral_block_device.#: \"\" => \"<computed>\"\n instance_state: \"\" => \"<computed>\"\n instance_type: \"\" => \"t2.micro\"\n ipv6_address_count: \"\" => \"<computed>\"\n ipv6_addresses.#: \"\" => \"<computed>\"\n key_name: \"\" => \"<computed>\"\n network_interface.#: \"\" => \"<computed>\"\n network_interface_id: \"\" => \"<computed>\"\n placement_group: \"\" => \"<computed>\"\n primary_network_interface_id: \"\" => \"<computed>\"\n private_dns: \"\" => \"<computed>\"\n private_ip: \"\" => \"<computed>\"\n public_dns: \"\" => \"<computed>\"\n public_ip: \"\" => \"<computed>\"\n root_block_device.#: \"\" => \"<computed>\"\n security_groups.#: \"\" => \"<computed>\"\n source_dest_check: \"\" => \"true\"\n subnet_id: \"\" => \"<computed>\"\n tenancy: \"\" => \"<computed>\"\n volume_tags.%: \"\" => \"<computed>\"\n vpc_security_group_ids.#: \"\" => \"<computed>\"\naws_instance.example: Still creating... (10s elapsed)\naws_instance.example: Still creating... (20s elapsed)\naws_instance.example: Still creating... (30s elapsed)\naws_instance.example: Creation complete after 34s (ID: i-04362e7210c113e2c)\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n" ```
Is there a way to format the stdout? When applying it gets hard to read: ``` "sdtout": "aws_instance.example: Creating...\n ami: \"\" => \"ami-ff4ea59d\"\n associate_public_ip_address: \"\" => \"<computed>\"\n availability_zone: \"\" => \"<computed>\"\n ebs_block_device.#: \"\" => \"<computed>\"\n ephemeral_block_device.#: \"\" => \"<computed>\"\n instance_state: \"\" => \"<computed>\"\n instance_type: \"\" => \"t2.micro\"\n ipv6_address_count: \"\" => \"<computed>\"\n ipv6_addresses.#: \"\" => \"<computed>\"\n key_name: \"\" => \"<computed>\"\n network_interface.#: \"\" => \"<computed>\"\n network_interface_id: \"\" => \"<computed>\"\n placement_group: \"\" => \"<computed>\"\n primary_network_interface_id: \"\" => \"<computed>\"\n private_dns: \"\" => \"<computed>\"\n private_ip: \"\" => \"<computed>\"\n public_dns: \"\" => \"<computed>\"\n public_ip: \"\" => \"<computed>\"\n root_block_device.#: \"\" => \"<computed>\"\n security_groups.#: \"\" => \"<computed>\"\n source_dest_check: \"\" => \"true\"\n subnet_id: \"\" => \"<computed>\"\n tenancy: \"\" => \"<computed>\"\n volume_tags.%: \"\" => \"<computed>\"\n vpc_security_group_ids.#: \"\" => \"<computed>\"\naws_instance.example: Still creating... (10s elapsed)\naws_instance.example: Still creating... (20s elapsed)\naws_instance.example: Still creating... (30s elapsed)\naws_instance.example: Creation complete after 34s (ID: i-04362e7210c113e2c)\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n" ```
`autonumber` is not reset to zero in the first place.
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
please remove the extra space at the start of the line to fix the failing tests
please remove the extra space at the start of the line to fix the failing tests
Tell people where we are looking `CONFIG_FILES`
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
should be self.forward.
```suggestion message_text = self.get_deprecation_message(msg, version=version, removed=removed, date=date, collection_name=collection_name, warn_change=warn_change) ```
CI failure due to: ``` 2017-01-31 20:28:20 ERROR: PEP 8: lib/ansible/module_utils/basic.py:725:18: E121 continuation line under-indented for hanging indent (legacy) ```
CI failure due to: ``` 2017-01-31 18:50:23 ERROR: PEP 8: lib/ansible/module_utils/netapp.py:150:31: W292 no newline at end of file (current) ```
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Just an empty line, could be removed for cleaner code
use list literal
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Just an empty line, could be removed for cleaner code
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
small typo ```suggestion # table availability in check_src/dst. ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
CI failure due to: ``` 2017-01-31 18:50:23 ERROR: PEP 8: lib/ansible/module_utils/netapp.py:150:31: W292 no newline at end of file (current) ```
With this simplification, the pythonic way of generating a list is to use list comprehension. You can replace the whole function body with: ```python return [parse_to_obj(r) for r in parse_to_logical_rows(vlan_out)] ```
CI failure due to: ``` 2017-01-31 20:28:20 ERROR: PEP 8: lib/ansible/module_utils/basic.py:725:18: E121 continuation line under-indented for hanging indent (legacy) ```
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
This is the non-generator path. 0 is added to val_data here : https://github.com/keras-team/keras/pull/9796/files/86e5448ff06d30bebfdf8a4781562ad6abaabd1c#diff-b25d82c3f751f73f6e62b8455547ac73R124
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
CI failure due to: ``` 2017-01-31 18:50:23 ERROR: PEP 8: lib/ansible/module_utils/netapp.py:150:31: W292 no newline at end of file (current) ```
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
With this simplification, the pythonic way of generating a list is to use list comprehension. You can replace the whole function body with: ```python return [parse_to_obj(r) for r in parse_to_logical_rows(vlan_out)] ```
Not a real issue, but we recommend to sort the order of lists if the order is not of importance.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
Similarly, ```if tc['skip'].get('i')```
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
you could also write this as: h_item = search_obj_in_list(w_item['member'], h, key='member') or {}
Could you please keep the same string quoting style across the module? ```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('UTC')), '2019-06-15T14:45:00+00:00'), ```
Drop the `as e` since it's not used, and is not compatible with python 2.4.
Don't need to import HAS_BOTO3 now.
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
`no_log=True` is argument spec will handle this.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Great, this is what I meant by passing the keyword args directly. Nice job.
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
To restore almost the old behavior, add `import errno` at the top and apply this change: ```suggestion except EnvironmentError as exc: if exc.errno == errno.ENOENT: self.fail("Error opening image %s - %s" % (self.load_path, str(exc))) self.fail("Error loading image %s - %s" % (self.name, str(exc))) except Exception as exc: ```
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
No need to escape whitespace.
Format your docstrings like other docstrings in the codebase
This is not used in single video extractor thus should not be here.
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
We have removed checks like this in the past. One thing to note is that the key need not exist on the filesystem to work if it has already been loaded into the agent. We would need to ensure that missing files are allowed.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
I was thinking we'd just use the release script from the older branches for older releases.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
both are valid tests, i don't see why you need to eliminate the existing one
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
The point of these conversion interfaces is that old code should still work. So in this case we should figure out a better solution. Please leave out this layer.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additional task can be executed before action on entity is executed by passing `pre_action` parameter to method. Another task can be executed after action is executed, by passing `post_action` parameter to method. -> Task executed before an action on entity can optionally be specified in `pre_action` parameter. Task executed after an action on entity can optionally be specified in `post_action` parameter.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
If you're only going to get `APSCOOKIE_` _or_ `ccsrftoken`, then you can just return `None` if you don't find anything and the existing token will be reused. If you are expecting to have both, then I would just dedent the next line to be outside the for loop, so that the token is always added to the dictionary on every run. Then you should be able to at least remove the manual headers building in `send_request`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
both are valid tests, i don't see why you need to eliminate the existing one
Or ```if not hasattr(filename, 'write')``` or ```if isinstance(filename, compat_str)```? Checking for an exact type makes the codes less flexible.
Or ```if not hasattr(filename, 'write')``` or ```if isinstance(filename, compat_str)```? Checking for an exact type makes the codes less flexible.
'+' is redundant here.
It would be awesome if buildah supported copying from a container.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Prefer consistent using of single quotes when possible.
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
there could be a function to convert entire list, as this code is repeated below
please add wait_for_vm_ip
Code markers around `put()`
Code markers around `put()`
That should only be called if the plugin should in `enabled` state afterwards.
Another option is to use `threading=True` or `use_threads=True`
That should only be called if the plugin should in `enabled` state afterwards.
Code markers around `put()`
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
That should only be called if the plugin should in `enabled` state afterwards.
Yes, unless we expect users to access it and set it (we don't), it should be private.
That should only be called if the plugin should in `enabled` state afterwards.
Code markers around `put()`
Code markers around `put()`
Yes, unless we expect users to access it and set it (we don't), it should be private.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
That should only be called if the plugin should in `enabled` state afterwards.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Yes, unless we expect users to access it and set it (we don't), it should be private.
That should only be called if the plugin should in `enabled` state afterwards.
Use fail_json_aws for AWS exceptions as the messages contain a lot more info
Use fail_json_aws for AWS exceptions as the messages contain a lot more info
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
`try_get`, single quotes.
Since this is now happening here and on [line 426](https://github.com/ansible/ansible/pull/30322/files#diff-cc1ca32d3b556628c6b2562406c7478dL426) does it make sense to change [line 407](https://github.com/ansible/ansible/pull/30322/files#diff-cc1ca32d3b556628c6b2562406c7478dL407) instead? Smaller net diff. Besides that, tested this and works for me.
Two line breaks after the first sentence.
This bit of metadata should also be added to each dataset in the "both" case.
If VMM domain, add support for "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
If VMM domain, add support for "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
Just leave it out, we'll think of something later.
Just leave it out, we'll think of something later.
I feel like it would actually be clearer and more economical to separate the two cases entirely: one input vs. multiple inputs.
Just leave it out, we'll think of something later.
```suggestion query=dict(type='list', elements='str'), ```
return dict((key, self.get(key)) for key in self.keys())
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
return dict((key, self.get(key)) for key in self.keys())
This wasn't used previously, is it really needed? If the answer is yes, you should use a `set` instead of a dictionary for keeping track of them.
small typo ```suggestion # table availability in check_src/dst. ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
small typo ```suggestion # table availability in check_src/dst. ```
That's OK, I just wasn't sure how it's working.
To follow the pattern of other applications, please put this conditional inside the `if weights == 'imagenet'` block
To follow the pattern of other applications, please put this conditional inside the `if weights == 'imagenet'` block
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
That's OK, I just wasn't sure how it's working.
You don't need to specify this field if there is no return output
should be `current_option =`
Same here. Don't do that!
so is it possible to update webapp and app settings at once? seems like UpdateAppSettings overrides CreateOrUpdate, so if user wants to update both, only settings will be updated
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
so is it possible to update webapp and app settings at once? seems like UpdateAppSettings overrides CreateOrUpdate, so if user wants to update both, only settings will be updated
```suggestion to iterate use a C(with_) directive. ```
Similarly, ```if tc['skip'].get('i')```
Use _download_webpage is urlh is not used. And note should be meaningful for typical users.
Use _download_webpage is urlh is not used. And note should be meaningful for typical users.
Use _download_webpage is urlh is not used. And note should be meaningful for typical users.
use basic.py's `missing_required_lib` function as it gives details on host and python to avoid user confusion
Python 3.5 does not have `unicode`. Take a look at the [ansible text helper methods](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/_text.py) for alternatives. Only noting the first occurrence.
I think we should add an `allow_overwrite` or similar param.
I think we should add an `allow_overwrite` or similar param.
Use _download_webpage is urlh is not used. And note should be meaningful for typical users.
How about lower-case? ```suggestion choices: [ 'dns', 'email', 'manual', 'webserver'] ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
it seems this and other parameters are missing from docs
I think we should add an `allow_overwrite` or similar param.
I think we should add an `allow_overwrite` or similar param.
You can just use 'playlist_count'
I think we should add an `allow_overwrite` or similar param.
This will throw an exception every time when a server is down. When glusterfsd is down the output looks like this: Brick 10.70.43.200:/mnt/engine Status: Transport endpoint is not connected Number of entries: - And you'll be trying to do int('-') which will throw ValueError. And the module throws error: fatal: [10.70.42.25]: FAILED! => {"changed": false, "msg": "Invalid heal status option."} in the function main.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
This will have detrimental effects on operations like 'modify' and 'delete', which does not require connection type of 'connection' or 'network device'. Also, it will break backward compatibility.
filters //= 2
Move the check_mode test into the `do_notify_teams` function, and see if you can do something relevant instead e.g. test the connectivity so you do as much as possible in check-mode.
Please implement check-mode. In this case check-mode could either not send a notification, or better, sends a "fake" notification (so authentication is attempted). It depends on the API if this is feasible. It's always better that check-mode is performing more logic without actually doing something.
Okay, I just tested this and it looks like fd.close() does not cause an error. It's useless to have it there but not strictly necessary to remove it.
Same here. required=False and default=None are obsolete. Only specify them if they are set.
Yeah, a list is fine.
Missing `raise`. I would probably change to `AnsibleAssertionError`.
Same here. required=False and default=None are obsolete. Only specify them if they are set.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
both are valid tests, i don't see why you need to eliminate the existing one
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
Simplier: ```python password.os.path.exists = lambda x: x == to_bytes('/path/to/somewhere') ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
no trailing conditionals, people tend to miss these (i'm guilty of having written too many of em)
Move the check_mode test into the `do_notify_teams` function, and see if you can do something relevant instead e.g. test the connectivity so you do as much as possible in check-mode.
```suggestion parts = to_native(date.strip()).split(':', 1) ```
We could fall back to `__file__` or something in that case at minimum. Could be useful to include that regardless.
Line is too long.
Missing `raise`. I would probably change to `AnsibleAssertionError`.
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
it should also check if it can write there
Missing `raise`. I would probably change to `AnsibleAssertionError`.
it should also check if it can write there
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Same here. required=False and default=None are obsolete. Only specify them if they are set.
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
both are valid tests, i don't see why you need to eliminate the existing one
Since this is length 1 always, you can use `connection.extend(response['connections'])` for the same result.
both are valid tests, i don't see why you need to eliminate the existing one
I have a concern on pagination here, `list_objects` is going to default to 100 or 500 items, which is fine most of the time (it was like this prior) but would make a nice enhancement.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
return dict((key, self.get(key)) for key in self.keys())
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
`return not owner or owner == publication_info['owner']` could be used.
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
`return not owner or owner == publication_info['owner']` could be used.
return dict((key, self.get(key)) for key in self.keys())
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
By non-trivial I just mean values that aren't None or empty strings. I'm not sure how much user control we expect over those settings but I might not have read the parameters carefully enough. The following untested somewhat pseudocode illustrates the simpler approach: ``` @AWSRetry(**backoff_params) def list_keys_with_backoff(connection, bucket): pg = connection.get_paginator('list_objects_v2') return [obj['Key'] for obj in pg.paginate(Bucket=bucket).build_full_result()['Objects']] def list_keys(connection, bucket): try: return list_keys_with_backoff(connection, bucket) except botocore.exceptions.ClientError as e: etc... ```
return dict((key, self.get(key)) for key in self.keys())
The behavior of the inventory script was last match wins but I think first match wins is more intuitive for setting the selection_order variable.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
`return not owner or owner == publication_info['owner']` could be used.
We really should get rid of the `login_unix_socket` parameter. This parameter is useless, `host` must be used instead ([doc](https://www.postgresql.org/docs/10/static/libpq-connect.html#LIBPQ-CONNECT-HOST)).
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
need to catch BotoCoreError here too.
Could you have a syntax close to : ``` if not re.match(): raise ... ``` That we don't have as much indentation levels.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Since we're optimizing to solve this bug, would be good to move regex compilation up to be a one-time thing. Maybe a class attribute or global for each compiled regex. ``` python class LinuxHardware(Hardware): BIND_MOUNT_RE = re.compile(r".*\]") [...] if re.match(self.BIND_MOUNT_RE, fields[1]): ```
Array ellipsis is an obscure feature and not necessary here. It hinders readability
the closing `)` on this line is misplaced.
No such meta field.
Since we're optimizing to solve this bug, would be good to move regex compilation up to be a one-time thing. Maybe a class attribute or global for each compiled regex. ``` python class LinuxHardware(Hardware): BIND_MOUNT_RE = re.compile(r".*\]") [...] if re.match(self.BIND_MOUNT_RE, fields[1]): ```
<nod> Before working on ansible, I'd do regex compilation at module scope. mpdehaan and jimi-c liked things at class level so I've put more things there but it still doesn't feel natural in python... Global scope and in the `__init__` should both do the right thing for this piece of code (the classes are only instantiated once so there's no performance disadvantage to compiling in `__init__`; I think that **init** should function normally as all of our `__new__` methods are returning a class.)
1/2 is good, the other 1/2 should be more. 'If you want to have keywords applied to the contained tasks, consider using import_role instead or use the "apply" keyword'
This breaks under quite a few circumstances: 1. With `%(episode_number)d` when there is no episode number, etc (gives NA in filename) 2. `%(playlist_index)s` doesnt pad like it does in filename 3. `--autonumber-start`, `--output-na-placeholder` etc won't work etc Generalizing code with `prepare_filename` (splitting out only the sanitization) will avoid these issues
<nod> Before working on ansible, I'd do regex compilation at module scope. mpdehaan and jimi-c liked things at class level so I've put more things there but it still doesn't feel natural in python... Global scope and in the `__init__` should both do the right thing for this piece of code (the classes are only instantiated once so there's no performance disadvantage to compiling in `__init__`; I think that **init** should function normally as all of our `__new__` methods are returning a class.)
<nod> Before working on ansible, I'd do regex compilation at module scope. mpdehaan and jimi-c liked things at class level so I've put more things there but it still doesn't feel natural in python... Global scope and in the `__init__` should both do the right thing for this piece of code (the classes are only instantiated once so there's no performance disadvantage to compiling in `__init__`; I think that **init** should function normally as all of our `__new__` methods are returning a class.)
This breaks under quite a few circumstances: 1. With `%(episode_number)d` when there is no episode number, etc (gives NA in filename) 2. `%(playlist_index)s` doesnt pad like it does in filename 3. `--autonumber-start`, `--output-na-placeholder` etc won't work etc Generalizing code with `prepare_filename` (splitting out only the sanitization) will avoid these issues
I would prefer that we stay away from nested functions like this if possible, moving into a scope where it could be tested independent of the `tests` method. We should probably give it a better name too. In `filters.core` we utilize a `unicode_wrap` function, so maybe we could do similarly here. We also use `partial` there instead of creating our own closure, but either way is fine with me. I'd also write tests to verify this functionality.
Since we're optimizing to solve this bug, would be good to move regex compilation up to be a one-time thing. Maybe a class attribute or global for each compiled regex. ``` python class LinuxHardware(Hardware): BIND_MOUNT_RE = re.compile(r".*\]") [...] if re.match(self.BIND_MOUNT_RE, fields[1]): ```
<nod> Before working on ansible, I'd do regex compilation at module scope. mpdehaan and jimi-c liked things at class level so I've put more things there but it still doesn't feel natural in python... Global scope and in the `__init__` should both do the right thing for this piece of code (the classes are only instantiated once so there's no performance disadvantage to compiling in `__init__`; I think that **init** should function normally as all of our `__new__` methods are returning a class.)
Array ellipsis is an obscure feature and not necessary here. It hinders readability
Small nit pick here - Do not remove `msg` attribute from `exc`, it is helpful in debugging. Rest LGTM
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
@hermansje Let's have `on_batch_{ begin | end }` be aliases for `on_train_batch_{begin | end}` like in your original code
Matching empty string is senseless.
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Tell people where we are looking `CONFIG_FILES`
Just to make an attempt at word-smithing > When doing an --list, represent shared variables inside groups or the inventory, > which has a smaller memory footprint but is not Ansible's internal representation
Tell people where we are looking `CONFIG_FILES`
a simpler fix i was already working on: `+ display.display(json.dumps(text, cls=AnsibleJSONEncoder, sort_keys=True, indent=4))`
a simpler fix i was already working on: `+ display.display(json.dumps(text, cls=AnsibleJSONEncoder, sort_keys=True, indent=4))`
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
^ that seems to be an expression not really a data type issue (sorting keys, this is another known json issue), in any case, there is also an existing `jsonify` in module_utils.
should be `auth.items()` for python 2 and 3 compatibility. Edit: I see `iteritems` comes from `six`, I'm just not sure why it's needed when `auth.items()` will work fine
(Similarly, mark any string that you are going to call decode on with as a b"string".)
use ```from ansible.module_utils.vmware import get_parent_datacenter```
use `unfrackpath(filename)` to ensure we get something the user can always use
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Nit: please shorten lines here to 80 char or less (also in `initializers.py`)
Dots must be escaped.
Should `args[1:]` here (the first entry in `args` is `self`).
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
Recursion should be replaced with plain loop.
No point in calling super here
Better to add `rank` here
Dots must be escaped.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
small typo ```suggestion # table availability in check_src/dst. ```
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
It seems you are indenting with 8 spaces. It should be 4.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
supporting snapmirror-label would affect this logic, are only one of the two could be present, or both of them.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It'd be good to include a default sleep here so this loop doesn't continuously hit the oVirt endpoint. Even just a one or two second sleep would be fine between tries.
It'd be good to include a default sleep here so this loop doesn't continuously hit the oVirt endpoint. Even just a one or two second sleep would be fine between tries.
Here be dragons. I don't see check-mode being tested anywhere in the module. So I expect the module to perform a reboot in check-mode. Probably not what people expect.
Technically, explicit 0 is also valid value for `start_time` but filtered with this check.
Need to `return bind_mounts` here
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
I don't think it's acceptable to have backend-specific statements if it can be avoided. Also this would fail most of the time because usually the input shape contains `None`.
Do not use underscore as prefix.
Do not use underscore as prefix.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
Similarly, ```if tc['skip'].get('i')```
You want to move that to module_utils once at least one of this and #59641 is merged.
You want to move that to module_utils once at least one of this and #59641 is merged.
Usually display_id is used before the actual video_id is extracted.
You want to move that to module_utils once at least one of this and #59641 is merged.
*be a string
Can you please add this logic to some method called `find_template` so you don't have to reimplenet the logic of update/create.
Please remove this example, since I would consider this usage as not recommended.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
fixture with load_json
supports_check_mode still needs to be toggled to False
Do not use underscore as prefix.
supports_check_mode still needs to be toggled to False
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
If we can't delete the publication for whatever reason, there will be no error and the module will be trapped in a endless recursive loop.
With the addition of `on_fit_batch_begin`, it might seem to users that `on_batch_begin` will run in all modes (fit/eval/predict). Same for `on_batch_end`. I'm not sure if there's a great way around that since we want to maintain backwards compatibility. Maybe we can just have `on_batch_begin` / `on_validation_batch_begin` (same for `end`)? Do we have use cases where users would want Callbacks in the public `evaluate` and `predict` methods? I'm picturing users mostly using the extra hooks for their validation data (especially with the TensorBoard callback)
Please raise a `NotIplementedError` when the use case is not supported yet.
check here for the regex fix https://github.com/Qalthos/ansible/pull/5/commits/89f2a106db4f7296822e118ad24f66cea84f3be9#diff-e72efaa6b72beb5339ad847e21a31220L87 Good catch on the first_port / last_port ... will add a fix for those. This is a common pattern to be used by eos modules. I have held off on pushing the modules upstream until we get the initial push of the refactored network shared modules
~~1. This won't work for UTF-8.~~ Nevermind, `BaseCookie.__ParseString` does not seem to be capable of UTF-8. 2. This will produce `"None"` string if there is no cookies, i.e. `cookie_header` is `None` that is completely wrong. 3. Also this should only taken place when `cookie_header` is a not a bytestring already.
Please put the docstring description on the first line
With the latest change this import is no longer needed: ```suggestion from ansible.module_utils.six import text_type ```
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
I missed this one in my last review: ```suggestion raise SystemExit('ERROR: Ansible requires the filesystem encoding to be UTF-8; Detected %s.' % fs_enc) ```
I mean, you could do an `or` but that might break pep8 on line length, I dont care either way, the major thing for me was just being defensive about index 0 potentially being a `None` value AND not the _only_ index.
A few stats with this change compared to devel and this PR (100 hosts and 1 debug using jinja2): ``` ==> devel.txt <== 765719 function calls (758704 primitive calls) in 4.990 seconds ==> 45568.txt <== 651530 function calls (644525 primitive calls) in 4.862 seconds ==> glob_get_paths.txt <== 651709 function calls (644704 primitive calls) in 4.881 seconds ``` ``` devel.txt 11: 3648 0.104 0.000 1.195 0.000 loader.py:423(all) 174: 2 0.000 0.000 0.030 0.015 loader.py:546(all) 45568.txt 16: 3648 0.069 0.000 0.734 0.000 loader.py:423(all) 218: 2 0.000 0.000 0.016 0.008 loader.py:549(all) glob_get_paths.txt 17: 3648 0.051 0.000 0.724 0.000 loader.py:423(all) 211: 2 0.000 0.000 0.017 0.009 loader.py:549(all) ``` ``` devel.txt 18: 2850 0.015 0.000 0.724 0.000 glob.py:9(glob) 45568.txt 451: 38 0.000 0.000 0.002 0.000 glob.py:9(glob) glob_get_paths.txt 426: 38 0.000 0.000 0.002 0.000 glob.py:9(glob) ```
Yeah that's probably more defensive given `UserError`, it _could_ be possible, though probably not that likely that there would be some array `[None,'foo', 'bar']`
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
You don't need to specify this field if there is no return output
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
`, no_log = True`
(Similarly, mark any string that you are going to call decode on with as a b"string".)
parentheses not needed.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Remove extra space: `inv.update({env: []})`
Missing dot escape.
Missing dot escape.
You don't need to specify this field if there is no return output
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
```suggestion Kwargs: ```
Okay I think this makes sense, let's just follow this pattern then.
This breaks under quite a few circumstances: 1. With `%(episode_number)d` when there is no episode number, etc (gives NA in filename) 2. `%(playlist_index)s` doesnt pad like it does in filename 3. `--autonumber-start`, `--output-na-placeholder` etc won't work etc Generalizing code with `prepare_filename` (splitting out only the sanitization) will avoid these issues
Combining could be moved to a postprocessor and exposed as a new generic cli option (I would prefer it to be in different PR if any).
I wonder if the output can be simplified to avoid repeating `unset` and `export`.
You can simplify your code a lot by simply updating your boolean, instead of using a list of booleans.
You can simplify your code a lot by simply updating your boolean, instead of using a list of booleans.
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
This can instead be `continue` and let the `else` unnest.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
If we're just testing broker compatibility I don't think we even need this part of the test.
I like this
`return not owner or owner == publication_info['owner']` could be used.
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
We're in the controller and this isn't something we're passing to an exception constructor. Therefore use to_text() here.
We should be able to merge the two cases with something like this? ``` if collections is None and collection_from_task: collections = [collection_from_task] ``` Now `collections` is either the non-None contents of `collections`, or the task's collection, or `None` if neither exist, which means we can drop the `collections` check from the `all()`s and just use `collections` regardless
Shouldn't these be `not_actions` ? ... and the tests should probably include some of these to catch the fact that they're not working... ;)
`not_data_actions` + tests (same as above)
We're in the controller and this isn't something we're passing to an exception constructor. Therefore use to_text() here.
`not_data_actions` + tests (same as above)
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
To match the previous behavior, we should have `connection='smart'` instead of `local`
This statement is never executed in the tests. We should have a test for that.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
We're in the controller and this isn't something we're passing to an exception constructor. Therefore use to_text() here.
small typo ```suggestion # table availability in check_src/dst. ```
We're in the controller and this isn't something we're passing to an exception constructor. Therefore use to_text() here.
Use the Python 2 and low 3 Time Machine: `'url too short: %s' % (video_pre_parts, )` or: `'url too short: %(video_pre_parts)s' % {'video_pre_parts': video_pre_parts, }` or: `'url too short: {video_pre_parts}'.format(video_pre_parts=video_pre_parts)` or: `'url too short: {0}'.format(video_pre_parts)` No doubt there are other ways (eg `....format(**locals())`
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
No, this should always be entered if `input_shape[0]`.
Good catch! yeah there should be a warning.
This debug message seems like it would appear _before_ we actually attempt to do any checking. It's probably worth keeping the old message (or something similar) _after_ the checking has been completed.
```suggestion Kwargs: ```
```suggestion Kwargs: ```
```suggestion Kwargs: ```
```suggestion Kwargs: ```
```suggestion Kwargs: ```
```suggestion Kwargs: ```
```suggestion Kwargs: ```
`User has been created`
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
I'd recommend changing `'{0}'` and `'{2}'` to use double quotes instead of single. `repr` usually gives single quotes, and as such you end up with something like: ``` was converted to 'password: '********'' (type string) ```
should be exception=last_traceback
I would probably go for "Exit" here, but that's more cosmetic than functional.
we normally use display instead of print
I think what you've got it good, thanks
it should be `minor_vers = int(version[1])`
In case this pattern is used in other modules as well, moving it into `exec_sql` is probably a good idea. Also, adding a new argument to `exec_sql` with a default value shouldn't affect the other users.
Just an empty line, could be removed for cleaner code
Here, `self.count_upgrade` is an int, and `outdated` (as above) a `dict` resp. `list`.
You are right! Fixed it in https://github.com/mheap/ansible/pull/3.
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
You can import `try_rm` from helper
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Unnecessary blank line
and -> or
colors should all be configurable
colors should all be configurable
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
Here be dragons. I don't see check-mode being tested anywhere in the module. So I expect the module to perform a reboot in check-mode. Probably not what people expect.
Is this try/except necessary? It's a test
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
style note on all of these.. Unless you need lines later, it's more idiomatic python not to allocate a named temporary variable here. Instead use out.splitlines() directly: ``` python for line in out.splitlines(): ```
style note on all of these.. Unless you need lines later, it's more idiomatic python not to allocate a named temporary variable here. Instead use out.splitlines() directly: ``` python for line in out.splitlines(): ```
I don't understand why we would `return False` here. This function is about giving back an instance based on the public IP address or failing gracefully with an error message for the user. If this `return False` is happening, we need to write code to handle that in all places it is called within the module. This can lead to extra `if/else` which we should avoid for maintainability purposes.
Should be `marker = instances.marker`.
CI failure due to: ``` 2017-01-31 18:43:10 ERROR: PEP 8: lib/ansible/module_utils/netapp.py:150:31: W292 no newline at end of file (current) ```
This line should be `el, el._parent`. Otherwise, you are making the block, have a parent of the el, so we create an extra level of parent relationship. Current: ``` el: BLOCK(uuid=ca00b048-ca01-4d89-34fa-000000000079)(id=4442932392)(parent=TASK: role1 : call role2 again) new_block: BLOCK(uuid=ca00b048-ca01-4d89-34fa-00000000011b)(id=4442932896)(parent=BLOCK(uuid=ca00b048-ca01-4d89-34fa-000000000079)(id=4442932392)(parent=TASK: role1 : call role2 again)) ``` using `el._parent`: ``` el: BLOCK(uuid=ca00b048-ca01-b999-e740-000000000079)(id=4602644128)(parent=TASK: role1 : call role2 again) new_block: BLOCK(uuid=ca00b048-ca01-b999-e740-00000000011b)(id=4602644688)(parent=TASK: role1 : call role2 again) ```
This line should be `el, el._parent`. Otherwise, you are making the block, have a parent of the el, so we create an extra level of parent relationship. Current: ``` el: BLOCK(uuid=ca00b048-ca01-4d89-34fa-000000000079)(id=4442932392)(parent=TASK: role1 : call role2 again) new_block: BLOCK(uuid=ca00b048-ca01-4d89-34fa-00000000011b)(id=4442932896)(parent=BLOCK(uuid=ca00b048-ca01-4d89-34fa-000000000079)(id=4442932392)(parent=TASK: role1 : call role2 again)) ``` using `el._parent`: ``` el: BLOCK(uuid=ca00b048-ca01-b999-e740-000000000079)(id=4602644128)(parent=TASK: role1 : call role2 again) new_block: BLOCK(uuid=ca00b048-ca01-b999-e740-00000000011b)(id=4602644688)(parent=TASK: role1 : call role2 again) ```
I don't understand why we would `return False` here. This function is about giving back an instance based on the public IP address or failing gracefully with an error message for the user. If this `return False` is happening, we need to write code to handle that in all places it is called within the module. This can lead to extra `if/else` which we should avoid for maintainability purposes.
tempted to make this a 'hard' syntax error, skipping the task seems wrong since it can never execute at this point
module.run_command is catching subprocess.CalledProcessError and calling module.fail_json, so should never get this exception at this point. (looks like that was already in the existing code and not introduced in this pr, so just a note...)
Missed one.. Should just be as below unless you want to also pass module into the function. ``` if os.path.isfile(cert_chain): cert_chain = open(cert_chain, 'r').read() ```
Missed one.. Should just be as below unless you want to also pass module into the function. ``` if os.path.isfile(cert_chain): cert_chain = open(cert_chain, 'r').read() ```
This condition is not needed, t is always None here.
You want `changed` to be `True` here if *at least* one DB was created, not if *all* DBs in `non_existence_list` were created (and there has been at least one).
It seems like returning this string is the expected path through the function. So this should probably just be a return instead of raising an exception. Then the code that's calling it can decide to print it and reraise the exception that got us here if it chooses.
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
Please remove the raising of an exception and properly fail the module.
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
You don't need to specify this field if there is no return output
and then remove the parts Glandos point you.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
There's no need to do the 'else', because everything that follows is also your 'else'. It's the continuation of your program.
If `self._module.params['name'] is None`, this will never match and the module fails.
No trailing $, override suitable.
add space after `(w[1])`
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I would expect a module to issue warnings only for something which the user needs to be warned about. If the user wants something to be absent and it already is absent, that's not something I would expect a warning about. You also don't issue a warning if the user has `state == 'present'` and the sequence is already there.
I would expect a module to issue warnings only for something which the user needs to be warned about. If the user wants something to be absent and it already is absent, that's not something I would expect a warning about. You also don't issue a warning if the user has `state == 'present'` and the sequence is already there.
Wrap `then` and `else` with ` to make the sentence easier to parse.
Right, better to use `then_expression` etc.
I'm trying to think of a different class name, especially less confusable with `ManageIQAlert`. But I don't have any good suggestion. (this does fit the class naming in existing manageiq modules, matching the module name, but that's not such a good scheme IMHO, no reason to stick to it...)
Right, better to use `then_expression` etc.
small typo ```suggestion # table availability in check_src/dst. ```
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Please explain this in doc.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Right, better to use `then_expression` etc.
Wrap `then` and `else` with ` to make the sentence easier to parse.
Right, better to use `then_expression` etc.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
I would expect a module to issue warnings only for something which the user needs to be warned about. If the user wants something to be absent and it already is absent, that's not something I would expect a warning about. You also don't issue a warning if the user has `state == 'present'` and the sequence is already there.
It would be more general to make this `epochs_since_last_save`, and change the check correspondingly.
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
There's no need to do the 'else', because everything that follows is also your 'else'. It's the continuation of your program.
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
Wrap `then` and `else` with ` to make the sentence easier to parse.
small typo ```suggestion # table availability in check_src/dst. ```
I would expect a module to issue warnings only for something which the user needs to be warned about. If the user wants something to be absent and it already is absent, that's not something I would expect a warning about. You also don't issue a warning if the user has `state == 'present'` and the sequence is already there.
Pass `default` to `_og_search_title` instead.
```suggestion Kwargs: ```
This changes the return message of this function. It's a bit more accurate, but may be worth noting in a changelog in case folks are asserting on msg.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
`current_version` could be mentioned in the error message.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
use `type='int'` here and you won't have to do manual conversion or checking manually
Bravo on tackling one of the gnarlier test setups ;-> :+1:
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
You should be able to use `self.vmware_test_platform` here.
Please remove this example, since I would consider this usage as not recommended.
It seems there is four spaces missing (unrelated to your changes).
You have the 'check_client' function to figure out if the requirements are present, but never actually use it, so the module fails on in import exception. I recommend you place a call in the class init so you dont have to remember to call it in every module.
This branch is never reached.
Prefer `if steps_per_epoch is not None`
Please remove this example, since I would consider this usage as not recommended.
when subfield(`user`) is used multiple times, extract the value into a variable and reuse it.
I'd keep the original style here: ```suggestion version_schema = { Required('removed_in'): deprecation_versions(), } ```
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
this might change in the future, this is not necessary as you're checking for error in response page.
this code is almost the same as the one `VVVVIDIE`, move into a seperate method in base class, and use it in both extractors.
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
I am not sure about option for return_si. But I believe that Service Instance is the object to perform any action on ManagedObjects. If it is required to provide this option then I think it should be True by default.
to be on the safe side and since I don't have access to test on AIX, could you make this conditional on data[1] existing? i.e `len(data) > 1`
I think this should be hostname, since hostname defaults to dest ([line 825](https://github.com/ansible/ansible/pull/14246/files#diff-c2e371537339bbab5d9d0cc5d6cb7adcL825)) if it isn't defined. That way this maintains consistency with the surrounding code. Should hostname be defined, I think it might be confusing. That was my only feedback though, this looks good.
this code is almost the same as the one `VVVVIDIE`, move into a seperate method in base class, and use it in both extractors.
no need to specify required=False or type=str as these are defaults
this code is almost the same as the one `VVVVIDIE`, move into a seperate method in base class, and use it in both extractors.
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
Actually, it's an opposite. It's a check for successful login.
when subfield(`user`) is used multiple times, extract the value into a variable and reuse it.
You have the 'check_client' function to figure out if the requirements are present, but never actually use it, so the module fails on in import exception. I recommend you place a call in the class init so you dont have to remember to call it in every module.
Ah, that makes sense! I forgot about `self.project.up()` also removing them...
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
This will fail if `vidwidth` is missing.
`Current host '%s' can not be %s...`
This will fail if `vidwidth` is missing.
when subfield(`user`) is used multiple times, extract the value into a variable and reuse it.
Don't assign a lambda function, use def
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
Code duplication 173, 213. There is no sense to extract fields explicitly.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
use tags.items() here, no need for iteritems import
You could do the same `';AES256' in fdata` check here as in test_vault_editor.py, and avoid the `re` module.
This is not unicode frienly, see `INVALID_VARIABLE_NAMES` in `lib/ansible/constants.py` , we had to update to allow for unicode chars .. also you should be able to reuse
Basically `os.path.isfile(metadata_filename)` is superfluous here since we control the file lifetime on our own and since we don't delete the file it should exist. This check may only fail if someone touched our file that is unexpected scenario that normally should not happen. In such cases we should stop right at failed `os.remove` rather than skipping such unexpected outcome with this check. If someone touches our files then it's definitely wrong and we should not continue.
This is not unicode frienly, see `INVALID_VARIABLE_NAMES` in `lib/ansible/constants.py` , we had to update to allow for unicode chars .. also you should be able to reuse
`# Returns `
Please fix docstring typos
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
s/if it specified/if specified/
```suggestion # require that the final recorded stack state was ROLLBACK_COMPLETE ```
Can we name `dest` better? I feel like `host_identifier` (or so) might be more readable.
Can we name `dest` better? I feel like `host_identifier` (or so) might be more readable.
This can instead be `continue` and let the `else` unnest.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
`del` is a builtin, not a function. These parens don't have to be here
This can instead be `continue` and let the `else` unnest.
```suggestion for app in sorted(set(apps)): ``` This way, you won't have trouble if apps show up more than once in the list (in which case `is_installed` and `is_outdated` can return wrong information), and the order is still deterministic also for older Python versions.
` or result > 255`
w00t thanks !!
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
If we're just testing broker compatibility I don't think we even need this part of the test.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Since you return above, unnest the `raise` here.
Do this as a oneline instead: `return camel_dict_to_snake.....` no need to assign.
The other unit test failure is due to a difference between `uuid5` on Python 2 and Python 3. In Python 2, `uuid5()` needs `bytes`: ```python def uuid5(namespace, name): """Generate a UUID from the SHA-1 hash of a namespace UUID and a name.""" from hashlib import sha1 hash = sha1(namespace.bytes + name).digest() return UUID(bytes=hash[:16], version=5) ``` In Python 3, it converts to `bytes` so you can pass in `bytes` or text: ```python def uuid5(namespace, name): """Generate a UUID from the SHA-1 hash of a namespace UUID and a name.""" from hashlib import sha1 hash = sha1(namespace.bytes + bytes(name, "utf-8")).digest() return UUID(bytes=hash[:16], version=5) ``` ```suggestion # uuid.uuid5() requires bytes on Python 2 and bytes or text or Python 3 return to_text(uuid.uuid5(uuid_namespace, to_native(string, errors='surrogate_or_strict'))) ```
I would rather see ValueError instead of general exception
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
Here you can simply write: ``` if name_parts: ``` Python considers empty containers to be False-y.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Here you can simply write: ``` if name_parts: ``` Python considers empty containers to be False-y.
Here you can simply write: ``` if name_parts: ``` Python considers empty containers to be False-y.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Adding the exception string to the error would help the user narrow down what the issue is.
Adding the exception string to the error would help the user narrow down what the issue is.
It probably makes sense to test that the exception reason also matches expectations
`current_version` could be mentioned in the error message.
`current_version` could be mentioned in the error message.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
small typo ```suggestion # table availability in check_src/dst. ```
Also, please don't use `\` to break up lines
`del` is a builtin, not a function. These parens don't have to be here
Also, please don't use `\` to break up lines
`current_version` could be mentioned in the error message.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
If it helps, note that every models have a `as_dict` method: https://github.com/Azure/msrest-for-python/wiki/msrest-0.4.12---Serialization-change
My bad. Could you please add this to vmware.py
to_text and u prefix on string.
More relaxed regex.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
Does not match `var IDEC='`.
print can be replaced using sys.exit Except this looks good to me.
Alright, isn't it possible to just catch this case a little bit nicer? I.e. look at `formats` at an opportune moment, and give out a better error message.
Again, path concatenation is not something that would be used much when dealing with Redfish. And in this particular case, we may get invalid path from the concatenation, since `self.manager_uri` can have a trailing `/` (and on most systems I encountered, this is actually true).
If the VLAN exists, you should check the name and state to make sure they are same as requested.
You can just use 'playlist_count'
Again, path concatenation is not something that would be used much when dealing with Redfish. And in this particular case, we may get invalid path from the concatenation, since `self.manager_uri` can have a trailing `/` (and on most systems I encountered, this is actually true).
Move into `_download_json`.
Then use `enumerate()` instead.
We don't really want the response metadata in the returned facts, so this should probably have `['Buckets']` at the end. Edit for clarity: ``` buckets = camel_dict_to_snake_dict(self.connection.list_buckets()['Buckets']) ```
In Postgres almost all integer parameters support units and they are almost always used. I don't ever remember seeing that anyone writes this in bytes, mostly it's a lot harder to read.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
<nod> please open that pr sooner, rather than later (aka, as soon as you are reasonably certain this is the env var name you want.). It is user facing so it would be good to expose the minimal number of people possible to the old name
<nod> please open that pr sooner, rather than later (aka, as soon as you are reasonably certain this is the env var name you want.). It is user facing so it would be good to expose the minimal number of people possible to the old name
you might want to get the module/action as the include can be given a name that does not match `include:`
hi Luke, I see from the code, you query the lock info and try to unlock the adoms upon logging out. however, I don't see any places where lock_adom() is called to lock a domain. if we don't explicitly lock the domain in our plugin, is it required to unlock it every time when the plugin is logging out? + @frankshen01 thanks, Link
So for example, if I didn't specify aws_profile/boto_profile but had the environment variable AWS_PROFILE set, that can be accessed with self.get_option('aws_profile') since aws_profile is the option name: https://github.com/ansible/ansible/blob/devel/lib/ansible/utils/module_docs_fragments/aws_credentials.py#L10.
We have been using sphinx format for docstrings. In sphinx format, this would be: ``` :arg terms: a list of lookups to run. e.g. ['parameter_name', 'parameter_name_too' ] :kwarg variables: ansible variables active at the time of the lookup :kwarg aws_secret_key: One part of AWS credentials :kwarg aws_access_key: The second part of AWS credentials :kwarg aws_security_token: Third part of the AWS credentials :kwarg region: AWS region in which to do the lookup :kwarg bypath: Set to True to do a lookup of variables under a path :kwarg recursive: Set to True to recurse into paths below the path (requires bypath=True) :returns: A list of parameter values or a list of dictionaries if bypath=True. ```
So we tend to not do the else if the previous if-block returns from the function. The else is unneeded.
need to catch BotoCoreError here too.
This one still needs to be swapped.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
This one still needs to be swapped.
Any logic for handling `changed` should be in `_finish_task` instead of here.
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
You don't have to quote this string.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
We really should get rid of the `login_unix_socket` parameter. This parameter is useless, `host` must be used instead ([doc](https://www.postgresql.org/docs/10/static/libpq-connect.html#LIBPQ-CONNECT-HOST)).
`current_version` could be mentioned in the error message.
This layer is commonly used with a positional argument, e.g. `PReLU(0.4)`. This should still work.
This method should be called `verify_file` and is not a private method since it is called from the inventory manager here https://github.com/ansible/ansible/blob/1cf07028d400cd3cef5699c37cadfefb7bbb9532/lib/ansible/inventory/manager.py#L262 You do not need to call it in parse().
Good catch! yeah there should be a warning.
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
```not (foo is None)``` => ```foo is not None```
@tstoner You can just do `if device_info`? same for os_version and os_platform.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
I think this should be 'exit' instead of 'abort'
```not (foo is None)``` => ```foo is not None```
Sorry for the late update, just spotted this (caught me out somewhere else) [fail_json_aws is defined](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/aws/core.py#L191) as `fail_json_aws(self, exception, msg=None):` You can simplify this to ``` module.fail_json_aws(e, msg="Unable to delete user {0}".format(user_name)) ``` Probably worth swapping out most of the fail_json calls for similar fail_json_aws calls too.
Same here. `self.api_client` instead of `client`
~~why stat and return the data when you are dropping it on caller?~~ 2nd caller does use
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_PROFILE') ```
So the suggestion I added above (copied below) works around this, if we add the following change we don't need to add the `ensure_required_libs` function or make any changes to `ensure_libs`. ```suggestion try: ensure_libs(sslrootcert=module.params.get('ca_cert')) except LibraryError as e: module.fail_json(msg=str(e)) ```
This line is too long. Max line length allowed in Ansible is 120 characters.
Another map that can be a list comprehension: ``` content = [x.strip() for x in m.group(3).split(" and ")] ```
Another map that can be a list comprehension: ``` content = [x.strip() for x in m.group(3).split(" and ")] ```
Optimizers have a `get_config` method precisely for this purpose.
Please remove this example, since I would consider this usage as not recommended.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
no, if the variable is set but empty, you should empty out the options
This should be max.
Relax `id` group.
Relax `id` group.
You are missing that it's a metadata provided by a 3dparty and there can by anything. So that you must ensure it's `int` before returning its value in info dict.
should be self.forward.
[Use `utils.qualities` instead](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/npo.py#L123).
Also add a `# Arguments` section for `*args`
Move flags into regex.
I'd probably prefer a single assignment with a conditional only for the argument. It would probably look cleaner this way: ```suggestion is_openbsd = u"OpenBSD" == to_text(platform.system(), errors='surrogate_or_strict') bcrypt_crypt_id = '2b' if is_openbsd else '2a' algorithms['bcrypt'] = algo(crypt_id=bcrypt_crypt_id, salt_size=22, implicit_rounds=None) ```
I'd probably prefer a single assignment with a conditional only for the argument. It would probably look cleaner this way: ```suggestion is_openbsd = u"OpenBSD" == to_text(platform.system(), errors='surrogate_or_strict') bcrypt_crypt_id = '2b' if is_openbsd else '2a' algorithms['bcrypt'] = algo(crypt_id=bcrypt_crypt_id, salt_size=22, implicit_rounds=None) ```
This is pointless message since you don't support login.
Missing `"..."` `set_fact: pubkey_string="{{ pubkeys.results | map(attribute='ansible_facts.pubkey_list') | join('\n') }}"`
same as above. ```python cmd = [self.nmcli_bin, 'con', 'mod'] ```
I know, was just wondering if it's intended that it works that way.
Device id is not escaped.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
You should probably expect unicode strings
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
I would suggest we at least display a message for this exception...
I would suggest we at least display a message for this exception...
I would suggest we at least display a message for this exception...
I would suggest we at least display a message for this exception...
I would suggest we at least display a message for this exception...
~~typo result~~ fixed
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Info. Error: " + to_text(resp_obj))) ```
`**{'Bucket': bucket}` is equivalent to `Bucket=bucket`. Please use the latter :)
Can we print entire error rpc. In case of error `message` alone is not very helpful.
1. This does not work [properly](https://github.com/rg3/youtube-dl/issues/14814). 2. This is ad hoc micro optimization exclusively for pluralsight for reducing number of requests and overall sleeping time while downloading. Remove.
I think that makes me even more concerned. You are saying that the argument spec that ansible will use becomes dynamic based on responses of APIs? I'm pretty sure that's not going to be allowed.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
Breaks if `node_views_class` is `None`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
If I got it right, resourse unpacking happens every time `tr` is called. Have you measured the overhead imposed by this approach? Probably it would be better to unpack it once to temp dir on start and cleanup on exit.
If I got it right, resourse unpacking happens every time `tr` is called. Have you measured the overhead imposed by this approach? Probably it would be better to unpack it once to temp dir on start and cleanup on exit.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Array ellipsis is an obscure feature and not necessary here. It hinders readability
Array ellipsis is an obscure feature and not necessary here. It hinders readability
Array ellipsis is an obscure feature and not necessary here. It hinders readability
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Better to put the activation as the `activation` keyword of the layer below
Don't use this pattern. No try/except block here.
Don't use this pattern. No try/except block here.
Is the match on trailing `\s+title` necessary to avoid false matches? ```suggestion for video_id in re.findall(r'(?is)<div\s[^>]*\bclass\s*=\s*["'.*?\bvideo-item\b.*?["'][^>]*>\s*<a\s[^>]*\bhref\s*=\s*["'](.*?)["']', webpage): ```
Is the match on trailing `\s+title` necessary to avoid false matches? ```suggestion for video_id in re.findall(r'(?is)<div\s[^>]*\bclass\s*=\s*["'.*?\bvideo-item\b.*?["'][^>]*>\s*<a\s[^>]*\bhref\s*=\s*["'](.*?)["']', webpage): ```
This is not used in single video extractor thus should not be here.
This is not used in single video extractor thus should not be here.
This is not used in single video extractor thus should not be here.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
Use `query` for query.
Use `query` for query.
You don't need a lambda here. Also, don't break lines with `\`.
```suggestion if type is not None: ```
Can we use `get_vm` method instead? Since find_vm_by_name finds vm based on VM only.
Pretty hard to read, put the resize on a separate line, not on the `return` line
Pretty hard to read, put the resize on a separate line, not on the `return` line
pass `port` and `validate_certs` as well. Since these details can be different for destination datacenter.
This is still flipped, this will grab the environment var and use it over something a user specifies on the CLI. To pick CLI first, try `self.boto_profile = self.args.boto_profile or os.environ.get('AWS_PROFILE')` then if that fails, the below conditional will try to use the config file.
```suggestion type: str required: True ```
f is already at 0, the `truncate()` is uselesss.
f is already at 0, the `truncate()` is uselesss.
f is already at 0, the `truncate()` is uselesss.
f is already at 0, the `truncate()` is uselesss.
@s-hertel that would be really nice for vanilla pulp ansible installations, which don't currently have token auth.
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
Make this method private and add a docstring explaining its purpose.
Example doesn't serve any purpose.
Example doesn't serve any purpose.
Make this method private and add a docstring explaining its purpose.
Example doesn't serve any purpose.
```suggestion version_added: "2.8" ```
Yes, please remove the return and update the caller.
this could just return ```suggestion return not self._raising ```
Hmm, I think so. If the user specified zero, it probably has a good reason (or should fail if docker doesn't like it).
Looks like `@contextlib.contextmanager` embeds this behavior and this would be enough: ```python @contextlib.contextmanager def timeout(timeout, raising=False): signal.signal(signal.SIGALRM, _raise_timeout) signal.alarm(timeout) try: yield except TimeoutError: if raising: raise finally: signal.signal(signal.SIGALRM, signal.SIG_IGN) ```
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
This can be moved to `check_dict` method.
This can be moved to `check_dict` method.
+1 this isn't used anywhere
```suggestion raise AnsibleParserError("the field '%s' should be a list, but is a %s" % (value, type(value))) ```
```suggestion raise AnsibleParserError("the field '%s' should be a list, but is a %s" % (value, type(value))) ```
Processing of `np_kernel` should be removed from this function
If we're just testing broker compatibility I don't think we even need this part of the test.
I think you should only do this whole `if` if `mode == 'persist_only'`.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
```suggestion if not (season_id and video_id): ```
Note that Kafka only supports kerberos as the SASL mechanism.
Note that Kafka only supports kerberos as the SASL mechanism.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
You can just use 'playlist_count'
I think that code got in by mistake. There is a PR by @rajinisivaram for supporting SASL/PLAIN, but it hasn't been merged yet. Support for SASL in system tests was also contributed by @rajinisivaram and maybe it assumed the presence of the yet unmerged PR.
There should be fallbacks for these values since they are more or less static.
You can just use 'playlist_count'
```suggestion subnet_ids: ``` Snake casing would help with readability of this option.
What's the point combining original and translated lyrics to a single file? There should be 2 separated entries in `subtitles` instead.
You could do the same `';AES256' in fdata` check here as in test_vault_editor.py, and avoid the `re` module.
1. Lack of data is denoted by `None`, not 0. 2. int_or_none.
No need to parametrize with just one case.
```suggestion msg = ' (Note: you must use pymongo >= {0} with MongoDB {1})'.format(loose_srv_requirement, loose_srv_version) ```
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
`validate_certs: no` is less secure and so, we should avoid to use it in our example.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
at this point, just use a playbook
Change to 0.
terms can be a list, not sure if this is being handled correctly
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
Change to 0.
terms can be a list, not sure if this is being handled correctly
Not convinced. Names should already be sensible by construction. What about just `weight.name`.
It's possible to get a `jenkins.JenkinsException: job[your_job] number[1] does not exist` here. Maybe adding a try/catch for this? ```python try: if self.server.get_build_info(self.name, self.build_number)['building']: time.sleep(1) else: return except jenkins.JenkinsException as e: time.sleep(1) ```
`args` is the list of positional arguments passed by the user. It could have any length.
```suggestion if 'no package matched' in to_native(error): ```
Currently IEs are randomly sorted. I guess sorted IE names make `lazy_extractors.py` look better.
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
Currently IEs are randomly sorted. I guess sorted IE names make `lazy_extractors.py` look better.
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Missing space after comma.
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
Should not break if missing.
No need to parametrize with just one case.
Great, this is what I meant by passing the keyword args directly. Nice job.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
don't make unrelated changes.
Incorrect axis naming; use https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L1386 as a reference
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
I think you can get rid of the rstrip('\n') here for the same reason as you got rid of it in _find_bind_mounts() (or alternatively, if rstrip is necessary here, then it's probably still needed in _find_bind_mounts() as well).
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
I think you can get rid of the rstrip('\n') here for the same reason as you got rid of it in _find_bind_mounts() (or alternatively, if rstrip is necessary here, then it's probably still needed in _find_bind_mounts() as well).
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
Just in case it's probably a good idea to use `.get()` instead of dict access syntax in case the key is unset.
Just in case it's probably a good idea to use `.get()` instead of dict access syntax in case the key is unset.
It'd be good to include a default sleep here so this loop doesn't continuously hit the oVirt endpoint. Even just a one or two second sleep would be fine between tries.
Just in case it's probably a good idea to use `.get()` instead of dict access syntax in case the key is unset.
Breaks if `node_views_class` is `None`.
Well, explicit is better than implicit so that it's not misleading ;)
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
default=None is the default
Line is too long.
```suggestion query=dict(type='list', elements='str'), ```
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Having a class for just one test method is unnecessary.
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
Same. The `filter` doesn't make sense to me
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
This would be a nice place to use tuple expansion `action, index = index_of_matching_route(....)`
This would be a nice place to use tuple expansion `action, index = index_of_matching_route(....)`
Download archive behavior must not change, it must only take place after success of the actual download and post processing.
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
No need to use a backslash before the single quotes.
No need to use a backslash before the single quotes.
No need to use a backslash before the single quotes.
self.act_fn => self.activation (unless self.activation is reserved already)
No need to use a backslash before the single quotes.
No need to use a backslash before the single quotes.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Just an empty line, could be removed for cleaner code
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
ð, this is a nice little refactor.
```suggestion Kwargs: ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
the `f.close()` is implied as part of the with block. Also, I don't think this should be in the module since it looks like a debug statement.
small typo ```suggestion # table availability in check_src/dst. ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
Some more: avc2, avc3, avc4. These would be enough.
no need to specify required=False or type=str as these are defaults
no, if the variable is set but empty, you should empty out the options
Missing HostedZoneId here which is important if you want to set a route53 ALIAS record later
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
Update `video_info` and return it directly.
here where you prevent logging with no_syslog, no_log already did the same
here where you prevent logging with no_syslog, no_log already did the same
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
Mandatory data must be accessed with `[]` not `get`.
`expected_status` to `_download_json` instead.
`expected_status` to `_download_json` instead.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
`expected_status` to `_download_json` instead.
1. Single quotes. 2. `expected`.
You can just use 'playlist_count'
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
One last thing I thought of: it may be good to catch `AttributeError` and `ValueError` if an invalid value is passed for `namespace`. Otherwise we get a stacktrace. ```suggestion try: uuid_namespace = uuid.UUID(namespace) except (AttributeError, ValueError) as e: raise AnsibleFilterError("Invalid value '%s' for 'namespace': %s" % (to_native(namespace), to_native(e))) ```
yeah, to_native is the way to do this correctly. Otherwise sooner or later we will end up with UnicodeErrors being thrown. Gotta start somewhere so might as well start with new code.
Why `IOError` or `AttributeError` can happen? I can see only `ValueError` occuring.
As discussed between me, @jborean93, and @abadger, let's just make this `except Exception as err:`
One last thing I thought of: it may be good to catch `AttributeError` and `ValueError` if an invalid value is passed for `namespace`. Otherwise we get a stacktrace. ```suggestion try: uuid_namespace = uuid.UUID(namespace) except (AttributeError, ValueError) as e: raise AnsibleFilterError("Invalid value '%s' for 'namespace': %s" % (to_native(namespace), to_native(e))) ```
`if not check_rc` is not required. It can go in else part
One last thing I thought of: it may be good to catch `AttributeError` and `ValueError` if an invalid value is passed for `namespace`. Otherwise we get a stacktrace. ```suggestion try: uuid_namespace = uuid.UUID(namespace) except (AttributeError, ValueError) as e: raise AnsibleFilterError("Invalid value '%s' for 'namespace': %s" % (to_native(namespace), to_native(e))) ```
we normally use display instead of print
Since this check-in action plugin ensures the prompt is out of `configure` mode, we can use `exit discard` here as it always ensures the prompt is changed to operational mode.
I see - if possible I'd like this in a separate PR because it's not related to IPv6, and has its own bug open already.
Cause it's an **utility function** and it's used in other places you've broken with this change.
This breaks under quite a few circumstances: 1. With `%(episode_number)d` when there is no episode number, etc (gives NA in filename) 2. `%(playlist_index)s` doesnt pad like it does in filename 3. `--autonumber-start`, `--output-na-placeholder` etc won't work etc Generalizing code with `prepare_filename` (splitting out only the sanitization) will avoid these issues
Change to `class Ec2EcsInstance(object):`
It's possible to get a `jenkins.JenkinsException: job[your_job] number[1] does not exist` here. Maybe adding a try/catch for this? ```python try: if self.server.get_build_info(self.name, self.build_number)['building']: time.sleep(1) else: return except jenkins.JenkinsException as e: time.sleep(1) ```
`try_get`, single quotes.
`try_get`, single quotes.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
Just to clarify why this works, jinja sets `__bool__` on `StrictUndefined` to a method that will raise an exception on use: https://github.com/pallets/jinja/blob/a2e83d07a30e1d6f1242993e694f8fdfad1d23f2/src/jinja2/runtime.py#L1093 So this just triggers `Undefined._fail_with_undefined_error` so we get the error raised.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
please note that behavior for non-caught exceptions is to return `None`, so please add another `return False` in the end and maybe replace this one with `pass` or a docstrinig with the explanation.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
This could be moved inside the conditional that follows to avoid checking when there are no vendored modules.
This could be moved inside the conditional that follows to avoid checking when there are no vendored modules.
That's a good point. Just fix the indentation in that part of the code, then.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
Maybe "strides". I had been considering deprecating `subsample` in favor of `strides` in Conv2d, too.
Some more: avc2, avc3, avc4. These would be enough.
heads up, `r` is undefined.
This is actually one reason you want to use `MutableMapping` over subclassing `dict`. `.get()` does not use `.__getitem__()` in `dict`. Both methods duplicate code for performance: ```pycon >>> class VarsWithSources(dict): ... def __getitem__(self, key): ... val = super(VarsWithSources, self).__getitem__(key) ... print(('__getitem__', val)) ... return val ... >>> v = VarsWithSources() >>> v['foo'] = 'bar' >>> v['foo'] ('__getitem__', 'bar') 'bar' >>> v.get('foo') 'bar' ``` Notice that `.get()` doesn't cause the print to happen. As such, your implementation as is will only work with some accesses of keys, and not others.
should be self.forward.
How about change the `get_mgmt_svc_client()` method as ```python def get_mgmt_svc_client(self, client_type, base_url, api_version): client_kwargs = dict(credentials=self.azure_credentials, subscription_id=self.subscription_id, base_url=base_url) if api_version: client_kwargs['api_version'] = api_version client = client_type(**client_kwargs) client.config.add_user_agent(ANSIBLE_USER_AGENT) return client ``` Since we want to construct the client instance in a single entry.
may be cleaner to build the list of methods, iterate on that list to build a list of (cmd,in_data,checkrc) for each method, then iterate over that list when invoking it. something like: ``` python method_names =['sftp'] if scp_if_ssh == 'smart': method_names.append('scp') elif scp_if_ssh: method_names = ['scp'] methods = [] for method_name in method_names: if method_name == 'sftp': methods.append(self._build_sftp_put_command(host, in_path, out_path)) if method_name == 'scp': methods.append(self._build_scp_put_command(host, in_path, out_path)) for cmd, in_data, checkrc, method in methods: (returncode, stdout, stderr) = self._run(cmd, in_data, checkrc) if returncode == 0: return if scp_if_ssh == 'smart': <the display warning/debug code here> # nothing succeeded and returned raise AnsibleError... ```
nit: doc how the output of `iperf` looks like. helps with understanding this code and regex.
nit: doc how the output of `iperf` looks like. helps with understanding this code and regex.
Have you tried ```suggestion monkeypatch.setattr(datetime.datetime, 'now', lambda: TIMESTAMP) ```
Please add `s` for seconds.
```suggestion webpage = self._download_webpage(url, video_id) ```
Please add spaces around the equal sign.
Please add spaces around the equal sign.
Please add spaces around the equal sign.
Please add spaces around the equal sign.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
The formats code should be ordered by format quality: prefering mp4 over webm, for the video it would be: 138 137 248 136 247 ...
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
traditionally, variables is a keyword arg. I don't think it matters in our paticular code base but we should keep it consistent with other lookup plugins.
traditionally, variables is a keyword arg. I don't think it matters in our paticular code base but we should keep it consistent with other lookup plugins.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Can you factorize this over `test_EarlyBaselineStopping_baseline_met`? The codes look a little redundant.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Just an empty line, could be removed for cleaner code
filename should already be a unicode object. Does cgi.parse_header return bytes-like objects? If so a wrapper is necessary.
filename should already be a unicode object. Does cgi.parse_header return bytes-like objects? If so a wrapper is necessary.
Change to 0.
Change to 0.
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
If you use to_text(xxx, errors='surrogate_or_strict') it won't throw exceptions.
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
Similarly, ```if tc['skip'].get('i')```
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
Casting to list isn't needed here ```suggestion elif any(fnmatch.fnmatch(item, pattern) for pattern in ignore_files): ```
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
Casting to list isn't needed here ```suggestion elif any(fnmatch.fnmatch(item, pattern) for pattern in ignore_files): ```
I think we should add an `allow_overwrite` or similar param.
Casting to list isn't needed here ```suggestion elif any(fnmatch.fnmatch(item, pattern) for pattern in ignore_files): ```
Another map that can be a list comprehension: ``` content = [x.strip() for x in m.group(3).split(" and ")] ```
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
@webknjaz we have no gaurantees that the artifacts are being built from a git checkout.
Casting to list isn't needed here ```suggestion elif any(fnmatch.fnmatch(item, pattern) for pattern in ignore_files): ```
like above, no need for security protocol here
last loaded wins, but iirc, we reverse search on handlers list
1. Single quotes. 2. `expected`.
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
Playlist title is optional.
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
Beware that the fourth positional argument has shifted, so if people used this interface using positional arguments it may break. (I don't think there's a risk, as we can safely assume you're the only user of the interface...)
You don't check whether login succeeded or not.
You don't check whether login succeeded or not.
Playlist title is optional.
121, 124 - DRY.
Use `query` for query.
strip_jsonp should work here
Pass `default` to `_og_search_title` instead.
Put `raise` after `if` section at the same indent.
Login should be in `_real_initialize`.
``` python try: webpage = self._download_webpage(request, url) except ExtractorError as e: if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403: raise ExtractorError('%s is not available in your region.' % self.IE_NAME, expected=True) raise ```
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
Pass `default` to `_og_search_title` instead.
You don't check whether login succeeded or not.
I can't think of any reason off the top of my head that we'd need to customize the module object creation, so just having create_module return `None` *should* be fine. IIRC `exec_module` is literally just about populating the module (already created by create_module or the base import machinery) from the code; the 3.x import machinery takes care of the transactional insertion/removal from `sys.modules` on fresh imports and reloads, so we should probably never mess with that in the 3.x loader code at all. It's been awhile, but I think it basically just calls create_module (and does the stock creation if we didn't return something), provisionally inserts the module to `sys.modules`, calls exec_module under an exception handler, and removes the module on an error if it inserted it.
I can't think of any reason off the top of my head that we'd need to customize the module object creation, so just having create_module return `None` *should* be fine. IIRC `exec_module` is literally just about populating the module (already created by create_module or the base import machinery) from the code; the 3.x import machinery takes care of the transactional insertion/removal from `sys.modules` on fresh imports and reloads, so we should probably never mess with that in the 3.x loader code at all. It's been awhile, but I think it basically just calls create_module (and does the stock creation if we didn't return something), provisionally inserts the module to `sys.modules`, calls exec_module under an exception handler, and removes the module on an error if it inserted it.
I can't think of any reason off the top of my head that we'd need to customize the module object creation, so just having create_module return `None` *should* be fine. IIRC `exec_module` is literally just about populating the module (already created by create_module or the base import machinery) from the code; the 3.x import machinery takes care of the transactional insertion/removal from `sys.modules` on fresh imports and reloads, so we should probably never mess with that in the 3.x loader code at all. It's been awhile, but I think it basically just calls create_module (and does the stock creation if we didn't return something), provisionally inserts the module to `sys.modules`, calls exec_module under an exception handler, and removes the module on an error if it inserted it.
I can't think of any reason off the top of my head that we'd need to customize the module object creation, so just having create_module return `None` *should* be fine. IIRC `exec_module` is literally just about populating the module (already created by create_module or the base import machinery) from the code; the 3.x import machinery takes care of the transactional insertion/removal from `sys.modules` on fresh imports and reloads, so we should probably never mess with that in the 3.x loader code at all. It's been awhile, but I think it basically just calls create_module (and does the stock creation if we didn't return something), provisionally inserts the module to `sys.modules`, calls exec_module under an exception handler, and removes the module on an error if it inserted it.
this is not good way to set 'changed', if user does not exist you are erroring out instead of returning 'ok' and `changed=False`
this is not good way to set 'changed', if user does not exist you are erroring out instead of returning 'ok' and `changed=False`
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
```suggestion query=dict(type='list', elements='str'), ```
CI failure due to PEP 8 issue: ``` 2017-02-15 10:09:55 ERROR: PEP 8: lib/ansible/modules/cloud/atomic/atomic_container.py:158:161: E501 line too long (302 > 160 characters) (current) ``` Also, that path value is wrong.
not sure we need this here as we should always be writing to a tmp file
CI failure due to PEP 8 issue: ``` 2017-02-15 10:09:55 ERROR: PEP 8: lib/ansible/modules/cloud/atomic/atomic_container.py:158:161: E501 line too long (302 > 160 characters) (current) ``` Also, that path value is wrong.
CI failure due to PEP 8 issue: ``` 2017-02-15 10:09:55 ERROR: PEP 8: lib/ansible/modules/cloud/atomic/atomic_container.py:158:161: E501 line too long (302 > 160 characters) (current) ``` Also, that path value is wrong.
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
You're right. In that case we should make sure the user does not pass more than 1 positional argument.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
Note, usually, one should check whether something is an instance of an abstractbaseclass instead of dict, list, or other builtin types. For instance: ``` python from ansible.module_utils.common._collections_compat import Mapping [...] if not isinstance(publish_def, Mapping): ```
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Missing space after comma.
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I would remove the emoji here ;o)
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
Lists also have .extend() which might be what you need here
For consistency, use `'` as the quote character
For consistency, use `'` as the quote character
As previously discussed on https://github.com/ansible/ansible/pull/20787 I much prefer os.path.isfile That way it won't try to read a directory path.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
For consistency, use `'` as the quote character
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
No need to parametrize with just one case.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
For consistency, use `'` as the quote character
```suggestion return super(cls, new_cls).__new__(new_cls, *args, **kwargs) ```
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
I think what you've got it good, thanks
You don't need to specify this field if there is no return output
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
`policy` should be added to `argument_spec` to be usable.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
`policy` should be added to `argument_spec` to be usable.
When using pytest, create top-level functions without using a class.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
-1 to ignoring this. There is a simple way to fix this for review process, though... Disable check mode in the argument spec. Then you can fix the module so that check mode does the right thing later.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```suggestion raise AnsibleParserError("the field '%s' should be a list, but is a %s" % (value, type(value))) ```
@wwitzel3 started this pattern. Check mode for tower modules doesn't do anything action-specific. We should track this in another issue.
@wwitzel3 started this pattern. Check mode for tower modules doesn't do anything action-specific. We should track this in another issue.
Wouldn't this end up returning `changed=200` to callers? Usually we keep this a boolean.
@wwitzel3 started this pattern. Check mode for tower modules doesn't do anything action-specific. We should track this in another issue.
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This check is no longer required with AnsibleAWSModule
`list`s have `.append()` method. You probably don't want to re-allocate a new instance on each iteration of the loop.
Wouldn't this end up returning `changed=200` to callers? Usually we keep this a boolean.
This check is no longer required with AnsibleAWSModule
This check is no longer required with AnsibleAWSModule
Note that if all tower modules use this same idiom... Many of those should probably remove claims of check mode support from their arg spec until they implement it as well... But that would definitely be a different PR ;-)
after the change to check the `a` HTML element `class` attribute, this is no longer needed.
```suggestion r'<a[^>]+class="tag-[^"]+"[^>]*>([^<]+)</a>', tag_list ```
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
both are valid tests, i don't see why you need to eliminate the existing one
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
both are valid tests, i don't see why you need to eliminate the existing one
at this point, just use a playbook
I mean, it's a pretty serious inconsistency.
Anytime I reach for map or filter, I like to use a list comprehension of generator exception instead as it is faster and considered more pythonic. ``` python return [p.name for p in q] ```
```suggestion - The name of content library to manage. ```
I guess it a typo? now -> not
1. Single quotes. 2. `expected`.
No direct URLs in tests.
Move data and query into `_download_webpage` call.
Actually, it's an opposite. It's a check for successful login.
`expected_status` to `_download_json` instead.
Actually, it's an opposite. It's a check for successful login.
use `_hidden_inputs` method.
use `self.MAX_FILES` instead of 999999
You are missing that it's a metadata provided by a 3dparty and there can by anything. So that you must ensure it's `int` before returning its value in info dict.
both are valid tests, i don't see why you need to eliminate the existing one
Optimizers have a `get_config` method precisely for this purpose.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
`note` and `errnote` of `_download_json` instead.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Lists also have .extend() which might be what you need here
This isn't ever going to be paginated. [docs](http://boto3.readthedocs.io/en/latest/reference/services/cloudfront.html#CloudFront.Client.create_cloud_front_origin_access_identity)
This breaks under quite a few circumstances: 1. With `%(episode_number)d` when there is no episode number, etc (gives NA in filename) 2. `%(playlist_index)s` doesnt pad like it does in filename 3. `--autonumber-start`, `--output-na-placeholder` etc won't work etc Generalizing code with `prepare_filename` (splitting out only the sanitization) will avoid these issues
These two lines can be made conditional on `threshold != 0.5`
Style: break long lines in the test
I don't believe this parameter should exist. I believe we should rely on the ability for libraries to use environment variables for `http_proxy` and `https_proxy`. Both `ansible.module_utils.urls` and `requests` can both utilize these environment vars. Setting these values via the `environment` keyword on a task is accepted. The module should not have a deviating method for applying proxies.
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
Style: break long lines in the test
so this should not be needed as `become` is defined as a boolean attribute, it is an indication that 'validation' is not happening on the play_context objects, which can lead to many of the same issues for other fields. The proper fix would be to ensure both objects trigger full validation of their attributes.
What about the session token? (That this stuff is hard to do is why `connect_to_aws` was abstracted so early on!)
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Lock Info. Error: " + to_text(resp_obj))) ```
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Lock Info. Error: " + to_text(resp_obj))) ```
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
You can import `try_rm` from helper
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Lock Info. Error: " + to_text(resp_obj))) ```
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Lock Info. Error: " + to_text(resp_obj))) ```
You can import `try_rm` from helper
dont need getattr here, extend/prepend are always part of FAs
dont need getattr here, extend/prepend are always part of FAs
We should try and use single-quotes. There're some inconsistencies in this module but the majority of strings are single-quoted.
We should try and use single-quotes. There're some inconsistencies in this module but the majority of strings are single-quoted.
We should try and use single-quotes. There're some inconsistencies in this module but the majority of strings are single-quoted.
This code is not required anymore (it used to - where did you still find it) - `_real_extract` only gets called when th eURL is suitable, and being suitable is defined as `re.match(self._VALID_URL, url)`.
you need to skip value from parent if include_tasks/include_role, but still inherit
dont need getattr here, extend/prepend are always part of FAs
there is a helper in `AnsibleModule` for mutually exclusive params: ~~~diff module = AnsibleModule( argument_spec=argument_spec, + mutually_exclusive=(('positional_args', 'named_args'),), supports_check_mode=True, ) ~~~
use ```from ansible.module_utils.vmware import get_parent_datacenter```
Remove blank line
`_search_regex` raises a `RegexNotFoundError` if the given pattern is not found. As a result, this checking does not work.
You should probably expect unicode strings
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Move flags into regex.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Move data and query into `_download_webpage` call.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
After taking a look at the new function, I could see leaving the stub function in so that it can establish default values for arg_spec and params.
After taking a look at the new function, I could see leaving the stub function in so that it can establish default values for arg_spec and params.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Technically, you could remove this line, and just use: ``` alias_results, self._legal_inputs = handle_aliases(spec, param) ```
Change to 0.
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
This statement should come afterwards
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
Ah, let me see if I can find an example of mocking run_command.
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
I'd sort the set when showing the error message, to guarantee consistent results for the same package list.
I'd sort the set when showing the error message, to guarantee consistent results for the same package list.
Use `self._parse_html5_media_entries` instead.
Lists also have .extend() which might be what you need here
```suggestion self.templar.available_variables = variables ```
Omit these lines please.
This is actually one reason you want to use `MutableMapping` over subclassing `dict`. `.get()` does not use `.__getitem__()` in `dict`. Both methods duplicate code for performance: ```pycon >>> class VarsWithSources(dict): ... def __getitem__(self, key): ... val = super(VarsWithSources, self).__getitem__(key) ... print(('__getitem__', val)) ... return val ... >>> v = VarsWithSources() >>> v['foo'] = 'bar' >>> v['foo'] ('__getitem__', 'bar') 'bar' >>> v.get('foo') 'bar' ``` Notice that `.get()` doesn't cause the print to happen. As such, your implementation as is will only work with some accesses of keys, and not others.
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
Looks like another weird conditional slipped through, this should be `if location not in ('us-east-1', None):`
fine with me as well. go ahead and push!
Change to 0.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
Get rid of `dim_ordering`, as it isn't doing anything anymore.
nvm, I figured it out
nvm, I figured it out
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
I think you still need `and value` here And while we're at it, I don't really see a reason for validator, as the only one is netconf_port, so one might as well fold that in to this method and make the check `if key == 'netconf_port' and value:` right? (Or if you really want room for more validators, `if not value: continue` followed by checking the key)
I think you still need `and value` here And while we're at it, I don't really see a reason for validator, as the only one is netconf_port, so one might as well fold that in to this method and make the check `if key == 'netconf_port' and value:` right? (Or if you really want room for more validators, `if not value: continue` followed by checking the key)
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
This will fail if `vidwidth` is missing.
This will fail if `vidwidth` is missing.
This will fail if `vidwidth` is missing.
How about having a whitespace after the commas? ```suggestion if not parents else 'dependency of {parents!s}'. format(parents=', '.join(parents)) ```
How about having a whitespace after the commas? ```suggestion if not parents else 'dependency of {parents!s}'. format(parents=', '.join(parents)) ```
This should be supports_check_mode=False.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
A simpler fix is `boto_params[param] = u"{0}".format(value)`
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Use ```room['rtmp_url']``` and ```room['rtmp_live']``` here as [video_url is a mandatory field](https://github.com/rg3/youtube-dl/blob/master/README.md#mandatory-and-optional-metafields)
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
It doesn't make sense to turn a unicode string into a unicode string. It's just `str(str(''))`, which is probably not what you want. Maybe you wanted to turn bytes into text here? In such case check'd be against `binary_type` and the translation should use `to_text()` shim.
Better to add `rank` here
If you check for the folder path here [compile_folder_path_for_obj] (before breaking) you could return the result and ignore all the other strategies.
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
Huh, I haven't the foggiest idea. I didn't do any editing of that content that I recall. Funny that it works. I guess we submit a patch and fix it in the backports? Funny that everything still works. I wish this was all handled in one place...
Better to add `rank` here
Better to add `rank` here
Better to add `rank` here
Better to add `rank` here
Better to add `rank` here
No. In this case the whole new notion of embeddable metadata meta fields should be introduced.
Better to add `rank` here
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
Lots of codes in this method duplicates swfinterp.py. Re-use existing codes instead.
Does the data model / json of the scaleways api ever change? A chained set of accessors like that tends to be a little fragile if the server response change. Could potentially use some defense against that. Afaict, KeyErrors or IndexErrors here would not be caught elsewhere and would cause a fatal error instead of a semi-graceful json_fail.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
This can be converted to return True. No need of new variable retry_request
For the get('organization') request response? I'm assuming the list of 'organizations' and 'users' will always have a single item? (at least as used with a oauth token as used here). Will that depend on the type of api_token? (ie, if there is something like a organization or group level api_key, would the results be different? If so, could be useful to explain in the docs)
Are these put/post/delete/patch/update methods used anywhere? I don't see uses of them.
Lots of codes in this method duplicates swfinterp.py. Re-use existing codes instead.
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
This can be converted to return True. No need of new variable retry_request
syntax error here too.
Tell people where we are looking `CONFIG_FILES`
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
1. Lack of data is denoted by `None`, not 0. 2. int_or_none.
```suggestion out = run_gluster(['volume', 'heal', name, 'info'], environ_update=dict(LANG='C', LC_ALL='C', LC_MESSAGES='C')) ```
You can just `return` without `else`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
The data has to be parsed, and the facts have to be sorted out. Like: * Number of files pending heal. * Number of files to be rebalanced etc based on the data thrown by the heal status. Just dumping the string as is, does not add any value to the facts module. The end user should be able to see particular keys and make any decision. This way, we are shifting the responsibility of parsing the data on the caller.
this module is marked as "legacy" and therefore the CI is not complaining about pep8 here, but it would help if we try to be pep8 compliant.
this looks wrong to me, so the file is changed if it already exists? also you don't compare the contents
yep, that is what I meant, basically make sure new code is pep8 compliant
option should deal with the case the dependencies are not avaiable and give a warning.
this looks wrong to me, so the file is changed if it already exists? also you don't compare the contents
this module is marked as "legacy" and therefore the CI is not complaining about pep8 here, but it would help if we try to be pep8 compliant.
use ```from ansible.module_utils.vmware import get_all_objs```
My bad. Could you please add this to vmware.py
This can be easily detected from m3u8 that's served in `sdUrl` for default youtube-dl UA.
Two line breaks after the first sentence.
Got it. But this is very confusing error message. anyways, not a blocker as such.
Got it. But this is very confusing error message. anyways, not a blocker as such.
use ```from ansible.module_utils.vmware import get_all_objs```
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Same: oneline this since the assignment is unneeded.
use ```from ansible.module_utils.vmware import get_parent_datacenter```
```suggestion error_msg = "Can't find the device based on label, UUID or name. " \ ```
```suggestion error_msg = "Can't find the device based on label, UUID or name. " \ ```
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Same function in `docker_swarm` module. It will be better to create a new module `docker_swarm_common` to assemble common code.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Use [get_bin_path](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/basic.py#L1908) to get path of file
I would rather see ValueError instead of general exception
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Use [get_bin_path](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/basic.py#L1908) to get path of file
Must not be None. Read coding conventions.
Must not be None. Read coding conventions.
I just filed https://github.com/ansible/ansible/issues/34119 which, since you're already making changes to this line, you could address.
I just filed https://github.com/ansible/ansible/issues/34119 which, since you're already making changes to this line, you could address.
need to catch BotoCoreError here too.
assumes native strings in line, you should convert to_native or ensure regex matches 'line' string type
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Can get rid of required=False.
This looks like it is unfortunately not quite this simple. We want the following fallbacks: * If the user specifies a value explicitly in the playbook, use that * If the config file has it, then use that. * If both of those do not have a value, then use the module's defaults. This likely needs changes both here and in the mysql modules themselves. The change here will look something like this (repeat for each of the values we're setting): ``` python if cp an cp.has_section('client'): if module.params['login_host'] is None: module.params['login_host'] = cp.getint('client', 'host', fallback='localhost') [....] ``` Inside of the mysql modules we'll have to change teh module's argument_spec. For instance, mysql_db.py has this: ``` python argument_spec=dict( login_user=dict(default=None), login_password=dict(default=None, no_log=True), login_host=dict(default="localhost"), [...] ``` We would need to change it to this: ``` python argument_spec=dict( login_user=dict(default=None), login_password=dict(default=None, no_log=True), login_host=dict(default=None), [...] ```
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
This has to be done only once, since the binary is always the same (`docker-machine`).
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
If `tags` is the empty string, you will get one `kv_pair` which equals the empty string. That's probably not what you want.
Same here, default parameter is **validate_certs**, the aliases should be removed. We also simplify this by *not* adding `required=False`, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
```suggestion Kwargs: ```
121, 124 - DRY.
I pushed this change in my commit to the code
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
might be nice to fail if they are both provided.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Can we print entire error rpc. In case of error `message` alone is not very helpful.
Can we print entire error rpc. In case of error `message` alone is not very helpful.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
Feel free to ignore me here but `get_*_coverage_files()` is common between python and powershell, you could just have the 1 function and have ``` def _get_coverage_files(language): coverage_dir = ResultType.COVERAGE.path coverage_files = [os.path.join(coverage_dir, f) for f in os.listdir(coverage_dir) if '=coverage.' in f and ('=%s' % language) in f] return coverage_files def get_python_coverage_files(): return _get_coverage_files('python') def get_powershell_coverage_files(): return _get_coverage_files('powershell') ```
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
what will happen if modification of `.git` file fails while `.git/` dir is already moved? I think we could try to roll it back.
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
You don't need to specify this field if there is no return output
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
First 2 references should be formatted as markdown links
```suggestion # just get value from attribute itself as normal ```
`pzuid` does not look to be used anywhere.
`pzuid` does not look to be used anywhere.
`pzuid` does not look to be used anywhere.
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
`**{'Bucket': bucket}` is equivalent to `Bucket=bucket`. Please use the latter :)
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
Or maybe ```suggestion self.default_inventory_hostname = '_'.join(( vm_model['name'], hashlib.sha1(to_bytes(vm_model['id'])).hexdigest()[0:4], )) ```
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
```suggestion self.module.fail_json(msg="The role ID isn't valid %s" % to_native(not_found)) ```
`final_interface = dict((k,str(v)) for k,v in final_interface.iteritems())` seems to be required here since the values from new_interface may contain non-strings while the values returned by the API are always strings. With this added line, the module becomes idempotent with passive proxies.
```suggestion query=dict(type='list', elements='str'), ```
```suggestion self.module.fail_json(msg="The role ID isn't valid %s" % to_native(not_found)) ```
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
I'm really not sure what this is supposed to do. You've proved that `diff` is truthy above, and now you're asserting that whatever object `diff` is is symmetric over `not`, but I'm not sure why. You don't seem to be making any claims about the contents of `diff`, so I don't quite see what the value of this test is.
Line is too long.
Format your docstrings like other docstrings in the codebase
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
0 is technically valid, so this should be `self.prefix_length is not None`
Will never happen since it does not throw if not fatal.
Can you factorize this over `test_EarlyBaselineStopping_baseline_met`? The codes look a little redundant.
Do we need a default case for this, e.g what happens if there is no `db`, `database` or `login_db` set, should we fail? Something like ```suggestion else: module.fail_json(msg="No database parameter set, need one of 'db', 'database' or 'login_db'") ```
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
this still has the #73643 issue, we might want to store the 'raw' notification instead and reprocess handler matching so we always get the 'latest' version of that handler
I wonder if it'd be hard to title-case the matched admonition. They are case insensitive. One can do any of ```rst .. Note:: .. notE:: .. NOTE:: .. NOTe:: ```
And with `\1` you preserve what's matched but I'd argue it should always be normalized to `Note:`.
`xrange` is not defined in Python 3.x
In principle, we can override `>`, `<`, `>=`, and `<=`. The only one we cannot really override is == which cntk has reserved for C++-side object equality so we can write things like ```python if tensor in list_of_tensors: ... ``` This is the reason why we have not introduced infix comparison operators. The risk is someone will use == to mean cntk.equal leading to unexpected behavior, while the benefit is syntactic sugar. For now, we have opted to avoid these surprises.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
If nothing matches `None` will be returned.
This function is quite big, and it does a lot of things. Might be better to split to to smaller functions, like we do in our other modules.
If nothing matches `None` will be returned.
Yeah, I think one squashed commits makes the most sense here.
both are valid tests, i don't see why you need to eliminate the existing one
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
to_text and u prefix on string.
This is not used in single video extractor thus should not be here.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
This is not used in single video extractor thus should not be here.
This is not used in single video extractor thus should not be here.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
I would rather see ValueError instead of general exception
both are valid tests, i don't see why you need to eliminate the existing one
Most of this stuff is included in the config of `super` and thus does not need to figure here.
The same concern exists for Theano with `data_format='channels_first'`. I do not know the extent of the performance hit. My guess is that it is small. I note that [native TF ops](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) use the same kernel shape for both data formats, which indicates that performance optimization can probably be handled at the backend level.
I don't understand this line
Fixed in https://github.com/ansible/ansible/pull/34186
Do not use leading underscore for locals.
The same concern exists for Theano with `data_format='channels_first'`. I do not know the extent of the performance hit. My guess is that it is small. I note that [native TF ops](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) use the same kernel shape for both data formats, which indicates that performance optimization can probably be handled at the backend level.
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
The same concern exists for Theano with `data_format='channels_first'`. I do not know the extent of the performance hit. My guess is that it is small. I note that [native TF ops](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) use the same kernel shape for both data formats, which indicates that performance optimization can probably be handled at the backend level.
Rather than a try/except you could do: `old_port = self.data.get("endpoint", {}).get("port")`
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
It seems like no_log and deprecation are separate things and should be handled in separate functions.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Not sure why we've wrapped here and 1118, decreasing readability, while not wrapping longer lines.
Do note that this only looks at the primary credential cache. This means that if you use a collection credential cache such as DIR, KEYRING or KCM (default in most distributions these days), you might not see a ticket that exists in a non-primary credential cache. Maybe consider using `klist -A`, or try a `kswitch -p <principal>`? The latter is easier to parse, but might break stuff if people are still using the old krb5 APIs (rather than GSSAPI) and were using the primary credential that you just made secondary.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
This seems like it would break passwords with leading/trailing whitespace.
This seems like it would break passwords with leading/trailing whitespace.
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
This seems like it would break passwords with leading/trailing whitespace.
This seems like it would break passwords with leading/trailing whitespace.
This seems like it would break passwords with leading/trailing whitespace.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
```suggestion r'''widgetId:\s+["'](\w+)''', rf_token_js, 'widgetId') ```
cropping, not padding
cropping, not padding
Array ellipsis is an obscure feature and not necessary here. It hinders readability
Array ellipsis is an obscure feature and not necessary here. It hinders readability
cropping, not padding
fixture with load_json
This is not used in single video extractor thus should not be here.
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
At this point it would be fine to have `np_kernel = kernel.eval()`
Get rid of `dim_ordering`, as it isn't doing anything anymore.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Similarly, ```if tc['skip'].get('i')```
What's the point of this? This is an implementation detail and it should not leave any trace if `-k` is used.
These are already in compat as `compat_filter` and `compat_map` [here](https://github.com/ytdl-org/youtube-dl/blob/master/youtube_dl/compat.py#L2970).
These are already in compat as `compat_filter` and `compat_map` [here](https://github.com/ytdl-org/youtube-dl/blob/master/youtube_dl/compat.py#L2970).
You probably don't need `{}` fallback anymore.
No need for this line
Is this try/except necessary? It's a test
There is already `--playlist-reverse`.
Use `train_dataset` and `val_dataset` as the names
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
There is already `--playlist-reverse`.
From Ansible 2.1 onwards (since this is a new module, it will only be in 2.3 and above) we can put this near the top, with the other imports. We can also stop using the wildcard import. So this would be between "import os" and "class OSXService" and read like this: ``` python from ansible.module_utils.basic import AnsibleModule ```
From Ansible 2.1 onwards (since this is a new module, it will only be in 2.3 and above) we can put this near the top, with the other imports. We can also stop using the wildcard import. So this would be between "import os" and "class OSXService" and read like this: ``` python from ansible.module_utils.basic import AnsibleModule ```
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Just assign the correct value to `video_id` later.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Usually we don't use the URL as `video_id`. If `video_id` is unknown yet, it's OK to use part of the URL, for example "a-housecat-a-stray-god-and-a-tail".
Hm... How about then introducing a prefix for such settings at least for this module? So, if user wants to provide binary data to be stored in property, they'd have to say, e.g. 'B64:blah' (where blah would be base64-encoded data). Caveat being that if users wants to store string which starts with B64:, they'd have to do something along the lines of B64:QjY0Og== (QjY0Og== being base64-encoded B64:, I think you get the picture :) Now, truth be told, not sure if this would be more acceptable for Ansible as project, but I'd see it as more consistent. Maybe second opinions on this could be useful too :)
Hm... How about then introducing a prefix for such settings at least for this module? So, if user wants to provide binary data to be stored in property, they'd have to say, e.g. 'B64:blah' (where blah would be base64-encoded data). Caveat being that if users wants to store string which starts with B64:, they'd have to do something along the lines of B64:QjY0Og== (QjY0Og== being base64-encoded B64:, I think you get the picture :) Now, truth be told, not sure if this would be more acceptable for Ansible as project, but I'd see it as more consistent. Maybe second opinions on this could be useful too :)
This statement seems useless.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
You can reuse boto3_tag_list_to_ansible_dict from ansible.module_utils.ec2 instead of doing this.
I meant `from ansible.module_utils.vmware import find_cluster_by_name`
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Optimizers have a `get_config` method precisely for this purpose.
use ```from ansible.module_utils.vmware import get_cluster```
My bad. Could you please add this to vmware.py
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Bravo on tackling one of the gnarlier test setups ;-> :+1:
this might change in the future, this is not necessary as you're checking for error in response page.
```suggestion module.exit_json(changed=True, db=db_name, db_list=db) ``` So behavior is the same as without `check_mode`.
This method isn't necessary.
Using `findall` and processing only first URL then is totally pointless.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Sure, a separate PR sounds good.
Using `findall` and processing only first URL then is totally pointless.
Using `findall` and processing only first URL then is totally pointless.
No need to use `sanitized_Request` request here, pass url directly to download method.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
You have some unmerged lines here
You have some unmerged lines here
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
This is actually one reason you want to use `MutableMapping` over subclassing `dict`. `.get()` does not use `.__getitem__()` in `dict`. Both methods duplicate code for performance: ```pycon >>> class VarsWithSources(dict): ... def __getitem__(self, key): ... val = super(VarsWithSources, self).__getitem__(key) ... print(('__getitem__', val)) ... return val ... >>> v = VarsWithSources() >>> v['foo'] = 'bar' >>> v['foo'] ('__getitem__', 'bar') 'bar' >>> v.get('foo') 'bar' ``` Notice that `.get()` doesn't cause the print to happen. As such, your implementation as is will only work with some accesses of keys, and not others.
This is actually one reason you want to use `MutableMapping` over subclassing `dict`. `.get()` does not use `.__getitem__()` in `dict`. Both methods duplicate code for performance: ```pycon >>> class VarsWithSources(dict): ... def __getitem__(self, key): ... val = super(VarsWithSources, self).__getitem__(key) ... print(('__getitem__', val)) ... return val ... >>> v = VarsWithSources() >>> v['foo'] = 'bar' >>> v['foo'] ('__getitem__', 'bar') 'bar' >>> v.get('foo') 'bar' ``` Notice that `.get()` doesn't cause the print to happen. As such, your implementation as is will only work with some accesses of keys, and not others.
You have some unmerged lines here
Yeah that's probably more defensive given `UserError`, it _could_ be possible, though probably not that likely that there would be some array `[None,'foo', 'bar']`
This should be configurable, because this isn't enough for the work I do with auto scale groups.
I would, really helps people who are new to the concept. When adding a url you would enclose it in `U(https://....)`.
I would, really helps people who are new to the concept. When adding a url you would enclose it in `U(https://....)`.
I would, really helps people who are new to the concept. When adding a url you would enclose it in `U(https://....)`.
If we can't delete the publication for whatever reason, there will be no error and the module will be trapped in a endless recursive loop.
updated or created isn't needed
This URL is now subscriber only. I've managed to find free one: ``` https://shahid.mbc.net/ar/episode/90574/%D8%A7%D9%84%D9%85%D9%84%D9%83-%D8%B9%D8%A8%D8%AF%D8%A7%D9%84%D9%84%D9%87-%D8%A7%D9%84%D8%A5%D9%86%D8%B3%D8%A7%D9%86-%D8%A7%D9%84%D9%85%D9%88%D8%B3%D9%85-1-%D9%83%D9%84%D9%8A%D8%A8-3.html ```
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
I'm pretty sure this can use `is_sequence()`.
this should look like this instead: ``` result = super(ActionModule, self).run(tmp, task_vars) if result.get('skipped', False) or result.get('failed', False): return result ```
Cause it's an **utility function** and it's used in other places you've broken with this change.
This is superfluous, the extension can be extracted automatically.
This is superfluous, the extension can be extracted automatically.
Why not leverage .setdefault here ? ``` kwargs.setdefault('url', os.environ.get('OVIRT_URL')) kwargs.setdefault('username', os.environ.get('OVIRT_USERNAME')) kwargs.setdefault('password', os.environ.get('OVIRT_PASSWORD')) ``` ï¿¼
> Speaking of which, I should submit a PR to add Python 3.5 to tox.ini and .travis.yml #12627.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
I don't think this will work correctly on python2. Pretty sure you need parenthesis there: ``` python except (ConfigParser.NoSectionError, ConfigParser.NoOptionError): ```
`author: Gregory Shulov (@GR360RY)"`
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Why not leverage .setdefault here ? ``` kwargs.setdefault('url', os.environ.get('OVIRT_URL')) kwargs.setdefault('username', os.environ.get('OVIRT_USERNAME')) kwargs.setdefault('password', os.environ.get('OVIRT_PASSWORD')) ``` ï¿¼
Code duplication 173, 213. There is no sense to extract fields explicitly.
For people following at home, we had a talk with privateip, qalthos, bcoca, jimi-c, and myself about this on slack, decided for now to have parameters overriding env vars. We'll discuss this more next week and see if we can push the values somewhere else (perhaps into inventory variables that are set on the connection plugin).
Code duplication 173, 213. There is no sense to extract fields explicitly.
For people following at home, we had a talk with privateip, qalthos, bcoca, jimi-c, and myself about this on slack, decided for now to have parameters overriding env vars. We'll discuss this more next week and see if we can push the values somewhere else (perhaps into inventory variables that are set on the connection plugin).
Code duplication 173, 213. There is no sense to extract fields explicitly.
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
> Speaking of which, I should submit a PR to add Python 3.5 to tox.ini and .travis.yml #12627.
For people following at home, we had a talk with privateip, qalthos, bcoca, jimi-c, and myself about this on slack, decided for now to have parameters overriding env vars. We'll discuss this more next week and see if we can push the values somewhere else (perhaps into inventory variables that are set on the connection plugin).
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
```suggestion assert ansible_json_encoder.default(test_input) == expected ```
`return not owner or owner == publication_info['owner']` could be used.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
`return not owner or owner == publication_info['owner']` could be used.
ERROR rather than BLAH :)
ERROR rather than BLAH :)
ERROR rather than BLAH :)
ERROR rather than BLAH :)
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
I think it's better to use `use_proxy=module.params['use_proxy']` here (and avoid the `use_proxy` property). (In my opinion, `fetch_url()` should use `use_proxy` from `module.params` if not explicitly specified, but that's probably too late to change, or at least too much effort. Moving the source of `use_proxy` as close as possible to the `fetch_url` call is at least making it easier to correct this mistake eventually in the future.)
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
no, if the variable is set but empty, you should empty out the options
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
no, if the variable is set but empty, you should empty out the options
Could you please dedent everything below including this line? There's no point in keeping it inside of context manager block, which _may_ swallow some types of exceptions.
Just an empty line, could be removed for cleaner code
I like it!
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
Not sure if this is the best way to refer to the module... what happens if we don't run nosetests form the right directory? Maybe relative imports are what we want to use here (since the unittest code is python2.6+). I think it's `from ... import swap_stdin_and_argv`)
Tests shouldn't be invoked directly, so this isn't needed.
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
Is this even needed, we will be dropping py2 and `to_text` does not call `__unicode__`. You may as well just put this in `__str__`.
Is this even needed, we will be dropping py2 and `to_text` does not call `__unicode__`. You may as well just put this in `__str__`.
I would add an additional check here to catch syntax errors like `-f 'bestvideo,,best'`. ``` python if not current_selector: raise syntax_error('Expected a selector', start) ```
I would add an additional check here to catch syntax errors like `-f 'bestvideo,,best'`. ``` python if not current_selector: raise syntax_error('Expected a selector', start) ```
filters //= 2
You've forgot to pass `info_dict` to `supports()`.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Name an example URL where `og:description` has HTML tags.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
Name an example URL where `og:description` has HTML tags.
Casting to list isn't needed here ```suggestion elif any(fnmatch.fnmatch(item, pattern) for pattern in ignore_files): ```
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
Why not just pass the target directory? This is all your need to perform this task.
Using `get` is pointless here.
Better to use `determine_ext` instead of `.endswith`
Example doesn't serve any purpose.
``` thumbnail = self._html_search_regex(r"preview_url:\s+'((?:https?:)?//media\.thisvid\.com/.+?\.jpg)',", webpage, 'thumbnail', fatal=False) ```
It'll look more clean if you name these `returncode`, `out`, and `_` (the underscore denotes you're not going to use that, and it's a common pattern in Python). You can also drop the parenthesis, they're not needed
don't use print, display.error or raise an AnsibleError exception, Ansible already does not fail due to an Exception from a callback event.
Use code formatting in the docstring (`) around arguments/etc. Also, please add a bit more information to the docstring so that someone would doesn't know about causal convolutions would understand vaguely what it's about from reading the docstring.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
this is a setting 'resolved' not the definition, you are mixing the concepts here.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
The locale should be set to C if we do string matching.
The locale should be set to C if we do string matching.
The locale should be set to C if we do string matching.
The locale should be set to C if we do string matching.
again, this syntax we should phase out ``` asks_file: "{{ lookup('first_found', files=['tasks.yaml', 'other_tasks.yaml'], errors='ignore') }}" ```
This can be more PEP8 with a '\n': ``` Python class YahooSearchIE(LazyLoadExtractor): _VALID_URL = None _module = 'youtube_dl.extractor.yahoo' @classmethod def suitable(cls, url): return re.match(cls._make_valid_url(), url) is not None @classmethod def _make_valid_url(cls): return 'yvsearch(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' ```
I think either name should be mandatory or this should take a label selector.
```suggestion """Add 'public.' to names of tables where a schema identifier is absent ```
I think either name should be mandatory or this should take a label selector.
It doesn't make sense to turn a unicode string into a unicode string. It's just `str(str(''))`, which is probably not what you want. Maybe you wanted to turn bytes into text here? In such case check'd be against `binary_type` and the translation should use `to_text()` shim.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
```suggestion - UUID of the instance to manage the serial ports, this is VMware's unique identifier. ```
Discussed this with @junrao. The main challenge with this option is having the top level error field for every response. This would probably affect a lot of code: 1. We would need to handle this top level error code everywhere. 2. A bunch of protocols that currently have a top level error code would no longer have them, so a bunch of code would have to be updated as well. So, it doesn't seem appropriate to do this as part of this KIP.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
`return not owner or owner == publication_info['owner']` could be used.
Else part is not necessary since we are initialising `b_passwd` already.
Ah only saw a few lines around the diff in github. Sorry about that.
Ah only saw a few lines around the diff in github. Sorry about that.
Ah only saw a few lines around the diff in github. Sorry about that.
Ah only saw a few lines around the diff in github. Sorry about that.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
Seems like this should either be ```b_missing.append(b_path)``` or ```missing.append(path)```. I don't see missing being compared or combined with any other strings later, so it may be that the latter is fine. Then again, it may be confusing to have a single variable which contains non-byte paths so it might be more readable to use the former.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
I think this should be `_return_if_object` since it isn't part of the public API.
```suggestion out = run_gluster(['volume', 'heal', name, 'info'], environ_update=dict(LANG='C', LC_ALL='C', LC_MESSAGES='C')) ```
check_output is not python2.6 compatible
```suggestion out = run_gluster(['volume', 'heal', name, 'info'], environ_update=dict(LANG='C', LC_ALL='C', LC_MESSAGES='C')) ```
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
The query should be something like ``` G.V().Has('TID', 'bd7f5334-115c-5943-487d-a77c486fa854') ``` according to the `name`
```not (foo is None)``` => ```foo is not None```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
```suggestion Kwargs: ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Great, this is what I meant by passing the keyword args directly. Nice job.
I'd recommend a more explicit import, ie ``` python from ansible.module_utils.basic import AnsibleModule' ``` And using regular imports for 're', 'shlex', 'os', 'json', 'tempfile'
Just noting the second bare except
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
```suggestion Kwargs: ```
Just an empty line, could be removed for cleaner code
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
`, no_log = True`
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
s/write target file {0}/put_file to {0}/
I'd recommend a more explicit import, ie ``` python from ansible.module_utils.basic import AnsibleModule' ``` And using regular imports for 're', 'shlex', 'os', 'json', 'tempfile'
```suggestion for app in sorted(set(apps)): ``` This way, you won't have trouble if apps show up more than once in the list (in which case `is_installed` and `is_outdated` can return wrong information), and the order is still deterministic also for older Python versions.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Breaks if `node_views_class` is `None`.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This condition is not necessary as `aggregate_spec` will never be an empty dictionary.
This condition is not necessary as `aggregate_spec` will never be an empty dictionary.
missing from docs fragment
missing from docs fragment
nvm, I figured it out
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
no, if the variable is set but empty, you should empty out the options
so this assertion looks incorrect, i would expect and empty string as the ssh args
so this assertion looks incorrect, i would expect and empty string as the ssh args
no, if the variable is set but empty, you should empty out the options
Bravo on tackling one of the gnarlier test setups ;-> :+1:
no, if the variable is set but empty, you should empty out the options
Bravo on tackling one of the gnarlier test setups ;-> :+1:
no, if the variable is set but empty, you should empty out the options
so this assertion looks incorrect, i would expect and empty string as the ssh args
Bravo on tackling one of the gnarlier test setups ;-> :+1:
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
so this assertion looks incorrect, i would expect and empty string as the ssh args
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Argh, it's so frustrating that the Elasticache API doesn't return ARNs! This is probably the best way to get user ID though: https://stackoverflow.com/a/10198870/3538079 There is always a chance that a user allowed to use Elasticache isn't allowed to use `rds.describe_db_instances`, so it's best to rely on as few other APIs as possible (I think everyone has permission to run `iam.get_caller_identity`)
Argh, it's so frustrating that the Elasticache API doesn't return ARNs! This is probably the best way to get user ID though: https://stackoverflow.com/a/10198870/3538079 There is always a chance that a user allowed to use Elasticache isn't allowed to use `rds.describe_db_instances`, so it's best to rely on as few other APIs as possible (I think everyone has permission to run `iam.get_caller_identity`)
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
There's still a loop on `format_id` which doesn't seem right: ``` for server, server_json in (try_get(video_player, lambda x: x['video']['servers'], dict) or {}).items(): if not isinstance(server_json, dict): continue for format_id in ('hls', 'dash'): if format_id not in server_json.keys(): continue if format_id == 'hls': formats.extend(self._extract_m3u8_formats( server_json[format_id], lecture_id, 'mp4', entry_protocol='m3u8_native', m3u8_id=format_id, note='Downloading %s m3u8 information' % server_json.get('id', '?') , elif format_id == 'dash': formats.extend(self._extract_mpd_formats( server_json[format_id], lecture_id, mpd_id=format_id, note='Downloading %s MPD manifest' % server_json.get('id', '?'), fatal=False)) self._sort_formats(formats) ... ```
There's still a loop on `format_id` which doesn't seem right: ``` for server, server_json in (try_get(video_player, lambda x: x['video']['servers'], dict) or {}).items(): if not isinstance(server_json, dict): continue for format_id in ('hls', 'dash'): if format_id not in server_json.keys(): continue if format_id == 'hls': formats.extend(self._extract_m3u8_formats( server_json[format_id], lecture_id, 'mp4', entry_protocol='m3u8_native', m3u8_id=format_id, note='Downloading %s m3u8 information' % server_json.get('id', '?') , elif format_id == 'dash': formats.extend(self._extract_mpd_formats( server_json[format_id], lecture_id, mpd_id=format_id, note='Downloading %s MPD manifest' % server_json.get('id', '?'), fatal=False)) self._sort_formats(formats) ... ```
I will leave it to smarter people than I to tell me if this is right.
This file will be kept locally and will not be deleted. It's to reduce amount of API calls during the execution.
And remove this afterwards.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
we really need something generic.... getting complex :-)
You don't need to specify this field if there is no return output
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
This variable is never assigned ```suggestion api.get_collection_versions('namespace', 'collection') ```
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
format and a user provided field is a bit of a security issue `%` notation is better here, but not a showstopper
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
required=False is default so no need to add.
required=False is default so no need to add.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
small typo ```suggestion # table availability in check_src/dst. ```
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
nvm, I figured it out
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
add space after `(w[1])`
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
@hermansje Let's have `on_batch_{ begin | end }` be aliases for `on_train_batch_{begin | end}` like in your original code
@hermansje Let's have `on_batch_{ begin | end }` be aliases for `on_train_batch_{begin | end}` like in your original code
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
Same remark as before regarding `output_shape`.
@bcoca corrected me that _execute_module() takes care of delegation so this is fine. After discussion, though, we did decide that we should set the ansible_pkg_mgr fact when we return from this action plugin so that we don't end up having to discover it every time the actin plugin is run on the same host.
Read coding conventions on optional metadata.
Read coding conventions on optional metadata.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
Read coding conventions on optional metadata.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
Not sure you want to do this if in_data is None
```suggestion query=dict(type='list', elements='str'), ```
```suggestion query=dict(type='list', elements='str'), ```
```suggestion raise ExtractrorError('No episodes returned for program with ID: %s' % program_id, expected=True) ```
I think that should be outside of this method because the value is also recalculated before calling the `_parse_episode_json` method.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
This won't work in case of live HLS WebVTT streams because you constantly get new subtitle segments at the same playlist URL. It's a shame X-TIMESTAMP-MAP support patch hasn't been merged to ffmpeg yet after 3 years, but in my use-case (vlive.tv) it's not required, so dumping HLS WebVTT via ffmpeg works quite good.
This should be removed.
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
Please remove this, `AnsibleModule` already prevents this.
```suggestion type: list entries: str ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
Display should use text strings, will need a to_text in the format and u prefix the string so we don't have any ASCII encoding errors on Python 2.
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Returning would close the file (I think) since you're already in a 'with' statement.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Returning would close the file (I think) since you're already in a 'with' statement.
Missing `=dict` on this and the next few lines
Missing `=dict` on this and the next few lines
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
Missing `=dict` on this and the next few lines
Missing `=dict` on this and the next few lines
Thanks. It turns out that data-brightcove-video-id is a bostonglobe-specific usage, so a dedicated extractor is better.
The following indentation should pass pep8 (with the `==` starting under the `r` in `assert`): ``` assert constants.get_config(cfgparser, 'defaults', 'unknown', 'ANSIBLE_TEST_VAR', '~/local', value_type='path', expand_relative_paths=False) \ == os.path.join(user['home'], 'local') ```
`expected_status` to `_download_json` instead.
`expected_status` to `_download_json` instead.
This line seems to be copy-pasted from `openssl_privatekey` - but this module here doesn't have these parameters.
both are valid tests, i don't see why you need to eliminate the existing one
Needs a check to see if it is empty, and if so, fail the module
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
Raise `AnsibleCallbackError`, which can be imported from `ansible.errors`.
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
i think it would better to put the default value once in the in referer policy processing function.
nit: **It** has no effect if a different TRANSACTION_BOUNDARY_CONFIG is specified.
I wonder if distinguishing like that, with `null` and `empty` pays off. Why not return an empty collection in both cases and simplify the checks on the return values of this method? This method doesn't seem to be the one to use when somebody wants to determine whether a topic exists or not.
the `get_referrer_url` function can return None, there is not point in setting `Referer` to None.
youtube-dl does not use non-browser user agent.
It's better to use the original ```mp3download.action``` URL here as redirected URL may change in the future.
same question around log level as above
same question around log level as above
the `get_referrer_url` function can return None, there is not point in setting `Referer` to None.
the `get_referrer_url` function can return None, there is not point in setting `Referer` to None.
It's better to use the original ```mp3download.action``` URL here as redirected URL may change in the future.
It's better to use the original ```mp3download.action``` URL here as redirected URL may change in the future.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
should be self.forward.
It's better to use the original ```mp3download.action``` URL here as redirected URL may change in the future.
youtube-dl does not use non-browser user agent.
Do you want the first &playlistId=... or the last? Maybe `query['playlistId'][-1]`? Obvs these are probably the same, but the _VALID_URL is capturing the last match, like this: ``` >>> re.match(r'''(?:(?P<pl>pl=\d+)|&)+''', 'pl=1&pl=2').groupdict() {'pl': 'pl=2'} ``` Maybe scrap lines 266-270 and just have `video_id = self._match_id(url)`? Or, ll.266-271 could become: ``` # must return a valid match since it was already tested when selecting the IE matches = re.match(self._VALID_URL, url).groupdict() # id is not enforced in the pattern, so do it now; ditto integration video_id = matches['id'] integration = matches['integration'] ```
Read and follow code conventions. Check code with flake8.
Examples need update to reflect rename
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Please break line into 2, for length ```python if (isinstance(min_value, (int, float)) and isinstance(max_value, (int, float))): ``` (same below)
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
Minor consistency nit- our stuff seems to be using `[action]_[backend]()`, where these aliased imports have that reversed. I'd vote for `[action]_[backend]()` over this- makes the code a little easier to read...
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
Just an empty line, could be removed for cleaner code
@puzan `rabbitmqctl status` doesn't support `vhost`. I run RabbitMQ 3.6.16. As quick fix, I added `add_vhost=True` as default argument to `_exec` to have something like this : ```python def _exec(self, args, run_in_check_mode=False, split_lines=True, add_vhost=True): .... some code here .... if add_vhost: args.insert(1, '-p') args.insert(2, self._vhost) ```
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Adding the exception string to the error would help the user narrow down what the issue is.
Making `name` optional is probably a good idea.
Adding the exception string to the error would help the user narrow down what the issue is.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
No, catch exception.
CI failure due to python 2.4 syntax error: ``` 2017-02-03 01:32:20 Compiling ./lib/ansible/module_utils/cloudera.py ... 2017-02-03 01:32:20 File "./lib/ansible/module_utils/cloudera.py", line 149 2017-02-03 01:32:20 dictionary = { value:key for key,value in dictionary.items() } 2017-02-03 01:32:20 ^ 2017-02-03 01:32:20 SyntaxError: invalid syntax ```
I think it makes sense to fail here instead. (Or return `[]`.)
`, no_log = True`
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
`del` is a builtin, not a function. These parens don't have to be here
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
```suggestion parts = to_native(version.strip()).split(':', 1) ```
Return ``None`` is also valid? ð
This method doesn't seem to do much. I would merge it into the run() method. * read_settings and parse_cli_args don't seem related. They don't operate on the same instance attributes, for instance. * It's a bit funny to have a private method (_read_settings()) calling public methods (read_settings() and parse_cli_args()) that aren't usable by anything else. * If this is merged into run(), it will only add one more line there and will remove 5 lines overall.
This method doesn't seem to do much. I would merge it into the run() method. * read_settings and parse_cli_args don't seem related. They don't operate on the same instance attributes, for instance. * It's a bit funny to have a private method (_read_settings()) calling public methods (read_settings() and parse_cli_args()) that aren't usable by anything else. * If this is merged into run(), it will only add one more line there and will remove 5 lines overall.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
No need to escape `\`.
I'd go for underlining.
No need to escape `\`.
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
This should not be fatal.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Trailing whitespace on a blank line is failing the PEP8 checks.
The Shippable CI failure is due to: ``` 2016-12-19 16:09:41 Run command: python2.4 -m compileall -fq ./lib/ansible/modules/infrastructure/stacki/stacki_host.py 2016-12-19 16:09:41 Compiling ./lib/ansible/modules/infrastructure/stacki/stacki_host.py ... 2016-12-19 16:09:41 File "./lib/ansible/modules/infrastructure/stacki/stacki_host.py", line 174 2016-12-19 16:09:41 rc = stack_r.status_code if stack_r.status_code != 200 else stack_r.status_code 2016-12-19 16:09:41 ^ 2016-12-19 16:09:41 SyntaxError: invalid syntax ``` This may also apply to line 210
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
I don't think we can fail out on this without a deprecation cycle first.
return dict((key, self.get(key)) for key in self.keys())
a leftover here which can be removed
return dict((key, self.get(key)) for key in self.keys())
The Shippable CI failure is due to: ``` 2016-12-19 16:09:41 Run command: python2.4 -m compileall -fq ./lib/ansible/modules/infrastructure/stacki/stacki_host.py 2016-12-19 16:09:41 Compiling ./lib/ansible/modules/infrastructure/stacki/stacki_host.py ... 2016-12-19 16:09:41 File "./lib/ansible/modules/infrastructure/stacki/stacki_host.py", line 174 2016-12-19 16:09:41 rc = stack_r.status_code if stack_r.status_code != 200 else stack_r.status_code 2016-12-19 16:09:41 ^ 2016-12-19 16:09:41 SyntaxError: invalid syntax ``` This may also apply to line 210
Ah never mind, I forgot that the `if response` handles when the recursive URL lookup might have ended.
This does not mean it should not be included.
I'm a bit confused. Is this adding cached related configs to `defaults` section? There are two places setting default values for cache config. I prefer to do default setting in a single place. How about just do it in `CloudInventoryCache`? Besides, it seems the `cache_path` config is not consistent in these two places.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
I don't see the point of this.
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
@samdoran then, I'd say that there's something wrong with the setup and TZ should be adjusted somewhere.
If it is not required, you don't have to add `'required: False`.
Please only import what you need, rather than `*`
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
Please only import what you need, rather than `*`
If it is not required, you don't have to add `'required: False`.
Please only import what you need, rather than `*`
Please only import what you need, rather than `*`
@samdoran then, I'd say that there's something wrong with the setup and TZ should be adjusted somewhere.
I'm not sure this is right, because I don't think that `ansible.module_utils.ansible_tower.HAS_TOWER_CLI` exists in `stable-2.4` It looks to me like you need a mix of the two, something like this: ```diff +import os + +from ansible.module_utils.ansible_tower import tower_argument_spec, tower_auth_config, tower_check_mode + ``` ```diff try: - import os import tower_cli import tower_cli.utils.exceptions as exc from tower_cli.conf import settings - from ansible.module_utils.ansible_tower import tower_auth_config, tower_check_mode - HAS_TOWER_CLI = True except ImportError: HAS_TOWER_CLI = False ```
```suggestion raise ExtractrorError('No episodes returned for program with ID: %s' % program_id, expected=True) ```
This should be relaxed since in most cases there is no need in exact match of dicts or dicts' keys. Moreover some internal, compatibility or autocalculated fields may be placed in original dict. So, `same_keys` feature should be removed completely.
1. Lack of data is denoted by `None`, not 0. 2. int_or_none.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
1. No umask respected. 2. There is no `os.chmod` in python 3.2 according to python [docs](https://docs.python.org/3/library/os.html#os.chmod). 3. flake8.
Use literals rather than constructors. ```suggestion set_commands, delete_commands, invalid_commands = [], [], [] updates, unmanaged_config = [], [] ```
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
Will break if `episode_title` is `None`.
Will break if `episode_title` is `None`.
~Hmm, your first example should not return None values, but empty strings IMO. If you want to assign None-values, you could do that using `null`. And that would be caught by the `required=True`.~ ~So if this is true, that seems to be a bug.~ You are right, YAML interprets no value as None (or null). And I stand corrected. I doubt a lot of modules handle this correctly as None is the default value (which means the parameter was not provided).
You're checking two separate properties here. This should be in a separate test.
You're checking two separate properties here. This should be in a separate test.
Passing `sys.argv[:]` here is useless wrt current implementation. If you look at the `main()`'s first three lines there's: ```python def main(args): ... (options, args) = parser.parse_args() # <-- immediatelly rewrites args variable ``` It looks like the initial implementation has been written by the person with some C-like background, where main accepts args data and returns 0. But in fact in this case it's not needed. Please remove this arg.
These don't appear to be "public" attributes, so we should stay consistent with indicating their privateness by prepending their names with an `_` character.
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
ð, this is a nice little refactor.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
return dict((key, self.get(key)) for key in self.keys())
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
Sorry, it's been some time since I was faced with this issue, thank you for clarifying.
Depending on where in the page the target may be, consider `self._html_search_regex()` which unescapes the returned match (eg, if it contains `&amp;` that should be `&`, or just `&#0049;` that should be `1`).
Line is too long.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
(Additional whitespaceânumber of spaces not multiple of 4.)
You can import `try_rm` from helper
You can import `try_rm` from helper
This change is correct and follows pep8 style guidelines. Indentation does not always have to be an increment of 4 if it aligns with the above structure.
121, 124 - DRY.
Anytime I reach for map or filter, I like to use a list comprehension of generator exception instead as it is faster and considered more pythonic. ``` python return [p.name for p in q] ```
121, 124 - DRY.
f is already at 0, the `truncate()` is uselesss.
Okay I think this makes sense, let's just follow this pattern then.
no, if the variable is set but empty, you should empty out the options
Ah, yes. My mistake. We should probably update _find_accountservice_resource() to save the AccountService URI. But that can be done in a separate PR.
Move on a single line.
Move on a single line.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
All formats should be extracted.
Either `default=''` or, better, let it crash (no default), since nothing else can work if this fails. Otherwise failure leads to a mysterious attempt to append `None` to a `compat_str`.
Just replace the part appended to non source formats with empty string.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
But it looks good overall
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
`six.raise_from(ValueError("Can not parse package name '%s', error: '%s'" % (name_string, to_native(e))), e)`
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
`six.raise_from(ValueError("Can not parse package name '%s', error: '%s'" % (name_string, to_native(e))), e)`
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
small typo ```suggestion # table availability in check_src/dst. ```
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
Do not escape quotes inside triple quotes.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Honestly, I'd change it to some `class CustomTestException(Exception): ...` to avoid any weird corner cases.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
I'm trying to think of a different class name, especially less confusable with `ManageIQAlert`. But I don't have any good suggestion. (this does fit the class naming in existing manageiq modules, matching the module name, but that's not such a good scheme IMHO, no reason to stick to it...)
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
We have an `is_sequence` function which you can get from `from ansible.module_utils.common.collections import is_sequence` that handles this distinction.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
And remove this afterwards.
And remove this afterwards.
small typo ```suggestion # table availability in check_src/dst. ```
Well, the final code is easier to read on a single line, so rather than extending it the result is IMO more readable so worth the effort.
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
Well, the final code is easier to read on a single line, so rather than extending it the result is IMO more readable so worth the effort.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
small typo ```suggestion # table availability in check_src/dst. ```
+1 this isn't used anywhere
+1 this isn't used anywhere
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
`six.raise_from(ValueError("Can not parse package name '%s', error: '%s'" % (name_string, to_native(e))), e)`
I did this so I can deprecate `--get-url` (along with all other --get options). Unless you want to do that too, `urls` field isn't really needed
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
We have an `is_sequence` function which you can get from `from ansible.module_utils.common.collections import is_sequence` that handles this distinction.
Just an empty line, could be removed for cleaner code
and -> or
Theano -> Theano/TensorFlow
A follow up PR that updates all postgres modules to use https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/postgres.py#L42 would be good. No need to block on this. Also that function should be updated to use `module.fail_json(msg=missing_required_lib("psycopg2"))`
A follow up PR that updates all postgres modules to use https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/postgres.py#L42 would be good. No need to block on this. Also that function should be updated to use `module.fail_json(msg=missing_required_lib("psycopg2"))`
A follow up PR that updates all postgres modules to use https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/postgres.py#L42 would be good. No need to block on this. Also that function should be updated to use `module.fail_json(msg=missing_required_lib("psycopg2"))`
Theano -> Theano/TensorFlow
Just an empty line, could be removed for cleaner code
Blank line required before the next section
I'd argue that it's less readable because line is too long now
`six.raise_from(ValueError("Can not parse package name '%s', error: '%s'" % (name_string, to_native(e))), e)`
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
Just an empty line, could be removed for cleaner code
small typo ```suggestion # table availability in check_src/dst. ```
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
I'm trying to think of a different class name, especially less confusable with `ManageIQAlert`. But I don't have any good suggestion. (this does fit the class naming in existing manageiq modules, matching the module name, but that's not such a good scheme IMHO, no reason to stick to it...)
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Better to use `determine_ext` instead of `.endswith`
nit: it will be hard to keep these arguments up-to-date- with those from `AnsibleModule` if they ever change. Perhaps we could just have `*args, **kwargs` here and pass it to the `AnsibleModule` init call. If unsupported params are passed through, the `AnsibleModule` will fail to initialize.
This argument is only accepted in Python 3, it would not work with Python 2.
It isn't a bug (so I'm going to merge this), but I do notice a few things about this list comprehension that I think could be changed. `if altname.strip()` is repeated twice at the end. I think that's probably a typo as it is equivalent to `if altname.strip() and altname.strip()` which is redundant checking. If you don't want to duplicate calling strip() on altname, you can also do that as part of setting altname. For readability, I'd split it up into two lines like this: ``` python altnames = (altname.strip() in str(altnames_ext).split(',')) altnames = [altname for altname in altnames if altname] ``` (Which seems to fit in with the style of this function as the next line further modifies altnames in a third list comprehension/generator expression).
f is already at 0, the `truncate()` is uselesss.
`/`, `:`, `\`, `|`, `<`, `>`, `"`, `?` and `*` are already always stripped.
This makes no sense - you already have it in `url`.
no need to do this check, the plugin never gets called if disabled
from_yaml should do that easily
I think we should add an `allow_overwrite` or similar param.
Looks like merge_list_by_key(), _standardize_value(), and _str_sorted() should be moved to be toplevel functions? (They don't make use of self).
from_yaml should do that easily
from_yaml should do that easily
This breaks under quite a few circumstances: 1. With `%(episode_number)d` when there is no episode number, etc (gives NA in filename) 2. `%(playlist_index)s` doesnt pad like it does in filename 3. `--autonumber-start`, `--output-na-placeholder` etc won't work etc Generalizing code with `prepare_filename` (splitting out only the sanitization) will avoid these issues
Looks like merge_list_by_key(), _standardize_value(), and _str_sorted() should be moved to be toplevel functions? (They don't make use of self).
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
Instead of ignoring these arguments, I would flag them as mutually exclusive (Proposal: https://github.com/ansible/ansible/pull/39809/commits/c984053884c1866b5bf8cd42a01e671352f4142e from #39809).
There's an additional parenthesis: (u'%(title)s **)**
There's an additional parenthesis: (u'%(title)s **)**
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Instead of infinite checking, please cap the amount of time to some (can be long) value. 5 or 10 minutes would be *plenty* for CFN to generate a changeset.
If user don't specify `template_cluster`, and template is not found in `cluster`, we should fallback to global search
If user don't specify `template_cluster`, and template is not found in `cluster`, we should fallback to global search
Prefer consistent using of single quotes when possible.
Prefer consistent using of single quotes when possible.
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
Please introduce line breaks in the docstring to avoid very long lines.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
i don't think we want roles in roles
i don't think we want roles in roles
Unclear why this needed to move upfront, since things like the implicit `Display` setup should have occurred with the implicit entrypoint import already...
Unclear why this needed to move upfront, since things like the implicit `Display` setup should have occurred with the implicit entrypoint import already...
```suggestion pn_admin_session_timeout: ```
That's a really interesting piece of information I did not know.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
Relax regex. Don't match empty string.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
And this `self._cache.set(self.cache_key, {url: ''})`
It would be awesome if buildah supported copying from a container.
Missing `"..."` `set_fact: pubkey_string="{{ pubkeys.results | map(attribute='ansible_facts.pubkey_list') | join('\n') }}"`
This introduces a different race condition, file can now be looked at in 'intermediate' state.
This introduces a different race condition, file can now be looked at in 'intermediate' state.
`return not owner or owner == publication_info['owner']` could be used.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Use dict literals: ```suggestion return {} ```
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
All formats should be extracted.
I realized last night my suggestion to make this an error is inconsistent with how the other sanity tests handle missing requirements. To maintain consistency it should be a warning instead: ```python display.warning("Skipping sanity test '%s' due to missing libyaml support in PyYAML." % self.name) return SanitySkipped(self.name) ``` I still see value in making missing test requirements an error, at least under some circumstances. We'll need to think more about how that should behave, and make sure it's consistent for all the tests.
Just an empty line, could be removed for cleaner code
```suggestion Test that the returned value for timezone consists of only uppercase ```
```suggestion """Add 'public.' to names of tables where a schema identifier is absent ```
Just an empty line, could be removed for cleaner code
Please use a parameterized pytest test instead of this pattern. Example: https://github.com/keras-team/keras/blob/master/tests/keras/layers/convolutional_test.py#L21
Just an empty line, could be removed for cleaner code
Got it. But this is very confusing error message. anyways, not a blocker as such.
Delete this block - this was a specific check for ensuring log output in the test_console_consumer
`wait` should be used if the `Service` is expected to exit naturally based on previous commands: ``` Wait for the service to finish. This only makes sense for tasks with a fixed amount of work to do. For services that generate output, it is only guaranteed to be available after this call returns. ``` You generally do not need to use it in concert with `stop` as `stop` is generally implemented either to synchronously wait (on a clean shutdown via SIGTERM) or kills aggressively enough that you don't actually have to wait (i.e. SIGKILL). I suspect many of the uses of `wait`/`stop` with these `Service` classes are just redundant -- that is rare or non-existent elsewhere. Use of `wait` elsewhere is mostly limited to things like a console producer/consumer that are known to need to consume a limited amount of data.
So if I update some parameter+ change state to running, it won't start, IIUC
falback to a static URL.
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
I'd be expecting some assertion here, like in the follow-up test, otherwise you're just assigning result but never using it.
I was testing this in my threading fact gathering branch, the .get method won't help with 'blocked' processes and will inconsistently return or just hang forever (I'm still trying to get a reliable reproducer). I found this by 'simulating' bad NFS mounts by throttling the traffic to the nfs server the VMs are using.
I think this should have a `raise` after this loop to raise an exception if none of the user-provided hostname preferences match, so we don't add hosts with the hostname `None` which would be the default return.
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
I think this should have a `raise` after this loop to raise an exception if none of the user-provided hostname preferences match, so we don't add hosts with the hostname `None` which would be the default return.
That's all correct code [53-93], do not remove it. Fix `add_m3u8_format` instead.
That's all correct code [53-93], do not remove it. Fix `add_m3u8_format` instead.
Could you please dedent everything below including this line? There's no point in keeping it inside of context manager block, which _may_ swallow some types of exceptions.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Actually, we had some discussions about group names the previous days on IRC. Apparently dashes have been not allowed in group names from Ansible 2.4 on; this hasn't been enforced so far, but now (with Ansible 2.8) it will be. It's still possible to disallow it, but every group with a dash (or other invalid chars) in them will trigger a big fat warning. So please get rid of the dashes here so users of this inventory plugin won't automatically get a list of warnings, even if they don't have invalid chars in their labels.
If you are removing the last user, users_to_add == ['None'], which is truthy so it fails on line 280. Same problem with remove the group "all".
If you are removing the last user, users_to_add == ['None'], which is truthy so it fails on line 280. Same problem with remove the group "all".
CI failure due to missing conditional when calling main: ```python if __name__ == '__main__': main() ```
CI failure due to missing conditional when calling main: ```python if __name__ == '__main__': main() ```
is there a convention for this? I'm wondering if this could be more than binary (present / absent / disabled)
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
Since this is length 1 always, you can use `connection.extend(response['connections'])` for the same result.
Do this as a oneline instead: `return camel_dict_to_snake.....` no need to assign.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
You can change line 263-269 like this: ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ``` and you can do the same in other such places.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
Query should go as `query` to `_download_webpage`.
The argument will already be a character string, no need to decode it.
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
Breaks if `node_views_class` is `None`.
```suggestion rcmd = "%s --sync --info %s" % (pacman_path, realname) ```
please note that behavior for non-caught exceptions is to return `None`, so please add another `return False` in the end and maybe replace this one with `pass` or a docstrinig with the explanation.
Prefix it with `is_` to indicate a boolean check.
This feels wrong because if it matters that we get inventory_hostname when using delegate_to then we wouldn't want to also use inventory_hostname in the non-delegate_to case... that probably means that this happens to make some test cases work but hte real bug is elsewhere (or we shouldn't have inventory_hostname in the else?) Would need to explore this more to understand what's actually happening here.
this could return here? Then the next stanza doesn't need the extra indent level
@pierremahot we'll need a test for this
Please remove this example, since I would consider this usage as not recommended.
Must not be fatal. Do not capture empty string.
Move flags into regex.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
I think this should be replaced with `K.epsilon()`.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Please remove this example, since I would consider this usage as not recommended.
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
```suggestion elif date_string.match(self.when): ```
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
Use the [boto3 exception guidelines](https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-2)
Query should go as `query` to `_download_webpage`.
Query should go as `query` to `_download_webpage`.
Query should go as `query` to `_download_webpage`.
For an info module you will only need the name as this will be the identifier. Please remove the other options
`delete` and `create` are not valid states
User could set `user_data` parameter to `None`, in such case exception still occurs.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Hmm, are security configs really relevant here if we don't do anything with ACLs? Seems like a lot of parameterizations here and we already get coverage from the `test_file_source_and_sink`? In general we've started to be more careful about a ton of parameterizations and covering more within each test since the setup/teardown costs can be quite substantial.
Missing `"..."` `set_fact: pubkey_string="{{ pubkeys.results | map(attribute='ansible_facts.pubkey_list') | join('\n') }}"`
With this simplification, the pythonic way of generating a list is to use list comprehension. You can replace the whole function body with: ```python return [parse_to_obj(r) for r in parse_to_logical_rows(vlan_out)] ```
If `port` is changed to a `list`, you'll need to do this here: ```suggestion ports = module.params['port'] if isinstance(ports, list): ports = ','.join(to_native(x) for x in ports) fullurl = ("%s%s/api/v2/config/serialports?ports=%s" % (protocol, to_native(module.params['cpm_url']), ports)) ```
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
My bad. Could you please add this to vmware.py
use ```from ansible.module_utils.vmware import get_cluster```
Module arg building doesn't take place here. This file packages up a module. It doesn't handle construction of module parameters at all. Action plugins sit in between module arg construction and here.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Nit: add `Cannot be {@code null}.` (maybe somewhere else, too)
This should be `b_output_path` to indicate it is a series of bytes. Even if the caller is sending in bytes, this function should convert it to bytes just like `b_collection_path` at the beginning. That allows our `b_` naming convention to hold, making this code look incorrect (trying to join `bytes` and `str`).
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
The method name with "sane" suggests quite a broad meaning. It's better to be more specific about what that method does. Also, does it need to be a method? I'd have a pure function instead.
fixture with load_json
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
Please break up this line into several
Please break up this line into several
You don't need to specify this field if there is no return output
filters //= 2
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
You don't need to specify this field if there is no return output
Must be numeric.
nit: add a newline here too.
this is already done by argspec when param is defined as boolean, all redundant
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
this is already done by argspec when param is defined as boolean, all redundant
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
does not resolve inheritance https://github.com/ansible/ansible/issues/25097
does not resolve inheritance https://github.com/ansible/ansible/issues/25097
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
This won't skip empty strings.
Thanks for running the experiment, @aknrdureegaesr. I'll open a separate PR to update the version to 2.8 on `devel`.
Thanks for running the experiment, @aknrdureegaesr. I'll open a separate PR to update the version to 2.8 on `devel`.
Just an empty line, could be removed for cleaner code
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
Might be worth validating that zones is a list rather than a single zone provided as a string.
Might be worth validating that zones is a list rather than a single zone provided as a string.
Preference would be for a unit test to be mocked sufficiently that a cleanup like this is not required. However, in this case if that involves a large amount of fragile mocking, I wouldn't worry about it now as having test coverage is better than not having it, even if it is a little messy.
Use single quotes consistently whenever possible. If this is expected error pass `expected=True`.
```suggestion # just get value from attribute itself as normal ```
IMHO this statement is hard to read. Woul rewrite to simple if else and for loop.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
Use single quotes consistently whenever possible. If this is expected error pass `expected=True`.
Use single quotes consistently whenever possible. If this is expected error pass `expected=True`.
Use single quotes consistently whenever possible. If this is expected error pass `expected=True`.
you need to skip value from parent if include_tasks/include_role, but still inherit
~@jborean93 i think you are doing the opposite transformation, you are turning 'seconds/epoch' into a date string~ nvmd, its opposite of what user wanted to implement, but how we can get 'epoch' to work with current module ... took me a bit to square the circle .. moving on ... nothing to see...
please remove the extra space at the start of the line to fix the failing tests
please remove the extra space at the start of the line to fix the failing tests
[Total bitrate is already included as a criterion in format sorting](https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/common.py#L756). If there's no special need, leaving this field blank is fine.
please remove the extra space at the start of the line to fix the failing tests
~@jborean93 i think you are doing the opposite transformation, you are turning 'seconds/epoch' into a date string~ nvmd, its opposite of what user wanted to implement, but how we can get 'epoch' to work with current module ... took me a bit to square the circle .. moving on ... nothing to see...
please remove the extra space at the start of the line to fix the failing tests
See `unified_strdate()` in `utils.py`.
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
no, as i said you would extract the metadata and return immediately.
both are valid tests, i don't see why you need to eliminate the existing one
Same here. `self.api_client` instead of `client`
Same here. `self.api_client` instead of `client`
```suggestion possible_names.extend([context.redirect_list[-1], context.plugin_resolved_name]) ```
I'd probably recommend using six, instead of a try/except dance. ansible ships with six in `ansible.module_utils.six` that can be used here.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
There's a utility method for this; also the regex can be relaxed: ```suggestion playlist_title = self._og_search_title(webpage) return self.playlist_from_matches( re.findall(r'''<a\b[^>]+\bhref\s*=\s*["']/video/([0-9a-z-]+)''', webpage), playlist_id, playlist_title, getter=lambda x: 'https://lumni.fr/video/' + x, ie=LumniIE.ie_key()) ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Could you add at the top of Apply the following line. This will create an ems log event for users with auto support turned on. netapp_utils.ems_log_event("na_ontap_ldap", self.server)
Fix test: ```suggestion 'ext': 'mp4', ```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
This is what `urlencode()` is already doing for you., so the function would be: ```python def encode_url_params(self, params): """Encodes key value pairs for URL""" return '?' + urlencode(params.items())
check_output is not python2.6 compatible
check_output is not python2.6 compatible
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
check_output is not python2.6 compatible
check_output is not python2.6 compatible
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
I wouldn't exactly call a dictionary `list`.
Here, `outdated` is a `dict` (or `list` in mheap/ansible#3).
I wouldn't exactly call a dictionary `list`.
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
I wouldn't exactly call a dictionary `list`.
Here, `outdated` is a `dict` (or `list` in mheap/ansible#3).
Parentheses around `e.message` are useless.
I wouldn't exactly call a dictionary `list`.
I wouldn't exactly call a dictionary `list`.
I wouldn't exactly call a dictionary `list`.
I wouldn't exactly call a dictionary `list`.
I wouldn't exactly call a dictionary `list`.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
You don't need to specify this field if there is no return output
Yeah, a list is fine.
Aren't we losing some good "text" here? Shouldn't probably do more than just `to_native(e)`
f is already at 0, the `truncate()` is uselesss.
<nod> I see what you mean about checking the length for the secret leaking information about the secret that the attacker would not otherwise know. However, checking the length for the plaintext doesn't seem to suffer from that same problem. The attacker already has an idea of how long the plaintext is because the length of the ciphertext will reflect that. So checking the length of the plaintext and falling back to os.urandom() if the plaintext is too short seems like it can prevent some problems without revealing new information? (Hmm... it would reveal that the plaintext is less than a precise value whereas looking at the length of the ciphertext would be more vague.... Would that be important or not?) The attacker can learn a lot about what is in a vault file from external sources... for instance, since they're yaml files, they likely have a rough outline of: ``` --- var: value ``` an attacker might also find the precise name to use for "var" by looking at playbooks to see which variable names exist that are not defined outside of a playbook. So then the only thing about the plaintext that they'd be lacking would be the actual value....
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
`raise_geo_restricted` and specify `countries`.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
I think this should be 'exit' instead of 'abort'
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
Breaks if not arr.
You don't need to specify this field if there is no return output
`User has been created`
Here you pass the variable `label`. You have never defined it, though (you defined `ch_label` -- maybe you meant that one?). That's the first of the sanity checks which fails. You might already get that output by running `flake8` on your module.
`start_time` may be `None` at this point.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
both are valid tests, i don't see why you need to eliminate the existing one
You can just use 'url' in the final dict if there's only one format
do you have an example with TTML subtitles? all the videos that i've tested with has only VTT subtitles.
do you have an example with TTML subtitles? all the videos that i've tested with has only VTT subtitles.
missing from docs fragment
`weights` are part of the base layer kwargs, so it doesn't need to be included in the test. `name` is only included in order to get the test to pass (otherwise the different names would make the configs different). You can remove it, especially since this is not be the proper syntax for this argument (needs a list).
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
I'm not clear on what conditions would trigger this, or what the user's action should be if it did occur.
I don't think it's acceptable to have backend-specific statements if it can be avoided. Also this would fail most of the time because usually the input shape contains `None`.
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
use an args list here instead of a string to avoid problems if the first field if lsdev output is unexpected. for ex: ``` python device_name = field[0] lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) ```
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
parent name also needs to be 'safe'
parent name also needs to be 'safe'
Since these modules are new in 2.4, do you need to add them at all? If this is needed then you can use `removed_in_version`
I don't think this will work correctly on python2. Pretty sure you need parenthesis there: ``` python except (ConfigParser.NoSectionError, ConfigParser.NoOptionError): ```
I don't think this will work correctly on python2. Pretty sure you need parenthesis there: ``` python except (ConfigParser.NoSectionError, ConfigParser.NoOptionError): ```
You should be able to use `self.vmware_test_platform` here.
Not sure what "This one go down into the class tree" means. I know it's from the original method, but see if you can improve this language so it's more clear.
Download archive behavior must not change, it must only take place after success of the actual download and post processing.
You should be able to use `self.vmware_test_platform` here.
You should be able to use `self.vmware_test_platform` here.
You should be able to use `self.vmware_test_platform` here.
`/`, `:`, `\`, `|`, `<`, `>`, `"`, `?` and `*` are already always stripped.
I don't think this will work correctly on python2. Pretty sure you need parenthesis there: ``` python except (ConfigParser.NoSectionError, ConfigParser.NoOptionError): ```
nvm, I figured it out
does this indicate that the module itself is broken? it should be indicated then that the user cannot fix the problem and that a bug should be opened.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Does the check module.run_command() through the transformation into smbios_dict have to be inside of the loop? It seems liks we could do that outside of the loop to be much more efficient.
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
f is already at 0, the `truncate()` is uselesss.
does this indicate that the module itself is broken? it should be indicated then that the user cannot fix the problem and that a bug should be opened.
Same as above: unnecessary fixture test.
f is already at 0, the `truncate()` is uselesss.
you can move it to before `if` as just `docs = {}` line, this should read better.
Why are you looping to all properties? If the need is to support MoRef, then why not add a new field instead of reusing something that is clearly meant for the name (hence `vm.config.name` checked) MoRef can not be changed or managed, it is an internal ID unique within vCenter, and to use it as reference is fine, but i'd never put that value in a `name` field..
Do not assign lambda, use def instead
Do not assign lambda, use def instead
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
can be ignored
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
terms can be a list, not sure if this is being handled correctly
```suggestion r'''widgetId:\s+["'](\w+)''', rf_token_js, 'widgetId') ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
In line with naming conventions in this API, this should be `_num_constants`.
Anyway, removal of `return 0` was not related to the purpose of the PR, but related to my refactoring suggestion. So it fits next to your change :)
No need to re-fetch the template, you can just write: ```python disk_attachments = self._connection.follow_link(template.disk_attachments) ```
Indentation level of `return` statement need to be increased.
`return not owner or owner == publication_info['owner']` could be used.
Second argument should be `video_id`.
`display` won't work in module code, hence this line should be removed
Second argument should be `video_id`.
Second argument should be `video_id`.
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
```suggestion return super(cls, new_cls).__new__(new_cls, *args, **kwargs) ```
```suggestion return super(cls, new_cls).__new__(new_cls, *args, **kwargs) ```
This TODO needs work
You did not test for that thus not catched.
This method is unused and must be removed.
This method is unused and must be removed.
You can import `try_rm` from helper
You can import `try_rm` from helper
I know, was just wondering if it's intended that it works that way.
You can import `try_rm` from helper
last loaded wins, but iirc, we reverse search on handlers list
self.act_fn => self.activation (unless self.activation is reserved already)
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Move to base class.
```suggestion assert ansible_json_encoder.default(test_input) == expected ```
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
It's probably not a good idea to make imports outside of the top of the module. Besides, only the first import will get evaluated while others will just load modules from the cache.
1. Don't shadow outer names. 2. `url_or_none`.
1. Don't shadow outer names. 2. `url_or_none`.
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
Don't re-invent URL parsing. Also, why `sub = sub.replace(';', '&')? ```suggestion parsed_url = compat_urlparse.urlparse(url) qs = compat_parse_qs(parsed_url.query) lang = qs.get('lang', [None])[-1] if not lang: continue ``` A URL query string might in principle have several `lang=xx` elements. The URL is parsed; the query string is returned as a `dict` of `list`s. We assume that, when it only makes sense for a query parameter to have one value, the last one in the list (-1) is meant. In this case it's probably the first as well.
1. Don't shadow outer names. 2. `url_or_none`.
Move flags into regex.
This should not be here as done by downloader.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
Since you assign to underlying private/protected variable, you don't need this public interface for someone external to modify it.
It's in the patch if gave to you. Of course your code works, but this can be handled by other functions to simplify things.
small typo ```suggestion # table availability in check_src/dst. ```
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
Just an empty line, could be removed for cleaner code
Returning would close the file (I think) since you're already in a 'with' statement.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
small typo ```suggestion # table availability in check_src/dst. ```
Given the location where the exception is raised, I don't think you should need to call `_add_host_to_keyed_groups` a second time. In the event of the template error, the group `betsy` should still be created, but without any parent groups, because `{{ location.barn-yard }}` couldn't be evaluated. I think this behavior is ideal. Sometimes, a key will only be present for some hosts, but not others. In that case, you may still want to apply the first level of grouping, but no apply the grandparent group.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Given the location where the exception is raised, I don't think you should need to call `_add_host_to_keyed_groups` a second time. In the event of the template error, the group `betsy` should still be created, but without any parent groups, because `{{ location.barn-yard }}` couldn't be evaluated. I think this behavior is ideal. Sometimes, a key will only be present for some hosts, but not others. In that case, you may still want to apply the first level of grouping, but no apply the grandparent group.
We have been using sphinx format for docstrings. In sphinx format, this would be: ``` :arg terms: a list of lookups to run. e.g. ['parameter_name', 'parameter_name_too' ] :kwarg variables: ansible variables active at the time of the lookup :kwarg aws_secret_key: One part of AWS credentials :kwarg aws_access_key: The second part of AWS credentials :kwarg aws_security_token: Third part of the AWS credentials :kwarg region: AWS region in which to do the lookup :kwarg bypath: Set to True to do a lookup of variables under a path :kwarg recursive: Set to True to recurse into paths below the path (requires bypath=True) :returns: A list of parameter values or a list of dictionaries if bypath=True. ```
In line with naming conventions in this API, this should be `_num_constants`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
`dynamic` is not a very descriptive name. It looks like what you want is to pass the output both to a file and to stdout. In general, this problem has already been solved by `tee`.
This would be a nice place to use tuple expansion `action, index = index_of_matching_route(....)`
`return not owner or owner == publication_info['owner']` could be used.
please add wait_for_vm_ip
The default is `None`, and in the docs no default will be shown. Especially since it is dangerous, I would show to the user explicitly that the default is `false`.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
```suggestion - List of tables in the publication at the end of runtime. ```
```suggestion sample: false ```
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
Sometimes you have a trailing dot (here), sometimes not (previous one). I guess you should pick one style and stick to it :)
tempted to say just use check_opts=True and remove syntax check afterward with remove_option (we do this in ansible-inventory).
Yeah, you'd need `return None, None` at the end of index_of_matching_route()
```suggestion sample: false ```
```suggestion """Add 'public.' to names of tables where a schema identifier is absent ```
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
pythonic style, use: ``` python for i, suffix in enumerate(suffixes): ``` rather than tracking i outside of the loop control.
pythonic style, use: ``` python for i, suffix in enumerate(suffixes): ``` rather than tracking i outside of the loop control.
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
It would be useful to tell the user which `key` is invalid.
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
It would be more general to make this `epochs_since_last_save`, and change the check correspondingly.
But it looks good overall
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
This snippet looks just like one in `role_find`. It probably deserves being moved into a reusable function.
ie this PR is fine, we can look at moving into Core at a later point
ie this PR is fine, we can look at moving into Core at a later point
ie this PR is fine, we can look at moving into Core at a later point
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
It would be awesome if buildah supported copying from a container.
```suggestion error_msg = "Can't find the device based on label, UUID or name. " \ ```
```suggestion error_msg = "Can't find the device based on label, UUID or name. " \ ```
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
This should not be necessary. Instead, a fitting picture out of `thumbnails` should automatically selected. If it's not, we'll fix that.
Okay I think this makes sense, let's just follow this pattern then.
option should deal with the case the dependencies are not avaiable and give a warning.
```suggestion # just get value from attribute itself as normal ```
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
You've already extracted `prgid` and `ch_userid` from URL, you should not additionally rely on these fields in `video_set`.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Could you add at the top of Apply the following line. This will create an ems log event for users with auto support turned on. netapp_utils.ems_log_event("na_ontap_ldap", self.server)
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Could you add at the top of Apply the following line. This will create an ems log event for users with auto support turned on. netapp_utils.ems_log_event("na_ontap_ldap", self.server)
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Same remark as before regarding `output_shape`.
Same remark as before regarding `output_shape`.
`return not owner or owner == publication_info['owner']` could be used.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Similarly, ```if tc['skip'].get('i')```
This is just style but we try to follow standard python naming conventions. So function and method names should be underscore separated like this: ```get_resources```.
This is just style but we try to follow standard python naming conventions. So function and method names should be underscore separated like this: ```get_resources```.
Matching empty string is senseless.
Matching empty string is senseless.
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
`xrange` is not defined in Python 3.x
So, this doesn't verify anymore that user is set, unlike the previous PR, I think that should be corrected.
Matching empty string is senseless.
@s-hertel that would be really nice for vanilla pulp ansible installations, which don't currently have token auth.
+1 it's better to just patch `time.time`
@s-hertel that would be really nice for vanilla pulp ansible installations, which don't currently have token auth.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
```suggestion module.exit_json(changed=True, db=db_name, db_list=db) ``` So behavior is the same as without `check_mode`.
```suggestion module.exit_json(changed=True, db=db_name, db_list=db) ``` So behavior is the same as without `check_mode`.
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
Great, this is what I meant by passing the keyword args directly. Nice job.
You've forgot to pass `info_dict` to `supports()`.
```suggestion return super(cls, new_cls).__new__(new_cls, *args, **kwargs) ```
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
You've forgot to pass `info_dict` to `supports()`.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
The ValueError should be reported in the docstring
i should need neither, only modules should need actual serialization
You can just use 'playlist_count'
1. `preference` is pointless. 2. `fatal=True` is the default. 3. Should be lowercase `hls`.
Use `query` for query.
Move flags into regex.
use `_hidden_inputs` method.
Move flags into regex.
use `_hidden_inputs` method.
`id` should not be optional. No need in trailing `/`.
No need to parametrize with just one case.
> I don't get this sentence. we can say that the storage domain is attached to a DC although it > is not up. What is not UP. The search for the DC is being done using the following search: dc = search_by_attributes(dcs_service, storage=storage_domain.name, status='up') status='up' - We filter the data centers with 'up' status, so you might get an empty DC although oVirt will contain a DC with attached storage domain but not in 'up' status Since you mention that you will use the DC afterwards I suggest to fetch DC without the status filter: dc = search_by_attributes(dcs_service, storage=storage_domain.name) and check if the dc is with 'up' status or not, if it isn't 'up' then we can raise an exception
lets expand this acronym, it took me a second to figure out what dp_rates stood for.
that isn't only issue, many users require specific directories on their remotes for different reasons, this violates 'remote_tmp' configurations, which are normally per user, that is why most of our focus on creating these lock files had to do with the target file and not a common temp dir.
Hm, given those 15(?) other tests that failed on Python 3 in calls to syslog.syslog(), could we monkey-patch the rest of the tests so this is the only test that actually writes to the real syslog/journal? (EDIT: when I say "the rest of the tests", I mean in test_basic.py.)
it might not be relevant in this particular case but be aware to better handle LANG when searching in output. use `module.run_command_environ_update = dict(LANG='C', LC_ALL='C', LC_MESSAGES='C', LC_CTYPE='C')` early after `module` has been instantiated to get that covered.
Okay... We shouldn't let tests drive implementation (unless it's a case where the implementation is more modular, easier to read, or more flexible once it's adapted to the test case). let me take a look at updating the test case.
Hm, given those 15(?) other tests that failed on Python 3 in calls to syslog.syslog(), could we monkey-patch the rest of the tests so this is the only test that actually writes to the real syslog/journal? (EDIT: when I say "the rest of the tests", I mean in test_basic.py.)
it might not be relevant in this particular case but be aware to better handle LANG when searching in output. use `module.run_command_environ_update = dict(LANG='C', LC_ALL='C', LC_MESSAGES='C', LC_CTYPE='C')` early after `module` has been instantiated to get that covered.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
I feel like this should be moved to `else:`
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Usually we use syntaxes like 'soundcloud said: ' but not brackets in error messages.
What is the reason for reordering all these parameters? This breaks `blame` attribution for these lines & doesn't improve the code.
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
Neither the 'title' nor the 'TransferProtocol@Redfish.AllowableValues' properties are required, so these are likely to cause KeyError exceptions. Suggest changing the `for` loop to something like this: ``` for key in actions.keys(): action = actions.get(key) if 'title' in action: title = action['title'] else: title = key result['entries'][title] = action.get( 'TransferProtocol@Redfish.AllowableValues', ["key TransferProtocol@Redfish.AllowableValues not found"] ) ```
Neither the 'title' nor the 'TransferProtocol@Redfish.AllowableValues' properties are required, so these are likely to cause KeyError exceptions. Suggest changing the `for` loop to something like this: ``` for key in actions.keys(): action = actions.get(key) if 'title' in action: title = action['title'] else: title = key result['entries'][title] = action.get( 'TransferProtocol@Redfish.AllowableValues', ["key TransferProtocol@Redfish.AllowableValues not found"] ) ```
Neither the 'title' nor the 'TransferProtocol@Redfish.AllowableValues' properties are required, so these are likely to cause KeyError exceptions. Suggest changing the `for` loop to something like this: ``` for key in actions.keys(): action = actions.get(key) if 'title' in action: title = action['title'] else: title = key result['entries'][title] = action.get( 'TransferProtocol@Redfish.AllowableValues', ["key TransferProtocol@Redfish.AllowableValues not found"] ) ```
Neither the 'title' nor the 'TransferProtocol@Redfish.AllowableValues' properties are required, so these are likely to cause KeyError exceptions. Suggest changing the `for` loop to something like this: ``` for key in actions.keys(): action = actions.get(key) if 'title' in action: title = action['title'] else: title = key result['entries'][title] = action.get( 'TransferProtocol@Redfish.AllowableValues', ["key TransferProtocol@Redfish.AllowableValues not found"] ) ```
same thing here- a strip() for leading spaces in the shebang might be a good idea- less an issue here since it's our code...
Um, this will fail IF the file exists, which doesn't match the message.
Do this as a oneline instead: `return camel_dict_to_snake.....` no need to assign.
We could add a backend method to do it, with custom implementations in each backend...
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
both are valid tests, i don't see why you need to eliminate the existing one
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
suggestion: ```py subtitles = {} for sub in re.findall(r'\bsrc="/w/api\s*(.+?)\s*srt\b', webpage): ... subtitles.setdefault(lang, []).append(...) return { 'url': video_url, ... } ```
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
I know you asked me about this but it might be a good idea to explain that PowerShell unpacks arrays if there's only a single entry so this is a defensive check on that.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
This TODO needs work
```suggestion b_password_string = b"|".join((br'(\w+\'s )?' + to_bytes(p.format(**self._fields))) for p in prompts) ``` `.format` requires splatting the dict, instead of just the dict itself
```suggestion return to_text(uuid.uuid5(uuid_namespace, to_text(string))) ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Just an empty line, could be removed for cleaner code
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
```suggestion query=dict(type='list', elements='str'), ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Actually, it's an opposite. It's a check for successful login.
> Speaking of which, I should submit a PR to add Python 3.5 to tox.ini and .travis.yml #12627.
Second argument should be `video_id`.
`return not owner or owner == publication_info['owner']` could be used.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
`return not owner or owner == publication_info['owner']` could be used.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
Same as https://github.com/ansible/ansible/pull/21849#discussion_r103172035, `timeout` isn't `username`.
In line with naming conventions in this API, this should be `_num_constants`.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
I think some other changes to the config have landed that should certainly eliminate the need for this, in particular the `TowerModule` class.
I think some other changes to the config have landed that should certainly eliminate the need for this, in particular the `TowerModule` class.
You should be using a context manager (`with open(...`) rather than manually opening and closing the file.
We can add this in a second PR. @WojciechowskiPiotr you could also keep this as a branch based on @morph027's with your changes as a new commit, then you can pull and rebase whenever @morph027 adds something, and later (once this PR is merged) create a new PR from your branch. Except, of course, if @morph027 already wants to include TLS support.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#blank-lines): There should be two blank lines before a function.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
We can add this in a second PR. @WojciechowskiPiotr you could also keep this as a branch based on @morph027's with your changes as a new commit, then you can pull and rebase whenever @morph027 adds something, and later (once this PR is merged) create a new PR from your branch. Except, of course, if @morph027 already wants to include TLS support.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I prefer to have a trailing comma everywhere, it makes further diff review easier. ```suggestion 'eos': re.compile(r'^Arista'), ```
Because the longdesc and requirements are read from files, we should still move all of those outside of the toplevel as well. So line 134 on can move into main() (or helper functions of main() if you prefer that).
I'd like a shorter name[1] here, but it looks like self.log and self.debug are taken. self.dl is likely too far. [1] since there will be a lot of `self.debug_logger.debug('foo %s %s', obj1, otherobj)` and `self.debug_logger.exception(e)`
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
Ah, this needs to be set to to `type='path'` so it will be automatically expanded.
I'd like a shorter name[1] here, but it looks like self.log and self.debug are taken. self.dl is likely too far. [1] since there will be a lot of `self.debug_logger.debug('foo %s %s', obj1, otherobj)` and `self.debug_logger.exception(e)`
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
Can we print entire error rpc. In case of error `message` alone is not very helpful.
I don't think we want 2 `elif` statements here. Maybe just `elif any((async_val, poll)):`
If these `,`s are thousands separators, might they be `.`s for some locales (plainly not a decimal point for a count)? ```suggestion view_count = str_to_int(self._html_search_regex( (r'<strong>([\d,.]+)</strong> views', r'Views\s*:\s*<strong>([\d,.]+)</strong>'), webpage, 'view count', fatal=False)) ``` (and `from ..utils import str_to_int` at the top).
self.cache contains function `get_all_objs` which already does this, so we can reuse it directly rather than modifying `find_obj`
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
self.cache contains function `get_all_objs` which already does this, so we can reuse it directly rather than modifying `find_obj`
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
you need to do `get_credentials` even if `profile` is not set (IAM instance profiles mean that neither environment variables, module parameters nor profile contain the keys)
you don't need to say `testcase failed`, it's obvious from testrunner's indication
The second parameter to webpage should not generally be `None` or a generic ID. Instead, pass in an ID of the video.
**Never ever** use `eval` on data you don't control.
you need to do `get_credentials` even if `profile` is not set (IAM instance profiles mean that neither environment variables, module parameters nor profile contain the keys)
Sorry: ``` python while True: try: info_dict['title'] = ... break except ...: trun_len -= 1 ```
Don't do this manually use `_download_webpage_handle`
This change is unrelated, you must open a new PR for it. That's one of the reasons why it's a good idea to use a new branch for each PR.
**Never ever** use `eval` on data you don't control.
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
**Never ever** use `eval` on data you don't control.
**Never ever** use `eval` on data you don't control.
This change is unrelated, you must open a new PR for it. That's one of the reasons why it's a good idea to use a new branch for each PR.
Matching empty string is senseless.
This change is unrelated, you must open a new PR for it. That's one of the reasons why it's a good idea to use a new branch for each PR.
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
This should also be `to_text` from ` ansible.module_utils._text` instead of `str` for python3 compatibility.
Don't do this manually use `_download_webpage_handle`
**Never ever** use `eval` on data you don't control.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
We should avoid lambdas and filters most of the time. Use list comprehensions and generator expressions instead. It's both faster and more pythonic to use those idioms.
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
Blank line required before the next section
The aliases should be available via the standard name. I'm not sure what this function is for ie ```python display_name=dict(type="str", required=False, aliases=["name"]), foo = module.params["display_name"] # foo would be set to the what's passed in as `display_name` or `name` ```
Better to use keyword arguments (same below). API change looks ok to me.
If `name` is an alias of `display_name`, and the user sets `name: xxx`, `params['display_name']` will be `'xxx'`. Ansible does that internally so no module has to do that.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
```suggestion type: list entries: str ```
Why not use a list comprehension here? It's probably more efficient: `return [self.sanitize_keys(i) for i in data]`
Don't shadow built-in names.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Just an empty line, could be removed for cleaner code
This `.close()` isn't needed, the context manager closes the file automatically.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
```suggestion next_page = urljoin( url, next_page and self._search_regex( r'''<a\b[^>]+\bhref\s*=\s*("|')(?P<url>(?:(?!\1).)+)''', next_page, 'next page link', group='url', default=None)) ```
Break the line after the `(` to unify the style across the file.
Break the line after the `(` to unify the style across the file.
Break the line after the `(` to unify the style across the file.
No need to parametrize with just one case.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
use ```from ansible.module_utils.vmware import get_cluster```
I'm totally fine with your explanation and it was just a starting point by my side. And you are right, that the usage in your module in this case is simpler, so no change needed.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Leave the trailing comma. This is explicitly allowed by python in order to make line-modifications (like moving the order of lines, or adding lines) without having to update unrelated lines.
If we don't go with a default regex value, this can just be `None`. ```suggestion filter_re = self._get_value_from_facts('BOOT_TIME_FILTER_REGEX', distribution, None) ```
when you opt-in to using a CM like this, make sure you only patch lines that you really need to patch. and put any assertions outside, whenever possible: ```suggestion assert ret == [] ```
You can avoid inspect with ```python if hasattr(client, 'DEFAULT_PROFILE') ```
Playlist id and title should not be fatal.
Playlist id and title should not be fatal.
Playlist id and title should not be fatal.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Having it upstream would be nice, but I doubt we can change our minimum required Jinja2 version anytime soon.
Up to your decision. But I would rename `updated` to `present` and would make it the default.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This can be more PEP8 with a '\n': ``` Python class YahooSearchIE(LazyLoadExtractor): _VALID_URL = None _module = 'youtube_dl.extractor.yahoo' @classmethod def suitable(cls, url): return re.match(cls._make_valid_url(), url) is not None @classmethod def _make_valid_url(cls): return 'yvsearch(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
`no_log=True` is argument spec will handle this.
`no_log=True` is argument spec will handle this.
small typo ```suggestion # table availability in check_src/dst. ```
`start`/`stop` is flexible since it means `_count/list_valid_files_in_directory` will be agnostic to the validation/training story, and only needs the `split` argument. But it doesn't make a big difference.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
"consumer group management" => "group management" for generality? "When the session timeout expires..." => "when a consumer's heartbeat is not received within the session timeout, the broker will mark the member as failed and rebalance the group".
Please make this method private (unless there is a rationale for making it part of the public API).
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
I'd argue that it'd look cleaner and would better correspond to the fixture name that implies that it returns only the date-related subset of facts.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
```suggestion if not has_migrations: ```
```suggestion if not has_migrations: ```
The locale should be set to C if we do string matching.
I think you want: `wait_until(lambda: self.producer.num_acked == MAX_MESSAGES, ...)` since if you specify `max_messages`, the verifiable producer will produce at most `max_messages` In the current form, I think it is guaranteed to time out
This call on connection object can raise ConnectionError exception which needs to handled here else it will result in stack trace in output. I have raised a https://github.com/ansible/ansible/pull/43353 to fix it for other supported platforms
I think you want: `wait_until(lambda: self.producer.num_acked == MAX_MESSAGES, ...)` since if you specify `max_messages`, the verifiable producer will produce at most `max_messages` In the current form, I think it is guaranteed to time out
I think you want: `wait_until(lambda: self.producer.num_acked == MAX_MESSAGES, ...)` since if you specify `max_messages`, the verifiable producer will produce at most `max_messages` In the current form, I think it is guaranteed to time out
This call on connection object can raise ConnectionError exception which needs to handled here else it will result in stack trace in output. I have raised a https://github.com/ansible/ansible/pull/43353 to fix it for other supported platforms
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
I would write: ```python else: if self.fstype == 'XFS': ... else: ... return out ```
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
67-74 code duplication with mp3 path.
~~1. This won't work for UTF-8.~~ Nevermind, `BaseCookie.__ParseString` does not seem to be capable of UTF-8. 2. This will produce `"None"` string if there is no cookies, i.e. `cookie_header` is `None` that is completely wrong. 3. Also this should only taken place when `cookie_header` is a not a bytestring already.
don't do this by default, set from cli `self._options` does not exist or is None
This does not fix anything.
This block would be a bit more legible, if you checked use_hostnames, then assigned to a temp variable whichever label the user has requested, and then appended that. Something like (pseudopython): ``` this_host = host if not use_hostnames: this_host = ip if frontend: frontends.append(this_host) else: backends.append(this_host) ``` This is admittedly a style thing, but I think it would be more readable/shorten a few lines.
don't do this by default, set from cli `self._options` does not exist or is None
Maybe have it as `default=True`? Imo it won't have any impact on searches using `host_name` and will prevent duplicate responses when using `host_ip` if it has more than one host interface.
Situations where the v6 string in question doesn't actually specify a port, e.g., 2001:db8:0:1 See: ``` def test_parse_ip_host_and_port_v6_with_brackets ```
As above: ```suggestion 'display_id': main_id, ```
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
``` r'itemprop\s*=\s*\"ratingValue\"\s*> ``` ``` r'itemprop\s*=\s*\"ratingValue\"[^>]*> ``` So that the code can live even if new attributes are added to this element Also, there's no need to escape double quotes in strings encapulated by single quotes.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
As above: ```suggestion 'display_id': main_id, ```
``` r'itemprop\s*=\s*\"ratingValue\"\s*> ``` ``` r'itemprop\s*=\s*\"ratingValue\"[^>]*> ``` So that the code can live even if new attributes are added to this element Also, there's no need to escape double quotes in strings encapulated by single quotes.
``` config['depthwise_initializer'] = initializers.serialize( self.depthwise_initializer) ```
Use `'` for strings for consistency with the rest of the file.
Use `'` for strings for consistency with the rest of the file.
I mean, it's a pretty serious inconsistency.
As exclude_tags could be an empty set, I would directly check `if exclude_tags and set(server_tags).intersection(exclude_tags)`. This way, it should also work when exclude_tags and server_tags are empty.
As exclude_tags could be an empty set, I would directly check `if exclude_tags and set(server_tags).intersection(exclude_tags)`. This way, it should also work when exclude_tags and server_tags are empty.
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
In this case, you don't need a generator, just ```suggestion return openvswitch_bridge ```
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
As exclude_tags could be an empty set, I would directly check `if exclude_tags and set(server_tags).intersection(exclude_tags)`. This way, it should also work when exclude_tags and server_tags are empty.
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
As exclude_tags could be an empty set, I would directly check `if exclude_tags and set(server_tags).intersection(exclude_tags)`. This way, it should also work when exclude_tags and server_tags are empty.
I mean, it's a pretty serious inconsistency.
Please add check-mode support (and if possible also diff support).
you can move it to before `if` as just `docs = {}` line, this should read better.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
this should raise an exception telling the user they need the required library
This string concatenation is confusing. It should be on a single line, and preferably be updated to look like: ``` 'AppDescs.AppID=%s' % self.appid, ``` There are other instances of this across codebase.
Updated to use percent formatting
Just add a backslash before `.tbz2`! easy peasy
This does not make any sense.
This does not make any sense.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
Please use 'msg' for returned messages, this is a standardized return value.
should not break the extraction if it wasn't able to parse json data.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Please put these *stdlib* imports above project imports separating sections with an empty line.
should not break the extraction if it wasn't able to parse json data.
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Also need `m/alacarta`: ```suggestion _VALID_URL = r'https?://(?:www\.)?rtve\.es/(?P<kind>(?:playz?|(?:m/)?alacarta)/(?:audios|videos)|filmoteca)/[^/]+/[^/]+/(?P<id>\d+)' ```
Use `self._search_regex` and `utils.unified_strdate` instead.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
nit: conifg -> config (applies elsewhere too)
nit: conifg -> config (applies elsewhere too)
nit: conifg -> config (applies elsewhere too)
nit: conifg -> config (applies elsewhere too)
nit: conifg -> config (applies elsewhere too)
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
```suggestion parts = to_native(version.strip()).split(':', 1) ```
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Use bullet points
This will fail if `self._find_managers_resource` has not been called yet. Method should probably check for the `self.manager_uri` presence and populate it instead of failing with attribute error.
None of the optional metadata should break the extraction.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Lots of codes in this method duplicates swfinterp.py. Re-use existing codes instead.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```suggestion - The content library description. ```
`fd` in name implies "file descriptor", but file-object is more than that. I'd do `module` or `module_file`
```suggestion - The content library description. ```
Please convert this to just a list comprehension: ```suggestion groups = [e.name for e in entities if isinstance(e, Group)] ``` Additionally, just convert to a list of names here, since you only ever need that, and not the object later.
`fd` in name implies "file descriptor", but file-object is more than that. I'd do `module` or `module_file`
Please convert this to just a list comprehension: ```suggestion groups = [e.name for e in entities if isinstance(e, Group)] ``` Additionally, just convert to a list of names here, since you only ever need that, and not the object later.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
I think we are fine with having the property and can do w/o the 'special dict key' which would show in the user's dict definition
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Move flags into regex.
You're checking two separate properties here. This should be in a separate test.
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
As this method is called get_network, we could expect that it return a network device object (or None if not found). Ortherwise we could also rename the method into something like network_exists_by_name.
Oh.... It derives from `unittest.TestCase` which is almost incompatible with pytest..
Oh.... It derives from `unittest.TestCase` which is almost incompatible with pytest..
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Oh.... It derives from `unittest.TestCase` which is almost incompatible with pytest..
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Oh.... It derives from `unittest.TestCase` which is almost incompatible with pytest..
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Oh.... It derives from `unittest.TestCase` which is almost incompatible with pytest..
Oh.... It derives from `unittest.TestCase` which is almost incompatible with pytest..
``` config['depthwise_initializer'] = initializers.serialize( self.depthwise_initializer) ```
``` config['depthwise_initializer'] = initializers.serialize( self.depthwise_initializer) ```
```suggestion query=dict(type='list', elements='str'), ```
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
You've forgot to pass `info_dict` to `supports()`.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
``` config['depthwise_initializer'] = initializers.serialize( self.depthwise_initializer) ```
`start_time` may be `None` at this point.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
Got it. But this is very confusing error message. anyways, not a blocker as such.
I believe the plan is to do a single PR to address this in all Postgres modules
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
should be self.forward.
super nit: the string is slightly malformatted. The script displays: Enter reviewers in the format of "name1 <email1>", "name2 <email2>: Also, Its not clear if I should actually type the quotes when entering reviewers.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Are we doing singleton `__new__`/`__call__` magic internally on some of the callback plugin types? Seems like this would never be `False` otherwise...
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
Unescaped dots. Also `)` may be contained in a string within JSON so matching `[^)]*` may fail.
super nit: the string is slightly malformatted. The script displays: Enter reviewers in the format of "name1 <email1>", "name2 <email2>: Also, Its not clear if I should actually type the quotes when entering reviewers.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Playlist title should not be fatal.
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
```suggestion center = len(modlicense) // 2 ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Just use `replace` or `re.sub`.
It should always return a list.
It should always return a list.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
A message string would good to say that image is not preset or something similar.
Code duplication 173, 213. There is no sense to extract fields explicitly.
A message string would good to say that image is not preset or something similar.
Code duplication 173, 213. There is no sense to extract fields explicitly.
A message string would good to say that image is not preset or something similar.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Looks like this `flat_list` generation only needs to be done once, so could move up outside the `playlist_dict` loop.
Looks like this `flat_list` generation only needs to be done once, so could move up outside the `playlist_dict` loop.
Looks like this `flat_list` generation only needs to be done once, so could move up outside the `playlist_dict` loop.
Looks like this `flat_list` generation only needs to be done once, so could move up outside the `playlist_dict` loop.
Similarly, ```if tc['skip'].get('i')```
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
New unit tests should be written using pytest style instead of unittest. The biggest difference being the use of functions and fixtures instead of classes.
Use `self._search_regex` and `utils.unified_strdate` instead.
Use `self._search_regex` and `utils.unified_strdate` instead.
var is a reserved keyword, use `v` or something like that.
What kind of values are valid here? I would expect this to be `float` based on the `0.0` in the description.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
var is a reserved keyword, use `v` or something like that.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
We should be able to merge the two cases with something like this? ``` if collections is None and collection_from_task: collections = [collection_from_task] ``` Now `collections` is either the non-None contents of `collections`, or the task's collection, or `None` if neither exist, which means we can drop the `collections` check from the `all()`s and just use `collections` regardless
We should be able to merge the two cases with something like this? ``` if collections is None and collection_from_task: collections = [collection_from_task] ``` Now `collections` is either the non-None contents of `collections`, or the task's collection, or `None` if neither exist, which means we can drop the `collections` check from the `all()`s and just use `collections` regardless
PEP8 issues (space around operators)
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I would prefer this to be a configurable default. End users have a strong tendency to relocate packages without asking vendors first.
Returning would close the file (I think) since you're already in a 'with' statement.
This line is too long. Max line length allowed in Ansible is 120 characters.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Returning would close the file (I think) since you're already in a 'with' statement.
This line is too long. Max line length allowed in Ansible is 120 characters.
f is already at 0, the `truncate()` is uselesss.
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
If nothing matches `None` will be returned.
If nothing matches `None` will be returned.
Yes, please remove the return and update the caller.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Sometimes response is None so this doesn't work
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Lack of data is denoted by `None` not 0.
Move inside a loop.
Breaks. Read coding conventions.
This divides the input into halves of size output_dim/2 that are then concatenated. The size of the output might not be output_dim anymore (eg: python(13/2) = 6; 6+6=12).
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
Maybe "strides". I had been considering deprecating `subsample` in favor of `strides` in Conv2d, too.
You don't need `+` to do string concatenation across two consecutive lines
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
I know, was just wondering if it's intended that it works that way.
```suggestion possible_names.extend([context.redirect_list[-1], context.plugin_resolved_name]) ```
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
You can remove this `module.exit_json` since the one on line 219 can be used.
Hmm, this doesn't seem great.
```suggestion query=dict(type='list', elements='str'), ```
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Optimizers have a `get_config` method precisely for this purpose.
You seem to have gone through the process of making this class a context manager, but don't use it as a context manager.
Optimizers have a `get_config` method precisely for this purpose.
```suggestion query=dict(type='list', elements='str'), ```
This is not used in single video extractor thus should not be here.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
i would add the aliases to the options in this way: option1 (alias1, alias2), option2 (alias1, .... Or simpler to direct them to `ansible-doc -l <module name>` for 'valid options', specially if you consider 'sub options'
i would add the aliases to the options in this way: option1 (alias1, alias2), option2 (alias1, .... Or simpler to direct them to `ansible-doc -l <module name>` for 'valid options', specially if you consider 'sub options'
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
No. Passwords should be retrieved at the time of usage, see `_get_login_info`.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
ignore_errors doesn't normally cover unreachable
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
You are not tracking timeout per child with this code. The time you're recording here is when you ask the library to queue the work.... It's not when the work starts. Therefore, you might as well save a single general timeout at the top of the method.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
I'm not fully sure what this is yet, but I would recommend renaming this function, as it is likely to cause confusion for devs/user due to ansible already calling something an "argument_spec"
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
I think that makes me even more concerned. You are saying that the argument spec that ansible will use becomes dynamic based on responses of APIs? I'm pretty sure that's not going to be allowed.
I think the signature of exec_command has changed in v2. If you take a look at local.py or the ConnectionBase class you'll see: ``` python def exec_command(self, cmd, tmp_path, in_data=None, sudoable=True): ```
```suggestion Kwargs: ```
Please add a docstring.
```suggestion - This boolean converts the variable into an actual 'fact' which will also be added to the fact cache. It does not enable fact caching across runs, it just means it will work with it if already enabled. ```
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
For compatibility we ask folks to use `.items()` since it works in Python 2.4 up to Python 3.x. If you _must_ use iteritems please use `six.iteritems()`.
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
It's inconsistency, so it's not ok.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Valid ISO 3166-1 code for Sweden is `se`.
this check is not needed, the default is `False` if you should never get a `None` at this point
i would add the aliases to the options in this way: option1 (alias1, alias2), option2 (alias1, .... Or simpler to direct them to `ansible-doc -l <module name>` for 'valid options', specially if you consider 'sub options'
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
`validate_config` call is missing
`, no_log = True`
Please remove this, `AnsibleModule` already prevents this.
The leading underscore in the '_meta' key is missing here.
You seem to have gone through the process of making this class a context manager, but don't use it as a context manager.
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
Are you able to expand on this a bit further, you should state that when it is true and the database does not match the config, then it is deleted and recreated.
i would add the aliases to the options in this way: option1 (alias1, alias2), option2 (alias1, .... Or simpler to direct them to `ansible-doc -l <module name>` for 'valid options', specially if you consider 'sub options'
ignore_errors doesn't normally cover unreachable
The only thing I want to do is to logout when the execution is complete or failed. I believe both __del__ and __exit__ are being called and to avoid having duplicate logout calls I just ended up doing it in __del__ (line 507)
The only thing I want to do is to logout when the execution is complete or failed. I believe both __del__ and __exit__ are being called and to avoid having duplicate logout calls I just ended up doing it in __del__ (line 507)
No. Passwords should be retrieved at the time of usage, see `_get_login_info`.
small typo ```suggestion # table availability in check_src/dst. ```
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Code duplication 173, 213. There is no sense to extract fields explicitly.
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
~take no_log from task~ nvmd, task failed to template ...
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
Code duplication 173, 213. There is no sense to extract fields explicitly.
I would split these ('install' and 'install --offline -p -r etc') into two separate tests so any failures are more specific and granular.
Code duplication 173, 213. There is no sense to extract fields explicitly.
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
maybe just one warning line? ``` python varname_conflicts = varnames.intersection(_RESERVED_NAMES) if varname_conflicts: display.warning('Found variables using reserved names: %s' % ','.join(sorted(varname_conflicts))) ``` Or is the one warning per var so that the warning duplicate detector catches them? If it is for warning de-duping, should each play get a fresh set of warnings or just one globally for each varname? (ie, include the play info in the warning msg...)
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
```suggestion query=dict(type='list', elements='str'), ```
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
```suggestion possible_names.extend([context.redirect_list[-1], context.plugin_resolved_name]) ```
Code duplication 173, 213. There is no sense to extract fields explicitly.
If `air_start` is `None`, the message should be `Coming soon!` instead of `Coming soon! None`.
Don't use bare `except:`
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
No. You should not shadow the original explicitly provided password.
Break up long line
Playlist metadata must not be fatal.
This is not used in single video extractor thus should not be here.
You seem to have gone through the process of making this class a context manager, but don't use it as a context manager.
You seem to have gone through the process of making this class a context manager, but don't use it as a context manager.
You are not tracking timeout per child with this code. The time you're recording here is when you ask the library to queue the work.... It's not when the work starts. Therefore, you might as well save a single general timeout at the top of the method.
You don't need start with this code as it will be virtually the same for all the things launched by apply_async in your loop. You can just use a single scalar local variable to hold the value. (It also is the end time or max time (and maxtime is really max_timeout), not start). Adding that together with the note that we should probably process statvfs information separate from the uuid info: ``` python results[mount] = {'info': mount_info, 'statvfs': pool.apply_async(get_mount_size, (mount_info['mount'],)), 'uuid': uuids.get(mount_info['device']) or pool.apply_async(self._udevadm_uuid, (mount_info['device'],)),} max_time = time.time() + max_timeout ```
Optimizers have a `get_config` method precisely for this purpose.
No. Passwords should be retrieved at the time of usage, see `_get_login_info`.
There is no point to use `remove_start` since line is always a string.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
You seem to have gone through the process of making this class a context manager, but don't use it as a context manager.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
There is no point to use `remove_start` since line is always a string.
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
Code duplication 173, 213. There is no sense to extract fields explicitly.
May be true but this is general speaking. What behavior specific changes would you expect? Can we possibly test against those? I don't think it is meaningful to duplicate code in n modules when using OOP style.
You can use [`ensure_libs`](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/postgres.py#L42).
```suggestion query=dict(type='list', elements='str'), ```
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
I realize this was in the original file, but it can be simplified as well: ```suggestion sys.exit(main(sys.argv)) ```
I realize this was in the original file, but it can be simplified as well: ```suggestion sys.exit(main(sys.argv)) ```
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Anyway, removal of `return 0` was not related to the purpose of the PR, but related to my refactoring suggestion. So it fits next to your change :)
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
Now it makes sense.. in this case it looks like it needs to happen in `_get_paths()` instead of or in addition to `all()`: ideally the globs would happen only once and remain cached while the lookup path remains unchanged, but that's a bunch more work than the original PR. Happy to abandon this for now, unless someone else is volunteering :)
Won't work. See how this is done for output template.
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
This line is too long. Max line length allowed in Ansible is 120 characters.
This line is too long. Max line length allowed in Ansible is 120 characters.
Just an empty line, could be removed for cleaner code
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
so this assertion looks incorrect, i would expect and empty string as the ssh args
Adding the exception string to the error would help the user narrow down what the issue is.
Adding the exception string to the error would help the user narrow down what the issue is.
This line is too long. Max line length allowed in Ansible is 120 characters.
Single quotes. `item` is already a string.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
return dict((key, self.get(key)) for key in self.keys())
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
This one will fail with the new to_unicode. With no arguments, this will return `"None"``(the equivalent of``str(none)`` ). If we want the test to return None, then update like this: ``` python none = ansible.utils.unicode.to_unicode(None, nonstring=passthru) ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
so this assertion looks incorrect, i would expect and empty string as the ssh args
This won't work in case of live HLS WebVTT streams because you constantly get new subtitle segments at the same playlist URL. It's a shame X-TIMESTAMP-MAP support patch hasn't been merged to ffmpeg yet after 3 years, but in my use-case (vlive.tv) it's not required, so dumping HLS WebVTT via ffmpeg works quite good.
Omit expected type.
It might be better to use `base64.b64encode()` here as that function does not append an extra `\n`
So, this doesn't verify anymore that user is set, unlike the previous PR, I think that should be corrected.
convention for the name of the first argument of a classmethod is "cls". If the parameter isn't used at all, make it a @staticmethod instead and remove the parameter altogether.
Throwing a exception do not seems like great UX for users.
`format_id` should be meaningful and not the same for every format.
Also pass `m3u8_id='hls'`.
`format_id` should be meaningful and not the same for every format.
More relaxed regex.
Also pass `m3u8_id='hls'`.
`format_id` should be meaningful and not the same for every format.
You should be able to use `self.vmware_test_platform` here.
is_map should be done using global re 'MAP_RE' so we have one way to identify map in a column value.
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
```suggestion from ansible.module_utils._text import to_native ... module.fail_json(msg='Vexata API access failed: {0}'.format(to_native(e))) ```
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
just don't know exactly what's in the properties :-)
`if not check_rc` is not required. It can go in else part
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
1. Single quotes. 2. `expected`.
`acodec == 'none'`.
1. Single quotes. 2. `expected`.
I would prefer mimic the original nova.cz player's behavior instead of letting rtmpdump to parse the URL as it may not always work.
Isn't `raise` missing there ? Calls to `str` are useless.
`acodec == 'none'`.
1. Single quotes. 2. `expected`.
I would prefer mimic the original nova.cz player's behavior instead of letting rtmpdump to parse the URL as it may not always work.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
1. Single quotes. 2. `expected`.
Please remove this example, since I would consider this usage as not recommended.
`acodec == 'none'`.
return dict((key, self.get(key)) for key in self.keys())
`(byte_counter / rate_limit) - elapsed` sometimes takes negative values (tested on python2). Negative delay to `sleep` results in `IOError` and failed download. There should be at least a check for that.
I mentioned an idea below (well, more like restated your own) of introducing a prefix for base64-encoded data, so user can easily mark those as such. So maybe that'd sort this part out too.
This can be simplified to `[None] * 5` or `(None, ) * 5`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Please raise a `NotIplementedError` when the use case is not supported yet.
Doesn't exist in yt-dl, but is easy to add.
What happens if I pass in a harmful string like `"(injection=__import__('os').listdir('.'))"`? Perhaps the identifier string should just be parsed for k,v pairs, using `set` or `setattr`.
Same, please rename
Use `assert_allclose`` instead
It could be just plain `return not ...startswith...`
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Add a sample dict returned by module.
it should also check if it can write there
This TODO needs work
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
`<script>.*` this part does not play a roll in the regex, may be change to `<script[^>]*>\s*(var\s*)?`. Split Long lines(longer than 80 columns). ```suggestion hydration_data = self._search_regex( r'<script>.*hydrationData\s*=\s*({.+?})\s*</script>', webpage, 'hydration data', default='{}') ```
This line is too long. Max line length allowed in Ansible is 120 characters.
I'd go for underlining.
Wrong key. Again breaks if no such key.
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
1. Single quotes. 2. `expected`.
1. Single quotes. 2. `expected`.
Wrong key. Again breaks if no such key.
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
Won't this just get the contents of the first page? I think you need to flatten this out by extending all `contents` to one list.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
`\s` not ` `.
Won't this just get the contents of the first page? I think you need to flatten this out by extending all `contents` to one list.
All these fields should be `fatal=False`.
Code duplication. Keep the original `_write_thumbnails` code and generalize item part. `param_name` is a bad name for something that describes an item's kind.
Instead of `get_config` twice in the module, how about reusing the existing `get_config` result from https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/network/nxos/nxos_facts.py#L290. In order to reuse you can define a function in FactsBase class that runs get_config and stores the result to a global variable maybe https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/network/nxos/nxos_facts.py#L181.
Code duplication. Keep the original `_write_thumbnails` code and generalize item part. `param_name` is a bad name for something that describes an item's kind.
It would be easier if RPM and DEB were to give the same structured reply, or having an agnostic module would not be very useful (in cases like "if upstream version is greater than x.y"). Comparing versions is a complex operation and there is no filter around `dpkg --compare-versions`. Also having the full version (epoch+upstream+release, following the standard distro notation) along with the upstream version would be useful I think.
`if not self.argspec_cache:` allows you to have a single return, not blocker, just seems cleaner
`if not self.argspec_cache:` allows you to have a single return, not blocker, just seems cleaner
If we're just testing broker compatibility I don't think we even need this part of the test.
Sure, a separate PR sounds good.
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
`no_log=True` is argument spec will handle this.
cc @rajinisivaram I'm not sure we should have this here - i.e., a unit test failure isn't particularly helpful if SHA1PRNG is unavailable (since the user may be fine with the null default).
Might want to change to `HAS_HEROKU` to match other Ansible modules code.
This syntax is not supported in python2.6. You will need to index your format like {0}
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
When using pytest, create top-level functions without using a class.
Sure, a separate PR sounds good.
terms can be a list, not sure if this is being handled correctly
That's something we should fix in the Keras backend.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
imports not needed.
`RETURN = r''' # '''`
There should be fallbacks for these values since they are more or less static.
This should not be fatal.
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
`expected_status` to `_download_json` instead.
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
You are later multiplying with a float. This has no effect on the output
Must return info dict.
All debug code must be removed.
As `title` is a mandatory field, you could use`video_data['clipTitle']`.
As `title` is a mandatory field, you could use`video_data['clipTitle']`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
This should not run in check mode and should we actually be doing this. Deleting a database because a change needs to occur seems to be pretty extreme and would have thought you would want a flag to set whether to do so like the container instances module.
Should this be updated to elif when using ci mode? ```suggestion elif state == 'present': ```
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
> Does that seem more helpful? If this error was to actually happen, it would mean that what the API returns has changed beyond what we expect. When the happens, I think all the user can do is report an issue here. there is a generic option to do this(`--dump-pages`), and we would ask to the user to use this option if needed. > Is it typical practice to say in error messages "report this error to youtube-dl"? If so I can add that as well. you can do that, by removing `expected=True` from the options passed to `ExtractorError`,
`return not owner or owner == publication_info['owner']` could be used.
Please remove this example, since I would consider this usage as not recommended.
And remove this afterwards.
`return not owner or owner == publication_info['owner']` could be used.
You want `changed` to be `True` here if *at least* one DB was created, not if *all* DBs in `non_existence_list` were created (and there has been at least one).
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
we already had similar warnings, the controller code will cut them as 'non json output from module' , it would be better to add to a 'warnings' field in the json output
we already had similar warnings, the controller code will cut them as 'non json output from module' , it would be better to add to a 'warnings' field in the json output
we already had similar warnings, the controller code will cut them as 'non json output from module' , it would be better to add to a 'warnings' field in the json output
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
This is covered by `assert self.hostA != other` ```suggestion ```
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
I don't think it's acceptable to have backend-specific statements if it can be avoided. Also this would fail most of the time because usually the input shape contains `None`.
We could add a backend method to do it, with custom implementations in each backend...
We could add a backend method to do it, with custom implementations in each backend...
We could add a backend method to do it, with custom implementations in each backend...
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I don't think it's acceptable to have backend-specific statements if it can be avoided. Also this would fail most of the time because usually the input shape contains `None`.
C/P error, should be `AWS ElastiCache is down`? Same on L450
C/P error, should be `AWS ElastiCache is down`? Same on L450
If you use `to_text(xxx, errors='surrogate_or_strict')` it won't throw exceptions.
`delete` and `create` are not valid states
probably inside the `if` instead of before since it's kind of confusing to see this for a test that isn't going to actually read the DLQ
`delete` and `create` are not valid states
I might suggest use `conn.shell.has_trailing_slash` and `conn.shell.join_path` like the copy module for any path manipulations on `dest`.
You should be able to use `self.vmware_test_platform` here.
You should be able to use `self.vmware_test_platform` here.
Return is not compulsory but will help end user to understand return value of module.
Please raise a `NotIplementedError` when the use case is not supported yet.
`autonumber` is not reset to zero in the first place.
instead of 'starting connection' here we might want to 'reserve socket path', to create it if it doesn't exist and to 'touch it' if it does (making a-connection timeout reset so we avoid a race condition)
In that case, we'd also better drop it, otherwise we'll get idempotency problems...
tempted to say just use check_opts=True and remove syntax check afterward with remove_option (we do this in ansible-inventory).
`(byte_counter / rate_limit) - elapsed` sometimes takes negative values (tested on python2). Negative delay to `sleep` results in `IOError` and failed download. There should be at least a check for that.
New person will be confused when you refer to `msg`, adding a brief description will help.
Please put the new parameters on a new line
Duration calculation is incorrect.
`autonumber` is not reset to zero in the first place.
Technically these are not protocols. I'm aware we are using some of them in `protocol` metafield in info dict but still I'd prefer diffrerent wording. Moreover I'd prefer something even more generic like `--skip-extraction-steps` with comma separated value list of possible values: `m3u8`, `f4m`, `mpd`, `smil`, `metadata` etc. (possibly even extractor-specific ones). This would allow to fine-tune the extraction not to download unnecessary data and minimize network I/O.
Return is not compulsory but will help end user to understand return value of module.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
If `display.verbosity` is falsy, this results in `python anisble_connection '' <pid> <uuid>` and the extra parameter isn't understood to be intended as a flag. I think this (and the above change to verbosity) should fix the issue? ```suggestion [python, ansible_connection, *verbosity, to_text(os.getppid()), to_text(task_uuid)], ```
`delete` and `create` are not valid states
If `display.verbosity` is falsy, this results in `python anisble_connection '' <pid> <uuid>` and the extra parameter isn't understood to be intended as a flag. I think this (and the above change to verbosity) should fix the issue? ```suggestion [python, ansible_connection, *verbosity, to_text(os.getppid()), to_text(task_uuid)], ```
`delete` and `create` are not valid states
Do we need to both consumer_properties and client_prop_file_override? maybe we can just use client_prop_file_override
`delete` and `create` are not valid states
tempted to say just use check_opts=True and remove syntax check afterward with remove_option (we do this in ansible-inventory).
Hmm, that could improve it a bit. It will be still a bit complex, though :) (Also, never underestimate users which will specify something which doesn't make sense ;) )
And for new style ziploader modules, a module scope 'log' object could work. ``` log = logging.getLogger(__name__) # <-- does __name__ get weird on remote modules? ``` Then instead of `self.debug_logger.debug(foo)`, it would be `log.debug(foo)` That would remove the need for the module introspect in AnsibleModule.log(). Then potentially of the rest of AnsibleModule.log() becomes a matter of which logging Handler is setup.
already have this in basic.py, no need to create your own, it also includes sanitation and no_log
supports_check_mode still needs to be toggled to False
This check repeats 3 times and you've already done at least one typo in one of the instances. Please move it into a function.
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
here's the definition of changed: https://github.com/ansible/tower-cli/blob/master/tower_cli/resources/setting.py#L136 I might have to come back to look at this later for the deeper questions here
supports_check_mode still needs to be toggled to False
supports_check_mode still needs to be toggled to False
None of the optional metadata should break the extraction.
This can instead be `continue` and let the `else` unnest.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
`del` is a builtin, not a function. These parens don't have to be here
Just noting the second bare except
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Failing on this one ``` =========================================================================================== FAILURES =========================================================================================== _________________________________________________________ test_select_params_should_provide_needed_args_to_create_if_module_has_basics _________________________________________________________ def test_select_params_should_provide_needed_args_to_create_if_module_has_basics(): needed_args = ['DBInstanceIdentifier', 'DBInstanceClass', 'Engine'] set_module_args({ "db_instance_identifier": "fred", "db_instance_class": "t1-pretty-small-really", "engine": "postgres", "allocated_storage": 5 }) module = rds_i.setup_module_object() > params = rds_i.select_parameters(module, rds_i.db_create_required_vars, rds_i.db_create_valid_vars) test/units/modules/cloud/amazon/test_rds.py:462: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ module = <ansible.module_utils.aws.core.AnsibleAWSModule object at 0x10fa6df10> required_vars = ['db_instance_identifier', 'engine', 'allocated_storage', 'db_instance_class', 'username', 'password'] valid_vars = ['backup_retention', 'backup_window', 'character_set_name', 'cluster', 'db_name', 'engine_version', ...] def select_parameters(module, required_vars, valid_vars): """select parameters for use in an AWS API call converting them to boto3 naming select_parameters takes a list of required variables and valid variables. Each variable is pulled from the module parameters. If the required variables are missing then execution is aborted with an error. Extra parameters on the module are ignored. """ facts = {} for k in required_vars: if not module.params.get(k): > raise Exception("Parameter %s required" % k) E Exception: Parameter username required lib/ansible/modules/cloud/amazon/rds_instance.py:830: Exception ============================================================================== 1 failed, 9 passed in 0.34 seconds ============================================================================== ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
```suggestion """Add 'public.' to names of tables where a schema identifier is absent ```
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
`validate_config` call is missing
You don't need to re-include some of these fixtures, as they are used in the `elb` fixture but never called in this test.
Actually, it's an opposite. It's a check for successful login.
Remove excessive verbosity. This fits well on a single line.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
There should be an `id` group.
Move data and query into `_download_webpage` call.
Move data and query into `_download_webpage` call.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
1. Single quotes. 2. `expected`.
`dynamic` is not a very descriptive name. It looks like what you want is to pass the output both to a file and to stdout. In general, this problem has already been solved by `tee`.
I'd put `(self._flags['become_success'] or chan.exit_status_ready())` into a `@property` for readability so that it'd look like ```suggestion while not self._cmd_finished: ```
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
instead of 'starting connection' here we might want to 'reserve socket path', to create it if it doesn't exist and to 'touch it' if it does (making a-connection timeout reset so we avoid a race condition)
I think that makes sense. Right now the fact that we download the collection is an implementation detail. So something indicating `--local-only` or `--no-server-verification`. Just some ideas.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Actually, it's an opposite. It's a check for successful login.
This ignores additional keyword arguments possibly passed by the user.
Actually, it's an opposite. It's a check for successful login.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Here only detect adding change
No need for this line
You don't need a lambda here. Also, don't break lines with `\`.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
Here only detect adding change
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
No need for this line
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Kind of a nitpick since this is setup.py... but API-wise I prefer returning a small dict with the dynamic values and letting the caller merge it/copy the static dict if necessary.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
`no_log=True` is argument spec will handle this.
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
`no_log=True` is argument spec will handle this.
For rtmp it's always flv despite of the extension.
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Below change will fix the ` TypeError: the JSON object must be str, not 'dict'` error ``` try: obj = json.loads(item) command = obj['command'] except (ValueError, TypeError): command = item['command'] ```
Is it worth treating these differently instead of including them in the UNRESOLVED list? People that look at JIRA release notes for a version would probably think the issue was fixed when it really hasn't.
This is checked by `_search_regex`.
My bad. Could you please add this to vmware.py
use ```from ansible.module_utils.vmware import get_cluster```
Remove excessive verbosity. This fits well on a single line.
Remove excessive verbosity. This fits well on a single line.
Mandatory data must be accessed with `[]` not `get`.
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
facts modules can trivially support check mode (#23107)
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
if datastore already exists
Mandatory data must be accessed with `[]` not `get`.
This is checked by `_search_regex`.
No `id` extracted.
This is a bit too much, it needs to be simplified somehow so it is easier to understand.
Like above, I think this should be `userid, name, password, group, email`
Breaks. Read coding conventions on optional metadata.
Breaks. Read coding conventions on optional metadata.
Keep it on the single line.
Can setting above three keys moved in `nxapi_implementation()`
get_exception() isnt imported anywhere
```suggestion ssl_ca_certs=dict(type='path'), ```
```suggestion via U(https://www.rabbitmq.com/ssl.html#automated-certificate-generation) and RabbitMQ ``` Also, there recently was a discussion in #ansible-docs about the word `via`; I think the result was to avoid it, since not everyone understands it.
I'd remove this comparison altogether, and after this just check if `_raw_params` is still empty.
return dict((key, self.get(key)) for key in self.keys())
User of this inventory plugin should be able to use `v6_main_ip` for value of `ansible_host` (i don't know if it makes sens to be able to use `internal_ip`) or no `ansible_host` at all (meaning that `server['label']` will be used instead).
User of this inventory plugin should be able to use `v6_main_ip` for value of `ansible_host` (i don't know if it makes sens to be able to use `internal_ip`) or no `ansible_host` at all (meaning that `server['label']` will be used instead).
This will cause the `overwrite=always` setting to never work, since the module exits before checking the value of `overwrite`. Please delete this line.
This will cause the `overwrite=always` setting to never work, since the module exits before checking the value of `overwrite`. Please delete this line.
```suggestion via U(https://www.rabbitmq.com/ssl.html#automated-certificate-generation) and RabbitMQ ``` Also, there recently was a discussion in #ansible-docs about the word `via`; I think the result was to avoid it, since not everyone understands it.
just call scaleway.ini we are in ansible conflict should not occur
I dont't have any resource and I get the following error: ``` Traceback (most recent call last): File "/home/goneri/.ansible/tmp/ansible-tmp-1562681655.5490832-209270742247135/AnsiballZ_vmware_content_library_info.py", line 139, in <module> _ansiballz_main() File "/home/goneri/.ansible/tmp/ansible-tmp-1562681655.5490832-209270742247135/AnsiballZ_vmware_content_library_info.py", line 131, in _ansiballz_main invoke_module(zipped_mod, temp_path, ANSIBALLZ_PARAMS) File "/home/goneri/.ansible/tmp/ansible-tmp-1562681655.5490832-209270742247135/AnsiballZ_vmware_content_library_info.py", line 65, in invoke_module spec.loader.exec_module(module) File "<frozen importlib._bootstrap_external>", line 728, in exec_module File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed File "/tmp/ansible_vmware_content_library_info_payload_z7gmsr1d/__main__.py", line 143, in <module> File "/tmp/ansible_vmware_content_library_info_payload_z7gmsr1d/__main__.py", line 137, in main File "/tmp/ansible_vmware_content_library_info_payload_z7gmsr1d/__main__.py", line 105, in get_content_lib_details File "/home/goneri/.virtualenvs/ansible/lib/python3.7/site-packages/com/vmware/content_client.py", line 744, in get 'library_id': library_id, File "/home/goneri/.virtualenvs/ansible/lib/python3.7/site-packages/vmware/vapi/bindings/stub.py", line 317, in _invoke return self._api_interface.native_invoke(ctx, _method_name, kwargs) File "/home/goneri/.virtualenvs/ansible/lib/python3.7/site-packages/vmware/vapi/bindings/stub.py", line 275, in native_invoke self._rest_converter_mode) com.vmware.vapi.std.errors_client.NotFound: {messages : [LocalizableMessage(id='com.vmware.vdcs.cls-main.validate_id_not_found', default_message='ID content_library of resource type [com.vmware.content.Library] not found.', args=['content_library', 'com.vmware.content.Library'])], data : None} ``` I think it would be more Ansible-ish to return an explicity `msg` key. This way, the users won't have to set `ignore_errors`.
return dict((key, self.get(key)) for key in self.keys())
I don't think the `or []` is needed here. If there are no server groups defined, the API already returns an empty list.
doc typo, s/funcition/function
Check for `embed_code` instead.
Yup, that's sensible to have a default limit since we'll be (typically) filtering out most of the historical events with that ClientRequestToken setting.
```suggestion except (AttributeError, KeyError): ```
```suggestion except (AttributeError, KeyError): ```
This will fail when there is no vlanId or vswitch in portgroup. I don't remember the exact reason, but I encountered error here sometimes in past.
Yup, that's sensible to have a default limit since we'll be (typically) filtering out most of the historical events with that ClientRequestToken setting.
```suggestion except (AttributeError, KeyError): ```
```suggestion except (AttributeError, KeyError): ```
Well, this is also very boilerplate, which you could deduplicate.
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
Would it maybe be better to only check the beginning of the query? Assume that the query is `SELECT * FROM USER_UPDATES`; in that case, because `INSERT` appears in `q.upper()` and `cursor.rowcount > 0` (assuming the table isn't empty), the module will say something was changed.
ð, this is a nice little refactor.
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
```suggestion query=dict(type='list', elements='str'), ```
Just an empty line, could be removed for cleaner code
Don't need these parens.
this should use the config system instead
Can you move this logic to `__get_storage_domain_and_all_template_disks` and just call: ``` return otypes.Vm( ... disk_attachments=self.__get_storage_domain_and_all_template_disks() ... ) ```
I would re-write to something like this: ```python def _attached_sd_service(self, storage_domain): dc_name = self._module.params['data_center'] # Find the DC, where the storage we want to remove reside: if not dc_name and self._module.params['state'] == 'absent': dcs_service = self._connection.system_service().data_centers_service() dc = search_by_attributes(dcs_service, storage=self.param('name'), status='up') if dc is None: raise Exception("Can't remove storage, because dataceneter bla bla') dc_name = dc.name attached_sds_service = self._attached_sds_service(dc_name) attached_sd_service = attached_sds_service.storage_domain_service(storage_domain.id) return attached_sd_service ```
Can you move this logic to `__get_storage_domain_and_all_template_disks` and just call: ``` return otypes.Vm( ... disk_attachments=self.__get_storage_domain_and_all_template_disks() ... ) ```
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
This should be modeled in the same way that all other modules within ansible currently work. Variables can be set per host and applied to tasks.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
we want want -> we want
This assertion doesn't make sense: you're testing whether your fixture returns a Mapping instance which it always does. ```suggestion ```
```python if size_pct is not None ```
Breaks if `node_views_class` is `None`.
I would prefer to reuse
I would prefer to reuse
same here, we really dont want to test the particular setting, just that both the default (dynamic template) and the nii entry are correctly parsed.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
This should be configurable, because this isn't enough for the work I do with auto scale groups.
should we allow 'run once' tasks? since they affect hosts globally it is kind of counter to 'notify for specific hosts'
Is this function used to retrieve large files? If so, I suggest redirecting directly to the file, instead of using PIPE -> 'stdout' variable and writing to the file only then.
cc @rajinisivaram I'm not sure we should have this here - i.e., a unit test failure isn't particularly helpful if SHA1PRNG is unavailable (since the user may be fine with the null default).
the name is not too descriptive but I dont have a good alternative at the moment either
cc @rajinisivaram I'm not sure we should have this here - i.e., a unit test failure isn't particularly helpful if SHA1PRNG is unavailable (since the user may be fine with the null default).
```suggestion zip_data = zip(sorted(new_list), sorted(old_list)) ```
```suggestion zip_data = zip(sorted(new_list), sorted(old_list)) ```
Also note that simply sorting does not necessarily give the correct result for lists of dicts. So this change could actually recreate/update services where nothing changed.
```suggestion zip_data = zip(sorted(new_list), sorted(old_list)) ```
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
ð, this is a nice little refactor.
```suggestion # just get value from attribute itself as normal ```
s/like C(mail)/(e.g., C(mail))./
```suggestion parts = to_native(version.strip()).split(':', 1) ```
`video_data` is totally useless. Write directly to id variable when found.
Format your docstrings like other docstrings in the codebase
Can we use `get_vm` method instead? Since find_vm_by_name finds vm based on VM only.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
`video_data` is totally useless. Write directly to id variable when found.
It's not safe to modify sys.path outside of unit test functions, as these changes will affect other unrelated tests.
return dict((key, self.get(key)) for key in self.keys())
Similarly, ```if tc['skip'].get('i')```
return dict((key, self.get(key)) for key in self.keys())
Similarly, ```if tc['skip'].get('i')```
I would write: ```python else: if self.fstype == 'XFS': ... else: ... return out ```
121, 124 - DRY.
Move this to line 175
should be self.forward.
self.get_stack_info returns a string. I don't think this will work as expected. You probably want it to return a list.
I'd probably still want to see `.absolute()` in the end
What is the reason for reordering all these parameters? This breaks `blame` attribution for these lines & doesn't improve the code.
This might fail on python 3 and json.loads expects string and getvalue() will return bytes .
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
you don't need to say `testcase failed`, it's obvious from testrunner's indication
With a timeout, this function will return False if the lock cannot be created. Without a timeout, this function will raise an exception. You should decide on one strategy or the other and implement it for both.
you don't need to say `testcase failed`, it's obvious from testrunner's indication
BlockingIOError is not available in Python2. Probably need to use OSError and check that it's the particular OSErrors that we care about.
you don't need to say `testcase failed`, it's obvious from testrunner's indication
I'm not sure if making this and lock_file conditional upon check_mode is the right thing to do. A module might need to lock a file in order to read it and decide if changes should be made.
I'm not sure if making this and lock_file conditional upon check_mode is the right thing to do. A module might need to lock a file in order to read it and decide if changes should be made.
Is`atexit` is the right approach here? The registered function will only run when the entire ducktape process finishes (i.e. _after_ all ~215 tests finish). Use of the `tempfile.mkdtemp` will still avoid path collisions from concurrent processes, so maybe it's good enough. Another possibility that at least results in immediate cleanup: put directory removal into `clean_node` (but check the containing directory is present before removing to avoid errors)
With a timeout, this function will return False if the lock cannot be created. Without a timeout, this function will raise an exception. You should decide on one strategy or the other and implement it for both.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
I would write it as `RECORDSET_VALUE_MAP = dict(...) if HAS_AZURE else {}`
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
```suggestion raise AnsibleError('Unable to use "%s" as a search parameter: %s' % (term, to_native(e))) ```
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
`return not owner or owner == publication_info['owner']` could be used.
You don't need to check languages. Read the whole post.
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
Mandatory data must be accessed with `[]` not `get`.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
when you opt-in to using a CM like this, make sure you only patch lines that you really need to patch. and put any assertions outside, whenever possible: ```suggestion assert ret == [] ```
The may match something unexpected. `r'var\s+__desc_popup_d_\d+\s*=\s*({[^><]+});'` is better.
You can use tuples; supported_resolutions won't be changed
Do we want floats like int(1.9999999999) to convert to 1? We might want to throw an error on float still. OTOH, if we allow floats, we probably also need to handle a string value of "1.0".
nvm, I figured it out
This code duplication may be eliminated.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You can import `try_rm` from helper
Break the line after the `(` to unify the style across the file.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
What's the point changing old time-proven regexes with another ones? That's not an improvement.
I see... it's putting them near split_xpath_last which is where they're used. Maybe move both the variables and the split_xpath_last function up to below the imports.
What's the point changing old time-proven regexes with another ones? That's not an improvement.
I believe more explicit top-level dirs would read better: ```suggestion DEFAULT_TEMPLATE_DIR = ( pathlib.Path(__file__) / '..' / '..' / '..' / '..' / 'docs/templates' ).absolute() ```
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
This should not be fatal.
This isn't valid yaml ` : `
This isn't valid yaml ` : `
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
This isn't valid yaml ` : `
121, 124 - DRY.
Ideally it's best if we can avoid `sleep` calls Is there a reason why you can't use `stop_node` without sleeping? This should block until the process is gone and the background thread has finished processing output from the consumer
Ideally it's best if we can avoid `sleep` calls Is there a reason why you can't use `stop_node` without sleeping? This should block until the process is gone and the background thread has finished processing output from the consumer
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
Ideally it's best if we can avoid `sleep` calls Is there a reason why you can't use `stop_node` without sleeping? This should block until the process is gone and the background thread has finished processing output from the consumer
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
You only need a simplified version of this. Actually, optparse's built-in action `append` should be sufficient here
You only need a simplified version of this. Actually, optparse's built-in action `append` should be sufficient here
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
You only need a simplified version of this. Actually, optparse's built-in action `append` should be sufficient here
yt-dlp's `--print` is a bit more complex, allowing printing data at multiple stages. Eg: `-O "after_move:%(filepath)s" will print the final file path. This function is needed to (easily) support that syntax, (and also other similar options)
You only need a simplified version of this. Actually, optparse's built-in action `append` should be sufficient here
Verifying here that IP address and prefix are in correct format would be good. Look for APIs: `socket.inet_pton(socket.AF_INET, address)` and `socket.inet_pton(socket.AF_INET6, address)`
In case this pattern is used in other modules as well, moving it into `exec_sql` is probably a good idea. Also, adding a new argument to `exec_sql` with a default value shouldn't affect the other users.
In case this pattern is used in other modules as well, moving it into `exec_sql` is probably a good idea. Also, adding a new argument to `exec_sql` with a default value shouldn't affect the other users.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
I completely missed that, apologies
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
In case this pattern is used in other modules as well, moving it into `exec_sql` is probably a good idea. Also, adding a new argument to `exec_sql` with a default value shouldn't affect the other users.
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
hmm using the key 'password' is not a good idea for a msg to the user, ansible would think this might be sensible data. (the return password would also be missing in the return docs) however, I would suggest to use the common return key `msg`
I would write this all on a single line as: ```python diff = parse_diff(out) if module._diff else {} ```
I realize this was in the original file, but it can be simplified as well: ```suggestion sys.exit(main(sys.argv)) ```
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
That should only be called if the plugin should in `enabled` state afterwards.
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
Good catch! yeah there should be a warning.
Can't be None.
This (and the other exception handling) should use the standard convenience function, which will format the exception for you: ``` self.module.fail_json_aws(e, msg='Error getting provider ARN for {0}'.format(name)) ```
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
This can instead be `continue` and let the `else` unnest.
`del` is a builtin, not a function. These parens don't have to be here
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
`del` is a builtin, not a function. These parens don't have to be here
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
`del` is a builtin, not a function. These parens don't have to be here
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
`del` is a builtin, not a function. These parens don't have to be here
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
That's incorrect. https://www.stream.cz/pohadky/lego-staveni/10015386-dalsi-staveni-z-lego-city-starter-set is a video but processed as a playlist.
That's incorrect. https://www.stream.cz/pohadky/lego-staveni/10015386-dalsi-staveni-z-lego-city-starter-set is a video but processed as a playlist.
This ignores additional keyword arguments possibly passed by the user.
Should not break the extraction if missing.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
both are valid tests, i don't see why you need to eliminate the existing one
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
both are valid tests, i don't see why you need to eliminate the existing one
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Title is mandatory.
`elapsed_sec`/`'elapsed_seconds`? I personally dislike time values/args without units...
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Could you use `output = Dense(2, name='dense_B')(c1)` instead? Using a temporary variable make the reader believe that you are going to reuse this layer in the test or in the network.
This should not be fatal.
when you opt-in to using a CM like this, make sure you only patch lines that you really need to patch. and put any assertions outside, whenever possible: ```suggestion assert ret == [] ```
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
For things with this many arguments, I'd really like to see keywords used to avoid any order mixups in the future.
I really hate that is the case, we never got a real good standard around 'number of v' to use for each case, most connections print all output at 3, winrm is one of the few that goes higher
Sure, a separate PR sounds good.
actually, that is not really the limit (just the limit of internally created aliases), verbosity does not have a hardcoded limit at this point (indirectly python int max value)
We have an `AnsibleAssertionError` for use here. It inherits from `AnsibleError` so that it is handled accordingly
For consistency path pruning should be done the same as in the boilerplate test: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L13-L14 https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L41-L42
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Optimizers have a `get_config` method precisely for this purpose.
Optimizers have a `get_config` method precisely for this purpose.
Optimizers have a `get_config` method precisely for this purpose.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Typo, should be email
Typo, should be email
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Omit these lines please.
both are valid tests, i don't see why you need to eliminate the existing one
Docstring contains a few typos, please fix / rephrase
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
No need to parametrize with just one case.
How about selecting a semantically better exception? ```suggestion raise LookupError( 'File "{target_path!s}" not found in collection path "{coll_path!s}".'. format(target_path=path, coll_path=ANSIBLE_COLLECTIONS_PATH), ) ``` P.S. `str()` is unnecessary since the specifier does that already.
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
Syntax error here (`}`)
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
For consistency, use `'` as the quote character
I see that the requirements lists python-2.6 as the minimum python version. Unfortunately, format strings in python-2.6 are more limited than in python-2.7 and later. So you need to be explicit about the position in the format args list you are looking at like this: ``` python response = rest.get('floating_ips/{0}/actions/{1}'.format(ip, action_id)) ``` There's a few other places with format strings that have to be fixed as well.
This is what `urlencode()` is already doing for you., so the function would be: ```python def encode_url_params(self, params): """Encodes key value pairs for URL""" return '?' + urlencode(params.items())
This is what `urlencode()` is already doing for you., so the function would be: ```python def encode_url_params(self, params): """Encodes key value pairs for URL""" return '?' + urlencode(params.items())
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
This is what `urlencode()` is already doing for you., so the function would be: ```python def encode_url_params(self, params): """Encodes key value pairs for URL""" return '?' + urlencode(params.items())
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For consistency, use `'` as the quote character
For consistency, use `'` as the quote character
Read code conventions on optional fields.
Since the very first thing that both of the above do is create a ```PasswordManagerPro``` object and then they just lightly wrap a method call on that object, it seems like they should really be integrated into the methods they're calling.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
This is just style but we try to follow standard python naming conventions. So function and method names should be underscore separated like this: ```get_resources```.
I was testing this in my threading fact gathering branch, the .get method won't help with 'blocked' processes and will inconsistently return or just hang forever (I'm still trying to get a reliable reproducer). I found this by 'simulating' bad NFS mounts by throttling the traffic to the nfs server the VMs are using.
return dict((key, self.get(key)) for key in self.keys())
This should probably be the last method in the class.
return dict((key, self.get(key)) for key in self.keys())
It'd be good to include a default sleep here so this loop doesn't continuously hit the oVirt endpoint. Even just a one or two second sleep would be fine between tries.
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Like above, I think this should be `userid, name, password, group, email`
Just leave it out, we'll think of something later.
Just leave it out, we'll think of something later.
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
`_search_regex` is enough here.
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
Remove leading space
`current_version` could be mentioned in the error message.
`current_version` could be mentioned in the error message.
Here, `outdated` is a `dict` (or `list` in mheap/ansible#3).
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Here, `outdated` is a `dict` (or `list` in mheap/ansible#3).
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
`return not owner or owner == publication_info['owner']` could be used.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
`return not owner or owner == publication_info['owner']` could be used.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
`no_log=True` is argument spec will handle this.
Some more: avc2, avc3, avc4. These would be enough.
when you opt-in to using a CM like this, make sure you only patch lines that you really need to patch. and put any assertions outside, whenever possible: ```suggestion assert ret == [] ```
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
This should not be fatal.
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
Yeah we need to handle all exceptions that would be otherwise handled in `TaskExecutor` (`_execute()`, `run()`) and `Worker.run()`.
rephrase of 'never used options, now it is recommended to always use options' .. which is 'format neutral', covering both `k=v` and `k: v`
traditionally, variables is a keyword arg. I don't think it matters in our paticular code base but we should keep it consistent with other lookup plugins.
traditionally, variables is a keyword arg. I don't think it matters in our paticular code base but we should keep it consistent with other lookup plugins.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
Use [`fetch_url`](https://github.com/ansible/ansible/blob/240d1a6afb43982f16acebef16778d17aab58160/lib/ansible/module_utils/urls.py#L1197) instead of `requests.get`
Since you return above, unnest the `raise` here.
Parameters that are not required, don't need a `required: False`. This is implied.
task_uuid seems unused
This check appears unnecessary, since the `stat` call below will also provide a user-friendly error message if the file does not exist.
Will break if `episode_title` is `None`.
Will break if `picture_url` is `None`.
it should also check if it can write there
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
I don't mind the current structure. I'd even be ok with setting `HAS_DNF = True` outside the `try` `except`. `Â¯\_(ã)_/Â¯`
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
If I got it right, resourse unpacking happens every time `tr` is called. Have you measured the overhead imposed by this approach? Probably it would be better to unpack it once to temp dir on start and cleanup on exit.
You can specify a path glob to configure search paths for plugins. Like the following contrived example: ``` ANSIBLE_CALLBACK_PLUGINS=`pwd`/*/ ansible localhost -m ping ``` Because we use `glob.glob` currently this allows for supplying plugin paths with glob chars, which people do use.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
I think this message is a bit confusing. It sounds like single quotes are not allowed in commands at all, which is not the case. Unmatch or uneven quotes are the problem. ```suggestion module.fail_json(msg="Unmatched single (') quote found in command: " + command) ```
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
```python current_config['received'] = (current_config.get('received') == 'yes') ```
```python current_config['received'] = (current_config.get('received') == 'yes') ```
move this into main so you only need to define on load instead on every call
move this into main so you only need to define on load instead on every call
move this into main so you only need to define on load instead on every call
You can import `try_rm` from helper
Similarly, ```if tc['skip'].get('i')```
In that particular example you should be able to use this instead: ```python mocked_xenapi = mocker.patch.object(fake_xenapi.Session, 'xenapi', create=True) ```
Similarly, ```if tc['skip'].get('i')```
Style note, I finally convinced people a year or so ago that ```{}``` is superior to ```dict()```. So new code should use the literal syntax.
Style note, I finally convinced people a year or so ago that ```{}``` is superior to ```dict()```. So new code should use the literal syntax.
Notice that, conceptually, the `set(a) | set(b)` operation is different than `a + b`. The former performs set union meaning that duplicates are removed, whereas the latter is a simple concatenation with the possibility for the same item to appear twice. If these are considered "set operations", then the else part should be replaced by something like: ``` c = a + filter(lambda x: x not in a, b) ```
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
**Never ever** use `eval` on data you don't control.
Ok, there's one thing we forgot: a `timedelta` object also has `days`, and seconds are up to one day. Fortunately, there's an easier way to do this all: ```suggestion time_in_nanoseconds = int(time.total_seconds() * 1000000000) ```
The impression I have gotten is that A6 records aren't used at all these days. There is also the following informational [RFC 6563: Moving A6 to Historic Status](https://tools.ietf.org/html/rfc6563) Hence I believe that listing A6 records only has the potential to cause confusion. Unless I'm wrong, and there actually are people who use A6 records today.
We've switched from pipes.quote() to six.moves.shlex._quote for python3 compatibility: ``` python from ansible.compat.six.moves import shlex_quote out_path = shlex_quote(self._prefix_login_path(out_path)) ```
We've switched from pipes.quote() to six.moves.shlex._quote for python3 compatibility: ``` python from ansible.compat.six.moves import shlex_quote out_path = shlex_quote(self._prefix_login_path(out_path)) ```
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
self.get_stack_info returns a string. I don't think this will work as expected. You probably want it to return a list.
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
Why do you have a different code path here? The non-check line does the same but provides a bit more info, so just using that in the check case should be fine I'd say.
self.get_stack_info returns a string. I don't think this will work as expected. You probably want it to return a list.
self.get_stack_info returns a string. I don't think this will work as expected. You probably want it to return a list.
self.get_stack_info returns a string. I don't think this will work as expected. You probably want it to return a list.
self.get_stack_info returns a string. I don't think this will work as expected. You probably want it to return a list.
the error should go to stderr, since sys.exit does this by default (and still returns rc=1) just use that.
We try to avoid defining ```_``` in case we ever decide to i18n the code. gettext traditionally uses ```_()``` to mark strings for translation and we wouldn't want to overwrite that.
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
The locale should be set to C if we do string matching.
We try to avoid defining ```_``` in case we ever decide to i18n the code. gettext traditionally uses ```_()``` to mark strings for translation and we wouldn't want to overwrite that.
I don't think we want 2 `elif` statements here. Maybe just `elif any((async_val, poll)):`
I checked that `--json` switch is supported by npm 4.2.0.
It's pointless to match URLs with strict regex, needless to say it's invalid due to `&` being delimiter in query. Match anything after `https?://` till closing quote or `&`.
It's pointless to match URLs with strict regex, needless to say it's invalid due to `&` being delimiter in query. Match anything after `https?://` till closing quote or `&`.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
so this assertion looks incorrect, i would expect and empty string as the ssh args
Use _ (underline) instead of webpage if the value is not used.
Rather than hard coding the path, use `get_bin_path`.
We can ditch this logic block since it is not relevant to your test - it was a very specific check on the correctness of the ConsoleConsumer start command to ensure the log4j settings were correct.
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
Just want to verify - will it be possible to apply these environment variables per host in the inventory file? The idea is that you may have multiple firewalls, some of which need proxy (or even different proxies) to be managed and others don't.
Just want to verify - will it be possible to apply these environment variables per host in the inventory file? The idea is that you may have multiple firewalls, some of which need proxy (or even different proxies) to be managed and others don't.
Could you please keep the same string quoting style across the module? ```suggestion (datetime(2019, 6, 15, 14, 45, tzinfo=tz('UTC')), '2019-06-15T14:45:00+00:00'), ```
I completely missed that, apologies
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
Nothing changed: 1. `re.sub` will break on `None` string. 2. Regex must match single quotes as well. 3. `utils.parse_count`.
(Additional whitespaceânumber of spaces not multiple of 4.)
(Additional whitespaceânumber of spaces not multiple of 4.)
(Additional whitespaceânumber of spaces not multiple of 4.)
Hmm can't do `ok and ...` because Python will short-circuit and won't print the failures... Maybe just: ``` if check_env_var(...): ok = False ``` for each check? Or leave it as a list :)
(Additional whitespaceânumber of spaces not multiple of 4.)
(Additional whitespaceânumber of spaces not multiple of 4.)
(Additional whitespaceânumber of spaces not multiple of 4.)
(Additional whitespaceânumber of spaces not multiple of 4.)
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
@s-hertel that would be really nice for vanilla pulp ansible installations, which don't currently have token auth.
Space (" ") instead of period(" ")
My bad. Could you please add this to vmware.py
``` r'itemprop\s*=\s*\"ratingValue\"\s*> ``` ``` r'itemprop\s*=\s*\"ratingValue\"[^>]*> ``` So that the code can live even if new attributes are added to this element Also, there's no need to escape double quotes in strings encapulated by single quotes.
You don't need to call `report_extraction` here and above, since the extraction is over already.
Just use `replace` or `re.sub`.
does not resolve inheritance https://github.com/ansible/ansible/issues/25097
Don't need to import HAS_BOTO3 now.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
Typo: it's `range`. This means that this mode wasn't tested, and in fact, never run.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
```suggestion query=dict(type='list', elements='str'), ```
I'd go for underlining.
```suggestion query=dict(type='list', elements='str'), ```
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
```suggestion query=dict(type='list', elements='str'), ```
I highly recommend using printf style formatting or using `.format()` instead of `+` concatenation. There is a performance hit for python to try and understand if it can do the operation by type inspecting the parts, figuring out how to do it, and what to do in the case of a failure.
No need to escape `\`.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Module arg building doesn't take place here. This file packages up a module. It doesn't handle construction of module parameters at all. Action plugins sit in between module arg construction and here.
I'm totally fine with your explanation and it was just a starting point by my side. And you are right, that the usage in your module in this case is simpler, so no change needed.
And remove this afterwards.
`del` is a builtin, not a function. These parens don't have to be here
stdout and stderr are being returned by suprocess.Popen().communicate() so they should be bytes already, I think.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#blank-lines): There should be two blank lines before a function.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
I'm totally fine with your explanation and it was just a starting point by my side. And you are right, that the usage in your module in this case is simpler, so no change needed.
Maybe this can just be "terms_set" too
Similarly, ```if tc['skip'].get('i')```
`Telemetry data not capture` to `Telemetry data not captured.` as per below.
stdout and stderr are being returned by suprocess.Popen().communicate() so they should be bytes already, I think.
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
stdout and stderr are being returned by suprocess.Popen().communicate() so they should be bytes already, I think.
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
no, if the variable is set but empty, you should empty out the options
small typo ```suggestion # table availability in check_src/dst. ```
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
so this assertion looks incorrect, i would expect and empty string as the ssh args
so this assertion looks incorrect, i would expect and empty string as the ssh args
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
`del` is a builtin, not a function. These parens don't have to be here
`del` is a builtin, not a function. These parens don't have to be here
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
And remove this afterwards.
It would be more general to make this `epochs_since_last_save`, and change the check correspondingly.
`return not owner or owner == publication_info['owner']` could be used.
If `display.verbosity` is falsy, this results in `python anisble_connection '' <pid> <uuid>` and the extra parameter isn't understood to be intended as a flag. I think this (and the above change to verbosity) should fix the issue? ```suggestion [python, ansible_connection, *verbosity, to_text(os.getppid()), to_text(task_uuid)], ```
If `display.verbosity` is falsy, this results in `python anisble_connection '' <pid> <uuid>` and the extra parameter isn't understood to be intended as a flag. I think this (and the above change to verbosity) should fix the issue? ```suggestion [python, ansible_connection, *verbosity, to_text(os.getppid()), to_text(task_uuid)], ```
```suggestion self.module.fail_json(msg='Unable to add required signing key for%s ', rc=rc, stderr=stderr, error=to_native(e)) ```
It'd be interesting to see a test case for something inheriting a `BaseException` too.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
```suggestion type: list entries: str ```
Don't we need to set version 0.10.1 for those initially? Otherwise, they will have trunk version
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
Don't we need to set version 0.10.1 for those initially? Otherwise, they will have trunk version
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
This should not be here as done by downloader.
missing from docs fragment
Extract id once before the loop.
```suggestion Kwargs: ```
missing from docs fragment
Ah, ok. As I said, I've never used docker-machine, so I assumed that it actually connects to the machine (using that shell) and exports the environment from there. If that's just the format, then yes, it really doesn't matter (as long as it is a format you can parse :) ). Both `bash` and `sh` are fine for me, use whatever you want then.
If an unknown keyword is specified, `kdata` has not yet been assigned at this point.
```suggestion query=dict(type='list', elements='str'), ```
I know, was just wondering if it's intended that it works that way.
```suggestion query=dict(type='list', elements='str'), ```
Please either change the comma to a semicolon here. Thanks!
You can save a line and go `Object value = valueTypes[level].get();` directly
Line too long. Prefer raising a `ValueError`. Use a consistent quote char (`'`).
this is too generic and can lead to picking the wrong video.
this is too generic and can lead to picking the wrong video.
Put these inside the `call` method, they shouldn't be class methods.
Missing `=dict` on this and the next few lines
If the length here is >1 and the user did not provide a folder, the module should fail immediately and tell the user to give a folder.
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
For consistency, use `'` as the quote character
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I think this should be 'exit' instead of 'abort'
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
For consistency, use `'` as the quote character
Please remove this example, since I would consider this usage as not recommended.
Remove blank line
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
What kinds of failures are we trying to mask here? Frequently retries also require delays between retries.
I'm afraid I don't touch lib/ansible code in devel anymore. Yeah, if you want to just fix it in devel, that would be fine with me.
when using dict you can just do `dict(msg=to_text(body), message_count=....`.
Do note that this does not take `self.principal` into account, neither is that being checked. So you might return with `changed=False` if there's a tgt for a totally different principal.
I'm afraid I don't touch lib/ansible code in devel anymore. Yeah, if you want to just fix it in devel, that would be fine with me.
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
CI failure due to PEP 8 issue: ``` 2017-02-15 10:09:55 ERROR: PEP 8: lib/ansible/modules/cloud/atomic/atomic_container.py:158:161: E501 line too long (302 > 160 characters) (current) ``` Also, that path value is wrong.
`boto3_dynamodb` variable is not used
Needs to be `run_commands(module, ['show vlan brief'])[0]`.
Use `'` as the quote character for consistency with the rest of the file
Oh, I see. `run_commands()` runs list of commands and returns list of results.
Oh, I see. `run_commands()` runs list of commands and returns list of results.
Actually, you can just use the `convert_legacy_kwargs` utility function I just added.
Nope! Never do an `except Exception`. This is a bad practice since you catch ALL the potential exception, and we may lose something import :-) You can instead do something like: ```python mail_server = self.params.get('mail', {}).get('server') mail_server = self.params.get('mail', {}).get('sender') ``` e.g: ``` >>> a = {} >>> print(a.get('mail', {}).get('a')) None ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Nope! Never do an `except Exception`. This is a bad practice since you catch ALL the potential exception, and we may lose something import :-) You can instead do something like: ```python mail_server = self.params.get('mail', {}).get('server') mail_server = self.params.get('mail', {}).get('sender') ``` e.g: ``` >>> a = {} >>> print(a.get('mail', {}).get('a')) None ```
Style: break long lines in the test
What happens if you have something like `a=b=c`? Then you will init the dictionary with the tuple `(a, b, c)`, which will fail. Usually you want to interpret `a=b=c` as key `a` with value `b=c`; for that, you need `metric.split("=", maxsplit=1)`.
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
```not (foo is None)``` => ```foo is not None```
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Probably the same with `--label` instead of `--uuid` here.
It also looks you you are missing the variable to be inserted for the `%s`.
this produces an exception when binary cannot be found, you should capture and return parser error
probably want a to_text and u prefix.
It also looks you you are missing the variable to be inserted for the `%s`.
note, if expanded paths is large, this might be slow. It's faster to do it like this, if so: ```suggestion expanded_paths=to_native(b', '.join(b_expanded_paths), errors='surrogate_or_strict') ```
B is added in the constructor if we remove the NT check.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Shouldn't this use the value of ansible_python_interpreter? There is a mechanism (winrm.py uses it) to pass in some host variables to connection plugins, so this should probably implement that.
each call to the AWS API should be wrapped in a `try...except`, such as ```python try: subnets_by_id = describe_subnets_with_backoff(connection, SubnetIds=subnet_ids, Filters=filters) except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: module.fail_json_aws(e, msg="Couldn't find subnet with id %s" % subnet_ids) ```
you can just `return True`, no need for a var.
each call to the AWS API should be wrapped in a `try...except`, such as ```python try: subnets_by_id = describe_subnets_with_backoff(connection, SubnetIds=subnet_ids, Filters=filters) except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: module.fail_json_aws(e, msg="Couldn't find subnet with id %s" % subnet_ids) ```
each call to the AWS API should be wrapped in a `try...except`, such as ```python try: subnets_by_id = describe_subnets_with_backoff(connection, SubnetIds=subnet_ids, Filters=filters) except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: module.fail_json_aws(e, msg="Couldn't find subnet with id %s" % subnet_ids) ```
each call to the AWS API should be wrapped in a `try...except`, such as ```python try: subnets_by_id = describe_subnets_with_backoff(connection, SubnetIds=subnet_ids, Filters=filters) except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: module.fail_json_aws(e, msg="Couldn't find subnet with id %s" % subnet_ids) ```
**Never ever** use `eval` on data you don't control.
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
you need to do `get_credentials` even if `profile` is not set (IAM instance profiles mean that neither environment variables, module parameters nor profile contain the keys)
I'd call it a failure counter. I didn't get the meaning of this var while scanning for the first time.
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
Newline before this line
Newline before this line
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
For consistency, use `'` as the quote character
For consistency, use `'` as the quote character
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
It can also happen that the argument has been passed in as a string before; Ansible would have converted it to an `int` if it was trivially convertable. `convert_duration_to_nanosecond` will fail on such strings. You should probably add something like ```suggestion try: return int(value) except ValueError as e: return convert_duration_to_nanosecond(value) ```
I realize this was in the original file, but it can be simplified as well: ```suggestion sys.exit(main(sys.argv)) ```
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
Newline before this line
I realize this was in the original file, but it can be simplified as well: ```suggestion sys.exit(main(sys.argv)) ```
I'd call it a failure counter. I didn't get the meaning of this var while scanning for the first time.
Then it is not secure. CTR mode requires an unpredictable and unique value as part of the counter. Previous code was correct in taking the full IV from PBKDF2 output.
You will need to include the OAUTH_TOKEN environment variable also.
You will need to include the OAUTH_TOKEN environment variable also.
```suggestion elif date_string.match(self.when): ```
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
`return not owner or owner == publication_info['owner']` could be used.
Some more: avc2, avc3, avc4. These would be enough.
Read code conventions on optional fields.
you shouldn't need to create an intermediate in-memory list here. Also, `str.startswith()` supports checking multiple values: ```suggestion out = "\n".join( line for line in out.split('\n') if not line.startswith(('You are using', 'You should consider')) ) ```
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
Sorry about `maxsplit`, I'm mostly using Python 3 nowadays and forgot it wasn't a keyword in Python 2. Anyway, `metric.split("=", 1)` will work fine in both Python 2 and 3, so it's good!
Line is too long.
Line is too long.
Line is too long.
Line is too long.
Line is too long.
```suggestion b_opath = os.path.realpath(to_bytes(os.path.join(path, group))) ```
`pzuid` does not look to be used anywhere.
Should this be a warning? The resource is not in a manageable (or possibly usable) state...
You can just use 'playlist_count'
You can just use 'playlist_count'
`pzuid` does not look to be used anywhere.
Use `{}` dicts.
Use `{}` dicts.
This one *might* not be redundant, if it's possible to make changes that will cause the CDN endpoint hostname to change...
Use `{}` dicts.
This one *might* not be redundant, if it's possible to make changes that will cause the CDN endpoint hostname to change...
The removal of this final raising of `HTTPError` means that there are some scenarios that can succeed, such as when given invalid redirection options. ``` RedirectHandlerFactory(follow_redirects='invalid', validate_certs=True) ``` Previous behavior was to raise an `HTTPError` in this situation, somewhat similar to `follow_redirects='none'`
The removal of this final raising of `HTTPError` means that there are some scenarios that can succeed, such as when given invalid redirection options. ``` RedirectHandlerFactory(follow_redirects='invalid', validate_certs=True) ``` Previous behavior was to raise an `HTTPError` in this situation, somewhat similar to `follow_redirects='none'`
You can just use 'playlist_count'
dashboardId parameter is missing.
`pzuid` does not look to be used anywhere.
The removal of this final raising of `HTTPError` means that there are some scenarios that can succeed, such as when given invalid redirection options. ``` RedirectHandlerFactory(follow_redirects='invalid', validate_certs=True) ``` Previous behavior was to raise an `HTTPError` in this situation, somewhat similar to `follow_redirects='none'`
dashboardId parameter is missing.
Use `{}` dicts.
Should this be a warning? The resource is not in a manageable (or possibly usable) state...
This one *might* not be redundant, if it's possible to make changes that will cause the CDN endpoint hostname to change...
Move on a single line.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Possibly referenced before assignment.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
this module is marked as "legacy" and therefore the CI is not complaining about pep8 here, but it would help if we try to be pep8 compliant.
Please remove this example, since I would consider this usage as not recommended.
there is no need to version params for new modules
No. Empty download URL is pointless.
there is no need to version params for new modules
Nesting generator expressions and list comprehensions like this is bad style. It has the same problems as a run-on sentence in natural languages (Making it hard for other people to read and keep the entirety of the clause in their memory. Easy to misinterpret the meaning because of misreading one small piece of the grammar). In most cases, using a ```for``` loop with indentation for at least one of the loops is better. If I understand this correctly, You are trying to take input of this form: ``` names = ['one >1.0,<2.0', 'two', '>3.0', '<4.0'] ``` and flatten it so that it is in this form: ``` names = ['one', '>1.0', '<2.0', 'two', '>3.0', '<4.0'] ``` ? If so, it's not quite right as it will currently return ``` ['one >1.0', '<2.0', 'two', '>3.0', '<4.0'] ```
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
Add ``` required_one_of=[['principal', 'group'],], ```
I see you are a Theano user. This wouldn't work with TF.
`video_id` is not actually a video id, i think the variable name should be changed.
I see you are a Theano user. This wouldn't work with TF.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
If I read the source correctly, this can be simplified to ```suggestion monkeypatch.setitem(C.config._base_defs, 'GALAXY_CACHE_DIR', cache_dir) ```
As already said: parse as JSON not with regexes.
`{}` does not work in python 2.6
It does; two lines later you are multiplying your `int` with `float`, which returns a `float`. Hence casting to `int` has no effect on the final type.
2.6 or 2.7? Also you `requirements` listed here and the modules.
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
parent name also needs to be 'safe'
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
parent name also needs to be 'safe'
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
Same here, default parameter is **validate_certs**, the aliases should be removed. We also simplify this by *not* adding `required=False`, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
Same here, default parameter is **validate_certs**, the aliases should be removed. We also simplify this by *not* adding `required=False`, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
```suggestion description: A list of variables whose values were changed. ```
Okay... what about using `sys.stderr.write('%s\n' % ('\n'.join(errors)))` at the end of this function and then the calling function does sys.exit(1) afterwards? Almost the same result but it doesn't abuse the exception mechanism to make it happen :-) Probably should do something similar with the exception raised by the new connect method... maybe make the exception thrown there specific and then in this toplevel exception handler, print the exception message to stderr and sys.exit(1). The general rule is exceptions should be thrown and unhandled if there are programming errors. Error messages and sys.exit should be used when there are errors the user can correct without diving into the ansible code.
```suggestion if self._module.check_mode: ``` You already checked for equality above.
parent name also needs to be 'safe'
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
This looks for tags with the `Name` key set to `dev` - maybe a better example would be: ``` # all instances with their `Environment` tag set to `dev` tag:Environment: dev # all dev and QA hosts tag:Environment: - dev - qa ``` Since `tag:Name` could be confused for "tags with the name dev" as in `dev : true` or something
GitLab authentication should not be inside this class. It should be in the main function and then you init your class with the gitlab_instance object in parameter. Look at other GitLab module
The (non-empty) matches succeeded (or an exception would have been raised) so the values are both truthy: ```suggestion headers['rfApiProfileId'] = api_token headers['rfWidgetId'] = widget_id ```
GitLab authentication should not be inside this class. It should be in the main function and then you init your class with the gitlab_instance object in parameter. Look at other GitLab module
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
You reassign this var on each loop iteration, please move it outside. ```suggestion ```
I would call super here like this: ``` python super(Connection, self).exec_command(cmd, tmp_path, in_data=in_data, sudoable=sudoable) ``` It doesn't do anything useful for the docker connection but once again, it's nice to do it so that anyone looking at the docker connection plugin for a basis to create their own connection plugin will do the right thing (the base class's exec_command() fetch_file(), and put_file() use the @ensure_connect decorator to make sure that our connection is open before attempting these actions. For plugins that actually need to establish a connection, this is a necessary step).
`delay_min_macos = delay_min | 1`
Python 3.5 does not have `unicode`. Take a look at the [ansible text helper methods](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/_text.py) for alternatives. Only noting the first occurrence.
Also, it seems like our convention for docs versions is quite bad. If we didn't want to use `.`, we could use something else like `_`.
I was testing this in my threading fact gathering branch, the .get method won't help with 'blocked' processes and will inconsistently return or just hang forever (I'm still trying to get a reliable reproducer). I found this by 'simulating' bad NFS mounts by throttling the traffic to the nfs server the VMs are using.
`_connect` already does nothing if `_connected` is False. It might _look_ weird, but you can call `_connect()` without checking and the right thing will happen.
`_connect` already does nothing if `_connected` is False. It might _look_ weird, but you can call `_connect()` without checking and the right thing will happen.
No need to parametrize with just one case.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
A golden rule I use is to alphabetically sort items in a list if the order is of no importance. It helps compare lists or finding items in a list more easily.
Have you considered using YAML booleans for boolean values ? I am not sure if @dsoper2 had been doing this already. IMO it provides a more native look and feel. We implemented this for ACI as well (where internally different values were used for booleans). Beware though that some values may look boolean, but sometimes allow for other values (e.g. None, empty, or different flags, etc...).
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Have you considered using YAML booleans for boolean values ? I am not sure if @dsoper2 had been doing this already. IMO it provides a more native look and feel. We implemented this for ACI as well (where internally different values were used for booleans). Beware though that some values may look boolean, but sometimes allow for other values (e.g. None, empty, or different flags, etc...).
I updated the description and added a note:
Use `%` instead of `.format()` to support older version of Python. ```python self.abort('%s is not a supported option on target platform' % key) ``` (L557 too)
I think we don't need to patch `datetime.datetime.fromtimestamp()` and `datetime.datetime.utcfromtimestamp()` methods as they just return a datetime object from patched `time.time()`.
I think we don't need to patch `datetime.datetime.fromtimestamp()` and `datetime.datetime.utcfromtimestamp()` methods as they just return a datetime object from patched `time.time()`.
Keep using `self.module.fail_json()`, of course fine. ð Changing all `.format()` into `%`, great! ð I've never noticed that the module has so many `.format()`...my reviews must be too rough at that time ð
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Have you considered using YAML booleans for boolean values ? I am not sure if @dsoper2 had been doing this already. IMO it provides a more native look and feel. We implemented this for ACI as well (where internally different values were used for booleans). Beware though that some values may look boolean, but sometimes allow for other values (e.g. None, empty, or different flags, etc...).
I think we don't need to patch `datetime.datetime.fromtimestamp()` and `datetime.datetime.utcfromtimestamp()` methods as they just return a datetime object from patched `time.time()`.
Ids must stay exactly the same.
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
It would be awesome if buildah supported copying from a container.
Okay, I just tested this and it looks like fd.close() does not cause an error. It's useless to have it there but not strictly necessary to remove it.
okay, seems right. Just the typo correction for `user` is required. Everything else looks good :)
okay, seems right. Just the typo correction for `user` is required. Everything else looks good :)
Thanks for fixing this. Do you mind fixing this one as well? ce.message won't exist on python3. `module.fail_json(msg=str(ce), exception=traceback.format_exc(), **camel_dict_to_snake_dict(ce.response))`
Thanks for fixing this. Do you mind fixing this one as well? ce.message won't exist on python3. `module.fail_json(msg=str(ce), exception=traceback.format_exc(), **camel_dict_to_snake_dict(ce.response))`
Thanks for fixing this. Do you mind fixing this one as well? ce.message won't exist on python3. `module.fail_json(msg=str(ce), exception=traceback.format_exc(), **camel_dict_to_snake_dict(ce.response))`
Thanks for fixing this. Do you mind fixing this one as well? ce.message won't exist on python3. `module.fail_json(msg=str(ce), exception=traceback.format_exc(), **camel_dict_to_snake_dict(ce.response))`
`ClientError` often has useful info in e.response: ``` module.fail_json(msg=msg, exception=traceback.format_exc(), **camel_dict_to_snake_dict(e.response)) ```
`ClientError` often has useful info in e.response: ``` module.fail_json(msg=msg, exception=traceback.format_exc(), **camel_dict_to_snake_dict(e.response)) ```
This method isn't necessary.
This method isn't necessary.
`ClientError` often has useful info in e.response: ``` module.fail_json(msg=msg, exception=traceback.format_exc(), **camel_dict_to_snake_dict(e.response)) ```
I think this should be a mandatory option when creating a disk and we don't randomly choose one.
.message doesn't exist at all when running Python 3. The exception handling guidelines have also added BotoCoreError to exceptions that should be caught (which do not have a .response attribute). https://github.com/ansible/ansible/blob/devel/lib/ansible/modules/cloud/amazon/GUIDELINES.md#boto3-1
Actually, better would be to move this to the toplevel as a regular function
There should be fallbacks for these values since they are more or less static.
`acodec == 'none'`.
`acodec == 'none'`.
Instead, please set `self.index = json.load(f)`. The JSON library uses the `.load` function to stream straight from files without needing to `.read()` first. This also avoids pesky encoding issues with Python2/3.
Using EOL escaping is prone to accidental line breaks during refactoring so I usually prefer using parens instead. Also, it's better to use `str.format()` with named params having in mind that we'll be moving towards 3.7/3.8+ codebase in the future and such syntax would be easier to upgrade.
Using EOL escaping is prone to accidental line breaks during refactoring so I usually prefer using parens instead. Also, it's better to use `str.format()` with named params having in mind that we'll be moving towards 3.7/3.8+ codebase in the future and such syntax would be easier to upgrade.
you can move it to before `if` as just `docs = {}` line, this should read better.
Use dict literals: ```suggestion return {} ```
How about selecting a semantically better exception? ```suggestion raise LookupError( 'File "{target_path!s}" not found in collection path "{coll_path!s}".'. format(target_path=path, coll_path=ANSIBLE_COLLECTIONS_PATH), ) ``` P.S. `str()` is unnecessary since the specifier does that already.
Sure, a separate PR sounds good.
Note: you don't have to use set explicitly here. The set methods can work with an iterable (which tuple is)
Move on a single line.
boolean tip: `if not (to_text(new_value) in choices or isinstance(new_value, int)):`
e is unsued, just `except Exception:` to avoid 'bare exceptions'
e is unsued, just `except Exception:` to avoid 'bare exceptions'
boolean tip: `if not (to_text(new_value) in choices or isinstance(new_value, int)):`
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I would also detect if the value is a bool and set it accordingly to `on`/`off`.
I think we should add an `allow_overwrite` or similar param.
Why not use a list comprehension here? It's probably more efficient: `return [self.sanitize_keys(i) for i in data]`
Why not use a list comprehension here? It's probably more efficient: `return [self.sanitize_keys(i) for i in data]`
Why not use a list comprehension here? It's probably more efficient: `return [self.sanitize_keys(i) for i in data]`
Why not use a list comprehension here? It's probably more efficient: `return [self.sanitize_keys(i) for i in data]`
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
For compatibility we ask folks to use `.items()` since it works in Python 2.4 up to Python 3.x. If you _must_ use iteritems please use `six.iteritems()`.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
unused variable `input_length`
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
It seems you are indenting with 8 spaces. It should be 4.
`return not owner or owner == publication_info['owner']` could be used.
This is fine for porting but for greenfield code or when someone next cleans this code up, it would be better to write it more like this: ``` python except ValueError: return False return True ``` Another possibility is that this whole function would be deemed unneeded in a refactor. Now that you've fixed up `get_bin_path()` to be more sane the caller of `is_available()` might just want to catch the ValueError itself.
`, no_log = True`
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Good practice since the `%` operator can be ambiguous: ```suggestion return self._extract_videos(model_id, self._BASE_URL_TEMPL % (model_id, )) ```
You've forgot to pass `info_dict` to `supports()`.
This is not used in single video extractor thus should not be here.
Some more: avc2, avc3, avc4. These would be enough.
'+' is redundant here.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
It's better to use `self._download_webpage(url, video_id)`
Is this even needed, we will be dropping py2 and `to_text` does not call `__unicode__`. You may as well just put this in `__str__`.
`None` is not an id.
Should check for a list.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
I would rather add all other fields to the error message.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
I'm on the fence about holding this up to try and come up with something clever that seems like we know what the future will hold. With this being the only use case now, it's hard to know what another warning could look like in the future, and how we might need to represent that.
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
action plugin should have already taken care of this
action plugin should have already taken care of this
Omit these lines please.
What kinds of failures are we trying to mask here? Frequently retries also require delays between retries.
If found this part weird with using `self` for temporary variables
For public APIs we should be accepting text strings and internally convert to bytes where needed. If we really must accept bytes (which in this case I don't see a reason to) we should prefix the arg with `b_` to indicate that. The `b_` prefix may go away as we start to add type annotations but so far the behaviour is the standard we usually follow in ansible.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Breaks. Read coding conventions on optional data.
There are a lot more changes here than I expected from the conversation in issue report. This is going to require careful review, and potentially unit tests to validate the behavior hasn't fundamentally changed.
should be exception=last_traceback
I think this `query` function should be separated out into a `_facts` module.
Instead of including a stacktrace in the message, better to put it into the exception field: ``` module.fail_json(msg="Xpath %s causes a failure: %s\n -- tree is %s" % (xpath, to_native(e), etree.tostring(tree, pretty_print=True)), exception=traceback.format_exc()) ```
Since you only check keys of the same object in the same fashion, you could collapse this using parameterize (for example, extend with other params): ```suggestion @pytest.mark.parametrize( ('fact_name', 'fact_value'), ( ('year', 2020), ('weekday', 'Saturday'), ), ) def test_date_time_facts(date_collector, fact_name, fact_value): assert date_collector['date_time'][fact_name] == fact_value ``` This will generate a separate test per each param while allowing you to keep the test function logic the same. https://docs.pytest.org/en/stable/example/parametrize.html
Used by the base class to be able to handle all ansible data https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/callback/__init__.py#L123
This can be put in the argspec, e.g. `required=False, fallback=(env_fallback, ['GCP_SERVICE_ACCOUNT_FILE']),`
This can be put in the argspec, e.g. `required=False, fallback=(env_fallback, ['GCP_SERVICE_ACCOUNT_FILE']),`
Used by the base class to be able to handle all ansible data https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/callback/__init__.py#L123
Instead of including a stacktrace in the message, better to put it into the exception field: ``` module.fail_json(msg="Xpath %s causes a failure: %s\n -- tree is %s" % (xpath, to_native(e), etree.tostring(tree, pretty_print=True)), exception=traceback.format_exc()) ```
@bcoca noted the use of state=info in today's meeting... I think a year ago, or so, we discussed using a separate module named with an _info suffix (like sophos_utm_info.py) for things that are just for gathering info about something which doesn't relate to the host it is run on. (You also thought you might turn that portion into a lookup plugin. That would also be fine. The difference is just that a lookup can only be run o nthe controller whereas a module can be used on either the controller or a remote host).
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
Instead of including a stacktrace in the message, better to put it into the exception field: ``` module.fail_json(msg="Xpath %s causes a failure: %s\n -- tree is %s" % (xpath, to_native(e), etree.tostring(tree, pretty_print=True)), exception=traceback.format_exc()) ```
no need to do this check, the plugin never gets called if disabled
Used by the base class to be able to handle all ansible data https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/callback/__init__.py#L123
Although it probably works passing `None` instead of "nothing" for the no force case makes me a bit nervous :)
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
return dict((key, self.get(key)) for key in self.keys())
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Actually, it's an opposite. It's a check for successful login.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Code duplication 173, 213. There is no sense to extract fields explicitly.
Actually, it's an opposite. It's a check for successful login.
This line is unnecessary.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
`u` prefix is not necessary as `from __future__ import unicode_literals` has the same effect, and such a syntax is not available in Python 3.2.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
I'm pretty sure this can use `is_sequence()`.
1. Regex should match any variation of whitespace around `=`. 2. Once you provide default, fatal is not used thus it's pointless to provide fatal along with default.
Should not break if no `type`.
Same here, default parameter is **validate_certs**, the aliases should be removed. We also simplify this by *not* adding `required=False`, and always starting with the type. Since every parameter has a type, starting with this adds consistency.
I don't think this is a good idea. This prevents the valid value `""`. ```suggestion else: ```
Similarly, ```if tc['skip'].get('i')```
Such cases should be handled, too. I guess a possible approach is creating a table with common video and audio codecs. If given codecs are not on the table, fallback to `video,audio` order.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
With `groups` below changing to just be a list of strings, this should be changed ```suggestion found_files = loader.find_vars_files(path, group, allow_dir=False) ```
I would prefer to reuse
Missed one space cleanup here: `inv.update({env: []})`
Missed one space cleanup here: `inv.update({env: []})`
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Please remove this example, since I would consider this usage as not recommended.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Python 2.6 needs {0}, {1} - empty brackets in various other places too.
This seems wrong. Won't this end up being the equivalent of: ``` /bin/sh -c if [ x"test" = x"test" ] ; then printf "hi" ; fi ``` When what we really want is the former which is the equivalent of: ``` /bin/sh -c 'if [ x"test" = x"test" ] ; then printf "hi" ; fi' ```
This seems wrong. Won't this end up being the equivalent of: ``` /bin/sh -c if [ x"test" = x"test" ] ; then printf "hi" ; fi ``` When what we really want is the former which is the equivalent of: ``` /bin/sh -c 'if [ x"test" = x"test" ] ; then printf "hi" ; fi' ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
This ignores additional keyword arguments possibly passed by the user.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
This ignores additional keyword arguments possibly passed by the user.
We should use hasattr
This method is called with only one argument, but there are no defaults given for the unused arguments. If it is called, the `NotImplementedError` will never be reached.
This method is called with only one argument, but there are no defaults given for the unused arguments. If it is called, the `NotImplementedError` will never be reached.
This method is called with only one argument, but there are no defaults given for the unused arguments. If it is called, the `NotImplementedError` will never be reached.
This method is called with only one argument, but there are no defaults given for the unused arguments. If it is called, the `NotImplementedError` will never be reached.
Raise a `ValueError` instead of an assert (and add it to the docstring).
Raise a `ValueError` instead of an assert (and add it to the docstring).
It'd be better to avoid reformatting code to change indentation settings. AFAIK, in Streams at least, we tend to use indents of 4 spaces.
`return not owner or owner == publication_info['owner']` could be used.
If we can't delete the publication for whatever reason, there will be no error and the module will be trapped in a endless recursive loop.
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
If you use `env_fallback` then you don't require this check.
If you use `env_fallback` then you don't require this check.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
If I got it right, resourse unpacking happens every time `tr` is called. Have you measured the overhead imposed by this approach? Probably it would be better to unpack it once to temp dir on start and cleanup on exit.
Make this a text string: ``` python self.user = u'Anonymous' ```
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
I think we don't need to patch `datetime.datetime.fromtimestamp()` and `datetime.datetime.utcfromtimestamp()` methods as they just return a datetime object from patched `time.time()`.
I don't think it's acceptable to have backend-specific statements if it can be avoided. Also this would fail most of the time because usually the input shape contains `None`.
Breaks if `node_views_class` is `None`.
Similarly for ll.48-51: ``` uploader_id = try_get(schema_video_object.get('creator'), lambda x: x[alternateName'])
`[]` is useless.
I'd rather see this part for all extractor errors.
`[]` is useless.
`[]` is useless.
`[]` is useless.
On further thought, this actually might break something with the new stuff, since you're relying on pyyaml blindly `call`ing whatever is passed in, but the prototype logic that supports object instances only does that call if `isinstance(loader, Reader)` is true. We could probably tweak that somehow, like `callable()` instead, which might be a little more resilient/Pythonic anyway... So this is definitely fine for released code, and it's something I'll keep in mind for the new stuff.
Prefer making multiple statements, it will be easier to read than breaking the statements into multiple lines. Breaking lines should only be done if necessary. ```python slices = [] for i in range(x.ndim): .... ```
You should be able to use `self.vmware_test_platform` here.
IMO, there is no need to serialize the object if user choose a curated way. So we can only keep the tag filter here as ```python result = [x for x in response if self.has_tags(x.tags, self.tags)] if response else [] ```
Some more: avc2, avc3, avc4. These would be enough.
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
I think this should be `_return_if_object` since it isn't part of the public API.
The `root_uri` may include a port number (e.g. 192.168.1:8000). Should probably split that off also.
Similarly, ```if tc['skip'].get('i')```
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
Also, why do you compute `data.split(delimiter)` again instead of using `data_arr`? ```suggestion metric.split("=", maxsplit=1) for metric in data_arr) ```
`return not owner or owner == publication_info['owner']` could be used.
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
small typo ```suggestion # table availability in check_src/dst. ```
This is Theano syntax and breaks with TF. Use `K` instead.
`return not owner or owner == publication_info['owner']` could be used.
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
```suggestion query = '%s=%s' % ('UUID', uuid) ``` Since single quotes are used everywhere else.
Please don't use lists for tracking differences, but `DifferenceTracker`. That produces a much better output.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
nvm, I figured it out
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
How about moving this `if` below the next `if`? Then you don't need the inner `if`.
nvm, I figured it out
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Just use `replace` or `re.sub`.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Just use `replace` or `re.sub`.
```suggestion try: TimeoutError except NameError: class TimeoutError(OSError): """TimeoutError shim for Python 2.""" def _raise_timeout(signum, frame): ```
``` r'itemprop\s*=\s*\"ratingValue\"\s*> ``` ``` r'itemprop\s*=\s*\"ratingValue\"[^>]*> ``` So that the code can live even if new attributes are added to this element Also, there's no need to escape double quotes in strings encapulated by single quotes.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
(Additional whitespaceânumber of spaces not multiple of 4.)
`xrange` has been removed in Python 3. Simply use `range` instead.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
pep8 stuff ``` if 'names' not in vmap: ```
paramlist needs to be instantiated before this line. Then after the loop len(terms) should be compared to the length of results. Also [line 172](https://github.com/ansible/ansible/pull/35569/files#diff-55e80dc4588cb031afcf2736c1338c47R172) should be removed or the 'return None' replaced with a continue
```suggestion return b'\r\n'.join(to_bytes(line, nonstring='passthru') for line in result) ``` (and import `to_bytes`)
`media_attributes` is somewhat misleading. It's the whole tag but not just attributes.
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
I don't think this is useful in this example. Please remove.
You should be able to use `self.vmware_test_platform` here.
Why not use a `list` as `key, value` are all same? `for option in options` seems make later logic clearer.
we use -o for output file elsewhere, it is not good to overload options with diff meanings
Python 3.5 does not have `unicode`. Take a look at the [ansible text helper methods](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/_text.py) for alternatives. Only noting the first occurrence.
Missed one space cleanup here: `inv.update({env: []})`
Use `train_dataset` and `val_dataset` as the names
More elegant would be to shuffle an array of indices once, then use the array to index X and y (yes, unlike the current code in this module, but like the code in `models.py`).
More elegant would be to shuffle an array of indices once, then use the array to index X and y (yes, unlike the current code in this module, but like the code in `models.py`).
This one is not legal. In python, a dictionary key must be hashable. dictionaries themselves are not hashable. Anything containing a dictionary would also not be hashable. So the key isn't valid.
@hermansje Let's have `on_batch_{ begin | end }` be aliases for `on_train_batch_{begin | end}` like in your original code
@hermansje Let's have `on_batch_{ begin | end }` be aliases for `on_train_batch_{begin | end}` like in your original code
This should match only integers.
@hermansje Let's have `on_batch_{ begin | end }` be aliases for `on_train_batch_{begin | end}` like in your original code
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
you need to skip value from parent if include_tasks/include_role, but still inherit
Replace all `f''` expressions: * where possible as below * for an expression where the braced expressions aren't just local variables, replace each `{expr}` by `{n}` with n starting at 0 and incrementing, and append `.format(expr0, expr1, ...)` to the string literal, or rewrite using `%` formatting * if the braced expressions are all local variables, you can just add `.format(locals())` (possibly distasteful) * for format literals used to add or change URL query parameters, consider using `update_url_query()` instead. ```suggestion msg = 'Panopto said: ' + response.get('ErrorMessage') ```
`any` seems it doesn't belong here. You'll want this to return an array. Additionally, I would prefer not casting to `float32` and use the native TF `bool` type instead (i.e. this function should be a thin wrapper over `tf.nn.in_top_k`). The fact that Theano does not have a bool type has to be dealt with in the Theano backend and should not affect the TensorFlow backend.
should be list(attr.items())[0] to work with python3 too. ``` An exception occurred during task execution. The full traceback is: Traceback (most recent call last): File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 310, in <module> main() File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 280, in main attrs = EcsAttributes(module, attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 131, in __init__ self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes) File "/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py", line 151, in _parse_attrs name, value = attr.items()[0] TypeError: 'dict_items' object does not support indexing fatal: [localhost]: FAILED! => { "changed": false, "failed": true, "module_stderr": "Traceback (most recent call last):\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 310, in <module>\n main()\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 280, in main\n attrs = EcsAttributes(module, attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 131, in __init__\n self.attributes = attributes if self._validate_attrs(attributes) else self._parse_attrs(attributes)\n File \"/var/folders/by/k8_fbl593dlctgqmwq5wzl2c0000gn/T/ansible_xs5l34yw/ansible_module_ecs_attribute.py\", line 151, in _parse_attrs\n name, value = attr.items()[0]\nTypeError: 'dict_items' object does not support indexing\n", "module_stdout": "", "msg": "MODULE FAILURE", "rc": 0 } PLAY RECAP ********************************************************************* localhost : ok=0 changed=0 unreachable=0 failed=1 ```
f is already at 0, the `truncate()` is uselesss.
Python 3.5 does not have `unicode`. Take a look at the [ansible text helper methods](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/_text.py) for alternatives. Only noting the first occurrence.
```suggestion msg: "{{ lookup('first_found', findme, errors='ignore') }}" ```
Rather than having this same code four times in this module, turn this into a method that gets called.
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
Rather than having this same code four times in this module, turn this into a method that gets called.
```python # warn when failing to skip due to lack of support for skipping only some versions display.warning('Including test "%s" which was marked to skip for --windows %s but not %s.' % (target, ', '.join(skip_valid), ', '.join(skip_missing))) ```
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
```python # warn when failing to skip due to lack of support for skipping only some versions display.warning('Including test "%s" which was marked to skip for --windows %s but not %s.' % (target, ', '.join(skip_valid), ', '.join(skip_missing))) ```
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
Missing `raise`. I would probably change to `AnsibleAssertionError`.
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
Rather than having this same code four times in this module, turn this into a method that gets called.
This branch is never reached.
Same, please rename
Use [`fetch_url`](https://github.com/ansible/ansible/blob/240d1a6afb43982f16acebef16778d17aab58160/lib/ansible/module_utils/urls.py#L1197) instead of `requests.get`
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Ah, maybe `list(dict)` will be a more suitable type name for this. And we can add a shortcut for `len(a) == len(b)`, which I think will make the logic a bit clear, like this: ```python if len(a) != len(b) and method == 'strict': return False for av in a: for bv in b: # the compare logic, no need to another iteration for bv in b and av in a
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
Typo? ```suggestion msg="Argument 'state' includes the value '%s' as an invalid choice" % bad_state) ```
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
int(True) == 1 and int(False) == 0, in python3 int(b'characters'[0]) == 99....
int(True) == 1 and int(False) == 0, in python3 int(b'characters'[0]) == 99....
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
No such field.
@samdoran then, I'd say that there's something wrong with the setup and TZ should be adjusted somewhere.
Missed `'` after \1.
CI failure due to: ``` 2017-01-31 18:50:23 ERROR: PEP 8: lib/ansible/module_utils/netapp.py:150:31: W292 no newline at end of file (current) ```
`get_object` will get the full item (including the body) - instead I think we should use `head_object` here as it'll still give back the etag without getting the full item. http://boto3.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.head_object To test this, you could make a 1-2GB object and then try this codepath. It should take a long time, and consume 1-2GB of memory.
Theano -> Theano/TensorFlow
Code duplication. This is already implemented in `CeskaTelevizeIE`.
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
check_output is not python2.6 compatible
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
`# Returns `
`# Returns `
It is not cover the remove nsg
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
Some more: avc2, avc3, avc4. These would be enough.
the tests should not really be for hostfile, as we are going to remove it. a mock setting with 2 entries would test the functionality, not the specific setting
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
`If an empty list C([]) is specified`
`_og_search_title` has already defaulted to `fatal=True`
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Yep, simply ignoring all other options when `state == 'absent'` is the easiest solution (that's what most other modules do, too).
this could return here? Then the next stanza doesn't need the extra indent level
Use `self._download_json` instead.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
OK. It was just a suggestion. UweSays: Switch statements are very non-java like and must die :-)
Nesting generator expressions and list comprehensions like this is bad style. It has the same problems as a run-on sentence in natural languages (Making it hard for other people to read and keep the entirety of the clause in their memory. Easy to misinterpret the meaning because of misreading one small piece of the grammar). In most cases, using a ```for``` loop with indentation for at least one of the loops is better. If I understand this correctly, You are trying to take input of this form: ``` names = ['one >1.0,<2.0', 'two', '>3.0', '<4.0'] ``` and flatten it so that it is in this form: ``` names = ['one', '>1.0', '<2.0', 'two', '>3.0', '<4.0'] ``` ? If so, it's not quite right as it will currently return ``` ['one >1.0', '<2.0', 'two', '>3.0', '<4.0'] ```
Looks like dead code here
Instead of try-except you should pass `default=None` for first `config URL` and try alternative way when `not config_url`.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Remove extra space: `inv = {'all': []}`
I like it!
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
`delay_min_macos = delay_min | 1`
doesn't this overlap a lot with fileglob/filetree> ... just like using w/o the *
It seems you are indenting with 8 spaces. It should be 4.
`url_or_none`, `str_or_none`. Read coding conventions.
I've provided **clear working** piece of code that you must just copy paste. Instead you introduced mess with base URL.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
```suggestion cpu_facts['processor_cores'] = int(data[1]) ```
```suggestion return super(cls, new_cls).__new__(new_cls, *args, **kwargs) ```
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
```suggestion assert isinstance(wrap_var(set(['foo'])), set) ```
You should be able to use `self.vmware_test_platform` here.
```suggestion - Runs C(apt-get install python-apt) for Python 2, and C(apt-get install python3-apt) for Python 3. - Only works with the system Python 2 or Python 3. If you are using a Python on the remote that is not the system Python, set I(install_python_apt=false) and ensure that the Python apt library for your Python version is installed some other way. ```
aws_ip_ranges -> aws_service_ip_ranges
This property should probably also be `_` prefixed- the way the aliases are encoded in here right now makes it pretty useless for anything but generating that string in the error case.
aws_ip_ranges -> aws_service_ip_ranges
Leftover reference to `vcenter`.
Leftover reference to `vcenter`.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
Why do you disallow `story` to be an id? Because you do not want it to be an id in your particular case that is clearly an ad hoc hack cause other extractors may use `_generic_id` and may allow `story` to be an id.
Why do you disallow `story` to be an id? Because you do not want it to be an id in your particular case that is clearly an ad hoc hack cause other extractors may use `_generic_id` and may allow `story` to be an id.
121, 124 - DRY.
check_output is not python2.6 compatible
I find this error message very hard to understand. I don't have any experience with GitLab servers, though :) If the other gitlab_* modules have the same text, we should probably keep it here as well. Changing it could be done in another PR once this is merged.
```suggestion help='Specify webdriver type when you want to use Selenium to execute YouTube's "n_function" in order to avoid throttling: "firefox", "chrome", "edge", or "safari"') ```
There is already `--playlist-reverse`.
Adding the exception string to the error would help the user narrow down what the issue is.
This ignores the input `value` and always returns the value of the `spring.mustache.escaper.value` property.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Passing `sys.argv[:]` here is useless wrt current implementation. If you look at the `main()`'s first three lines there's: ```python def main(args): ... (options, args) = parser.parse_args() # <-- immediatelly rewrites args variable ``` It looks like the initial implementation has been written by the person with some C-like background, where main accepts args data and returns 0. But in fact in this case it's not needed. Please remove this arg.
```suggestion query=dict(type='list', elements='str'), ```
```suggestion query=dict(type='list', elements='str'), ```
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
```suggestion query=dict(type='list', elements='str'), ```
Add `cmd_verbosity` to the docstring.
Probably better to write this as ``` python if self.args.refresh_cache or not self.is_cache_valid(): self.update_cache() ```
Missed one space cleanup here: `inv.update({env: []})`
Same, mention this is spatial cropping.
Same, mention this is spatial cropping.
This will fail when there is no vlanId or vswitch in portgroup. I don't remember the exact reason, but I encountered error here sometimes in past.
Like I said I don't remember exactly where it happened but that is why I added that if block. I am ok without if block if it is working on your systems.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Same, mention this is spatial cropping.
Do not use underscore as prefix.
Do not use underscore as prefix.
Do not use underscore as prefix.
Replace all `f''` expressions: * where possible as below * for an expression where the braced expressions aren't just local variables, replace each `{expr}` by `{n}` with n starting at 0 and incrementing, and append `.format(expr0, expr1, ...)` to the string literal, or rewrite using `%` formatting * if the braced expressions are all local variables, you can just add `.format(locals())` (possibly distasteful) * for format literals used to add or change URL query parameters, consider using `update_url_query()` instead. ```suggestion msg = 'Panopto said: ' + response.get('ErrorMessage') ```
121, 124 - DRY.
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
```not (foo is None)``` => ```foo is not None```
To avoid linter errors, change this to ```suggestion d_ = d self.assertTrue(d == d_) ``` and hope that the linter doesn't get too clever ;-)
10 is default.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
10 is default.
10 is default.
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
```not (foo is None)``` => ```foo is not None```
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
small typo ```suggestion # table availability in check_src/dst. ```
Code duplication 173, 213. There is no sense to extract fields explicitly.
Code duplication 173, 213. There is no sense to extract fields explicitly.
```suggestion if not folder_obj: ```
This is actually one reason you want to use `MutableMapping` over subclassing `dict`. `.get()` does not use `.__getitem__()` in `dict`. Both methods duplicate code for performance: ```pycon >>> class VarsWithSources(dict): ... def __getitem__(self, key): ... val = super(VarsWithSources, self).__getitem__(key) ... print(('__getitem__', val)) ... return val ... >>> v = VarsWithSources() >>> v['foo'] = 'bar' >>> v['foo'] ('__getitem__', 'bar') 'bar' >>> v.get('foo') 'bar' ``` Notice that `.get()` doesn't cause the print to happen. As such, your implementation as is will only work with some accesses of keys, and not others.
*Right now.* But that isn't something that should be depended upon in general and especially if you are creating a subclass of a builtin type. I did recall the non-hacky way to fix this, though. Change the constructor to be dict-compatible and then create an alternate constructor using classmethod to do what you want. Then use the classmethod in your code. Looks like this: ``` python class VarsWithSources(MutableMapping): def __init__(self, data): self.sources = "<Source unset>" super(self, VarsWithSources).__init__(data) @classmethod def new_vars_with_source(cls, data, sources): new_vars_with_source = cls(data) new_vars_with_source.sources = sources return new_vars_with_source ```
This is missing a `cwd=` spec at the latest. If we need a git revision number, we should really think about releasing more often instead.
@bcoca noted the use of state=info in today's meeting... I think a year ago, or so, we discussed using a separate module named with an _info suffix (like sophos_utm_info.py) for things that are just for gathering info about something which doesn't relate to the host it is run on. (You also thought you might turn that portion into a lookup plugin. That would also be fine. The difference is just that a lookup can only be run o nthe controller whereas a module can be used on either the controller or a remote host).
This should be split into building url and extracting formats.
It probably makes sense to test that the exception reason also matches expectations
I'd argue that it'd look cleaner and would better correspond to the fixture name that implies that it returns only the date-related subset of facts.
Original extractor classes (`ie_key`s) should be preserved. Otherwise you break existing download archives.
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
`pzuid` does not look to be used anywhere.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
`pzuid` does not look to be used anywhere.
-1 to ignoring this. There is a simple way to fix this for review process, though... Disable check mode in the argument spec. Then you can fix the module so that check mode does the right thing later.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#blank-lines): There should be two blank lines before a function.
I'd argue that it'd look cleaner and would better correspond to the fixture name that implies that it returns only the date-related subset of facts.
I'd argue that it'd look cleaner and would better correspond to the fixture name that implies that it returns only the date-related subset of facts.
Maybe use the same convention as we use in the other builders here. Have these variables as Double objects and default to null here. Then check for null before including them in the XContent output and leave defining the defaults to the parser? This applies to all the models
we already had similar warnings, the controller code will cut them as 'non json output from module' , it would be better to add to a 'warnings' field in the json output
You should be able to use `self.vmware_test_platform` here.
`start`/`stop` is flexible since it means `_count/list_valid_files_in_directory` will be agnostic to the validation/training story, and only needs the `split` argument. But it doesn't make a big difference.
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
Not required with AnsibleAWSModule
Matched data-video should not be empty.
Matched data-video should not be empty.
Matched data-video should not be empty.
Matched data-video should not be empty.
Either way is fine. In general `<title>` is better than extracting from embedded data as the former is less likely to change. If there's an example that `<title>` or `settings['title']` is missing, a fallback should be provided, otherwise the extraction should be fatal.
Should probably use a [paginator](http://boto3.readthedocs.io/en/latest/reference/services/route53.html#paginators) here to support large accounts.
`capabilities` can be cached instead of fetching it from remote host each time. https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/network/vyos/vyos.py#L80
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
Use `self._download_json` instead.
If we're just testing broker compatibility I don't think we even need this part of the test.
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
Let's avoid `*` imports, even if the import list is very long. The namespace in `models` is very busy, and we need what is free and what isn't.
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
It looks like params are not only moved, some are added.
It looks like params are not only moved, some are added.
Got it. But this is very confusing error message. anyways, not a blocker as such.
Got it. But this is very confusing error message. anyways, not a blocker as such.
This is not used in single video extractor thus should not be here.
this is basically noop, unless you are under pipelining, in which you get None, tmpdir will still be populated though
this is basically noop, unless you are under pipelining, in which you get None, tmpdir will still be populated though
this is basically noop, unless you are under pipelining, in which you get None, tmpdir will still be populated though
This should not be fatal.
None of the optional metadata should break the extraction.
Name an example URL where `og:description` has HTML tags.
This logic tried to enforce a minimum version requirement, which the new code does not. Since it doesn't sound like you have added compatibility with older versions (or have any reason to), why not do something like: ``` min_version = '2.4' if loose_srv_version < LooseVersion(min_version): module.fail_json(msg='MongoDB {0] found, the minimum version supported by this module is {1}'.format(srv_version, min_version)) ```
`pzuid` does not look to be used anywhere.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
nvm, I figured it out
How about moving this in the main `if:` branch above? Then there's no need to do funny tricks for `mysqlvar_val` in the `elif:` branch.
Should be `marker = instances.marker`.
How about moving this in the main `if:` branch above? Then there's no need to do funny tricks for `mysqlvar_val` in the `elif:` branch.
Small introduced typo: ```suggestion # Search for 'key' entry and extract URI from it ```
Better to leave this part of the code unchanged and implement a property setter on the wrapper.
You don't need a lambda here. Also, don't break lines with `\`.
This can instead be `continue` and let the `else` unnest.
This can instead be `continue` and let the `else` unnest.
This feels a lot like reimplementing argument spec validation methods inside a module. I would advise against this. > We need raw user input so that we can distinguish between cases when (a) a user explicitly assigns a value to an option and (b) a value gets assigned because of default value for the option. I don't fully understand this need. The module should not care if a user provided the value or if it came from the default setting in the argument spec. It should only care about the value. Treating the value differently based on where it was set, particularly if the provided value is the same as the default value, seems overly complicated.
This can instead be `continue` and let the `else` unnest.
You don't need a lambda here. Also, don't break lines with `\`.
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
This can instead be `continue` and let the `else` unnest.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
Remove this flush, it is doing nothing just before the closing of the file.
A flush is missing either here, or at the end of _save_model itself.
A flush is missing either here, or at the end of _save_model itself.
A flush is missing either here, or at the end of _save_model itself.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
This can instead be `continue` and let the `else` unnest.
This can instead be `continue` and let the `else` unnest.
This can instead be `continue` and let the `else` unnest.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
You don't need a lambda here. Also, don't break lines with `\`.
This can instead be `continue` and let the `else` unnest.
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
Some 62 out of 64 other extractors that do a similar thing have called the corresponding method `_call_api()`. I'm only pointing this out in case you might want to do so.
You don't modify ignore_when_null in this function so it's probably harmless to use [] as its default value but it's a bad habit to get into. You should try to always use a immutable as a default value. In this case, you can do: ```ignore_when_null=tuple()```.
If you're unfamiliar with why that is, you should probably google it. It has to do with python processing the function declaration once when the function is declared and therefore there's only one copy of the default value which is used every time the function is called. If you have a mutable container as a default value, it will not be recreated between invocations so it may not be empty the second time you call the function.
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
Looks like merge_list_by_key(), _standardize_value(), and _str_sorted() should be moved to be toplevel functions? (They don't make use of self).
What happens if we have multiple IP pool with same name. In the past, we have seen a lot of issues due to the same name objects.
@Dref360 yes I think it is best to keep the same behavior as before.
return dict((key, self.get(key)) for key in self.keys())
This should be max.
return dict((key, self.get(key)) for key in self.keys())
What happens if we have multiple IP pool with same name. In the past, we have seen a lot of issues due to the same name objects.
this is already done by argspec when param is defined as boolean, all redundant
This should be max.
I don't think boto_params will include access_key or secret_key if a profile is being used (which might be through passing `profile` parameter or with `AWS_PROFILE` set) Looking at https://github.com/jmenga/requests-aws-sign the way to do it is to use ``` session = session.Session() credentials = session.get_credentials() ``` but even there, we'd need to cope with the `profile` parameter.
return dict((key, self.get(key)) for key in self.keys())
should be self.forward.
return dict((key, self.get(key)) for key in self.keys())
this is already done by argspec when param is defined as boolean, all redundant
Need a colon at the end here
This logic seems ignore the use case of removing all tags.
What happens if we have multiple IP pool with same name. In the past, we have seen a lot of issues due to the same name objects.
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
this is already done by argspec when param is defined as boolean, all redundant
we want want -> we want
1. What's the motivation for a wait time? Can the user just call sleep themselves? Perhaps just remove wait_time entirely. Otherwise: 2. I suggest default 0 wait time 3. don't always set wait time to 0
I suggest 100 be the default
I think it's likely the proxy code won't work as I haven't been able to test it well under Meraki
You don't modify ignore_when_null in this function so it's probably harmless to use [] as its default value but it's a bad habit to get into. You should try to always use a immutable as a default value. In this case, you can do: ```ignore_when_null=tuple()```.
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
we want want -> we want
This was a copy paste and still references Meraki
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
we want want -> we want
we want want -> we want
Need a colon at the end here
Thank you very much for your review of this! Will fix.
Which state the entity should have after executing the action can be specified by passing `wait_condition` parameter. -> State which the entity should be in after execution of the action can be specified by `wait_condition` parameter.
Thank you very much for your review of this! Will fix.
Need a colon at the end here
It is usually a good idea to prepend some text so that it is easier to find out where an error was raised (in case it's not clear from the error message).
we want want -> we want
this is already done by argspec when param is defined as boolean, all redundant
return dict((key, self.get(key)) for key in self.keys())
Pylint rules should be disabled only where needed.
Why do you have a different code path here? The non-check line does the same but provides a bit more info, so just using that in the check case should be fine I'd say.
this is already done by argspec when param is defined as boolean, all redundant
Need a colon at the end here
Doesn't exist in yt-dl. See also: * parse_qs * srt_subtitles_timecode * traverse_obj In this case, it's simple function that you could implement locally.
Pylint rules should be disabled only where needed.
Anytime I reach for map or filter, I like to use a list comprehension of generator exception instead as it is faster and considered more pythonic. ``` python return [p.name for p in q] ```
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
Dict can be defined outside try block
Style: space needed after comma.
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
you could narrow this down to oserror/ioerror
Require n-n-n in `id` field; no need to match the tail: ```suggestion _VALID_URL = r'(?:https?://[^/]+\.duboku\.co/vodplay/)(?P<id>(?:[0-9]+-){2}[0-9]+)\.html' ```
Require n-n-n in `id` field; no need to match the tail: ```suggestion _VALID_URL = r'(?:https?://[^/]+\.duboku\.co/vodplay/)(?P<id>(?:[0-9]+-){2}[0-9]+)\.html' ```
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
It could still be broken out without being a separate function. Having a separate function reads easier, but I am mostly suggesting the logic be broken out more for easier reading and maintenance.
multiple dictionary access: instead of ```python if required_config.get('rotation', None): rotation = required_config['rotation'] ``` use: ```python rotation = required_config('rotation') if rotation is not None: # do your stuff ``` use this rule for all dictionary access below
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
`AnsibleConnectionFailure` is a generic error, it does not mean the resource is missing. It should be more like an err 500.
I realize this was in the original file, but it can be simplified as well: ```suggestion sys.exit(main(sys.argv)) ```
Any reason not to use a CM? ```suggestion with codecs.open(os.path.join(*file_paths), 'r', 'latin1') as f: info_file = f.read() ```
```suggestion - name: Show variables with 'hosts' in their names ```
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Fair engough. Then, if I haven't overlooked anything, there is no need to pass `privatekey` to `_check_signature()` as you can call `csr.verify(self.privatekey)` directly.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
Fair engough. Then, if I haven't overlooked anything, there is no need to pass `privatekey` to `_check_signature()` as you can call `csr.verify(self.privatekey)` directly.
Use a `main()` function for the body of the test.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
There should be fallbacks for these values since they are more or less static.
There should be fallbacks for these values since they are more or less static.
Better to leave this part of the code unchanged and implement a property setter on the wrapper.
This should be relaxed since in most cases there is no need in exact match of dicts or dicts' keys. Moreover some internal, compatibility or autocalculated fields may be placed in original dict. So, `same_keys` feature should be removed completely.
```suggestion Kwargs: ```
Just an empty line, could be removed for cleaner code
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
should probably specify that this is only used for deletion
All methods only used once should be explicitly inlined.
As the `return_timestamps` is reverted, `msg_timestamps` is not needed anymore. lgtm otherwise.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
Reuse the result of [previous `get_bin_path` call](https://github.com/ansible/ansible/blob/8534178b1d28f2134da8f6b6634879157b5e34e9/lib/ansible/modules/system/filesystem.py#L397).
Would there be any utility to sorted() on files/sub_folders? AFAICT, os.walk will use the os.listdir() results directly for filenames. os.listdir() is doc'ed as 'arbitrary order' (iirc, more or less up to fs). Wondering if sorting those results would make for more reproducible behavior when trying to replicate errors. It shouldn't matter at all if there are no bugs, but it could make tracking down odd failures easier.
You should be able to use `self.vmware_test_platform` here.
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
I'm not sure this should work (that may be a "this shouldn't work in the future even if it works now") I think AnsibleUnsafeText should convert any string it's given into a text string, ie: unicode type on python2 and str type on python3. This may be the case now but the self.assertEqual is just not picking it up. For each of your three test cases, try putting non-ascii characters into them. (Note that the bytes one will needs a special incantation so it works on python3: ``` python b_text = u'some byte string cafÃ©'.encode('utf-8') ```
You can import `try_rm` from helper
Aren't we losing some good "text" here? Shouldn't probably do more than just `to_native(e)`
This line is too long. Max line length allowed in Ansible is 120 characters.
Adding the exception string to the error would help the user narrow down what the issue is.
And as the return is a dictionary of headers, instead of tracking `self._ccsrftoken` here, you should be able to set your return dictionary to be `{'x-csrftoken': csrftoken_search.group(1)}`, and everything should work as expected.
Please make this method private.
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
This doesn't seem to be py2.4 compliant ``` 2017-01-27 04:09:40 Compiling ./lib/ansible/module_utils/netconf.py ... 2017-01-27 04:09:40 File "./lib/ansible/module_utils/netconf.py", line 79 2017-01-27 04:09:40 yield 2017-01-27 04:09:40 ^ 2017-01-27 04:09:40 SyntaxError: invalid syntax ```
```suggestion query=dict(type='list', elements='str'), ```
is this really what was intended given compatibility? and do none of our tests rely on the existing behavior to wait until that message is logged? i would have expected some that use the REST API (e.g. pretty much anything distributed that submits a connector as one of its first post-start tasks) and would be flaky if we change the default to `INSTANT`
@pierremahot we'll need a test for this
```suggestion query=dict(type='list', elements='str'), ```
```suggestion 'ACCEPT', '--cstate', 'NEW', ```
This line is unnecessary, webpage is never used.
Aren't we losing some good "text" here? Shouldn't probably do more than just `to_native(e)`
Aren't we losing some good "text" here? Shouldn't probably do more than just `to_native(e)`
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
probably inside the `if` instead of before since it's kind of confusing to see this for a test that isn't going to actually read the DLQ
Please remove this example, since I would consider this usage as not recommended.
Please remove this example, since I would consider this usage as not recommended.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
This change is specific to static shape inference in Theano. It should be made in `K.any` and `K.not_equal` (only in the Theano backend).
`capabilities` can be cached instead of fetching it from remote host each time. https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/network/vyos/vyos.py#L80
```suggestion fallback=(env_fallback, ['ANSIBLE_HWC_PASSWORD']), ```
Grammar nitpick... Quick fix here would be to swap the comma for a semi-colon. The more detailed version is that this forms an invalid dependent clause the way it is written right now. A semi-colon would fix that, as would splitting off the `use the ...` content into its own sentence.
I don't think it's acceptable to have backend-specific statements if it can be avoided. Also this would fail most of the time because usually the input shape contains `None`.
This can all be replaced by `module.client('iam')` or `module.resource('iam')`, but module.resource doesn't support the aws_retry feature.
```suggestion # just get value from attribute itself as normal ```
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
You've forgot to pass `info_dict` to `supports()`.
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
nit: this doesn't need to be a field, you can just use a local variable
nit: this doesn't need to be a field, you can just use a local variable
Probably the same with `--label` instead of `--uuid` here.
Probably the same with `--label` instead of `--uuid` here.
Probably the same with `--label` instead of `--uuid` here.
Probably the same with `--label` instead of `--uuid` here.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Simplify, harmonise with yt-dlp pt5: ```suggestion if try_get(data, lambda x: x['viewCam']['show'], dict): raise ExtractorError('Model is in private show', expected=True) elif not try_get(data, lambda x: x['viewCam']['model']['isLive'], bool): raise ExtractorError('Model is offline', expected=True) ```
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Use ansible. module_utils.to_native or to_text here. To_Native converts to the str type (which is bytes on Python2 and text on python3). To_text converts to text type (Unicode on Python2. Str on python 3). Which you choose depends on what the rest of the module uses..
Weird. Yesterday it was working: ``` python -m youtube_dl http://mobile-ondemand.wdr.de/CMS2010/mdb/ondemand/weltweit/fsk0/75/752868/752868_8108527.mp4 [download] Destination: 8108527-752868.mp4 [download] 1.4% of 291.34MiB at 8.53MiB/s ETA 00:33 ERROR: Interrupted by user ``` But not now.
Breaks all videos embedded with exact `<ul class="media-list items" id="media-related-items"><li data-video-info`.
There could be a check in here to prevent both label and label_id from being specified if state is absent.
It's better use a flag to control write epoch-level summary or batch-level summary. The batch-level summary will be overwrite in your implementation.
Code markers around `put()`
Code markers around `put()`
Code markers around `put()`
Note that format strings changed in python-2.7 So things like "{} {}".format() needs to change to "{0} {1}".format() for python-2.6 compatibility.
This could be problematic. If you set the seed to a constant and use multi-processing then all children processes would share the same seed and you'll get batches with repeated samples.
Worth wrapping all these long fail_json calls at the comma before exception - otherwise it goes off the side at PR (I know there are lots of lines that are already too long but let's not add more)
fixture with load_json
`(?s)` == `DOTALL`. Current code works fine. This PR is noop.
Use `assert_allclose`` instead
I think this is overkilled if `devices` and `ulimits` are both lists of `str`
Besides providing another example, you can also prove that Brightcove's Javascript indeed references data-brightcove-video-id. For example, in https://github.com/rg3/youtube-dl/blob/732d116/youtube_dl/extractor/jwplatform.py#L36, there are lots of deprecated usages.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
PEP8: missing commas
~if not keeping encryption, remove the __ansible_vault key, just assign the value directly~ nmvd, misread the if to the opposite ...
Change to 0.
```suggestion # just get value from attribute itself as normal ```
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
This won't work as expected in case of `fatal=True` and `_json_ld` failure.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
I expected an example URL for > more time in one line
This won't work as expected in case of `fatal=True` and `_json_ld` failure.
You are using different ids in url and here. Don't do that.
Raise a `ValueError` instead of an assert (and add it to the docstring).
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
`expected_status` to `_download_json` instead.
Seems close enough, so I'll take that test as good as the 'unkillable' status is the main issue once the problem surfaces. I still have not been able to reproduce the problem i saw reliably, it just has happens a few time across the many times I've tested the gathering threaded code. It seems to happen less with Py3 versions, but since I'm not sure about how to trigger it, that is just anecdotal data. I was thinking of downgrading to nfsv3 since that was a lot more prone to this kind of issue ... but its probably not worth it.
This could simple read "converted"
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
Do not remove old patterns.
Actually, it's an opposite. It's a check for successful login.
Actually, it's an opposite. It's a check for successful login.
Actually, it's an opposite. It's a check for successful login.
Do not remove old patterns.
Please use code formatting around code keywords (`)
Please use code formatting around code keywords (`)
while purging all username we should preserve the username which is used to run the playbook otherwise we might hit connection timeout in middle and leave the box with partial configurations
"Passed to `tf.Session.run`", with ` around code
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
We want to print the full shapes for clarity. Creating a new array in the exception is not an issue: we're interrupting execution anyway, so we don't care about resources consumption.
This is already validated in the constructor, no need.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
fixture with load_json
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
Change this argument from bool to choices with the following choices `[never, always, if-supported]` In the `never` case, do not attempt to lock the conf data store In the `always` case, try to lock the conf data store and error if the lock operation failes In the `if-supported` case, try to lock the conf data store and continue unlocked if the lock operation fails The default value should be `never`
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
Shouldn't this use the value of ansible_python_interpreter? There is a mechanism (winrm.py uses it) to pass in some host variables to connection plugins, so this should probably implement that.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I completely missed that, apologies
I completely missed that, apologies
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
It would be nice to see the same msg in exit_json.
```suggestion elif date_string.match(self.when): ```
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
```/tv/tags/[^/]*?``` => ```/tv/tags/[^/]+```
```suggestion elif date_string.match(self.when): ```
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
Both cases test the same thing, don't repeat yourself. Test things based on their properties. Here you'd probably want to test iterables, not just sets.
```suggestion elif date_string.match(self.when): ```
It also looks you you are missing the variable to be inserted for the `%s`.
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
You don't need a lambda here. Also, don't break lines with `\`.
some of the magic vars rely on post_validate already being run to have the correct value
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
some of the magic vars rely on post_validate already being run to have the correct value
You don't need a lambda here. Also, don't break lines with `\`.
This is more efficient: ```suggestion key = next(iter(old[0]) ```
You don't need a lambda here. Also, don't break lines with `\`.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
Remove this flush, it is doing nothing just before the closing of the file.
Would benefit from being explicitly named "accuracy". Otherwise it turns up as "mean_n" and is very confusing.
These 2 `if` statements could probably be combined. To `pop` when if it doesn't start with `_` or not equal to `msg`.
You don't need a lambda here. Also, don't break lines with `\`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
You don't need a lambda here. Also, don't break lines with `\`.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
This can instead be `continue` and let the `else` unnest.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
Remove this flush, it is doing nothing just before the closing of the file.
This can instead be `continue` and let the `else` unnest.
No such meta field.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
This can instead be `continue` and let the `else` unnest.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
maybe we should have a constant somewhere with _source and _ingest? pretty sure we already use them somewhere else
Remove this flush, it is doing nothing just before the closing of the file.
Remove this flush, it is doing nothing just before the closing of the file.
Remove this flush, it is doing nothing just before the closing of the file.
You could convert things to int right here: ```suggestion requests_version = tuple(map(int, requests.__version__.split('.'))) ```
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Same for `addThroughputSensor`.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
I think it's fine to keep this here for now but, I wonder if this check (and similar checks in the future) should go into the `OpenShift` client as they are specific to `OpenShift` and not `Kubernetes`.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
no, if the variable is set but empty, you should empty out the options
Use `env_fallback` ``` from ansible.module_utils.basic import env_fallback ... api_key=dict(fallback=(env_fallback, ['HEROKU_API_KEY', TF_VAR_HEROKU_API_KEY']), type='str', no_log=True), ```
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
some of the magic vars rely on post_validate already being run to have the correct value
maybe we should have a constant somewhere with _source and _ingest? pretty sure we already use them somewhere else
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
Please raise a `NotIplementedError` when the use case is not supported yet.
Please remove this example, since I would consider this usage as not recommended.
`del` is a builtin, not a function. These parens don't have to be here
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
Using EOL escaping is prone to accidental line breaks during refactoring so I usually prefer using parens instead. Also, it's better to use `str.format()` with named params having in mind that we'll be moving towards 3.7/3.8+ codebase in the future and such syntax would be easier to upgrade.
Theano -> Theano/TensorFlow
I would suggest renaming this to `user` with choices `["currentUser", "anyUser"]` and `default: currentUser` for better consistency with host.
This line does not need quotes. (nitpick)
Theano -> Theano/TensorFlow
This will remove check for datacenter from line 215 ```suggestion dc_obj = self.find_datacenter_by_name(datacenter_name=self.params['datacenter']) if not dc_obj: self.module.fail_json(msg="Failed to find the datacenter %s" % self.params['datacenter']) objects = get_all_objs(content, vimtype, folder=dc_obj.networkFolder) ```
Why have 2 parameters to set the name or ID, surely we would just want to set the name and not worry about the ID. Is there a benefit to using the ID over the name, if not then this should just be removed.
Why have 2 parameters to set the name or ID, surely we would just want to set the name and not worry about the ID. Is there a benefit to using the ID over the name, if not then this should just be removed.
see previous discussion on renaming idempotently
Simplify, harmonise with yt-dlp pt6: ```suggestion formats = self._extract_m3u8_formats( 'https://b-%s.%s/hls/%d/%d.m3u8' % (server, host, model_id, model_id), video_id, ext='mp4', m3u8_id='hls', fatal=False, live=True) self._sort_formats(formats) ```
Seems like this is better to be; ``` description: - Required unless I(create_mode) is C(default) or C(restore_long_term_retention_backup). - Specifies the resource ID of the source database ``` The point around non_readable_secondary and online_secondary, why must you set the value when you can source it yourself if it is the same as `name`. Also if this is only enacted when the database is created, why would the ID be the same as the new database being created.
see previous discussion on renaming idempotently
Below there are more like this, if you'd care :-)
Why have 2 parameters to set the name or ID, surely we would just want to set the name and not worry about the ID. Is there a benefit to using the ID over the name, if not then this should just be removed.
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
Why have 2 parameters to set the name or ID, surely we would just want to set the name and not worry about the ID. Is there a benefit to using the ID over the name, if not then this should just be removed.
Probably some potential for improved grammar here. > use the equivalent become one instead Maybe something more like: > The %s command line option has been deprecated in favor of the "become" command line arguments
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
You also need to store this into a variable, otherwise you can't use the resulting path.
I'd put `(self._flags['become_success'] or chan.exit_status_ready())` into a `@property` for readability so that it'd look like ```suggestion while not self._cmd_finished: ```
Trivial fix, but it would be good to say 2.12 instead of 2.12.1 here so that we get the latest patch release. There's one other place in the file that also needs to be updated.
This branch is never reached.
so this assertion looks incorrect, i would expect and empty string as the ssh args
also worthy noting, -G won't show actual ssh options used, just those configured
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
nit: it will be hard to keep these arguments up-to-date- with those from `AnsibleModule` if they ever change. Perhaps we could just have `*args, **kwargs` here and pass it to the `AnsibleModule` init call. If unsupported params are passed through, the `AnsibleModule` will fail to initialize.
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
The default should match all jobs.
That makes perfect sense to me.
Lookup plugins run on the controller. The minimum python version for the controller is python 2.6. So str.format() can't use "{}". The easy workaround is to use "{0}" and "{1}" instead.
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
str.join() accepts an iterable. You use a list comprehension which first creates a `list()` in memory and then gets fed to `str.join()`. You can use a generator expression which will gen unwinded by `str.join()` internally without consuming memory for an intermediate list representation. ```suggestion "\t%s - '%s:%s'" % (to_text(p) if p else 'base', str(self), r) for p, r in self.required_by ```
No bare except.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
It seems you are indenting with 8 spaces. It should be 4.
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
missing from docs fragment
Should match the variable registered in the preceding task. ```suggestion spot_price: "{{ spot_prices.ec2_spot_pricing_history.0.spot_price }}" ```
Incredibly unlikely to be a problem, but this should be `>=`. Actually, this is a bit risky anyway because one timestamp is from the driver machine, the other is from the worker machine where the connector is running. (We ntp the workers during setup, so they are reasonably in sync. I can't remember the exact details, but I think we had issues with this previously due to clock skew; iirc it was in code that generated security certs on the host and then tried to use them on the workers.)
unused variable `input_length`
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
Why uppercase? I think the standard is to use lowercase. It's bad practice to pass args through that use * and ** to unpack. Better to be explicit about what arguments are being passed in.
The `bool` type handles more cases than just `yes`. To assign the public_ip variable here to be true/false when provided or None by default, all you should need is to set the default to `None` as below, then assign the variable using: ``` module.params.get('assign_public_ip') ```
I like the fact that you move the potential conversion from text to bytes lower in the call stack, to where the API actually needs a byte string.
That's a good point. Just fix the indentation in that part of the code, then.
```suggestion self._module.fail_json(msg="value must be of type string or dict") ```
it should also check if it can write there
it should also check if it can write there
terms can be a list, not sure if this is being handled correctly
Move data and query into `_download_webpage` call.
strip_jsonp should work here
1. Relax whitespace. 2. default and fatal are not used together. 3. Should not match empty string.
Use `self._parse_json` instead. This also looks very similar to `sources` parsing in `self._parse_jwplayer_data` that should be probably generalized.
It would be nice to return the object you created too: `res['provider'] = self._get_saml_provider(self._get_provider_arn(name))`
You have the 'check_client' function to figure out if the requirements are present, but never actually use it, so the module fails on in import exception. I recommend you place a call in the class init so you dont have to remember to call it in every module.
This isn't compatible with Python 2.4, which is causing it to fail the py24 tests: ``` 2016-08-11 20:25:51 + python2.4 -m compileall -fq -x 'module_utils/(a10|rax|openstack|ec2|gce|docker_common|azure_rm_common|vca|vmware|gcp|gcdns).py' lib/ansible/module_utils 2016-08-11 20:25:51 Compiling lib/ansible/module_utils/cloud.py ... 2016-08-11 20:25:51 File "lib/ansible/module_utils/cloud.py", line 86 2016-08-11 20:25:51 except Exception as e: 2016-08-11 20:25:51 ^ 2016-08-11 20:25:51 SyntaxError: invalid syntax ``` You can use this instead: ``` python except Exception: e = get_exception() ```
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
I don't think you need to return this fixed string on success. Just not returning anything should be fine.
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
You should be able to use `self.vmware_test_platform` here.
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
Glancing over the code, `packages_to_remove` might be a clearer name here- I saw the `packages.remove('setuptools')` below and was like, "wait, I thought we wanted to keep it?!" until I realized what was happening...
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
You should be able to use `self.vmware_test_platform` here.
Okay I think this makes sense, let's just follow this pattern then.
Add a `# Arguments` section to the docstring.
Add a `# Arguments` section to the docstring.
it should also check if it can write there
This should be a character string (prefixed with `u`)
tests now make no sense since they also abused the modification of the setting, we should now check that when the option is 'smart' and network os is set we get the 'right' facts module
`.*` on both ends of regex make no sense. Also when capturing at least one character is required - there is no sense capturing empty video id.
Extraction should be tolerate to missing fields. Everything apart from title and formats considered optional and should not break the extraction if missing.
Also, for posterity: ``` $ ipa --version VERSION: 4.4.0, API_VERSION: 2.213 ```
Also, for posterity: ``` $ ipa --version VERSION: 4.4.0, API_VERSION: 2.213 ```
Wrap `then` and `else` with ` to make the sentence easier to parse.
Wrap `then` and `else` with ` to make the sentence easier to parse.
Must be numeric.
Must be numeric.
same note about not needing to crate another set here with the additional note that you have to reverse the args (since my_arg_names is a set but IncludeRole.FROM_ARGS is not): ``` python for key in my_arg_names.intersection(IncludeRole.FROM_ARGS): ```
```suggestion - name: Install python package using a proxy # Pip doesn't use the standard environment variables, please use the CAPITALIZED ones below ```
```suggestion # require that the final recorded stack state was CREATE_FAILED ```
idk what the maintainers think about this, but I personally think this change is out of the scope of this PR. If this function is desired, it can be added separately. For now, you could just replace `self._match_valid_url(url)` with `re.match(self._VALID_URL, url)` as many other extractors already do.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
a simpler fix i was already working on: `+ display.display(json.dumps(text, cls=AnsibleJSONEncoder, sort_keys=True, indent=4))`
Is it not vim.vApp.PropertySpec ? https://github.com/vmware/pyvmomi/blob/575ab56eb56f32f53c98f40b9b496c6219c161da/docs/vim/vApp/PropertySpec.rst
This probably needs a core review.
Is it not vim.vApp.PropertySpec ? https://github.com/vmware/pyvmomi/blob/575ab56eb56f32f53c98f40b9b496c6219c161da/docs/vim/vApp/PropertySpec.rst
Is it not vim.vApp.PropertySpec ? https://github.com/vmware/pyvmomi/blob/575ab56eb56f32f53c98f40b9b496c6219c161da/docs/vim/vApp/PropertySpec.rst
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
Just an empty line, could be removed for cleaner code
It might also be useful to print login response code to supplement earlier login method debug. white testing this patch I felt login did not go through
You don't need a copy of the list in memory here. Better use a generator expression: ```suggestion versions = (v for v in self.versions if v != '*') ```
eg find type by URL ext
Remove excessive verbosity. This fits well on a single line.
`expected_status` to `_download_json` instead.
You don't need a copy of the list in memory here. Better use a generator expression: ```suggestion versions = (v for v in self.versions if v != '*') ```
Don't use automatic field numbering!
Returning would close the file (I think) since you're already in a 'with' statement.
Returning would close the file (I think) since you're already in a 'with' statement.
Returning would close the file (I think) since you're already in a 'with' statement.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
I really hate that is the case, we never got a real good standard around 'number of v' to use for each case, most connections print all output at 3, winrm is one of the few that goes higher
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Probably the same with `--label` instead of `--uuid` here.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
Just leave it out, we'll think of something later.
The data has to be parsed, and the facts have to be sorted out. Like: * Number of files pending heal. * Number of files to be rebalanced etc based on the data thrown by the heal status. Just dumping the string as is, does not add any value to the facts module. The end user should be able to see particular keys and make any decision. This way, we are shifting the responsibility of parsing the data on the caller.
I would write this all on a single line as: ```python diff = parse_diff(out) if module._diff else {} ```
Typo in the help message
Typo in the help message
Unclear what purpose this line serves.
The point of these conversion interfaces is that old code should still work. So in this case we should figure out a better solution. Please leave out this layer.
I really hate that is the case, we never got a real good standard around 'number of v' to use for each case, most connections print all output at 3, winrm is one of the few that goes higher
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
What are you trying to do here? There should be a single regex.
This makes no sense - you already have it in `url`.
This can be more PEP8 with a '\n': ``` Python class YahooSearchIE(LazyLoadExtractor): _VALID_URL = None _module = 'youtube_dl.extractor.yahoo' @classmethod def suitable(cls, url): return re.match(cls._make_valid_url(), url) is not None @classmethod def _make_valid_url(cls): return 'yvsearch(?P<prefix>|[1-9][0-9]*|all):(?P<query>[\\s\\S]+)' ```
This makes no sense - you already have it in `url`.
This test is basically a copy-paste of the old one. It does exactly the same thing. Instead of making a copy, use `@pytest.mark.parametrize`.
Instead, you can use `return data.get('name')` and it will return None if name is undefined.
This is more efficient: ```suggestion key = next(iter(old[0]) ```
There should be fallbacks for these values since they are more or less static.
There should be fallbacks for these values since they are more or less static.
Remove excessive verbosity. This fits well on a single line.
Remove excessive verbosity. This fits well on a single line.
I would use a different var name, `file` is a builtin within Python. I also don't know anything about Kubernetes but should this path be hard coded.
There should be fallbacks for these values since they are more or less static.
Remove excessive verbosity. This fits well on a single line.
We do want to keep the CIPHER_WRITE_WHITELIST check here for sanity. It could be changed to throw an error, though, as cipher_name should be set in __init__ with your change.
should be self.forward.
Weird. Yesterday it was working: ``` python -m youtube_dl http://mobile-ondemand.wdr.de/CMS2010/mdb/ondemand/weltweit/fsk0/75/752868/752868_8108527.mp4 [download] Destination: 8108527-752868.mp4 [download] 1.4% of 291.34MiB at 8.53MiB/s ETA 00:33 ERROR: Interrupted by user ``` But not now.
Avoid spaces in regular expressions. See rutube.py for an example.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
As you've noticed, we don't want to do this here because in this case the pkg_mgr is coming from a pre-existing fact.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
The regexp can be problematic when the json payload contains ";", for example the anime title can be "Dat Girl;ï¼". In this case the matched result is not a valid json string.
Actually, it's an opposite. It's a check for successful login.
Should not break if no `type`.
Could you please dedent everything below including this line? There's no point in keeping it inside of context manager block, which _may_ swallow some types of exceptions.
I don't think you need to return this fixed string on success. Just not returning anything should be fine.
Breaks if no tags or it's not a string.
I feel like this changes too much, for what could be achieved with less: ```diff diff --git a/lib/ansible/plugins/callback/json.py b/lib/ansible/plugins/callback/json.py index 3961a78aab..fd344a0cf0 100644 --- a/lib/ansible/plugins/callback/json.py +++ b/lib/ansible/plugins/callback/json.py @@ -101,14 +101,16 @@ class CallbackModule(CallbackBase): summary[h] = s custom_stats = {} + global_custom_stats = {} if self.get_option('show_custom_stats') and stats.custom: custom_stats.update(dict((self._convert_host_to_name(k), v) for k, v in stats.custom.items())) - custom_stats.pop('_run', None) + global_custom_stats.update(custom_stats.pop('_run', {})) output = { 'plays': self.results, 'stats': summary, 'custom_stats': custom_stats, + 'global_custom_stats': global_custom_stats, } self._display.display(json.dumps(output, indent=4, sort_keys=True)) ```
Breaks if no tags or it's not a string.
Breaks if no tags or it's not a string.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Fix indent. Use `pylint` as linter.
Fix indent. Use `pylint` as linter.
It's all very confusing, and `Convolution2D` wasn't doing great on that front either. Here I think we should refer to the kernel dimensions as `kernel_dim*` and to the target tensor dimensions as `conv_dim*`.
```suggestion raise AnsibleError('Invalid setting identifier, "%s" is not a string, it is a %s' % (term, type(term))) ```
Better to add `rank` here
Duration calculation is incorrect.
Note that this is also being removed in https://github.com/ansible/ansible/pull/68560
both are valid tests, i don't see why you need to eliminate the existing one
both are valid tests, i don't see why you need to eliminate the existing one
```suggestion self.module.fail_json(msg="Invalid end VLAN ID %s." % vlan_id_end) ```
Better to add `rank` here
Better to add `rank` here
Better to add `rank` here
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
Another option is to use `threading=True` or `use_threads=True`
`start_time` may be `None` at this point.
This line should be right after `"""`. Put "`" around function names.
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Another option is to use `threading=True` or `use_threads=True`
`start_time` may be `None` at this point.
no, if the variable is set but empty, you should empty out the options
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
Better to add `rank` here
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
You can simply use `webpage = self._download_webpage(url, video_id)` here.
Real id is in widget dict.
Change to 0.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This needs to go outside of CM. If `ipsubnet` will raise exception it will interrupt code block within `with`.
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
Having an import in a test function is not the best idea since it mutates the whole test runtime process. You'd probably need to do the whole test in a subprocess to properly isolate it.
What is your TF version? Here you are taking a slice, which as far as I can tell breaks shape inference and causes the following code to fail. A workaround is to manually set the shape of the slice. This may not be the case with the latest TF version. Unclear
What is your TF version? Here you are taking a slice, which as far as I can tell breaks shape inference and causes the following code to fail. A workaround is to manually set the shape of the slice. This may not be the case with the latest TF version. Unclear
We can reduce the level of indents: ```python elif option == 'test': elif option == 'retries': else: result[option] = self.healthcheck.get(option) ``` And I don't thinks someone will be bored enough to specify a `test: ""` to get into the `elif self.healthcheck.get(value): ` check
Move data and query into `_download_webpage` call.
`url` is not a video id.
So removed `required=False` and add `type='str' instead. Do this for the others as well.
So removed `required=False` and add `type='str' instead. Do this for the others as well.
So removed `required=False` and add `type='str' instead. Do this for the others as well.
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
It should always return a list.
Use the function defined earlier: ```suggestion mobj = _get_element_by_tag_and_attrib(html, tag='a') ```
Well, basically that's the problem of these people not us. We don't care whether one can read regexp or not. Moreover most likely next time this code is read by someone is when extractor breaks due to layout change. Chances are this snippet is already irrelevant by that time.
This should be `b_output_path` to indicate it is a series of bytes. Even if the caller is sending in bytes, this function should convert it to bytes just like `b_collection_path` at the beginning. That allows our `b_` naming convention to hold, making this code look incorrect (trying to join `bytes` and `str`).
This breaks under quite a few circumstances: 1. With `%(episode_number)d` when there is no episode number, etc (gives NA in filename) 2. `%(playlist_index)s` doesnt pad like it does in filename 3. `--autonumber-start`, `--output-na-placeholder` etc won't work etc Generalizing code with `prepare_filename` (splitting out only the sanitization) will avoid these issues
This should be `b_output_path` to indicate it is a series of bytes. Even if the caller is sending in bytes, this function should convert it to bytes just like `b_collection_path` at the beginning. That allows our `b_` naming convention to hold, making this code look incorrect (trying to join `bytes` and `str`).
this is an unsafe way to update the file, it can lead to data corruption and other processes reading incorrect/incomplete data. write to a tmp file and use atomic_move from basic.py
We should be able to merge the two cases with something like this? ``` if collections is None and collection_from_task: collections = [collection_from_task] ``` Now `collections` is either the non-None contents of `collections`, or the task's collection, or `None` if neither exist, which means we can drop the `collections` check from the `all()`s and just use `collections` regardless
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
it should also check if it can write there
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
```suggestion # just get value from attribute itself as normal ```
```suggestion # just get value from attribute itself as normal ```
No. Empty download URL is pointless.
Do not remove old patterns.
+1 this isn't used anywhere
+1 this isn't used anywhere
I've already pointed out: I won't accept this.
I would add an additional check here to catch syntax errors like `-f 'bestvideo,,best'`. ``` python if not current_selector: raise syntax_error('Expected a selector', start) ```
well, not die with unexpected exception .. tempted to say there is no real reason the type should be incorrect for any keys. So ending in an error should be fine, just not an unhandled one.
Another map that can be a list comprehension: ``` content = [x.strip() for x in m.group(3).split(" and ")] ```
Simple string concatenation is enough here.
May be None.
May be None.
Experimenting here shows that salt must be ascii-only text-type on python3. password can be either text or bytes on both python2 or python3. I'd suggest: ``` python # passlib allows either text or byte strings for password but salt must be ascii-only text on python3 encrypted = cls.encrypt(to_text(password, errors='surrogate_or_strict'), salt=to_text(salt, errors='surrogate_or_strict')) ```
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
Experimenting here shows that salt must be ascii-only text-type on python3. password can be either text or bytes on both python2 or python3. I'd suggest: ``` python # passlib allows either text or byte strings for password but salt must be ascii-only text on python3 encrypted = cls.encrypt(to_text(password, errors='surrogate_or_strict'), salt=to_text(salt, errors='surrogate_or_strict')) ```
Do this as a oneline instead: `return camel_dict_to_snake.....` no need to assign.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
My personal preference on this and the `self.no_log_values.update` is that we should make `list_no_log_values` and `list_deprecations` always return the correct type (which it looks like they may already), then you can just do: ``` self.no_log_values.update(list_no_log_values(spec, param)) self._deprecations.extend(list_deprecations(spec, param)) ``` This would remove 6 lines that are unnecessary.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
I'm curious why it's necessary to pass the loader in this case (and the others in thise PR)? I was under the impression that `shared_loader_obj` was no longer needed.
Preference would be for a unit test to be mocked sufficiently that a cleanup like this is not required. However, in this case if that involves a large amount of fragile mocking, I wouldn't worry about it now as having test coverage is better than not having it, even if it is a little messy.
Passing `sys.argv[:]` here is useless wrt current implementation. If you look at the `main()`'s first three lines there's: ```python def main(args): ... (options, args) = parser.parse_args() # <-- immediatelly rewrites args variable ``` It looks like the initial implementation has been written by the person with some C-like background, where main accepts args data and returns 0. But in fact in this case it's not needed. Please remove this arg.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Preference would be for a unit test to be mocked sufficiently that a cleanup like this is not required. However, in this case if that involves a large amount of fragile mocking, I wouldn't worry about it now as having test coverage is better than not having it, even if it is a little messy.
not sure why you moved all the code to _version ... why not keep here? seems like useless jump
May be None.
Again: ```suggestion {'ids': '[{0}]'.format(song_id), 'br': bitrate, 'header': cookie}, separators=(',', ':')) message = 'nobody{0}use{1}md5forencrypt'.format( URL, request_text).encode('latin1') ```
It would be more pythonic to write this as `self.chassis_uri_list = [ch["@odata.id"] for ch in response["data"]]`.
Also, it's a classical property. Refactor it in a more elegant way: ```python @property def valid(self): try: return os.path.getmtime(self.file) + self.max_age > time() except IOError: return False ``` P.S. When reusing this snippet, please add the trailer to the long commit description: ``` Co-authored-by: Sviatoslav Sydorenko <wk@sydorenko.org.ua> ```
Remove excessive verbosity. This fits well on a single line.
May be None.
@chouseknecht makes sense. Also, as a first iteration, this is already good so I wouldn't stress it to find a better abstraction at this stage. I think once this module matures, we can start thinking about splitting some of this logic.
For clarity -- in this PR, currently int(1.9) ==> 1 and int("1.9") ==> TypeError
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
For clarity -- in this PR, currently int(1.9) ==> 1 and int("1.9") ==> TypeError
Please use a parameterized pytest test instead of this pattern. Example: https://github.com/keras-team/keras/blob/master/tests/keras/layers/convolutional_test.py#L21
maybe we should have a constant somewhere with _source and _ingest? pretty sure we already use them somewhere else
Bravo on tackling one of the gnarlier test setups ;-> :+1:
It would be awesome if buildah supported copying from a container.
Bravo on tackling one of the gnarlier test setups ;-> :+1:
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Instead of `list`, use `Sequence`. Similarly, replace `dict` above by `Mapping`. (You'll need `from ansible.module_utils.common._collections_compat import Mapping, Sequence` to be able to do that.)
Instead of `list`, use `Sequence`. Similarly, replace `dict` above by `Mapping`. (You'll need `from ansible.module_utils.common._collections_compat import Mapping, Sequence` to be able to do that.)
return dict((key, self.get(key)) for key in self.keys())
Instead of `list`, use `Sequence`. Similarly, replace `dict` above by `Mapping`. (You'll need `from ansible.module_utils.common._collections_compat import Mapping, Sequence` to be able to do that.)
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
None of the optional metadata should break the extraction.
Please add check-mode support (and if possible also diff support).
also worthy noting, -G won't show actual ssh options used, just those configured
The result of this: `- apt: clean=yes package=whatever state=installed` would be that 'whatever' is ignored and user gets told 'all ok and changed', this is misleading. while 'upgrade' goes through many hoops to ensure compatibility with others states/info (too many IMHO, i would simplify this a lot)
s/write target file {0}/fetch file to {0}/
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
return dict((key, self.get(key)) for key in self.keys())
And this `self._cache.set(self.cache_key, {url: ''})`
Shouldn't this be using `.get()` ```suggestion inventory = self._cache.get(self.cache_key)[url] ```
return dict((key, self.get(key)) for key in self.keys())
You don't need a lambda here. Also, don't break lines with `\`.
You don't need a lambda here. Also, don't break lines with `\`.
I don't think it's messy, just wanted to make sure.
This parameter is required according to the docs. But I see that either cert_url or cert_path is required. Maybe the docs should make this more clear. I would add it to the description of both options, and maybe add a separate note as well.
This parameter is required according to the docs. But I see that either cert_url or cert_path is required. Maybe the docs should make this more clear. I would add it to the description of both options, and maybe add a separate note as well.
This parameter is required according to the docs. But I see that either cert_url or cert_path is required. Maybe the docs should make this more clear. I would add it to the description of both options, and maybe add a separate note as well.
This parameter is required according to the docs. But I see that either cert_url or cert_path is required. Maybe the docs should make this more clear. I would add it to the description of both options, and maybe add a separate note as well.
This parameter is required according to the docs. But I see that either cert_url or cert_path is required. Maybe the docs should make this more clear. I would add it to the description of both options, and maybe add a separate note as well.
I think this should be replaced with `K.epsilon()`.
If either of these attrs is missing whole playlist extraction is broken.
Maybe just `_` prefix `warnings`on `ValidationResult` for now? This definitely doesn't seem like it'd be generally useful as-is, and we'd almost certainly have to restructure it later to create actual warning objects if we have more than one (rather than a list of dicts).
Playlist metadata must not be fatal.
It would be awesome if buildah supported copying from a container.
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
Note for us: Before merging, switch this to the new #980 structure, i.e. `formats` entry consisting only of url+format+ext. All further listformats or selection business can be removed as well.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
Move flags into regex.
Move flags into regex.
`expected_status` to `_download_json` instead.
Now you break extraction if any of these keys is missing.
Now you break extraction if any of these keys is missing.
Code duplication. `url` must not be `None`.
Now you break extraction if any of these keys is missing.
`normalize_interfaces` is aimed at sanitizing user input, and seems to be redundant while parsing running-config where the interface names are already normalized.
You'll need ```BostonGlobeIE``` in ```bostonglobe.py```
```suggestion for b_path in b_colldirs: ```
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Playlist metadata must not be fatal.
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
Similarly, ```if tc['skip'].get('i')```
Just an empty line, could be removed for cleaner code
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
It would be awesome if buildah supported copying from a container.
Read coding conventions on optional fields.
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
Why not pass `check_mode` into `exec_sql` and let it (if set to `True`) simply not execute the command? Then you don't have to repeat the pattern `if not check_mode: / exec_sql(...) / else: / self.executed_queries.append(...)` all over the module.
Use `with open(` instead of `open(`
Read coding conventions on optional fields.
`E226 missing whitespace around arithmetic operator`.
In general argument_specs should be returned to the caller rather than subclassing AnsibleModule just to add it. AnsibleModule's behaviour could change in the future and subclassing makes it more likely that things would break than if you are simply passing an arg_spec to the module which it then uses to instantiate an AnsibleModule.
1. Breaks if div is not found. 2. `re.finall`.
[PEP 8](https://www.python.org/dev/peps/pep-0008/#pet-peeves): Remove extra space: `inv.update({env: []})`
I learned recently that you can use actual separate literals to improve readability: ```suggestion @pytest.mark.parametrize(['url', 'expected'], [ ```
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
IMO no need to. Each step is idempotent, we failed to reach desired state but we got closer. But mostly, it's just easier ;-)
Remove loop. Add a method extracting meta data by name, call it for each meta field separately.
as discussed previously, no such thing "alert policies". every mention of "policy/ies" should be renamed...
You appear to have dropped `Element`
IMO no need to. Each step is idempotent, we failed to reach desired state but we got closer. But mostly, it's just easier ;-)
It is also OK as-is if you like it; I just wanted to make it clear you don't *have* to obey the consistency if you see a better way. [I think I was in a bike-shedding mood when I did this review... Feel free to push back :-)]
"new" may sound as "to be added", suggest "desired" instead.
just a small typo, serached->searched
I'd probably add `distribution_parts = []` after yield inside of `if` block and then you'd only need `distribution_parts.append(name)` outside of if-block without a need to have diverse code or `else`-block.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
I'd probably add `distribution_parts = []` after yield inside of `if` block and then you'd only need `distribution_parts.append(name)` outside of if-block without a need to have diverse code or `else`-block.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
`postInfo` contains far more metadata that should also be extracted. Consider [this](https://github.com/taichatha/youtube-dl/blob/master/youtube_dl/extractor/common.py#L63-L198) for a set of relevant fields.
Parse from flashvars JSON.
Experimenting here shows that salt must be ascii-only text-type on python3. password can be either text or bytes on both python2 or python3. I'd suggest: ``` python # passlib allows either text or byte strings for password but salt must be ascii-only text on python3 encrypted = cls.encrypt(to_text(password, errors='surrogate_or_strict'), salt=to_text(salt, errors='surrogate_or_strict')) ```
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
`query` is unset when `ext_exists` returns `True`.
This could be problematic. If you set the seed to a constant and use multi-processing then all children processes would share the same seed and you'll get batches with repeated samples.
f is already at 0, the `truncate()` is uselesss.
Check for `embed_code` instead.
The number of batches in the Sequence
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Indeed, or you can just increment the input seed for each new process.
supporting snapmirror-label would affect this logic, are only one of the two could be present, or both of them.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
supporting snapmirror-label would affect this logic, are only one of the two could be present, or both of them.
supporting snapmirror-label would affect this logic, are only one of the two could be present, or both of them.
I don't believe this parameter should exist. I believe we should rely on the ability for libraries to use environment variables for `http_proxy` and `https_proxy`. Both `ansible.module_utils.urls` and `requests` can both utilize these environment vars. Setting these values via the `environment` keyword on a task is accepted. The module should not have a deviating method for applying proxies.
supporting snapmirror-label would affect this logic, are only one of the two could be present, or both of them.
enumerate is not needed here. i is not used
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
```suggestion self._module.fail_json(msg=("An error occurred trying to get the ADOM Lock Info. Error: " + to_text(resp_obj))) ```
it should also check if it can write there
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
```suggestion Test that the returned value for timezone consists of only uppercase ```
It probably makes sense to test that the exception reason also matches expectations
that still happens no matter what info you pass to the module ... unsure how removing this info for the module to CHOOSE to share the dir is a simplification. Speaking of the end user, we CAN show them the tempdir being used since that info is available on the controller, but not when the module itself generates it (and many do).
provisioning_state is readonly as well, so let's remove it from parameters
this should not be None, it should already have resolved to the configured system_dirs, so should be changed anyways
No need to parametrize with just one case.
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
provisioning_state is readonly as well, so let's remove it from parameters
Raise `AnsibleCallbackError`, which can be imported from `ansible.errors`.
Raise `AnsibleCallbackError`, which can be imported from `ansible.errors`.
I like host_label()
```suggestion Test that the returned value for timezone consists of only uppercase ```
```suggestion assertEquals(0L, JoinWindows.of(ofMillis(DEPRECATED_OLD_24_HR_GRACE_PERIOD)).gracePeriodMs()); assertEquals(0L, JoinWindows.of(ofMillis(DEPRECATED_OLD_24_HR_GRACE_PERIOD + 1L)).gracePeriodMs()); ```
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
This ignores additional keyword arguments possibly passed by the user.
Just leave it out, we'll think of something later.
Currently IEs are randomly sorted. I guess sorted IE names make `lazy_extractors.py` look better.
no need to specify required=False or type=str as these are defaults
This whole block should be changed into: ```python module = AnsibleModule( argument_spec=dict( name=dict(type='str', required=True), remote=dict(type='str'), state=dict(type='str', default="present", choices=['absent', 'present']) ), supports_check_mode=True, ) ``` Assuming that **name** is always required, and **repo** is required when **state == 'present'**. - Put the type-option first, as this one is usually always added - Lines in Ansible can be 160 chars wide, so there's usually no need to split it a line
I can't think of any reason off the top of my head that we'd need to customize the module object creation, so just having create_module return `None` *should* be fine. IIRC `exec_module` is literally just about populating the module (already created by create_module or the base import machinery) from the code; the 3.x import machinery takes care of the transactional insertion/removal from `sys.modules` on fresh imports and reloads, so we should probably never mess with that in the 3.x loader code at all. It's been awhile, but I think it basically just calls create_module (and does the stock creation if we didn't return something), provisionally inserts the module to `sys.modules`, calls exec_module under an exception handler, and removes the module on an error if it inserted it.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
I think he's suggesting a second error handler- currently this fall-through would be used for both "you tried to exec_module something that wasn't ansible.module_utils.basic" (for which the current message is fine), but also the case where the for loop completed without finding basic (in which case the error message will be incorrect and confusing). Basically just add an `else` clause to the end of the `for path in convert...` loop that raises a different ImportError that we couldn't find basic.
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
Another option might be to build it the way we wish it were, then start a deprecation warning cycle on this bridging behavior (eg, do something like this and/or input inspection with an explicit optin/optout in plugin metadata, decorator, or whatever, then issue a dep warning on the exception catch or undefined inputs for plugins that haven't explicitly opted into receiving them). :shrug:
Why not just not set a 'default' for the Option() if the goal is to ignore the default value? Or set the default to an empty container as unfrack_paths intends. Then the callback doesn't need to care about the default
In any case, this PR is a great addition for Keras, thank you!
Missing HostedZoneId here which is important if you want to set a route53 ALIAS record later
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
```suggestion type: list entries: str ```
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
```filename, file_extension = os.path.splitext('/path/to/somefile.ext')```
Since Ansible subscribes to unicode sandwich, this should be the callers' (actually, where the data enters the system) responsibility.
What is the reason for reordering all these parameters? This breaks `blame` attribution for these lines & doesn't improve the code.
catchall exception handling is generally not a good idea as it neither gives a better user message nor aids in debugging. If you feel you must do it this way, be sure to return the stacktrace (retrieve that using raceback.format_exc() and put it into the exception parameter to fail_json).
How about this - ```suggestion msg = "No corresponding incident" if len(incidents) == 0: if state in ('acknowledged', 'resolved'): return msg, False return msg, True elif state != incidents[0]["status"]: return incidents[0], True return incidents[0], False ```
How about this - ```suggestion msg = "No corresponding incident" if len(incidents) == 0: if state in ('acknowledged', 'resolved'): return msg, False return msg, True elif state != incidents[0]["status"]: return incidents[0], True return incidents[0], False ```
If we decide to deprecate, then we should have additional logic to detect that the action came in via _raw_params rather than name and issue a deprecation warning. However, we may want to do this via a "long deprecation cycle" which we've talked about the need for but haven't nailed down any rules for yet.
```None if 'globals' not in test else test['globals']``` => ```test.get('globals')```
Maybe think about doing: ``` '-o', 'self.output', '-d', 'self.delimiter', ] ``` instead, this is a very long list, and making these changes is likely to make it more readable.
AnsibleAWSModule has a function to check boto3/botocore versions you can use here. ```suggestion return len(load_balancers) > 0 and self.module.botocore_at_least('1.9.0') ```
this is not a safe across py2 and py3, use the provided `string_types` instead ... but better yet, jsut define the option as type: list and this will be automatically handled for you. Single element, comma separated string and 'actual list' will all be normalized so you always get 'a list'.
AnsibleAWSModule has a function to check boto3/botocore versions you can use here. ```suggestion return len(load_balancers) > 0 and self.module.botocore_at_least('1.9.0') ```
No need to escape whitespace.
What's the point changing old time-proven regexes with another ones? That's not an improvement.
I'm pretty sure this can use `is_sequence()`.
`User has been created`
I'm pretty sure this can use `is_sequence()`.
no need to specify required=False or type=str as these are defaults
I'm pretty sure this can use `is_sequence()`.
no need to specify required=False or type=str as these are defaults
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
I'm pretty sure this can use `is_sequence()`.
`User has been created`
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
`vrtvideo` should be hardcoded.
We talked on IRC. For other people looking for the information, subprocess.Popen.communicate() returns str type on python 2 which are bytes. On Python 3, it returns bytes type which also represents bytes. We'd only need to use to_bytes here if communicate() was returning the unicode type on python 2 or the str type on python3.
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
The next `if` should come first. The module should die if not all DBs exists no matter whether it's in check mode or not.
Should not `cursor.close()` be always called ? `close` is not called when an exception occurs.
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
Maybe have it as `default=True`? Imo it won't have any impact on searches using `host_name` and will prevent duplicate responses when using `host_ip` if it has more than one host interface.
Maybe have it as `default=True`? Imo it won't have any impact on searches using `host_name` and will prevent duplicate responses when using `host_ip` if it has more than one host interface.
1. `v` may not be dict. 2. `v.get('slug')`.
1. `v` may not be dict. 2. `v.get('slug')`.
Situations where the v6 string in question doesn't actually specify a port, e.g., 2001:db8:0:1 See: ``` def test_parse_ip_host_and_port_v6_with_brackets ```
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
no need to specify required=False or type=str as these are defaults
no need to specify required=False or type=str as these are defaults
requiring this as a dict and not using suboptions nor no_log makes the connection password too exposed.
no need to specify required=False or type=str as these are defaults
`User has been created`
[textwrap.dedent](https://docs.python.org/2.7/library/textwrap.html?#textwrap.dedent) could be used here.
`User has been created`
When `password` is not specified (this is a requirement for MIQ external auth) what get's passed to the MIQ API? Seem like it should test `password is not None` before building the json.
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
terms can be a list, not sure if this is being handled correctly
`User has been created`
terms can be a list, not sure if this is being handled correctly
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
No. Use `smuggle_url` if you need to pass some additional attribute.
required=False is default so no need to add.
I like this
Sorry, I think we had a misunderstanding when we talked earlier. I don't think we should be raising unless we add more exceptions so that we can tell why an exception occurred (right now, we'd have to catch the AnsibleError and then parse the message to tell why we failed.) raise_on_error is bad API. The API should either raise whenever there is an error or let the caller discriminate. Passing in a flag to tell the function to raise isn't meaningful. If we start raising an error, then we have to audit the code and decide what the failure case means in the present code. If the code doesn't depend on it (or works in some scenarios) then we probably have to replicate that behaviour instead of changing to always failing.
required=False is default so no need to add.
required=False is default so no need to add.
```suggestion # just get value from attribute itself as normal ```
Also, you can do ```python lv_type=dict(default='jfs2'), # ...snip... opts=dict(default=''), ```
```suggestion # just get value from attribute itself as normal ```
Also, you can do ```python lv_type=dict(default='jfs2'), # ...snip... opts=dict(default=''), ```
Also, you can do ```python lv_type=dict(default='jfs2'), # ...snip... opts=dict(default=''), ```
```suggestion # just get value from attribute itself as normal ```
i cannot imagine people look at deprecated files first for examples ...., but they do see changes to them and then try to use those to justify subsequent changes.
You are right, looking at kernel source, 'unknown' is a valid option for duplex (http://elixir.free-electrons.com/linux/v4.12-rc6/source/net/core/net-sysfs.c#L236 for example)
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Remove this line.
I'd go for underlining.
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
Use `self.url_result(inner_url, 'Generic')` instead.
`result` is empty and no capability is returned. Is this expected? You might want to call `get_device_info` here to get the device capabilities.
Use `self.url_result(inner_url, 'Generic')` instead.
Just an empty line, could be removed for cleaner code
This won't work for a Sequential model. I'd recommend separating the two cases (graph / sequential) entirely, for clarity.
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You can just `return` without `else`.
Got it. But this is very confusing error message. anyways, not a blocker as such.
```suggestion elif date_string.match(self.when): ```
```suggestion elif date_string.match(self.when): ```
I'd recommend changing `'{0}'` and `'{2}'` to use double quotes instead of single. `repr` usually gives single quotes, and as such you end up with something like: ``` was converted to 'password: '********'' (type string) ```
You've forgot to pass `info_dict` to `supports()`.
I'm not sure about these defaults - a delay of 3 and backoff of 2 for 10 tries would mean that, to fail, this retry decorator would wait for 3069 seconds (`3 + 3*2 + 3*2*2 ....`, or `sum([3 * 2**i for i in range(10)])`) or about 50 minutes. That seems like a really long time, especially since most modules make several calls. A better default might be 4 tries, for a total default wait time of 45 seconds and having a max of, say, a minute between tries. That way, if someone wanted 10 tries it would only take about 7.5 minutes to fail.
When we have an m3u8 download and no ffmpeg installed we'll get unhandled exception and crash with a traceback. Previously there were an additional check before this line that has been reporting an error and returning quietly so that `check_version()` were never reached thus no unhandled exception. For now lets just restore it and later think how to move these checks outside actual downloading routines to phase when we select downloader.
You've forgot to pass `info_dict` to `supports()`.
this looks like preexisting issue, the lookupfile's dirname should always be in searchpath
My bad. Could you please add this to vmware.py
Same as for other modules, use `Group has been updated`
This syntax is not supported in python2.6. You will need to index your format like {0}
This syntax is not supported in python2.6. You will need to index your format like {0}
This syntax is not supported in python2.6. You will need to index your format like `{0}`
Syntax error? ```suggestion from ..announce import create_short_message, create_long_message # pylint: disable=relative-beyond-top-level ```
It should always return a list.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
Please remove this example, since I would consider this usage as not recommended.
You can use tuples; supported_resolutions won't be changed
`return not owner or owner == publication_info['owner']` could be used.
Here be dragons. I don't see check-mode being tested anywhere in the module. So I expect the module to perform a reboot in check-mode. Probably not what people expect.
``` config['depthwise_initializer'] = initializers.serialize( self.depthwise_initializer) ```
This should be regular text. ```suggestion - Creates or destroys a data migration services subnet group. ```
Maybe rename this to substitute_crypto_req since it's replacing the one from requirements.txt with the one we autodetect rather than simply appending.
```suggestion # just get value from attribute itself as normal ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
connection plugins should not have their own python logic. If distros are using different python/missing python it is up to user to add (plenty of examples with raw and ansible_python_interpreter).
Since only `ImportError` is being handled here, use this instead: ```python try: ec2 = pytest.importorskip("ec2") finally: # rest of code here ``` That way the tests will be properly skipped if the import isn't available.
json is a subset of yaml so it is most likely to be loaded here even if it was json to begin with, but pyyaml parser can introduce some differences, you might want to reverse the order.
I'd go for underlining.
I made i mistake in the original code here already. Line must be ``` python self._fail('login', info['msg']) ```
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
Oh, I misread this. I thought it was returning the path not the result of an evaluation. I tend to try and avoid `lambda` at all costs (harder to read/maintain usually), but I don't see a better way to write the test.
Oh, I misread this. I thought it was returning the path not the result of an evaluation. I tend to try and avoid `lambda` at all costs (harder to read/maintain usually), but I don't see a better way to write the test.
Oh, I misread this. I thought it was returning the path not the result of an evaluation. I tend to try and avoid `lambda` at all costs (harder to read/maintain usually), but I don't see a better way to write the test.
Oh, I misread this. I thought it was returning the path not the result of an evaluation. I tend to try and avoid `lambda` at all costs (harder to read/maintain usually), but I don't see a better way to write the test.
Rather than hardcode "/redfish/v1/UpdateService", better to read the value of the "@odata.id" property from the "UpdateService" property.
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
you don't need to say `testcase failed`, it's obvious from testrunner's indication
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
I'll submit something soon
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
This is in the test suite, and in the test suite, warnings are an error of us, aren't they? So why isn't the implementation ``` raise Exception(message) ```
```suggestion error_msg = "Can't find the device based on label, UUID or name. " \ ```
```suggestion error_msg = "Can't find the device based on label, UUID or name. " \ ```
Remove excessive verbosity. This fits well on a single line.
Move to the L416's dict construct is OK, no need another conditional check
In case this pattern is used in other modules as well, moving it into `exec_sql` is probably a good idea. Also, adding a new argument to `exec_sql` with a default value shouldn't affect the other users.
If you like, something like this can be redone as `if protocol in ('tftp', 'ftp', 'sftp', 'scp'):`
should be handled someway in `js_to_json`, at least add a `TODO` to indicate that this should be fixed in a general way.
should be handled someway in `js_to_json`, at least add a `TODO` to indicate that this should be fixed in a general way.
else is unnecessary here because we raise an exception before
You are not tracking timeout per child with this code. The time you're recording here is when you ask the library to queue the work.... It's not when the work starts. Therefore, you might as well save a single general timeout at the top of the method.
You are not tracking timeout per child with this code. The time you're recording here is when you ask the library to queue the work.... It's not when the work starts. Therefore, you might as well save a single general timeout at the top of the method.
Title part should be optional.
Title part should be optional.
The various `CALLBACK_` prefixed class attributes are missing. Take a look at the other callbacks for an example. In particular, this is needed: ``` python CALLBACK_NEEDS_WHITELIST = True ```
The various `CALLBACK_` prefixed class attributes are missing. Take a look at the other callbacks for an example. In particular, this is needed: ``` python CALLBACK_NEEDS_WHITELIST = True ```
All modules in VMware space uses Jinja variables like the current implementation. I would stick to this naming scheme as this will make all modules same and readable. Adding arbitary values does not make sense to me.
All modules in VMware space uses Jinja variables like the current implementation. I would stick to this naming scheme as this will make all modules same and readable. Adding arbitary values does not make sense to me.
The various `CALLBACK_` prefixed class attributes are missing. Take a look at the other callbacks for an example. In particular, this is needed: ``` python CALLBACK_NEEDS_WHITELIST = True ```
The various `CALLBACK_` prefixed class attributes are missing. Take a look at the other callbacks for an example. In particular, this is needed: ``` python CALLBACK_NEEDS_WHITELIST = True ```
This existence check executes on the ansbile controller, e.g 'your workstation', while the remote_tmp happens on the target machine, e.g 'webserver'. Even if this was being executed on the correct machine you would still have a race condition between check and creation. In any case, I already have a code change that fixes this correctly and it will soon be a PR.
note: You can combine these loops to be more efficient: ``` python ppaths = [p for p in ppaths if not p.endswith('/ansible_modlib.zip') and not p.endswith('/debug_dir')] ```
`default=None` is the default, it's not required.
When using pytest, create top-level functions without using a class.
note: You can combine these loops to be more efficient: ``` python ppaths = [p for p in ppaths if not p.endswith('/ansible_modlib.zip') and not p.endswith('/debug_dir')] ```
this is checking the directory on the controller, not on the remote
From our triage meeting, we all found we were confused by this line. Making it more verbose will likely make it easier to understand.
You can just use 'playlist_count'
This line is too long. Max line length allowed in Ansible is 120 characters.
This won't work in case of live HLS WebVTT streams because you constantly get new subtitle segments at the same playlist URL. It's a shame X-TIMESTAMP-MAP support patch hasn't been merged to ffmpeg yet after 3 years, but in my use-case (vlive.tv) it's not required, so dumping HLS WebVTT via ffmpeg works quite good.
`try` block should contain fewer statements. `Exception` should be replaced with a more precise exception type.
You can import `try_rm` from helper
This line fails for me trying to run Ansible under Python3 - `response.headers` is there, but there is no `getheader` method. I don't know the internals of what is returned from `open_url` but I can call `get` on it and it works for both Python2 and Python3: ``` fatal: [127.0.0.1]: FAILED! => { "msg": "An unhandled exception occurred while running the lookup plugin 'manifold'. Error was a <class 'ansible.errors.AnsibleError'>, original message: ['Traceback (most recent call last):\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 226, in run\\n team_data = client.get_teams(team)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 166, in get_teams\\n data = self.request(api, endpoint)\\n', ' File \"/Users/dave/work/src/ansible-test/ansible/lib/ansible/plugins/lookup/manifold.py\", line 113, in request\\n if response.headers.getheader(\\'content-type\\') == \\'application/json\\':\\n', \"AttributeError: 'HTTPMessage' object has no attribute 'getheader'\\n\"]" } ```
Then use `enumerate()` instead.
Then use `enumerate()` instead.
If it's not found you will try extracting from 404 page. Remove all this 404 mess.
this would be equivalent of `if '-' in md5_remote:` since `etag_multipart` is never used other than this conditional.
You can do `return pg.paginate(Bucket=bucket).build_full_result()` Not a blocker though
Lists also have .extend() which might be what you need here
You can add required=True here too and remove the check below.
Better to put the activation as the `activation` keyword of the layer below
Do you have any references for the inline if being discouraged? If you don't like the inline if, then I'd go with the normal if block.
`# Returns `
same as others, return directly test
Please avoid capital letter variables (`X`) and add a docstring (same as the TF backend should be fine).
Try using `six.reraise()` here so that under py3 it'd show the previous exception trace
Change to 0.
``` >>> re.match(r'/(?=[^*])[^/\n]*/[gimy]{0,4}', r'''/\/\/\//''') <_sre.SRE_Match object; span=(0, 3), match='/\\/'> ```
``` >>> re.match(r'/(?=[^*])[^/\n]*/[gimy]{0,4}', r'''/\/\/\//''') <_sre.SRE_Match object; span=(0, 3), match='/\\/'> ```
``` >>> re.match(r'/(?=[^*])[^/\n]*/[gimy]{0,4}', r'''/\/\/\//''') <_sre.SRE_Match object; span=(0, 3), match='/\\/'> ```
Why include the `.` in the character groups? `[\w.]` is the same as `[.]`- and allows lots of things we don't want...
``` >>> re.match(r'/(?=[^*])[^/\n]*/[gimy]{0,4}', r'''/\/\/\//''') <_sre.SRE_Match object; span=(0, 3), match='/\\/'> ```
These 2 regexes ought to be merged, though maybe not in the scope of this PR: ``` r'(?:\b|[^a-zA-Z0-9$])(?P<sig>[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\)(?:;[a-zA-Z0-9$]{2}\.[a-zA-Z0-9$]{2}\(a,\d+\))?', ```
```/tv/tags/[^/]*?``` => ```/tv/tags/[^/]+```
```suggestion r'(?:\b|[^a-zA-Z0-9$])(?P<sig>[a-zA-Z0-9$]{2,})\s*=\s*function\(\s*a\s*\)\s*{\s*a\s*=\s*a\.split\(\s*""\s*\);[a-zA-Z0-9$]{2,}\.[a-zA-Z0-9$]{2,}\(a,\d+\)', ``` This works for me.ð
``` >>> re.match(r'/(?=[^*])[^/\n]*/[gimy]{0,4}', r'''/\/\/\//''') <_sre.SRE_Match object; span=(0, 3), match='/\\/'> ```
Why include the `.` in the character groups? `[\w.]` is the same as `[.]`- and allows lots of things we don't want...
Cross-compability, backwards compatibility, command line compatibility, ease of discovery. * Other packaging modules support comma separated package entries. * The pip module itself supports comma separated package entries * pip supports single string entries as valid packages * comma separated list entries are the natural way to write lists on the commandline. * error messages if people were to violate these rules (for instance: ```ansible localhost -m pip -a 'names=django>=1.11.0,<1.12.0'``` wonn't point to the actual solution unless we implement this sort of detection for creating the error message... in which case we might as well do the right thing.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
Use `'` for strings for consistency with the rest of the file.
Cross-compability, backwards compatibility, command line compatibility, ease of discovery. * Other packaging modules support comma separated package entries. * The pip module itself supports comma separated package entries * pip supports single string entries as valid packages * comma separated list entries are the natural way to write lists on the commandline. * error messages if people were to violate these rules (for instance: ```ansible localhost -m pip -a 'names=django>=1.11.0,<1.12.0'``` wonn't point to the actual solution unless we implement this sort of detection for creating the error message... in which case we might as well do the right thing.
No need for this line
No need for this line
should probably be validating whichever components aren't part of the vlan's "primary key" (seems like parent interface/node/interface_name, but not sure off the top of my head) and either allow them to be modified or at least warn/error if they're not in the requested state
From slack: > mattclay: sivel abadger1999 We've avoided a lot of unicode issues in ansible-test by running with LC_ALL set, so most of the the encoding work in ansible-test has been on an as needed basis. Working towards removing the use of LC_ALL we'll want to go with the unicode sandwich, but we don't yet have good functions in place like _text provides to do that. So we do want to go unicode sandwich here which means contents should become text on both python2 and python3. Then other code later on will have to be changed to be sure that it's not mixing text and bytes.
Refer https://github.com/ansible/ansible/pull/49414#pullrequestreview-180616762 The capability dict in onyx cliconf plugin can store version and other product releated information at time of connection initilaization instead of executing `show version` for every task run.
The code is the same, just the data differs, so I think it would be clearer to move the loop outside the if. ``` python output_data = self.py3_output_data if sys.version_info[0] >= 3 else self.py2_output_data for msg, param in output_data.items(): ... ```
replaced is not a good state, it should be part of present (would be 'changed' return status)
If you are removing the last user, users_to_add == ['None'], which is truthy so it fails on line 280. Same problem with remove the group "all".
Omit these lines please.
```not (foo is None)``` => ```foo is not None```
Use `assert_allclose`` instead
Can you use the waiter for this instead? http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.Waiter.SubnetAvailable
Move this condition up a level: ``` python if expand_path == '~' and not self._connection.remote_is_local: ```
Move this condition up a level: ``` python if expand_path == '~' and not self._connection.remote_is_local: ```
Glancing over the code, `packages_to_remove` might be a clearer name here- I saw the `packages.remove('setuptools')` below and was like, "wait, I thought we wanted to keep it?!" until I realized what was happening...
Below change will fix the ` TypeError: the JSON object must be str, not 'dict'` error ``` try: obj = json.loads(item) command = obj['command'] except (ValueError, TypeError): command = item['command'] ```
This expression do look a bit suspcious, can you explain a bit more what you try to achieve ? (cause that's if "A and B or A and B" and I am a bit unsure on the order to which I need to evaluate things)
This limits you to 1000 hosts where previously it iterated all the pages.
`return not owner or owner == publication_info['owner']` could be used.
If we can't delete the publication for whatever reason, there will be no error and the module will be trapped in a endless recursive loop.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
dashboardId parameter is missing.
dashboardId parameter is missing.
Title is mandatory.
dashboardId parameter is missing.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Title is mandatory.
Title is mandatory.
Title is mandatory.
Title is mandatory.
dashboardId parameter is missing.
dashboardId parameter is missing.
Title is mandatory.
dashboardId parameter is missing.
Title is mandatory.
dashboardId parameter is missing.
dashboardId parameter is missing.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
It's better to use `compat_urllib_parse.urlencode` in this line. One of the benefits is that there is no need to escape ep in `generate_ep()` anymore.
Title is mandatory.
Title is mandatory.
dashboardId parameter is missing.
```suggestion elif paramname == 'SubnetIds': ```
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
`expected_status` to `_download_json` instead.
It would be awesome if buildah supported copying from a container.
It would be awesome if buildah supported copying from a container.
fixture with load_json. If it's not valid json then load_json just gives you back a plain string
You must provide account credentials/cookies for testing.
`expected_status` to `_download_json` instead.
You probably don't need `{}` fallback anymore.
It would be awesome if buildah supported copying from a container.
It would be awesome if buildah supported copying from a container.
@willthames bcoca asked me to look at your problem. I think that we want to use to_native() here and we probably want to use errors='surrogate_or_strict' as well. to_native() converts the string into the type which an undecorated string literal has on that version of python. That type is called "str" on both python2 and python3 but it's a byte string on python2 and a text string on python3. It will have the following benefits: * It's the most compatible since it's the same type as str on both platforms. (It just has better defaults and more flexible error handling than using str()). * For most module_utils code, we use native string types right now so that a module author can mostly write idiomatic python and it mostly just works. They don't run into a problem combining byte and text type. (They do have to worry about it when they deal with an external API which needs a specific type but those are not as common so it's easier to deal with those when the time comes and not worry the rest of the time).
You probably don't need `{}` fallback anymore.
Use `with open(` instead of `open(`
```suggestion query=dict(type='list', elements='str'), ```
Use `with open(` instead of `open(`
This will not work: in the case of exception, the control flow will not reach this line because the block execution will be interrupted one line above. ```suggestion assert "Cannot json serialize" in str(excinfo.value) ```
We use `pytest` to run tests and the helpers from `unittest.TestCase` should be avoided (ideally, `unittest.TestCase` should never be used because it limits the compatibility with `pytest`). Instead, use `pytest.raises()`: ```suggestion expected_error_msg = ( r'^The --prompt option is not supported if ' r'also reading input from stdin$' ) with pytest.raises(errors.AnsibleOptionsError, match=expected_error_msg): cli.parse() ```
I'm not sure in this. So in case of two properties (k1=v1 and k2=v2) do you generate the `--consumer-property k1=v1 --consumer-property k2=v2` string? The repeated property didn't work when I tried it out and it only picked up the first one. I think you need to pass `--consumer-property "k1=v1,k2=v2"` as with some other commands. In case the "k1=v1,k2=v2" format is needed, there is a nice one-liner way to do it: ``` ','.join("%s=%r" % (key,val) for (key,val) in k.iteritems()) ```
```suggestion description: A list of variables whose values were changed. ```
```suggestion if self._module.check_mode: ``` You already checked for equality above.
Again: ```suggestion return ('params={0}'.format(encrypted_params), headers) ```
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
yes, and the best way to make sure that the key-IV pair does not repeat when you can't have a full list of all IVs used is to use random values in both random seed for PBKDF2 is not enough, it just makes the key random, not unique
```suggestion if self._module.check_mode: ``` You already checked for equality above.
```suggestion if self._module.check_mode: ``` You already checked for equality above.
```suggestion if self._module.check_mode: ``` You already checked for equality above.
What about the session token? (That this stuff is hard to do is why `connect_to_aws` was abstracted so early on!)
```suggestion if self._module.check_mode: ``` You already checked for equality above.
I'd probably prefer a single assignment with a conditional only for the argument. It would probably look cleaner this way: ```suggestion is_openbsd = u"OpenBSD" == to_text(platform.system(), errors='surrogate_or_strict') bcrypt_crypt_id = '2b' if is_openbsd else '2a' algorithms['bcrypt'] = algo(crypt_id=bcrypt_crypt_id, salt_size=22, implicit_rounds=None) ```
nothing. The point is to make collision between nonce and key as unlikely as possible. Using static nonce doesn't give you that. Cryptography is hard enough to get right _without_ going against recommended best practice.
Better to use more meaningful names than u or p. That helps users to understand what youtube-dl are using from their secret storages.
It won't be longer.
```suggestion description: A list of variables whose values were changed. ```
```suggestion if self._module.check_mode: ``` You already checked for equality above.
This looks for tags with the `Name` key set to `dev` - maybe a better example would be: ``` # all instances with their `Environment` tag set to `dev` tag:Environment: dev # all dev and QA hosts tag:Environment: - dev - qa ``` Since `tag:Name` could be confused for "tags with the name dev" as in `dev : true` or something
The change to this module is the only one that I question. I'm leaning towards putting this on the allowed list. The reason is that the code presently in the module is the equivalent of a UNIX pipe. The decompressor is able to chunk the data from the file to the database program as it decompresses that portion of the file. The run_command() version has to store all of the data from the decompressor in memory before passing it to the database program. So the memory usage can balloon in this case.
Better to use more meaningful names than u or p. That helps users to understand what youtube-dl are using from their secret storages.
This should use the existing `AzureRMAuth ` rather than requiring these keyvault vars only. Then auth using alternative ansible support methods works too. https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/azure_rm_common.py#L971 This is how the other azure plugins work already (e.g. inventory plugin https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/inventory/azure_rm.py#L274 )
Extraction should be tolerate to missing fields. Everything apart from title and formats considered optional and should not break the extraction if missing.
You can import `try_rm` from helper
Please keep your code style consistent: first you assign vars for some time, then you pass lots of function args directly. There's a better way.
`re.sub` part can be put in `transform_source` parameter of `_parse_json`.
nitpick: it would be nice for the second clause to be aligned vertically with the clause above
nitpick: it would be nice for the second clause to be aligned vertically with the clause above
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
https://stackoverflow.com/a/2239753 ```suggestion if consecutive_good == self.module.params[ ```
I think you can simply delete this and the next line. `namespace_tx` and `namespace_rx` are already `int`s at this point.
Also, why do you compute `data.split(delimiter)` again instead of using `data_arr`? ```suggestion metric.split("=", maxsplit=1) for metric in data_arr) ```
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
You are right! Fixed it in https://github.com/mheap/ansible/pull/3.
im not sure syntax check makes any sense in this context, why do it via pull? the playbook should be checked by ansible-playbook, using pull as a proxy for a check seems contrived.
`no_log=True` is argument spec will handle this.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Just an empty line, could be removed for cleaner code
`current_version` could be mentioned in the error message.
Just an empty line, could be removed for cleaner code
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
```suggestion query=dict(type='list', elements='str'), ```
`return not owner or owner == publication_info['owner']` could be used.
Remove this line and de-dent `if:` block. (And remove the `changed` variable in the `state == 'import'` block completely.)
```suggestion - Whether passed queries run in a single transaction or commit (C(yes)) them one-by-one (C(no)). ```
Given this can add/remove do we want to say `update`? ```suggestion - Name of the database to connect to and update the schema. ```
```python $ python2.6 Python 2.6.9 (unknown, Apr 10 2018, 17:32:50) [GCC 7.3.0] on linux4 Type "help", "copyright", "credits" or "license" for more information. >>> import pkg_resources /home/wk/.pyenv/versions/2.6.9/lib/python2.6/site-packages/pkg_resources.py:17: DeprecationWarning: the sets module is deprecated from sets import ImmutableSet >>> stdst = pkg_resources.get_distribution('setuptools') >>> stdst setuptools 0.6b4dev-r0 (/home/wk/.pyenv/versions/2.6.9/lib/python2.6/site-packages) >>> stdst.as_requirement() Requirement.parse('setuptools==0.6b4dev-r0') >>> stdst.as_requirement().specs [('==', '0.6b4dev-r0')] ```
Is this requirement no longer true? The old logic doesn't match the error message, but you haven't replaced it with anything at all.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
`return not owner or owner == publication_info['owner']` could be used.
This logic tried to enforce a minimum version requirement, which the new code does not. Since it doesn't sound like you have added compatibility with older versions (or have any reason to), why not do something like: ``` min_version = '2.4' if loose_srv_version < LooseVersion(min_version): module.fail_json(msg='MongoDB {0] found, the minimum version supported by this module is {1}'.format(srv_version, min_version)) ```
Maybe it makes sense to prefix the label-based groups by something like `docker_swarm-label-` or so, so that short/generic labels don't overwrite existing groups. Or maybe also make this prefix an option for the inventory plugin so users can overwrite it or leave it away if they don't think there will be collisions.
Move flags into regex.
Move flags into regex.
Move flags into regex.
What is the need here for writing and reading from a JSON file? Seems this file would be created during execution, but in a temporary directory, and deleted immediately. Not sure what benefit there is to doing this, as opposed to just storing in a variable for use.
Note there probably isn't a reason to import warnings here rather than at the toplevel.
It's more readable to have outside DC loop inside `if cluster_name` and `elif host_name` conditions since they are independent within overall context and can be interchanged.
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
you don't need to say `testcase failed`, it's obvious from testrunner's indication
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
`{}` is not compatible across python versions that support format, use `{0}` or `%` instead
'+' is redundant here.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
unused variable `input_length`
Playlist metadata must not be fatal.
Playlist metadata must not be fatal.
Blank line required before the next section
```suggestion creation_date=dict(type='str', required=False), ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
```suggestion creation_date=dict(type='str', required=False), ```
> ```python > import uuid > video_id = uuid.UUID(self._html_search_regex( > r'data-io-video-id="([^"]*)"', > webpage, 'video_id')) > ``` It's actually only there once playback has started. Before it starts the `video_id` is not set in the `video` element yet.
Docstring contains a few typos, please fix / rephrase
Docstring contains a few typos, please fix / rephrase
Docstring contains a few typos, please fix / rephrase
It is safe to just make it default to `hash`, no need for the string conversion. Hash is not the name of a specific hash function anyway, just a Python utility.
I'd put `(self._flags['become_success'] or chan.exit_status_ready())` into a `@property` for readability so that it'd look like ```suggestion while not self._cmd_finished: ```
i've seen plenty of 'dummies', i just have not seen a pattern to them.
```suggestion # require that the final recorded stack state was DELETE_COMPLETE ```
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
Ah never mind, I forgot that the `if response` handles when the recursive URL lookup might have ended.
Good catch! yeah there should be a warning.
please note that behavior for non-caught exceptions is to return `None`, so please add another `return False` in the end and maybe replace this one with `pass` or a docstrinig with the explanation.
Instead, you can make this `record.get('values') or []` instead of the inline conditional.
Use `query` for query.
The leading underscore in the '_meta' key is missing here.
The leading underscore in the '_meta' key is missing here.
Use `query` for query.
`pzuid` does not look to be used anywhere.
`pzuid` does not look to be used anywhere.
Use `query` for query.
`pzuid` does not look to be used anywhere.
you can move it to before `if` as just `docs = {}` line, this should read better.
Sure, a separate PR sounds good.
Here, `self.count_upgrade` is an int, and `outdated` (as above) a `dict` resp. `list`.
Use `query` for query.
```suggestion SubnetIds=module.params.get('subnet_ids'), ``` and here as well
Use `query` for query.
`pzuid` does not look to be used anywhere.
you can move it to before `if` as just `docs = {}` line, this should read better.
`pzuid` does not look to be used anywhere.
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
small typo ```suggestion # table availability in check_src/dst. ```
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
use ```from ansible.module_utils.vmware import get_parent_datacenter```
use ```from ansible.module_utils.vmware import get_cluster```
use ```from ansible.module_utils.vmware import get_parent_datacenter```
- I wonder if we need to also catch things that are not text (for instance a number)? - The previous code handled that further down with a format string. We also wouldn't want to throw a traceback here on non-utf8 bytes. Since this is logging we probably want to use errors='replace' to deal with that. - I took a look at systemd.journal on fedora21. (Note: these behaviours are unaffected by client locale settings. Don't know if the systemd daemon has a settable locale setting). - in python2 it will take either bytes or unicode string. If the string is not utf-8, systemd.journal registers it as a binary blob. - On python3 this must be a unicode string. - Also took a look at syslog on fedora 21(these are unaffected by the client locale setting) - In python2 it must be a byte string. A non-utf-8 string becomes the replacement character - In python3 this must be a text str type. So this whole method needs to be reworked for python3 compatibility.
Please raise a `NotIplementedError` when the use case is not supported yet.
Please raise a `NotIplementedError` when the use case is not supported yet.
I wonder if this wouldn't be better named `lag_type` either as the default name, or an alias. As LAG seems to be a common term (at least I know this term). cc @rsmeyers @jmcgill298
Similarly, ```if tc['skip'].get('i')```
Please use a parameterized pytest test instead of this pattern. Example: https://github.com/keras-team/keras/blob/master/tests/keras/layers/convolutional_test.py#L21
Argh, I just realized the PluginLoader attribute stuffing (update_object) has been happening on `class_only` cases, which is broken for "same name, different behavior" cases (since subsequent loads will overwrite the class vars on the existing type object, not instance vars). It works here, since `all` is `yield`ing the plugin class immediately after calling `update_object` on it, but the whole pattern is busted for `class_only`, esp for things that might consult the class var during or after `__init__`. We've needed to rethink that for awhile, and this kinda sets it in a little more concrete. :(
Not catching non-200 responses.
Optimizers have a `get_config` method precisely for this purpose.
- does not match the correct image. - you're not following the coding conventions.
typo for `user`
If it's not found you will try extracting from 404 page. Remove all this 404 mess.
If it's not found you will try extracting from 404 page. Remove all this 404 mess.
You should be able to use `self.vmware_test_platform` here.
Anytime I reach for map or filter, I like to use a list comprehension of generator exception instead as it is faster and considered more pythonic. ``` python return [p.name for p in q] ```
No such meta field.
`urljoin` already does these checks.
All formats should be extracted.
```suggestion module.fail_json(msg='The following volume names were not found: ' ```
No such meta field.
FYI, in case you switch to working on whole config, `get_config.config` gives you the whole tree. (`get_config(:foo).config` is generally equivalent to `get_config.config[:foo]`.) Also, VMDB::Config is deprecated. May be better to use `::Settings.to_hash`.
Capture between tags.
This should be recursively delegated to pbs extractor instead.
Do not capture empty strings.
They're not being added in _get_loop_items, it seems like they're added in the internal execution so this may be the easiest way to clean them up.
I think this might now work when there is dict of dict in response? It might break idempotency in those cases. I think you need to call it recursively when there is dict of dict or dict of list of dict.
```suggestion file_name, file_exts = os.path.splitext(str(url.rsplit('/', 1)[1])) # Preserving double filename extensions like .tar.gz _, double_ext = os.path.splitext(file_name) if double_ext: file_exts = double_ext + file_exts: ```
Parse from flashvars JSON.
I think this should be using mock.patch? iirc, this can leave ansible.module_utils.facts.system.pkg_mgr monkeypatched to be a mock for the rest of the tests.
I would name the method `passwd_check`.
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
The number of batches in the Sequence
The number of batches in the Sequence
yt-dlp's `--print` is a bit more complex, allowing printing data at multiple stages. Eg: `-O "after_move:%(filepath)s" will print the final file path. This function is needed to (easily) support that syntax, (and also other similar options)
I'm pretty sure this can use `is_sequence()`.
so this assertion looks incorrect, i would expect and empty string as the ssh args
Ok, there are a bunch of these that need addressed, to index your format string for py2.6 support.
Here's how I'd fix this (since pylint complains about the change that autopep8 makes): ``` diff diff --git a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py index cafcbdbbc5..c55e8132a4 100644 --- a/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py +++ b/lib/ansible/modules/storage/netapp/netapp_e_storagepool.py @@ -120,14 +120,13 @@ def select(predicate, iterable): if predicate(x): yield x +def _identity(obj): + return obj class GroupBy(object): # python 2, 3 generic grouping. def __init__(self, iterable, key=None): - if key is None: - def key(x): - return x - self.keyfunc = key + self.keyfunc = key if key else _identity self.it = iter(iterable) self.tgtkey = self.currkey = self.currvalue = object() ```
The set of format string meta fields is strictly defined. This must not match arbitrary field.
All methods only used once should be explicitly inlined.
You don't need to specify this field if there is no return output
```suggestion query=dict(type='list', elements='str'), ```
I see... it's putting them near split_xpath_last which is where they're used. Maybe move both the variables and the split_xpath_last function up to below the imports.
Another map that can be a list comprehension: ``` content = [x.strip() for x in m.group(3).split(" and ")] ```
I did not suggest moving `subtitle_original_lang_code` into loop.
Don't lookup `lang_code` twice.
Sounds good. But it needs to be serializable.
no, if the variable is set but empty, you should empty out the options
No need to escape whitespace.
need to x2 check tmrow, but this should be an error, we don't allow for circular parenting
If you check for the folder path here [compile_folder_path_for_obj] (before breaking) you could return the result and ignore all the other strategies.
filters //= 2
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Better to put the activation as the `activation` keyword of the layer below
If you check for the folder path here [compile_folder_path_for_obj] (before breaking) you could return the result and ignore all the other strategies.
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
I guess you misuse \\. For example: ``` >>> repr(re.match(r"""'(?:[^'\\\\]*(?:\\\\\\\\|\\\\['"nurtbfx/\\n]))*[^'\\\\]*'""", r"""'\'""")) 'None' ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
`continue` not `break` (with `break` we can miss some VM). Or `fail_json(â¦`, because a VM object without name shouldn't exist.
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
Using the `match` parameter saves you from having to do an `assert`. ```suggestion with pytest.raises(FailJson, match='Unable to find required'): z = ZipArchive( src="", b_dest="", file_args="", module=fake_ansible_module, ) ```
I wonder if the output can be simplified to avoid repeating `unset` and `export`.
`re.sub` part can be put in `transform_source` parameter of `_parse_json`.
Don't re-invent URL parsing. Also, why `sub = sub.replace(';', '&')? ```suggestion parsed_url = compat_urlparse.urlparse(url) qs = compat_parse_qs(parsed_url.query) lang = qs.get('lang', [None])[-1] if not lang: continue ``` A URL query string might in principle have several `lang=xx` elements. The URL is parsed; the query string is returned as a `dict` of `list`s. We assume that, when it only makes sense for a query parameter to have one value, the last one in the list (-1) is meant. In this case it's probably the first as well.
Don't use floating point math for calculations that depend on precise results! Instead, you can simply calculate `((videos_count + self.PAGINATED - 1) // self.PAGINATED) + 1`
`re.sub` part can be put in `transform_source` parameter of `_parse_json`.
I wonder if the output can be simplified to avoid repeating `unset` and `export`.
an exception for when they are not a list of tuples 'invalide plugin property, contact plugin author ...'
an exception for when they are not a list of tuples 'invalide plugin property, contact plugin author ...'
`@unittest.skipUnless(basic.has_journal, ...)` might be clearer.
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
this is a non atomic operation and can lead to file corruption, write to a temp file and use shared 'atomic_move' to put the file into place
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
It's probably more idiomatic to receive a list of path segments without separators here and pass them to `os.path.join` again as list of segments.
Indent isn't really necessary here: ```suggestion if already_loaded_vendored_modules: print( 'doh, some vendored stuff was already loaded: {0}'. format(already_loaded_vendored_modules), file=sys.stderr, ) ```
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
What is the reason for reordering all these parameters? This breaks `blame` attribution for these lines & doesn't improve the code.
```suggestion for key, value in self.parameters.plugin_options.items(): ```
How about ```suggestion q = q.lstrip()[0:max_keyword_len].upper() ``` and removing the `.upper()` calls below? Will be more efficient :)
None is default.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Instead, you can just return the results of `ensure_present` since this is the last line of this branch
Lookup plugins run on the controller. The minimum python version for the controller is python 2.6. So str.format() can't use "{}". The easy workaround is to use "{0}" and "{1}" instead.
```suggestion for key, value in self.parameters.plugin_options.items(): ```
This should be a private method, I believe
Lookup plugins run on the controller. The minimum python version for the controller is python 2.6. So str.format() can't use "{}". The easy workaround is to use "{0}" and "{1}" instead.
Okay, if it's used by lots of modules it should go to the other PR.
typo: ot -> to
The next `if` should come first. The module should die if not all DBs exists no matter whether it's in check mode or not.
None is default.
Since attr_field is a list, attr_fields would be a better name (and for the 'field' list above as well)
`False` is not a valid note.
`False` is not a valid note.
Yeah, a list is fine.
I think this will fail on py3, as `encoded` will be a list of bytes. ``` TypeError: sequence item 0: expected str instance, bytes found ``` Might make `b''.join` and then use `to_native(data, errors='surrogate_or_strict')`
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
```suggestion # just get value from attribute itself as normal ```
The problem is that you start the connection before we know the connection details for sure, so getting the data earlier will make it even worse. In some cases (when all is known before task templating) you should have no issues as play_context carries the correct info, but if you need info to change at the task, or worse, loop/delegation levels you'll run into trouble much sooner. Most of the time this problem can be ignored as plays tend to reuse the same information w/o changing it, specially networking ones. As you note, since we are passing the connection information and using set_options/get_option on them, we should be able to ignore most of the play_context data, but this requires all connection plugins to correctly source the data (all those in core do, but many of those in collections do not). Why I was planning to add deprecation notices to play_context soon.
When running as `youtube-dl.exe` build with python 2 from path containing non-ASCII `find_file_in_root` ends up returning `None`. When `localedir=None` is passed to `gettext.translation` it picks up `_default_localedir` constructed using `os.path.join` with mixture of byte strings and unicode strings that results in similar problem: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "gettext.pyo", line 468, in translation File "gettext.pyo", line 451, in find File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` We can workaround be skipping it completely when we found no locale dir: ``` python locale_dir = find_file_in_root('share/locale/') if locale_dir: try: ... ``` Or we can mimic what `gettext` do by appending extra path in `get_root_dirs`: ``` python ret.append(os.path.join(decodeFilename(sys.prefix), 'share', 'locale')) ```
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
This looks like it is unfortunately not quite this simple. We want the following fallbacks: * If the user specifies a value explicitly in the playbook, use that * If the config file has it, then use that. * If both of those do not have a value, then use the module's defaults. This likely needs changes both here and in the mysql modules themselves. The change here will look something like this (repeat for each of the values we're setting): ``` python if cp an cp.has_section('client'): if module.params['login_host'] is None: module.params['login_host'] = cp.getint('client', 'host', fallback='localhost') [....] ``` Inside of the mysql modules we'll have to change teh module's argument_spec. For instance, mysql_db.py has this: ``` python argument_spec=dict( login_user=dict(default=None), login_password=dict(default=None, no_log=True), login_host=dict(default="localhost"), [...] ``` We would need to change it to this: ``` python argument_spec=dict( login_user=dict(default=None), login_password=dict(default=None, no_log=True), login_host=dict(default=None), [...] ```
'p' is already removed when, kwargs.pop('p')
ternary isn't available in python-2.4 If the freeipa module works on python2.4 then this will need to be expanded into a regular if-else.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
`return not owner or owner == publication_info['owner']` could be used.
`return not owner or owner == publication_info['owner']` could be used.
@s-hertel using client exceptions rather than botocore exceptions is nicer when they actually exist (which they do here for a kms client): ``` except connection.exceptions.NotFoundException: return None except (botocore.exceptions.ClientError, botocore.exceptions.BotoCoreError) as e: # Legitimate failure module.fail_json_aws(e, ... ```
* move description extraction * add thumbnail ```suggestion 'description': clean_html(vidello_values.get('product_desc')), 'formats': formats, 'thumbnail': url_or_none(try_get(vidello_settings, lambda x: x['player']['poster'])), ```
You want `changed` to be `True` here if *at least* one DB was created, not if *all* DBs in `non_existence_list` were created (and there has been at least one).
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
Also, you don't actually need these error messages after `assert` since this is a unit test
Also, you don't actually need these error messages after `assert` since this is a unit test
I'd suggest update the existing test directly in this PR.
I'd suggest update the existing test directly in this PR.
I'd suggest update the existing test directly in this PR.
This is too restrictive. Rather, the conditional below should be `if self.write_grads and weight in layer.trainable_weights`
You don't need to specify this field if there is no return output
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Just an empty line, could be removed for cleaner code
this should use the config system instead
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
Just an empty line, could be removed for cleaner code
this should use the config system instead
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
would you mind adding the same for allocation ids? :+1:
keep the old fallback code.
A golden rule I use is to alphabetically sort items in a list if the order is of no importance. It helps compare lists or finding items in a list more easily.
A golden rule I use is to alphabetically sort items in a list if the order is of no importance. It helps compare lists or finding items in a list more easily.
This needs to be rewritten to support Python 2.6.
A follow up PR that updates all postgres modules to use https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/postgres.py#L42 would be good. No need to block on this. Also that function should be updated to use `module.fail_json(msg=missing_required_lib("psycopg2"))`
You can use [`ensure_libs`](https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/postgres.py#L42).
This argument is only accepted in Python 3, it would not work with Python 2.
This argument is only accepted in Python 3, it would not work with Python 2.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
last loaded wins, but iirc, we reverse search on handlers list
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
terms can be a list, not sure if this is being handled correctly
Finally, `db_exists` checks whether **all** DBs in the list exist. This doesn't really help here. You really need to work with `existence_list` and `existence_list`.
terms can be a list, not sure if this is being handled correctly
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
(Similarly, mark any string that you are going to call decode on with as a b"string".)
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Technically since we're doing this in a fixture, either `monkeypatch` should be used to insert these into `globals()`, or you should return `mod`, and then just use `mod.Template` and `mod.AnsibleNativeEnvironment` in your tests.
nit: this is a good place to use a "guard expression" ```suggestion if not loader: return None spec = spec_from_loader(fullname, loader) if spec is not None and hasattr(loader, '_subpackage_search_paths'): spec.submodule_search_locations = loader._subpackage_search_paths return spec ```
Add support if VMM domain parameters: "vmmDomainProperties": { "microSegVlan": { "vlanType": {}, "vlan": 0 }, "portEncapVlan": { "vlanType": {}, "vlan": 0 }, "vlanEncapMode": {}, "allowMicroSegmentation": 0, "switchType": {}, "switchingMode": {}, "epgLagPol": { "enhancedLagPol": { "name": "string", "dn": "string" } }
Hmm, nevermind. It seems that if I remove the `resource_pool` argument altogether then everything works fine. Previously this value was set to `Resources` even though we don't have any explicit resource pools, but without the value an error was thrown previous to this commit.
we've avoided using _ as a 'unused var' in case we decide to use i18n .. which also has special uses for _
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
how about ```suggestion installed_packages = defaultdict(list) ```
this should use the config system instead
shouldn't this line and the one below just not be here, and the loop be `for arg, version in self.DEFAULT_DEPRECATED_ARGS` (though those aren't really a default either, so `DEFAULT` is a bit of a misnomer)
shouldn't this line and the one below just not be here, and the loop be `for arg, version in self.DEFAULT_DEPRECATED_ARGS` (though those aren't really a default either, so `DEFAULT` is a bit of a misnomer)
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
This needs to be a list of 2 dictionaries. ``` [{'ndmpd-authtypes': 'plaintext'}, {'ndmpd-authtypes': 'challenge'}] ```
shouldn't this line and the one below just not be here, and the loop be `for arg, version in self.DEFAULT_DEPRECATED_ARGS` (though those aren't really a default either, so `DEFAULT` is a bit of a misnomer)
Sure, a separate PR sounds good.
Read code conventions on optional fields.
It's a good question. On one hand, it's nice to have a clean list which isn't littered with extra 1000 fields you're not interested in. On the other hand, it's very annoying if you need something which is returned by docker but thrown away by the module, and you need to loop over the result and feed it into `docker_*_facts` just to get the value back. How about adding a `verbose_list_elements: yes|no` option which toggles between returning a subset and everything? Then one can enable full output if one needs it.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
Use `for index, (item_got, item_expected) in enumerate(zip(got, expected)):` instead. Either use descriptive names for type variables or don't extract them as variables at all.
This is not used in single video extractor thus should not be here.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
I was looking into moving `ansible.utils.vars.merge_hash()` and discovered we have `ansible.module_utils.common.dict_transformations.dict_merge()` that was added in #41471. I wonder if that function could be used in this case.
@Akasurde Is it possible to have `len(temp_vm_object.propSet) != 1` ? Has I understand it temp_vm_object.propSet will only contain the name of the temp_vm_object.
This is not used in single video extractor thus should not be here.
This is not used in single video extractor thus should not be here.
This is not used in single video extractor thus should not be here.
Code duplication 173, 213. There is no sense to extract fields explicitly.
It's a good question. On one hand, it's nice to have a clean list which isn't littered with extra 1000 fields you're not interested in. On the other hand, it's very annoying if you need something which is returned by docker but thrown away by the module, and you need to loop over the result and feed it into `docker_*_facts` just to get the value back. How about adding a `verbose_list_elements: yes|no` option which toggles between returning a subset and everything? Then one can enable full output if one needs it.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
This should not be a new paragraph, but continue the previous paragraph (item), right? ```suggestion port 3000 if available or asinfo -v status returns ok ```
Please note that in Python we don't use brackets unless really needed.
Similarly, ```if tc['skip'].get('i')```
```suggestion if not dcpath.endswith("/"): ```
@pdellaert in python you can't access [set](https://docs.python.org/3.6/library/stdtypes.html#set-types-set-frozenset) elements by index: ``` >>> a=set((1, 3, 2)) >>> a {1, 2, 3} >>> a[0] Traceback (most recent call last): File "<stdin>", line 1, in <module> TypeError: 'set' object does not support indexing ```
If we use `self.api_client` then this API will look like - ```suggestion self.datacenter_id = self.get_datacenter_by_name(datacenter_name=self.datacenter) ```
Code looks good to me but wouldn't mind seeing some unit tests. a little refactoring may make it easier to test, something like: ``` python def _parse_lsdev(self, out_lsdev): devices = [] for line in out_lsdev.splitlines(): field = line.split() device_name = field[0] device_state = field[1] device_type = field[2:] devices.append({'name': device_name, 'state': device_state, 'type': device_type}) return devices def _parse_lsattr(self, out_lsattr): device_attrs = {} for attr in out_lsattr.splitlines(): attr_fields = attr.split() attr_name = attr_fields[0] attr_parameter = attr_fields[1] # attrs.append({'name': attr_name, # 'parameter': attr_parameter}) device_attrs[attr_name] = attr_parameter return device_attrs def _get_device_attrs(self, lsattr_cmd, device_name): lsattr_cmd_args = [lsattr_cmd, '-E', '-l', device_name] rc, out_lsattr, err = self.module.run_command(lsattr_cmd_args) device_attrs = self._parse_lsattr(out_lsattr) return device_attrs def _get_devices(self, lsdev_cmd): rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._parse_lsdev(out_lsdev) return devices def get_device_facts(self): device_facts = {} device_facts['devices'] = {} lsdev_cmd = self.module.get_bin_path('lsdev', True) lsattr_cmd = self.module.get_bin_path('lsattr', True) rc, out_lsdev, err = self.module.run_command(lsdev_cmd) devices = self._get_devices(lsdev_cmd, out_lsdev) for device in devices: device_attrs = self._get_device_attrs(lsattr_cmd, device['name']) device_facts['devices'][device['name']] = { 'state': device['state'], 'type': ' '.join(device['type']), 'attributes': device_attrs } return device_facts ``` The _parse_lsattr and _parse_lsdev could be unit tests with sample output from the commands
You want `changed` to be `True` here if *at least* one DB was created, not if *all* DBs in `non_existence_list` were created (and there has been at least one).
Remove this line and de-dent `if:` block. (And remove the `changed` variable in the `state == 'import'` block completely.)
`del` is a builtin, not a function. These parens don't have to be here
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Preference would be for a unit test to be mocked sufficiently that a cleanup like this is not required. However, in this case if that involves a large amount of fragile mocking, I wouldn't worry about it now as having test coverage is better than not having it, even if it is a little messy.
Line too long
Returning would close the file (I think) since you're already in a 'with' statement.
```python for path, format_id in (('', 'audio'), ('video', 'sd'), ('videohd', 'hd')): self._download_xml( 'https://www.heise.de/ct/uplink/ctuplink%s.rss' % path, video_id, 'Downloading %s XML' % format_id, fatal=False) ```
Returning would close the file (I think) since you're already in a 'with' statement.
This works in China? I thought the param would have to be missing.
Format your docstrings like other docstrings in the codebase
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Format your docstrings like other docstrings in the codebase
```python for path, format_id in (('', 'audio'), ('video', 'sd'), ('videohd', 'hd')): self._download_xml( 'https://www.heise.de/ct/uplink/ctuplink%s.rss' % path, video_id, 'Downloading %s XML' % format_id, fatal=False) ```
Do not change the order of extraction scenarios.
You could replace this entire block with: ``` from distutils.version import StrictVersion return StrictVersion(host_version) >= StrictVersion('.'.join(map(str,version))) ```
You could replace this entire block with: ``` from distutils.version import StrictVersion return StrictVersion(host_version) >= StrictVersion('.'.join(map(str,version))) ```
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
you need to skip value from parent if include_tasks/include_role, but still inherit
you need to skip value from parent if include_tasks/include_role, but still inherit
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
```suggestion # just get value from attribute itself as normal ```
This adds a lot of complexity. If we wait for the queue to be empty, then there is no batch getting computed so it is safe to modify.
This adds a lot of complexity. If we wait for the queue to be empty, then there is no batch getting computed so it is safe to modify.
This should be a `ValueError` (never raise `Exception`).
This should be a `ValueError` (never raise `Exception`).
This doesn't seem to handle filters. Then again, filters are a hard problem because they could change the type of the variable intentionally.
Split GitLab authentification en project gathering. Add a custom check on `git.projects.get(project)` with a custom message
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
Use a separate skip and prune list, as is done in other sanity tests: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L7-L14 Then check each separately: https://github.com/ansible/ansible/blob/60a24bbdaae3a17bf20613810f347bfb8283f306/test/sanity/code-smell/boilerplate.py#L38-L42
Yeah, separate PR is fine, though we should also not be relying on config for that for anything but the builtins and maybe local non-collection plugins- collections should be able to provide that metadata directly (probably via something like the metadata-only decorator stuff I was playing with).
If we're just testing broker compatibility I don't think we even need this part of the test.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Chances of not finding datastore is also possible even when user passes the datastore name. Change the error message
I think this should have a `raise` after this loop to raise an exception if none of the user-provided hostname preferences match, so we don't add hosts with the hostname `None` which would be the default return.
Please remove the raising of an exception and properly fail the module.
this creates race condition. there is a time between remove and move that the file is unavailable. I see original code did same, but we should just allow move to work as it will be an atomic operation
Looks like dead code here
Minor style point: I'd probably put as a method inside ZK, but that's a bit subjective really.
This should be regular text. ```suggestion - Creates or destroys a data migration services subnet group. ```
We should convert filenames to bytes before passing to open. Like this: ``` python with open(to_bytes(in_path, errors='surrogate_or_strict'), 'rb') as in_file: ```
We should convert filenames to bytes before passing to open. Like this: ``` python with open(to_bytes(in_path, errors='surrogate_or_strict'), 'rb') as in_file: ```
```suggestion elif paramname == 'SubnetIds': ```
`expected_status` to `_download_json` instead.
why fail here? I think we should just do nothing
`topics` defined here and in next test, maybe move up to `init`
resource group should be parsed from image.id, considering the list_all scenario.
why fail here? I think we should just do nothing
is it important to have 3 brokers for this test? I'm wondering if the tests would be more resilient and faster with just one broker and replica of each topic.
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
why fail here? I think we should just do nothing
why fail here? I think we should just do nothing
Let's keep the naming aligned with docutils' own RST terminology/definitions, at least: ```suggestion _RST_ROLE = re.compile(r":\w+?:`") _RST_DIRECTIVE = re.compile(r".. \w+?::") ```
Nothing to do with RFC 3986.
Debug code must be removed.
Debug code must be removed.
Please only import what you need, rather than `*`
Let's keep the naming aligned with docutils' own RST terminology/definitions, at least: ```suggestion _RST_ROLE = re.compile(r":\w+?:`") _RST_DIRECTIVE = re.compile(r".. \w+?::") ```
(Still first impressions stuff) guess output_options() etc are actually modifying self.parse by side effect and accumulating the options. Related, could the options data be built up first instead of output_options()/connect_options() etc incrementally modifying the passed in self.parser? (Thats not entirely related to the singleton stuff, but it could make it more clear when the parser instance is finalized and immutable-ish) ``` python def vault_options(parser): parser.add_option('--vault-password-file', default=[], dest='vault_password_files', help="vault password file", action="callback", callback=CLI.unfrack_paths, type='string') parser.add_option('--vault-id', default=[], dest='vault_ids', action='append', type='string', help='the vault identity to use') self.parser = vault_options(self.parser) ``` to: ``` python option_data = [{'options': ['--vault-password-file'], 'default': [], 'dest': 'vault_password_files', 'help':"vault password file", 'action': 'callback', 'callback_id': 'UNFRACK_PATHS', 'type': 'string'}, {'options': ['--vault-id'], 'default': [], 'dest': 'vault_ids', 'action':'append', 'type': 'string', 'help': ''the vault identity to use'}] ... parser = init_parser() # or whatever constructs it for option in option_data: # or likely, some helper method to setup the args and resolve callback_id to a callable parser.add_option(option) ``` ie, pass all the data to the parser constructor instead of incrementally modifying it. If there is nothing dynamic in the options data, it could be copied around and each cli could build it's own parser instance. Could potentially make it easier to build cli docs as well.
ð, this is a nice little refactor.
This probably needs a core review.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
Is this really useful? It might be more confusing than helpful, because it's making the behaviour of `K.switch` different from that of `theano.tensor.switch`. Actually, I think it's even doing the opposite of what Theano's `switch` would do: `switch` would add broadcast dimensions on the left, but `expand_dims` is adding broadcast dimensions on the right.
I like this!
Can we add a `key` name as well ? It is very confusing message if we have multiple warnings like this - ``` [WARNING]: The value 600 (type int) in a string field was converted to u'600' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value {'Name': 'aws-blorp_rhel7'} (type dict) in a string field was converted to u"{'Name': 'aws-blorp_rhel8'}" (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. [WARNING]: The value 300 (type int) in a string field was converted to u'300' (type string). If this does not look like what you expect, quote the entire value to ensure it does not change. ``` Maybe something like - ```suggestion msg = ('The value {0!r} (type {0.__class__.__name__}) in a string field of argument {1} was converted to {2!r} (type string). ' ```
You need to close the `Connection`.
You're setting `value` exactly the same way that `new_item` was set. Either reuse `new_item` or use `value` instead of `new_item`
```suggestion raise AnsibleParserError("the field '%s' should be a list, but is a %s" % (value, type(value))) ```
From the code below, it looks like this doesn't do what you think it does. It creates a list of dictionaries which contain precisely one key, whose value is another dictionary whose only key is `SpreadDescriptor`.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
One-line docstring description should end with a period.
Is anything `required_together`, if not please remove this line
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Why not also do this when `module.check_mode` is `True`? Then the check mode behavior is closer to the real thing.
Upon further reflection, I think these three lines along with `check_mutually_exclusive` are erroneous for subspecs. We don't currently have a way to specify `required_if/one_of/together` or `mutually_exclusive` for subspecs, so in every case *but* the networking "aggregate" thing, this is severely broken (as you'd be making nonsensical checks in most cases)
Cross-compability, backwards compatibility, command line compatibility, ease of discovery. * Other packaging modules support comma separated package entries. * The pip module itself supports comma separated package entries * pip supports single string entries as valid packages * comma separated list entries are the natural way to write lists on the commandline. * error messages if people were to violate these rules (for instance: ```ansible localhost -m pip -a 'names=django>=1.11.0,<1.12.0'``` wonn't point to the actual solution unless we implement this sort of detection for creating the error message... in which case we might as well do the right thing.
Cross-compability, backwards compatibility, command line compatibility, ease of discovery. * Other packaging modules support comma separated package entries. * The pip module itself supports comma separated package entries * pip supports single string entries as valid packages * comma separated list entries are the natural way to write lists on the commandline. * error messages if people were to violate these rules (for instance: ```ansible localhost -m pip -a 'names=django>=1.11.0,<1.12.0'``` wonn't point to the actual solution unless we implement this sort of detection for creating the error message... in which case we might as well do the right thing.
Two line breaks after the first sentence.
Chances of not finding datastore is also possible even when user passes the datastore name. Change the error message
Chances of not finding datastore is also possible even when user passes the datastore name. Change the error message
Either `text` or `html` is mandatory.
the module will always fail. Use `module.exit_json` and `module.fail_json` based on `result`
Nesting under distribution ID is useful when you know it, but when returning a single item it's nice if you can make it available under the key the user asked for it with. Take for example: `ansible -m cloudfront_facts -a 'region=us-east-1 distribution=yes domain_name_alias=rsb.io' localhost`. As a user, I'd like to be able to say something like: `{{ cloudfront['rsb.io].ARN }}` to get the ARN, instead of (currently) `{{ cloudfront.[cloudfront.keys()[0]].distribution.ARN }}`. You could return both, so users could either use the ID or one of the CNAMEs to access the facts. They would be unique, since in CloudFront you can't have overlapping CNAMEs ever.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Note that format strings changed in python-2.7 So things like "{} {}".format() needs to change to "{0} {1}".format() for python-2.6 compatibility.
If we can't delete the publication for whatever reason, there will be no error and the module will be trapped in a endless recursive loop.
the order is incorrect, it probably 'works' if you don't have duplicate vars in inventories as the set_variable is overriding any cached vars you would have yet you do the reverse override here.
small typo ```suggestion # table availability in check_src/dst. ```
If we can't delete the publication for whatever reason, there will be no error and the module will be trapped in a endless recursive loop.
`return not owner or owner == publication_info['owner']` could be used.
Just an empty line, could be removed for cleaner code
Just an empty line, could be removed for cleaner code
Does the order matter? If yes, it's probably better to use ```suggestion return '/'.join(sorted(priv_list)) ```
`return not owner or owner == publication_info['owner']` could be used.
There is no guarantee something was changed here. So this would mean the module can only either fail or report changes.
Cosmetic: ```suggestion ''' Alternate constructor to instantiate class with sources ''' ``` A bit more informative about what the method is intended to be used for.
Cosmetic: ```suggestion ''' Alternate constructor to instantiate class with sources ''' ``` A bit more informative about what the method is intended to be used for.
Cosmetic: ```suggestion ''' Alternate constructor to instantiate class with sources ''' ``` A bit more informative about what the method is intended to be used for.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Better to leave this part of the code unchanged and implement a property setter on the wrapper.
Nitpick, but the line would be more readable if `padding` was a list instead of a tuple (many parens here).
You don't need a lambda here. Also, don't break lines with `\`.
Okay, so to implement the examples like this: ``` with_cyberark_password: appid: 'Application1' query: 'safe=...;' output: 'password ....' ``` We'll want to take the dict from terms instead of from kwargs. terms will hold the dict that the user passed in so you should be able to drop in replace it in your constructor like so: ```CyberarkPassword(**terms)```
no, I forgot this was around ... I think I'll ask for tips on IRC
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
You can import `try_rm` from helper
It may be beneficial to clarify that this is cyberark vault, to avoid confusion where someone may think the error is in reference to ansible vault.
It may be beneficial to clarify that this is cyberark vault, to avoid confusion where someone may think the error is in reference to ansible vault.
It may be beneficial to clarify that this is cyberark vault, to avoid confusion where someone may think the error is in reference to ansible vault.
It may be beneficial to clarify that this is cyberark vault, to avoid confusion where someone may think the error is in reference to ansible vault.
Break the line after the `(` to unify the style across the file.
you don't need to say `testcase failed`, it's obvious from testrunner's indication
This does not need to be wrapped.
Always use raises with `match=` or you'll catch false positives. Especially because almost any exception is a subclass of `Exception`. ```suggestion with pytest.raises(Exception, match='Error'): ```
This does not need to be wrapped.
This does not need to be wrapped.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Simplier: ```python password.os.path.exists = lambda x: x == to_bytes('/path/to/somewhere') ```
```suggestion return b'\r\n'.join(to_bytes(line, nonstring='passthru') for line in result) ``` (and import `to_bytes`)
Yep... Reading the Unsafe code, AnsibleUnsafeText and AnsibleUnsafeBytes are just light wrappers around the equivalent python types. Since the equivalent python types are fragile when mixing types, this is fragile as well. I think we need to consider it invalid to pass Text type to AnsibleUnsafeBytes and invalid to pass Bytes type to AnsibleUnsafeText. By extension, it's also invalid to pass Native strings to either AnsibleUnsafeText or AnsibleUnsafeBytes because that will be wrong on one of python2 or python3.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
nit: add a newline here too.
Non-ASCII characters in Python 3 pass tests: ``` 0.1s test_bytes: data_from_yaml=b'some byt\xc3\xa9s', type(data_from_yaml)=<class 'bytes'> 0.1s test_native_text: data_from_yaml='some nativÃ© text', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml='some unicodÃ©', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ``` Python 2 fails with non-ASCII characters: ``` # pytest output self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_bytes> > self.assertEqual(b_text, data_from_yaml) E AssertionError: 'some byt\xc3\xa9s' != u'some byt\xe9s' self = <units.parsing.yaml.test_dumper.TestAnsibleDumper testMethod=test_native_text> > f = AnsibleUnsafeText(n_text) E UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 10: ordinal not in range(128) # some q output 0.1s test_bytes: data_from_yaml=u'some byt\xe9s', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> 0.1s test_unicode: data_from_yaml=u'some unicod\xe9', type(data_from_yaml)=<class 'ansible.parsing.yaml.objects.AnsibleUnicode'> ```
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
This dict wrapping trick is only requred when both `i` and `j` are not dicts. This approach will fail with misleading assertion (`invalid value for field _`) when corresponding list items are of different type.
"weights are loaded based on the network's topology" might be a clearer way to put it.
Why must batch size be one? Just looking for clarification because I'm not 100% sure what this case is checking for because dense prediction tasks including FCNs can train with batch sizes >1.
This should be modeled in the same way that all other modules within ansible currently work. Variables can be set per host and applied to tasks.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
It's a nitpick, but there are inconsistent quotes in these files. Please just use `'` everywhere.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
IIRC should be just `raise` to re-raise the existing error
Same remark as before regarding `output_shape`.
This layer is commonly used with a positional argument, e.g. `PReLU(0.4)`. This should still work.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Probably not necessary to report consumer startup time in this test? Also `start_consumer` is a misleading name, since it doesn't actually start the consumer :) Also - on line 88, change `self.consumer.stop_node(node)` -> `self.consumer.stop()`
With the addition of `on_fit_batch_begin`, it might seem to users that `on_batch_begin` will run in all modes (fit/eval/predict). Same for `on_batch_end`. I'm not sure if there's a great way around that since we want to maintain backwards compatibility. Maybe we can just have `on_batch_begin` / `on_validation_batch_begin` (same for `end`)? Do we have use cases where users would want Callbacks in the public `evaluate` and `predict` methods? I'm picturing users mostly using the extra hooks for their validation data (especially with the TensorBoard callback)
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Nit - Change the message to: "Operation aborted, self-heal in progress." removing the capitalisations.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Have you considered using `@contextlib.contextmanager`? It would look cleaner.
Please add `# Arguments` and `# Returns` sections.
I think we should have an entry-check to protect from reuse: ```suggestion def __enter__(self): assert not self.timed_out ```
Might want to replace this with help message.
Missing `"..."` `set_fact: pubkey_string="{{ pubkeys.results | map(attribute='ansible_facts.pubkey_list') | join('\n') }}"`
stdout and stderr are being returned by suprocess.Popen().communicate() so they should be bytes already, I think.
Some more: avc2, avc3, avc4. These would be enough.
Sufficiently trimmed, `prepare_config` could fit in 5 lines, so maybe it's not so bad to have it twice? If factored out, it should have a better name anyway.
Add a `# Arguments` section to the docstring.
Add a `# Arguments` section to the docstring.
Missed one.. Should just be as below unless you want to also pass module into the function. ``` if os.path.isfile(cert_chain): cert_chain = open(cert_chain, 'r').read() ```
C/P error, should be `AWS ElastiCache is down`? Same on L450
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
I think these should be `is True` since the `.assertTrue` being replaced would fail if on something like `"foo"` which is truthy. So the `assert "foo"` would pass where `self.assertTrue("foo")` wouldn't.
CI failure due to PEP 8 issue: ``` 2017-01-31 22:24:00 ERROR: PEP 8: test/units/template/test_templar.py:447:161: E501 line too long (172 > 160 characters) (current) ```
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
if datastore already exists
Check for the exception in the test body instead of using a decorator. Also, since you're testing for an exception, you only need to define the input and not compare against expected: ```suggestion with pytest.raises(TypeError): ansible_json_encoder.default(test_input) ```
Fix test: ```suggestion 'ext': 'mp4', ```
There should be fallbacks for these values since they are more or less static.
I'd lose the space here, between `%s:` and `%s`, so that we get precisely what is sent.
https://github.com/ansible/ansible/blob/devel/lib/ansible/parsing/splitter.py also, you probably want to add these in a collection, not core
I'd recommend changing `'{0}'` and `'{2}'` to use double quotes instead of single. `repr` usually gives single quotes, and as such you end up with something like: ``` was converted to 'password: '********'' (type string) ```
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
```suggestion # just get value from attribute itself as normal ```
ContainerInstance doesn't support profile, it's why it doesn't have a `models` method
`del` is a builtin, not a function. These parens don't have to be here
Please remove this example, since I would consider this usage as not recommended.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
`del` is a builtin, not a function. These parens don't have to be here
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
When reducing the replica count, the force option is mandatory. This will fail if force is not set. Also for remove brick can you check there are not pending heals. If we are removing a brick from a volume which has pending heals and if that brick had the only good copy, we have data loss.
When reducing the replica count, the force option is mandatory. This will fail if force is not set. Also for remove brick can you check there are not pending heals. If we are removing a brick from a volume which has pending heals and if that brick had the only good copy, we have data loss.
This whole block could've been done with a nested list comprehension without any need for temporary variable introduction: ```python names = [ name for name_list in names for name in name_list.split(',') ] ``` Alternative FP approach would look like: ```python from itertools import partial, reduce ... names = reduce( lambda l, e: l + e, map( partial(str.split, sep=','), names ), [], ) ``` (but Pythonistas don't like such style in general)
Can be replaced with: ```python def check_service_state(self, host, service_name): host_service_system = host.configManager.serviceSystem if host_service_system: services = host_service_system.serviceInfo.service for service in services: if service.key == service_name: return service.running msg = "Failed to find '%s' service on host system '%s'" % (service_name, host.name) cluster_name = self.params.get('cluster_name', None) if cluster_name: msg += " located on cluster '%s'" % cluster_name msg += ", please check if you have specified a valid ESXi service name." self.module.fail_json(msg=msg) ``` This way it stops looping through services as soon as it finds the correct one, and if it finds none, it fails
I think either name should be mandatory or this should take a label selector.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
It likely makes sense to add the remaining psycopg2 parameters including host and port.
Ah, yes, I miss read the code. Nothing to change here.
small typo ```suggestion # table availability in check_src/dst. ```
Use match arg instead: ```suggestion with pytest.raises(TypeError, match='Cannot json serialize'): ```
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
return dict((key, self.get(key)) for key in self.keys())
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
`User has been created`
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
This is what `urlencode()` is already doing for you., so the function would be: ```python def encode_url_params(self, params): """Encodes key value pairs for URL""" return '?' + urlencode(params.items())
Leftover reference to `vcenter`.
And this as well.
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
Please don't add any aliases except for backward compatibility. We don't want to offer more choice than necessary.
Use fail_json_aws for AWS exceptions as the messages contain a lot more info
Use fail_json_aws for AWS exceptions as the messages contain a lot more info
```suggestion self.parser.add_argument("--no-fail-on-errors", action="store_true", default=False, dest='dont_fail_on_errors', ``` A common pattern in CLI args is yup use "no".
pass `port` and `validate_certs` as well. Since these details can be different for destination datacenter.
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
The Base64 decoding can be hoisted out of the loop
For consistency, use `'` as the quote character
This should be `{0}` so it continues to work with python 2.6
This should be `{0}` so it continues to work with python 2.6
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
Both [`exit_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2254) and [`fail_json`](https://github.com/ansible/ansible/blob/ebd08d2a01d96d41f8bc1ccf27bc1bbf91060a44/lib/ansible/module_utils/basic.py#L2261) methods call `sys.exit`: the old code checked that `fail_json` has been called and would have failed if `exit_json` were called in `pip.main`.
And the same here
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
And the same here
You should change this one to ```suggestion return res > 0 ``` to avoid the problem. The function `db_create` is called only in two places; in one place, the return value is ignored (import), and in the other (present), you need to know whether *at least one* DB was created, and not whether *all* DBs have been created. So if you return `res > 0` here, `changed` is determined correctly for `present`.
This inline doc formatting is odd to me. Are you trying to do sphinx format maybe? ``` :param binary: ... :param subsystem: ... :param other_args: ... ```
since force-push ate my previous commit to fix this: s/coloon separated path(s)/path(s) (colon-separated)/
If all you do with `ReverseGradient` is call it, why should it be a class? Everything in the backend is a function.
since force-push ate my previous commit to fix this: s/coloon separated path(s)/path(s) (colon-separated)/
it might not be relevant in this particular case but be aware to better handle LANG when searching in output. use `module.run_command_environ_update = dict(LANG='C', LC_ALL='C', LC_MESSAGES='C', LC_CTYPE='C')` early after `module` has been instantiated to get that covered.
```suggestion out = run_gluster(['volume', 'heal', name, 'info'], environ_update=dict(LANG='C', LC_ALL='C', LC_MESSAGES='C')) ```
Since you're screenscraping, set the locale to C before scraping. See: gluster_peer
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Don't use raw urllib2 APIs. Instead, use `self._request_webpage()`, which is more robust.
it might not be relevant in this particular case but be aware to better handle LANG when searching in output. use `module.run_command_environ_update = dict(LANG='C', LC_ALL='C', LC_MESSAGES='C', LC_CTYPE='C')` early after `module` has been instantiated to get that covered.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
call create, so we are sure the disk is up to date with parameters provided by user.
lacking parameter validation, user should be notified if the minimal requirements for lookup to work are not met
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
`title` must never be `None`.
No `^` and `$`. Override `suitable`.
```suggestion # just get value from attribute itself as normal ```
Actually, why not just do ```py video_params = self._parse_json(self._search_regex( r'\bvlive\.video\.init\(([^)]+)\);', webpage, 'video params'), video_id, transform_source=lambda s: '[' + s + ']') status, long_video_id, key = video_params[2], video_params[5], video_params[6] ``` It should be much more robust.
Raise a `ValueError` instead of an assert (and add it to the docstring).
Raise a `ValueError` instead of an assert (and add it to the docstring).
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
It seems a `ProgrammingError: syntax error at or near "$"` occurs.
Use `to_native` from - https://github.com/ansible/ansible/blob/db304c27c75fd98b78dd0b2e23cb45a014ed6c17/lib/ansible/module_utils/_text.py#L260
"" -> ''
"" -> ''
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Could you explain to me the reasoning behind this change? All your tests pass in yt-dlp without this
Not needed as you have `required=True`
Not needed as you have `required=True`
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
121, 124 - DRY.
121, 124 - DRY.
If you check for the folder path here [compile_folder_path_for_obj] (before breaking) you could return the result and ignore all the other strategies.
This method isn't necessary.
This method isn't necessary.
+1 for to_text
It would be neat if `randomize_list` also accepted a similar `seed` arg for repeatable (pseudo-random) ordering.
``` self.assertRaises(ValueError, get_ip_version, '192.168.0.1') ``` should work with python 2.6 but you can't check the error message.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
Code duplication 173, 213. There is no sense to extract fields explicitly.
You don't need a lambda here. Also, don't break lines with `\`.
Passing `sys.argv[:]` here is useless wrt current implementation. If you look at the `main()`'s first three lines there's: ```python def main(args): ... (options, args) = parser.parse_args() # <-- immediatelly rewrites args variable ``` It looks like the initial implementation has been written by the person with some C-like background, where main accepts args data and returns 0. But in fact in this case it's not needed. Please remove this arg.
Please use a parameterized pytest test instead of this pattern. Example: https://github.com/keras-team/keras/blob/master/tests/keras/layers/convolutional_test.py#L21
Is`atexit` is the right approach here? The registered function will only run when the entire ducktape process finishes (i.e. _after_ all ~215 tests finish). Use of the `tempfile.mkdtemp` will still avoid path collisions from concurrent processes, so maybe it's good enough. Another possibility that at least results in immediate cleanup: put directory removal into `clean_node` (but check the containing directory is present before removing to avoid errors)
You can import `try_rm` from helper
I think truststore and ca could be stored in a single directory. The files are related and are created together.
Is`atexit` is the right approach here? The registered function will only run when the entire ducktape process finishes (i.e. _after_ all ~215 tests finish). Use of the `tempfile.mkdtemp` will still avoid path collisions from concurrent processes, so maybe it's good enough. Another possibility that at least results in immediate cleanup: put directory removal into `clean_node` (but check the containing directory is present before removing to avoid errors)
we already had similar warnings, the controller code will cut them as 'non json output from module' , it would be better to add to a 'warnings' field in the json output
you can move it to before `if` as just `docs = {}` line, this should read better.
I think truststore and ca could be stored in a single directory. The files are related and are created together.
```suggestion except OSError as err: ```
I think truststore and ca could be stored in a single directory. The files are related and are created together.
Is`atexit` is the right approach here? The registered function will only run when the entire ducktape process finishes (i.e. _after_ all ~215 tests finish). Use of the `tempfile.mkdtemp` will still avoid path collisions from concurrent processes, so maybe it's good enough. Another possibility that at least results in immediate cleanup: put directory removal into `clean_node` (but check the containing directory is present before removing to avoid errors)
An example of using the `mocker` fixture. ```suggestion def mock_NamedTemporaryFile(mocker, **args): mock_ntf = mocker.MagicMock() mock_ntf.write = mocker.MagicMock() mock_ntf.close = mocker.MagicMock() ```
makedirs_safe already does this, just use that function
Tests shouldn't be invoked directly, so this isn't needed.
This is never reached if Content-length is not set.
Perhaps it could be SPACEWALK_CONFIG, and be consistent with other variables such as ANSIBLE_CONFIG, [COLINS_CONFIG](https://github.com/ansible/ansible/blob/devel/contrib/inventory/collins.py#L38). Note that gce uses [GCE_INI_PATH](https://github.com/ansible/ansible/blob/devel/contrib/inventory/gce.py#L134), docker uses DOCKER_CONFIG_FILE, nsot uses NSOT_INVENTORY_CONFIG. Not sure what the core devs would prefer here, but perhaps it would make sense to be consistent with ANSIBLE_CONFIG.
Okay I think this makes sense, let's just follow this pattern then.
this is basically noop, unless you are under pipelining, in which you get None, tmpdir will still be populated though
this is basically noop, unless you are under pipelining, in which you get None, tmpdir will still be populated though
You need either `to_bytes(text)` or `text.encode('utf-8')` here as well.
You need either `to_bytes(text)` or `text.encode('utf-8')` here as well.
I think truststore and ca could be stored in a single directory. The files are related and are created together.
You can import `try_rm` from helper
makedirs_safe already does this, just use that function
`%d` in path still does not work: ``` [debug] System config: [] [debug] User config: [] [debug] Custom config: [] [debug] Command-line args: ['--embed-thu', 'https://www.youtube.com/watch?v=bSBTcQNPNqc', '-f', '18', '-v'] [debug] Encodings: locale cp1251, fs utf-8, out utf-8, pref cp1251 [debug] youtube-dl version 2020.09.06 [debug] Git HEAD: bf6c312 [debug] Python version 3.7.0 (CPython) - Windows-10-10.0.10240-SP0 [debug] exe versions: ffmpeg N-85653-gb4330a0, ffprobe N-85653-gb4330a0, phantomjs 2.1.1, rtmpdump 2.4 [debug] Proxy map: {} [youtube] bSBTcQNPNqc: Downloading webpage [youtube] bSBTcQNPNqc: Downloading thumbnail ... [youtube] bSBTcQNPNqc: Writing thumbnail to: How to print %d using printf in C language-bSBTcQNPNqc.jpg [debug] Invoking downloader on '...' [download] How to print %d using printf in C language-bSBTcQNPNqc.mp4 has already been downloaded [download] 100% of 8.39MiB [ffmpeg] Converting thumbnail "How to print %d using printf in C language-bSBTcQNPNqc.webp" to JPEG [debug] ffmpeg command line: ffmpeg -y -loglevel "repeat+info" -i "file:How to print %d using printf in C language-bSBTcQNPNqc.webp" "-bsf:v" mjpeg2jpeg "file:How to print _d using printf in C language-bSBTcQNPNqc.jpg" ERROR: file:How to print %d using printf in C language-bSBTcQNPNqc.webp: No such file or directory Traceback (most recent call last): File "C:\Dev\youtube-dl\master\youtube_dl\YoutubeDL.py", line 2065, in post_process files_to_delete, info = pp.run(info) File "C:\Dev\youtube-dl\master\youtube_dl\postprocessor\embedthumbnail.py", line 61, in run self.run_ffmpeg(thumbnail_filename, jpg_thumbnail_filename, ['-bsf:v', 'mjpeg2jpeg']) File "C:\Dev\youtube-dl\master\youtube_dl\postprocessor\ffmpeg.py", line 239, in run_ffmpeg self.run_ffmpeg_multiple_files([path], out_path, opts) File "C:\Dev\youtube-dl\master\youtube_dl\postprocessor\ffmpeg.py", line 235, in run_ffmpeg_multiple_files raise FFmpegPostProcessorError(msg) youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessorError: file:How to print %d using printf in C language-bSBTcQNPNqc.webp: No such file or directory ```
`%d` in path still does not work: ``` [debug] System config: [] [debug] User config: [] [debug] Custom config: [] [debug] Command-line args: ['--embed-thu', 'https://www.youtube.com/watch?v=bSBTcQNPNqc', '-f', '18', '-v'] [debug] Encodings: locale cp1251, fs utf-8, out utf-8, pref cp1251 [debug] youtube-dl version 2020.09.06 [debug] Git HEAD: bf6c312 [debug] Python version 3.7.0 (CPython) - Windows-10-10.0.10240-SP0 [debug] exe versions: ffmpeg N-85653-gb4330a0, ffprobe N-85653-gb4330a0, phantomjs 2.1.1, rtmpdump 2.4 [debug] Proxy map: {} [youtube] bSBTcQNPNqc: Downloading webpage [youtube] bSBTcQNPNqc: Downloading thumbnail ... [youtube] bSBTcQNPNqc: Writing thumbnail to: How to print %d using printf in C language-bSBTcQNPNqc.jpg [debug] Invoking downloader on '...' [download] How to print %d using printf in C language-bSBTcQNPNqc.mp4 has already been downloaded [download] 100% of 8.39MiB [ffmpeg] Converting thumbnail "How to print %d using printf in C language-bSBTcQNPNqc.webp" to JPEG [debug] ffmpeg command line: ffmpeg -y -loglevel "repeat+info" -i "file:How to print %d using printf in C language-bSBTcQNPNqc.webp" "-bsf:v" mjpeg2jpeg "file:How to print _d using printf in C language-bSBTcQNPNqc.jpg" ERROR: file:How to print %d using printf in C language-bSBTcQNPNqc.webp: No such file or directory Traceback (most recent call last): File "C:\Dev\youtube-dl\master\youtube_dl\YoutubeDL.py", line 2065, in post_process files_to_delete, info = pp.run(info) File "C:\Dev\youtube-dl\master\youtube_dl\postprocessor\embedthumbnail.py", line 61, in run self.run_ffmpeg(thumbnail_filename, jpg_thumbnail_filename, ['-bsf:v', 'mjpeg2jpeg']) File "C:\Dev\youtube-dl\master\youtube_dl\postprocessor\ffmpeg.py", line 239, in run_ffmpeg self.run_ffmpeg_multiple_files([path], out_path, opts) File "C:\Dev\youtube-dl\master\youtube_dl\postprocessor\ffmpeg.py", line 235, in run_ffmpeg_multiple_files raise FFmpegPostProcessorError(msg) youtube_dl.postprocessor.ffmpeg.FFmpegPostProcessorError: file:How to print %d using printf in C language-bSBTcQNPNqc.webp: No such file or directory ```
Is`atexit` is the right approach here? The registered function will only run when the entire ducktape process finishes (i.e. _after_ all ~215 tests finish). Use of the `tempfile.mkdtemp` will still avoid path collisions from concurrent processes, so maybe it's good enough. Another possibility that at least results in immediate cleanup: put directory removal into `clean_node` (but check the containing directory is present before removing to avoid errors)
Anyway, removal of `return 0` was not related to the purpose of the PR, but related to my refactoring suggestion. So it fits next to your change :)
Is the support for multiple pids only for clean up? Since the code checks for a fixed control file, I was thinking we expect only one process at a time.
With a timeout, this function will return False if the lock cannot be created. Without a timeout, this function will raise an exception. You should decide on one strategy or the other and implement it for both.
I think truststore and ca could be stored in a single directory. The files are related and are created together.
Should this be `num_lines=3` for all three (cf. L140-L142)
I think truststore and ca could be stored in a single directory. The files are related and are created together.
Shouldn't need this line, it's handled by the superclass's constructor.
makedirs_safe already does this, just use that function
makedirs_safe already does this, just use that function
Hmm, doesn't seem like this is correct. >version ['1', '0', '0-SNAPSHOT'] major_minor ['1', '0'] Extracting ['tar', 'xf', '/Users/ijuma/src/kafka/core/build/distributions/kafka_2.11-1.0.0-SNAPSHOT-site-docs.tgz', '--strip-components', '1'] Traceback (most recent call last): File "./release.py", line 235, in <module> command_stage_docs() File "./release.py", line 227, in command_stage_docs cmd('Extracting ', 'tar xf %s --strip-components 1' % docs_tar, cwd=os.path.join(kafka_site_repo_path, docs_version(version))) File "./release.py", line 108, in cmd output = subprocess.check_output(cmd, *args, stderr=subprocess.STDOUT, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 566, in check_output process = Popen(stdout=PIPE, *popenargs, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 710, in __init__ errread, errwrite) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 1335, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory: '/Users/ijuma/src/kafka/../kafka-site/10'
Also, it seems like our convention for docs versions is quite bad. If we didn't want to use `.`, we could use something else like `_`.
again, this syntax we should phase out ``` asks_file: "{{ lookup('first_found', files=['tasks.yaml', 'other_tasks.yaml'], errors='ignore') }}" ```
They're not being added in _get_loop_items, it seems like they're added in the internal execution so this may be the easiest way to clean them up.
`del` is a builtin, not a function. These parens don't have to be here
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
I might suggest use `conn.shell.has_trailing_slash` and `conn.shell.join_path` like the copy module for any path manipulations on `dest`.
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
This is not used in single video extractor thus should not be here.
When `user_data` is `None`, an error occurs: ``` AttributeError: 'NoneType' object has no attribute 'items' ```
When `user_data` is `None`, an error occurs: ``` AttributeError: 'NoneType' object has no attribute 'items' ```
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
Why do we need to create the intermediate tuple? ```suggestion for ie_key in set( map(lambda a: a[5:], filter( lambda x: callable(getattr(TestDownload, x, None)), filter( lambda t: re.match(r"test_.+(?<!(?:_all|.._\d|._\d\d|_\d\d\d))$", t), dir(TestDownload))))): ```
When `user_data` is `None`, an error occurs: ``` AttributeError: 'NoneType' object has no attribute 'items' ```
Meh, what you have is fine for now- they're basically singletons already, so that constructor arg is probably superfluous, but I don't think there are any active plans to kill it... Just IIUC whatever reason it existed for in the first place doesn't exist anymore. So this looks good to merge to me.
```suggestion value = super().__get__(obj, obj_type=obj_type) ```
So if I update some parameter+ change state to running, it won't start, IIUC
rephrase of 'never used options, now it is recommended to always use options' .. which is 'format neutral', covering both `k=v` and `k: v`
rephrase of 'never used options, now it is recommended to always use options' .. which is 'format neutral', covering both `k=v` and `k: v`
rephrase of 'never used options, now it is recommended to always use options' .. which is 'format neutral', covering both `k=v` and `k: v`
rephrase of 'never used options, now it is recommended to always use options' .. which is 'format neutral', covering both `k=v` and `k: v`
In `check_mode: yes` the returned query will always be `SELECT 1 FROM 'tablename'`. But this is not what I expected. Normally I like to see what query will be executed for that change. Please change this behavior to always return the query which will be executed even if it is not in `check_mode: yes`
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
All of them should be is None IMHO.
All of them should be is None IMHO.
Lowercase this one too, please.
Lowercase this one too, please.
tempted to say just use check_opts=True and remove syntax check afterward with remove_option (we do this in ansible-inventory).
Change to 0.
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
Another (and possibly cleaner) way to do this is to use `pytest-mock`: ```python class SpiedOnTarget: @staticmethod def do_a_thing(): return None def test_empty_retry_iterator(mocker): decorate_with_no_retries = retry_with_delays_and_condition(backoff_iterator=[]) spyable = mocker.spy(SpiedOnTarget, do_a_thing) invoke_retriable = decorate_with_no_retries(SpiedOnTarget.do_a_thing) invoke_retriable() assert spyable.call_count == 0 ```
Now you break extraction if any of these keys is missing.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
both are valid tests, i don't see why you need to eliminate the existing one
This condition is not needed, t is always None here.
This condition is not needed, t is always None here.
This condition is not needed, t is always None here.
For readability please include a blank line between tasks ```suggestion - name: Retrieve credential from CyberArk Vault using PAS Web Services SDK via Central Credential Provider ```
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
`.lrc` may contain another tags apart from time tags (ID tags) that are completely filtered out now.
Please update the method doc to reflect this change
so this makes more sense now
What would be required for this to be idempotent, e.g. support check mode. http://docs.ansible.com/ansible/playbooks_checkmode.html
You should probably expect unicode strings
Mark any string that you are going to call encode on as a ```u"string"```. Otherwise you can run into problems on Python2.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
```suggestion parsed_network['options'] = clean_dict_booleans_for_docker_api(network['options']) ``` While this also accepts `True` and `False` (and converts them to `"true"` and `"false"`), it makes sure that all keys and values are strings.
Instead of making the plugin aware of the tests, use `mock.patch` to mock the `LPass` class in the tests.
Please change this to a guard expression, just like the one above: ```python if group_data is None: return for key, data in group_data.items(): # it's one tab less now ^_^ ``` It helps to keep nesting low and style would be more consistent.
```suggestion query=dict(type='list', elements='str'), ```
I think that may be a result of running the module in the way you are. But it shouldn't be. Imagine you aren't running the module "locally" but running it on a remote machine.
to_text and u prefix on string.
CI failure due to python 2.4 syntax error: ``` 2017-02-09 14:40:48 Compiling ./lib/ansible/module_utils/network_common.py ... 2017-02-09 14:40:48 File "./lib/ansible/module_utils/network_common.py", line 110 2017-02-09 14:40:48 data = b"" 2017-02-09 14:40:48 ^ 2017-02-09 14:40:48 SyntaxError: invalid syntax ```
I think this should be a mandatory option when creating a disk and we don't randomly choose one.
Use `self.url_result(inner_url, 'Generic')` instead.
Probably better to write this as ``` python if self.args.refresh_cache or not self.is_cache_valid(): self.update_cache() ```
```suggestion version = "(unknown version)" ```
Probably better to write this as ``` python if self.args.refresh_cache or not self.is_cache_valid(): self.update_cache() ```
`expected_status` to `_download_json` instead.
`expected_status` to `_download_json` instead.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
`expected_status` to `_download_json` instead.
`expected_status` to `_download_json` instead.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
The pylint error is occurring because this `MockSelector` class shadows the one on line 59.
This branch is never reached.
can you add spaces? `new KeyManager[] { km }, new TrustManager[] { tm }`
This is to align new Ansible facts guidelines - ```suggestion return {'changed': self.change_detected, 'failed': False, 'screenshot_info': screenshot_facts} ```
Don't assign a lambda function, use def
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
Then use `enumerate()` instead.
This should set self._connected = True (not really needed right now but could have ramifications later) and also use display to print a message. For instance, this is what the docker connect plugin does: ``` def _connect(self, port=None): """ Connect to the container. Nothing to do """ super(Connection, self)._connect() if not self._connected: display.vvv(u"ESTABLISH DOCKER CONNECTION FOR USER: {0}".format( self.actual_user or '?'), host=self._play_context.remote_addr ) self._connected = True ```
Then use `enumerate()` instead.
Then use `enumerate()` instead.
is `ts` well known word for Traffic shaping? If yes, then I am ok. Otherwise, key name can be `traffic_shapping` or something similar.
I don't know if the query element is really needed. It seems superfluous as the API is already directed to this vserver. (But we found other cases where the request seems over qualified).
Need these to be kwargs for safety; generated Azure SDK is unsafe to use positional args. We're trying to move everything there to use kwargs.
You are right! Fixed it in https://github.com/mheap/ansible/pull/3.
Need these to be kwargs for safety; generated Azure SDK is unsafe to use positional args. We're trying to move everything there to use kwargs.
This file will be kept locally and will not be deleted. It's to reduce amount of API calls during the execution.
I would suggest we at least display a message for this exception...
I would suggest we at least display a message for this exception...
I'm trying to think of a different class name, especially less confusable with `ManageIQAlert`. But I don't have any good suggestion. (this does fit the class naming in existing manageiq modules, matching the module name, but that's not such a good scheme IMHO, no reason to stick to it...)
Wrap `then` and `else` with ` to make the sentence easier to parse.
This doesn't seem right... It's ignoring the push and pull mode parameter altogether so I think it will break that functionality. IIRC, ternary also isn't available in python 2.6... just write it out as an if-then-else, it will be easier to understand as well.
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
The batch size dimension might not be `None`. It has to be specified in quite a few situations (e.g. usage of the present layer in a stateful network).
This doesn't seem right... It's ignoring the push and pull mode parameter altogether so I think it will break that functionality. IIRC, ternary also isn't available in python 2.6... just write it out as an if-then-else, it will be easier to understand as well.
You can place fixtures into a conftest.py file and then they will be loaded automatically instead of needing an implicit import.
https://github.com/mozilla/sops/blob/afd073a5be0fe2232d7cd345b9b30edc70ccb962/cmd/sops/encrypt.go#L32 ```suggestion class SopsFileAlreadyEncrypted(SopsError): ```
```suggestion query=dict(type='list', elements='str'), ```
should be self.forward.
This ignores the input `value` and always returns the value of the `spring.mustache.formatter.value` property.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Actually, it's an opposite. It's a check for successful login.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Actually, it's an opposite. It's a check for successful login.
'+' is redundant here.
This is pointless.
`headers` now can be passed right in `_download_webpage`. Also there is already the same dict in `login_request` that may be extracted and reused.
Actually, it's an opposite. It's a check for successful login.
This should be a character string (prefixed with `u`)
On python 2 `root` is byte string and `file_path` is unicode. When `root` contains non-ASCII `os.path.join` fails when trying to decode with default ascii encoding: ``` C:\temp\ÑÐµÑÑ\youtube-dl>youtube-dl.exe -vs test:youtube [debug] System config: [] [debug] User config: [] [debug] Command-line args: [u'-vs', u'test:youtube'] [debug] Encodings: locale cp1251, fs mbcs, out cp866, pref cp1251 [debug] youtube-dl version 2015.12.18 [debug] Python version 2.7.10 - Windows-7-6.1.7601-SP1 [debug] exe versions: ffmpeg N-73189-g7728d23, ffprobe N-73189-g7728d23, rtmpdump 2.4 [debug] Proxy map: {'http': 'http://127.0.0.1:8888', 'https': 'https://127.0.0.1:8888'} Traceback (most recent call last): File "__main__.py", line 19, in <module> File "youtube_dl\__init__.pyo", line 414, in main File "youtube_dl\__init__.pyo", line 404, in _real_main File "youtube_dl\YoutubeDL.pyo", line 1676, in download File "youtube_dl\YoutubeDL.pyo", line 664, in extract_info File "youtube_dl\extractor\common.pyo", line 291, in extract File "youtube_dl\extractor\testurl.pyo", line 65, in _real_extract File "youtube_dl\utils.pyo", line 2556, in translate File "youtube_dl\utils.pyo", line 2604, in find_file_in_root File "ntpath.pyo", line 85, in join UnicodeDecodeError: 'ascii' codec can't decode byte 0xf2 in position 6: ordinal not in range(128) ``` `root` should be decoded with proper encoding: ``` python full_path = os.path.join(decodeFilename(root), file_path) ```
We used dd rather than cat in the jail, chroot, and zone plugins. Can use similar code here. I believe that code also does this without a shell which could be nice for making this more generic (not that most installs will be lacking bash but it's always nice to avoid) and potentially avoiding shell quoting issues.
some of the magic vars rely on post_validate already being run to have the correct value
CI failure due to: ``` 2017-01-31 18:50:23 ERROR: PEP 8: lib/ansible/module_utils/netapp.py:150:31: W292 no newline at end of file (current) ```
It's a statement, not a function. ```suggestion assert ansible_json_encoder.default(test_input) == expected ```
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
I would just make this a plain function that calls fetch_url and then lowercases the keys instead of making it a decorator. I'm a little hesitant about overriding the name (I'd use a different name than fetch_url) but I can see you do that so you don't have to change the name everywhere. Since I'm not the module author, I won't block it over that but I think it's better style to use a new name.
As this may need to be updated, consider 1. make the value a class var `_USER_AGENT` 2. import utils.std_headers and let non-null `std_headers['User_Agent']` override this value, so that `--user-agent ... ` or `--add-headers "User-Agent: ..."` take precedence (allows cli work-around if the site needs a new UA).
@annikulin it needed more work than I initially thought to get httpapi plugin host var working. Probably we can commit this code as is and I will commit a followup PR to make it configurable using ansible host vars
If you expect this invocation to emit an exception, `assert`ion doesn't make sense here: ```suggestion ansible_json_encoder.default(test_input) ```
As this may need to be updated, consider 1. make the value a class var `_USER_AGENT` 2. import utils.std_headers and let non-null `std_headers['User_Agent']` override this value, so that `--user-agent ... ` or `--add-headers "User-Agent: ..."` take precedence (allows cli work-around if the site needs a new UA).
Could you have a syntax close to : ``` if not re.match(): raise ... ``` That we don't have as much indentation levels.
More or less correct not taking code duplication into account. >Aside from the fixes, should we loop and display all of the errors (instead of just `errors[0]`)? You can if this make sense. >Also, is `errors` always a list (remove the `isinstance` check)? There is no such guarantee.
Specify an epoch number
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
```suggestion query=dict(type='list', elements='str'), ```
to_text and u prefix on string.
f is already at 0, the `truncate()` is uselesss.
you can move it to before `if` as just `docs = {}` line, this should read better.
Minor consistency nit- our stuff seems to be using `[action]_[backend]()`, where these aliased imports have that reversed. I'd vote for `[action]_[backend]()` over this- makes the code a little easier to read...
self.ec2 still needs to be defined here. Also, AnsibleAWSModule lets you do `self.ecs = module.client('ecs')` and `self.ec2 = module.client('ec2')`, so you could remove the imports get_aws_connection_info and boto3_conn.
The may match something unexpected. `r'var\s+__desc_popup_d_\d+\s*=\s*({[^><]+});'` is better.
refactor: ```python additional_kwargs = ( {'showAuthenticationRestrictions': True} if authentication_restrictions_supported else {} ) result = db.command( 'rolesInfo', role, showPrivileges=True, **additional_kwargs ) ```
I think this might explode if `obj_type` is not one of `functions`, `indexes` or `tables`, maybe it would be safer to do something like? ```suggestion obj_func = self.obj_func_mapping.get(obj_type.strip()) if obj_func is not None: obj_func() else: module.warn("Unknown filter option '{}'".filter(obj_type.strip()) ```
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
Not something that you have to change but I think this could be simplified to ```python for obj_func in self.obj_func_mapping.values(): obj_func() ```
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
no, if the variable is set but empty, you should empty out the options
same here, we really dont want to test the particular setting, just that both the default (dynamic template) and the nii entry are correctly parsed.
nit: this doesn't need to be a field, you can just use a local variable
Read coding conventions on optional fields.
