You are completely right. What about this? Too ugly?: ``` js_catalog_template = \ r"""{% autoescape off %} ... ```
Nitpick: Append a \ to the end so it doesn't generate an empty first line.
Typo - m2m not m2n
Please add the reference or simply remove the section.
Docstring is a bit confusing.
Unneeded empty line.
Unneeded empty line.
Unneeded empty line.
Unneeded empty line.
Unneeded empty line.
Once again, exec is not needed here.
Why use exec? You can just write contents of the string in the function.
The query.select_related has numerous states: it can be False (for no select_related), it can be True (which seems to indicate that depth based select_related should be used) or it can be a dict (for user-selected restriction). I think here field_dict could end up being True here. In the long run it would be better to split the query.select_related to two variables: one would be query.select_related = True/False, another would ne query.select_related_restriction = None or dict_of_asked_selections. For the time being maybe field_dict = isinstance(self.select_related, dict) and self.select_related or {} would do? (naturally, not tested).
then you should be able to remove [0] from django/contrib/gis/db/backends/oracle/operations.py too (just so we stay consistent) (same for spatiallite)
should be string_types[0]
This test is not such a good idea. I think the order in which signals are executed is not guaranteed but rather an implementation detail and the test does not check if a_signal and c_signal trigger the receiver at all.
I think this is unsafe - this way the _deleted_object_pks is class level variable, not instance level variable. Add this into __init__ instead.
Is there need for the deleted_object_pks as there is already a list of deleted_objs which contains the needed information.
If there's GEOS 3.1 (as on Ubuntu 10.04), however you'll need to raise a `NotImplementedError`.
In fact, unless you have a special sequence like \n, \r, \t, the raw prefix is not strictly necessary. But for consistency, it's better to always add it to indicate that none of the escaped letters have to be interpreted as special-meaning sequences.
I think that the string should be prefixed by 'r' (raaw string), so as the backslashes are not interpreted as special sequences.
You can use `type='choice'` with `choices=['ipython', 'bpython']` for options with a predefined set of choices: http://docs.python.org/library/optparse.html#optparse-standard-option-types
assertEqual(..., True) -> assertTrue(...)
This is now an unused import - `strftime` is a method of the `datetime` instance
simpler: datetime.now().strftime(''%B %d, %Y - %X')
This should be a `tuple`.
It might be worth compiling the regexp in the class or [module level and reuse](https://github.com/django/django/blob/master/django/contrib/localflavor/ca/forms.py#L16-L17).
Is it necessary to have the PEP8 fixes in this pull request? I'm not sure what the recommendation is for the Django repository, but in my own repositories I ask for either a PEP8 fix before the code changes, or one just after (to separate out changes which should have no functional impact).
This line is now an unused import
``` py % (float_number) ``` Note: The parentheses are not required here.
These tests don't pass TypeError: today() takes no arguments (3 given) happens again in test_date_list_order
Doesn't this line need to be outsite the `{% for %}` loop? Otherwise it gets called for each `o` and won't actually cycle...
Fair, that's me misunderstanding what the tag actually does. Looks great then!
What's the point of this query? I don't see anything in the view which could delete users (and even then, why should it delete users…)
Is there really no alternative to a plain except? This would even catch KeyboardInterupt etc which we surely don't want. Which exceptions can occur here? As a last resort you can use except Exception, but I'd prefer it explicit.
I'm almost sure the "smart" is not needed here. Just use force_text. However, do we know what type of encoding is expected here? If it is UTF-8 encoded string, we should use force_bytes instead.
This behavior doesn't exist in the current implementation of `HttpResponse`.
I'm not sure it's useful to implement _set_container in the base class, as the path seems different depending on stream.
These last four lines are duplicated in both conditions, should therefore come after the if block.
I think you should use `six` to support both Python 2 and Python 3. ``` py from django.utils.six.moves import xrange ```
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
I don't think it's accurate to query the database at init time, as we are not even sure yet that we will need this info. I'd rather have a cached property, so it will only get fetched when we really need it.
That's already better, but there is even a cached_property decorator in django.utils.functional that does the job of caching the value.
I wouldn't create the postgis_topology extension, as AFAIK it is not used currently in Django.
``` cursor.execute("CREATE EXTENSION postgis") cursor.commit() ```
It would be more elegant, and possibly more efficient, to use: ``` template_postgis = getattr(settings, 'POSTGIS_TEMPLATE', 'template_postgis') cursor.execute('SELECT 1 FROM pg_database WHERE datname = %s LIMIT 1;', template_postgis) if cursor.fetchone(): return template_postgis ``` This is how `QuerySet.exists()` is implemented.
Nitpicking: I would have reused the test_invalid_project_name test, looping on "for project_name in ('7testproject', '../testproject'):". This would allow us to test more names with less code duplication.
Here's how I would have written it: https://gist.github.com/3911240. Hopefully it's not worse than the previous version.
Two things to note here: 1. I don't like much the dependence on settings.DEBUG. Either unconditionally raise, as done in other parts of this file, or make usage of the logging infrastructure (getLogger('django.template'), logger.error(...)). 2. I'd like to keep the return statement at the end, if possible
I know that logging is currently not used, but it might/should in the future. Let us forget this now, this should be the subject of a separate ticket anyway. But then I'd advocate for unconditionally raising the TemplateSyntaxError.
This test doesn't fail either in current code. I suggest to simply drop it. No need to update the pull request, I'm going to commit the patch soon.
follow -> following
According to the 1.6 release notes, the _has_changed method on widgets has been deprecated, so I don't think this should be necessary? "If you defined your own form widgets and defined the _has_changed method on a widget, you should now define this method on the form field itself." (looks like ReadOnlyPasswordHashField already has _has_changed implemented)
This change isn't needed and adds a bit of noise.
You could put that on two lines, it would increase readability IMHO.
`and 'DummyCache' in`
This should be a PendingDeprecationWarning at this time. (Also a \n would help readability.)
pass the context like the `index` method above does. it's bad practice to include mutables (in this case a dictionary) as the default of a kwarg
should be `extra_context or {},` (include a trailing comma)
This is wrong, `SESSION_COOKIE_NAME` is the name used in the cookie, not an attribute name on the `request` object. Besides it isn't equal to `'session'` by default.
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
Blank except is a nogo.
You at least have to reset this at the end of the test to not leak this change into other tests (use try/finally)
I see. `npath` sounds good. IMO the alternative is to explicitly encode under Python 2: ``` if not six.PY3: pf = pf.encode(fs_encoding) os.environ['djangocompilemo'] = pf + str('.mo') os.environ['djangocompilepo'] = pf + str('.po') ``` where `fs_encoding` would be imported from `_os`.
At first sight, I don't understand why you replaced `repr` by `str`, but if you have a good reason go ahead.
Minor: I would put this line inside the `with` block. Yes, `cm` leaks outside the block, but that isn't clean :) There's a few other instances of this below.
For the reasons explained above, I would avoid `force_str` if possible. For instance, it's to override `test_dir` with a native string version at the top of the function: ``` test_dir = os.path.dirname(os.path.dirname(__file__)) project_dir = os.path.dirname(test_dir) base_dir = os.path.dirname(project_dir) ```
This code assumes that the filesystem uses 'utf-8', because that's what `force_str` defaults to. Furthermore, under Python 2, when `force_str` (ie. `force_bytes`) is called on a bytestring with as encoding argument that isn't utf-8, it decodes the string with utf-8 and re-encodes it with the given charset. In this case, that isn't desireable. I think it'd be safer to use: ``` os.environ['djangocompilemo'] = pf + str('.mo') os.environ['djangocompilepo'] = pf + str('.po') ``` (assuming code works, I didn't test) IIRC Python 3 automatically encodes environment variables set to unicode values. That techniques offloads the problem to the language :)
Same here, remove the `u` before `"true"`.
This fails under python 3.2.3: `AttributeError: 'NamedNodeMap' object has no attribute 'has_key'`
You don't need the unicode `u` prefix here since you're importing `unicode_literals` from `__future__`.
I don't think you can do it like this for multicolumn lt, gt constraints. The natural constraint is: a < val1 or (a == val1 and b < val2) at least that is what PostgreSQL gives you. EDIT: We can just throw an error in multicolumn non-exact lookups here for now.
why opts.pk here? Not saying this is incorrect, but I just don't see immediately why this is a correct replacement for the above. The old code above was copy-paste from old code in sql/query.py, and I never got to the point of actually understanding what it is doing.
Yeah, multicolumn case is what I am interested in, the results will not be correct for cases where the first column match, the second is smaller and we use __lt. So, error out in multicolumn case for now, then lets think if we can make this work properly (for some DBs the DB itself knows how to implement (a, b) < (val1, val2)).
Q never used
I don't know of this particular case, but I wonder if we will have a fun time ahead regarding NULL handling in general - partial match foreign keys etc, and what it in general means for a composite field to be null... There are some similar cases in Query.add_filter() negated handling.
Colorize is not tested currently: http://ci.djangoproject.com/job/Django%20Coverage/HTML_Coverage_Report/_var_lib_jenkins_jobs_Django%20Coverage_workspace_django_utils_termcolors.html#n43 So testing the return value makes sense for me.
`min` and `max` attrs should only be added if `self.localized is False`
`step` attribute should only be added if `self.localized is False`
This should be done this way instead: ``` python @property def input_type(self): return 'text' if self.localized else 'number' ```
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
I would have put the strings in a list, then finally ugettext(", ").join(the_list)
I would suggest to use the ungettext_lazy('%(number)d minute', ''%(number)d minutes', 'number') syntax, if possible.
I think this patch is still valid, to be honest. Having a reverse proxy or load balancer is a valid use case and it is not unusual or against the HTTP spec for those to include a port number in the `HOST` header.
I think there are enough tests about forms using the formats machine to sanitize input values. I'd rather specifically tests `sanitize_separators` in a separate `test_sanitize_separators` test.
This unfortunately doesn't guarantee that all transactions are always rolled back. _dirty is never set if you run read-only queries in the default autocommit mode, yet transaction is started by any query (the cursor.is_dirty() checks if transactions are managed before setting ._dirty). It seems making sure ._rollback is called after every request would be a god idea if the connection isn't going to be persisted. Even better approach is to make the _dirty flag behave somewhat sanely. But this is not this issue's problem.
I think this is an extra import that isn't used anywhere. Same in each of the `backends/*/base.py`.
This will accept prefixless sha1 hashes which weren't accepted previously.
use `unittest.skipIf` decorator on the class
This points to something weird: if I do `dumpdata --pks 2,3,4 app` I'll get _any_ object of any type with PKs of 2, 3, or 4. That's... weird. I think a better approach would be to make `--pks` only work if you've specified a _single_ model. So `dumpdata --pks 2,3,4 app.Model` will work, but `dumpdata --pks 2,3,4 app app2` would through an error.
I don't like the idea of reading from stdin; that's unlike how any other management command works. Let's take this part out, I think it's YAGNI.
This whole `try`/`except` logic can be replaced by a `self.assertRaises(SSLError, backend.open)`.
Please move [standard library imports](http://www.python.org/dev/peps/pep-0008/#imports) with the [other ones](https://github.com/ezequielsz/django/blob/90a9140051aeeb84ab9d46c6209f42c5c3820908/tests/regressiontests/mail/tests.py#L4-L11).
Maybe we could raise a `ValueError` if `self.use_ssl and self.use_tls`? The message should also make reference to `EMAIL_USE_SSL` and `EMAIL_USE_TLS` since we default to them when `use_(ssl|tsl)` are `None`.
Python 3 doesn't have a long type any longer. You should probably special-case Python 2 here (same remark for the test).
Might be worth renaming this to `self.root_queryset`.
And this to `self.queryset`.
No need, I will commit the patch soon.
If it is already in the env, can we be sure that we are able to reuse the socket? Does the following code work in pyhton 3.4? I think sockets are not inherited by child processes there. (On the run, but should get investigated)
Move that import before `os`.
This should be fixed.
Minor: I tend to prefer testing with a literal: "John Doe was created successfully". That's slightly more reliable. But that's your call :)
Is this conditional really necessary? If it is, it means that in some cases a success message with placeholders could be returned, that sounds bad.
This is actually done by `SimpleTestCase` now.
Call `super` here instead.
This code isn't correct. (2, 7) is the check you want, and then with >= if I am not mistaken.
Looking at collections source code I think you mean `collections.Iterator` here.
Actually `e` is unused here, may as well remove it.
We can't assume six is installed; Django bundles it. This line needs to be `from django.utils import six` instead.
This is not Python 3 compatible; needs to use `except ImproperlyConfigured as e` instead.
"actor" variables are unused
Should be able to fix it when committing, just making a note of it. Thanks for the patch; I happen onto the problem from time to time as well. :-)
"actor" variables are unused
Like so: ``` EXCLUDE_FROM_PACKAGES = ['django.conf.project_template', 'django.conf.app_template', 'django.bin'] ```
Please don't add a new private method, just do this check in `__new__`.
Why the underscore? "[Nonexistent](http://www.thefreedictionary.com/nonexistent)" is a legitimate word according to the Collins English Dictionary.
Let's call this `non_existent`, please.
I don't care about the underscore, only about the non-existence of the word "inexistant".
Not important, but I think it should be `{"key": "value"}` (note the added space after the colon) per pep8.
You don't need to call `bool` since `assertFalse` does this (same goes for the next line).
should the error message on line 333 change as well? (it's the same as this one)
The `L` suffix raise a `SyntaxError` under python3. This should be `lambda: long(9999999999999999999)`.
Leave an empty line between stdlib imports and project ones.
I would use `force_text` here as "%s$%s" is always unicode due to unicode_literals import.
This method should be added after the docstring
it seems to me like this sort of docstring belongs on the keys method itself and not the test
I haven't looked at the code and perhaps it's obvious, but where do 'None', 'True', and 'False' come from? I wouldn't expect them to appear given the testing data.
Also, what is it doing? I would have thought this would happen automatically
does this actually raise an error if validation fails? - I seem to recall that errors are just printed to stdout I know you are pushing into new testing areas here (thanks for going the extra distance BTW) but a failing test would be nice to at least demonstrate this testing approach
Yup, good point.
I think it's a perfect use-case for a set. Changing it to `set(['DATABASES', 'CACHES'])` would be compatible with python2.6+ (which is what we support for now).
I would add the explanation: "Settings that may not work well when using 'override_settings'
Set literals are Python 2.7+ only, so this won't work for now. It would need to be a list or similar at the moment.
I think this test should be in its own class so it can have a setUp/tearDown with the "old_warn_override_settings" logic. If the assertions fail, COMPLEX_OVERRIDE_SETTINGS won't be restored to its original values which would cause the test to leak state.
Please use the implied line continuation in braces instead of backslashes.
The indentation is a bit odd here, it gives the impression that the second line is still in the isinstance()
fget is the first positional argument, just do property(fget) (and probably use my_property or something similar instead of fget as method name)
Please add a blank between # and the following word.
We need to remove these blank lines which were added
Please use `self.assertEqual`
That would gobble any TypeError raised in `Field.clean()`.
create -> creates
remove this assertion? (see 90af278203963e3e3f96e443971cd38a2dad34e4)
please rebase your changes, this assertion has been removed
This is not used only by `get_or_create`.
- More code - Less obvious code than the original - Overly long constant name - Style not used in the rest of Django
In this case the current state of things is preferrable to this pull request. :-1:
Better yet: `empty_label or VERBOSE_BLANK_CHOICE_DASH`
Cleaner API with `empty_label=None`
I'm not sure this line belongs here
remove u'' prefix (syntax error on Python 3.2 and unnecessary since this file has `from __future__ import unicode_literals`).
This could be made much simpler by adding `attrs['for'] = id_for_label` and remove the duplication between the templates. I don't know if there's any particular reason not to do that.
I think although `JSON` is better, I'd rather this was consitent with all of the other `HttpResponse` classes. Doesn't make the correct, but consistence should come first here.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Please alphabetize imports.
I can see a decent reason to use the `DjangoJSONEncoder` as the default as it gives us `Decimal` and `datetime` support for free. These are very common use cases for django sites (especially datetime!).
set the safe
May as well put in the newline here.
consider assertRaisesMessage so you can check the error message as well.
"utf8" appears to be most commonly used
newline after json
I'd chop the intermediate variable
There should be 1 newline (the little icon that github displays shouldn't appear).
@lukaszb which contrib/admin file are you talking about? Notice [how contrib/admin/options.py](https://github.com/django/django/blob/master/django/contrib/admin/options.py#L1860) doesn't have the missing new line icon. Make sure not to add two newlines, just put your cursor right where the missing new line icon is and press ENTER once.
Instead of adding this extra attribute you should set `'application/json'` as the default `content_type` in the `JSONResponse.__init__`.
The class should really be named `JSONResponse`.
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
Use `ConcreteRelatedModel.objects.get(bases__id=base.id)` here instead of comparing lists.
Use `assertEqual(base, rel.bases.get())`.
Use `assertIsNone` instead.
Giving a last review before committing. Thanks Michael for your efforts and your patience. Don't you think this block would be more readable in this form?: ``` python # We need an email.Message object if isinstance(content, EmailMessage): # convert content into an email.Message content = content.message() elif not isinstance(content, Message): # For compatibility with existing code content = message_from_string(content) ```
this method doesn't appear to be necessary
no spaces around = (mangle_from_ = False)
I think this line should be: ``` try: os.makedirs(...) finally: os.umask(old_umask) ``` so the umask is reset in case of an exception
May as well while we're here
Since we don't have to support old python versions anymore, you can use the `@property` syntax, which I think is more readable.
This should be Django's vendored copy `from django.utils import six`
I'm not sure the usage of `settings.FORMAT_MODULE_PATH` is correct here. Now the `format_module_path` keyword argument is no longer used (thus the failing test, I think).
don't need the trailing comma
basestring isn't Python 3 compatible. Please use `six.text_type` instead.
Looks good, my mistake.
I think we could swap this and the previous `if` over - no reason to do the `has_related` check if we've specified the list. Alternatively, move the `has_related` inside an `if ... is False`
This should use a variant on the `check_isseq` used elsewhere in the file. At present this does restrict you to a list or a tuple, but we may as well keep this consistent.
Same situation here - it may be easier to check the reverse case (`isinstance bool`)
Why cast to a tuple? We could just check if it's falsey...
I believe this change could have some unintended consequences. Query.setup_joins() has an allow_explicit_fk parameter, and this change will likely break that code. (I haven't tested this, but seems likely...)
Almost forgot this one... I think it would be nice to allow attnames to work for .update() - the attnames are usable almost everywhere, so having them available in even more places doesn't really hurt. It is worth checking if the allow_explicit_fk could be removed from ORM, and the proposed patch added to init_name_map(). I am not sure what (if anything) this would break. Quick look indicates that allow_explicit_fk is set to True somewhat randomly. Another option is to deal with this inside update, but as said that amounts to another hack.
Brackets around the left hand side shouldn't be needed
would it make sense to make this a property? the class seems a bit inconsistent as to property vs. method, for example I see that initial_form_count is a method
These tests should be skipped if docutils isn't installed ``` try: import docutils except ImportError: docutils = None @unittest.skipUnless(docutils, "no docutils installed.") class DefaultRoleTest(TestCase): ```
You don't need the trailing \ here. EDIT: I see you just moved that code, that's fine.
`User.objects.latest('pk').pk` would look better IMHO.
There's no circular import issue here, is there? The import should go at the top of the file.
need to add ``` fields = '__all__' ``` on Meta to avoid a deprecation warning
Nitpick, you could have used `MAX_GET_RESULTS` here to avoid breakage if we ever change this constant.
I'd prefer to keep the docstring consistent with those in the rest of the file (which don't have the extra line).
rephrase: signed more than max_age seconds ago (also remove extra newline in docstring)
For this and all of the above methods, the docstring should be enhanced to explain the case that returns blank.
That's not "cruft" -- that's making user code look like it was written after Python 2.4 was released. And also, ``` python @classmethod @queryset_only def as_manager(... ``` does work.
Why not use decorator syntax for classmethod? While you're at it, why not hide the queryset_only attribute in a decorator: ``` python def queryset_only(method): method.queryset_only = True return method ```
Some explanation on why this is needed would be nice
Not required (starts with _)
Following your note on `_update` below -- keep the `queryset_only is None` part; otherwise you can't override the default to avoid copying private methods.
Well then, might be bikeshedding, but in that case I'd just use the name Manager all the way through; `Manager = Manager.from_queryset(QuerySet)` should work fine, and will avoid the wrong message about a Manager class without queryset methods.
The use of Empty that is imported from models.fields looks very weird until one looks at its definition. Can't you use object() directly? Edit: No, you can't, Python2 won't let you. Still, the use of a class imported from fields feels hackish.
Yes, I realized that a little after I posted but I had to run off. I suspect this points to a worthwhile refactoring of _get_queryset_methods to a function, say `get_exportable_methods`, that is defined next to the QuerySet class, and takes a QuerySet class and a filter. That would keep all handling of the queryset_only flags in django.db.models.query, which I'd find preferable. But I wouldn't push for that too hard.
Ok, Carl's argument is convincing enough for me.
I think it's a better API; a custom manager could be using its name in a `__new__` method.
Django doesn't use _-prefixes consistently in general, and never uses them for class names.
This would be more readable as a one-liner: `predicate = inspect.isfunction if six.PY3 else inspect.ismethod`
Please add parentheses around the `and` block, precedence isn't obvious.
I think we usually omit a newline after docstrings
Might be nice to copy `__doc__` here as well
Could we call this `BaseManager` instead? That's what it is now...
This inner import is a syndrom of the circular dependency between `Manager` and `QuerySet`. Could we avoid it by moving this code inside `_Manager`? `Manager` would know how to create a subclass of itself with the methods of a given `QuerySet`.
`quote` isn't used anywhere.
Need spaces around `-` sign.
Need spaces around `+` sign.
no space between "e. g."
Yeah, the import itself is very likely non-necessary, too.
I can't see a need for it...
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
Much better IMO, I haven't managed to fail it but let's see what @aaugustin thinks. I didn't find any other usages of `get_app_paths()`. Edit: I probably should have posted that globally since it's not directly connected to this line of code.
I think I'd prefer not to make the PEP8 changes, the existing style seems fine to me.
should this consider both updateteddate and pubdate together? i.e. right now if entry A has updatedated date yesterday and entry B has pubdate today, it looks like entry A will be considered the latest.
not listing updateddate as the last kwarg is technically backwards incompatible if someone is calling this item using args instead of kwargs but it seems unlikely to me.
Oooooh. _/me grabs shovel, digs hole, hides_
You can probably use `assertSequenceEqual` here which might be a bit nicer.
As discussed on IRC: no.
Why has this logic changed? I can't see what it has to do with removing the use of `_clone()`
No, I think you've changed both of them. I don't think they're any more similar now than they were, the logic is fundamentally the same and this sort of change is not needed.
remove leading zero from "03" (invalid on Python 3)
I guess yes - having multiple foreign keys to same related field (composite or concrete) doesn't make sense. No need to actually do that pre-commit though.
indentation of 11 spaces seems curious. I usually just intent 4 spaces, in a case like this, other people line it up with the parens, but I would follow the style of the file when in doubt.
it looks to me like we always pass the stacklevel as a kwarg
I'd make an intermediate variable to avoid calling form_list.keys() up to 3 times (same in get_prev_step())
Should this be `r.field.name` so the error in the example of the ticket is: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.target'. Add a related_name argument to the definition for 'parent'. ``` instead of: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.myapp:specialdetail'. Add a related_name argument to the definition for 'parent'. ```
it may be better to replace the try/except with: ``` if hasattr(v, '__call__') v = v() ```
no need to use string interpolation here "The INSTALLED_APPS settings..."
I think we can omit "Please fix your settings."
This second assertion isn't what you want (It'll pass before and after the code change I believe.) Instead, you should be setting `INSTALLED_APPS` to a tuple with duplicates and using `with self.assertRaises(ImproperlyConfigured)`
There should be a space after each comma when defining tuples
Unless I'm missing something, this should be: ``` send_mail(subject, message, from_email, [self.email], **kwargs) ``` why the change to `from_email=None` and removing `[self.email]`? Also, don't remove the double newline above `class User`
I don't think it really make sense to pass recipient_list... the point of using `email_user` is to send mail to `AbstractUser.email`
might want to verify the rest of the email attributes. It will probably identify the bug I pointed about above
the dictionary key/values should be indented
include trailing , (that way if more values are added in the future, we won't have to edit this line again)
two newlines above class name
don't remove double newline and imports should be alphabetized (`from django.core` would be above `from django.db.models.signals`)
don't camelCase variables in Python. Go with underscores, "abstract_user", or just "user".
My question would be: do you need to define a set of allowed characters? Does not just base64 encoding (with the URL-safe character set) the output of secure random not achieve the same goal? On Mon, Aug 4, 2014 at 9:52 AM, Curtis Maloney notifications@github.com wrote: > In django/middleware/csrf.py: > > > @@ -25,6 +25,7 @@ > > REASON_BAD_TOKEN = "CSRF token missing or incorrect." > > > > CSRF_KEY_LENGTH = 32 > > +VALID_CHARS = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789' > > This same set of chars is defined in django.utils.crypto as the default > for "allowed_chars" for the get_random_string function. > > Should we consider making this a more accessible constant? > > — > Reply to this email directly or view it on GitHub > https://github.com/django/django/pull/1477/files#r15738414.
`six` appears to be an unused import both here and in the test.
Well, one concern is that Base64 has a default line length limit, which Python honors. You may not be hitting it now, but someone may in the future.
This should be `assertTrue()` as `assert_()` is deprecated.
Whilst I've not subjected it to exhaustive testing, it did pass some simple doctests: https://gist.github.com/funkybob/6332718
This should be `assertTrue()` as `assert_()` is deprecated.
If I'm not completely mistaken this will fail if the attacker requests a page where `csrfmiddlewaretoken` or `HTTP_X_CSRFTOKEN` is shorter than the `CSRF_KEY_LENGTH`.
The known set of chars is needed to implement the Viogniere<sp?> cipher... look below at line 40
When considering my own approach for this same problem, I specifically avoided using xor as when using it on printable characters, you wind up with lots of unprintables you probably don't want to put in your page. Two approaches I considered were: 1. restricting tokens to hex ascii, and xoring their binary forms 2. using a "caeser cipher" approach, where each char is offset in the list of valid chars by the corresponding char in the random pad. [modulo the list of chars, of course]
" for docstring consistency
Discussion of this function is outside of the scope of this ticket, this is merely a backport of what's already in master and 1.6: https://github.com/django/django/blob/master/django/utils/module_loading.py#L12
Doesn't exist in 1.5, be careful when backporting
This feels wrong, `JSONSerializer = BaseJSONSerializer` should work too (I know we could just import JSONSerializer from signing and use as is, but that feels wrong)
Ups, nevermind; you have it in 1.5 now :/
I'd do: ``` kwargs['separators'] = kwargs.get('separators', (',', ':')) ``` On Wed, Aug 21, 2013 at 8:06 PM, Tim Graham notifications@github.comwrote: > In django/contrib/messages/storage/session.py: > > > ``` > > else: > > self.request.session.pop(self.session_key, None) > > return [] > > ``` > > > > + > > - def serialize_messages(self, messages): > > - encoder = MessageEncoder(separators=(',', ':')) > > look ok? https://gist.github.com/timgraham/dc1cc1abe202d3830eab > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/1488/files#r5903355 > .
In general, this utility is long overdue. In detail, I think error_prefix is odd here -- you're essentially mixing a piece of error formatting (or even logging) with the function.
I'd move the `separators=(',', ':')` into `__init__` of `MessageEncoder`, so we always get "efficient" (having '__json_message' as key doesn't look to efficient ;)) json without having to specify it everywhere. But we can do this in a 1.6 cleanup commit after committing this.
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
As the code itself hints, there's no reason to assume the imported attribute is a class.
please include newlines between methods
there's also six.assertRaisesRegex which can be useful for checking the message
I like to include a trailing comma in cases like this so if more args are later edited it doesn't require editing this line again (keeps git blame cleaner)
like trailing commas in the last item in a dictionary as stated above
This is ready for commit. But... don't you think code this could be more readable moving some code to a new helper function? The existing code is already a bit convoluted, and this fix adds lines and indent levels that make it worth some refactoring.
If so, I think a separate commit would be better.
remove extra newline
there should be 2 newlines above class definitions
remove pdb stuff
This test change doesn't seem to make sense. EDIT: I was reading the diff incorrectly... In any case, a plain except: isn't good. Is there some specific exception type to catch? Or at least, use except Exception so that out of memory errors etc aren't accidentally caught here.
Again, error handling changed.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
I looked into this for some other code I was working on (https://github.com/django/django/pull/1649), and `OSError` is the closest common ancestor that works with the various combinations of Python 2.7/3.3 and Windows/Unix.
Ah, I see why you added it now. I didn't realize it was an existing attribute.
For backwards compatibility reasons, users using the widget like `SelectDateWidget({'id': 'myid'}, [2012, 2013, 2014], True)` this is going to break. It'd suggest to move `months=None` to the end of the argument list.
""" for docstrings
This will be called upon by third party db maintainers. I think it is OK to check each core DB here, and just no do any check for non-core databases at all.
Should the default stay as split_statements()
Usually non-test code doing connection.vendor checks should instead use some database feature flag or backend method. At least this needs an explanation why this is done.
are the Meta classes necessary? the test fails and passes before and after the fix without them
1 line too many.
title.verbose_name and same typo in else branch
Don't have a strong preference, maybe @andrewgodwin could chime in.
IMO, it would be helpful to give the test_migrations_# modules more semantic names as to the purpose of them for each test. I'd also make each assert a separate test method so if there's an issue with the first one, the others can still be run.
I'm thinking about adding a hint to provide a `deconstruct` attribute function for `value`.
This doesn't actually work if `name` and `ext` are both too long: ``` pycon >>> import os >>> orig_name = 'name'*200 + '.' + 'ext'*200 >>> name, ext = os.path.splitext(orig_name) >>> name = name[:255 - len(ext)] + ext[:255] >>> len(name) 709 ```
I'd use six.assertRaisesRegex to check the error message as well
this doesn't seem ideal. Generally we use something like this to skip a test: ``` @unittest.skipUnless( connection.vendor == 'postgresql', "This test applies only to PostgreSQL") ``` However, I am not sure if we want to run this on other backends besides SQLite. We also have the skipUnlessDBFeature and skipIfDBFeature which may be useful instead.
I think the verbiage that you use below (`anonymous user objects`) is more grammatically correct than the `users objects` you use in this instance.
Also a typo here.
I think `sys.maxint` would make more sense here.
`register_to` rather than `registry_to`
extra newline was deleted (should be 2 after imports)
Good point, I guess we can keep it as is. Maybe just rename `site` to `register_to`, i.e. `autodiscover_modules('admin', register_to=site)`
site -> register_to
site -> register_to
I'd call the keyword and variable "registry" and pass in `registry=site._registry` as another application may have a different convention for how it wants to define a registry.
I wouldn't add this newline
well, it's not functionally equivalent. if some imports succeed `site._registry` won't reflect those that succeed before the failure. I was thinking you could add a `registry` keyword to `autodiscover_modules` to allow passing in an optional `registry`.
This test isn't properly acting as a regression test as it passes even if the second change in options.py isn't made.
could we make more specific assertions here using `assertFormSetError` - I think that'll make the test more readable.
This logic could be consolidated to avoid repeating the same conditionals twice. Just check both `max_num` and `absolute_max` independently for `None` and set default as needed, then once they are both set, check that `absolute_max > max_num`. The minor difference in error message here doesn't justify all the repeated logic, IMO; a simple "absolute_max must be greater than max_num" is fine.
I think `base_mgr` would be more clear/consistent with the rest of the code
IMO, these tests would be less verbose with assertRaises. what do you think? edit: actually I'd use six.assertRaisesRegex to verify the message 'Good' (maybe change it to something better) so you're sure you didn't trigger an AttributeError some other way in the test.
That's probably worth adding to the release notes in the (admittedly unlikely) case that someone's (a) doing that and (b) reads the notes :)
Why does this change the existing test? Generally, changing old tests indicates that you're introducing a potential regression, because old behavior isn't going to be tested any more.
I'd probably use `if six.PY2` here, so we remember to remove this branch when we drop Python 2 compatability
This test isn't correct, it passes before any changes are made to the template. Admin actions isn't the problem. I think you'd need to make a custom template that overrides `{% block object-tools-items %}`
I personally wouldn't have newlines between all of these since the ) on its own line it basically a newline. I'd just use a newline to break up each `# Test *` section -- although individual test methods with setUp might be more clear
extra newline. also, commit message should be in past tense "Fixed #...."
how about applying the get_cache() change to the second occurrence on the line and adding :setting: to CACHES
good opportunity to add `` around get_cache() and CACHES
params -> parameters
I'm not sure this can be removed without a proper deprecation. In any case, it needs a ticket.
Use `//` instead with a `from __future__ import division` import.
IMHO `len(test_labels)` and `2` and quite explicit `int` operands in this case making it clear the return value of `//` will also be an `int` but well, I think I'm bikeshedding here.
Committed this change in ab643cd63402ef8ed4776faebc0ed4f00b933e1d because @apollo13 also stumbled on it.
I'm unclear with the purpose of this line is -- the "statements" local variable isn't used
use Model.objects.create() rather than `save()`? I don't think manually specifying an id is needed (or a best practice)
Start the docstring with "#4492 --" to reference the ticket
migrations isn't used
two spaces between class names please
I've never seen underscores in model names before, since I don't think we are testing that behavior, it may make sense to remove them. Also, please use double quotes for docstrings, I believe that's what the majority of Django uses.
I'm not sure what this sentence means
Despite this starting with an underscore, I notice it's in use by 3rd party projects so it may be worth going through a deprecation cycle -- see `django.utils.deprecation.RenameMethodsBase` for a helper.
If there's no use case for passing relative URLs to `get_callable()` then I think it's better to explicitly handle them and not invoke that method. It makes the intent of the code more clear and easier to follow I think.
I'd use a tuple rather than a list
It makes sense to me. Helped me get my head around the whole promotion/demotion rationale.
This should be -> False...
I prefer keeping imports at the top of modules.
Prefer wrapping the expression in parentheses rather than using a backslash
unused import (please check code with flake8 as there are some "expected 2 blank lines" warnings as well).
I think you should refer to the `empty_strings_allowed` property of the related field instead of special casing `CharField` here. ``` python if value is None or (value == '' and not related_field.empty_strings_allowed) ``` Not sure an extra `connection.features.interprets_empty_strings_as_nulls` check is also required here since both values will be interpreted as `NULL` anyway.
Since 21194 was closed as a dupe, you may want to update the references to 19299.
This test needs to be made to pass or skip when the connection interprets_empty_strings_as_null -- skipIfDBFeature is your friend (on Oracle, line 149 will raise an IntegrityError).
I don't think the two lines (`*_normal`) are needed here since this functionality is most likely tested elsewhere (and you don't make use of those variables in your assertions later on).
I'm trying on SQLite and the new test isn't skipped. If I revert the changes in django/db/models/fields/related.py it fails, but if I revert the change in this file, it still passes.
You don't need to assign the result to a variable here.
Make sure you reference your ticket number in the docstring (see the other tests in the file).
Per pep8, this should be `max_length=10` (note the lack of whitespace around the equal sign).
Nitpicky but I'd call it `PrimaryKeyCharmodel`, just to be more explicit about what it is.
Nice touch to follow the previous model's docstring, but I think this one should simply be: `Model with FK to a model with a CharField primarey key, #21194` The `{Null,}BooleanField` of the previous one just means `NullBooleanField and BooleanField`.
This change has fixed the simple case alignment issues. As you mentioned, only_load cannot handle some of the more complex cases (and one of the reasons I didn't include a PR with the ticket).
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
too many newlines (check code with flake8).
an app containing a locale folder
I'd remove this docstring, it no longer has much to do with python's version at all
Personally I'd just completely inline it into the function, it's not that much code anymore…
It's probably not a very common use case, but if a cache table is created and then another one is later added, running `createcachetable` again will throw an error because the first table already exists. I think it would be nice to handle that case.
Imports should be sorted too.
extra space after [
Why this restriction? If several files are saved in a quick sequence — for instance with a text editor's "save all" feature" — only the first change willl be taken into account.
Please use parentheses rather than backslashes for line continuations.
I don't think this is necessary - this is a developer only message - it will never be displayed to end users.
Good point. We should likely use `six.text_type` though because someone's crazy verbose_name is quite likely to include non-ascii characters which would blow up on py2 if we just user `str`
Again, imports at the top of the file
This class does not need to live inside this method.
This import should be at the top of the file, and is likely not python 2/3 compatible
I suggest having just 1 `os.chmod` call: ``` os.chmod(full_path, self.permissions_mode if self.permissions_mode is not None else settings.FILE_UPLOAD_PERMISSIONS) ```
This will _not_ close connections when `settings.CONN_MAX_AGE > 0`.
use `with six.assertRaisesRegex(self, ...`
I'd suggest using parentheses so you can omit the backslash
import at top of file please
another PEP8 error is no comma after , -- if you'd like to clean that up, you can just remove ",None" as that's the default if the key doesn't exist.
I think the test fails as it is as you're no longer passing `self.timeout` to `smtplib.SMTP_SSL`. I don't think Django should specify a default of 60. Instead it should be `None` and only passed to the SMTP connection if the user specifies it. Here's a quick sketch of what I have in mind (plus some cleanup): ``` python # If local_hostname is not specified, socket.getfqdn() gets used. # For performance, we use the cached FQDN for local_hostname. connection_class = smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP connection_params = { 'local_hostname': DNS_NAME.get_fqdn(), } if self.timeout is not None: connection_params['timeout'] = self.timeout self.connection = connection_class(self.host, self.port, **connection_params) # TLS/SSL are mutually exclusive, so only attempt TLS over # non-secure connections. if not self.use_ssl and self.use_tls: self.connection.ehlo() self.connection.starttls() self.connection.ehlo() ``` For the test you'd subclass `EmailBackend` and verify the connection has the timeout use specified.
Susan, your latest PR doeesn't seem to take the above suggestion into account.
might as well use `setdefault` in the test as well
2 spaces above class names is correct -- shouldn't remove this newline.
the try/except needs to be added back
I don't think we should suggest doing it this way, hence I'd suggest removing this test.
Instead of putting timeout in the `__init__` method, make it a class attribute. Here's an example change where we use this same technique: 8b0014869f666b44cd20692e38073ec0a0a8cb08
Thank you for the contribution & taking on the ticket! :smiley_cat:
You probably don't want this to be a class-level attribute, because they are exactly that (class-level, not object-level). The better approach is to accept an optional timeout argument to `__init__` and store that on `self` to later be passed in to `smtplib.SMTP`.
this should appear above the code in green as it does in the original file.
I see you incorporated some of my suggestion as to how to refactor this, but as it is now the `connection_params` variable isn't used.
You should set `self.timeout` to `timeout`, not 60.
missing space after `self,` as described above (and two lines below)
please add a newline after this
Ok, I'm +1 on your approach. Thank-you very much for the review and feedback.
this line should be: `def __init__(self, *args, **kwargs):`
As suggested by Tobias, it should be: ``` class MyEmailBackend(EmailBackend): def __init__(*args, **kwargs): kwargs['timeout'] = 60 super(MyEmailBackend, self).__init__(*args, **kwargs) ```
Whoops, just realized the original author was someone else! Sorry about that. Nonetheless, thanks for discussing!
The module (since it's something that can be compiled externally easily enough and with Django's release cycle, won't get updated very often).
IMO, Django doesn't need to ship with this.
If the tests work without it, I think it should be fine to remove.
two lines between classes is correct
+1 for `__all__ += operations.__all__`, duplicating giant `__all__` lists would be a code smell of its own.
instead of "(1.7)", I'd suggest "(remove in 1.8)"
this could be modified similar to the below for backwards compatibility I think.
personal preference: I think `'_language' not in request.session` reads a bit clearer.
couldn't we provide backwards compatibility by falling back to 'django_language' here if '_language' doesn't exist? we could remove that after 1 release.
That docstring doesn't add much info. It isn't useful to paraphrase a function's signature!
`except Exception` unless we really have a good reason for a bare except.
Tests for this feature seem yet to be missing, and I would rename the message a bit ala 'Error in 500 callback'
Please restore this empty line and add another after the definition of replacement
Restore this empty line and the one below
I'd check settings.DEBUG_PROPAGATE_EXCEPTIONS, and then raise immediately - otherwise just log
`Exception as e`
`Exception as e`
Path/exc_info/extra should be just `**kwargs` and then added as `(msg, kwargs)`
by convention - 'handle_' as a prefix is used for methods that actually handle an exception condition. This is more of a utility around sending the signal, so while I don't want to bikeshed the naming of it, I'll just say that starting with handle_ is probably not a good choice.
Hmm, removing the thread local is technically backwards incompatible, but I guess we can get away with it^^
This should be a PendingDeprecationWarning, and you should add an entry in docs/internals/deprecation.txt.
Unless we deprecate `get_cache`, this is an unused import.
The docstring should explain why such proxy is needed.
not sure the difference, but I see we use `codecs` rather than `io` here: admin_scripts/tests.py: with codecs.open(path, 'r', encoding='utf-8') as f:
I see :/ Well `force_str` should still save you the promise checks.
I think you should use `force_text` here since the regex match can't be a promise and `force_str` aliases it on Py3.
I think we typically prefer list comprehensions in cases like this. I think the following is equivalent: `[os.path.abspath(basedir) for basdir in basedirs if os.path.isdir(basedir)]`
This is not going well if the user tries to give permission 0o000. I know, I know, who is in the sound mind gives permission 0o000 to files. But still.....
It works. But it exceeds 80 characters.
consider removing (I don't think we could ever get here and the default is to return None anyway)
revert -> use
I don't see a test for this method and I don't see that it's actually called unless there's some magic going on.
We can safely assume `hasattr(self, 'view_on_site')` will always be `True` here.
Correctly indent the bracket to match the `return` indentation.
Store the result of `self.get_view_on_site_url(obj)` as a local variable to avoid two function calls.
Remove leading and trailing white space of `RestaurantInlineAdmin`.
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
Use `assertIn` instead.
Use `assertIn` instead.
Use `assertNotIn` instead.
Remove this blank line.
The only allowed values for `view_on_site` are a boolean or a callable thus you can safely use the `self.view_on_site` conditional here.
nevermind, I see it was. You might consider using `assertRaisesMessage` to make the test a bit more specific.
Actually the whole body of this method could be moved into `get_view_on_site_url`.
Removing `url_markup_template` breaks the customization use case in #19464.
better name: `get_template_substitution_values()`
I think the idea was to replace <a> with <img>. Maybe the change is fine as I guess it's still possible; it just requires overriding the entire `template_with_initial` instead of `url_markup_template`.
Move this import to the top of the file.
Use only ``` if PY: # python2 specific code else: # python >= 3 specific code ```
Oops, yes. I meant PY2.
do you think it would make sense to do something like: ``` DEFAULT_LEVELS = dict((v.upper(), k) for (k, v) in DEFAULT_TAGS.items()) ```
Same for the capital letter and trailing dot.
`self.request()` rather than `self.handler(self._base_environ())`? Interestingly `Client.request()` is the only method that goes through the middleware, all others (`get()`, `post()`, etc. simply proxy `RequestFactory`.
I thought about it a bit, I think we should name it `request_instance` rather than `_request`. Having both `request` which is a dict and `_request` which is the actual request instance is confusing.
No need to change this now... but would base_path = 'foo__bar', prefetch_through = '__baz' and prefetch_to_attr = '__baz_list' clarify things here? You could then append base_path and either prefetch_through or prefetch_to_attr together as needed.
Yes -- arguably it might be better if it does crash if required is provided so people know to update their code.
The `num_args` argument was introduced in b6812f2d9d1bea3bdc9c5f9a747c5c71c764fa0f specifically for `get_callable` (note how it can take two arguments but the `num_args` is 1). I suspect there might be something weird going on but I haven't had time to look into it and unfortunately, we cannot ask the original committer of that change anymore :(
You've removed the `num_args=1` argument (which `lru_cache` doesn't support) here which is probably a bug. The fact that the test suite doesn't break because of this is intriguing and should be investigated further.
I'd use `'%s:%s_%s_changelist'` here.
Same here. And I'd remove the `info` variable completely.
There's still a few changse here :/
We don't want to be modifying this file, it's skipped by the `setup.cfg`, and is a copy of the stdlib file.
choosing a different string wouldn't hurt
no space after #
Could you add `stacklevel=2` here? That makes the warning marginally more useful. Same for the second warning.
Not a big deal, but the usage is to import `from django.conf import settings`
I think you could merge the two `if` statements into one: ``` if (lang_code not in supported and lang_code in deprecated_locales and deprecated_locales[lang_code] in supported): return deprecated_locales[lang_code] ```
Just to make sure people don't start using, this, I'd make it a "private" variable (and maybe make it a "constant" too): `_DEPRECATED_LOCALES`.
I would reuse the same wording as in `promote_joins` it's more clear IMO: "demote a->b automatically, or otherwise the demotion of b->c doesn't actually change anything in the query results."
[...] remove matching rows **for rel_b**.
"Considre case" > "Consider the case".
"if all childs refer same children", I'm not too sure what it means. Also maybe the `num_childs` var could be changed to `num_children`.
Since both `SignalTests` and `ModelSignalTest` only cover `Model` signals, maybe this one could be called `LazyModelRefTest`? Nitpicking but some classes have `Test` and others have the plural `Test*s*` in their name.
Indeed, you are right.
I think the `@property` syntax would be more readable here.
Since you made it a `property` you can just use `self.level_tag` where `label_tag` was used before (no need to create a temporary variable).
PEP8 requires two blank lines between class definitions.
Instead of ``` choices = list(filterspec.choices(changelist)) self.assertEqual(len(choices), len(expected_displays)) for i, display in enumerate(expected_displays): self.assertEqual(choices[i]['display'], display) ``` you can write ``` choices = tuple(c['display'] for c in filterspec.choices(changelist)) self.assertEqual(choices, expected_displays) ```
You should probably use double quotes `""` instead of quotes `''` (there is already some discussion on django-developers here: https://groups.google.com/forum/#!topic/django-developers/MQFrQjrJfoo). The same for L853 and L856.
Not really important but you don't need the square brackets: `set(instance_attr(inst)[0] for inst in instances)`.
You could also remove `self._supported_languages` in `__init__` (and OrderedDict import).
I believe there's a typo in that `pat` should be `part`.
Avoid conditional imports.
I'm not sure splitting this out to a separate function makes the code easier to follow.
This is the default charset in Django, I wouldn't call it unusual :)
This isn't Django's default charset (unless I'm mistaken).
longer line is fine
Can you include latin-1, non-ASCII characters? `café` is one of the few English words matching this requirement. `Just latin-1 :)` will encode identically in ASCII, latin-1 and utf-8, making the tests much less interesting.
In my opinion a single test method would be sufficient to test these four cases. It's a micro-optimization, but the test suite is painfully slow and every little gain is worth it.
don't reorder as above
prefer a single longer line
we shouldn't reorder kwargs due to the possibility of users passing them as positional args (as the test update you made indicates)
`assertTrue` would be appropriate here.
I just tried this (merged into master) on Oracle, this assertion fails (I ran only the model_inheritance_regress tests).
Never mind, just read the whole ticket :) Maybe the initial `assertIsInstance(p.restaurant.serves_pizza, bool)` would make more sense here. Else it might end up being refactored.
While we're at it we could reorder those alphanumerically.
Just use `get_current_site()`.
patterns is deprecated, please remove.
I'd omit this blank line.
nit: It doesn't actually set anything in the context, it's just a context processor that returns values that will be set in the context.
omit encoding and absolute_import unless actually needed.
That's very minor but you can use `assertIn` here.
I'd drop the intermediate variable
I think the usage of `partition` is correct here.
Unless I'm mistaken, there's no equivalent for this in your new `get_request` function.
single line as above
Need an `.as_view()` here: `views.BaseAdminDocsView.as_view(template_name='admin_doc/index.html'),`
`kwargs` parameter is neglected, all subclass context data is ignored
remove trailing whitespace
Ok, I don't think it needs to be skipped on sqlite (since it passes). A note in the docstring that it's only a problem on certain databases would be helpful.
we can wrap this line at 80 chars
please alphabetize imports
Possible one-liner alternative implementation : `locales = list(chain(*[l.split(',') for l in locale]))` (chain from itertools)
could you explain why the existing test was removed? I see it says "unused" on the ticket, but I don't really understand.
how about escape_uri_path? to distinguish from file system paths, etc.
"The reason for not ..." substracting -> subtracting
No need to use `in` here, `kwargs['settings] == 'ROOT_URLCONF'`.
Call `clear_url_caches()` instead. It's more likely to stay up to date when the code lives on, and it resets the `get_callable` cache which is missing from your patch.
I would have set `TestUtilsHashPass` as a `SimpleTestCase` subclass, so you can simply use `with self.settings(...)` and remove usage of override_settings (which is rather aimed to decoration).
Why do you include a `username` key, some backends do not work with username/password pairs (e.g. client certificates).
built in imports before django imports
I usually alphabetize foo.bar before any foo.bar.*
I think we could use unittest.TestCase since there's no DB interaction here.
``` # duck type check for objects that may be mocks ```
I don't understand your rationale -- `assertIsInstance` does the same check but throws a more helpful error message.
no comma needed
``` """ DateField.to_python() should handle mock dates (#21523). """ ```
Trailing white space.
You could retrieve `target_model` while avoiding creating a an unnecessary `list` and `dict`. ``` python for seen_model, seen_alias in seen_models.items(): if seen_model and seen_alias == alias: ancestor_link = seen_model._meta.get_ancestor_link(model) if ancestor_link: column = ancestor_link.column break ```
Technically, `name` should be a string, not an integer. For brevity, you could use `[Person(name=name, person_country=self.usa) for name in 'abcde']`
This line is not needed.
I think it should be `model._meta.local_concrete_fields`.
Adding a reference to the ticket number (in the docstring for example) would be helpful here.
We're not altering vendored module.
Might be worth caching `super.to_python` here.
Putting all queries on their own newline should help readability: `'...queries were:\n%s'`.
You don't need a list comprehension here -- `join` accepts any `iterable`: `'\n'.join(query['sql'] query in self.captured_queries)`
use """ here? I think the indentation adds clarity to the template
Is there any reason to duplicate the list of API names here? Could we perhaps use the `__all__` or `__dir__` or `messages.api`
Seems like some slightly more intelligent code to ignore the exception (`issubclass` would do) might be more future proof to any changes in the API
Yup, new version is better.
This import is not used.
This test already passes without the code change. The test for this new feature should fail before you apply your patch and pass after.
This seems wrong to me - we disallow pickle + unpickle between major versions, but get_version() returns minor version, too. It should be OK to unpickle 1.6.1 querysets in 1.6.2.
`exceptions.ObjectDoesNotExist` is referenced at line 1819.
Keep `django` imports together.
missing newlines (please check your code with flake8)
built-in imports go first (after `__future__` and before django)
move this line before `from django.utils.translation` to alphabetize
this should be from `django.utils import six`
I think we should include `*args, **kwargs` and pass them to the super `__init__`
I'm saying if a database has `connection.ops.max_name_length() >= 74` this test won't pass because the database will be able to handle "verylongmodelnamezz...."
more descriptive names would be enhance readability of the test, e.g. "ModelWithLongField", "ModelWithDBColumn"
remove "for this"
Please include a more description error message than "This test is not required for this database" see other tests for an example.
`long_field_name` replaces the existing fields
`long_field_name = 'a' * (allowed_len + 1)`
I suggest multilining this string to make it more readable, something like: ``` checks.Error( 'Autogenerated column name too long for field "%s". ' 'Maximum length is "%s" for database alias "%s".' % ( column_name, allowed_len, DEFAULT_DB_ALIAS ), hint='Set the column name manually using db_column', obj=cls, ) ``` (same idea in the test)
imports should go at the top of the file unless it causes a circular import which shouldn't be the case here I think
the preferred way is to use @unittest.skipIf as a decorator on the test method to skip the test.
I think the error message that @akaariai provided is a bit better: "Autogenerated column name too long for field [field_name]. Maximum length is [xx] for database alias [somealias]."
@akaariai suggested "If the field has manually assigned column, use that directly without any truncation or validation. Assume the user knows what he is doing." The user has manually assigned a column if `db_column is not None` (of course we would also include the length check in addition to that).
hint could be: 'Set the column name manually using db_column.'
I think the skip condition needs to be amended as this test won't pass on DB backends if `connection.ops.max_name_length() >= 74` (the length of the model field), right? It would also be helpful to be a bit more descriptive to say _why_ the test is not required for this database.
unless you can generate a model so the field length is always `connection.ops.max_name_length() + 1`, the skip condition should probably be `connection.ops.max_name_length() < X` where X is the length of the column name here.
looks good, but we should move the `allowed_len is not None` check outside the loop as it won't change each iteration
the quotes around verylong... aren't present in the error message so the test isn't passing
Right so I think the skip condition in order to avoid false failures should be: `@unittest.skipIf(connection.ops.max_name_length() > 74` but it would be better if we could keep the skip condition as it is so the test is run on all databases and automatically generate a model that has a field name with length `connection.ops.max_name_length() + 1` If you're still unsure about this, let's sync up on IRC.
built-in imports like unittest should go above django imports, separate by a newline. e.g. ``` from __future__ import unicode_literals import unittest from django ... ```
since we don't use `att_name` you can change the name to `_` -- that's a common convention for unused return values.
Regarding multiple database support, I believe we want to do something like this: ``` from django.conf import settings from django.db import connections for db in settings.DATABASES.keys(): # skip databases where the model won't be created if not router.allow_migrate(db, cls): continue connection = connections[db] allowed_len = connection.ops.max_name_length() ... ``` We can also go back to putting the database alias (`db`) in the error message.
Looking at the code a bit more, I believe we just want to check `f.db_column` -- it will be `None` if the user hasn't provided a value. With the current implementation, if the user provides a value equal to the auto-generated value, we'll inadvertently perform this check.
Ahh didn't notice `_modified_settings` could have duplicate items.
I realize it involves creating a `dict` instance to immediately transform it to a `list` but I'm not convince we should support two initialization paths for `SimpleTestCase._pre_setup`.
`if kwargs['setting'] in ('INSTALLED_APPS', 'STATICFILES_DIRS')` The later is fixed at initialization time too I think
MINOR: the test would be clearer if this were more verbose as auth_app_config
You don't need a list comprehension here, `set("%s.%s" % ...)]` was just fine.
While we're at it we could also specify which related field to select; only `'content_type'`.
Looking at it we should also pass `obj` to this method and cache its results, just like we do with `get_group_permissions`: ``` python def get_user_permissions(self, user_obj, obj=None): """ Returns a set of permission names the user has. """ if user_obj.is_anonymous() or obj is not None: return set() if not hasattr(user_obj, '_user_perm_cache'): if user_obj.is_superuser: perms = Permission.objects.all() else: perms = usr_obj.user_permissions.all() perms = perms.values_list('content_type__app_label', 'codename').order_by() user_obj._user_perm_cache = set("%s.%s" % (ct, name) for ct, name in perms) return user_obj._user_perm_cache ```
`obj` is not passed to `get_(user|group)_permissions` since it's always equals to `None` at this point; expand the diff and look at the full body of `get_all_permissions`.
Please remove the `unicode` prefix; they are not allowed on Python 3.2 and we're already importing `unicode_literals` from `__future__`.
obj is not really used typo: through*
We should `try` yielding and `finally` restoring `old_cwd`.
You could use `self.module.autodiscover()`, but that might be obscure :)
I've consistently used `from django.apps import AppConfig` and `from django.apps import apps` to avoid the "which `apps` are we talking about?" problem.
This is the only use of cursor in this block.
Yes, that feature request is tracked in https://code.djangoproject.com/ticket/19527.
Frankly, I don't remember the details here, and I only have time to glimpse the PR now, but it seems that there may be two cases where multiple rows of returned values may be expected: `bulk_create()` on one hand, and an `UPDATE` statement on the other (you wouldn't need to returned values in an ORM `update()` call, but you would need them in the lower-level API).
OK. I already have them returning at a lower level but public update method still just returns the number of rows affected. I'll look into the `bulk_create()` case. Thanks
Also, you've defined `fetch_returned_values()` for Postgres as `cursor.fetchone()`, which is wrong when many rows are expected.
This should probably be a separate method -- perhaps, one that could be used for the insert as well. The code here should read, ``` python if self.returning_fields: r_sql, r_params = self.return_values_fragment() if r_sql: result.append(r_sql) params += r_params ``` The default `return_values_fragment()` should raise `django.db.utils.NotSupportedError`
Indents should be four spaces.
"will no longer be supported"
I'd say "and either ... or else"
The `HAS_PEP8` constant is unnecessary IMO. ``` py try: import pep8 except ImportError: pep8 = None ``` Then: ``` py @unittest.skipIf(pep8 is None, "needs pep8") def test_something(self): pass ```
I'd like `import_string` to catch `ValueError` and `AttributeError` and re-raise `ImportError` for those cases as described in the ticket. Otherwise this looks great (and needs another rebase for my deprecation timeline re-ordering earlier today... sorry about that).
"relations" or "a relation" also include prefix the docstring with "#21846 --"
"its equally-named replacements" is confusing, since "it" seems to refer to this module, rather than the individual classes that used to be in it. I would re-word this error as: ``` django.contrib.contenttypes.generic is deprecated and will be removed in Django 1.9. Its contents have been moved to the fields, forms, and admin submodules of django.contrib.contenttypes. ```
We might as well always convert `app_module.__path__` to a list and avoid catching the `TypeError`.
For consistency with the rest of the code, I think you can omit the comma at the end.
I don't completely recall what this was needed for tbh, to only return certain app statics? Not sure.
Ah, I realized these are E128 which we are ignoring in the flake8 section of setup.cfg. I don't mind the changes, but we are ignoring it because there are 2K+ violations and seemingly not a lot of value in fixing them.
it would help readability if description[5] and description[4] were assigned local variables describing what they represent
This refactor looks good to me.
Personally I prefer the existing hanging style of indentation as it doesn't require breaking things up into so many short lines, however, neither the existing style nor what you've changed it to should throw a flake8 error -- does it for you? We've finished the flake8 cleanup so there shouldn't be any existing errors now.
missing whitespace around ==
same thing with .create() and easier names to remember
alphabetize imports (put before os)
instead of character1 and character2 I would use threepwood and marley and then use threepwood.name, etc. instead of repeating the string
please check this test on Python 3 ``` Traceback (most recent call last): File "/home/tim/code/django/tests/admin_views/tests.py", line 3735, in test_limit_choices_to_as_callable self.assertEqual(response.content.count('threepwood'), 2) TypeError: expected an object with the buffer interface ```
unused import (recommend you check your code with flake8)
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
Yes, it looks good.
I don't think you need `absolute_import` here - you don't need to to do a relative `.models` import a few lines down. You would need it to ensure that `import models` would fail to import the relative module.
Please use flake8 and fix indentation errors here
don't think "or None" should be needed (None or None) is None
remove "or None"
It doesn't seem like a proper separation of concerns to have `isinstance()` checks for specific field types here and in `ModelForm` methods. Unfortunately, I can't make an alternate recommendation without really digging into this.
Maybe you can explain this as to why the logic is repeat both here and in the formset. Overall, this seems a bit hacky to me.
Please don't move import. Also the import in the line below should be alphabetized.
I've removed an extra newline that caused a flake8 error.
I believe you would need to add a custom `save_form` method to a `ModelAdmin` and somehow incorporate the `change` flag in it -- perhaps modify the form's cleaned_data to assign the field to a model field before save.
I'm not seeing if/why adding app_label here is necessary.
likewise, the last argument to `save_model()` and `save_related()` should be `False` when adding.
Don't remove newline at EOF (check code with flake8)
or `_('Add %s')`
You could put both conditions on one line here with an `and` statement.
Actually a relation is hidden if it ends with a `'+'`. Here `rel` has a `is_hidden` method that abstract this check.
I'd prefer adding a [0] instead of `_, _, _`
More testcase would be nice, such as: ``` () ('url', 'title', 'content', 'sites') ('url', 'title', ('content', 'sites')) (('url', 'title'), ('content', 'sites')) (('url', 'title', 'content', 'sites'),) ```
A docstring would be nice.
I would rename this method to `assertCollapsed` to be consistent with the unittest assertions.
Indentation is off here, please check code with flake8.
remove the `.encode()`
No `u` prefix (python3.2 compatibility)
`assertEqual` is fine here (also note that we use `assertEqual`, not `assertEquals` in Django)
you can actually do `set(self.field_names).difference(fields)` here.
`raise NotImplementedError("ValuesQuerySet does not implement `only()`")`
I'm going to change this to assertRaisesMessage when I commit it.
Also, you don't need to wrap the set in a `list`, since it's later passed on as `*field_names`.
``` Superuser creation skipped due to not running in a TTY. You can run `manage.py createsuperuser` in your project to create one manually. ```
What happens if you have two models with two through models like the following? I suspect an endless recursion. But haven't tried it. ``` python class A(models.Model): b_s = models.ManyToManyField('B', through='AB') class B(models.Model): a_s = models.ManyToManyField('A', through='BA') class AB(models.Model): a = models.ForeignKey(A) b = models.ForeignKey(B) class BA(models.Model): b = models.ForeignKey(B) a = models.ForeignKey(A) ```
The other formats.py seem to use `'\xa0'`
Maybe use hint="Use through_fields to specify which two foreign keys Django should use".? Seems consistent with the usage of hints in the next errors.
you can use `literal_match.group(1)` instead.
Using `self.assertNotIn` would be better here, but you'll have to rename the first argument of `push` to something else so that `self` refers to the `TestCase` instance and not the `DummyContext` one.
I think we should drop the space after "function" through this file (can be a separate commit).
What about having `request` as a required positional argument? Or, if it is to support calls such as `view = views.CustomTemplateView.as_instance()` (no arguments), then what about initializing request like `if request is None: request = RequestFactory().get('/fake')`
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
add period at end of sentence
please add this to an existing ModelAdmin if possible so we don't need another model.
yes, that's what I was thinking
It seems much simpler to split `as_json` into two functions, one which returns a string with JSON, and another which returns a json-serializable structure; rather than putting a new flag on this.
Is there a similar test for unique_together? If yes, then there should be one for index_together, too. If not, then I guess removing this test is OK.
missing space after the second comma (please check code with flake8)
I was thinking to still keep this as a separate test method, just put that method below this one
Please put this test back in its original spot so it doesn't appear as something that changed.
I think there should be a new test for this branch.
I see now, my mistake. Please put it under `test_index_together` though.
It's technically a `function`, not a `method`
I think there's also a word missing here: "will **be** truncated".
You should be able to use `absurl.startswith(('http://', 'https://', '//'))` here.
The docstring is not accurate here.
You can simply use `assertRedirect(response, obj.get_absolute_url(), ...)` here. No need for string formatting.
You should use `fetch_redirect_response=False` instead of `target_status_code=404`. It seems to be an outdated pattern used in a few places and I'll probably clean it up soon.
This is a very minor detail but I think the rest of the code uses tripe double quotes (`"""docstring"""`) for docstrings.
replace try/except with `if 'class' in attrs:`
If 'class' is already in attrs, this should append `self.form.required_css_class` to it, not leave the value unaffected.
Please try to stay near 80 char per line…
`attrs['class'] += ' ' + self.form.required_css_class`
don't need outer parentheses
This check seems to be done after the WHOLE field has been read into memory, am I right? The goal was to prevent this.
Ah, so this won't be triggered by accessing request.POST. It seems fine to me then. :)
You have an `%s` in the error message, but you aren't formatting the string with a parameter.
use assertRaisesMessage? (helps to ensure the expected TypeError is raised)
Also, see ticket trac, it seems 2396 is obsolete.
`self.fail` will actually exit the method the moment it's called, which means that `os.environ['PATH']` won't be restored. How about rewriting the test this way instead: ``` def test_find_command_without_PATH(self): """ find_command should still work when the PATH environment variable doesn't exist (#22256). """ current_path = os.environ.pop('PATH', None) try: self.assertIs(None, find_command('_missing_')) finally: if current_path is not None: os.environ['PATH'] = current_path ```
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
, -> and
fields -> options comma after auto_now_add
I think that such iterables like `[None, False]` should be tuples like `(None, False)`, because it's less memory consuming and faster a bit. Anyway, it is not very important, because of small container size.
"a DeprecationWarning" -> "an Error"
Two lines between class definitions please.
Since you're referring to `context.render_context[EXTENDS_HISTORY_CONTEXT_KEY]` in a couple of places here it might be a good idea to store it in a local variable. e.g. ``` python extends_history = context.render_context.setdefault(EXTENDS_HISTORY_CONTEXT_KEY, []) parent_name = compiled_parent.name if parent_name in extends_history: raise TemplateRecursionError('Circular template extension error in %s' % extends_history) else: extends_history.append(parent_name) ```
don't add whitespace here
It would be better if we could refactor the control flow so we don't have to repeat these lines which also occur after the last else statement in this file.
For Python3 compatibility, you should use `b"foo bar baz quux\n"`
any reason not to include `and not isinstance(self.widget, CheckboxSelectMultiple)` as before? I guess the user could still use a custom widget, but maybe not? Otherwise, seems fine.
I'm not sure, but I found this: "JSON text SHALL be encoded in Unicode. The default encoding is UTF-8." http://www.ietf.org/rfc/rfc4627.txt
add trailing comma
missing end quote
add trailing comma
consider assertRaisesMessage to make the test a bit more specific.
Add a reference to docs/ref/models/fields.txt
Does `serializers.serialize` write bytes or text to the stream? In the case of the later we should probably use codecs.open or similar (for py2 at least)
`stream=open(output, 'w') if output else self.stdout`
Stray `,` at the end of the help text.
From my testing, unicode is handled correctly.
Indentation is wrong here - 5 spaces used
Don't need versionadded or :meth: stuff in docstrings.
I think we can get here also from the raise in line 228 (that is, an error during commit, not rollback). I don't think closing is justified then.
Those -> These
Forget it, I misread the double for-loop.
That's why I wrote "maybe" ;)
Here however, you shouldn't use a list comprehension as it makes you call `regex.match` two times instead of one. Plus a dict iterates on keys by default, so you don't need to write `.keys()`.
~~Maybe a list comprehension here too.~~ EDIT: Forget it, I misread the double for-loop.
~~Maybe a list comprehension here too.~~
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
What if the prepared value contains unicode? (As I said before, you should use a list comprehension instead of a generator, it'll be about 2 times faster here)
`items = value.split(self.delimiter) if value else []` is slightly faster.
Why not using a `bulk_create` here? I may be a bit obsessed with performance, but I like when tests also are fast ;) ``` python self.objs = NullableIntegerArrayModel.objects.bulk_create([ NullableIntegerArrayModel(field=[1]), NullableIntegerArrayModel(field=[2]), NullableIntegerArrayModel(field=[2, 3]), NullableIntegerArrayModel(field=[20, 30, 40]), NullableIntegerArrayModel(field=None), ]) ```
This change indeed isn't necessary. Delete wraps signals, too, inside atomic. So, for the delete case the .atomic() doesn't do anything.
The biggest problem for consistency is model save() - there the signal are outside transaction control. I think we should change _every_ place in Django to be consistent, or change none of them. So, lets deal with signals inside or outside transactions in separate patch.
The argument that all related operations signals happen inside transaction is OK for me. Ditto for wrapping .delete() and .update() in atomic(savepoint=False), that doesn't cost much.
You could replace this outdated pattern with: ``` with self.assertRaises(ValueError): # ... ``` while you're there.
I'm wondering whether the signals should be handled inside or outside of the transaction. Technically, this is backwards incompatible, as an exception in a post signal handler will prevent the object from being saved, which isn't the case currently. My distaste and distrust for signals pushes me to keep them outside of transactions, but I haven't thought a lot about it and there are probably good arguments either way.
The custom error message can easily be replaced by a docstring. Using test assertions correctly is more important.
You can leave this docstring
remove this and use `RemovedInDjango20Warning` instead
As above, leave the docstring and change to deprecation to 2.0.
master is now Django 1.8 so we start the deprecation now and remove it in two release which will be Django 2.0
Shouldn't that second test be against `request.session[SESSION_HASH_KEY]`? Because now, the value must be equal to both the users pk and their session auth hash, or the session is flushed.
Shouldn't we pass in lhs_sql, rhs_sql, lhs_params and rhs_params? The problem is that if the connection needs to reuse the same part of the SQL multiple times, or it needs to have the expressions in reverse order, then the params will be in wrong order. Maybe this is an existing problem? If so, we could create a new ticket for this, and not care about this problem in this pull request.
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
To match `django.db.models.sql.compiler` behavior, as_sql() should probably be replaced by `self.compile(annotation)`.
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
IIRC get_cols() was renamed to get_group_by_cols() some time ago - no need to have both.
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
It is thread safe as long as the integer_field and float_field are used in stateless manner. I think that is the case, but verifying that isn't easy.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
Just trash it IMO, and the corresponding one in gis. The converters changes already completely removed/renamed two (private) methods on DatabaseOperations and Compiler
Typo: annotaion -> annotation
This loop seems strange to say the least - all but last result are overwritten by the looping.
Since the deprecation is in the constructor, shouldn't it specify `django.db.models.sql.aggregates.Aggregate`? **Edit:** Instead of `Aggregate` you could use `self.__class__.__name__` so it works for subclasses. Alternatively you may deprecate the whole module at module level.
I always like to see `assertRaisesMessage` so we can verify the `TypeError` is the one we expect.
Looking at this, this one picks first source as self.source. Above self.col is picked from last target. Should we just throw an error for multicolumn expressions? I bet they don't work currently in any sane way, so lets not pretend they work.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
is it possible to make the try/except block a bit smaller? try/except/else maybe? That will help to show where the error is expected.
If this file is deprecated, might as well revert the whitespace changes to keep the diff cleaner.
extra space after ,
I would put the arguments all on this line
only -> instead? also, remove space after "only."
I realize this predates your PR, but why is 'unused' not used? It appears to be the target field provided by the SQLUpdateCompiler during as_sql(). This seems like a really good spot to allow a backend to hook in and CAST the expression to a type that is allowed by the target column.
convert to feature flag? or at least make a ticket for it.
`annotations` is spelled incorrectly here.
okay, but would be helpful to say _why_ we need to always return True.
not sure we really need backwards compatibility here
You could use RenameMethodsBase.
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
The wording `update your urlpatterns with a list of ...` seems unclear to me, it almost sounds like I need to call an `update` method with some argument that is a list, or something. I would say `update your urlpatterns to be a list of ...`.
`+=`? (Here and a few other places, feel free to ignore if you prefer the look of this)
Please remove the tab on this line (you probably want to configure your editor to insert 4 spaces when you press tab) as well as the trailing whitespace.
It looks to me like you can use just `len(self._fields) + len(aliased_fields)` for this, we dont' really need to make a whole list.
Just missing spaces at the end of these strings - I've added them.
Missing blank line at the end of the file.
I'd use force_text() instead, it's safer.
I don't like importing from admin.tests here. Maybe we could factory out the minimum shared logic (which I believe is just setupClass and tearDownClass) and put it somewhere in django.test.
One too may newlines
I find `assertEqual` preferable since `asserTrue` checks `bool(expr) is True` which could pass for a result we don't want here. Well, I guess what we actually want is `assertIs(expr, True)` as described in the Python docs.
``` py self.assertFalse(r.closed) ```
``` py self.assertTrue(r.closed) ```
Wondering if we should convert the suggestion part to an hint instead.
Might be worth adding a `@property` (just like `ordered`) that returns whether or not the query is sliced. This would prevent code duplication with `Query.aggregate`.
I think `getLogger()` calls typically go at the top of a file.
missing space after : (check code with flake8)
assertTrue -> assertIn (although hopefully we can avoid a need for the changes in this file in the first place)
please put imports at the top of the file
Might consider using the console logger by default for this to be more useful. I don't think most people will configuration logging in development to enable it otherwise. On the other hand, I don't know if this would clutter up the runserver logs.
Ok, cool. :thumbsup:
not sure about the purpose of this test. I don't really like using `assertNotEqual` since there are an infinite number of "not expected" strings that will cause the test to pass.
Please remove trailing newlines in files (check code with flake8).
I just cut'n'pasted a working pattern I had in django-contemplation... this was only meant as a PoC [and to shut up the "Oh, but I _want_ it!" whiners :)]
I think if we're supporting multiple error classes we should make it a list instead of a whitespace separated string
alphabetize g before o also I would combine with the "from" imports below
seems like this doesn't need to be a variable as it's only used once
MEDIA_TYPES is not a module level constant anymore, I'd rename it to `media_types`.
`type(self)(...)` looks more Pythonic to me.
The size of self.MEDIA_TYPES won't be large, but it would be good to pre-compute this.
``` py media_types = [('css', dict), ('js', list)] ``` looks better to me.
Oh the code looks fine, it's just that this should be 4-space indented not 8.
Something is wrong with the indentation here, you might want to use `flake8` from the top directory to spot warnings.
This will need to be updated to use argparse.
There should be a way for users to disable the coloring of `runtests` too.
You can use `if six.PY2` (import `six` from `django.utils`)
From a quick look I was under the impression that the unit tests for `ModelState` were in there as well, but anyway it's a nitpick.
Do you think renaming the `kwarg` to `cached=True` would make more sense here? I feel like the double negation might be a bit confusing.
This change isn't correct as it will disable the check unless testing. Maybe this would work: `if 'django.contrib.auth.backends.ModelBackend' in settings.AUTHENTICATION_BACKENDS`
missing space after comma (check code with flake8)
We might want to remove this dead branch.
Add a space before `M2M`.
Merged overridden settings into one decorator.
Do you think it would make sense to test a real use case form intead? ``` python class ConfirmDeleteForm(forms.Form): confirm = models.BooleanField() ``` And update the tests accordingly to delete/post `confirm=1`.
I'm reminded of #21381 (removing contrib.redirects dependency on contrib.sites), but not sure that should block this.
I'm not convinced this deserves a separate test. Consolidating the `test_forever_timeout` test might be enough.
new kwargs should be added to the end of the list just to be super safe regarding backwards compatibility.
this is usually called `opts = self.model._meta`
rcvr -> receiver (no need to obfuscate it)
use """ for consistency with other docstrings
This won't pass on py3k, since `repr(u'abc')` -> `'abc'`.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
check the group permissions before `is_active = False` too.
my preferred style is: "#17903 -- Inactive users shouldn't have permissions..."
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
deindent text comma after get_group_permissions() nor -> or
this and the check in `get_group_permissions()` is redundant with the check in `_get_permissions`
First we should verify this passes before we toggle `is_active` to False.
Actually I guess the ideal way to test this would be something like: ``` backend = ModelBackend() backend.get_user_permissions(user) ```
> Although... _Does_ TextInput support datetimes? Yes, with TextInput, the date is serialized like this: 2014-05-09 14:08:21.805873 and you can manually edit any part, including microseconds.
nitpick: we are not so attached to the 80 chars limit, I think having those 3 lines on one should be fine.
This name shouid be changed, either to "lowercases_column_names_in_introspection" or to "uppercases_column_names". The Oracle backend lowercases column names in introspection because it uppercases them in creation.
Consider ``` python base_name = 'Field' if not connection.features.lowercases_column_names else 'field' ``` for the general rule that in if expressions, the "iftrue" part should be the more common, reflecting the default.
There's a lot of repetitions of ``` python if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): ``` in this function now. Also, for Oracle, it doesn't check things it could check (e.g. that `ip_address_field` is a CharField). I think both issues could be addressed with a smarter field-type-asserter; perhaps this is out of scope for the PR, and should be done separately.
... as null=True when they aren't.
This if (lines 114--123 as I write this) can be folded into the previous one (109--112).
`else: assertFieldType('text_field', "models.TextField(null=True)")` (might be taken care of by general improvement described at bottom of method)
`else: assertFieldType('time_field', "models.DateTimeField()")`
To be consistent, BigIntegerField should be qualified with `if c.f.can_introspect_big_integer_field`
The replacement of the `hasattr` check by a `try`/`except AttributeError` can mask `AttributeError`s within `backend.has_perm`.
any reason for passing args as kwargs? e.g. `subject_template_name=subject_template_name`
Don't put each parameter on its own line.
I think it would be better to use the same parameter formatting style as the `save()` method below.
format parameters as described above
can return directly, no need for intermediate variable
alphabetize import (I'd put this below `from django import forms`)
import should go at the top of the file unless it causes a circular import
I don't see a reason to make this a staticmethod. A user might want to use something from the class when overriding it.
can include more than one parameter on each line as noted above
import at top of file
This is what I mean: ``` def construct_email(self, subject_template_name, email_template_name, subject_template_name, email_template_name, ...): ``` Basically wrapping at 80 characters.
I wonder if it would be better to include `.send()` in the new method and call it `send_mail()`. That gives some additional flexibility if the user doesn't want to actually send an email for some reason.
You could combine "errors" and content of `pofile` in a file. Here is a untested approach: ``` py logfile_format = """\ Invalid input: %s ----- Output of %r: %s """ pofile_log = '%s.log' % pofile with open(pofile_log, "w") as fobj, open(pofile) as fpofile: fobj.write(logfile_format % (errors, pofile, fpofile.read())) ```
I'd move this message to `CommandError`: ``` py msg = "errors happened while running msgmerge\n%s\nSee invalid input for msgmerge %r." raise CommandError(msg % (errors, pofile_debug)) ```
Gotcha, okay I think this is acceptable.
I think all the calls to `render()` can be removed (it worked for me in this test at least)
If initial_forms=3 and min_num=4 and extra=3 I'd expect total_forms to be 6 and not 7 EDIT:// oh, I see below that this would probably be a change in backwards compat; in that case never mind ;)
See the messages for the methods above and add them these here too
This can be a class attribute: ``` py class SessionStore(SessionBase): session_class = Session def __init__(self, session_key=None): # ... ``` Then you can subclass `SessionStore` and update the `session_class` attribute: ``` py class MyCustomSessionStore(SessionBase): session_class = CustomSession ```
Everything testing stuff with LC_\* needs careful treatment for windows etc…
looks like plain TestCase will be sufficient here and we can remove the super call to setUp
you can use `a` here again.
can simply use "a" rather than "a#" in this, the next, and some of the other tests.
assertEquals (deprecated alias) -> assertEqual I would also reverse the order of the arguments and use `self.assertEqual(Article.objects.all().count(), 0)`. That is what I have seen most often in tests.
chop blank line
Your are missing the `except` to this `try`.
`assertEqual` the "s" version is a deprecated alias.
I don't think `classonlymethod` is correct here. Its exception message "This method is available only on the view class." doesn't make sense in this context.
please including trailing comma on dicts so if more options are added in the future, we don't need to modify this line again.
remove extra newline (please check code with flake8)
I see we use assert elsewhere, but I would prefer to raise an exception as asserts are ignored when running with `python -O`.
Is this line needed? I wonder if it's better to raise an error if you try and use sessions without it installed.
collections is before copy alphabetically
Hmm, I guess fewer moving pieces does make sense for this, OTOH if you can't load a file off disk you're pretty broken :-) On Sun, May 18, 2014 at 4:04 PM, Markus Amalthea Magnuson < notifications@github.com> wrote: > In django/views/debug.py: > > > @@ -1121,7 +1135,7 @@ def default_urlconf(request): > > <!DOCTYPE html> > > <html lang="en"><head> > > <meta http-equiv="content-type" content="text/html; charset=utf-8"> > > - <meta name="robots" content="NONE,NOARCHIVE"><title>Welcome to Django</title> > > - <meta name="robots" content="NONE,NOARCHIVE"><title>{{ window_title }}</title> > > I figured all of these are in strings to be able to serve error pages even > if the template engine has failed. But that's just a theory :) > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/2682/files#r12776836 > . ## "I disapprove of what you say, but I will defend to the death your right to say it." -- Evelyn Beatrice Hall (summarizing Voltaire) "The people's good is the highest law." -- Cicero GPG Key fingerprint: 125F 5C67 DFE9 4084
consider calling this variable simply "title" (that's what the admin uses)
deindent this line 4 spaces
no need for nested conditionals here, just combine them using `and`
comparisons with `False`, `True`, and `None` should use `is` or `is not`, rather than `==` or `!=`
no need for parens
Have you tried running the tests? `NameError: name 'connections' is not defined` here
Can `@override_system_checks` be moved to the class? Not sure if it works there, I know `@override_settings` does.
move to finally
this should be in `finally` just in case the commands before throw an exception
if no app*
move import to top of file
still seems like we're missing this type of query: `filter(tags__content_type=ctype)`
Need to remove u'' prefix on strings for Python 3.2 compatibility.
I even wonder if this part of the test should be kept at all, it tests specifically for the "feature" you are removing.
wrong spacing around = `site_obj = Site.objects.create(domain=SITE_NAME)`
use flake8, it will tell you how to fix it.
Remove the spaces around `=`.
please check flake8, `mark` is no longer used.
Can we normalize the error message with https://github.com/django/django/blob/master/django/db/models/fields/related.py#L460-L463.
It looks like we already used this approach in `SingleRelatedObjectDescriptor` (raise a `ValueError` on unsaved objects) so I guess it's fine to use it here as well. I'm still unsure how this interacts with the `AttributeError` case but I guess it can be revisited later if necessary.
please use `self.assertRaisesMessage` or `six.assertRaisesRegex` rather than `self.assertRaises` to check the exception's message as well
Can't figure out when the `AttributeError` is supposed to happen, I'm gonna try to remove its handling and see what breaks in the test suite.
move this line outside `assertRaises` (keep `assertRaises` blocks as small as possible so it's clear what is expected to throw the error)
""" #10811 -- Assigning an unsaved object to a OneToOneField should raise an exception. """
`return None` doesn't appear to be necessary -- that's the default.
I think we could simplify the test by simply testing the presence of 3 occurrences of `<option value="0">empty_label</option>` in the result.
I suggest testing `if empty_label is not None`, because we can imagine someone wants to set empty_label to the empty string.
This change is backwards incompatible for someone having subclassed the widget and customized `none_value`. We might let `none_value` as is, and simply update `none_value` in `__init__` (I'm open to arguments...).
It seems like `name` is never stored. Are you missing a `self.name = name or func.__name__`.
consider a constant for 'tests.py' since it's repeated a lot
including the file name in the header would be helpful as there could be more than 1 file.
Shouldn't we add an `else: raise` here? Then the `if settings.configured:` below would be unnecessary.
We have to be sure that a real setting has been accessed at least once before. After checking some code paths, I think it is the case and this should be safe to do.
To prevent unexpected `FieldDoesNotExist` exceptions raised in `if field.attname == field_name:` to be silennced. It's generally good practice to restrict the `try` body to the only parts expected to raise the exception.
ideally this bit would be in the `else:` branch of the try/except.
The check seems a bit convoluted to me, you should be able to get rid of the `err` variable. What about: ``` python try: cls._meta.get_field(field_name, many_to_many=False) except FieldDoesNotExist: if field_name.endswith('_id'): try: field = cls._meta.get_field(field_name[:-3], many_to_many=False) except FieldDoesNotExist: pass else: if field.attname == field_name: continue ```
revert this change since you ended up removing has_permission here
don't need an else here (raising PermissionDenied short-circuits), that'll make the diff less scary too.
Please don't rename the context variable as that's backwards incompatible. Thus, I wouldn't rename the local variable either.
Yes, I believe that's the point of the suggestion -- so you can override the method if you want to customize the behavior.
no need for intermediate variable
I wasn't expecting this additional check to be added in all these cases. In the default case, there's no change and it doesn't seem very DRY to require both.
Thanks for the patch. Clean and simple. Maybe that's just nitpicking but what about changing that `if` to `elif`? Because since `MEDIA_URL` must always explicitly end in slash, we might not want to add a slash if a trailing one is missing from it.
actually I think we should set these 3 values from `none_value` in an else after the new elif I suggested above and then remove them as class attributes. There's an issue if someone has subclassed the widget and set `none_value` -- that value would be ignored with this change.
I'd remove this check, otherwise tuples of other lengths will be silently ignored. Better for an exception to be thrown.
I'd go with `elif empty_label is not None:` and remove the next line
comma after "list" chop "selects box" (or rephrase... currently it doesn't make sense to me)
too many newlines here
I think these should be removed as class attributes as it implies they can be overridden, but as far as I can tell, they will be assigned in `__init__()` no matter what.
I still think think should be `if empty_label is not None`, otherwise types other than list, tuple, or string will be silently ignored.
a separate model (and same note as above about spaces at end of string)
Yes, but there we are testing behavior on TestCase so it makes more sense. Maybe it's fine here, but it seems fishy. In any case, I haven't looked into alternatives.
think we should say 'for database "%s".'
The blank space for the string usually goes at the end of the line instead of the start of the next line.
No... this is just an assumption we can make in the test.
Find the minimum max allowed length
supports long field names. -> doesn't have a column name length limit.
these lines are a bit long... ``` m2m_field = models.ManyToManyField( VeryLongModelNamezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz, related_name="rn1", ) ```
think this should be a separate error code since the message is different
The reason for this is that your for loop is running on both dbs, at first `allow_migrate()` returns `True` for the first db (`default`) thus setting `connection`, `allowed_len`, `db_alias` accordingly, but you are not terminating the loop, making it try `other` db with `allow_migrate()`, returning `True` and setting the variables again.
I see no reason not to use `db = router.db_for_write(cls)` instead of this whole for/continue loop. AFAIK, this will give you the same result you're looking for.
I don't think nesting the test cases is the correct approach to avoid the errors you encountered.
use `and` and parenthesis rather than nesting if statements
Actually, I think we can skip the router stuff and just use `django.db.connection`. These tests aren't run with custom routers so this'll always be run on the default database. (so we can move the skip condition to `test_long_column_name`).
Same note goes here.
Even though you are running the test only if the db doesn't `supports_long_model_names`, you are using `allowed_len` without checking if it isn't `None` (which is the default).
+1 to a public method on the handler
If `lookup_params_all` is an instance of `dict` you can iterate over its keys directly: `for key in lookup_params_all`. You can also remove the extra spacing inside any: `any(field_path in lookup_param for lookup_param in lookup_params_all)`. You can detect whitespace issues by running `flake8` from the source.
Add a space after `=`.
You still have to iterate over `lookup_params_all` don't you? ``` python >>> a = {'a__a': 1, 'b__b': 2, 'c__c': 3} >>> any('a' in key for key in a) True ```
You have the same docstring for 4 tests but they are obviously meant to test different things, so clarifying that would be helpful.
I think `data={}` can be omitted.
It would probably be better to check `cl.queryset.query.distinct`
I don't think "base on test..." is important. Corrected grammar would be "based on test..."
I would do keep two lists `construct_inline_exclude = list(exclude)` and append to each of them, passing `construct_inline_exclude` to `construct_instance()`, rather than the list comprehension. A commend as two why we need the two different variables would be helpful.
You could show a message like `"Preserving test database for alias '%s'"` here.
`msg = None` then only warn if msg is set.
with -> the
Actually, should probably use a constant for this rather than repeating the string everywhere: `DJANGO_VERSION_PICKLE_KEY = '_django_version'` (in `django.db.utils`, I think)
should be indented as in other places
version -> pickled_version `current_version = get_version()` (so we don't have to call it multiple times) check `if version:` first so we can skip `get_version()` if no version on pickled model.
put `warnings.warn()` outside the if/else so you don't need to repeat it
is not specified.
missing `if current_version != pickled_version`
Should probably prefix `'django_version'` with an underscore to mitigate the chance of clashing with a field of he same (we use a similar convention for cookies that Django sets).
shouldn't the translation be deactivated in the end? (i.e. activate the language prior to the first activate call)
not Python 3 compatible
not sure a mention of the ticket is needed (if we did that every time we made a change, things would be pretty cluttered)
Yep, I think that's correct.
Why the `.copy()`? By the way, it seems that the way `QueryDict.__init__()` is implemented, you can use `QueryDict(None)` to get an empty `QueryDict`. Come to think of it, I don't see a reason why `QueryDict` has any required argument. We could make `query_string=None` the default and it should work the same.
Can you explain why it's okay to move `patch_vary_headers()`? (I know nothing about it and am just reading about it now.) Also, remove (I think) the failing test.
I would separate each `with` statement with a line break. right now it looks like a huge block of stuff.
Also, I think we need to allow querying using parent type. That is if we have f = ForeignKey(Restaurant) where Restaurant is subclass of Place, then querying using f__in=[place1, place2] should work. While it is arguable if this is a good API, this works currently, and forbidding it will make currently working user code break.
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
docstrings on these methods would be helpful
put this on the class so you don't have to repeat it in each method
passed to query relations.
Couldn't this be done either inside get_lookup_constraint() (found somewhere in models/fields/related.py if I remember correctly)? The method already needs to iterate through the values and do some value conversions. Also, it might make sense to define the check part as a submethod, that is the code in: ``` if (value._meta...) pass else: raise ValueError() ``` is duplicated two times, removing that duplication will make the code a bit cleaner to read. If for some reason doing this as part of get_lookup_constraint() doesn't work, then at least make a separate method for this, build_filter() is already complex enough. And if this is moved to get_lookup_constraint(), again separate method in related.py would be a good idea.
don't need a trailing comma for lists with a single element (only needed for tuples)
"Checks the type of the object..." (The fact that it's a method and that it calls check_query_object_type is readily apparent)
Either "It checks whether..." or "If not, raises a ValueError..." (i.e. `it` should be either in both cases or in none).
you can also write the negation of the condition in the `if`, and raise the error if condition is `True` (avoids the `pass` and the `else`.
`self.oc` doesn't appear to be used
As noted in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style, we're not so strict about it in code.
What happens if the pk field isn't in the self.query.select? I think using self.query.get_initial_alias() instead of self.query.get_meta().db_table should fix this issue.
`pk = self.query.get_meta().concrete_fields[self.query.get_meta().pk_index()]` > `pk = self.query.get_meta().pk]`
probably want something like: `sorted(_SEP_UNSAFE)` so the order isn't random. Might be clearer to output something like "0-9A-Za-z-_=" though.
won't work if `sep` is more than a single character.
in this model, the `ManyToManyField` `authors` is replaced by `books`, right? If yes, could we test it? In other words, test that both directions are influenced by the `default_related_name`.
I think you can omit `_ =` (here and below).
[`create` already saves the model](https://docs.djangoproject.com/en/dev/ref/models/querysets/#django.db.models.query.QuerySet.create), you don't need to repeat it (same for others below)
I'd format it like this to prevent a long line: ``` return self.opts.default_related_name % { 'class': self.opts.model_name.lower(), 'app_label': self.opts.app_label.lower(), } ```
`Editor 1` -> `Editor`
Yep, looks fine now. I think there may been a newline at the top of the file before.
extra newline (check flake8)
This check was my least favorite part of this change. It feels odd to issue a warning for using the default. I never came up with a clever way to make this warning more meaningful/reduce false positives.
I'm not seeing why this change within this commit, but it could be just me.
python3 tests failed because `six.iteritems(old_test_settings)`.
There are two issues I see with this: In terms of code, the `elif key=='TEST'`executed for every key that isn't TEST_\* is a little funny. In terms of semantics, you assume that not including a value in the dict is the same as setting it to None, which isn't true (e.g. `TEST['CREATE_DB']` is a Boolean which defaults to True ). I think it is better to do something like (untested) ``` python test_settings = conn.setdefault('TEST', {}) old_test_settings = {} for key, value in six.iteritems(conn): if key.startswith('TEST_'): new_key = key[5:] new_key = self.TEST_SETTING_RENAMES.get(new_key, new_key) old_test_settings[new_key] = value if old_test_settings: if test_settings: if test_settings!=old_test_settings: raise ImproperlyConfigured(...) else: #not test_settings test_settings = old_test_settings warnings.warn(...) # now test_settings can be used ``` This doesn't pin exactly any mismatch, but that can be done only when an error has been detected (and then TEST_SETTING_RENAMES_REVERSE may still be useful)
check flake8, two newlines above functions expected I think.
The PR looks good, but these line and the other docstring line needs a more verbose description. here is a docstring from another regressiontest: ``` """ Regression test for #12913. Make sure fields with choices respect show_hidden_initial as a kwarg to models.Field.formfield() """ ``` it describes what the Test does so that people directly know what it does ;) +1 if the docstring gets updated.
Hm, it seemed to work for me when I pulled down your branch and made the changes.
remove u'' prefix (not valid on Python 3.2) and add `from __future__ import unicode_literals` if you need it.
missing some trailing commas
note that `Meta` should appear after fields per: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#model-style I made this one change when I committed it.
for the end of a list, I prefer this style: ``` 'object_id_concrete', ] ``` This has the advantage of not needing to modify a line like `'object_id_concrete'],` when adding more items to list which keeps subsequent diffs and git blame cleaner.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
I would deindent these ] and also include a trailing comma in case more items are added later
above `to_fields` is on a separate line -- would be nice to be consistent.
removing unnecessary multilines like this will make it nicer.
assertTrue -> assertIn
It would be nice to be consistent with your indentation style. Personally, I prefer: ``` data_not_concrete_abstract = models.ForeignObject( Relation, from_fields=['abstract_non_concrete_id'], to_fields=['id'], related_name='fo_abstract_rel' ) ``` over ``` friends_abstract = models.ManyToManyField('self', related_name='friends_abstract', symmetrical=True) ``` Feel free to have lines that are longer than 80 characters, like: ``` m2m_abstract = models.ManyToManyField(Relation, related_name='m2m_abstract_rel') ``` if it improves readability.
This check would benefit for being a little stronger. As currently phrased, it's checking that every value of f.rel in local_fields is _either_ a related.ManyToManyRel or None. This doesn't validate that the right field is returning the right result (e.g., a data field returning M2M for some reason).
I think it's make more sense to rename "view" to `status_code` and pass it as an integer instead of a string.
a better alias would be `HTTP_REASON_PHRASES` -- `MSG` is very vague.
`.get()` -> `[]`
Just use `_resolve_special(status_code)` as noted below, I don't think we need different `resolveXXX` variants.
don't seem like we need `client=True` -- how about `getattr(urls, 'handler%dxx' str(status_code)[0])`
I would prefer to omit it for now.
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
It's my suggestion to address your concern: ""we are writing a code thrice instead of once"
If we were starting from scratch, we'd probably go with this, but I'd rather not change it now. Use a local `status_code=40X` variable in the `except` clauses if you don't want to respond the int.
e.g. ``` except http.Http404 as e: status_code = 404 logger.warning('Not Found: %s', request.path, extra={ 'status_code': status_code, ... ```
And we are now logging 500s twice... and the names like "Not Found" are now different. It's not worth all these differences and inconsistencies.
I think `get_exception_response` would be a better name for the method.
how about `_resolve_special` -> `resolve_error_handler()`. I don't see a need for separate methods like `resolve4XX` and `resolve5XX`, especially when you pass any status code to either and achieve the same result.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
I think we should revert the logging changes as it appears we're adding additional logging calls where they didn't exist before.
How about `@lru_cache` on `get_git_changeset()` instead? I'm not a huge fan of `@lru_cache` with `maxsize=None` in general.
This should be defined outside the `try` - if `call_command` raises, `merge_file` won't be defined in the `finally` clause.
need to use `six.iteritems` for Python 3 compatibility.
4 space indent for consistency with test below
tests aren't entirely consistent, but I prefer omitting a newline after the docstring.
prefer lines longer than 80 characters if it improves readability as described in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style
was referring to `call_command`. the `os.path.join` is okay.
FWIW, I prefer including a trailing comma in dicts like this so if more lines are added later, we don't need to modify the last line again (keeps diffs/git blame cleaner)
alternatively, could treat this like databases where the lack of an option means `False`. Don't have a strong preference personally.
Wouldn't it be simple to do — so that you don't have to define a wrapper class which isn't used anywhere else — something like that: ``` Python def __iter__(self): with self.db.wrap_database_errors: for item in self.cursor: yield item ```
I believe this way is also much more efficient. The __next__ path causes two extra method calls, and one with statement to be executed for each call.
Nitpick but `dict.get` default value for a missing key is already `None`.
`STATICFILES_IGNORE_PATTERS` -> `STATICFILES_IGNORE_PATTERNS`
F401 'urlquote' imported but unused
add trailing comma
don't need `date_of_birth` field
Yea, it seems a bit unusual, but I don't have an alternative to suggest.
No need to duplicate all this stuff, just put a conditional in the interpolation: `' (%s') % capfirst(field.rel.field_name)) if field.rel else ''`
The test is incorrect. Testing manually with `manage.py createsuperuser` doesn't work. `django.utils.six.moves.input` returns strings, not integers.
Although the test works fine, this will fail admin checks: `fkuser.CustomUser: (auth.E003) 'CustomUser.username' must be unique because it is named as the 'USERNAME_FIELD'.` so might as well fix that.
I think 1 needs to be '1'. Try it calling `manage.py createsuperuser`: ``` Username: 1 Error: email instance with pk '1' does not exist. ``` even though: ``` >>> Email.objects.values('pk') [{'pk': 1}] ```
this seems to hang on PostgreSQL/MySQL: Error: group instance with pk 1 does not exist.
domin -> domain
These test cases miss the originally reported usage: raise `ValidationError({'code': ErrorList(['error message.'])})`
Yeah - that was the source of my confusion about the `setdefault` thing. My original test case was wrong, but the same problem manifests if you use `ErrorDict()`.
These three lines are essentially doing the fix - not the change to `update_error_dict`. Prior to these calls, printing `self._errors` shows that each "value" in self._errors is a `ValidationError()` instance; this converts the ValidationError instance into an ErrorList, which has the right behaviour when printed.
Need to use six.assertRaisesRegex for Python 3 compatibility
omit newline for consistency with other tests
It could indeed be backwards incompatible as I described (users may have to update their code).
I don't think we should go so deep into validation, we opt out from numbers but at the same time we allow the whole unicode range. Unicode numbers like `๑` would happily validate therefore it's an uphill battle. I'd opt for a vastly simplified regex to validate FQDN: `'(?:[a-z0-9\u00a1-\uffff-]+\.?)+'`. Sure it'll let some invalid segments go through (e.g. leading/trailing hyphens) but at least it doesn't pretend of being exhaustive. Proper validation requires a parser anyway.
`localhost` or rather `localhost.` is a FQDN, that shouldn't require a special case.
It wouldn't validate the following: - http://.com - http://. - http://.. - http://../ - http://.www.foo.bar/ - http://.www.foo.bar./ It would indeed validate the following URL (but they are actually valid): - http://example - http://example. All the others are about leading and trailing hyphens, if we really want to filter them out despite the increased complexity then I suggest we break the pattern into multiple variable for readability: https://gist.github.com/386830e46e8d2aca9dcb Regarding formal grammar, it's spread out among a bunch of RFCs, I doubt it's worth the effort.
rq? res? please use better names.
I think connection is a bad name to use because of database connections `django.db.connection`.
use message or input_msg through, no need for two different variables I think
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
I don't think we should include a default implementation of this. Simply refactoring: ``` while user_data[field_name] is None: raw_value = input(force_str('%s%s: ' % (capfirst(field.verbose_name), ' (%s.%s)' % (field.rel.to._meta.object_name, field.rel.field_name) if field.rel else ''))) try: user_data[field_name] = field.clean(raw_value, None) except exceptions.ValidationError as e: self.stderr.write("Error: %s" % '; '.join(e.messages)) user_data[field_name] = None ``` Into something like: ``` while user_data[field_name] is None: user_data[field_name] = self.get_input_data(...) ``` so that the method can be overridden as necessary is enough. But let's have Chris give his input before proceeding.
"leave blank to use" wouldn't be applicable for FKs
Yes, that's right -- `auth_app.User._meta.swapped` should always be True; we can omit the change to the condition.
I think it can be omitted.
I would call it "handles_files" and add a brief coment
Maybe we could make it less coupled if there were some attribute on the handler class that could be checked here.
the object's existence in the database is again checked for if the ...
can occur in some
I'm talking specifically about `index_together = 42`.
is this needed? seems like it's invalid...
Did you mean: ``` python IMMUTABLE_WARNING = "get_fields return type should never be mutated. If you want \ to manipulate this list for your own use, make a copy first" ```
``` python for obj, query_name in six.iteritems(parent._meta.get_fields(data=False, related_objects=True, include_hidden=True, **options)): ```
Ah... now I see.
pep8: no spaces around `options_instance`
`hasattr(field, "is_gfk")` - what's the underlying use case here? We shouldn't be hard-coding a concept like GFK into the API.
It's fine to say "is_gfk" here, because we're in contenttypes, which is defining GFKs. However, we should be capturing the underlying use case - it's a field of type X, which has a specific set of properties and behaviours.
... and I take a closer look and I see the reason - `RelatedObject.model` already exists. So; what about the other way around; add parent_model to field? That way, you can ask every field "what model do you belong to?" and "what model are you associated with?". Normal data fields return the same model for both; RelatedObjects return different models.
preferred style is not to use backslashes, e.g. ``` FOO = ( "..." "..." ) ``` Also please always add () when referring to methods (get_fields() in this case) in docs or messages to distinguish them from attributes.
please avoid bare except
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
The old options look pretty easy to deprecate. We just accept `**kwargs`, and alias any older `kwarg` to the new one + deprecation warning.
There would have to be a `reverse_many_to_many` as well for consistency and since these are pretty much on/off flags, I think we should aim at convenience.
This change is concerning - it indicates that there's a backwards incompatible change in the API. If existing users are invoking with `many_to_many=False`, we should _at least_ preserve that usage.
And now I look at the implementation for get_field, I see that @PirosB3 has implemented the backward compatibility approach with kwargs already.
The approach you've taken here is: - Cache the result of get_fields() for a specific set of arguments - look up a name in that list; - Raise FieldDoesNotExist if the name is not found. The other obvious approach I can think of would be: - Cache a list of _all_ fields - Look up the name in that list - Raise FieldDoesNotExist if the name is not found - Raise FieldDoesNotExist if the field doesn't have the requested properties. I'd be interested to see the "memory vs speed" tradeoff for these two approaches.
if include_parents is False, this line generates a result that isn't used. Move it inside the if for a minor performance boost.
The significance of `export_name_map` isn't described.
Just because you _can_ cram this all on one line, doesn't mean you have to. This would be a lot easier to read as: ``` field_list = tree[self] if self.proxy: field_list += tree[self.concrete_model._meta] for f in field_list: ... ```
Indentation can do a lot for legibility here: ``` fields.update( (field, (field.name, field.attname)) for field in self.local_fields if include_non_concrete or field.column is not None ) ```
A minor matter of style, but "GO below this line" isn't needed. All you need is the section header. I'd also suggest making the header more prominent - precede and follow the header text line with a line of `####` that goes the full width (or to col 76, anyway - 1 indent back from max line length) of the code. ``` ########################################################################### # Deprecated methods ########################################################################### ```
This shouldn't be a "class in a class"; it should be in a utility section at the bottom of the file.
Either _all_ fields should have an m2m property (because m2m is a fundamental property that a field can have), or none of them do. A hasattr check doesn't make sense here. Same goes for is_gfk a few lines earlier. m2m is probably a fundamental property of fields, but gfk is masking something more abstract.
As with `@raise_deprecation`, this should be a module-level utility, not a method on the class.
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
`virtual` defaults to True so it seems there's no need to include it. I guess I would sort of like if there were a shortcut method so we don't have to pass `related_objects=True, related_m2m=True` when we want to search all fields as it seems like a common case. Not coming up with a good name at the moment though.
please alphabetize with the rest of the django imports
get_fields() (add parenthesis) to distinguish it from other alternatives which are properties
include trailing ,
omit trailing , before ) (only include it if the tuple is multilined)
to minimize size of try: ``` try: m2m = kwargs['many_to_many'] except KeyError: pass else: warnings.warn(.... ```
I'd say "You may be able to replace it with ..." to avoid including the function name twice.
I probably missed your reply to this, but connection is a confusing name since it usually refers to `django.db.connection`
I would rather not do this reordering as part of this diff. It makes things quite a bit scarier, even though I believe most of the code has simply been moved. If you want to submit a patch to do this for the existing methods, we could merge it first and then rebase this patch on top of it, but I'm not sure it's worth it (to reorder at all).
Keeping the try block limited to just the code you expect to throw the exception is a good practice. It prevents a situation where there's some other bug than what you expected. For example, if `warnings.warn(` somehow threw a `KeyError` and it was in the try block, you would unexpectedly hide that bug.
add trailing comma
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
I would use a list comprehension rather than `list(map())`
Everything is still moved around in this file making review difficult.
is `link` what we call `rel` in the rest of the code? link has me thinking `<a href="...">`. Naming is hard.
add trailing comma
The return type of get_field()
I think the hardcoded hash should be replaced by `relpath = self.hashed_file_path("...")` There was a recent change (adding end of file newlines to the CSS flies) that caused the hash of all files to change so this would allow us not to have to update this hash each time.
Don't monkey-patch the exception, make a new one: `self._update_errors(ValidationError({f.name: e}))`
I think you should drop the semicolons at the end of SQL statements.
Yes, I do. Ending statements with semicolons is redundant at best (as used here); if followed by whitespace, the semicolons can actually break things. Code in tests serves as example, and so shouldn't include them. This is essentially like pep8 issues -- you don't have to clean up old code, but please avoid introducing new ones.
might as well make this one line
don't think we need `skipIfCustomUser`
Could you write the test without using fixtures? I think it would be a lot simpler.
assertEquals (deprecated alias) -> assertEqual
docstring with example input/output would be really helpful
Please ignore, my suggestion is invalid syntax.
unclear if this is `'name' not in lang_info` or `not ('name' in lang_info ...` (I think the first) would be helpful to restructure or adds parens so it's easily readible
tried_codes -> possible_lang_codes (the first name implies to me that they are being tried as the list is constructed which doesn't seem to be the case)
I see the pattern is used in other tests, but I wouldn't alias the function if it's only used once
Since 'iso-8859-1' is being used in the line above also, I wonder if it is not better have a variable on top like `FALLBACK_ENCODING = 'iso-8859-1'`
Well, it being here has kind of been overridden since as of a month or two ago the autodetector now strips unique_together and index_together from the model options when writing files, which I suspect is what triggered this bug.
u prefix won't be there on Python 3
remove blank line (check code with flake8)
I'm asking to change the code so that a u'' prefix isn't generated in the output.
There's a lambda called `strip_prefix` in `inspectdb.py` that should be of use.
actually I think the preferred solution is to omit the u'' prefix, even on Python 2. The output already includes `from __future__ import unicode_literals` so there shouldn't be a problem without it.
I'd combine w/previous line for better readability
My understanding of SubFieldBase is that all it does is call `to_python` whenever any value is assigned to the field. Personally, I wish it were on DateField and friends: being able to pass ISO8601 formatted strings and have them be date/time objects immediately makes for neater test cases.
(same pattern as above, if you change it)
It's true, but decimal and datetime are much more popular.
Is there a reason that I'm missing (probably) that the field's length is 36 (and each DB's backend definition is 36, with the exception of postgres, which has the native datatype)? Removing the dashes (if a string) or calling `.hex` turns the value into 32 chars, which both `uuid.UUID()` and postgres' datatype support as a input format, and both use the dash-inclusive output format.
oh that's what i've missed. thats true there is something wrong on that line
Marc, did you try to store by default in a binary column? AFAIK PostgreSQL is using a binary field internally.
would it make sense to lazy-load uuid as most projects won't need it? It could be done with just one more line of code in this file and in django/forms/fields.py
consider using a more descriptive name than "test_migrations" as I imagine there will be other migrations needed for other tests.
Nitpick: Since Django no longer [supports Python 2.6](https://docs.djangoproject.com/en/dev/faq/install/#what-python-version-can-i-use-with-django) and this is a new feature in Django 1.8, you can use Python 2.7's new `assertIsInstance` method here: https://docs.python.org/2.7/library/unittest.html#unittest.TestCase.assertIsInstance
move this to an else block in (try/except/else)
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
Couldn't give you an opinion without spending a lot of time figuring out the purpose of this patch.
I suggested this realiasing for tests only, I'd prefer a `if six.PY3 unquote_to_bytes() else unquote()` in the actual function. It helps with comprehension.
`repercent` is a confusing name, maybe `repercent_broken_unicode`? Also it needs a docstring with pointers to the RFC etc.
I would have been interested in something closer to werkezeug's. That takes encoding as a parameter, etc. **Edit**: TL;DR skip to https://github.com/django/django/pull/2932/files#r15440287
The latin1 encoding mess is a WSGI thing, Django wasn't always a WSGI framework, and who knows what will be the next best thing in the future. When these things were contained in the WSGIHandler that made sense, but if we extract a reusable function it shouldn't be tied to such specifics.
Why can't we just return unicode (i.e. decoded bytestring, so `str` on PY3 and `unicode` on PY2)? In that case the signature would be `uri_to_iri(uri, encoding='utf-8')` just like werkzeug.
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
They can only be decoded if these bytes were previously encoded in this encoding.
"If the charset is set to `None` no unicode decoding is performed and raw bytes are returned.". In that case you are returning unicode (already decoded) not raw bytes.
path = uri_to_iri(path).encode(UTF8) env['PATH_INFO'] = path if six.PY2 else path.decode(LATIN1)
I don't think it's necessary to create new files for this test. We could use for example `django.contrib.auth.models.Group` for a simple model with a name, and the test could be appended to the `TemplateRegressionTests` class, for example.
longer lines are okay if they help readability (I moved `model='Fake'` to the previous line)
I think it's useful to use the docstring to state the expect behavior rather than just say "Test ..." so I modified this.
Going to use `self.__class__.__name__` instead of hardcoding `BlockNode` to be safe in case of sublcassing.
I believe save() isn't required after adding permissions (M2M change)
prefer assertRaisesMessage to make sure we get the `ValueError` we expect and not some other one.
as noted in other PR, think we can omit a newline before a single assert
prefer this style for multilined docstrings: ``` """ Text """ ```
You'll want to use `force_text` here.
NotContains always makes me nervous since it's fragile (a typo or a change in the way we generate the HTML could make it pass). Could we make `class="inlinechangelink">Change</a>` a constant and use it in all 3 of the new tests? That would help alleviate those concerns.
checking the `has_registered_model` attribute in the template context could also be useful.
I would probably omit most of the blank lines in these new tests. They are fairly short and straight forward.
general note: prefer including trailing commas in lists like this so if more items are added later, we don't need to modify the line again (keeps diffs/git blame cleaner)
This seems out of place in a test class called `TestValidatorEquality`.
since we're using `FileField`, I don't think we need to keep this test if Pillow isn't installed
since it's only used in a single test, I think this can be moved inline to the test method
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
Would this original line not raise `ValidationError` further down in the `clean()` method? https://github.com/django/django/blob/master/django/forms/models.py#L1240. Might need to add it back.
this parenthesis is redundant and white space after 'if' is required. like 'if not isinstance ... dir(current):'
This 'filter-syntax24' key is duplicated. seems good to use 'filter-syntax25'.
Sorry, I should have said simply `raise` without the `e`.
Same as above, (simply `postgis`)
I think we can even simplify to `if oracle or postgis:`
Same as above (including the `prefix`)
For consistency, let's use also `prefix + 'MinimumBoundingCircle'`
When Python 2 needs a bytestring and Python 3 a normal str, the current usage in Django is to use `force_str()`, which by default encodes in UTF-8 (on Python 2 only).
This import should be alphabetized, but we can fix that up when committing.
remove u'' prefix (incompatible with Python 3.2 and we already have `from __future__ import unicode_literals` in this file)
my understanding reading the ticket is that this is only on necessary on Python 2. Can you confirm? If so, we should probably put this an `if six.PY2:` condition so we remember to remove the logic when we drop Python 2 support.
Use """ for consistency with other docstrings. suggested text: Verify HttpResponse.set_cookie() works with unicode data.
Looks good, on a cosmetic level, I wouldn't group the queryset declarations at the top but declare them before each assertion.
I feel it's more readable like it was previously.
This is compliant with the PEP8 rules that we care about, let's not make the diff bigger than needed.
Or even go so far as to split them into three tests - one assertion per test. Then if one fails it won't prevent the other two from passing, etc.
I think if you check `setup.cfg` for the project, it explicitly switches off E128 checks. Don't think it's too big of a deal either way :).
This doesn't work with fields that are not "select_relatedable". For instance `Species.objects.select_related('name')` doesn't raise an exception.
You could get away with something a bit more compact than that I think -- you don't need to wrap the text in parentheses, and you probably shouldn't split up the class name just to adhere to PEP8, line length isn't a big worry. Same goes for the other instance. ``` python expected = [ Error( "Field is using a table that has already been " "registered by <class 'invalid_models_tests.test_models.Bar'>.", hint=None, obj=Foo._meta.get_field('bar'), id='fields.E340' ) ] ```
prefer `request_hander = NoColorWSGIRequestHandler if no_color else WSGIRequestHandler` rather than duplicating more than what's necessary
override `__init__()` instead. after `super()` then `self.style = no_style()`
It would be clearer to pass `True` as a keyword argument here.
I'd multi-line this to prevent the need to scroll horizontally in github's review; otherwise LGTM.
Ahh didn't notice the `create_user` call, sorry for the noise.
Maybe you can do the following: ``` python if user.last_login: login_timestamp = user.last_login.replace(microsecond=0, tzinfo=None) else: login_timestamp = '' value = (six.text_type(user.pk) + user.password + six.text_type(login_timestamp) + six.text_type(timestamp)) ``` to avoid to have two conditions and to avoid inline ones.
Not critical, but I think it better to remove because that makes sure we don't still have code to support the older versions. As a minor point, initialization, although done only once per thread, invokes an expensive stored procedure, so it affects startup time. On the other hand, customization of the Oracle backend does seem to be a relatively popular practice. Your call.
With this change, I think it is no longer necessary to initialize `self.oracle_version`.
PEP8 E226: you need to have whitespace around the + signs
please use slightly longer lines such as here (move `EXTENDS_HISTORY_CONTEXT_KEY)` up) when it improves readability
I meant for the entire string here to be a constant; otherwise looks good to me.
Running the entire test suite I could reproduce the error, but not if only running `django.contrib.gis`. Not sure exactly the cause but this code seems suspicious as we leave a different model admin registered for other tests.
please use a variable for this string so that if it changes, we don't have to update it below as well
How about adding len(field_name) to _data_size on each iteration? Makes much more sense to me.
Also, what if we have a huge number of very short 'name=value's? This will create a dictionary with lots of small strings -- again lots of memory.
What if the 'field_name' is huge? It seems to me that it still goes into memory.
An unhandled `SuspiciousOperation` will result in a `400 Bad Request` response which is ok since it is a client error. However, `413 Request Entity Too Large` would be the correct status code for this error.
Removed extra code in PR #3852.
Servers DO limit the size of the URL including GET parameters. Maybe this protection is not enough, but the "problems" you mention seem intrinsic to the Python VM and not something we can fix easily here. So, having this protection in place is much better than not having any. As for making this limit per-view, that seems like a nice-to-have feature. We accept patches. :)
This might either throw errors or block forever (dunno how field_stream is implemented) if field_stream is empty at this point. Not sure, but something to check!
First of all, I think this should also apply to request.GET, we basically have the same problem there, unless servers severely limit the lengths there (no idea :(). That said, I don't think this protection is enough, eg take this simple example: `dict((i,i) for i in string.ascii_letters)` will consume 3352 on my box already, with raw data in the range of 52*2 bytes + form overhead (granted, the latter is big, but still something to consider). Also, a simple list on my box already takes 80 bytes of memory. Since we are using `MultiValueDict` with lists as items we'd already be at 3352 + 80 \* 52 ~ 8000 bytes and that's probably not all of it. Last but not least, to make this feature generally useable I think we'd need to be able to alter that per view like file uploads allow.
Was `MultiPartParserError` before and should at least be `Exception`
When the stream is empty an empty string is returned immediately.
A doc string is needed for get_db_converters so any 3rd party backends know exactly what is expected from this method
returning `b''` for BinaryField (as original code did) should be required under Python 3, IIRC.
`SELECT * FROM (SELECT "_SUB".*, ROWNUM AS "_RN" FROM (%s) "_SUB" %s) WHERE` ... (`ROWNUM AS "_RN"` should be part of the SELECT clause, not FROM clause).
append(...), not append[...].
prefer adding `()` to avoid backslash
You also needs to "unmock" this method in a try/finally block. Maybe we can first decide on a resolution about using mock (#23289) so we don't have to add more of this cruft though.
oops, I see. nevermind, I guess.
prefer listing the ticket number and a brief description (if necessary) rather than the full link to the ticket as that can clutter things up.
yeah, i don't think instance patching requires cleanup, that instance goes away at the end of the test
CommandError is unused
User projects aren't what I had in mind, but yes, you're correct as long as users aren't using the old test runner. I was thinking of the [contributing docs on unit tests](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/unit-tests/) in which we say, "A database with the alias other. The other database is used to establish that queries can be directed to different databases. As a result, this database can use any backend you want. _It doesn’t need to use the same backend as the default database._" Since we have no automating testing of running our tests with different database backends, I am not sure how well this works right now (and it's probably not something we need to consider for this change).
Does this change behavior slightly in that we are only checking the default database instead of all databases in settings like `HAS_SPATIAL_DB` does? It may be fine since we use the same pattern in the rest of the tests for database features, just want to confirm. The patch looks good.
I admit Django still has much code looking like that, but it should be safe to simply use `if options['empty']:` below without first pushing the result in `self`. Having the value on `self` might make sense when we want to use the value in other methods. Same for `options.get('help', False)`, as we are using the parser in both `call_command` and `run_from_argv`, we can be sure that `'help'` is in the options dictionary, so `options['help']` is fine.
The following properties indicate if
Calling `is_valid()` in `__repr__` is not an option (as it triggers validation).
suggested format: #19820 - Deserializer should give a helpful error message ....
It's preferable to re-use models instead of adding new ones if possible.
please alphabetize imports
no longer need trailing comma in tuple here and below I'd chop "In" from the message, otherwise it looks good.
assertRaisesMessage (and then can also remove `as ex`)
There's currently an used `skipUnless` import in this file; please remove it.
There is the problem that many people actually do use runserver in production despite all our warnings, so the current thinking among the core team is that we do have to treat runserver problems as security issues.
Heh. So the fact I used `f.func_code` is a hint that I've been using Python for a while... Here are the versions for modern (2+3) Python: ``` python def _clone_func(f, new_globals): from types import FunctionType as Function return Function(f.__code__, new_globals, f.__defaults__, f.__closure__) ``` and ``` python class WSGIRequestHandler(simple_server.WSGIRequestHandler, object): #... handle = _clone_func(six.get_unbound_function(simple_server.WSGIRequestHandler.handle), globals()) ```
In a project where a similar need arose, I chose to sort-of monkeypatch the function instead of copying. The code was, essentially, a general "utility": ``` python def _clone_func(f, new_globals): from types import FunctionType as Function return Function(f.func_code, new_globals, f.func_defaults, f.func_closure) ``` and its use in my child class, adapted to this case: ``` python class WSGIRequestHandler(simple_server.WSGIRequestHandler, object): #... handle = _clone_func(simple_server.WSGIRequestHandler.handle.im_func, globals()) ``` This, essentially, re-interprets the parent class's method with the importing module's globals (of which, the only one relevant is `ServerHandler`). Note the use of `im_func` above to get from the method to the function; also, note that I only tried this on Python 2. I'll see now if it works for Python 3 as well.
is `str()` needed? I assume `%s` takes care of that.
Same question as above.
The test fails on non-sqlite, probably because of PKs not being reused.
Not sure this is really required since it appears a couple lines below. At least maybe we could assert its `len()`.
Do we have a formal authorization from the author to include this? I don't see any license information in the post (which I just skimmed) and the footer says "Copyright © 2013 Ross McFarland. All Rights Reserved" which I don't believe is compatible with our license.
If there is no danger of a circular import error, I'd move this to the top of the file.
Looks like a typo to me.
Could we patch a StringIO instead of devnull and then verify the contents of log_message()? See tests/check_framework/tests.py for an example. Also the patching should be in setUp/tearDown or in a try/finally so if something goes wrong the unpatching still happens.
I think usual formatting is: ``` # -*- coding: utf-8 -*- from __future__ import unicode_literals import os import sys from wsgiref.simple_server ... ``` (wsgiref is a built-in so it goes with os/sys)
please check code with flake8 (`E231 missing whitespace after ','`)
We prefer docstrings on their own line, also this one isn't particularly helpful.
Superfluous `u` prefixes. They are not Python 3.2 compatible and this file already has `from __future__ import unicode_literals` anyway.
Use a try/finally block to restore the original `datetime` once you are done.
maybe you'd like to include the ticket number here so there' s a link between "Models for #" and "Test for #" Otherwise, LGTM minus the release notes. I guess we should do one more 1.5.x. release...
I like to put the ticket inline with the description: `#23431 - Specifying...`.
Actually version two would be slightly faster, if the speed is more critical in this case
Could be shortened to just two lines as well: ``` python t = getattr(_active, "value", _default) or translation(settings.LANGUAGE_CODE) result = getattr(t, translation_function)(eol_message) ``` but it would decrease readability IMO
All this if nesting (lines [303-309]) is semantically equivalent to: ``` python _default = _default or translation(settings.LANGUAGE_CODE) t = getattr(_active, "value", _default) result = getattr(t, translation_function)(eol_message) ```
might as well have a trailing comma.
Cool. I tested the new patch. It all works for me.
This patch looks mostly good and works for me. My one suggestion is that the test with a date object be explicit, like `test_sitemap_last_modified_tz`, rather than put into the i18n test.
You should have spaces around the `-` operator.
I would probably allow an additional parameter to allow using `CREATE EXTENSION IF NOT EXISTS` to handle legacy databases where the extension has been installed by hand. I don't see a way how Django could just automatically fake the migration otherwise.
I'm pretty sure someone will complain that this check is assymetrical, and as a consequence equality isn't symmetrical. Equality must always be reflexive (a == a) symmetrical (a == b iff b == a) and transitive (a == c if a == b and b == c).
I find binary operators very legible for set operations: `self.keys - keys`
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
Shouldn't we have a decorator for that? (kinda off-topic, I know)
This is `verbose_name` and you should make it translatable. Look at how other contrib apps do it.
I don't think you need `dispatch_uid` here. AFAIK `dispatch_uid` is largely a workaround for the duplicate import problem that was mostly eliminated by the project structure refactor in 1.4 and completely eliminated by the app loading refactor in 1.7.
If `value` is a `dict`, `set(value)` suffices, but maybe that's obscure and you chose the more explicit version on purpose.
+1 (in separate patch)
or something like: ``` py if connection.vendor != 'postgresql' and f in ('postgres_tests' , 'postgres'): ```
My proposed way is definitely broken. Maybe isinstance(other, KeysValidator)? This might be another instance of things we should do globally, not just in this patch.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
Nitpick, `deprecation` comes before `encoding`.
This line should be sorted 2 lines below.
chop blank line I would probably consolidate the opening closing brackets a bit like the other tests do so the test doesn't appear so long
Exception seems okay, but I've investigated possible failure scenarios
not sure there is a need to include the ticket in every test. Instead of "expect that", I would phrase it as "the error message should tell ..."
I didn't get a deserialization error with this test_string: ``` test_string = """[{ "pk": 1, "model": "serializers.article", "fields": { "author": 1, "headline": "Unknown many to many", "pub_date": "2014-09-15T10:35:00", "meta_data": [ ["author", "meta1"] ] } }, { "pk": 1, "model": "serializers.author", "fields": { "name": "Agnes" } }, { "pk": 1, "model": "serializers.categorymetadata", "fields": { "kind": "author", "name": "meta1", "value": "Agnes" } }]""" ```
Instead of simply `list(....)`, use this: ``` with self.assertRaisesMessage(serializers.base.DeserializationError, expected): objects = serializers.deserialize('json', test_string) for obj in objects: obj.save() ``` You could also just omit the `CategoryMetaData` object from the fixture and create it with the ORM.
I would name the test `test_reverse_text`.
I don't think this needs to live here - it could just live under the definition of `GeometryField` - the `ready` method would be perfect if we were adding this to something which lives outside of `contrib.gis`.
The query you want here to eliminate 2 separate queries is: `SELECT TABLE_NAME, 't' FROM USER_TABLES UNION ALL SELECT VIEW_NAME, 'v' FROM USER_VIEWS` And then you can use the same logic you used with the postgres backend.
(note newer caching of states)
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
this get_field_by_name should be adjusted with formalized model meta API I guess
Indexes are not constraints, generally.
At the point where the instance is created, there is not access to the model or its fields (we are in a nested class in the model class definition). Options and/or the modelbase metaclass, will have to connect the model to the index.
There should be a sane API through `schema` ( A SchemaEditor, I presume) to do this.
Oh, I get it. either fields or field-names. The code needs to be more explicit (and defensive) about it.
I think you should keep the old code here -- that way, you avoid new semantics as much as possible (also, with this change I think you lose the deprecation warning)
I'd use a classmethod to provide the default index type (I think that's cleaner than resetting the attribute in the initializer)
Isn't it preferable to manage `self.options['indexes']` as a set? Then you avoid any bugs of including-indexes-twice.
Perhaps it isn't worth breaking consistency. For sure it can wait and be done separately.
Consider, instead of the `__iexact`: ``` python table_name = "gis_neighborhood" if not connection.features.uppercases_column_names else "GIS_NEIGHBORHOOD" GeometryColumns.objects.filter(**{GeometryColumns.table_name_col(): table_name }) ```
I'd use a multiline string and indent it internally. Also, remove the semicolon in the end. Doesn't do any good, and can do harm.
I would expect some explanation on why `quote_name` is used for some names and `geo_quote_name` for others.
quote names of objects (`'CREATE INDEX "%(index)s"...'` etc). These parameters are spliced into the statement, not passed as arguments.
nitpicking: use the same quotes as elsewhere
Actually, quoting the parameters before interpolation makes _more_ sense on Oracle than other backends, because on Oracle `quote_name` also handles shortening.
The add_geometry_metadata sql, is, as far as I can see, not DDL -- and so, it can be executed by passing arguments rather than splicing them. This would require the elements of geometry_sql to be (sql, args) pairs instead of just strings.
Ok. I'm still new :)
I think "by" in this sentence should be replaced by "with": normally we'd say "tried to replace X _with_ Y"
I think for the benefit of Python 3 users at least we should set `__cause__` on this new exception to the original `KeyError`.
It seems like this error message would be even more useful, and would address the confusion that made us originally think this was a bug, if it went on "wasn't able to because some of the replaced migrations are already applied."
Maybe wrapping the inline conditional in parentheses would help readability.
I meant `module == ('builtins' if six.PY3 else '__builtin__')`
this line is very hard to read maybe you should do something like this: ``` python builtins = 'builtins' if six.PY3 else '__builtin__' if module == builtins: ... ```
Better make it a method instead of a lambda. If I'm not mistaken lambda expression assignment is also a flake8 violation.
A free option for getting the tests running with Oracle is outlined [on the wiki](https://code.djangoproject.com/wiki/OracleTestSetup#using-the-oracle-developer-day-pre-installed-vm) if you are interested.
why not? If the database backend cannot support it, it should be controlled by a feature flag not a vendor check.
How about: ``` r"""LIKE BINARY CONCAT('%%%%', REPLACE( REPLACE( REPLACE(%s, '\\', '\\\\'), '%%%%', '\%%%%'), '_', '\_'), '%%%%')""" ```
I hope it won't adversely affect readability, but if you can limit line lengths to 119 characters that would be good (see ticket #23395).
That part looks confusing, as `cr` and `lf` will potentially be used on `buffer_`, not only `chunk`. Instead, I would define two simple helpers `endswith_cr` / `endswith_lf` within `__iter__` — maybe there is some simpler way to do that but I couldn't find one: ``` Python def endswith_cr(line): return line.endswith('\r' if isinstance(line, six.text_type) else b'\r') ```
Shouldn't the line 112 also be adapted ? `chunks()` could have split the bytes between a `\r` and a `\n`, hence the following code might lead to unexpected results: ``` Python if line[-1:] in (b'\n', b'\r'): yield line ```
re: location of tests -- oops, I confused `test_utils` with `utils_tests`.
`assertEquals` is deprecated and should be replaced by `assertEqual`. In a more personal-taste spirit, is it really useful to make 4 separate tests instead of consolidating them into one? The fact that the last 3 are identically named is an error, for sure.
this doesn't pass flake8, I'd probably create a separate variable so you don't need funky indentation. ``` file_storage_settings = ( 'MEDIA_ROOT', ... ) ```
can import go at top of file? also, `test_utils` seems like an odd place for these tests. Generally that module is for testing `django.utils`.
I tend to side with Tim's preference for the `#23601 - Don't allow arbitrary imports but pass everything through resolve.` formating.
`model.__name__` alone is not sufficient. It would need to check for equality of both `model.__name__` and `model.__module__`.
I suggest `model.__name__` rather than `str(model)` (x2).
as the fourth
Why are you setting it to `None` here? It looks like it's not used between this line and line `#581`.
I guess it's a bit defensive, it helps ensuring that behavior is always identical. `print("hello",)` would give different results in PY2 and PY3 for instance.
I'd keep the ticket reference in the testcase.
is print_function needed? it doesn't appear in the rest of the code base.
Think the position of the newline should be altered -- above it seems to be so that the line fits in a standard size terminal window -- here the first line is too long -- should break after "non-nullable" instead.
Also message above doesn't have quotes around the model name.
Maybe `null_actions` for consistency with `post_actions`? And move it to where we init `actions` and `post_actions`? L581.
Once (field_name, model_name) expand I doubt it'll fit in 80chars even above. Good catch on the quote inconsistency.
"operation in the new migration file before the AlterField operation" (to give better guidance?) need newlines in the this message
Maybe a little too familiar wording? Also a suggestion of what one may want to do would be helpful, for instance: `(e.g. deal with existing NULL using a separate RunSQL or RunPython operation)`.
Not really, feel free to remove it in `get_or_create` as well.
We don't wrap at 80 chars, anything below 100 chars is generally fine. Also we shy away from backslashes.
is this line used? I don't see "_bumpme" anywhere else in Django.
I'd move this ) to the previous line
distinct -> a different
`None` not needed.
appears to be an inadvertent change
imports should be on separate lines, plus add a blank line between built-in and Django imports
use same indent style as previous item
don't need to assign these to self.
preferred format is just to prefix the message with the ticket number. "#23063 - Test that ..."
How about something like "assertTemplateUsed and assertTemplateNotUsed are only usable on responses fetched using the Django test Client."
I think this error message isn't very helpful (i.e. it's not actionable), and it leaks an internal detail, that we monkey-patch response objects with a `templates` attribute). What happened is a detail, what we need to know is **why** it happened, so we can fix it.
`assertRaisesMessage` should be sufficient here.
Missing 1 space of indentation.
Rather than implementing a special CursorWrapper for Oracle to do this, it is better to include the change in the general CursorWrapper. This has two immediate advantages over doing it in the Oracle backend: 1) The new feature can be shared with any other backend which supports it (3rd party backends included) 2) The new feature is automatically included in CursorDebugWrapper (which your version of make_cursor disables) The disadvantage -- exposing the interface to backends which do not support it -- is a small price to pay in comparison.
Simpler: ``` python params = params or [] if kparams: return self.cursor.callproc(procname, params, kparams) else: return self.cursor.callproc(procname, params) ```
Make this a global import.
in an absent
Can this line be written like the following line? ``` py msg = "This id does not appear to be a valid UUID4 identifier: {}" self.assertEqual("4", uuid_as_hex[12], msg=msg.format(uuid_as_hex)) ```
assertEquals is deprecated. Please use assertEqual instead.
I think the standard message of assertEqual is enough? `AssertionError: 200 != 201`
please use parentheses instead of backslash
or just `"TRACE {} {}"`.
Should be `del self.request_factory`.
It would be great to also have a test with a reverse manager.
Yes `RelaltedManager` is good.
I'd rather not pollute the global namespace. Could you use a temporary `Apps` (e.g. https://github.com/django/django/blob/master/tests/migrations/models.py#L24)
`assertEquals()` is deprecated, use `assertEqual()` instead.
"deleting it will allow.." is a little ambiguous. "deleting the user will allow.." may sound better.
Maybe you've made some other changes, but `$ ./runtests.py file_storage` passes for me with this change: ``` diff diff --git a/django/core/files/storage.py b/django/core/files/storage.py index 1471d4e..702f6a6 100644 --- a/django/core/files/storage.py +++ b/django/core/files/storage.py @@ -76,7 +76,7 @@ class Storage(object): """ return get_valid_filename(name) - def get_available_name(self, name, max_length=100): + def get_available_name(self, name, max_length=None): """ Returns a filename that's free on the target storage system, and available for new content to be written to. @@ -88,9 +88,11 @@ class Storage(object): # exists) to the filename until the generated filename doesn't exist. # Truncate original name if required, so the new filename does not # exceed the max_length. - while self.exists(name) or len(name) > max_length: + while self.exists(name) or (max_length and len(name) > max_length): # file_ext includes the dot. name = os.path.join(dir_name, "%s_%s%s" % (file_root, get_random_string(7), file_ext)) + if max_length is None: + continue # Truncating file_root if max_length exceeded. truncation = len(name) - max_length if truncation > 0: ```
No, `max_length` shouldn't be a required argument. I can think of multiple situations where I don't care about the maximum length.
I think a better wording would be: "Backwards compatibility for storage backends without support for `max_length` will be removed in Django 2.0."
Please remove this new line.
You can have a look at 9bf652dfd6a738fd841471f6abd71cba1b206d9f as an example of how we introduced object level permission to authentication backends.
In order to avoid breaking backward compatibility with custom storage class with overridden `get_available_name` we should only pass `max_length` if the inspected method allows it and raise a `django.utils.RemovedInDjango20Warning` if it's not the case.
This will need to be tested.
Shouldn't `w[0].message` be `w[0].category`? You could also deindent this line.
Good catch, I would also expect `**kwargs` to be listed after `*args`.
E124 closing bracket does not match visual indentation
E124 closing bracket does not match visual indentation
Move those import to the top of the file.
I'd combine these 3 lines "from django.utils import html, six, text"
when building docs: `WARNING: intersphinx identifier u'django-formtools' is not alphanumeric`
this works (need it to be a list instead of generator): ``` ignored_roots = [os.path.normpath(p) for p in (settings.MEDIA_ROOT, setting.STATIC_ROOT] ```
Would os.path.normpath() be better here? It seems to remove the trailing slash.
remove extra newline
needed? don't think any books would be deleted by this query.
remove extra newline
Please check code with flake8 as described in the patch review checklist and correct the "no newline at end of file" warning here.
I don't see the need for `TransactionTestCase` and the `atomic` context managers? (if I switch to `TestCase`, things still blow up without the fix in `flush.py`)
This seems wrong because it would only mask an issue with STATIC_ROOT not existing.
I can confirm that this doesn't fix the issue.
`for (old_field,new_field) in zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many):` makes the code in the loop simpler and removes the need for the hack.
should be `first_state`, not `project_state`, I suspect.
think this could be split at a different place for better readability
use parentheses to avoid backslashes and I would also try to keep the comprehension on a single line as breaking it up like this makes readability more difficult IMO.
``` items["imports"] += ( "..." "..." ) ```
similar to the hanging indent for messages, for string interpolation I like: ``` return "Graph: %s nodes, %s edges" % ( len(self.nodes), sum(len(x) for x in self.dependencies.values())), ) ```
I like to include a trailing comma in cases like this, so if more items are added, we don't need to modify that line again. Will make this change and commit.
I won't require it if you don't like it, but the style I prefer is ``` raise RuntimeError( "Error..." ) ``` (allows longer lines of text and less need to break the string up)
please check flake8, I believe this is a warning because the line identation isn't distinguished from the next (fix by add 4 more spaces to this line)
ticket reference doesn't seem necessary
Silenced the output. The `create_default_site` method deserves a more basic test, but there's more to it than the output, could be another ticket I guess (this one is pretty convolved as is). Here's a [sketch of a test](https://github.com/wrwrwr/django/commit/8927a52a4271ab8208783ce4c2af31814314a6c8).
We could also move `create_permissions` (plus the three private functions) to `auth/signals.py` to avoid that. If I understand the "Where should this code live?" [note](https://docs.djangoproject.com/en/dev/topics/signals/#connecting-receiver-functions) correctly that's where it should be.
don't need a trailing comma for lists of length 1 (only applies to tuple).
I don't think this change is needed. It seems to have been applied to ensure that `CallableChoiceIterator` is used on a copied `ChoiceField`, but if it were needed then the field we are copying would already have a `CallableChoiceIterator`, which we will be copying. So the `callable(value)` if statement in `_set_choices` will never happen. In any case, it would be much nicer to write this as `result.choices = ...` rather than manually using the property.
No input; the diff matches my (vague) memories of looking at this earlier.
@vanschelven or @expleo -- any input on this issue? Seems you two may have looked into it a bit from your previous work on the patch.
You shouldn't have a `u` prefix here
I don't think this test is sufficient. Having the first element in the output is quite likely. I'd check for the html or at least for `John` and `Paul`
is the helper method a stylistic change only? makes review difficult.
I wouldn't move it to a helper method, at least not as part of this commit.
Can you reference the ticket number in the docstring, please.
Can you reference the ticket number in the docstring, please.
Can you add a period at the end, please.
you can remove ticket reference
``` py self.assertRaisesMessage( ImproperlyConfigured, '...', ) ```
you can remove ticket reference
``` py self.assertRaisesMessage( ImproperlyConfigured, '...', ) ```
I am just going to make this docstring a bit more descriptive.
trailing comma please
reason for not
This -> These
include trailing comma please
By the way, if the patch in issue 22775 is accepted, it can also go into 3.4.
I don't think `Context` or `Template` (as for views) are good examples for meta data on a model. And I can't think of a use-case right now. Is it possible to render everything after the first "line" (summary) as body? That would probably make more sense.
Can you use `assertContains()` here to prevent errors due to attribute order in the HTML tags.
Well, the lines below it no longer have %s in them, so yes - remove it.
Same here, can you use `assertContains()` here to prevent errors due to attribute order in the HTML tags.
You might care to reformat these function calls to use the normal 4 space hanging indent style.
FWIW, I submitted several patches to isort and the author was very responsive. I just didn't care enough about this one to fix it.
I'm afraid isort insists on the backslash version
comma before "and"
`HTMLParser.error` is removed too. You may want to add an `error` method to `html_parser.HTMLParser`.
space after #
But now the imports aren't alphabetized anymore... :)
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
bounds_order (plural? reads funny to me since one bound cannot be ordered)
check flake8 ("missing whitespace around operator" here)
If we could assert it's None or the large value, that seems slightly better. Otherwise, LGTM.
You don't need `.lower()` here. It's already lowercase from within `reload_model()`.
Neither do you need `lower()` here.
For the sake of consistency, can we convert `model_name` to lower in here. All occurrences are calling `.lower()` explicitly.
You don't need the `lower()` here.
Yes, this should be taken care of before.
This line and the line above can be simplified to `return found_create_migration, after_state`
I don't think we need an explicit `if` here. `_pending_lookups` is `{}` by default and thus the for-loop body isn't run anyways.
I'd put the trailing `}` in a new line.
You're calling `model_name.lower()` twice in most cases
Wouldn't the following work here: ``` python except MiddlewareNotUsed: if settings.DEBUG: logger.warning('MiddlewareNotUsed: %r', middleware_path, exc_info=True) ```
IMO it would be better to use `logger.debug`.
Use RequestFactory? (the existing tests probably pre-date it)
I would make separate test classes for each data set e.g. the two tests that use cars can be a separate class with setUpTestData limited to creating the two cars.
beautiful, assuming it works
Do we need the base class? I would have skipped it.
Not the greatest variable name...
And use `work_file` here.
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
You can avoid `thefile` by adding here: ``` work_file = orig_file ```
You can safely join this an the next line. You have up to 119 chars per line. ;)
You can safely join this an the next line. You have up to 119 chars per line. ;)
Can you add something like "Skipping optimization" here, please
Great, I just change this line to check the message in calls rather than simply its length.
I think the issue is simple enough that we can omit the docstring.
Still looks bad to me; maybe the force push didn't work. CI should rebuild force pushes.
There's a tab on this line that crashes CI on Py3.
no need for this import
unittest.mock isn't available in Python < 3.3. see ticket #23289
It's probably better to move the new kwargs to the end, as some people might depend on the ordering...
You should be able to use `self.assertInHTML()` which is defined on `django.test.testcases.SimpleTestCase`.
Same as above: try using `assertInHTML()` to make the test deterministic.
I included the `any()` call to prevent problems with `RenameField` operations that that involve a field that's in an `foo_together`. Turns out, the `RenameField` handles the state changes itself. No need to check for it here.
Can you use `self.assertNumberMigrations()`, `self.assertOperationTypes()` and `self.assertOperationAttributes()` instead of things like `self.assertEqual(first_action.__class__.__name__, "AlterUniqueTogether")`, please. Have a look through at the top of the test case on which arguments they expect and how they work. They are also heavily used all over the place in the autodetector tests. (A overall cleanup is in #3564.)
I'd probably keep those lines unwrapped. Maximum line length is at 119 chars.
This sounds a little formal, cold and computery. "Password reset sent" is possibly misleading, I'm not sure what would be better wording.
a one -> one
Maybe you can extract the test code from the Py3ExceptionReporterTests and skip importing the "actual test code" if six.PY3 is False? ``` python class Py3ExceptionReporterTests(TestCase): rf = RequestFactory() @unittest.skipIf(not six.PY3, "Python 3 only test") def test_reporting_of_nested_exceptions(self): from other_module import do_actual_testing do_actual_testing(self.rf) ```
It's usually best to do cleanup changes in a separate commit or pull request. I recommend only touching the imports you need to for now.
This string is unclear to me. Maybe say something like this? Reverse should reorder tests while maintaining the grouping specified by `DiscoverRunner.reorder_by`.
dependency graph (no dash) I think you mean "intra-app" rather than "in-app"
use dict comprehension: `{op: set() for op in ops}` (although maybe you could use defaultdict too)
I'd keep this on one line for better readability
use { } set comprehension as in b2aad7b836bfde012756cca69291c14d2fdbd334
I'd rather not drop the concrete creation of two instances here to false positive test cases. The operations when running migrate will create new fields and as such are different instances. (This applies for all the test cases).
I'd like to keep the deconstruct implementation here and add a deprecation warning for deprecated in 1.8 and removed in 2.0. This would then follow the regular deprecation path but keeps backwards compatibility. (keep `__new__`, `__eq__` and `__ne__` methods around as well) You might also need to touch the operations in `django.contrib.postgres.operations`.
Can you check for `is not None` here, please. At least on SQLite an empty string is a suitable way to be passed to `reverse_sql` to give `RunSQL` a noop backwards migration. (PostgreSQL fails with `django.db.utils.ProgrammingError: can't execute an empty query`)
There are some references to `_constructor_args` left in the `Operation.__repr__()` and `Operation.describe()` methods.
I think you could write `self.program_options.append('-f')` here. This way you won't need to add a new parameter to `compile_messages`.
You can remove `extra_args=[]` now, thanks!
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
Oh, I'm very sorry to only see this now, but you should also use ugettext, instead of gettext (which works on bytestrings in Python 2).
Please use force_text instead of smart_text. smart_text is only useful when you want to preserve the lazy status of a string.
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
Might help to be explicit here: django.template.loaders.base.Loader
I see you've simply moved this, but I'd cleanup "template source loader" -> "template loader" to use consistent terminology.
I'd order "django.utils import (X)" stuff before any `django.utils.(foo)`
I think a docstrings explaining what `prefix_gen` generates would be good.
I'd avoid passing `ascii_uppercase` as an argument here and just use the sequence in the `prefix_gen` method.
I feel worried about keeping a `while True` loop here. I will lead to an infinite test run if the implementation of the code to be tested is broken. Can you change that into a for loop. You are already counting `i` upwards, but aren't using it.
I may be missing something, but it seems this line could be bumped out one indent - no point in re-setting `prefix` to None on every product, when it won't be used again until the next outer (count) loop.
Are there situations in which this can happen other than "too many subqueries"? If not, I'd suggest an error message that might be more helpful to the end user would be "Maximum recursion depth exceeded: too many subqueries."
We prefer test names (and docstrings if more detail is needed) that describe the specific condition / situation the test is checking, rather than a reference to the ticket number, which requires more work to dereference when reading the code. (If needed, the ticket number is always available via the commit message).
I'd write this loop as ``` for pos, prefix in enumerate(prefix_gen()): if prefix not in self.subq_aliases: self.alias_prefix = prefix break if pos > local_recursion limit: raise Runtime... ```
`infinite`, not `inifinite` (no `i` before the `f`)
`context.exception.message` -> `six.text_type(context.exception)`
The tests fail on Python 3: ``` python Traceback (most recent call last): File ".../tests/queries/tests.py", line 391, in test_avoid_inifinite_loop_on_too_many_subqueries context.exception.message, AttributeError: 'RuntimeError' object has no attribute 'message' ``` http://djangoci.com/job/django-pull-requests/1656/
You can maybe remove the `i` here: ``` python for _ in xrange(20): x = Tag.objects.filter(pk__in=x) ```
I think the plan should be `[a4, b2, a2, a3]`, effectively switching `a4` and `b2`. In other words, working on the app itself as long as possible before touching other apps that refer to this.
This isn't really a state you can end up with, because you have two leaf nodes in one app. `manage.py migrate` will not work: https://github.com/django/django/blob/master/django/core/management/commands/migrate.py#L78
Use consistent docstring style with rest of file? ``` """ Text """ ```
The apostrophe after "to" seems to be a typo to me (maybe even the entire "to'" should be removed, I don't really understand the sentence).
include trailing comma on this line so if more items are added later, we don't need to modify it again
Best to make it a separate commit for clarity.
Can't this case be handled by calling related model's meta.get_field(link_field_name)? If that is the case, then the `for field in self.through._meta.fields` loop would be much simplified.
Nitpicking, but I'm not sure the "Defaults to False" is really useful here. That's a bit implied by the option's presence.
You don't need a context manager here anymore (handled inside of `unapply_operations()`. Can you additionally check for the state changes after rename (see lines 417 ff on how to do that).
This is really a separate fix, but I guess we can do them in the same PR.
`self.timezone.tzname(self.data)` only raises an exception under pytz, right? In that case, we should have an ImportError-guarded import of `AmbiguousTimeError`, replacing it with a custom exception class (that nothing will ever raise) if it can't be imported. That way if pytz is installed, this will catch `AmbiguousTimeError` only, and if pytz is not installed, this will never catch anything.
I guess the count aggregation passes in `['count']` as `aggregate_names`. I think some explanation in the docstring of what the `aggregate_names` argument is for. It seems to have the effect of reducing the number of cases in which a subquery is needed, but I don't really fully understand why that should be the case.
Oh, of course, sorry. Totally missed the loop somehow. Ignore this, I think it's fine as-is.
I find the way you've written it quite understandable. No suggested improvements come to mind.
Where is it taken care of that a `Ref` will already exist in the inner query? Might be nice to have that information here.
``` py self.assertIs(type(f.__repr__()), str) ```
I'd move all `django.utils.encoding` import to one line.
Use of the mixin isn't ideal here since there a lot of unrelated tests which aren't affected. If we have some other deprecation that affects these tests, we might miss updating them.
missing trailing comma
What's the rationale for defaulting charset to 'us-ascii'? Given the way the default is calculated in cpython, it seems like this could result in a behavior change when we remove `SafeMIMEText.__init__()` when our workarounds are no longer needed.
That link appears to be Python 2.7, correct? Python 3.3+ looks to behave differently.
I think @chicheng means doing the equivalent of: cache.get_or_set('some-timestamp-key', datetime.datetime.now)
`self.assertRaisesMessage()` (if all sublcasses inherit from Django's test case)
Shouldn't django allow lazy-evaluation function as default value? (Calculate the default value as needed)
django-admin.py is now installed as django-admin so I changed it here.
this would fix https://code.djangoproject.com/ticket/23912 too
this should use `django.utils.six` as imported at the top of this file
This should be `WXXX` instead of `EXXX` since it's a Warning, not an Error.
I'd move `if self.max_length` into `_check_max_length_warning()` I think check should accept `**kwargs` but there seems no need to pass them on to `_check_max_length_warning`.
Correct, warnings and errors are collected together.
It looks like we should call super() here as the other fields do.
@tchaumeny reverted fa534b9 here.
I mean the revert.
You can remove this docstring.
Yes, I would open a new PR(and probably a ticket too) unless there is a reason I don't know about it. In any case, I don't think using `assert`s is a good idea. Try the following code with and without the `-O` option for example: ``` py from django.core.mail.message import EmailMessage email = EmailMessage( 'Subject', 'Content', 'from@example.com', 'to@example.com') print(email.message()) ``` Without the `-O` option: ``` sh $ DJANGO_SETTINGS_MODULE="wakefield.settings" python x.py Traceback (most recent call last): File "x.py", line 6, in <module> 'to@example.com') File "/home/berker/hacking/django/django/core/mail/message.py", line 227, in __init__ assert not isinstance(to, six.string_types), '"to" argument must be a list or tuple' AssertionError: "to" argument must be a list or tuple ``` With the `-O` option: ``` sh $ DJANGO_SETTINGS_MODULE="wakefield.settings" python -O x.py From nobody Wed Nov 26 18:30:08 2014 MIME-Version: 1.0 Content-Type: text/plain; charset="utf-8" Content-Transfer-Encoding: 7bit Subject: Subject From: from@example.com To: t, o, @, e, x, a, m, p, l, e, ., c, o, m Date: Wed, 26 Nov 2014 18:30:08 -0000 Message-ID: <20141126183008.1632.71698@rama> Content ```
You could remove `record=True` here too.
I'd use `warnings.simplefilter("ignore")` here since you want to silence the warning.
I'd change this check with `not isinstance(to, (list, tuple))`. You can pass a `set()`(and almost any iterable except a string) to `EmailMessage` with using the current check.
The common CPython message format for `TypeError` is `'to' argument must be a list or tuple, not 'foo'`.
IMO it's unpythonic to type check any more strictly than necessary. I would definitely not require this argument to be a list or tuple, when any iterable should work.
It would be great to keep the API simple and consistent with the Python standard library and the ecosystem. So, `not isinstance(to, (list, tuple))` would be enough in my opinion.
please use assertRaisesMessage to be sure the TypeError is the one we expect.
can omit these two newlines
can we isolate this test? it fails without running test_cache03 first: `./runtests.py template_tests.syntax_tests.test_cache.CacheTagTests.test_cache04` I guess other tests here have the same issue.
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
no parens needed
preferred format: "#12554 - Make sure ..."
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I'd omit the blank line after the docstring as you've done in most places.
`>` appears to be a typo
unicode -> str (Python 3, first)
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
wrap docstrings at 80 chars
`from django.utils.six import range` for consistent testing on py2/3 (or `list(range(5))` to test what's being tested on py2 now).
It seems we can probably move deprecation warning handling to the actual test cases now. We can make it a follow-up item after merging the first version of this if you like.
I wouldn't have changed the ones where the test doesn't care either way what type of redirect is done (of course we'll have to go back to silencing those)
why is this method needed? It seems redundant since `View.as_view()` calls `__init__()`.
Thank-you for the explanation. I'd guess the warning it `__init__` is probably not needed for most use cases, but it doesn't hurt and is only for 1 version. We can keep all the `permanent=True` stuff to silence warnings for now and remove them in 1.9. I'll add a TODO so we don't forget.
As long as there is only 1 test method I'm not sure we really need all the extra variables, setUp method, etc. It makes things look more complex than they are.
I would consider: `def get_backends(tuples=False)` to simplify a bit and avoid the need for an extra loop in the new `get_backends()`
#23925 - The backend path added to the session should be the same one as defined ...
could you please rebase your branch and use the new [setUpTestData()](https://docs.djangoproject.com/en/dev/topics/testing/tools/#django.test.TestCase.setUpTestData) method.
chop newline for consistency
Shouldn't we use `as_postgresql` here to make sure a `NotImplementedError` is raised on backend with a missing implementation. Also you should replace `qn` by `compiler`.
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
preferred format is "#15346, #15573 - Issue description"
This looks good, but I think we need to "cleanup" after the test and restore `Database.__version__` to its original value. I am thinking we can use `mock.patch` for this once https://github.com/django/django/pull/3649 is merged. The following worked for me after I rebased your branch on the mock PR: ``` diff diff --git a/tests/backends/tests.py b/tests/backends/tests.py index 2d6fba6..cf3e22a 100644 --- a/tests/backends/tests.py +++ b/tests/backends/tests.py @@ -22,7 +22,7 @@ from django.db.backends.utils import format_number, CursorWrapper from django.db.models import Sum, Avg, Variance, StdDev from django.db.models.sql.constants import CURSOR from django.db.utils import ConnectionHandler -from django.test import (TestCase, TransactionTestCase, override_settings, +from django.test import (TestCase, TransactionTestCase, mock, override_settings, skipUnlessDBFeature, skipIfDBFeature) from django.test.utils import str_prefix, IgnoreAllDeprecationWarningsMixin from django.utils import six @@ -247,15 +247,15 @@ class PostgreSQLTests(TestCase): self.assertIn('::text', do.lookup_cast(lookup)) def test_correct_extraction_psycopg2_version(self): - from django.db.backends.postgresql_psycopg2.base import Database, DatabaseWrapper + from django.db.backends.postgresql_psycopg2.base import DatabaseWrapper - only_digit_version = '2.6.9' - Database.__version__ = only_digit_version - self.assertEqual(DatabaseWrapper.psycopg2_version.__get__(self), (2, 6, 9)) + version_path = 'django.db.backends.postgresql_psycopg2.base.Database.__version__' - version_with_non_digits = '2.5.dev0' - Database.__version__ = version_with_non_digits - self.assertEqual(DatabaseWrapper.psycopg2_version.__get__(self), (2, 5)) + with mock.patch(version_path, '2.6.9'): + self.assertEqual(DatabaseWrapper.psycopg2_version.__get__(self), (2, 6, 9)) + + with mock.patch(version_path, '2.5.dev0'): + self.assertEqual(DatabaseWrapper.psycopg2_version.__get__(self), (2, 5)) class DateQuotingTest(TestCase): ```
FWIW I don't think that's quite accurate - a third-party project could support a Python-3-only version of Django, but itself also still support earlier Django versions, and Python 2. (That said, I think the convenience import is still the right thing to do.)
I understand your concern and I'm not convinced either. Maybe the decision would be easier to take after evaluating the probable number of uses of mock.
This will raise an `AttributeError` on Python 3.3+ since `unittest.mock` is a submodule: ``` py $ python3.4 Python 3.4.1 (default, Jul 11 2014, 12:38:25) [GCC 4.6.3] on linux Type "help", "copyright", "credits" or "license" for more information. >>> import unittest >>> unittest.mock Traceback (most recent call last): File "<stdin>", line 1, in <module> AttributeError: 'module' object has no attribute 'mock' >>> import unittest.mock >>> ```
I think you want: `'{0:f}'.format(d)`
Please check flake8. This should be: ``` py fields.update(self.fields) # add [...] ```
``` py if field_order is None: return ```
I think we should raise an exception if `key` is not in `self.fields`.
Missing asserts here? Also, please split the test into smaller parts.
Sorry, I was referring to the `# If necessary, rearrange by field_order.` line, not the docstring.
Would it be enough to check `form.fields`? This might make the test a bit easier to follow instead of having to parse the HTML to see what's expected..
Seems ok to me.
seems like this could be a separate test
please include trailing comma on multiline kwargs so if more are added later, we don't need to edit the last line again
You can now rebase your branch and change this to `setUpTestData` (classmethod).
``=`` -> '=' ``==`` -> '=='
You could just use `django.utils.encoding.smart_text` here.
I think this is the problematic line since str on Python 2 returns bytes while on Python 3 it returns unicode. It should be force_str or force_text I believe
Why is the middleware check here? It seems to me that `AUTH_VERIFY_SESSION = False` should be deprecated regardless of whether you have the middleware in your settings or not.
You'll probably need to skip this test on Python 3.2, too.
Very clever! I figured we were going to have to do something uglier to get at the list of default middlewares, but this works well, and as long as it runs on at least one supported Python version it should alert us to an issue; headers shouldn't ever vary between Python versions.
Why is `Vary: Cookie` in this list? Doesn't that contradict the stated goal of the test? (I realize that it won't pass without that, until #3672 is merged).
`get_random_string()` will never allow you to connect to the same memory database instance. You can probably use `self.connection.alias` for that so each database alias has it's own unique memory database. This also allows it to work with `threading.local`.
We support (and transparently use instead of the stdlib one) external installations of pysqlite. So I'd change this kind of checks to verify the version of the underlying sqlite3 is >= 3.7.13.
Missing `cls.cls_atomics` argument.
Can we move this conditional out of the loop? (I see it was copied from `_fixture_setup`.
nitpicking: could you swap these two checks: `old_default != new_default and not self.skip_default(new_field)`
(That is, the already-existing "upgrade considerations" section.)
Actually, wouldn't it be technically possible to make dynamic `from_queryset` managers directly reconstructable using a similar technique as you used for `as_manager`? As long as the base manager class and queryset class are stored somewhere, you could save both of them and use them both to reconstruct.
Oh, I guess that would only work if you used the `class_name` argument, and matched it to the name you assign it to. Still, I think the error message might be more clear and accurate if it said "Managers created dynamically using `from_queryset` must be importable: inherit from them or assign them to a module-level name." or similar.
Yes, I had checked on master, which doesn't make sense. I get the same result on this branch.
Oops, sorry, failed to account for the possibility that you added the `__eq__` method later in this PR :-)
I feel like there should be some dependencies declared on the operation here - the one that comes to mind is that it should depend on creation of its model, and delete model should depend on it.
Ah, sorry, you're rolling it into the create/delete operations rather than optimising it in, my bad. It's fine then!
I changed `objects` to `foo` here and all the migrations tests still passed, so I think there may be another test needed.
For geometries, the data-source is different from a Geometry instance, as a data-source represents a list/table of geometries and attributes. This difference does not exist for rasters, the data source _is_ the raster. Thats why I named this class GDALRaster, as I suppose that is the more intuitive name. Did you have a second class in mind for the actual raster? If not, all rasters will be instances of RasterSource, which I think is not ideal.
The projection of this raster is `3086`, somehow the `WKT` version of the GDAL info does not have the number in it explicitly. I can update the raster such that the srs gets the correct srid from it (in my experience, from the WKT version is not always very clear what srid it really is depending on what software the raster was generated and how).
I updated the file on my branch such that the wkt contains the correct information. `ds.srs.srid` returns `3086` https://github.com/geodesign/django/blob/raster/django/contrib/gis/gdal/tests/data/raster.tif
This should probably be updated with the new gdalinfo, which basically includes one more line in the coordinate system: `AUTHORITY["EPSG","3086"]]`
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
This isn't a valid `CharField`. Could you please add a `max_length` attribute.
``` py # #23405 - ... ```
You can drop `\`. ``` py if (not field.null and not field.has_default() and not isinstance(field, models.ManyToManyField) and not is_no_default_allowed): ```
This isn't a valid `CharField`. Could you please add a `max_length` attribute.
Nitpicking: I don't like the indention here. I'd probably go with: ``` python if (not field.null and not field.has_default() and not isinstance(field, models.ManyToManyField) and not (field.blank and field.empty_strings_allowed)): field = field.clone() ``` The cryptography project uses: ``` python if ( not field.null and not field.has_default() and not isinstance(field, models.ManyToManyField) and not (field.blank and field.empty_strings_allowed) ): field = field.clone() ```
or use dict comprehension: ``` py {color_names[x]: '3%s' % x for x in range(8)} ```
You can use a dict comprehension here, too.
Having a `[` followed by a `(` on the next line makes the code a bit move difficult to read and the performance benefit is absolutely negligible here as the result is cached.
Would options.extend() work here (and below)? I think that would be more readable.
again, extend() might be better
might as well make these dict comprehensions (and in the next two files)
Please leave the blank line here, it's imo more readable.
reuse initial here and don't call to_python twice
Why not do: ``` if key not in self: self[key] = value ```
You can brake the docstring into two lines.
Remove spaces (also in the test): ``` py """Sets a default [...]""" ```
+1, but taking verbosity into account.
It would be good to show a warning message here.
Needs a rebase (these files are now alway included as of 28e8c54d7d2800a8ac98cf646a9e074055bc1b1b).
Good point, that might the reason. I'm fine with zeroing existing rows then. I opened another ticket to keep track of that feature: [#23996](https://code.djangoproject.com/ticket/23996)
Could you add two `Rider`s here and check both of them for `0` in `_order` below.
I think we should set an initial ordering (​https://github.com/django/django/blob/aa5ef0d4fc67a95ac2a5103810d0c87d8c547bac/django/db/models/base.py#L1624-L1633) . Otherwise upcoming saves will start to be ordered, while old data isn't. The ordering of the existing data should be done by the default ordering of the referenced model (model._meta.ordering)
Imports should be alphabetized. I would just import `make_aware`, but that's a matter of taste, I think :)
Indeed, simply setting get_default_timezone() like this doesn't work for pytz timezones that have DST.
You don't need to specify a value for `timezone` in master.
Could you change that to `#24017 - Tests string representation`
I'd use `*args, **kwargs` for arguments that are simply passed-on without being accessed or modified, to reduce the number of places that a change in signature would need to be reflected, and to avoid having to repeat the same default values. We've had issues in the past in Django (in forms/formsets, IIRC) where the default value for some parameter to a superclass method changed, or a new optional argument was added, but nobody remembered to update subclass method signatures accordingly, causing bugs.
My idea of converters is that backend converters are applied to convert the data to uniform format, then the field converters change that format to the wanted Python object representation. So, in this case, if the bug can't be fixed, then we need to add a backend converter. Doing that for Concat expression would be much better than doing it on all TextFields, but of course before we pass the expressions instead of internal_type to backend's get_db_converters that can't be done. Maybe it is possible to add a cast on SQL level to Concat on MySQL, something like "CAST(Concat('foo', 'bar') AS CHAR)". It might be that if the datatype of Concat expression is incorrect on SQL level, then further operations on the value (say lower()) will not work correctly.
The problem is MySQL. You can use "--column-type-info" for mysql command line client to see that the return type of the expression is blob. Of course, this being MySQL adding a CAST as char in there doesn't actually do anything. The return type is still blob. You can use "cast(concat(a, b) as char(10000) character set utf8)" to get a real cast as VAR_STRING, but you'll have to supply the length, too. And, this being MySQL you'll get silent truncate of data if the length is too short...
I just checked and Postgres/MySQL support that but SQLite doesn't... so I guess you're right, it's better this way.
The SQL function `COALESCE` can be called with a single argument (at least on PostgreSQL). That might not be useful, still I believe Django shouldn't prevent this.
Is this check correct? A `Coalesce` can still result in a null value (if all of its arguments are null), so even if the expression is already a `Coalesce` ISTM it needs to be wrapped again (or have `Value('')` added to the end of its `source_expressions`, but just wrapping in another `Coalesce` seems cleaner).
Won't this result in a confusing SQL-level error if you pass in `None` for `expression` or `pos` by accident? I'm assuming `length` is the only one we actually expect to possibly be `None`. If that's true, I think it would be better to do something like: ``` expressions = [expression, pos] if length is not None: expressions.append(length) ``` Or, if you prefer: `expressions = (expression, pos, length) if length is not None else (expression, pos)`
Ah! Of course, sorry I missed that.
Add a custom converter only for MySQL + Concat combination in Concat.get_db_converters()? I believe we are doing the wrong thing for expression converters. We should specialize more (that is, if some aggregate needs custom converters, then add custom converters for that aggregate only instead of for all expressions), and we should also pass the expression instead of the internal_type to backend.get_db_converters. I am going to change the signature of backend.get_db_converters() so that it gets expression instead of internal_type as input parameter.
This needs to be named `related` for it to work.
I don't have strong feelings about this. One possibility is to remove this, and if we get complaints about the removal during alpha or beta we can reintroduce it back. Another approach is to check how hard it is to write code that works both in 1.7 and 1.8 for those cases that use RelatedObject.
Might this be a good place for a longer docstring explaining which modules are part of the multiple-template-engines system, and which are part of the DTL? The fact that these two are mixed up together in `django.template` remains one of my larger concerns with this PR. I don't see a better solution, but it seems likely to result in future bad patches due to a developer misunderstanding whether they are dealing with a generic API or a DTL API, so anything we can do to clarify would probably be good.
``` py with warnings.catch_warnings(): ```
To make it less general, `message="Overriding setting DATABASES can lead to unexpected behavior"` can be passed here.
Could you add a check for `options` here the same way as below.
Could you add an `assetNumberMigrations` before the `assertOperationTypes` and join the `assertOperationAttribute` checks; they take `**kwargs`.
Yes thanks for the answer!
Please use `assertRaisesMessage`.
get_or_create -> get_or_create(). The exception message can be much simpler in my opinion. Also, if `len(lookup_parameters)` is 1, then the "Wrong parameters:" part is should be "Wrong parameter:" .
Same as above (use `assertIs` instead).
I'd use `assertIs` here.
Remove one of these blank lines (should only be two total). (`tests/file_storage/tests.py:454:1: E303 too many blank lines (3)`)
`django/core/files/copy.py:28:37: E127 continuation line over-indented for visual indent` pep8 wants you to indent it like this: ``` fd = os.open(new_file_name, os.O_WRONLY | os.O_CREAT | getattr(os, 'O_BINARY', 0) | (not allow_overwrite and os.O_EXCL or 0)) ```
`E226 missing whitespace around arithmetic operator`
I think this will create a new connection if the alias hasn't been used yet. What about: ``` python for alias in connections: try: connection = getattr(connections._connections, alias) except AttributeError: continue connection.close() ```
Yeah hiding it in `ConnectionHandler` would make more sense.
Could you wrap this line after the comma.
(To make the implication explicit: if not, perhaps this method shouldn't have `case` in its name.)
If the only use of for_save is in here, we could just have it as an attribute of the compiler. (Insert/UpdateCompiler has a class-level attribute for_save=True, other compilers have it as False)
If you have time, we also try to include on trailing comma on the last kwarg so if more items are added later, we don't have to modify that line again.
since the brackets on their own lines add whitespace, I think you could omit the blank line between queries/assertions in most cases to make this file a bit shorter.
I definitely do think we should at least try introducing the cast_sql method as described here. The argument types would be Field instances (and the names should likely be changed to input_field and output_field for consitency of Expression.output_field).
It seems this method will not allow for 3rd party fields to define their own rules. This might be OK for a first cut, but we might later on want to have something better. I wonder if we could just have a cast_sql with the following API: ``` def cast_sql(self, input_type, output_type): """ Returns a cast expression from input_type to output_type. For example, if input_type is INTEGER and output_type is FLOAT, then returns CAST(%s AS FLOAT) for PostgreSQL. The return string must have %s placeholder. This will be filled with the input expression, which is of type input_type. """ ```
This check of for_save could be added to the place where resolve_expression is called in the compiler (first call resolve_expression, then check if resolved.contains_aggregate -> FAIL).
move ) to next line for consistency
If you assign the default as `Value(None)`, then you shouldn't need to conditionally add `self.default` in get/set_source_expressions. It should just convert to NULL sql string.
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
I noted this too and wasn't sure if it was an error or not. Can you 'save' an aggregate? ``` Model.objects.update(salary=Max('salary')) # would this work? ```
Instead of passing in `db_type` and `internal_type`, I would suggest just passing the field and the connection. That way, the method can extract the pieces of information it needs, which may be different for different backends.
This test should include updating a decimal field that includes decimal points: ``` Value(Decimal("1.1")) ```
Michal and I discussed this on IRC and I don't think such a generic function is going to help here. This is a very narrow use case (implicit casting isn't working for certain fields in case expressions), and it needs to be special cased for certain fields. This isn't an Integer->Float kind of situation. I'm happy enough with the method to stay. If we can generalise later then that will be OK, but I don't want this to hold up the merge.
clarify: "model field"
We need to keep an alias for backwards compatibility.
likewise, should keep it here
I'd move the exception above or below ObjectDoesNotExist
The import can be moved to the top.
Is new code needed? The sense of error is the same, I think you should use `fields.E003` here too.
You are not using `removed_for_migrations.get('message')` as a primary source here.
Can we wrap this line after the comma.
Good point. Using `None` seems to make more sense, now that the variables hold more information than just yes/no.
Could you rename the field to `RemovedField` given the test case name.
Makes sense. Lets go with `MyField` then.
So, values of deprecated_for_migrations can be True, False and dict, right? I think this is a bit complicated. I'd set the default value to None and only accept a dict.
I'm still unsure if the names are good, but I don't have an idea for better ones.
seems like we could use `super()` instead.
Oh, didn't see that. Well this is fine for now. I think refactorings could be done later.
Nitpick but we try to alphabetize these as we go.
I'd use `assertIsNone`
You can use `self.assertIsNotNone(req2)` I think.
no newline between fields (see style of other forms) Also, I don't think `label` and `initial` need to be specified. Try to include only the minimum functionality that's needed to reproduce the error and prove the regression is fixed.
Similarly, could this be an empty string to simply (please simplify other values if possible as well).
I think the test name is good enough, so I'd remove the docstring or replace it with a more informational one.
Same here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom</p>\n' 'rest of the HTML' ) ```
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
You don't need to use `"""..."""` here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom' '<input id="id_hidden1" name="hidden1" type="hidden" />' '<input id="id_hidden2" name="hidden2" type="hidden" /></p>' ) ```
Please move `)` to a new line: ``` py return self._html_output( normal_row='<p%(html_class_attr)s>%(field)s %(field_name)s</p>', error_row='%s', row_ender='</p>', ) ```
You had a `if not model and not hints` here before. Any reason why this is gone? The only thing I can think of, routers have to take care of `model=None` anyways, so this "precaution" isn't necessary anymore.
Maybe add a note that we are deliberately not deconstructing `hints` here because we don't auto-generate the operations? Otherwise somebody is getting confused at some point. (Same for `RunPython`)
It may be useful to remind the reader here that `update()` returns the number of rows matched, not the number updated. (actually, it may make better sense to just drop the assertion. The next assert really checks everything).
`self.assertTrue(books and all(book.no_value is None for book in books))`
Wonder if it might be worth to also specify the `app_label` for clarity here. ``` python "The verbose_name of %s.%s is longer than %s characters" % ( perm.content_type.app_label, perm.content_type.model, verbose_name_max_length, ) ```
Won't that create an unbound method on PY2? IMO we should just use `def` with `@staticmethod`.
I think I'd favor `noop` directly at this level rather than supporting `noop` within the list. So `sql=('', ('something', 'something')` triggers an error rather than just skipping as no-op.
Actually maybe not, I had `noop == function` in mind but that's for `RunPython`.
Could you use `assertRaisesMessage()` here.
It might not be feasible since the message will be different for each database. This technique seems to be copied from other tests.
I prefer the bracket on the next line so you needn't move it when adding more items
Oops, right. That's a pity.
I think we need to rename CombinableMixin, or just stuff the asc() and desc() methods in the current CombinableMixin. The reason is that if I want to do some other wrapper expression than F() (say, SumIf that returns Sum(Case(When(...))) from resolve_expression, then I need to subclass CombinableMixin, and also add asc() and desc() methods. It would be better if we could just subclass CombinableMixin and write resolve_expression. (Another case of needed methods is refs_aggregate() which we should be able to remove once where/having split is done in the compiling stage) I think we can still do this during alpha if this change is wanted.
think these newlines can be omitted -- a parens on its own line adds spacing.
I wonder what is the use case of Resolvable that doesn't implement Combinable (btw should we just rename CombinableMixin to Combinable independent of other needed changes?) I don't object making F an Expression subclass, but even in that case I think F shouldn't resolve to F-instance. So, resolve_expression would still work as it does now.
Not needed for this PR, but we could likely change the logic so that mysql returns an expression instead.
`default=uuid.uuid4,` is generally the correct way to set the default for a uuid field. It will get called automatically whenever a new instance is created.
imports must be in alphabetical order
Do you checked if there is a way to use other models? It will be good to inherit one and add only needed field that reproduces your changes
No need to have empty lines, see the code above
You can inherit `AbstractUser`, where are all these fields, and only add the `id` field. It will be generated only if you will not specify it, but if you add it explicitly, it will work as you need.
`uuid.uuid4` is a function, and, as understand, you want to set some random data for it, so you must call it. But I don't think that default is needed there though.
Hi, thanks for the patch. Please add a space after commas. (see PEP8). `elif not isinstance(fieldset[1]['fields'], (list, tuple)):` `return must_be('a list or tuple', option=label, obj=cls, id='admin.E008')`
Why did you change this line? It looks unnecessary to me.
If I'm reading the code correctly, `fieldsets[0]` is a tuple. Perhaps the error message should be `"The value of 'fieldsets[1]['fields']' must be a list or tuple."`
Only two empty lines required. You can run `flake8` on source to spot these kind of warnings.
could you use the same doc string style as above? ``` """ ... """ ``` Also should be "Transforms... " to match coding style guidelines.
per the code updates, I think this should be `{field_name: (field_name_other_table, ...}`
`unittest._TextTestResult` is deprecated. You can use `unittest.TextTestResult` directly.
You can join this line with the previous.
Unrelated, but I wonder if we need '-k', '-r', '-d' for the new options rather than only their verbose counterparts. Seems like we are going to run into a conflict a some point with two options with the same first letter if we keep doing that.
You don't have to subclass `unittest.TextTestRunner` since it has `resultclass` argument. You can pass `resultclass=DebugSQLTextTestResult` without subclassing it.
use set comprehension: `{m[0] for m in plan}`
preferred style is: ``` @override_settings( INSTALLED_APPS=[ "migrations.migrations_test_apps.lookuperror_a", "....", ], ) ```
I know existing tests are bad about this, but seems like we should have "cleanup" in a finally block.
I think it's enough to reference #24100 since that's relevant to do todo: ``` # TODO: Remove when migration plan / state is passed (#24100). ```
You don't check for the conversion flag and type specifiers. But I think that's fine. Would get a bit noisy otherwise and the current approach seems unlikely to give false positives.
Could you wrap it according to PEP8. I know this style is heavily used in this file, but we should change that eventually. ``` python res = self.client.post( '/edit/author/%d/update/interpolate_redirect_nonascii/' % a.pk, {'name': 'John Doe', 'slug': 'john-doe'} ) ```
this can be 1 line (we prefer longer lines when it improves readability)
I would bring that up on django-developers.
I think that we could make use of a six moved import: `six.http_client` (https://pythonhosted.org/six/#module-six.moves)
No, it should be made consistent with other codes (capfirst or title, I haven't checked).
Perhaps we can use a similar approach for status_code and status attributes, too. Setting two different attributes to do the same job would be bad: ``` py resp = HttpResponse(status=503) resp = HttpResponse() resp.status_code = 503 ``` status_code is already used in many places, perhaps we can also add status_code to the constructor of HttpResponseBase.
It makes sense to me that you would leave it unset unless `self.reason_phase` explicitly sets it.
same issue as with obj_refs_aggregate
not aggregate is tested twice
This will subtly change existing code. First, if the queryset is already evaluated, then currently **contains** checks against the cached results. Second, when calling x in qs, the queryset doesn't get evaluated any more. My preference is to not change this unless there is large-scale support to change the behavior.
or `''.join(newurl)`. Also, you could just use it in line 86: ``` py % {'method': request.method, 'url': ''.join(newurl)} ```
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
with -> width
flake8 complains about missing spaces around `*`
`elif` might be clearer (I understand it's not necessary)
`band_input`, you don't get much by saving one char :-)
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
We try to avoid line continuation backslashes in Django, and it's not a problem to overcome the 80-chars limit when it makes readability better.
We might instead replace other instances by `self._ptr`, to convey the idea of a private and internal variable. Just a suggestion.
We are now aiming for the PEP 257 convention, that is using `Flush` instead of `Flushes`.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
no space for "Spatial Reference"? (or no caps if it's not meant to refer to the class)
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
I think `enumerate` would work here
prefer hanging indent style with 1 arg per line
I prefer putting the closing ) on the next line
prefer hanging indent style: ``` GDAL_TO_CTYPES = [ None, ... .... ] ```
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
comma after tuple
width, height, and offset
or to hold
The path needs updating (I'd use a relative one)
PEP 8 requires this blank line
I'm not sure if it's a good idea to define it in `setUp`, let's define it in the method where it is used.
Are both branches tested here? Otherwise this looks good.
Unfortunately these is an issue here! fields_map calls relation_tree, that is a cached property. If any of these two raise an exception (due to premature relation tree) or cache less information then cached_property will not work correctly.
Clarified version of what I had in mind: ``` # Helper method to provide a way to access this without caching it. # For example, admin checks run before the app cache is ready and we # need to be able to lookup fields before we cache the final result. ```
You can drop this line.
Please add an empty line above.
Your assumption here is that the order of the fields doesn't change. I think we should check for the `to` model and the `through_fields` instead.
In that case, sure.
I think this should be `old_m2m_model`.
and Python 3
3rd party imports go below django imports
this goes below `from uuid ...` -- whether it's `import` or `from ... import` doesn't affect ordering
I think `value_to_string()` might be closer to what we want -- then every time we access the value, we need to use `user._meta.pk.to_python(request.session[SESSION_KEY])` to get the value back.
Let's keep that, you're right that this doesn't cost us much.
`frozenset` is missing.
Since you're touching this line anyways, could you rewrap the import like ``` python from .base import ( a, b, c, d, e, ) ```
``` #22232 - Tests for circular extension ... ```
As no one has offered a rationale for deviating from the PEP, I'd leave it as is.
I think we might be too late to add more deprecation's to 1.8 (also missing deprecation docs).
no dash needed for "nonexistent"
I find this code a bit confusing -- where is the `FieldError` expected to be raised? `expression.input_field.output_field`? Could you use an if statement for that check rather than try/except or maybe move the code that's not expected to raise into an else block of this try/except? .Not an expert here, so maybe it's fine as is.
style guide says this should be "Checks ..."
Sounds good -- `RemovedInDjango21Warning` is now on master.
Well, this is not what PEP 257 recommends. https://www.python.org/dev/peps/pep-0257/
only need 'coding' if there are non-ascii chars in the file
Please move this to below of the docstring. ``` py def render(self, context): "Display stage -- can be called many times" # Set engine attribute here to avoid changing the signature of either # Context.__init__ or Node.render. The engine is set only on the first # call to render. Further calls e.g. for includes don't override it. context.template_name = self.name # ... ```
``` py template_name = getattr(context, "template_name", "unknown") ```
``` py logger.warning("%s - %s", template_name, e) ```
Could you also update `logger.warning` to `logger.debug`. You may want to wait for confirmation from a core developer before change it. Thanks!
"Unknown" -> "unknown"
I guess we might alphabetize `migrations, models`
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
Yea, good point.
I believe the whole else branch is non-needed. So, we need just the child.get_group_by_cols() call here.
extra newline, otherwise looks good.
Please wrap long lines for easier review: ``` self.assertHTMLEqual( f.widget.render('datetimerange', ''), '<input ...' ) ```
"whether this expression is about to be used..." (or add a question mark at the end if you prefer the "is" version)
It would be good to use `six.reraise` here.
the depth parameter is gone as of Django 1.7
The other option is to wrap the file with something like: ``` from django.core.files import File class ChunkedFile(File): DEFAULT_CHUNK_SIZE = 4096 def __iter__(self): return self.chunks() return StreamingResponse(ChunkedFile(open(fullpath, 'rb'))) ``` I considered using this wrapper for FileResponse.
I had a similar thought.
(I personally don't have any preference between the options, just wanted to throw out another idea.)
I would go with the "could" option and port `FileResponse` to 1.7 rather than change an existing (stable) class.
In the usual case for using this, it wouldn't be because "an initial migration has been applied before,", it'd be because the database pre-existed any (Django) migrations at all. Also, it's really the contents of your initial migration file that you need to compare to, not your model definitions. Suggested wording: "Detect if tables already exist and fake-apply initial migrations if so. Make sure that the current database schema matches your initial migration before using this flag!" As a bonus, this also hints at the fact that the automated check here is no more sophisticated than just checking if tables exist.
+1 "using this flag as only table names are checked" (combine the last sentence)
This is minor, but the double exclamation point feels a little overblown. I'm not sure any exclamation points are needed at all; the text should suffice.
I'd omit the blank line since it's hard to get confused in 3 lines of code. Also the commit message could describe the issue being fixed instead of the implementation of the fix.
I see before: `to_fields=[], from_fields=[self.object_id_field_name]` after: `to_fields=[object_id_field], from_fields=[]` I could very well be missing something...
I'd personally omit the newlines you've added before super (don't recall this is a pattern we've used elsewhere)
parentheses are also fine with me.
personally in favor of longer lines vs. backslashes
I think this would be more readable if they were on one line each. It's fine if they are longer than 79 characters
As Collin said, slightly longer lines are okay rather than awkward wrappings like this.
Actually, it might make sense to keep this check. It's more of a "not a string" test than a "must be a tuple". We could just say "must be a list". (even though tuples are allowed too.)
include parens after method names: get_RELATED_order()
This is probably a wrong default implementation - it doesn't take into account that the relation can be to a different model. Also, we do support multicolumn relations internally, so something that uses all relation fields would be useful. I guess this duplicates work already done in descriptors. The **get** implementations need to build filters to get the related object(s) for an instance, so we need to check that we don't have duplicate implementations.
add trailing comma
better name? `get_filter_kargs_for_object()`
I would simply say `# Hook for subclasses to run these tests with alternate models.` (details about which other classes use it may go stale)
add trailing comma
prefer hanging style: ``` return { self.fk_field: ..., } ```
`... Using multi as True` and `...imports as multi`
In general, I find boolean flag parameters that fundamentally change the operation of a function to be an API smell. (Not sure if there's a name for this principle, but it's often referred to in discussions of Python stdlib APIs.) As an alternative, I think it would be cleaner to have a separate utility function that takes either a string or a model, and returns a string, and then in the place where you'd use the `always_text` flag, wrap the call to `resolve_relation` with a call to that utility. (Yes, that's an additional function call, but we first optimize for readability and nice APIs, and then optimize for performance when we have data showing where our bottleneck is.)
Could we change this (and other similar places that check for string references) to directly call lazy_related_operation. The idea is that the calling code doesn't need to care if the reference is by string, and it doesn't need to care if the referenced model is already loaded. In all cases, it is OK to just call lazy_related_operation.
`always_text` is gone.
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
Doesn't matter, but I think if this appears in `__all__`, `NOQA` isn't needed.
You can also add a deprecation warning for usages like `from django.forms.extras.widgets import SelectDateWidget`.
This usage looks a bit magic to me, but I think it can stay as it is. The module level deprecation warnings in https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01 are different than this, so stacklevel=2 can be removed in the following locations: - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-9e264d0b47bfdd60be1698bca9bae281R19 - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-68395a4996a48dd1b3cd34ddd9efe762R12
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
No need to add `stacklevel=2` here.
module level constants should be all caps
The new import order guidelines haven't merged yet, but they call for putting try/except imports last (as isort can't parse them to order them elsewhere).
Missing trailing comma after `dictionary`.
I'd opt for longer lines for most of these `assertEqual`s (we prefer longer lines up to 119 chars when it helps readability).
prefer if you use hanging indent style for this assertion to match the other tests
This method should be made private as it does not belong on `Manager`. I think this is the source of the test failures.
I'm fine if you want to use this style in GIS, but more the rest of the code, I think a single # is sufficient.
Surely no much difference in readability and 80 doesn't look "significantly uglier"; actually I've just realized I have the margin set at 80 also ;-)
+1 for exp_{sql|param} or ann_{sql|params}.
Since you're changing this line already, maybe it's worth changing the variable names from agg_{sql,params} to something like a_sql or expression_sql.
I suggested that because `annotation_select` now contains expressions other than aggregates. But I didn't notice the method was in the AggregateCompiler, so it probably is just aggregates in that dict. Not worth worrying about I guess.
up with Django imports
I suggest to rewrite it this way: ``` python def get_lookup(self, lookup_name): lookup = { 'in': RelatedIn, 'exact': RelatedExact, 'gt': RelatedGreaterThan, 'gte': RelatedGreaterThanOrEqual, 'lt': RelatedLessThan, 'lte': RelatedLessThanOrEqual, }.get(lookup_name) if lookup: return lookup if lookup_name == 'isnull': return super(ForeignObject, self).get_lookup(lookup_name) raise TypeError('Related Field got invalid lookup: %s' % lookup_name) ```
Is there any reason not to use the normal registration process for this method, overriding the relevant lookups and removing any which are not valid? The current implementation would not allow for a third part lookup (which may be useful if there is a non standard `db_type` for example).
I'd `conditional_escape()` each argument.
Should we add some context to the message (like part of the HTML snippet) to help identify the needle? I'm a bit worried developers will have a tough time figuring out what the message means.
`with self.assertRaisesMessage('Needle HTML does not have a root element'):`
2 optional items: - TestCase could be SimpleTestCase or unittest.TestCase (but not sure it's worth the possibility that DB will be used later and not caught) - assets could probably be single lines
slightly prefer this style so lines don't have some non-multiple of 4 indent: ``` msg = ( "..." ) ```
I think you can use `with self.assertRaisesMessage` equivalently here (context manager form is much easier to read IMO)
Since you need an extra line anyway, I'd guess I'd do: ``` msg = '...' with self.assertRaisesMessage(ValidationError, msg): ```
I think you should use `self.assertIsNot()` instead.
Well, technically it is not a "deep copy".
`assertIsNot()` as well.
Since this is a bug, it will be good to have a separated test for this issue.
To save a line: "is not ready; refs ##24146."
It's the "app registry" (no 's')
to be safe: ``` try: errors = BookAdminWithListFilter.check(model=Book) finally: Book._meta.apps.ready = True ```
chop blank line
would be nicer to output some attribute of `entry` I think
this can be one line for better readability
I think this approach is too naïve. `related_model` can be a model class.
I wonder if it would be feasible to raise a warning or an exception if database queries are ran during a `SimpleTestCase`.
could you use hanging indent style instead? ``` __new__( ..., ..., ) ```
line breaking is a bit odd -- %s could fit on the previous line also, one space after period
Here's the style we usually use for long messages: ``` msg = ( '....' '....' ) with self.assertRaisesMessage(ImproperlyConfigured, msg): ```
Sorry to be picky, could you rename the test function name to something a bit more verbose? a suggestion could be: "test_exception_raised_if_model_declared_outside_app"
needs indentation here. run flake8
extra parens aren't needed
basically, if you put the `return prepared_migration_statement` in the `except:` clause it should work fine.
Anyway, good practices include: - keeping the try clause as small as possible - avoiding multiple returns Hence the correct idiom is: ``` try: import autopep8 except ImportError: pass else: prepared_migration_statement = autopep8.fix_code(prepared_migration_statement, ...) return prepared_migration_statement ```
`finally` will be executed anyway, was there `ImportError` or not, so autopep8 result will be not returned
please move this to `except` and return `autopep8` result in `try`
Interesting. I just tried it. This returns 2. ``` def func(): try: return 1 finally: return 2 ```
Can you use hanging indents here: ``` python a = b( c, d=e, ) ```
no blank line needed
no blank line needed
No, the `form_class` kwarg to `formfield()` actually means a form field class. This code is correct. (The naming is that way because in the context of `formfield()` we know we're dealing with a field, but we have two kinds of fields, database and form fields, to worry about.)
Got it. Thanks
"mapped to a form field class"
if _not_ keep_parents :)
I think this test is sufficient, no need for the other one. Can you rename it to `test_delete_keep_parents()` though.
You can drop that line since you are no initializing `self.indention` in `__init__()`.
Can you use explicit argument names here, please (`arg=[...]`)
assertRaisesRegexp is deprecated on Python 3, you use `self.assertRaisesMessage` I think
If we had to do it again, "edit" would probably make sense, but I think "change" makes sense given that terminology is used elsewhere "change view", "change permission", etc.
that's the default in 1.9, but I don't if you want to include it anyway
> ... even if nothing bind us to use the same term for url and pattern name. I know it's just it's just something I noticed. Wouldn't object `edit` being used in the end.
compatibility in Django 1.9
Is there a reason `edit` was chosen instead of `change`. It's the only pattern that differs from it's name.
Why are we not just using `connection.clear_old_columns()` here? If this is really needed, I'd consider replacing `clear_old_columns()` with a context manager: ``` py with connection.disabled_stmt_cache(): cursor.execute(...) ```
"remains coherent" is a bit undefined -- it seems you mean ensuring relations are still properly defined.
Why y, x instead of x, y? Is this from PostgreSQL's function definition. If so, OK, if not, then I think the order should be x, y.
Ok I get it, `compiler.compile(Value(5))` would return something like `'%d', (5,)`.
This as_sql method can be deleted if you remove the custom template and implement get/set_source_expressions as above.
I think we should avoid writing new test suites that use fixtures. Fixture loading is extremely slow, and it's actually harder, IMO, to follow what the data should look like once you've aggregated it. I would suggest either creating all the data in a setUp method, or creating the data you need at the top of each test.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
You don't need to change the template here as long as get/set_source_expressions reads/writes x/y in the right order. ``` def get_source_expressions(self): return self.y, self.x def set_source_expressions(self, exprs): self.y, self.x = exprs ```
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
I suggest you use [setUpTestData](https://docs.djangoproject.com/en/dev/topics/testing/tools/#django.test.TestCase.setUpTestData) instead of `setUp`.
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
The problem with this line is that further down you're referencing `self.x` and `self.y` directly. If another part of the code calls `set_source_expressions`, you're going to be using old values. You should override get/set_source_expressions to read from and assign to self.x, self.y.
I think this should be a `ValueError`
include trailing comma so if more kwargs are added, we don't need to modify this line again
base class (StatAggregate)
I think the definition for this might be clearer as: ``` def __init__(self, expression, delimiter, **extra): super(StringAgg, self).__init__(expression, delimiter=delimiter, **extra) ``` The docs already have this definition, and multiple expressions do not make sense for this aggregate. You can also ditch the kwarg processing to check for delimiter (which is inconsistent with the docs at this point).
:+1: on @charettes (thanks for the hint, didn't know this function exists :smile: )
Missing duplicate trailing underscore: `__all__`
"Both Y and X must be provided". Switch the Y and X in the error.
No need for that. `text_type` is a subset of `string_types`. Python 3: ``` python >>> six.text_type <class 'str'> >>> six.string_types (<class 'str'>,) ``` Python 2: ``` python >>> six.text_type <type 'unicode'> >>> six.string_types (<type 'basestring'>,) >>> str.__bases__ (<type 'basestring'>,) >>> unicode.__bases__ (<type 'basestring'>,) ```
I think we should include `six.text_type` to `isinstance` check too.
or ``` py except (ValueError, KeyError): return False ```
If you take it that way, go with the dict. On February 11, 2015 2:06:14 PM GMT+01:00, Lukas Klein notifications@github.com wrote: > > @@ -33,6 +33,12 @@ > > RFC3986_GENDELIMS = str(":/?#[]@") > > RFC3986_SUBDELIMS = str("!$&'()*+,;=") > > > > +PROTOCOL_TO_PORT = { > > - 'http': 80, > > - 'https': 443, > > - 'ftp': 21, > > The only protocols serving a Django site should be http and https > indeed. For the sake of performance, should we still use > `socket.getservbyname()` or can we stick with the hard-coded dict? I > mean, how often have the http and https ports changed [in the time > since Django exists]? > > --- > > Reply to this email directly or view it on GitHub: > https://github.com/django/django/pull/4108/files#r24492970
Yes, `socket.getservbyname()` works on Python 2.7.9 and 3.4.2 on Linux and at least 2.6.6 on Windows.
Can you put the tuples in variables. That makes it more readable.
socket.getservbyname() might work. https://docs.python.org/3/library/socket.html#socket.getservbyname
can you put `if not value` in the isinstance block below
I tend to prefer `self.assertRaisesMessage` as an alias for `six.assertRaisesRegex`, otherwise this change is fine with me (and to backport).
Got your point. I wouldn't use schema_editor here either.
I think we can use `if not is_protected_type(value):` here. Then the changes in the m2m tests can be reverted and this should be good to go.
You can use `self.assertIsNone` here.
I think you can combine the two tests and call it `test_durationfield_prepare_value()`. The test seems self explanatory so I don't think a docstring is needed.
You don't need the inner list comprehension: `tuple(i for i in x)` works just fine.
You don't return anything for `list`, `tuple` or `dict`. Hence, in case the tests are passing, your tests are wrong.
Replace "items" with "values"
"... items whose values deconstruct ..."
Yes, fine with me.
On my pull request #4097 I don't see the `else` executed either in Django's own test suite. The `except`, however, and the `raise ValueError()` inside is actively used. The entire for loop can practically be replaced by the same code which is used during Django's boot process: "here are a bunch of Python modules, go and find all model classes in there and register all relations".
I'd certainly be tempted to get rid of this branch, unless someone can identify a case that hits it.
An equivalent, somewhat less ugly option: Instead of the above, add a `from_db_value` method: ``` python def from_db_value(self, value, connection, context): if ((not value) and isinstance(value, six.string_types) and connection.features.interprets_empty_strings_as_nulls): return None return value ``` `super(ForeignKey, self).get_db_converters(connection)` then invokes it. But I'm really not sure that's what `from_db_value` was intended for.
Adding here these lines fixes the failures: ``` python if connection.features.interprets_empty_strings_as_nulls: self_converters.append(lambda val,*args: None if isinstance(val, six.string_types) and not val else val) ``` but this is getting uglier and uglier
to make it simpler: ``` py skipIfNonASCIIPath = unittest.skipIf(...) ```
Do we really need to skip these tests? I'd rather see them fixed.
No, your analysis is correct. In Python 2, sometimes `module.__file__` can contain absolute paths, but I don't remember the exact details and it's very unlikely.
If `django.__file__` contains non-ASCII characters, this will raise an exception. `is_ascii(force_text(django.__file__))` or catching the encoding exception in the is_ascii function would be safer approach. (This would be incorrect if `django.__file__` is a relative path, of course.)
Are you using PROXY_PARENTS as some type of flag? We already went through the "flags" path throughout the Meta API refactor and ended by removing it because it required imports. Even though this is an internal function, I would advise to find a better solution because, personally, I don't think it's good practice to have one argument that can be of different types (in this case, boolean or object) as it increases the risk of bugs, and it also can be confusing to other people. But that's just me.
a OrderedSet, like @timgraham suggested
I think this docstring should also explain the meaning of the three possible values of `include_parents`
Let's avoid `hasattr` as much as possible by having a default value of `originating_model = None`.
three values: True, False, and ..
recopied (no dash) get a different
What I'd prefer is a proper enum type, but we don't have one that we've adopted for use in Django. Lacking that, I don't think there's really much difference between True/False/PROXY_PARENTS and ALL/NONE/PROXY_PARENTS.
Ah, when Model is None.
(okay, now I saw the docs)
That's fine in my book.
I'd like to have some actual tests for the underlying foreign keys: see the `self.assertFKExsits()` and `self.assertFKNotExists` usage in `test_rename_model_with_self_referential_fk()`
I think we should go with `related_object.field.rel.to is not model` instead. It's more self explaining and should do the same.
Please use this style to limit lines to 120 characters so we don't have to scroll to review it: ``` self.assertEqual( ..., ... ) ```
Please wrap docstrings at 79 characters and include a period at the end of the sentence.
This should be done in `get_db_converters` not as `from_db_value` for performance reasons. Where possible, we should avoid the existence of any converter functions, even when they become noops like this.
A name like `uuid_pk` might avoid confusion with `field.rel` but no worries if you think the current name is fine.
Can `source` be falsey and not `None`? If not, I think it's better to use `source or self.related_field` and make the method a one-liner.
The recommendation is to double indent in this particular case so as to avoid visual confusion with the contents of the block.
Actually, no, it's not a bug in flake8: ``` python if (foo and bar): pass ```
+1. I like this approach.
As above: no need for casting.
I don't understand how this should work with a `Node` instance. `forwards_plan()` would expect `node.key` I think.
Style: can you sort `__str__` and `__repr__` between the other private methods on top.
Well, I guess we should take the node instances then.
You can you use the `cached_property` decorator here.
Even simpler: don't use the key at at all, but the node instance itself.
You can you use the `cached_property` decorator here.
No need to call `keys()` here.
When you keep sets for `parent_keys` and `children_keys` on a `Node` you don't need a lambda here. Not sure if that's worth it though.
I think we can get rid of `self.nodes` when we add `implementation` to the node itself: `node = Node(key, implementation)`
No need to cast the set into a list. You can iterate over sets.
Style: Can you move that `add_child()` above `add_parent()`.
I'd prefer to decorator the test with `@override_settings` so we don't need to indent the entire test.
I'm not sure this needs to be changed. Testing the default value seems useful.
Please use single quotes as in other tests.
I find this docstring a bit confusing (copied from elsewhere, I know). I think something like "settings.CSRF_HEADER_NAME can be used to customize the CSRF header name" would be simpler
Might want to use simple quote here.
Use `force_update` in this case to make sure an error is thrown if it doesn't exist.
I'd like not to use `import *` as that makes flake8 unable to detect undefined names. I think a better long term solution is to break this file up into multiple `test_*.py` files so it's not so monolithic.
I looked at the log and realized those tests are run with `USE_TZ=False` so everything should be good here.
What about using `(pk=cls.b4.pk)` instead? I think it would be easier to find the origin of the data this way.
form = ...
this could probably be a docstring.
Element -> MyForm
Can you issue a `RuntimeWarning` here telling the user that Django falls back and it might be time to clean up using `squashmigrations` and link to https://docs.djangoproject.com/en/dev/topics/migrations/#squashing-migrations.
A better name would be `test_graph_iterative()` now.
Put `import warnings` before `from collections import deque`.
Can you also rename `test_deep_graph()` to `test_graph_recursive()`
Any chance to separate the rename of `node` to `target` from the commit adding the iterative fallback. I suggest to first rename `node` to `target` and then add the iterative fallback.
I'd rename that to "target". See `root_nodes()` for an explanation of what we consider root nodes.
In case we raise an `InvalidBasesError` `self.ready` stays `False` which makes the `StateApps` instance pretty much unusabel. Can you reset it to `True` before raising the exception above, please.
Ah, I see. I was curious whether that was a common style in Django, etc. Thanks for the reply @timgraham > On Feb 24, 2015, at 7:49 PM, Tim Graham notifications@github.com wrote: > > In django/forms/forms.py: > > > @@ -580,12 +586,16 @@ def value(self): > > if not self.form.is_bound: > > data = self.form.initial.get(self.name, self.field.initial) > > if callable(data): > > - data = data() > > - # If this is an auto-generated default date, nix the > > - # microseconds for standardized handling. See #22502. > > - if (isinstance(data, (datetime.datetime, datetime.time)) and > > - not getattr(self.field.widget, 'supports_microseconds', True)): > > - data = data.replace(microsecond=0) > > - if self._initial_value is not UNSET: > > I don't really mind either way but discussed briefly in IRC and concluded: "Code is clearer when objects of a given type always have the same set of attributes - the presence of a sentinel value is a clearer marker of intent (as opposed to bug) than the absence of an attribute entirely." -Carl Meyer > > — > Reply to this email directly or view it on GitHub.
Shouldn't that be `self.assertIs(name, form['name'])` to check for the same instance. No need for `val3` then.
`hasattr` is a more idiomatic approach to this (also saves a couple lines of code), unless there is a specific reason for using an object like this.
please revert whitepsace changes in this file
Doesn't seem to me that a doc string is really needed since the test is simple, but if you think it's useful you could say something useful like "Index names should be deterministic." -- that's more helpful than requiring someone to reference a ticket.
With a non-English LANGUAGE_CODE and if the active language is ....
no parens needed here and a couple lines below
these assertions would fit on 1 one
`os.chmod` should be before the `try`. It doesn't make a big difference but that's the common pattern in general.
Seems okay to me. I guess the alternative would to vary the message based on OS. Not sure that complexity is required though.
This test is problematic on Windows: ``` ====================================================================== FAIL: test_notafile_error (template_tests.test_loaders.FileSystemLoaderTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\template_tests\test_loaders.py", line 266 , in test_notafile_error self.engine.get_template('first') AssertionError: "Is\ a\ directory" does not match "[Errno 13] Permission denied: u'c:\\Users\\Tim\\code\\django\\tests\\template_tests\\templates\\first'" ```
Does the raised exception have the same `errno` on both platforms? If that's the case you could do: ``` python with self.assertRaises(IOError) as ctx: # .... self.assertEqual(ctx.exception.errno, errno.WHATEVER) ```
Since you are touching this if condition already, can you change the code formatting: ``` python if (new_field.rel and (fks_dropped ...) and new_field.db_constraint): # continue here ```
Can you make this upper case and give it a slightly more unambiguous name, e.g. `TIMESINCE_CHUNKS`
no comma needed
in case of -> if
remove first comma (also as someone not intimately familiar with the ORM, I'm not quite sure what "default select" means (I assume it's a reference to `default_cols` -- maybe no further explanation is needed).
I removed it from my code.
I didn't either, I guess you just made a typo with RemovedInDjango20Warning instead of 21.
Believe it or not, we're importing this one at work. (wasn't me this time :). I'm actually not sure what you've done to replace it.
I am personally using Widget.rel in some of my code. Some sort of compatibility would be nice if it's not too hard.
I wonder why we use `smart_text` here.
prefer `self.assertRaisesMessage` to check the message too (need to inherit `SimpleTestCase` for that)
This has two undesireable side effects: 1. It generates file names without a hash, defeating the purpose of `HashedFilesMixin`. This will result in incorrect caching while `HashedFilesMixin` precisely exists to provide cache invalidation when static files change. 2. It lets errors slip through silently when a file doesn't exist. This may be considered a feature or a bug, depending on the developer's expectations. (Some developers consider that a missing CSS file or image isn't an issue. I don't know if they would also advocate not raising an error when a Python module isn't found ;-) I consider that it should raise an exception.)
`# Write the migrations file to the disk.` and something like `# Alternatively, makemigrations --dry-run --verbosity 3 will output the merge migrations file to stdout rather than saving the file to the disk.`
As long as you can't crash the debug page, you're fine. I don't have a strong opinion one way or another. I just wanted to make sure it wasn't an inadvertent change.
I have to admit that I turned several module-level functions into engine methods without giving it much thought. Feel free to move engine methods in other classes as needed.
It's `grep -C10 <line_where_error_occurred> <template_source>`. It could use a docstring.
Excellent. The lexer has no business knowing about origins.
It's hard to assess the correctness of this change through visual inspection. I'll trust you (and the test suite) on this.
Passing the last argument as a keyword argument (`in_tag=False`) would make the code easier to follow. This is almost always better for boolean arguments, except when they're the only argument of the function.
I'm reluctant to pass a `Template` to the `Engine` because that creates a circular relation between the two classes. If you keep this design, you must at least rename `compile_string`, because it no longer accepts a string in argument. In fact I would add a new method and deprecate `compile_string`.
This file can be removed.
This file should be `models.py` -- did you try running the tests locally? There are ImportErrors with `$ ./tests/runtests.py messages_tests`
this can be a single line (we prefer longer lines when it improves readability)
We prefer hanging indent style like this: ``` self.assertEqual( res.context_data["form"].errors["__all__"], ['You must confirm the delete.']) ) ``` Also please drop the u prefix on strings.
Unindent by 1 space. Indention must be a multiple of 4 spaces.
Are the different models testing two different code paths? It's unclear to me why the second test isn't sufficient for testing the number of deleted rows too.
That seems okay to me.
A parameter the controls whether a tuple or a single item is returned from a method doesn't seem like a great API. I'd be inclined to drop `rows_count` unless you discussed this with someone else.
please include trailing comma in dictionary so if more items are added, we don't have to modify this line again
I think we should trigger a custom exception here rather than `ZeroDivisionError`
you can replace the dash in this message with a space
I'm about to commit this, but for future reference note that assertEquals is a deprecated alias and should be assertEqual
As multiple addresses are allowed, I suggest "to one or more addresses specified ...".
chop first comma
since -> if
to prevent the interface from getting confusing.
revert whitespace change please
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
`assertNotContains` is a bit fragile; instead I'd like if you could check `response.context` variables.
Here's a ticket if you have interest in trying to do the implementation: https://code.djangoproject.com/ticket/24476
do you think a ticket to allow using `set_script_prefix()` as a context manager would be useful? (if only in tests)
prefer the context manager version of `self.assertRaisesMessage()`
Because it's a predefined identifier, similar to ENGINE and NAME in the [DATABASES](https://docs.djangoproject.com/en/1.8/ref/settings/#databases) setting and BACKEND and DIRS in [TEMPLATES](https://docs.djangoproject.com/en/1.8/ref/settings/#templates).
this line could go in "else" of try/except/else
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
I'd include the min length in the error message
Why is NAME in capitals? For comparison, DATABASES and CACHES use lower-case 'default' and then capitals, LOGGING uses lower-case only.
I would code it like this: ``` DEFAULT_USER_ATTRIBUTES = ('username', 'first_name', 'last_name', 'email') def __init__(self, user_attributes=DEFAULT_USER_ATTRIBUTES, max_similarity=0.7): self.user_attributes = user_attributes ```
has a -> is of a
I would read it as "validators in a 'U' 'L'" so I would say "in a" rather than "in an" but if you read it as "unordered list" than "an" is fine.
chop first comma "this feature" -> "a password_changed() method"? wrap docstrings at 79 chars
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
prefer hanging indent to allow longer lines
(This is also more "food for thought" than an actual request for change - whatever you prefer is fine.)
`hasattr` is ugly because of its propensity to silently hide `AttributeError`, and because of its look-before-you-leap inefficiency. I would avoid it and instead use something like: ``` password_changed = getattr(validator, 'password_changed', lambda *a: None) password_changed(password, user) ```
I'd like to second @aaugustin's point about this conceptually fitting very well into the custom user models. This does not require yet another setting, so let's not. On the bigger picture I really would like to prevent settings.py to continue to turn into a file full of dictionaries with dotted Python paths and initialization parameters. Let's use the extension API we've built into the auth app for such a case.
Scanning a list will not be faster than a membership test of a set (unless the list of words is very small).
This would be better as a set rather than a list.
no dash in "email"
its so that, for example, a ...
You don't need a list comprehension here.
I'm not sure about the `backend` terminology here. I think naming this function `get_password_validators` would be more consistent with the rest of the the code.
If `user_attributes` is set to `()` or `[]`, the default set of attributes will be used. That may be surprising. Can you make a strict check for `user_attributes is None`? I understand that the validator doesn't do anything then and can simply be removed from the settings in that case, but I can imagine situations where someone would control `user_attributes` (e.g. through an UI) and not `AUTH_PASSWORD_VALIDATORS`.
If I were writing this from scratch, I'd consider "a bunch of functions that all take an optional `password_validators` arg and call `get_default_password_validators()` if it's not given" to be an indication that perhaps a higher-level class is in order that you can instantiate with a set of password validators and then call methods on (and a default instance of that class based on settings could be provided at module level). But I don't feel strongly enough about this to suggest actually rewriting it on that model.
Oh I missed that. Sorry!
Since the list is in order of most common use, the code detects incorrect passwords slightly faster if you preserve the order. :bikeshed:
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
Since this is part of a contrib application I think this should be named `AUTH_PASSWORD_VALIDATORS`.
Never mind, even such an API would be useless since the raw password is no longer available after its initially set. So there really is no way around that limitation of this validator.
I'm theoretically reluctant to this being a global module rather than something tied to the User model. In practice AUTH_USER_MODEL is already a global singleton so this doesn't change the picture. (Sorry if I brought this up before.)
Any reason to use `chain` here? Both `match.groups()` and `sub_match.args` are tuples, so a simple `match.groups() + sub_match.args` should suffice. Other than that, LGTM.
Maybe this should be in another file, this file is large enough already.
could you fix the other test cases in this file and make it a separate commit? I see at least `BooleanFieldTests` that has database activity but uses `unittest.TestCase`.
Can you call this function `django_datetime_cast_date` for consistency? Everything else has cast_date / extract / trunc.
the tests pass for me on Oracle using `'TRUNC(%s)'`
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
``` python # but in UTC, the __date only matches one of them ```
I couldn't see a reason not to use `super` here, otherwise LGTM.
IMO, it might be better to harcode the expected HTML rather than generating it programatically as it would be more clear what's expected.
Yes, I know. I'll leave it to Aymeric for a second opinion.
I couldn't find a valid way of making the `Exception` catching cloak possible misconfiguration but I wonder if it wouldn't be better to make session serializers re-raise a common `DeserializationError` and catch it here.
I think debug logging would be fine here.
Is it expensive to restore the old language? I'd think it'd be less error prone if the method didn't have side-effects by default and simpler if we could drop the `deactivate` parameter, but I'll let you decide as the i18n expert.
please use 4 space indent
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
blank line shouldn't be removed probably
I don't think so; base classes shouldn't depend on subclasses. Create a `DatabaseFeatures` subclass for the dummy backend and set the attribute there.
prefer a longer line for readability
Special-casing this flag here looks weird.
Use `{'default': {}}` for clarity.
add trailing comma
I would typically put the "and"s on the previous line
if they define
I am not sure what the "rem" prefix means
please try to make this line fit in 119 chars
You might use single quotes throughout the new code.
I'd avoid abbreviations: ``` m2m_fields = [ (field_name, field) for field_name, field in state.models[app_label, self.name_lower].fields if f.many_to_many ] ```
No need for `getattr()`
`for (app_label, model_name), through in sorted(self.new_through_models.items()):` saves you the next line and is still readable.
Why do you need self.author_publisher_m2m here and the line below.
Can you move that function above `only_relation_agnostic_fields()` and a brief docstring.
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
That would of course require a backwards incompatibility note, and the failing test would need to recreate the fatty and salty tags between each assertion.
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
I would fix the test by recreating the tags between each `assert`, eventually we should fix GFK to make their "clearing" consistent with FK (i.e. can't clear if not nullable, and nullify if nullable).
Welcome to the wonderful world of `contenttypes` where clearing a GFK (even an optional one) actually deletes the objects.
Same as below, you should be able to call `self.using()` directly.
I'd rather find out why we are getting the failure first. User can opt in for `self` to be a custom manager with the `__call__` syntax, doing `self.model._default_manager` bypasses it.
We can't assume that the `objects` manager exists, you can just use `self.using()` since its already a manager.
I think creating the objects is really out of scope for this function. Also it's tricky, what if a custom default manager filters out some objects? We may try adding them again.
has very high precision so we can test this on...
`).order_by('name')` on next line
I wouldn't omit parenthesis here
single quotes please
add period to the sentences
A bit odd that this test has a doc string and the others don't.
Add a trailing comma.
I think it wouldn't hurt to consistently add it there too.
`raster_model` or even just `r` is probably fine.
single line is fine
Indeed, the idea is to not fail at import time as much as possible. However, it's not really feasible in `__init__`, because `djang.db.connection` represents only the `default` connection, and you don't know at this stage for which connection the field is created (it might be that the `postgis` database is not the default one). So you have to delay the check to a later stage, in a method which receives a `connection` object.
If possible, no conditional imports.
Not sure that description adds much value.
try to be consistent and use single quotes in most places (sorry existing code is inconsistent)
, -> .
no blank line before first field
as a tuple
Use the context manager version for better readability: ``` msg = '....' with self.assertRaisesMessage(ImproperlyConfigured, msg): self.set_up_test_model(True) ```
repetitive with method docstring
prefer hanging indent style (allows longer lines, indentation always multiple of 4): ``` rasterheader = ( 1, 0, ... ) ```
migration_class, model_name, etc.
python -> a
Lastest decision is to use pep8 style docstrings for new code. e.g. "Packs -> Pack"
Routines -> Methods
`test_fields` or simply `fields` if no name collision
This will not work. `cls._meta.ordering` is defined in `django.db.models.options.Options#_prepare` if `order_with_respect_to` used, so it will fail if I will use only `order_with_respect_to`.
These changes have to be as separated commit (since unrelated to ticket)
It will be better to use smth as @timgraham suggested - `ordering_overriden`. It will be `False` by default, and may change to `True` in case of `order_with_respect_to`.
I think so, because we don't need original ordering values, we need only a flag.
prefer hanging indent style: ``` raise ValueError( "Can't apply ..." ) ```
For better readability rather than splitting the string across two lines: ``` msg = "can't apply.. " with self.assertRaisesMessage(ValueError, msg): ```
line too long
It's much nicer to include a doc string with an explanation of the issue (if it can be done simply enough) rather than requiring the reader to lookup the ticket (also include the ticket number if there is further background/explanation in the ticket).
Nitpick: it's not useful to put `stdout_encoding` in a temporary variable...
Prefer the context manager version: ``` self.assertRaises(Resolver404): resolve(url) ```
prefer ``` test_urls = [ '/lookahead-/a-city/', ... ] ``` rather than putting them in the loop.
Use keyword arguments to make it clearer.
I think you can do without using a temporary variable to store the messages. Just use the value directly in the assert.
Make it a "private" method: `_initialize_signal_car` just to make it obvious it's not a test method.
I would turn this into a docstring.
Should we check explicitly only for name '+'. I'm not sure if users can define some other hidden related name if they want to. In that case we shouldn't override the user's hidden name with an auto generated name.
Better to rewrite docstrings in a separate commit.
prefer simply describing the behavior: "APPEND_SLASH should preserve ..." rather than prefixing every docstring with "Tests that"
This was noted in another PR that I closed to avoid creating a merge conflict: "upper" -> "earlier"
I'll edit this docstring to remove the references to the removed parameers, but please check my edits.
This should like go in `@override_settings` rather than modifying the setting directly which might leak to other tests.
under what circumstances do we need this? My system has 'UTF-8', so it's not very exciting as that's the default for these functions.
Drop this empty line
User triple double-quotes (`"""`) for docstrings, please.
Ah, got it. In that case you should rely on try-finally. ``` python temp_pgpass = None try: if passwd: temp_pgpass = tempfile.NamedTemporaryFile(...) ... subprocess.call(args) finally: if temp_pgpass and os.path.exists(temp_pgpass.name): os.unlink(temp_pgpass.name) ```
I think `NamedTemporaryFile()` supports context managers, doesn't it. You should be able to use ``` python with tempfile.NamedTemporaryFile(...) as temp_pgpass: # Do some magic ```
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Unindent by one level, please.
Better to use the file handler's write than `print`.
This function shouldn't be defined inside the method.
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
Any of these three solutions works for me :-)
The `isinstance` check feels a bit dirty but I guess it's simpler than having two transform classes. No strong opinion from me, just something to think about.
could `extract_type` default to `lookup_name`? not sure if it's different for any of the transforms we have so far.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
Can you make this work adding `self.assertTrue(profile.image.closed)` after this line? I wouldn't expect accessing the image dimensions to leave the file opened.
Also `4x8.png` is left on the file system when the tests conclude.
The reason it's here is that it has been implemented more or less this way for a long time (though the code hasn't been even this clear before compiler expressions refactor). MySQL has been the only backend to reach this part of code. If some backend would allow grouping by primary key only, and wouldn't need expressions in having either, then that backend would get extra expressions in GROUP BY. This is non-optimal, but not an error. Of course, if somebody wants to clean this up, +1 to that.
RawSQL needs to be added to the group by clause, we can't know if it refers to something that doesn't have an existing alias. Getting CombinedExpression and Date here seems curious. These should be fixable, but lets not do it in this patch.
Good for me: https://github.com/django/django/pull/4399.
Include expression if it is a PK or if the alias is not one an alias of a PK? Wouldn't this include all fields that have an alias? (I know I must be reading this incorrectly because the tests pass..)
Would the following be considered over-engineered? ``` python from django.core.urlresolvers import reverse from django.utils.functional import lazy from django.utils import six from django.utils.translation import ugettext def _password_helptext(): message = ugettext('...using <a href="%(password_change_url)s">this form</a>') password_change_url = reverse('password_change') return message % {'password_change_url': password_change_url} password_helptext = lazy(_password_helptext, six.text_type) ```
Ahh I see, didn't realize that.
We can combine this with the previous test class (rename it you like) and move the `@unittest.skipUnless` decorator to the class instead of each method.
Don't think we need to repeat the docstrings from individual methods.
test failure says this should be `(None, None)`
need to use `from django.test import mock`
Forget about the single quotes, we use them in this location all over this file.
I'd leave `'operations'` an empty list. Also, can you use single quotes here, please.
check that -> and that (no comma needed since the two clauses are independent)
prefer including a trailing comma in kwargs so if more items are added in the future we don't have to modify this line again
Can you reuse the existing `self.engine` instead of defining a new one? That would keep the test short and focused. (If there's a good reason to define a new engine, sorry, I missed it.)
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
This should be removed.
no blank line after docstring
`all(f.name != db_field for f in fields)` (not sure if it's bettter/worse than the current version)
I'd rename that to `found_create_model_migration`
Thanks for addressing this.
You also need to get the name of the table column from the respective field
"CreateModel and AddField"
You need to get the table out of the model this field belongs to. See the `isinstance(operation, migrations.CreateModel)` branch above.
use: `any(name for app, name ... )`
I'd change that to `found_add_field_migration`
... and change this to `return (found_create_model_migration or found_add_field_migration), after_state`
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
I think the current version is clear. You could change the `[...]` to `(...)` though
"tables or columns it would create"
I think we need to ignore models with `managed=False` or `proxy=True` here as they never receive any database level operations anyways.
I suggest to add a line break and list models one per line with 2 spaces indentation.
missing quote after `modelname` which should also be `model_name`
Can you put the `\n`s at the end of the previous line.
`((app_label, model_name), [fields])` LGTM On April 1, 2015 3:46:12 PM GMT+02:00, Alex Hill notifications@github.com wrote: > > - from those operations and use them to provide a nicer error > > message. > > + > > - This will work for any function passed to > > lazy_related_operation that > > - has a keyword argument called 'field'. > > - """ > > + > > - def extract_field(operation): > > - # Expect a functools.partial with a kwarg called 'field' > > applied. > > - try: > > - return operation.func.keywords['field'] > > - except (AttributeError, KeyError): > > - return None > > + > > - extract_fields = lambda ops: list(filter(None, > > map(extract_field, ops))) > > + > > - # Generate pairs of (("app_label", "modelname), [fields]) > > Yes you do. The idea was to give an example of the literal contents of > the variable rather than its origins, hence the quotes surrounding each > element. I'm happy to go with `(app_label, model_name)`, without the > quotes. > > --- > > Reply to this email directly or view it on GitHub: > https://github.com/django/django/pull/4423/files#r27569838
Should be "its"
this doesn't seem relevant since we're testing with dry run anyway.
maybe we could describe what "direct related models" are? not sure the ticket reference is helpful here add period
You need to call clear cache in `ProjectState.remove_model()` if you remove it here.
This needs to be on the same indentation level as `unregister_model()`, otherwise you're enforcing a rendering of `self.apps` ;)
We are actually only removing a single model, not multiple.
I think this is fine as-is.
The usual style is to put the closing parenthesis on the next line and include a trailing comma on this line.
I think you can simply decorate the method with `@contextmanager`. Also, a docstring for the method would be good to add.
is there a need to store `self._ready` on self instead of simply using a local variable (besides for checking it in tests)? `del self._ready` seems a bit ugly.
Please wrap docstring at 79 chars I prefer to use this style, "StateApps.bulk_update() should update apps.ready to False and reset the value afterwards." rather than "Tests that..." in every docstring.
This can be a separate ticket, but this message probably needs to be revised now that migrations are compulsory for all apps in 1.9.
This bit of code implies that you can change `AUTH_USER_MODEL` and Django will deal with it. I don't think that's true. Changing `AUTH_USER_MODEL` at runtime would require rebuilding the entier app registry. Think about the common pattern `ForeignKey(settings.AUTH_USER_MODEL, ...)` for example.
Let me put this differently :-) Is this required to make the test suite pass? If not, I'd prefer we do not include it. If yes, I'd like to look at the failing tests, because they must be weird.
If it's just those two tests, I suggest to clear the cache explicitly
Seems like a context manager would be good here so the cache can be cleared regardless of whether or not the test passes (also we could simply decorate the test method).
Maybe the problem is that field_name refers to field.name when field.attname should be used. I'm not sure how to get field.attname. It seems val.pk is wrong for two reasons, first the relation might be pointing to some other field than pk, and also it might be that retrieving the val instance might require executing a queryset.
As `supports_microseconds` defaults to True, I don't think we need to create a subclass here, let's just test `HiddenInput`. Same for `TextInput` below.
Does the use of double quotes for the separator argument matter here? I'm used to most string values having to use single quotes, but I'm not a mysql user so I'm not entirely sure it matters. I did a quick search and it appears that mysql supports double or single quotes for string literals.
rst -> docutils maybe? I think we could put the stuff after `.get(` on the same line too if you want. otherwise, LGTM.
It seems to me that 1 test should be sufficient for testing the "as" functionality.
1. Add this import: from {{ project_name }} import views
I think we could just say, "Function views:" and omit "Example X" for each case
1. Including another URLconf
Dotted path isn't deprecated for `include()`
1. Add a URL to urlpatterns: url(r'^$', views.Home.as_view(), name='home'),
This seems incorrect -- we aren't using any data from the formset.
drop u prefixes on strings (we use `from __future__ import unicode_literals` instead)
one line is fine here (prefer longer lines up to 119 chars when it improves readability) don't think `?next=%s` is needed
including trailing comma in dicts so if more items are added later we don't need to modify this line again
The `u` prefix is not required since `unicode_literals` is imported.
Unnecessary list comprehension, `all(isinstance(v, SafeDate) ...)` should do.
Use a style like this to avoid long lines: ``` self.assertEqual( "Processed 1 object(s).\nProcessed 2 object(s).\n" "Processed 3 object(s).\nProcessed 4 object(s).\n", command_output ) ```
is this test needed? I'd suspect it's already tested.
You can use `assertRaisesMessage(FieldError, '...', Note.objects.filter, kws)` instead of the `lambda` here. I think it'd improve readability a bit.
Ah, I think I forgot my parens when checking. Thanks for double-checking for me :)
prefer the context manager version: ``` self.assertRaisesMessage(FieldError, 'Cannot ..'): Note.objects.filter({'note': 'n1', 'misc': 'foo'}) ```
I'd use a semantic test name like `test_error_raised_on_filter_with_dictionary`
A concern I have, looking at this, which I didn't explicitly mention in the original ticket [because I've never done such], is that this would allow the same accidental non-error if given an `OrderedDict`, because it supports the same expansion but isn't a subclass of the `dict` type. I think I'm now reaching for real niche use-cases that have presumably never knowingly happened [or they'd have been reported long before I noticed], but still...
confirmed: ``` >>> from collections import OrderedDict >>> isinstance(OrderedDict(), dict) True ```
Might care to wrap some lines than went beyond 119 characters now.
I would either rename `old_rel` to `_` or `_old_rel` here to denote it's unused.
We don't really need all the history of when it was broken/fixed.
missing spaces around *
is this limited to TLDs? it seems all labels are limited to 63 characters.
I'd suggest something like `'example@atm.%s' % 'a' * 63` (and 64 for the invalid one)
This looks like a good candidate for `kwargs.setdefault('form', self.get_form())`
this could be 1 line
1. I think you just need a `urlpatterns` variable at the module level. 2. Maybe a simpler test could just call `get_context_data()` on an instantiated version of the mixin or one of its subclasses and verify 'form' is there.
`ContextMixin` doesn't use it but is very explicit about what it's trying to achieve. I guess `SingleObjectMixin` could be updated (in another commit) to use `setdefault` and avoid an extraneous `dict` creation and update.
Those two arguments are required for `DecimalField` (I assume `None` isn't a valid value).
I would only add this validator `if self.max_digits is not None and self.decimal_places is not None` instead of checking it in `DecimalValidator.__call__`.
The system check framework will throw an error if a model uses `DecimalField` without those arguments. I'm not sure if there's a use case for instantiating `DecimalField` outside of a model (perhaps in `output_field`, but don't think validators are used there). All in all, I think the current version is okay.
You don't need to break this line, if it's below <=119 characters. It's better readable in my eyes.
Revert change on this line (caused by find/replace, I guess).
and let's call it `allow_unicode` on the Python side.
I think `if not self.allow_unicode` would be fine
The idea is that `InlineModelAdmin` is always used with a `ModelAdmin`, so we don't need to include the files again.
We can remove this - it's always included above.
Ahh we were so close, we tried removing `or name in self.query.external_aliases` but this triggered more failures. This all makes sense now.
Is there a specific reason to `insert(0...` instead of `append`? `basedirs` is transformed to a set just below, so I think ordering really doesn't matter here.
I suppose you might use single quotes for consistency.
Just curious if there is a reason for the `runTest` name instead of the usual non-camel case name.
perhaps more generally, "Database queries aren't allowed in SimpleTestCase." (since queries can be executed in ways other than just the oRM)
transaction , or serialized if they are not available,
Nuke the `list()` call
I think you can drop the `list()` here.
It might be nice to create some objects and verify the ordering so that models aren't inadvertently refactored and ordering attributes lost which would eliminate their regression nature.
Probably, I don't think the benefit is worth the cognitive load of someone looking at the test and wondering about it.
I prefer "... raised (#24654)." to save a line also wrap 1st line at 79 chars
chop parenthesis cause it's a property now
The `u` prefix is not necessary (as unicode_literals is imported at the top of the file). `self.assertIn` can be used here.
You might also test the user agent string in `mail.outbox[0].body`.
simpler? ``` if self.object._deferred: obj = obj._meta.proxy_for_model return obj._meta.model_name ```
something similar to above to remove the repetition would be great.
This change turns this into a confusing/possibly-useless test. What is the response content? What assertion can we make about it? The universe of "things which are not the empty string" is very large, and includes many things which would be wrong.
It seems like there's no longer a need for the defensive use of `.get()` here; `CSRF_COOKIE` must always be set at this point.
If you can try to make logical commits with the tests passing after each one as in https://github.com/django/django/pull/3770, I've found that quite helpful as a reviewer.
If possible, it would be great to try to submit cleanups like this as separate pull requests that can be merged ahead of the main composite field work. Otherwise, I fear we will end up with a monolithic pull request that will be very difficult to review.
Can you check explicitly? ``` if tried is None: tried = [] self.tried = tried ``` This is a good practice in general to avoid hard-to-diagnose errors if an unexpected, falsy value of `tried` is passed in.
only -> the
AFAIR it is needed when the targeted value can be null, so as None is not transformed to the string "None". I don't know if it is the case here.
I think I would use `assertTrue(all(isinstance(name, six.text_type) for ...)` but don't care too much either way.
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
chop newline for consistency with other tests
Here's a regression test that passes on master but crashes with the new version (after the deprecation warning is silenced): ``` diff diff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py index 4677962..b2845ff 100644 --- a/tests/model_fields/tests.py +++ b/tests/model_fields/tests.py @@ -31,6 +31,11 @@ from .models import ( class BasicFieldTests(test.TestCase): + + def test_get_val_from_obj(self): + f = BooleanModel() + self.assertEqual(f._meta.get_field('string')._get_val_from_obj(None), 'abc') + def test_show_hidden_initial(self): """ Regression test for #12913. Make sure fields with choices respectdiff --git a/tests/model_fields/tests.py ```
If it's not clear, my suggestion is merely to leave the original implementation of `_get_val_from_obj()` instead of changing it to `return self.value_from_object(obj)` and to change the deprecation warning/docs to avoid implying that the methods are completely identical in their behavior. I can finish this if you have given up on it.
The implementation is slightly different, so I wouldn't make this change.
How about `# View is not a callable (explicit import; arbitrary Python object)`
I'd use present tense here: "... is not a callable ..."
How about # View is not a callable (string import; arbitrary Python object)
As below, use `django.utils.six`.
Use `six.string_types` from `django.utils.six` (which is already imported).
Please use a hanging indentation: ``` python self.assertEqual( set(...), {...}, ) ```
I think that `patch_cache_control` can accept multiple keywords in a single call.
Please use set literals: `{'max-age=0', 'no-cache', ...}`
There's `model_label = '%s.%s' % (self.app_label, self.model_name)` in this file which could use `self.label_lower`
including trailing comma and chop blank line that follows
You can remove the `model = self.model` above and use `self.model._meta.label` here.
You've lost the `value = value.strip()` (line 1223 as of `master` at 8714403614c4dfa37e806db4a6708b8a91a827a4) [which needs to happen after the conversion to a text type]
don't need an else
this could go in the else block of the try/except
, -> .
The message from the exception (if one was supplied)...
no blank line needed
`force_begin_transaction_with_broken_autocommit` is a really long name, but its purposes still isn't obvious to me. Could you add some info to the docstring about its purpose? If the name could be simplified/shortened, I think that would be beneficial as well.
A list comprehension may be more readable/Pythonic.
Oh, there is a fourth option: turn the `autocommit` flag on the SQLite backend into a property, so that we can hook into `connection.autocommit = True` to run the transaction hooks.
This is a very minor thing, but I wonder why I didn't make the savepoint-ids item in this tuple a set instead of a list, considering its only used for containment checks? I think it would be a trivial change, just change this from `self.savepoint_ids[:]` to `set(self.savepoint_ids)`
Yes, that's true. :-)
This will become a performance issue for the database before it becomes one for the Python process :-)
single line please
we lost 'invalid' here
prefer always including a trailing coma so if more items are added we don't have to modify this line again
this could be a single line - we prefer longer lines up to 119 characters when it helps readability
I'm probably missing something, but it seems like this test and the next one are shadowed by tests of the same name later in the same `TestCase`.
instead of `in (1, 2, 3, ...)` it would be something like `in (self._str_types[x] for x in ['Point', 'LineString', ...])`
prefer assertRaisesMessage to verify the message contents as well
Objects from child models where the parent's m2m field uses `related_name='+'` should be retrieved correctly.
Can you check for the correct error message, please.
Add a new line between `__future__` and stdlib imports to appease isort.
Yes it was Ian, but my example used joined fields for an update which isn't (yet) allowed. How about something like: ``` Author.objects.update(alias=Greatest('name', 'goes_by') ``` Which will also test the handling of varchars in a Greatest.
The default should be the most common I think. So set the default, then change it in the postgres features.
Just make it: ``` if len(expressions) < 2: ``` That avoids problems with sqlite and mysql. GREATEST(x) is always x on backends that support single arguments anyway.
We do not skip tests based on vendors unless we absolutely have to. You need to create a backend feature and switch on that. Then you need two tests - one that tests null when the feature is true, and one that tests null when the feature is false. See: `django.db.backends.base.features.BaseDatabaseFeatures`
The problem here is that you can't just use `Value('')` for the default. If you're doing `GREATEST(date_field, other_date_field)` then coalescing a date type with a char type is going to produce an error. The type itself will probably have to accept a default. ``` sentinel = object() def __init__(self, *expressions, **kwargs): ifnull = kwargs.pop('ifnull', sentinel) if ifnull == sentinel: raise ValueError('ifnull is required') if ifnull is None: # user has asked NOT to use coalesce else: self.ifnull = self._parse_expression(ifnull) ``` And then you would use `Coalesce(expression, self.ifnull)` in the coalesce method, or completely skip calling the coalesce method if `ifnull is None`. This is just one idea, but probably the best one I have right now. I don't really like forcing a user to provide an `ifnull` though, because it feels like we're disadvantaging the user. Another idea would be to use a backend feature. Something like `greatest_least_uses_nulls`, and then the tests could switch on that feature flag to provide different test results. I'd probably like to get a rough consensus on which way to go here.
On Mysql, Oracle, and SQLite
Can you move the exception to `django.db.migrations.exceptions`, please.
Or, if feature is not supported, and timeout is set, raise an exception as well.
Maybe backend features also should be added to prevent statement execution if some other backend will set this timeout.
I wasn't familiar with `assertFormError` actually. Guess the main difference is that `assertFormError` is a single field. Happy to leave that though, the nicer `assertFormValid` is useful in itself.
By the way, I don't find `assertFormNotValid` compelling as we already have `assertFormError`.
True, unless we made `assertFormNotValid(expected_errors)` have to match the exact state of form errors. Currently both `assertFormNotValid` and `assertFormError` would pass if you only provide a subset of the errors that happened. Not sure it's really worth it though.
I think we can remove the "Believe it or not" bit.
unique_together-> index? (or something more generic like unique|index_together
``` raise InvalidTemplateLibrary( "Unsupported arguments to ..." ```
`Library` is a public API. In order to move it, you must include a dummy subclass whose `__init__` raises a deprecation warning. See `django.contrib.gis.db.models.manager.GeoManager` for an example of how to do this. Add the relevant information to 1.9.txt and deprecation.txt.
lines can be longer
above you didn't include a blank line before each elif branch
, -> % (missing tests for this branch) same issue with InvalidTemplateLibrary raised below
in most places you have a blank line after the function before the assert, but not all
I don't remember anything in particular, I just refactored incrementally and ended up there.
Scratch that, the public API is `django.template.Library`, not `django.template.base.Library`
I think list() is redundant with sorted(), e.g. https://github.com/django/django/pull/4666
Add period. Also would be helpful to mention what drawbacks a user might see due to this. Otherwise I think the warning will leave users wondering why it's a problem.
maybe something like "Normally Django will use a connection to the 'postgres' database to avoid running initialization queries against the production database when it's not needed (for example, when running tests). Django was unable to create a connection to the 'postgres' database and will use the default database instead."
Just test with `'Site with this Domain name already exists.'`. This might fail on Python 2 because of unicode literals representation.
trailing comma here and next line
please include trailing comma
I would feel more comfortable with this if it were named `IntervalToSeconds`.
Wouldn't it be simpler (and friendlier to parallelization), instead of monkey-patching the canonical `Sum`, to start this method with `class MySum(Sum): pass` and then use `MySum` instead? We could even define the inner functions as proper methods then.
I had imagined this flag would be removed, but if you think it will be useful for other backends, I don't mind keeping it. It's difficult to know which tests to apply it to without any backends in core that use it though.
one line would be fine here I think, or I prefer: ``` return compiler.compile( SecondsToInterval(Avg(IntervalToSeconds(expression))) ) ``` so it's easier to balance the parenthesis
Could this be moved into the Oracle backend, as a class that inherits the general `Avg` and is only registered for `DurationField`? That would seem much cleaner.
Yes, because it can also be "truthy" by containing a list of fields. True means all fields. FWIW I also tested `objects.values().annotate().exists()` and that was fine before and after this patch.
only need 1 field really, right? I'd tend to always put the fields first when defining the class.
Keep the null property of the old field. If it has changed, .... separately. (also please wrap at 79 chars)
This will require an `as_oracle()` with `self.template = 'CURRENT_TIMESTAMP'` on the other end.
What about defaulting to `NOW()` instead? This should be compatible with PostgreSQL and MySQL and that's what I would expect a `Now()` function to be doing.
Actually removing the trailing parentheses (e.g. `CURRENT_TIMESTAMP`) should work on all backends including SQLite.
Need to test that result is as expected, not only calling it.
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
URLconf chop trailing space
URLconf is "attribute" the correct term? I think of it as a "module-level variable."
has been -> is
Probably want to use `**extra_context` added in 53361589905c7c07692cd77f398ce6cb5ac39779 rather than mutate `self`.
please remove `on_delete=` from these FKs.
(inadvertence revert here too)
I think you may have inadvertently reverted some of my edits here.
Careful, you're mutating `self.config` rather than a copy of it. If you hang onto an instance of `SearchVector` and reuse it then resolve_expression will be called on it twice. You'd be better off figuring out a way to add `config` via `self.set_source_expressions()` rather than overriding resolve_expression and `as_sql`. Even if that means using private expressions to build the components.
Don't need parentheses around `self._nodes_and_edges()` Also check flake8 errors, otherwise LGTM. Also Refs -> Fixed in the commit message.
Ahh didn't notice that. I just remembered a recent commit that converted many of those to literals.
You could use a set literal here.
This should probably be: ``` try: duplicate_path = os.path.join(test_dir, 'file.txt') .... finally: if os.path.exists(duplicate_path): ``` so if something fails, we still cleanup. Alternatively, could refactor to use setUp/tearDown methods.
this variable can be at the class level, no need to set it up for each test method.
`float` is clashing with python's builtin
could you please use this style so lines don't exceed 119 characters? ``` self.assertEqual( '/ns-included1/test4/inner/37/42/', reverse('...') ) ```
I won't complain as long as your choice makes sense and is within 119 chars.
Alternatively, you could handle this where `fields` is updated with `new_class.declared fields` like so: ``` for field_name, field in new_class.declared_fields.iteritems(): if opts.exclude and field_name in opts.exclude: continue if opts.fields and field_name not in opts.fields: continue fields[field_name] = field ```
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
I don't think this docstring is required.
There's a class method called `setUpTestData()`. Please use that instead.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
You can join this and a couple of other lines. We have a max line length of 119 chars.
One empty line above, please.
s/strng or or/string or/
Wrap at 79 chars, please.
Can you sort those attributes please
Valid point. Feel free to change the decorator in a separate commit.
use snake case, please: `test_login_required()`
Can you switch to the same logic as in the decorator: `if isinstance(..., (list, tuple)): ...`
This is mainly to avoid edge cases. Here's an example: Imagine a 3rd-party node sets a value with key `include.html` in `context.render_context`. It's not probable, but perfectly possible. Later `IncludeNode` runs and happens to also use `include.html` as a key. It will pull whatever is already in `render_context` from that previous node when it shouldn't. Using a custom key won't eliminate the edge case completely, but it does reduce the probability of edge cases. The `ExtendsNode` uses a key value of `extends_context`. `IncludeNode` could do something similar.
This is better. I didn't think about the problem with variables that can change values. I have one concern, though. The same `render_context` instance is shared across nodes in the `Template.render()` call, so `template_name` isn't a very safe key to use. The potential arises to clash with other nodes. Maybe we could adjust the approach a bit? My thought is to create a cache dict in the `render_context` using `self` as a key. For example: ``` cache = context.render_context.setdefault(self, {}) template = cache.get(template_name) cache[template_name] = template ``` Alternatively, you could use a unique, uncommon key rather than `self`. The benefit here is that multiple `IncludeNode` instances could share the same cache. That means a template like below would only parse `template.html` once: ``` {% include "template.html" %} {% include "template.html" %} {% include "template.html" %} ``` That seems appropriate in this case.
might be nice to revert the ordering changes to keep the diff cleaner
one longer line is preferred (or at least avoid non-multiple of four indentation).
If we went with `get_model_class()` above, this could simply be `model`.
In this context, I think "session_model" is more meaningful. I think it's not intuitive what "session_class" means. If we follow the pattern elsewhere, I guess "get_model_class" could be the way to go.
Actually... I might just merge this as is, and clean up a couple of docs problems once it's in trunk.
It's helpful to use `self.assertRaisesMessage` to ensure this is the `TypeError` that we expected.
I'd move this block into e.g. `_sort_operations()`
I'd move this and the remaining 2 blocks into `_optimize_migrations()`.
I'd omit a blank line after each docstring.
Mind adding a docstring, please.
To allow registration of a task twice with different names/options.
is the value ever modified such that we need a setup method? if not , I think it would be better if it were simply a class attribute.
is this message an accurate improvement? `Using an aggregate in order_by() without also including it in annotate() is not allowed:` I'll also update the test to use `assertRaisesMessage` as suggested by Simon when merging.
I would test for the complete error message.
This should still be handled by `default_alias`. Something like: ``` @property def default_alias(self): if len(self.source_expressions) == 1 and hasattr(self.source_expressions[0], 'name'): return '%s__%s' % (self.source_expressions[0].name, self.name.lower()) raise TypeError("Complex expressions require an alias") ```
This error no longer makes sense with multiple-arg aggregates. You'll either need to join the output of all source expressions so the error produces: > Cannot compute Sum(arg1, arg2): 'X' is an agggregate # (where X is either arg1 or arg2) Or you'll need a different error message for the case of `len(args) > 1`. There may be another solution (like ditching this message altogether) but I'll let you experiment with that if you like.
I thinking removing APP_DIRS from TEMPLATES (since it defaults to False) is a better suggestion than setting it to False.
.get() falls back to None to `False` isn't really needed I think.
I guess this should be more specific like `CheckTemplateSettingsAppDirsTests`
I'd make the settings more minimal, omitting things like 'context_processors' which aren't important for the test.
After iterating over the items in `_template_response_middleware` Django explicitly renders the response (which is correct). To prevent double rendering, could you update `rendered` to `True` after the rendering in line 177, please :)
`if not rendered` is fine :)
I think we should go with what we do in lines 170 following: ``` python if hasattr(response, 'render') and callable(response.render): response = response.render() ```
I'd probably combine that with the outer `if`: `if not rendered and hasattr(...) and callable(...):`
or to force
"If the exception handler returns a TemplateResponse, that has not been rendered so far, force a rendering"
This should be overridable by `default_error_message` and passing `error_messages` to the formset for consistency with `Field`.
This should pass a `ValidationError` with a code.
Nevermind, it's outside of tests.
please use `self.assertIsInstance(options['verbosity'])` instead of plain assert statements.
I think you're missing a newline between stdlib and django imports.
You don't have a to build a list here. The following should do. ``` python self.pet.people.add( Person.objects.create(name='Ellen'), Person.objects.create(name='George'), ) ```
You can simply this to: ``` python pet = Pet.objects.prefetch_related('people').get(pk=self.pet.pk) ```
I guess if we change that, the stream API won't work by default for tags that don't specify a `stream` method.
Lately, we've been preferring hanging indent so everything isn't stuck on the right side/indented non-multiple-of-4: ``` def request_context_response_with( func, response_class, ...) ``` We could also update the docstrings to "Return ..." while they are being touched.
please include periods
"Return" instead of "Returns"
Please remove the deprecated parameters from `stream()`: context_instance, current_app, dirs, dictionary. Similarly for `stream_to_response()`.
Please create a `_stream()` helper with this signature and use it so that the deprecated parameters don't appear in the `stream()` signature.
I guess `mark_safe()` is needed because the empty string is considered "unsafe"? In that case, it might be easier to understand the intention with: `mark_safe('').join(...)`
Ideally, `stream()` wouldn't have this deprecation code.
This docstring still uses `render` rather than `stream`. I think it would help to move part of these docstrings to `annotate_exception`. Example: ``` diff @contextmanager def annotate_exception(context, token): + """ + Checks for errors during template rendering. If debug is True, contextual + line information is added to the exception before it is reraised. + """ try: yield except Exception as e: @@ -944,10 +942,9 @@ class Node(object): def render_annotated(self, context): """ - Render the node. If debug is True and an exception occurs during - rendering, the exception is annotated with contextual line information - where it occurred in the template. For internal usage this method is - preferred over using the render method directly. + Render the node with debug information if an error occurs. For + internal usage this method is preferred over using the render method + directly. """ with annotate_exception(context, self.token): return self.render(context) @@ -960,10 +957,9 @@ class Node(object): def stream_annotated(self, context): """ - Render the node. If debug is True and an exception occurs during - rendering, the exception is annotated with contextual line information - where it occurred in the template. For internal usage this method is - preferred over using the render method directly. + Stream the node with debug information if an error occurs. For + internal usage this method is preferred over using the render method + directly. """ with annotate_exception(context, self.token): for chunk in self.stream(context): ```
It probably makes sense to remove the helper methods that are now used only once.
`response_class = StreamingHttpResponse if stream else HttpResponse`
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
Since there's many occurrence of nested property access in the patch (`self.filter_expr.resolve`, ...) I don't think the micro-optimisation here is worth it without further benchmarking.
Could we maybe put this logic in a context manager or decorator? It'd be nice not to duplicate it from `render_annotated`. Quick example: ``` python from contextlib import contextmanager @contextmanager def annotate_exception(context, token): try: yield except Exception as e: if context.template.engine.debug and not hasattr(e, 'template_debug'): e.template_debug = context.template.get_exception_info(e, token) raise def stream_annotated(self, context): with annotate_exception(context, self.token): for chunk in self.stream(context): yield chunk ```
Would it make more sense for the default behavior of `Node.render()` to be `return ''.join(self.stream(context))`?. It seems that tags should be able to get away with just defining a `stream` method.
I can't be sure it is performance critical without testing but it looked like it could be when dealing with large loops. I just suggested it because a ticket was recently opened about a template performance regression in between 1.7.x and 1.8.x if I remember correctly.
Please add a docstring: ``` """ If you have a field named defaults and want to use it as an exact lookup, you need to use 'defaults__exact'. """ ```
I'd move `'defaults': 'testing'` to the next line and include a trailing comma per our usual style.
This used to be in an `else` clause, now it is not. Meaning that calling `self._extract_initial_form_count()` was pointless, because it will be overridden anyway.
I don't think the formset and form situations are parallel. Initial form count is used in a variety of ways throughout formsets and model formsets, including when bound. A probably-incomplete list, gleaned from a quick grep: - Deciding whether a form should be permitted/ignored when totally empty/unchanged (this is allowed for extra/additional/new forms, but not for initial forms). - Many uses in inline-formsets, including deciding whether or not to look for a PK field, deciding whether to pass an `instance` to the individual form when instantiating it, deciding which forms should get initial data passed to them from the initial data passed to the inline formset. I am extremely skeptical that it is feasible (or worthwhile) to correctly maintain backwards-compatible behavior in all these cases while removing the concept of initial forms.
This seems like a highly questionable assumption. It means that anytime you have initial forms, you must use a management form to get correct behavior, correct? I am concerned that the failure mode here (having initial forms but forgetting to include the management form) would be very hard to debug.
Oh never mind, I see that you are now using multiple `return` statements; that's OK.
I'd suggest to put this in a new `test_uuid.py` file.
did you consider using `setUpTestData` for this class? Might make things a bit simpler. In particular, this test is a bit long and I think each `From..., prefetch ....` could be a separate test method.
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
I might be missing something but it looks like this attribute isn't used anywhere.
I think you could make a good use of `collections.Counter` here.
Given `self.inner_votes` is an instance of `collections.Counter` this could be simplified to `self.inner_votes.update(inner_votes)`.
preferred style, also "catched" -> "caught" ``` raise Exception( 'Exception... that should be caught' '...' ) ```
catched -> caught
Please include periods in docstrings.
Could you explain why the limit is 8? (or mention it's somewhat arbitrary)
This should be three tests, not one.
is `if request.GET` needed? In the "null" case, I'd expect it to be an empty QueryDict in which cause "in" checking should still work fine. I'd write it as: ``` language = request.GET.get(LANGUAGE_QUERY_PARAMETER) if language and check_for_language(language): ... ```
It looks like we usually uppercase the function name (e.g. `CAST({} as {})`).
I think an explicit `for` loop wouldn't hurt here.
This test requires a little bit more validation - all this checks is that force_insert is a valid argument (or, at least, and argument to save() that doesn't raise an error). It doesn't verify that force_insert is passed into the underlying save method.
> Just so I'm clear then, sorry, would filter(foo__trigram_distance=("Test", 0.5)) be the same as filter(foo=TrigramDistance("Test", 0.5))? If so, then that's fine, I just thought they differed somehow. Until [#25367](https://code.djangoproject.com/ticket/25367) is fixed you have to rely on annotate. Should be along the lines of: ``` python annotate( foo_distance=TrigramDistance(F('foo'), 'Test') ).filter(foo_distance__lte=0.5)` ```
The function is definitely useful, but I'm not sure that it should exist as a lookup. There are no other lookups in Django which take multiple arguments like this one does. Expressions are currently the right API for multi parameter functions. Also I'm pretty sure `foo__trigram_distance((F('bar'), F('closeness'))` won't work, whereas you'd get this for free with the expression version.
We definitely want to have a way of saying `.filter(TrigramDistance(F('foo'), 'test') > 0.7)` or something, but we haven't been able to come up with the right syntax yet so annotate is the compromise. I wasn't aware of the geo lookups, they were written a long time before expressions existed when that would have been the only way of implementing them. GeoDjango in general is in need of a lot of tidy up in a post-expressions world.
I'm not completely convinced we should have this as a lookup. The API feels very strange, and we have the `TrigramDistance` expression which feels more similar to other things. `trigram_similar` is fine.
I don't think keeping the attributes as `None` on the modelform is the right approach. I think they shouldn't be there at all. Furthermore, we use hanging indents or keep everything in one line if it doesn't exceed 119 characters (I don't think you need the explicit list in there, a generator should work: ``` python new_attrs = OrderedDict( (f, None) for f in readonly_fields if f in self.form.declared_fields ) ```
You should be able to skip that line
Please use hanging indents here, too: ``` python self.assertEqual( list(...), [...], ) ```
Ah, you're right. makes sense, then.
this should be `assertIsInstance` check
when possible, I like to avoid "Tests that.." boilerplate since that's always the point of tests. suggestion: `Paginator.page_range should be an interator.`
Might be simpler without intermediate variables: ``` self.assertIsInstance( Paginator([1, 2, 3], 2).page_range, type(six.moves.range(0)) ) ```
`listiterator` i guess, if there can't be other types passed to the iterator creation moment (e.g. tuple)
Also, this is not good that tests differences between pythons versions are via exceptions. You should use `six`
I think this is fine as it is. I don't like that we have to check for the exception or fallback to using the private output_field_or_none though. Problem for another day.
Maybe instead of repeating this each time we could say something like "Corresponds to test_inlineformset_factory_nulls_default_pks for the case of ..."
do we need a blank line before each method? seems like it just makes things longer.
It actually _does_ get added, it's just that `lamdba self: self.file.seekable` raises an AttributeError and therefore `hasattr(file, 'seekable')` returns false in py2.
do we need six.PY3? I assume AttributeError will be raised on Python 2 either way.
Don't see why not.
which must return True if the current user can access the view.
I think "to override the login_url attribute" is more accurate.
Do we actually need to pass in the renderer separately to `BoundField`? It gets a reference to the whole form already, so it could just access `form.renderer`.
Have you thought about what happens if you don't have jinja2 installed? IMHO jinja2 shouldn't be a hard dependency for Django. Maybe it should fall back to a DTL based Renderer in that case.
Read the warning 2 lines above :-)
Looks like you don't ever handle the `else` case here. I would just change the next few lines of default-handling code to set `renderer` instead of `self.renderer`, and then follow up with an unconditional `self.renderer = renderer`
This will need updating to account for #4846 (`getargspec` is deprecated in Python 3 and will soon be removed).
Can you please unfold this loop. It's hard to check what actually failed if one item in the list fails.
Please drop that new line
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
make this `'>Error: Seite nicht gefunden<'`
as below for i18n41
Would be slightly better to use non-contrib models in case sites is someday removed.
I think dash can't be used in an app name, correct? e.g. "'foo-bar' is not a valid app name. Please use only numbers, letters and underscores."
would be fine to use double quotes so you don't have to escape the single
`None` as a default value to `get()` is not required here. I would also just do `if method` since `None` is falsey it's really a nitpick.
It is more generic than shortcircuting the `is_active` flag, isn't it? It logs in the given user.
Not a bad plan at all. I originally suggested `force_login` on the ticket to make it clear that it bypasses the authentication systems completely. Everything here is pretty clearly a testing utility mind.
Ignore other point, I didn't realize `missing_args_message` was an argparse convention.
I'd expect the set to be done after mangers & admins are added
Can you use `django.utils.timezone.now()` here, please, even though the previous code didn't do that.
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
should this be used? (with a test too) arguments -> options
I think it's better to omit the try/except and instead say `Settings(settings_module) # should not raise an exception`. See 071801ccff970682a799ce754431a3c3ce3d6902
when DEBUG = False.
it's helpful to use assertRaisesMessage to ensure this is the exception we expect
ImproperlyConfigured should be raised if DEBUG=False and ALLOWED_HOSTS is empty.
I think `warnings.filterwarnings('always')` is unneeded.
I think this line is unneeded.
think we can chop the blank lines in the last 3 tests
I think slightly nicer is: ``` msg = '...' with self.assertRaisesMessage(ImproperlyConfigured, msg): ```
I guess we could simply use `f.content_type = Image.MIME.get(image.format)`
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
@carljm, yes, I was a little confused, `bool()` will be enough.
what about `return [] if settings.ALLOWED_HOSTS else [W020]` -- That is explicit and readable.
`not statement` is used several times above, so need to be consistent in code style.
I don't think so, at least PEP8 suggests: ``` For sequences, (strings, lists, tuples), use the fact that empty sequences are false. Yes: if not seq: if seq: ``` (https://www.python.org/dev/peps/pep-0008/)
Well, I think we need to return error if hosts is empty, not if it's non-empty, so I don't think `not statement` will work here.
@MarkusH - that looks good to me.
Newline shouldn't be removed at the end of this line.
no ticket reference needed
chop blank line
separate issue but I have no idea what the existing SAVED_USER/SAVED_PASSWORD stuff is and it doesn't seem to be explained anywhere
How about making `app` an optional argument. If not specified, it would run on all `app_configs`? I guess `remove_contenttypes` is a misleading name because it will create content type too. If we had a separate `utils.py` file, then we could us the same `update_contenttypes` name. IMO, code in `management.py` is meant for use by management commands, not for user code.
Exceeds maximum line length of 119 characters.
``` @mock.patch('django.contrib.contenttypes.management.update_contenttypes') def test_remove_contenttypes(self, mocked_update_func): management.remove_contenttypes(self.app_config.name) self.assertEqual(mocked_update_func.call_count, 1) ```
`self.assertEqual(uct.call_count, 4)` But IMO it is better to use patch as decorator instead of context manager.
Need to test how many times `update_contenttypes` was called and test arguments which passed to it.
you can put this on the line above
just state the expected behavior: "A custom manager may be defined on an abstract model. It will be inherited by the abstract model's children."
I'd go with separate methods for each of the different combinations.
You may change the others if you like, but please make it a separate commit.
please use assertRaisesMessage to check this is the ValueError we expect.
I don't think such a regression is likely and we don't have similar checking elsewhere so I think it's fine to remove. Yes, please squash commits.
Now that I look at this, I think I would combine the 3 cases that use this in 1 test method to avoid the helper method. We prefer using the context manager version of `assertRaisesMessage` for better readability.
the ticket reference doesn't seem necessary since the expected behavior is straightforward
I think we can chop the blank lines before Meta in these classes
is this to ensure that `bulk_create()` didn't create any objections even though it raised an error? I don't think that's really needed. Otherwise, this patch looks good.
use assertRaisesMessage to check the msg too
Chop this line with above change.
I'd probably change this hunk in the diff to: ``` python if getattr(field, 'auto_now', False) or getattr(field, 'auto_now_add', False): default = timezone.now() internal_type = field.get_internal_type() if internal_type == 'DateField': default = default.date() elif internal_type == 'TimeField': default = default.time() # DateTimeField already has correct default now ```
Can you combine the model states to have 3 fields: `DateField`, `DateTimeField`, and `TimeField`.
You don't handle `TimeField`.
Can you use `mock.patch` instead, please. See #4901
``` python not ( isinstance(field, (models.DateField, models.DateTimeField, models.TimeField)) and (field.auto_now or field.auto_now_add) ) and` ```
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
`Do not set is_staff.` sounds tricky. `is_staff must be set to True` sounds more clearly.
For new code, I try to avoid the "Test that" prefix as the purpose of all tests is to test things. Instead just state the expected behavior, "Setting request.urlconf.=None will cause the the default URLconf to be used."
while we are here, I think "Text Node" should be `self.__class__.__name__` instead (this is consistent with other code)
if kept as a separate class, I'd copy the `setUpClass` method from `NodelistTest`
`str(` seems unnecessary.
Maybe it's better to use `str` here instead of `six.text_type` since you already know that you are in Py3 at this point. Same for the other occurrences of `six.*_type`. Or just use `python_2_unicode_compatible` instead.
`__unicode__` instead of `__unicode`
This `u` prefix is not required because of the `__future__` import.
do you need `six.assertRaisesRegex` or would `self.assertRaisesMessage` work? (latter leaves less work to do when dropping Python 2).
I do think keeping the try block as small as possible is helpful for understanding how the code is supposed to work.
no dash needed for "subexpression"
omitting the ellipsis seems okay to me. Do we need to include 'id__max' twice, e.g. `Cannot compute Max(): 'id__max' is an aggregate`
I don't have a strong feeling about either case; I think both are equally readable. I was only pushing the `else` alternative forward in the name of consistency. I wish there a was a `try/elif` construct for this exact case.
We usually try to keep the keep only the expression raising the exception dealt with in the `try` clause and move the _safe_ in the `else` clause.
I can see this was already done this way but I think it wouldn't hurt to convert it while you're around.
Try to reduce line length to make review easier.
I don't think this is useful to test 0 call count, because if questioner will be called, it will produce side effect (for this case). It makes sense for cases where questionnaire is actually called
Small nitpick, I would replace those bare side effect `Exception` by `AssertionError` while you're around.
should be `datetime.datetime.now().time()`
Yea, that change doesn't make sense. Thanks for explaining timezones to me, Aymeric :wink:
should be `datetime.date.today()`
Since the ticket you referenced hasn't moved forward for 11 months, I rather see a fix for this issue here and a deprecation sometime in the future (maybe 1.9 if somebody does it), than having broken code for the next 2 or 3 releases.
Can you add a `call_count` check, please: https://github.com/django/django/pull/4901/files#diff-c11e6432df7086eda3dfb9ab8e5b2839R1491
No, it's unrelated to the underlying database column type, but part of these particular field implementations to define what the "default" value is.
Did you see that `TimeField` uses `datetime.datetime.now().time()` and `DateField` `datetime.date.today()`? I guess there might be a discrepancy with using `timezone.now()` in some cases.
I forget the reason for that restriction. What I meant was something like: ``` python def assertDefault(field, field_name, expected_default): with connection.cursor() as cursor: editor.add_field(Author, field) cursor.execute("SELECT %s FROM schema_author;" % field_name) self.assertEqual(cursor.fetchall()[0][0], expected_default) ```
FWIW, I wasn't sure we should even fix this ticket since auto_now/auto_now_add are somewhat weird APIs (see #22995). I'm a bit wary of changing them to be tz aware since there would be some inconsistency in existing user's timestamps on upgrade.
Not sure I'd consider it "broken" since no one has reported a problem. As I mentioned, it could be bad/confusing for existing users if their timestamps are suddenly shifted when they upgrade Django, but I don't care much about the issue -- just suggesting it's time wasted if we come up with better APIs (like database defaults).
The diff in MarkusH's above doesn't make auto_now(_add) timezone aware, it hardcodes them to be computed in UTC instead of using `settings.TIME_ZONE`, which doesn't make sense to me.
Yes, sounds good. And +1 for the positional argument. (_args, *_kwargs) doesn't cost much.
I think I would do `RemovedInDjango20Warning = PendingDeprecationWarning` so we don't give it a meaning it doesn't really have.
I wanted it because it is adding a field (as an implementation detail), and the error text in the first try said "you can't add non-null fields to non-empty tables". I want to make sure the error message is inaccurate, and that this holds in this context and not just in the full `AddField` operation.
Given the failure I've seen, I'd like to see a similar test where `new_field` has `null=False` and a default.
According to http://docs.oracle.com/cd/E11882_01/server.112/e41084/functions213.htm#SQLRF06142 this `if` block may be redundant (it mentions specifically `CLOB`, not `NCLOB`, but it would be surprising if they differ)
There are various reasons for doing this for example to mitigate design faults like circular dependencies or to postpone the construction triggers that could happen at compile time (i.e. when a class type is built) or even to keep the module namespace clear. Not sure without an example.
`if six.PY3` would be clearer than try/except here.
You can move these imports to the top of the file.
By using `six.PY3`, it'll be easier to identify what code blocks can be removed when we drop Python 2 support.
Please move imports to the top of the file.
do the two different identifiers test anything different? If so, I'd go with `related_names.extend([])`
Not sure a helper method is really needed. We could use a boolean like `related_name_invalid = False` and then have the conditions set it to `True`. and then replace `if related_name and not...` with `if related_name_invalid:`
I think the test should be fine to run on Python 2 as well. We use `from __future__ import unicode_literals` to avoid needing the u prefix.
Well I did not check the encoding declaration (well.. I apparently checked another file) and I just told him to use the `chr()` syntax so that is pretty much my fault :-(
I had the same idea with the test location, but then realized that the serializers already test the UUIDs use case and handle them differently (through `value_to_string`). So I think the test is correct.
I don't mind what Claude proposed. I think it would be better to test this at a lower level, probably in `tests/serializers`. That should help verify there aren't any uuid issues with the other serializers too.
use `with self.assertRaisesMessage(PermissionDenied, 'Forbidden user agent'):`
I guess we should remove this logging call since `BaseHandler` now also does logging.
No `self` parameter, just the exception class.
We might add `('Forbidden user agent')` to the exception.
why `strings_only=True`? otherwise make sense to me.
Okay, would be nice to have some tests for that if possible.
This implementation seems less than ideal. We shouldn't add things to `request.META` that weren't really in the request env; this could be misleading to other middleware or view code. Seems to me we should instead make the "force logout if no header" behavior in `RemoteUserMiddleware` conditional on a class attr which defaults to `True`, then this subclass wouldn't need to do anything but override that class attr.
I think `PersistentRemoteUserMiddleware` would be a clearer name.
I'd suggest to check `response.context[REDIRECT_FIELD_NAME]` instead.
a separate test method would be preferred
there's no need to "cleanup" by logging out as each test creates a new test client
Unicode should be capitalized.
Shouldn't this be `except UnicodeError`. I think this points to the fact that more tests are needed, in particular I'd like to see one where `force_bytes(SECRET_KEY)` actually blows up.
Yes please, I didn't audit for all instances.
could you split this string over multiple lines? ``` name = ( "...." "...." ) ```
if a case is only used in 1 file like `FinderTestCase`, I'd put it there.
is there is reason not to have `self.urlopen()` return `f.read()` instead of just `f`? Just seems like the tests could be less verbose that way.
ZipFile already supports the context management protocol, so ``` py with zipfile.ZipFile(buf) as zf: ... ``` would be better.
I think we could make the `urlopen` method a context manager.
You may omit the "Tests that" prefix since all tests test things and just describe the expected behavior.
I think this would be a bit more readable: ``` url = reverse('... show_less_response = self.client.get(url) ```
please use single quotes for consistency
are you sure about this point of "consist of only A-z0-9-_=", as opposed to those characters may not appear in the separator? (not too familiar with this restriction myself) I don't know that the complexity of a `setter` is necessary. I'd just modify the test to initialize a `Signer` each time.
should use `RemovedInDjango110Warning`
Sounds good. Feel free to submit that as a separate pull request. We can probably merge that first and then rebase this.
Okay, feel free to update this PR or send a new one.
Bad conflict resolution -- urls attribute is deprected in favor of `@override_settings(ROOT_URLCONF='view_tests.urls')`
I would also avoid `yield`ing the model if it's unused.
What about allowing multiple positional `*lookups` instead, it would make the code more readable. ``` python @contextlib.contextmanager def register_lookup(model, *lookups): try: for lookup in lookups: model.register_lookup(lookup) yield model finally: for lookup in lookups: model._unregister_lookup(lookup) ```
This is very much work in progress. I think we should move the lookup registration to some other place (django.db.models.**init** perhaps) to avoid circular imports. The lookups <-> fields circularity is a bit nasty to have.
I don't have any preference here.
Definitely -- a place specifically designed for preparing the module is needed. It'll also help 3rd party backends that need to override specific as_sql methods.
add period and `# The value from the form's initial data is used.`
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
please multiline the string ``` '<select id="id_f" name="f" disabled><option value="J">John</option>' '<option value="P">Paul</option></select>') ```
Yes, in case of a failure it gives an easier to debug message.
Can you use `ModelState.from_model()` here, please, as this is what the migration framework will use internally.
Can you use `with self.assertRaisesMessage()` here instead of a bare try-except, please.
Yeah, makes sense, now that I read the code again.
"Create" with a capital c
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
If you want to respect the user ability to choose their failureException ( https://github.com/python/cpython/blob/master/Lib/unittest/case.py#L357 ), you can use ``` python self.fail("Not resolved metaclass conflict") ``` instead of forcing the AssertionError. Other thought : by doing this, you may lose all the details of the original `TypeError` exception which might prove useful for debugging when the test fail (but I'm less sure about this one since I'm not sure what might trigger the `TypeError` in the first place).
Shouldn't mixins be to the left of the base class `models.Model`? This is my understanding of how mixins on class-based views work anyway.
a name like "create_data" seems more semanttic.
create_initial_data and create_big_data below
I'd omit the second "inner_method" since it's not meant as a backwards operation and not used as far as I can tell.
You can use `assertRaisesMessage`.
for new code we're using PEP257 verb style "Return..." "for related field referencing to this" isn't grammatically correct.
`from django.utils.six.moves import range` (move from other file to fix flake8)
I don't think `'site' in locals()` is acceptable. How about `site=None` to start and then checking if `site is not None` here? A regression test and a Trac ticket are also required.
I'd omit the . before 'get'
could we inspect `query.order_by` instead? Maybe it's fine as-is, but that seems a bit less fragile.
"since we add a nicely..." (make one sentence)
no blank line
Please use this style for docstrings: ``` """ ... """ ```
no blank line
no blank line
Please use: ``` msg = ( "..." ) with assertRaisesMessage(ValueError, msg): ``` to make the test easier to follow.
This needs an order_by clause so that the results are guaranteed to come back in the right order.
longer line is fine so you can use same style/indentation as others
use a single line
use a single line
I think this should be an error rather than a warning.
Don't really need this function I think. It's easy enough to decorator other functions if they're added (as in django/core/checks/security.py)
"The SESSION_COOKIE_NAME and LANGUAGE_COOKIE_NAME settings must be different." (don't think the hint is needed as it's just repetitive)
no need to specify `obj=None` I believe.
Please break this down into a couple of lines to make it easier to read. Also, the `distinct` call should be unnecessary for this bug, and only introduces extra work that distracts from the main problem.
It would be fine to put these on a single line `{'publisher': 1, 'count': 1}`
I'd prefer a test name like `test_nonselected_annotations_not_in_groupby`, to clarify the purpose of the test.
A style that didn't require so many lines and use non-4-space indent would be more consistent with the rest of the code. Something like: ``` vals = list(Book.objects.annotate(xprice=F('price')).filter(xprice__lte=30) .values('publisher', 'contact').annotate(count=Count('pk')).values('publisher', 'count') .order_by('publisher')) ```
use single quotes
add trailing comma on kwargs
In fact, maybe the tests could be refactored to use a loop and list of options for each iteration like filename and mimetype.
seems like a helper method to get the attachment path would save some repetition
The commas aren't necessary in the docstring sentences.
I think we should have a test and handling for the case where `mimetypes.guess_type()` returns `None` as done in `_create_attachment()`.
Use the context manager version of `open()` so you don't need to worry about closing it manually.
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
like to use `assertRaisesMessage` to ensure this is the SerializationError we expect.
Can you drop the user argument, please. You already gave all information in `self....`.
use isort to sort imports
seems like this line should be in an else branch (i.e. it's currently not applied to things with allow_tags=True)
I don't think it's possible to hit the second deprecation warning. `on_delete` needs to remain a kwarg so it's optional, but after that, something like `models.ForeignKey(Question, 'pub_date', on_delete=models.PROTECT)` will raise `TypeError: __init__() got multiple values for keyword argument 'on_delete'`.
kwarg -> arg
Sounds okay. The warning should be updated to say something like "Pass to_field as a kwarg instead of as an arg."
`"on_delete will be a required kwarg for %s in Django 2.0." % self.__class__.__name__` I assume this should apply to `ForeignObject` as well.
Is this link needed? Seems a bit out of place for the warning.
The easiest solution might be to duplicate the warning in `OneToOneField`.
stacklevel 2 isn't useful when the warning is raised for OneToOneField. Ideally we could have stacklevel=3 for that case to give `question = models.OneToOneField(Question)` instead of `super(OneToOneField, self).__init__(to, on_delete, to_field=to_field, **kwargs)`.
use `django.utils.version.get_docs_version` in place of "1.9" also please limit lines to 119 chars
Could be useful to say `Pass to_field='{2}' as a....` and add `on_delete` to the format
I think this second sentence could be removed
Thanks for the clarity, Tim :-) In that case, I think we may as well still go ahead and provide the deprecation shim and warning that we are able to provide (for `ForeignKey(SomeModel, 'to_field')`, which is likely much more common) by shortening this line to just `if not callable(on_delete)`. And we'll just have to rely on a backwards-incompatibility note in the release notes (that you should no longer pass `to_field` positionally, and you can pass `on_delete` as the positional second arg) to help anyone who is doing `ForeignKey(SomeModel, 'to_field', on_delete=models.WHATEVER)`.
Actually it should be `if on_delete and not callable(on_delete)` -- or just turn the `if` into an `elif`.
It could be moved to right after `from_fields` and `to_fields` (it can't go before them because they are actually required and have no default). But IMO there's not much value in this; `ForeignObject` is not public API, and almost nobody (except maybe Django developers, or someone working on some custom type of relational field) types its signature directly. But because it's not public API we're also free to rearrange its signature as we see fit, with no need for a deprecation path, so I'd be fine with moving `on_delete` earlier in the signature.
Well, there are a number of existing cases of docs URLs in user-facing messages (especially in migrations, but other places as well). I think there is a lot to recommend them from a UX perspective; someone who gets this warning is quite likely to in short order need a reference of the available `on_delete` options. I don't think the URL-going-stale issue is that big for a deprecation warning, which has a limited lifespan anyway. If someone does happen to rearrange those docs in the next couple years, we'd just update the message. (Like the ones in migrations, the message should use a Django-version-specific docs link, not the `stable` redirect, so that for a given Django version the link shouldn't ever go stale.)
This is a nitpick, but `on_delete` is not an attribute you set, it is an argument you pass. I think that second sentence could just be removed. What might be more useful here is a stable link to the `on_delete` docs.
Well, we _could_ make `on_delete` an actually-required arg to `ForeignObject` right now, and move it even before `from_fields` and `to_fields`, but that would require duplicating the deprecation warning in both `ForeignKey` and `OneToOneField`.
Yes, I'm also thinking that might be simplest. It makes sense that deprecation warnings occur in the public-API class, not in an internal base class. And this doesn't really save us any duplication anyway, since `ForeignKey` still has to duplicate the warning.
Oh, you already have the warning in `OneToOneField` also? Then I see no reason at all to keep this warning here. Just make `on_delete` a fully required arg to `ForeignObject` with no default, and get rid of this warning.
please use `assertRaisesMessage` to verify this is the `TypeError` we expect (also helps for tracking which tests map to which code).
It seems you will need to vary this part of the message based on Python 2 or 3.
How about something like to cover both cases: ``` python func = getattr(obj, name, None) if name and not callable(func): raise ValueError("The keyword...") ```
use single quotes
You could, just seemed easier not to have nested if statements.
It's this part that I think needs to be changed (line 24): > 'func' is a function at the time it is passed to _dec There's no longer an argument called `func` that gets passed to `_dec`.
I think the filename isn't important so I would just use `_, filename = tempfile.mkstemp()`. Since temporary files are created inside a django_XXX directory by runtests.py, I don't think cleaning it up is necessary.
`to_python` should _not_ be called here.
Correct - there is a significant performance improvement when no fields need a converter (defined in the db backend or as `from_db_value`). Arguably it would be nicest if `ArrayField` only defined it when it was needed, but this would cause inheritance issues so I'm happy for it to be there all the time.
According to Django docs: > If present for the field subclass, from_db_value() will be called in all circumstances when the data is loaded from the database, including in aggregates and values() calls. > to_python() is called by deserialization and during the clean() method used from forms. https://docs.djangoproject.com/en/1.8/howto/custom-model-fields/#converting-values-to-python-objects [Here](https://github.com/django/django/blob/8047e3666b0b50bb04e6f16c2a4fb21ddfd5713f/django/contrib/gis/db/models/sql/conversion.py) you can look at from_db_value implementation
The docs say, "For performance reasons, `from_db_value` is not implemented as a no-op on fields which do not require it (all Django fields)."
Wouldn't be nicer if `from_db_value` was declared on Field? Then you can call `from_db_value` without checking `hasattr`
Why do you fallback to `to_python` method? It's kind of unexpected, since normally `to_python` isn't called from `from_db_value`
I would call it somethign like `BookFkAsPk` so it's more descriptive about the purpose of the test model.
If possible, it would be nice to verify the query results instead of using this try/except pattern (which hides the traceback and makes a test failure more difficult to debug). Not sure if there's a good reason for the previous test using the pattern. The only thing I can think of is cross-database compatibility.
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
I've just tested, and ordering by count is fine, provided you switch the order of expected to: ``` {'rating': 4.0, 'count': 1}, {'rating': 4.0, 'count': 2}, ``` To remain consistent, let's order the first test by `count` also.
Please change to `field = self.annotation_select[name].output_field`. `output_field` is part of the expressions API. The field property is there for backwards compatibility with older code.
using `Lower` seems more readable
You should probably inject `*sys.exc_info()` here as well.
Since `LOCALE_FILENAMES` defaults to an empty list I'd suggest you make `domains` unconditional append it to `['django']`.
use the `timezone.override()` context manager
Looking at the parallels between `localtime` and `localdate` again, I wonder how `localtime` ought to behave when `settings.USE_TZ` is `False`. Seems like it ought to just return `datetime.datetime.now()` (that is, the naive current local time) when `value=None`. I think this could easily be accomplished by just calling `now()` instead of the new `_now_utc()` helper. When `value` is set and `USE_TZ=False`, I guess perhaps `localtime` should just have no effect? Or just raise an error? But any change here would be backwards-incompatible, so perhaps not worth it.
As noted above, `localtime` only works when `USE_TZ` is `True` at this time. There is even a test for this. A straightforward implementation of `localdate` as `localtime(...).date()` will have the same restriction and thus be consistent. It may be useful to make these functions fallback reasonably when `USE_TZ` is `False` for the benefit of pluggable applications. In that case, `localtime()` should return: 1. `datetime.datetime.now()` if no `value` is provided 2. `value` if it is provided and it is naive 3. (probably) an exception if `value` is provided and it is aware The third point is debatable. I tend to be strict in what my code accepts, which may not be a best practice in Python but prevents silent data corruption. It's easy to slip and manipulate the wrong type accidentally when time zones are involved... No changes will be needed in `localdate`; it'll get a consistent behavior automatically if we make these changes to `localtime`. In any case, that should happen in a separate commit.
Yes, I know. I was suggesting that to parallel `localdate`, `localtime` with no `value` when `USE_TZ=False` should return `datetime.datetime.now()` (the naive current local time). I think this may still be a valuable parallel, even though calling `localtime` with a naive `value` does not work. But I don't feel strongly about it. Curious what @aaugustin thinks.
If it's changed to return naive current local time when `USE_TZ=False` (as discussed above) that should also be mentioned here.
This docstring could use another sentence explaining the new `now` functionality. Something like "If the `value` parameter is omitted, returns the current time in the current timezone."
Yes, that's what I was suggesting. Distinct PR / commits aren't a big deal. In fact, if I was writing the code, I'd create two commits, one to improve `localtime` first and then one to add `localdate` but that doesn't matter much anyway.
Isn't there a risk of this doing a database query? That doesn't seem acceptable. Can't we first check the plain FK attribute (i.e. `field_id`), and only check further if it is `None`? If it's not `None` then clearly the assigned object had an ID. If it is `None` then we just need to see if there's an unsaved object in the "main" attribute or not.
I guess this is not strictly related to the primary purpose of the commit (as in, the functools case would work without this)? If so, it would be better to make this a separate ticket and pull request for clarity, and it also needs its own test.
Use a `set` literal here.
You'll need to order your imports to appease isort here; `functools` comes before `math`.
format used by DjangoJSONEncoder is
Compare with [L49](https://github.com/scop/django/blob/testdb-destroy/django/db/backends/base/creation.py#L49) and [L207](https://github.com/scop/django/blob/testdb-destroy/django/db/backends/base/creation.py#L207). I think we should aim to do the same everywhere. Perhaps even factor out a `_database_display_str()` method.
Are all the methods required? My intuition is that `allow_migrate()` would be sufficient for testing.
could we use `with mock.patch.object(connections['default'].validation, 'check_field')` as done in the other test? I think it's a bit cleaner than the current approach (which was done when we didn't have mock available).
Why is it necessary to register a separate lookup for Year type? Isn't it possible to reuse common lookups in a generic way? In other words, using lookup Gt lookup linked with Year transform.
a misspell? SQLFuncMixn -> SQLFuncMixin
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
I was asking as major databases support year extract functions, so year comparing can be done as consequent joining of a transform and standard comparison lookup. So, creating YearGt and etc lookups will become really unnecessary if year transform will just convert datetime to a year representation using EXCTRACT, YEAR or STRFTIME calls (depending on database).
What was the importing done for inside method? Looks like a hack, should import django.db.models.lookups module instead if having cross importing problem.
The problem is that an expression like extract(year from datefield) = 2015, then the DB will not be able to use indexes on datefield. But if you instead have datefield >= '2015-01-01' and datefield < '2016-01-01', then the db can use indexes. This is the underlying reason why we have the special year lookups.
I guess we could remove the mention of Oracle and just say "for databases which limit..."
I think it is a mistake Lookup is a subclass of RegisterLookupMixin. Because registering lookups or transforms on a Lookup doesn't make any sense.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
for new code, we are going for PEP 0257 verb style "Find ..."
For clarity here, shouldn't we use `Func` rather than `Transform`, since they are equivalent and the latter is a back-compat-only name? It seems like using `Transform` might suggest to someone reading this code that there's something distinct about `Transform` as opposed to `Func`.
I'm not sure about this change. Why do we suddenly need to support non-iterables passed to `range` or `in` lookups in this PR? This could break code that currently works, if someone is passing an instance of a custom iterable class to `range` or `in`.
This could be extracted too. Also it's a pep8 warning on the latest pep8 - apparently you shouldn't assign lambdas and should use `def` instead.
I _think_ that `Ref` will also need to return True, since it is a named reference to an existing `Col`.
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
I can confirm it is (I tried writing this patch a few months ago)
F() expressions aren't the only ones that can refer to other columns in the query. How about Q(other_field__isnull=True). Also, expressions are free to resolve columns of the query without using F-expressions. We need some other way to know if the expression refers to columns of the query. Maybe we could first resolve the expression, the check for Col references? That might be better. The check should be done in the expression, so that the expression tells Django if it is referring to any columns. Making the compiler guess this is the wrong way in my opinion.
Inner functions are slow, especially for pypy - best to extract this!
I didn't actually expect, or mean for you to benchmark it, as either is "fast enough" IMHO. I simply didn't notice the trailing comma on L24, hence my assumption it was just one message (in which case _I'd_ consider it more idiomatic to use `append`)
This line is related to the `save` method, and should sit beneath it, rather than the new `get_updated_model` method.
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
please create the list separately so as to limit line lengths to 119 chars. ``` logins = [ self.super_login, ... ] ```
please limit line length to 119 chars so horizontal scrolling isn't required to view the patch.
This docstring should be customized for the purpose of this test (it looks to me like it's copied from the other test).
I don't know that "invariable" is the best word -- actually, I didn't know it was a word. I'll try to suggest something if you don't have any alternatives.
no need to logout at the end of a test -- this is done automatically for each test
Use `showmigrations` instead of `"migrate", list=True` which is deprecated (we seem to have a bug in `@ignore_warnings` that causes it to leak state as the tests should catch the use of deprecated features and fail).
usual style is to put the ticket number in parenthesis at the end of the sentence
If `squashmigrations` could check for replacements, that seems ideal, but not sure introducing the executor into that command is a good idea.
I see the parallel to how they are assigned in `WSGIRequest`, but still I would put them on separate lines here.
Please use hanging indent: ``` self.assertEqual( set(request.META.keys()), {'PATH_INFO', 'REQUEST_METHOD', 'SCRIPT_NAME', 'CONTENT_TYPE', 'wsgi.input'} ) ```
Do you think `None` is better than an empty string / empty dictionary, respectively? A few other edits: https://dpaste.de/G9P3
Since everything is forced to `six.text_type` below I think it would be safe to skip the serialization for `dict` values. e.g. ``` python if not isintance(value, dict): try: value = json.loads(value) except ValueError: ... ```
conslike -> like_constraint_field_names? also, assertions could be moved out of the "with" statements.
Please add a docstring: ``` """ ArrayField shouldn't have varchar_patterns_ops or text_patterns_ops indexes. """ ```
I guess it's up to you. If you want to fix them all in another commit, okay. Feel free to merge the patch.
I have been in the habit of omitting the "Tests that" prefix and simply stating the expected behavior.
I'm always wary of putting assertions inside loops and if-statements because you're never certain they are executed. If you added a counter and an assertion that `count==1` after the loop, that would be defensive.
Any reason not to use a list comprehension? I think that's usually more readable.
This should be replaced with `@isolate_apps()` as done in a08fda2111d811aa53f11218fa03f3300dfff4cb.
add period at end of sentence
no blank line please
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
I see, thanks!
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
json.dumps(). (add parens and period)
would be -> is
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
May be simpler? ``` match = re.match(r'^\d+', name) return int(match.group()) if match is not None else None ```
You can use the `with translation.override(obj.language_code)` context manager to simplify it.
Yes, that's good. Suggested wording: If `subcommand` is missing due to misconfigured settings, the following line will retrigger an ImproperlyConfigured exception (get_commands() swallows the original one) so the user is informed about it.
Do you envision more complex behavior than returning a custom class? If not, I wonder if `get_bound_field_class()` would be simpler.
simpler suggestion: ``` """ Return a BoundField instance that will be used when accessing the form field in a template. """ ```
I was thinking: ``` python def bind_to_form(self, form, name, **kwargs): return BoundField(form, self, name, **kwargs) ``` but I'm not convinced this is a good practice for a "just in case" scenario, so we can probably drop the idea.
My feeling is that mock should used as a last resort where other ways of testing don't work. Any thought about this? For example, if I'm looking at the tests to see how to use this feature, it won't really be clear with the mocked version.
Seems fine to rename everywhere, but it seems out of the scope of this PR to touch `BoundField.__init__`.
I wonder if we might add `**kwargs` to the signature of this method and `BoundField` to allow for future expansion? (In the past, there have been some instances where we've wanted to add additional parameters and we have to add non-trivial backwards compatibility shims to allow that.)
Return ... (I think this can be flowed onto the previous line too)
It would nice to have some example to justify the "more flexible" approach. Alternatively, instead of having a method to return a class, it seems sufficient to have an attribute on the form Field: `bound_field = BoundField`
I think you could simplify this a bit by using `self.client.login(self.super_login)` and the ORM to create the initial objects instead of the add view.
please limit docstrings to 79 characters and add period
I'm unsure the purpose of `ugettext_lazy` here.
please revert whitespace addition
I suggest to call the variable `changed_fields_labels`.
please limit line length
I'm not so sure `name.lower()` is correct. Hopefully there is a more canonical way to get the name of that accessor.
Consider `isolate_lru_cache` -- that seems to make it clearer that it clears both on enter and exit. Don't mind if it's not changed though.
I would put this in the docstring "This method is decorated with lru_cache because it's performance critical..."
I guess the only reason not to combine this if statement with the previous one is readability? Don't have strong preference about it.
Is `plan` meant as the second argument? Looks like we're missing a test for this branch.
That code is marginally longer, but I think it's clearer. I'll leave it up to what you think is best though.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
We've been using "Take / apply" verb-style in new docstrings.
Migrations plans with both forwards and backwards migrations are not supported.
Don't really need the ticket reference I think.
`Also include shadowed fields of the parent class.` (can move to previous line I think)
"Also include shadowed fields of the parent class."
This could mask actual errors if the referer is on another domain but happens to have the same path as the missing page. I think the correct check is to compare the referer with a rebuilt URI including the scheme and domain.
I don't think we should have that here
You don't need this `pass` anymore.
no comma chop "itself"
Try to write a docstring so that looking up the details in the ticket isn't necessary. Include the ticket reference only if it's an obscure issue that would benefit from the additional context provided by the ticket.
There are problems on Windows with this line "The process cannot access the file because it is being used by another process." I think we have had similar issues before -- maybe you can search for some history if it's unclear how to solve it.
A dictionary mapping domains to extensions could be useful in avoiding if/elif.
use `open()` as a context manager instead of try/except.
this could use the indent style of the previous `CommandError`.
no `u''` prefixes on strings please
I'd suggest to remove the :param: stuff in the strings you've touched as that's not really something we've adopted throughout the code base.
return directly, no need for `path` variable.
To make this backwards compatible with older Django versions, `extra_email_context=None` should be the last item.
This test needs to cover the case where this line is inadvertently removed (i.e. should test that the extra context values can be used in the email template). Also, `extra_context` should be merged with `context`, e.g. `context.update(extra_email_context)`.
It would probably be less confusing if this were `dict(greeting='Hello!')` so we don't have so many parts called "extra_email_context".
`opts.update(extra_email_context)` (since `extra_email_context` is a dictionary)
Instead of "Testing that..." try to state the expected behavior: "extra_email_context should be available in the email template context."
You could replace the two assertions with `self.assertRedirects(response, '/custom/', fetch_redirect_response=False)`
I understand but `dict` keys are not like JavaScript objects properties, they don't have to be string as long as they are hashable. Here you can use `key is not None` and avoid the `str()` conversion. Give it a try locally.
I still don't understand why `key is not None` is not working here.
Does Simon's suggestion not work? If not, I don't understand why not.
You don't need to call `keys()` here, iterating over a `dict` yields its keys.
If the `edges.get(None, ())` call above works comparing `key` to `None` here should also be working. I also don't know any other Python object which `str()` representation is `'None'` that are not `None` itself.
A more succinct version might be something like: ``` python for key, subroots in self.edges.items(): if key is not None: for root in subroots: roots.extend(self._nested(root, seen, format_callback)) ```
To keep backwards compatibility, we need to add `enclosures=None` after `updateddate=None`.
use hanging indent please: ``` raise ValueError( "..." "..." ) ```
The layout should be something along those lines ``` python for enclosure in item.get("enclosures") or []: handler.addQuickElement("link", "", { "rel": "enclosure", "href": enclosure.url, "length": enclosure.length, "type": enclosure.mime_type }) ```
please use `assertRaisesMessage` to verify it's the `ValueError` we expect (also makes the test easier to read and debug).
add trailing ,
chop blank line
Seems these classes need something like `feed_type = feedgenerator.Atom1Feed` if you want them to be atom feeds.
Perhaps something like `allows_not_any`, `allows_empty_choice`? The distinction here isn't "this has a python `None` value", it's a "none of these are included, because the relation is an empty set". Perhaps a docstring along those lines would make sense here, too? Eg. ``` """ Return `True` if a "(None)" choice should be included, which filters out everything except empty relationships. """ ```
Gotcha - entirely possible that the public `null=True` behavior is solely for M2M fields, yup. That's where I ran into it when upgrading REST framework to pass existing test suite against master.
Please wrap docstrings at 79 chars.
Please use hanging indent to make better use of line lengths: ``` python inline_re = re.compile( r"""^\s*trans\s+((?:"[^"]*?")|(?:'[^']*?'))""" ) ```
came case names is only for assertions
We like to include trailing comma on the last item in a dict so if more items are added later, we don't have to modify this line again.
I suppose it would be nice to remove this from this changeset to keep the diff clean and instead submit a separate cleanup that does this for all admin.py's.
Actually, since that's totally unrelated to the actual change, can you revert your change, please.
While you're around, can you use the following style: ``` python return TemplateResponse( request, self.change_user_password_template or '...', context, ) ```
well, I'd suggest to revert this change entirely as it's unrelated to the patch.
1. Please try to refrain from making unrelated cleanups like this (when otherwise not touching the code) as it's confusing with looking through commit history. 2. ModelClass instances -> ModelAdmins and Fix -> Fixed in the commit message 3. Thanks!
I wonder if this initialization needs to be done in `setUpClass()` or if doing it at the class-level would work? ``` class DateInputTest(WidgetTest): widget = DateInput() ```
I don't think adding this line has anything to contribute to the commit. I'd just stick with the first line of the docstring. If you want to include the issue number I usually go with preceding it to the docstring: `#25252 - Running select_related() ...`
I think `ValueError` is the more appropriate error here. As you've pointed out in IRC though, other examples, like `delete()` and `only()`, use this exact logic and raise type errors. It's better to remain consistent. I don't think we should change the others to ValueError either, because that'd break user code for no real gain.
Lets also test that `values_list()` throws the same error. You can do it in the same test method.
Using `elif approximate >= ApproximateWith.YEARS:` and keeping the final `else` clause as is would remove a nesting level.
If you could add `# for allow_tags deprecation` besides this line and the others `@ignore_warnings` in this file, that's helpful when removing deprecated features. Thanks!
format_html(), format_html_join(), or mark_safe()
existing issue, but interpolating `'ff00ff'` seems a bit odd, doesn't it? I'd just include that in the original string.
while you are here, could you move this below the `value` method - it seems to be orphaned from its parent.
instead of sorting these, I'd just put 'multiline_html_allow_tags' on the next newline so that we don't need to modify more than one line when removing the deprecated feature
This should be a new warning, W021.
I don't know that the ticket reference is necessary. We try to reserve it for obscure issues that can't be easily captured in a docstring.
chop "Test that" prefix (and just state the expected behavior)
Hehe yeah, I overlooked it.
This is sorted above the "from" imports.
Both `response` vars are unused.
please limit line lengths to 119 characters like this: ``` '<li class="success">The short message "<a href="%s">ShortMessage_Deferred_timestamp object</a>" ' 'was changed ....' ```
Please use a style like this: ``` python reverse( 'admin:%s_%s_change' % (opts.app_label, opts.model_name), args=(quote(pk_value),), current_app=self.admin_site.name, ) ```
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
add: "in Django 1.9"
Actually this should be `classmethod` for `InlineModelAdmin` and a regular method for `ModelAdmin`.
Now that all provided objects (`ModelAdmin` instances and `InlineModelAdmin` subclasses) are bound to a model I think we could remove the `model` argument from the methods signature and use `obj.model` instead.
single line for this would be fine. I adjusted the commit mesage in the PR title. I think it's better to use "Refs" for follow up commits so it doesn't appear as the main fix for the ticket.
LGTM besides extra newline that fails flake8.
I think this change is inadvertent as now `actual_test_processes()` is unused.
I guess you copied form existing tests, but it would be nice to be consistent in use of quotes (I'd go with single here). Also I think we could omit the blank lines.
suggested wording: `Context.push() with a Context argument should work (#24765).`
I'd put each key/value on its own line and please include a trailing comma on the last item (habit so that if more items are added later, we don't need to change that line again)
Pickling of a QuerySet using datetimes()...
... when QuerySet.datetimes() gets passed ...
You can standardize on 1 space after periods.
It might be better to create a separate test class so you can define the new objects right above it instead of having to reference the classes 300 lines above where the test is.
If you can describe the issue instead of simply "Regression test for #25389" that saves looking up the ticket to figure out the issue.
I think it'd be better not to use models from other applications.
Removed in ea8e7fd989095c1444528c8b9808076985d5ea0a, thanks.
single line for these assertions is okay (we prefer longer lines if it helps readability)
chop extra space after period
chop "Tests that" prefixes, otherwise LGTM. I'm slightly nervous this will create weird edge cases that haven't been tested but I guess that's why it's alpha. :-) (I suggested a simpler commit message in the PR title too).
Update copy/pasted docstrings.
limit line length
I don't think try/except/fail is a good pattern. See 071801ccff970682a799ce754431a3c3ce3d6902 for the reasoning.
This would make more sense in a separate commit cleaning up the entire file, imo.
Oops. Missed the fact that this pattern is not used in django anymore. @scop sorry for making you do this only to undo when core dev comes :)
@MarkusH Cleaning up all the tests like this makes sense of course, but since this particular test is not yet committed and the change is rather trivial - it can be done before commit as well (and serve as an example of a good test later). Besides, cleanup may happen but it might not as well for a plenty of reasons (no resources, unexpected difficulties, etc), so imo it's better to do this now with this particular test. Why should one commit something that already needs cleanup? Hope this makes sense.
flake8 doesn't like the hanging indent here.
Meanwhile, I merged a conflicting patch. I think you just need to remove the quotes from around the star.
from Python, so we quote and substitute parameters manually.
Do we have sufficient test coverage? In particular, I'm looking for a test which verifies this "QUOTE(?)" bit.
I'm not sure if the included traceback will give enough information to debug this, but it seems like a message something like "Rendering `<template name>` raised an exception, so {% include %} will render as an empty string." might be more helpful.
I don't think you need to use the `'template - ...'` prefix here, the log is already namespaced under `'django.template'`.
You want to either pass `exc_info=True` or `sys.exc_info()` here. `exc_info=e` only worked because it evaluated to `True`.
Yes, we should probably add an actual message like you've done here and use `exc_info=True`. Please do it in a separate commit or pull request using "Refs #18773 -- ..." in the commit message (for reference, the commit is dc5b01ad05e50ccde688c73c2ed3334a956076b0). Thanks!
Adding something like this before the loop could help: ``` _bit_undefined() = object() [at module level] bit = _bit_undefined() ```
Do you have time to complete these changes today? Otherwise, I'll try to take care of it before the feature freeze for 1.9.
I think `IncludeNodeLoggingTests` would be a better name.
Unless I'm missing something you don't need to define a class and nest an instance of it in a list to reproduce your use case. Simply passing a callable that throws an exception should do. e.g. ``` python engine = Engine(loaders=[ ('django.template.loaders.locmem.Loader', { 'child': '{{ raises }}', }), ], debug=False) def raises(): raise Exception engine.from_string('{% include "child" %}').render(Context({'raises': raises})) ```
I think a simple `django.template.Context` will do here.
Move this direct module import above `from collections` to appease isort.
Yes, actually, I also wondered if this was a backwards-incompatible change.
Yes, we should definitely reject HTTPS requests with no referrer; otherwise we may as well just remove the referrer-checking entirely. I don't think this PR changes that.
Wouldn't it be possible to have an insecure referer and a secure request? Thinking about the case where you have a separate API.
Yeah, that's what I had guessed, just didn't look into it. So the only thing that's new here is a more specific error message for that case. Nothing to see here then, all good.
No need to use `False` as a default value here, `None` also evaluates to `False`.
Ok I didn't think this through, I assumed that one could add inlines with the add permission. Of course for the author. If you like I can also withdraw my PR to django's repo and do the PR to you branch, so you keep control on this (you did all the work, and you're obviously more experienced than me in this, I just thought you may have no more time to spend on this). Also, I'm willing to backport this patch to 1.9 (or 1.10, but can't wait for 1.11 to use it in my projects). I see you have a 1.9 backport branch too, we may want to share efforts on this. My backport branch isn't in production yet, but will probably be in the two or three weeks. It seems to work well for now.
Hi All, I was a little surprised to see a get_uneditable_fields method in addition to get_readonly_fields. I suppose that provides the best backward compatibility, though it was a little confusing on first glance to have _two_ methods with very similar names. I don't really have a better suggestion though. _Maybe_ a get_field_names() that handles the possibility of declared_fieldsets, and a can_edit() that checks add and change permissions. It makes the code more complicated, but it might be a little more intuitive. Just a thought.
Why `list(set(`? No tests seems to fail if I remove them.
This code ignores the value of `readonly_fields`. I noticed this because it breaks an inline with a field which is defined as a method in the inline itself (and, thus, needs to be in `readonly_fields`). I'm currently using this workaround (there might be a more clever way to solve it): ```python return [field.name for field in self.opts.local_fields] + \ [field.name for field in self.opts.local_many_to_many] + \ list(self.get_readonly_fields(request, obj)) ```
This change isn't correct. The test database name isn't the alias.
Please use this style: ``` with self.assertRaises(Restaurant.DoesNotExist): place.restaurant ```
field.remote_field here too (you may squash your commits when updating, thanks)
As noted on the build failure, "Usage of field.related has been deprecated. Use field.remote_field instead."
For future reference, we are using PEP 257 style verbs for new docstrings "Format...", etc.. Also, it's nice to be consistent with trailing punctuation.
As above, wrap the format in quotes. "Your URL pattern '{}' has .."
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
We usually only include this if there are non-ASCII characters in the file.
As above, wrap the format in quotes. "Your URL pattern '{}' has .."
I'm not too keen on beginning each warning with "In your url patterns, ..". How about "Your url patterns .." ? "Your url patterns have used `include` with a regex containing a '$'. " .. "Your url patterns have a regex beginning with a '/'." .. "Your url patterns have a pattern with a name containing a ':'." ..
`Import json` should be at the beginning/
`{myattr_dec_m, myattr2_dec_m}` looks better to me.
these asserts can be changed to use assertTrue, but it's not really important.
Note that with the two instances you added, there are now 3 instances in the file of almost the same pattern: ``` python try: # Statement can fail when keepdb is on self._execute_statements(cursor, statements, parameters, verbosity, allow_quiet_fail=keepdb) except DatabaseError as err: description = str(err) # Avoid user already exists error when keepdb is on if specific_error not in description or not keepdb: raise ``` I think the 3 instances can be folded into `_execute_statements()` (and your new instances can also print a message when execution fails acceptably, when `verbosity>=2`, like the existing one does).
If I understand correctly "let's delegate..." -> "that will be done in instance.full_clean()"? I'd like to check a few more things later today so you can hold off on that update until I finish review.
Okay, I understand the idea. Suggested wording for this line: "here (assigning None to a non-nullable field), delegate..." I've forgotten exactly what I wanted to check tonight, so I'll return to it Monday. When backporting, you could probably include 681df1aeafb30092430157f7977f713e1ce234ca too in order to minimize conflicts.
would be helpful to explain what the issue is (e.g. how must the polygon orientation be fixed)
Put the ending `)` on a new line.
Can add `from django.utils.six.moves import range` for consistency on py2/3.
Use `from __future__ import unicode_literals` instead of the `u` prefix.
I think the name could be a bit more specific like `include_with_dollar` to prevent clashes with possible future checks that involve include, slash, or name. Maybe a `views.py` for the dummy view so we don't need to define it in every urls file would be an improvement as well (or even something like `lambda x: x` in place of an actual view might work).
Check ticket it's explained there.
suggested wording: "Yield each item in iterable at most once and exclude those that appear in skip_set."
only include coding if we have non-ascii chars
sorry it should be metaclasses instead of metadatas
I don't know if it's public API, but this is Django Models base metaclass, and there is no other way to do it then use it directly.
No reason it was fixed in other places, but this also doesn't change anything here.
Repeating would be quite rare situation, only for classes with multiple metaclasses, so defining new value used only once in 98% of time would be slower in the end.
It seems these could fit on a single file. We could define `args = (str(self.name), bases, body)` to avoid repeating them.
It depends, but it can be public. You can solve metaclass conflicts manually creating class inhertiting from all of your metaclasses, or automatically by using this function (`metaclassmaker` or `six_with_metaclassmaker`), that would do exactly the same new metaclass for you.
start docstring on next line and "Create..."
I think this is implied by the underscore prefix.
Django 1.9 only supports Python 2.7 and 3.4+ so something like `ErrClass = socket.error if six.PY2 else OSError` should be okay.
I think `ValueError` would make more sense here.
Didn't know `__instancecheck__` was never called when `instance.__class__ is self`.
I'd suggest something like: ``` 'You have multiple authentication backends configured; ' 'you must provide the `backend` argument or set the `backend` ' 'attribute on the user.' ``` You can omit the plus sign.
Please use assertRaisesMessage to verify this is the ValueError we expect.
Removing this code now requires us to pass a backend into `force_login` if multiple authentication backends are configured. Was that intentional? It doesn't seem like this requirement is in line with what `force_login` is meant to be. After updating to 1.10, I now have hundreds of calls to `force_login` in my unit tests that need updating. This is an easy mechanical update, but was this commit intended to be a test-code-breaking change in this way? If not, I'm happy to go file a bug...
You can skip the blank lines in these tests as three lines long isn't too difficult too read with spaces.
I'd use a name like `assertBackendInSession`.
As above, use a more descriptive docstring like "The logout view should send "no-cache" headers for reasons described in #25490."
I'd use a more descriptive name like `test_logout_doesnt_cache`.
I think we could just omit the "USER" row if it's not on the request.
Is this meant to do anything? `AttributeError: 'User' object has no attribute 'items'` I don't think it's necessary. Some fields on the user model could be sensitive too. A mention in the 1.10 release notes is appropriate too.
Test for `{{ request. user }}` too.
I think the template system silences the exception -- I just observed that no data appears in the table. Your proposal is what I had in mind.
We don't want to allow database queries in `SimpleTestCase` as the user will leak outside of the test case. I think creating a mock user like this should suffice: ``` class User(object): def __str__(self): return 'jacob' request.user = User() ```
As `remove_stale_contenttypes` doesn't deal rely on migration generated apps you should be able to remove the three lines above.
"as a positional"
Please add a trailing comma.
I think params[:] would be more fitting here. This is more explicit in saying "return a copy", and list(params) could turn something that isn't a list into a list, thus making debugging harder.
I think it is kinda hiding symptoms instead of fixing actual problem. If you will look at this method in django1.7 it is returning `[]` here https://github.com/django/django/blob/e03fe2f6bbad7305146d0e19e5e9a36eda2b982c/django/db/models/fields/related.py#L1344 If you will remove this return, it will fail with the same exception. So, I think it should be fixed not there, but lets wait for some core dev who is more aware of these checks.
Please do not change formatting
I know about pep8. Django codebase is not following pep8 for all cases (https://github.com/django/django/blob/6afa6818fcf25665bbf61f0921c8c8c6fa8f223e/setup.cfg#L7). Also, if you're adding or changing logic it should not contain formatting changes to look cleaner.
That seems convincing, especially if we'll throw out this code sometime soon anyway.
Please do switch to gunicorn, or finally fix this swallowing of errors! You get the "populate isn't reentrant" message also, when your binary dependencies are not correct. I just had this error once again on Arch Linux after updating the system...
Thanks for the link, would be nice to have a ticket for it, probably.
Could we add some complementary method in the apps registry to handle this use case? Ideally, the management command machinery should not have to fiddle with apps "intern" variables.
Another vote for moving this logic into apps as a private method.
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
I would either use `self.assertTrue(Carrot.objects.filter(tags__tag='orange').exists())` or `self.assertEqual(Carrot.objects.get(tags__tag='orange'), bear)` but otherwise LGTM.
Note that this code is most probably going away in the next (post 1.10) version of Django.
What about a field_name like `fk1__fk2__geofield`? Wouldn't then the result be `fk1`? It should be `fk1__fk2` IMHO.
no backends support
It can be returned immediately without `result` variable
You _could_ turn this into a oneliner ... ``` '.'.join([str(int(num)) for num in string.split('.')]) ```
Just state expected behavior instead of "Test...", e.g. "collectstatic --clear should delete broken symlinks."
In what case is this branch reached? Should there be a test for it? I guess you meant `raise CommandError(e)`.
I prefer checking for the expected syntax since "NotIn" can fail in all sorts of ways (for example, if you have a typo in the string).
"Test checks MySQL query syntax"
for kind in ['day', ...]:
I'd use `Article.objects.create()` instead of `.save()`
Oh I missed the fact `datetime_trunc_sql` was used by `datetimes()`. This is fixing the reported use case where `'field'` is a `DateField` but wouldn't it break in the case of `dates('field', 'day')` where `'field'` is a `DateTimeField`? It looks like it wouldn't get truncated at all in this case.
please include trailing comma
Small nitpick, I would use `bulk_create` here. ``` python Article.objects.bulk_create( Article(pub_date=pub_datetime.date(), pub_datetime=pub_datetime) for pub_datetime in pub_datetimes ) ```
new style is "Return all models...". I think the "private API" bit is implied by the underscore prefix, but doesn't hurt to be explicit if you like.
Could we avoid some loops if we had one outer loop? ``` for f in m._meta.get_fields(include_parents=True, include_hidden=True): if f.is_relation and f.related_model is not None and not isinstance(f.related_model, six.string_types): ... ```
Yes, also we loop over `related_fields` again to generate `related_models`.
The interesting test case is this: ``` season_2009 = Season.objects.create(year=2009, gt=111) season_2009.games.create(home="Houston Astros", away="St. Louis Cardinals") season_2009.games.create(home="Houston Astros", away="Chicago Cubs") season_2009.games.create(home="St. Louis Cardinals", away="Houston Atros") season_2010 = Season.objects.create(year=2010, gt=222) season_2010.games.create(home="Houston Astros", away="Chicago Cubs") qs1 = Season.objects.exclude(games__home__contains='Houston') qs2 = Season.objects.exclude(lookups.Contains(F('games__home'), 'Houston')) ``` where the qs1 and qs2 objects should match. The encouraging thing is that the code is trying to call split_exclude(). It might be hard to make this test actually work, the split_exclude() code is pretty big hack, and especially if the expression creates joins to multiple different relations it will be hard to make the current code work properly. But, if I recall correctly, we don't support .filter(games__away__contains=F('games__home')) either.
"model._meta.apps should be used..." seems clear to me.
Can you describe the reason for using 'singular' here and (as an example) not 'plural'? Code looks fine style-wise; I'm trying to understand the issue a bit more since translation isn't my expertise (If you want a review about that).
Thanks -- is there ever a case where singular is empty but not plural? I thought `kwargs['singular'] or kwargs['plural']` could guard against that if it makes sense.
I was thinking we could only skip this test if the system timezone wasn't equal to `settings.TIMEZONE` but it looks like it would require a lot workaround to get things working correctly.
Minor nit, but I prefer stating the expected behavior like this: `# SRS and SRID may be assigned to None.` since all tests are obviously for testing things.
We typically use single quotes for either the inner or outer string to avoid backslashes.
Please use test skipping: `@unittest.skipIf(six.PY2, "Python 2 doesn't support Unicode package names.")`
doesn't make much difference, but I'd use `if six.PY2:`
I guess this could say "doesn't support all the lookups" in case gis_lookups is a list.
It's okay. Probably the issue is obscure enough that a reference to the ticket wouldn't hurt for posterity.
Tests that need to run by simulating the command line, ...
`negative = bytes < 0`
Is there a reason you are using`&minus;` instead of `-`? It won't work in non-HTML templates.
This class was doing some checks about the geometric parameter. It's clear that if we want to accept more widely expressions, it will not be possible to check that like we did it before. However, I'd like to see new tests about what happens when wrong parameter (not geometric or without srids) are passed to geometric functions. We should ensure that the error messages are clear for the developer.
I've created https://code.djangoproject.com/ticket/25629 to track this.
Regarding the implementation, I'd rather have some class variable (`max_expressions`?) checked in base class instead of "dumb" `__init__` methods. To be experimented...
Note that I didn't plea for keeping the functionality. I just said that if we remove that, it should be done properly (backwards incompatibility note, separate commit).
We are mostly targeting 1.10, and if some parts need backporting to 1.9, just suggest it on the PR.
Many thanks for the example. I guess this is the same before the patch, is it? Then we might fix that in a separate patch. That would keep this patch a bit smaller.
Is that removal related to 5f7035cec7d5? If yes, we might commit it separately with an appropriate message.
We use line lengths up to 119 characters when it helps readability. I wouldn't reformat this line when it doesn't have any other changes.
How about keeping setUp the same and making the necessary changes in the new test that needs it? I think that might make the expected test result easier to understand.
It would make the diff less confusing if you didn't reorder the models. You can use `ForeignKey('Employee')` if that's the main reason for the move.
You could add that as an assertion (that is, assert len(lookups) > 0). I think that would make sense - len(lookups) == 0 is an error somewhere in Django's code, that is, it is a condition that really shouldn't ever happen. Anothre thing we could do here is supply the allowed field names, like we do in other cases where lookup fails. But this can (and probably should) wait for another PR.
`with self.assertRaisesMessage(TypeError, msg):`
An invalid nested lookup on a related field raises a useful error.
I'd rather try breaking up the admin_views files into submodules first.
of a model only referred to and don't think we need "and not result in an AttributeError." -- how something crashed at one time isn't important for future reference.
I'd try to be a bit more specific and state the expected behavior like "should raise DisallowedModelAdminToField". Hopefully all of Django doesn't crash. :-)
Move the new arity checking code into `expressions.Func` also.
What about `//www.example.com`? I think this should be allowed.
What's the relevance of this test for ssh://? It seems to already pass before this commit.
Okay, I'll drop that point, however, it seems odd to me to reject an empty scheme even if someone specifies `schemes=['']` (which seems unlikely anyway). I don't know that rejecting this case is important.
What about using an `elif isinstance(m2m_relation, ManyToManyRel)` clause instead and issuing a `continue` in an `else` branch? This looks more safe in regard to third party fields that might exposed them as `many_to_many = True`.
Put the ending parenthesis on a new line and add a trailing comma to `...self.using`.
use a single line here -- lines up to 119 characters are preferred when it helps readability.
omit "Tests that" prefix in favor of just stating the expected behavior
could probably omit some blanks lines
I can't come up with a way to differentiate both instance either. Ideally they would have a similar API.
This change looks suspicious to me and must not be covered by tests since `SortedDict` is not imported from anywhere.
without any arguments
Let's delete that empty line and reorder the lines alphabetically.
I meant -- isn't the call to `localtime` going to raise the same exception as the template engine? Because the template engine calls this function or an equivalent one.
Same remark about ordering here
Thanks for taking the time to run the benchmarks!
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
could this be a separate test method? otherwise LGTM
I think we are missing the `call_command()` here.
Use a `SimpleTestCase` instead as it provides `assertRaisesMessage` and avoids wrapping each test case in a transaction which is not required here.
point -> points
please revert line deletion
Please use hanging indent here and below in `assertEqual`: ``` data = [ {'0': 'a', '1': '42'}, ] ```
I don't think we need a separate test class here.
We're still at war with doctests so I'm not sure this is required.
Added level fix as well
good catch, the second is fixed in https://github.com/fcurella/django/pull/1
I would rather keep the current behavior, but other opinions are welcome. It could be the target of a different ticket.
e.g. I think this should either be a warning or an error.
Add trailing commas.
level should be 'error', not 'info'.
Nice idea, that would also show the possible benefits of using the logging infrastructure.
django -> model
keeping this on a single line is okay (we allow up to 119 characters when it helps readability)
Add a trailing comma.
I think the blank lines could be omitted between the model fields.
no blank line needed before/after docstring or at the start of each test
use the context manager version: `with self.assertRaisesMessage(...):`
I'm not sure I'm a big fan of this error message. "Shadowing" has a specific meaning that may not be clear to everyone. Perhaps something along the lines of "You cannot use the name ... as the to_attr argument, as the model already has a field with this name"
please use assertRaisesMessage to check the message too.
While you're making changes for readability, I would find it best to declare one key-value pair on each line, like you did in the other diff.
Is the complexity of testing with a logger needed? I think a print statement and passing `stdout=StringIO()` to `call_command()` in order to check the value would be sufficient.
Usually just sentences.
No blank line at the end of docstring please.
I don't find this style helpful given the return value is already mentioned in the first sentence. You can incorporate the arg into that sentence too: "Given a relative or absolute path to a static asset, return..."
"version 2.0" -> "Django 2.0." (helps grep)
In general django doesn't allow contrib imports from core, but it might be worth making an exception in this case.
Although ideally I'd like to know what it was intended for before recommending deprecating it.
Wouldn't it be easier to put this check in `StaticNode.handle_simple()`? Also, you seem to have occluded the `do_static()`, which was previously the actual `static` template tag…this means that you aren't handling the `{% static PATH as VAR %}` case any more, I think.
+1. You'll also actually get two warnings, won't you? One for the tag, one for the helper.
"favor", we use US spellings.
no blank line needed
Right, I would create a "Someday/maybe" ticket and give it a keyword of "2.0" so we remember to start the deprecation then.
It might be worth delaying this deprecation for a few releases, otherwise I fear it could become quite annoying if not impossible for third-party packages to adjust their templates to run deprecation warning free and support older versions of Django.
I think you'll need to move this into the function itself, otherwise it looks like the warning will trigger even if you don't use the template tag (that seems to be the reason for the build failure).
Maybe it could be worth to introduce a new type of DeprecationWarning ? Something like `WillBeDeprecatedInFuture`, that would be visible only to Django developers (did not check if it was possible with the `warnings` module though)...
We don't typically use this style of docstring. I prefer if you restructure it as a sentence.
Considering this change isn't targeted specifically at CharField and should work for a variety of fields, it might be good to have some number/integer based tests as well.
My code sucks. Feel free to change in other places.
Using interpolation here would make it more readable IMO. e.g. `"%s::%s" % (sql, self.lhs.output_field.db_type(connection))`
NVM then, I didn't notice it was a pattern used around the file. Let's be consistent here.
Minor issue, but I would prefer using `None` as the argument default, and then using `get_template(template_name or "403_csrf.html")` when loading the template, and then using `if template_name is None` in the `else` clause. I think this is what @charettes initially suggested? The advantage is just that we avoid hardcoding the default template name in two different places.
Yes, thanks for pointing that out. I'll create a ticket to make sure those error views are also changed. In the meanwhile I suggest we do it the right way here.
No need to push a change for this and trigger a CI build, just leaving a note to not commit this line change.
I think we shouldn't silence the exception in all cases here, only when `template_name != 'csrf_failure.html'`. Changing the default value of `template_name` to `None` and actually raising the exception `if template_name is not None` should do.
typo ("templat ename")
@carljm that's exactly what I had in mind when I suggested using `None` as a default value.
happy new year ! yeah effectively finally this is required for python < 3.5 as you explain (I just tested it in an interactive session). I'm happy to open a PR with this specific change so.. should not be too long to come..
I would avoid cloaking the `resolver` variable, I like your `sub_resolver` naming above.
Please open a ticket to track the bug (all non-trivial changes should have a ticket).
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
@knbk I do think keeping everything related to url under a singe module does make the most sense as Aymeric say's.
hmmm.. now I think I'm wrong, you want to only have the first partial func.. `func.func` shouldn't anyway be another partial or else that would be problematic I think, as views have to return something else.. Sorry for disturbance ;)
If we believe that most users of Django won't be able to reverse-engineer or remember the reason for having two distinct modules — and I do — then we should put everything in the same module.
Is there a reason to keep the URL-related APIs split between `django.conf.urls` and `django.urls`? I believe everything should be moved to `django.urls`.
adding trailing comma
adding trailing comma
adding trailing comma
How about adding a `list_filter_sentinel` to the list filter links only if `list_filter_defaults` is used? Then changes like this won't be required, I think.
adding trailing comma
For new code, new PEP257 docstring verb style: "Return..."
Please remove those lines as it will target 2.0.
Please use the helper methods `self.assertOperationType()` et. al.
Sounds good, thanks. Please use the commit message from the pull request title or something similar when updating. Then uncheck "Patch needs improvement" and I'll give it a final review.
Why is the order non-deterministic... a set somewhere? I think we should try to avoid that if possible.
I'd rather not have a reference to migrations in here. Instead I'd prefer overriding the `StateApps` class in `django.db.migrations.state` to catch the `LookupError` and reraise with an amended message.
No need for the `u` prefix, we're already importing `unicode_literals`.
Create a separate pull request or commit in this pull request that precedes the changes for the ticket which makes the import change.
No need to define another attribute. The form class should be accessible as `self.TestForm`.
Please keep cleanups like this in a separate commit or pull request to avoid blaming those changes to a commit which contains new features.
`response.get('Cache-Control')` should do.
Use single quotes to stay consistent with the code above.
Remove this and the following line, `_get_current_token` already sets `CSRF_COOKIE`
Is there any reason you are not using `request.get_port` like above? I also do not like the duplication, can you set `good_referer` before like: ``` good_referer = settings.SESSION_COOKIE_DOMAIN if settings.USE_CSRF_SESSIONS else settings.CSRF_COOKIE_DOMAIN ``` and then simply check on ``` if good_referer is not None and … ```
Yeah, screw that :D in the worst case make it an attribute on the CSRF class, so a user can override it if we go down the route with an extra class.
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
Merge with the line below since you are not using `session_token` later on. Is it actually needed to sanitize the session token? After all the user cannot change it.
Move that below the `csrf_processing_done` -- we do not need to do extra work in that case.
Not sure we want to use `settings.CSRF_COOKIE_NAME` for this. What about `CSRF_SESSION_KEY = '_csrf_token'` just like we do with `LANGUAGE_SESSION_KEY`.
I think the session cookie should be independently configurable. Technically there's no reason we'd need two settings, it would be possible to just have `CSRF_SESSION_KEY`, and use it both as the session key and the trigger to use sessions at all (if it's not set, we don't). Not sure if that's actually better than just having two settings.
All of these empty tests look awkward. I'll try to find a better way to share some tests -- probably along the lines of ``` python class CSRFTestBase(object): # all the common parts go here class CSRFCookieTest(CSRFTestBase, TestCase): # Cookie-specific tests and utilities class CSRFSessionTest(CSRFTestBase, TestCase): # Session-specific tests and utilities ```
`getattr` raises an exception when the attribute doesn't exist and no default is given
Oh sorry, I did mix it up with `dict.get` -- /me goes into the shame corner
`getattr(request, 'csrf_processing_done')` would suffice since `None` is not true.
Hehe :D Thanks, I'll approve now and merge later today after a final testrun
`_csrftoken` please to not collide with user set variables and also use the variable in tests instead of hardcoding
I kinda dislike that `KeyError` spans this much code, but I do not see a nice way around it either. On a minor nitpick I'd also rename `_get_current_token` to just `_get_token` just to be in line with `_set_token`
Please remove it and put it into a module level variable in the csrf module (and start it with an underscore) -- I really dislike settings, especially when it comes to security ;)
Yes, just be careful not to mess up the `else:` case below
Again single quotes
Here we need ``` python elif settings.CSRF_COOKIE_DOMAIN is not None and settings.CSRF_USE_SESSIONS: raise ImproperlyConfigured("When CSRF uses sessions, use SESSION_COOKIE_DOMAIN instead of CSRF_COOKIE_DOMAIN") ``` This, to make sure people don't just forget such settings, which probably express some security assumptions about their deployment.
Why would you need to sanitize something that's already in your session? Seems a bit late...
We could rename `CSRF_COOKIE_NAME` as `CSRF_ENTRY_NAME` or `CSRF_ENTRY_KEY`, and then using it as cookie name if we're cookie based and session key if we're session based. This would be an improvement over the current code, but probably not over separate settings.
Assuming we use something other than `CSRF_COOKIE_NAME` as the session key, `"CSRF_COOKIE"` seems like an odd key into `request.META`.
This looks odd. If `CSRF_USE_SESSIONS`, then the `CSRF_COOKIE_DOMAIN` should be irrelevant, and `SESSION_COOKIE_DOMAIN` should be used instead. We shouldn't get more good referrers then we had before.
In the DutH sprints, @raphaelm and I considered an option to make `CSRF_USE_SESSIONS` default to "use sessions if sessions are being used in the project". We found it a bit too "magical", so we dropped it. Since the default project template does use sessions, and is likely to prefer to use sessions for CSRF too, it would be nice to make this default to `True`. Regretfully, this would introduce a backwards-incompatibility with AJAX code. I suggest, though, that we add `CSRF_USE_SESSIONS = True` to the default new-project template.
add trailing comma
I suggested to remove the blank line because the ) is already providing space.
Or rather, you can delete the assignment from `_get_current_token` and leave the check here.
This should probably be done in the application code by setting `DATABASE['TEST']['MIGRATE']` as described in the ticket.
No one has objected on the mailing list thread, so I think we can proceed with skipping the deprecation.
I think it would be best if these warnings at least named the relevant view which received a bad template name (and perhaps the template name which could not be found, as well). The information can be found in the stack trace (at least the former can, not sure about the latter), but there's no reason not to make it available right in the error message, is there? Same for the other errors.
I suggest you use a constant to refer to the default `template_name`. Have a look at how it was dealt with in #5577.
Looks like Windows isn't happy with the dots. I think something like 'nonexistent' should work.
I think a list comprehension would be more readable.
one more for the single line version
Simply iterate over `constraint.values()` since you don't use `name`.
I would make sure one of the index name ends with `_like` or simply iterate over `constraint.values()`.
This can fit on a single line.
longer lines here are okay, we try to avoid non-multiple of 4 indents
I think `ValueError` would be appropriate here (the problem is with the values passed to the login view).
set, with and without...
We avoid backslashes and use this style: ``` msg = ( "Redirection loop for authenticated user detected. Check that " "...." ) ```
Please use assertRaisesMessage to check the message too. We prefer the context manager version usually `with self.assertRaisesMessage(ValueError, msg)`. I think combining the two tests so you can reuse the `msg` variable would be fine.
for multi-line docstrings we use this style: ``` """ Detect... """ ```
URL should be capitalized
loggued -> logged in keep -> stay
"Stay on ..." (and please be consistent with no spacing around the sentences) Add a period to each sentence too.
please remove added newline
Newline after the open parenthesis, and then just a four-space hanging indent for following lines. Avoids losing so much horizontal space to indentation.
argument -> a GET parameter
I suggest: ``` self.assertEqual( csrf_cookie.value, self._csrf_id_cookie, '.....' ) ```
I don't think flake8 does any checking of docstrings. The 79 char suggested limit is mentioned in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style.
Chop " we"
Is this branch a candidate for removal in some future release? Either way, would be helpful to elaborate on how the backwards-compatibility case arises. I think it's upgrading Django in the presence of existing token set by older versions of Django, but would like t to confirm.
to be -> are
wrap docstrings at 79 characters
`string.letters + string.digits`
Looking at the code changes below in the middleware, I also see no clear reason for not returning a new token here to stay a little bit more compatible to with what we had before.
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
Ahh. Got it. That makes sense. (Seems fine to me if we eventually remove it. Maybe raise a deprecation warning.)
It would allow our "AJAX" method to continue working unchanged: https://docs.djangoproject.com/en/dev/ref/csrf/#ajax
I personally generate the NONCE's on the client side using javascript (so I don't need the token in the response body). It would be nice to continue long term to accept the raw cookie value as a valid csrf token.
I guess it should be `_compare_salted_tokens` (rather than "padded") to fix build errors.
I'd say "ASCII alphanumerics"
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
My understanding is that this shouldn't be necessary as of 9f6b704769ba5bc0daafc25340d3dc28b18d8fb1.
Since this initializer is a public API, I think we need to add new arguments at the end, for backwards compatibility.
I believe these tests belong in `tests/template_backends/test_django.py`.
Please use 4 space indent: ``` templates = [{ 'BACKEND': ... }] ```
No need to reference the ticket unless it's a complex issue that requires additional context of the ticket.
Please use 4 space indent as done in other `self.assertEqual` assertions in the file I mentioned.
Please don't change all the other unaffected lines.
Please keep this on 1 line (we prefer long lines up to 119 characters if it helps readability and avoids non-4 space indent).
no u prefix -- we use `from __future__ import unicode_literals`.
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
We try to avoid starting the docstring with "Test ...". Please rephrase it.
Most of Django could be updated, but I'm torn about whether or not we should do it (increased chance of backport conflicts / less useful git blame).
Use PEP 0257 verb style, "Return True.."
For new docstrings, we are using PEP 0257 verb style ("Call.... and clear...") Below, "Return..."
I think usually we use a try/finally block if this is only applicable to 1 test.
"computed based overviews" is there a missing word? e.g. "computed based on overviews"? I'm not sure of the exact meaning, but probably chop the comma before "or".
I think it'd work if you put the mixin to the left of the base class where it's used.
You mean `super()`? Seems okay to me.
Fair, but we are still in a critical section of code performance-wise.
While my tests suggest that iterating a set is ~8% slower in this case, it is a negligible difference once you look at the whole `_expire_cache` function.
For what I've read about performance, sets perform better when testing membership and lists perform better when iterating over (which seems the case here). To be checked...
Maybe there's a benefit to using `utils.formats.FORMAT_SETTINGS` and adding `USE_THOUSAND_SEPARATOR` to it? For simplicity, even adding `USE_THOUSAND_SEPARATOR` to that list would likely be fine.
I don't think removing this check is the right thing to do.
Maybe this line should be moved out of the try block? I guess `int()` is the only thing expected to raise `ValueError`.
No big deal since it's a test file, but I'd write it as: ``` except ValueError: pass else: queryset |= ... ```
Do we need such a large try/except block? That makes it difficult to spot what statement(s) might throw an exception and could hide other bugs.
please avoid non-4 space indentation
The import should be conditional and the test skipped if enum isn't installed.
Our policy is not to require the installation of requirements and instead skip the relevant tests.
Please use 4 space hanging indent as done in other tests.
It's okay, we have the same issue elsewhere I believe.
Code looks good. Regarding the name, I'd like to make it clear when the truncation happens. For example, I could imagine truncation of decimal places (maybe that happens too). I'm certainly open to other suggestions. We could even add 'silently' to the name. Since no other database (probably) exhibits this behavior, I think it's fine to make it as descriptive as possible.
Here's a ticket about that: https://code.djangoproject.com/ticket/15940
Thanks this sounds good. Perhaps something like `truncates_out_of_range_x` would be a good name.
The semantics of the test still seem odd to me. I think the expected behavior is that an exception is raised so I would expect to see `assertRaises(...)`. Are any backends besides MySQL expected to reach the "else" block. The test is written in such a way that silent truncation looks like the "normal" case.
`self.backend_range` is `(None, None)` so this code isn't run for it.
The Oracle backend is included in Django so we could certainly test that without much difficulty. There are a few different SQL server backends. https://bitbucket.org/Manfre/django-mssql is the main one I know about (it's author is on the Django team) -- it's still being updated for Django 1.8 though.
Ok, I see. Makes it useful for the rare case you want the function both decorated and un-decorated.
Just to be sure, the new implementation is guaranteed to behave the same as the old one? Maybe the docs could call this out "which behaves exactly the same."
If the override is for the whole method, just use the method decorator.
See commit 7d81ee6efc3 for an example of a test needing to simulate command line.
The committer can amend this when merging, but there's no advantage in using restructedtext markup like ":setting:" in docstrings.
I don't think `lru_cache` makes much sense here, the `cached_property` decorator should do the trick.
Simply deindent and remove the `else`.
I think using a `stale` property here would make more sense. It would avoid a function call in some case and would be more consistent with the current `Origin` API. e.g. `loader_name` uses `@property` instead of being called `get_loader_name()`.
The `mtime` kwarg breaks Py2. Is it even used? The only use I can find is a direct assignment to `FileSystemOrigin.mtime`.
Add a trailing comma.
Alright, missed that!
This conditional is not required anymore given the check above.
This will fail with `AttributeError` if `numpy` is not installed.
Suggestion: ``` python raise ValueError( "Subqueries aren't allowed across different databases. Instead, " "force the inner query to be evaluated using `list(inner_query)`." ) ```
is `db_rhs and` needed? `None` is okay to compare to strings.
I guess Article/Category deletes aren't doing anything since you already asserted exists() -> False. Anyway, I think I'd put this in a separate method. `test_loading_with_exclude_app` / `test_loading_with_exclude_model`
We try to avoid non-4 space indent like this. You could move this to `msg = "..."` instead.
single line is fine
"tuple: (set of model classes, set of app_configs)"
Return whether or not the specified....
the wording used for similar options is simply "Can be used multiple times."
wrap docstrings at 79 characters.
Should be replaced with [`assertRaisesMessage`](https://docs.djangoproject.com/en/1.9/topics/testing/tools/#django.test.SimpleTestCase.assertRaisesMessage).
Quote from [PEP-257](https://www.python.org/dev/peps/pep-0257/): > The docstring is a phrase ending in a period. It prescribes the function or method's effect as a command ("Do this", "Return that"), not as a description; e.g. don't write "Returns the pathname ...".
no comma needed
Use direct indexing as done in 1845bc1d1007751a7f65c66aeddc35f032f6bf41.
This could be inlined in `load_label` since it has been used only once.
I couldn't find any old-style class usage relevant to this in Django codebase so we probably could use `type(object)` instead of `object.__class__`.
`()` can be removed.
It would be better to move these two into a separate test method.
This function does two things: 1. Parse labels 2. Re-raise `LookupError`s as `CommandError` I'd probably handle the latter step in `loaddata.py` and `dumpdata.py`. Also, I'm not sure whether changing output of a command is backward incompatible or not(In CPython it's not for example) . I don't think many people rely on exact output of Django management commands.
Unless I'm missing something, `dest='exclude'` is actually not needed, but I see that it's the common pattern in other files in `django/core/management/commands/`.
`CommandError` -> CommandError (no markup)
Then we could slap an `if six.PY2` around it, what do you think? That way we'll know to remove it when we drop Python 2 support.
You're right. We don't have `if six.PY2` for `__ne__` methods anywhere else so let's keep it consistent.
FWIW I made sure we don't forget to remove these methods [when we drop support for Python 2](https://code.djangoproject.com/ticket/23919).
Use `SimpleTestCase` to prevent unnecessary transaction wrapping.
Oops sorry, I missed the import somehow and thought you were using `django.test.TestCase`
I think that we usually don't add a space between comma and bracket.
looks like this is supposed to be "unexpected" from the previous line
You could do this setup in Python. `self.school.students.add(...)`
``` change_url = reverse('admin:admin_widgets_school_change', args=(self.school.id,) self.selenium.get(self.live_server_url + change_url) ```
This doesn't seem to be necessary to reproduce the bug. Just refreshing the page without making any changes caused the select options to clear.
Horizontal and vertical filters keep selected options.... (#22955).
I guess I would say something like "The inner CharField is missing a max_length."
I prefer to include the ticket reference only for obscure issues where additional context provided by the ticket is helpful.
I think there's an `assertIs` method.
This makes makes it not obvious at all that the contents of the `try/except IntegrityError` are properly wrapped in a transaction. This is necessary to prevent errors on databases which actually enforce transactional integrity on errors like PostgreSQL.
I guess I'd put sort this method below the other "can_*" feature (can_introspect_foreign_keys)
This will pass if you have a proxy for a concrete child model and try to access the parent model's custom manager. You need to check if `cls` is a direct proxy for `self.model`.
I would use: ``` self.assertRaisesMessage(AttributeError, "'ProxyModel' has no attribute 'test_objects'"):` TestModel.test_objects ```
Please do not assume a model only inherits from `django.db.models.Model` I inherit from standard python classes as well. Add check for `issubclass(model, django.db.models.Model)`.
chop "type object"
use of one the styles in 04de4369325097472d7ad036dac262555002ba88
We use hanging indent and try to avoid non-multiple of 4 space indent, something like: ``` warnings.warn( "Access to manager '%s' defined on non-abstract base " "class '%s' from child class '%s' is deprecated." % (self.manager.name, self.model.__name__, cls.__name__), .... ) ``` Add something like: "Add the manager to the child class to silence this warning."
have this line use 8 space indent and the `raise` line use 4 space.
This test name mentions multi-table inheritance but the body of the test has nothing to do with it.
I don't think you need this check here. This case will be handled in the for loop. Otherwise you can skip the first item in `cls.mro()` as well.
I think some caching would make sense here.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
My thought was caching the return value in someway (in a dict eg. `self.cache[cls]`) to speedup by not looping over the bases each time a inherited manager is accessed. I would like to hear from other devs what they think on this.
I would do `if mgr_name not in cls.__dict__:`
This one seems ok to me.
Also, the atomic(savepoint=False) is really cheap (no DB action at all) when used inside another atomic. So, the atomic() here makes the atomic() inside save cheap enough to not matter (of course, benchmarks tell the truth).
This may affect query counts tested by `assertNumQueries` in `TransactionTestCase` which should be mentioned in the release notes.
I think this one requires a savepoint, but create() calls save(), and save has savepoint=False.
Indeed this one looks fine. It will have beneficial performance effects if: - ATOMIC_REQUESTS is not in use - `update_or_create` ends up creating an object - the `save` method of that objects does long things like sending email _after_ the write (i.e. once it holds an exclusive lock on the database)
"... final db state after the last state operation, hence ..."
must be in INSTALLED_APPS in order... (chop the second sentence). Try to use a similar style for the other messages too.
Add a trailing comma in kwargs so if more items are added later, we don't have to modify this line again.
While you are touching this, you can convert this to use our preferred indent style of putting the closing parenthesis on the next line.
use a hanging indent style: ``` INSTALLED_APPS=[ 'django.contrib.admin', ] ```
I think there's little need to keep this -- I don't think any other checks are controlled by DEBUG.
could move this to the previous line while you're here
Patch LGTM. Do you think it might be worth removing the code duplication for the `negated` case while were around? It looks we're simply reusing the same logic wrapped in `'(NOT %s)'`.
I think we generally use `assertTrue()` instead of `assertIs(..., True)` in Django.
I think `assertIs` was used because `assertTrue(1)` doesn't fail.
could upgrade this to assertRaisesMessage
Not sure about the status here given the referenced commit had to be reverted, but this at least needs a rebase to merge cleanly.
Did you try to move it to the base class? By the way, I would keep the `_destructor` name if possible, by consistency with `_constructor`.
isn't valid so that we don't pass NULL pointer....
while touching this line, could you replace w/ -> with
I prefer stating the expected behavior rather than "Test that..." since all tests are for testing. e.g. "A language not present in settings.LANGUAGES can be installed/used by a project."
I guess renaming the `fields` variable to `columns` wouldn't hurt here. At first I assumed `fields` was a list of `db.models.Field` and thought there could be an issue with the use of `f.name` instead of `f.column`
I would omit the blank line above each "with", up to you though.
couldn't -> can't
NotEqual (chop s)
no comma since the stuff after "and" couldn't be a sentence on its own
deindent this line and the next line by 4 spaces
cast to list instead of str
The flake8 error is due to missing a space after the comma here. Please use single quotes instead of double.
`assertEqual(list(a), [...])` should be simpler
I think you can apply my test patch and that should be sufficient.
I think backwards compatibility isn't critical here, but a mention in the release notes wouldn't hurt.
This change seems to imply that existing bookmarks will break.
Please use 4 space hanging indent style as seen elsewhere in this file such as `cls.superuser = ...`
no u'' prefixes -- we use `from __future__ import unicode_literals`
don't think you need the explicit list comprehension (drop braces)
as above: ``` return ( ... or ... ) ```
I think (hope?) Python packaging is at a point that if Django wanted to make argon2 the default that it could just depend on argon2-cffi instead of bundling. That being said though, the first mandatory dependency being a C based one might be ambitious, and there isn't much reason to worry about having PBKDF2 as a default. PBKDF2 is considered secure and is a perfectly fine password KDF.
Presumably at some point this change will be released.
Surely you want all of the password hashes in the list of available ones so that people can log in with them? Of course argon2 is unlikely to be out there in the wild, but if someone tried it and then decided to switch back they wouldn't be able to do so by deleting the settings, they'd have to copy/paste the default and re-add it. There's little harm in including it by default afaik. You might not want to have something other than PBKDF2 to be the default though, people might accidently have bcrypt or argon2 installed and not realize it and end up unable to log in if they deploy. Not sure if that's a big worry or not though.
Of course, the above doesn't take into account the availability of the hasher, since PBKDF2 is available (via efficient C) in the stdlib in 2.7.9+ and 3.something+ and can be done reasonably in pure Python before that whereas scrypt, bcrypt, and argon2 will all require an external library (generally C based).
From a security stand point, argon2 is better than PBKDF2 because it's memory hard as well as CPU hard. Security wise argon2 > scrypt > PBKDF2 ~= bcrypt.
Not necessary for this. It could be done as a separate PR if you are so inclined.
As above, please use hanging indent.
no need for "ok" variable.. can return directly.
Our code currently requires the first hasher to be usable, putting it as first and not installing the extension will break (look at `get_hasher('default')`)
The hashers seem to be ordered based on where they appear in settings so I'd move it up.
What is the reason for adding this hasher it after PBKDF2 but before BCrypt? Adding it anywhere but in first position will have no effect anyway. It would only serve to upgrade existing Argon-hashed passwords to PBKDF2e
I think the best argument is "There's little harm in including it by default afaik.". If someone tried using argon2 they can as well adjust their settings, after all they are testing against an unreleased version.
Please use 4 space hanging indent: ``` argon2.low_level.hash_secret( force_bytes(password), ..., ) ```
Please use `argon2.DEFAULT_HASH_LENGTH` here,
Another option could be to refactor into 3 separate test methods that call a common helper method to run the logic currently in the loop. This can be easier to debug than assertions that run within a loop.
1 line is okay --- we prefer longer lines up to 119 characters when it helps readability.
I'd declare this as a `test_params` variable above to avoid the funky indent.
Maybe you could convert `datetime` to `utctimetuple()` and `date` to `timetuple()` here instead. That's the actual type you'll need for `timegm` anyway and you won't have to deal with naive and aware datetime comparison this way.
`max()` handles the `None` case correctly.
Why would the Last-Modified header not be set when it is not found in ALL maps? shouldn't it be set as soon as one is found.. and only NOT set if no last_mod is found.
Ah yes.. I see what you mean.
If I'm not mistaken `dict.setdefault()` is atomic on some version of Python 3 at least.
Three suggestions: 1. Strip `<>` chars and print "lambda". 2. Fallback to the original suggestion proposed in the ticket: Use `callable.short_description` if available. 3. Wrap `for field_name in cl.list_display:` with `enumerate()` and use the index in `_coerce_field_name`. (e.g. field-lambda-1_year) The third suggestion is probably overkill for that case.
please use this style: ``` post = models.ForeignKey( Post, ..., ) ```
Please add a trailing comma
please use the context manager version: `with self.assertRaises(AttributeError):` (there's another ticket open to change existing usages)
It would help to use `assertRaisesMessage` here. I always find it useful to be able to match an error message up to where it's tested.
You can break the docstring close to 79 character and use this style for the ticket reference: ``` """ Ensure that each LiveServerTestCase binds to a unique port or fails to start a server thread when run concurrently (#26011). """ ```
What do you think about standardizing the usage to import each function individually? (here and elsewhere)
You can add an `__all__ =` to avoid the need for `# NOQA`.
"Importing from django.core.urlresolvers is deprecated in favor of django.urls." (don't need to mention the version since RemovedInDjango20Warning appears with the message)
Let's fix the indentation to use our preferred style: ``` python return reverse( 'django.contrib.gis.sitemaps.views.%s' % self.geo_format, kwargs={ 'label': obj[0], 'model': obj[1], 'field_name': obj[2], }, ) ```
Small nitpick but since an empty `list` evaluates to `False` the `len(...) > 0` isn't required and makes the whole check less readable IMHO.
You could use `for else` construct here. ``` python for fixture_label in fixture_labels: if len(self.find_fixtures(fixture_label)) > 0: break else: return ```
Now that we know exactly which base lookup failed we could adjust the `InvalidBasesError` message.
Nitpick but metaclass should be one word.
I think the mixin and `TestCase` approach is more common in the tests code base.
I think we can drop `catch_warnings` and the related assertion.
Please use the context manager version instead: `with self.assertRaisesMessage(CommandError, "No fixture named 'db_fixture_1' found."):`
You don't need a list comprehension here.
I just find `map` sexy, totally worth the loss in clarity. :P
But that would be less pythonic :-)
Could do `all(map(isascii, s))`
This assertion won't fail without the provided fix since `Article.objects.all()` is an instance of `QuerySet` which has a `query` attribute. You should pass a non-`QuerySet` object to `isinstance` instead.
use a more descriptive name
use a single line or use hanging indent (we avoid non-4 space indents)
single line as above
returns->return (use PEP257 verb style for new docstrings)
except if features.can_return_ids_from_bulk_insert=True
This should be in the existing `from .views` block.
explicit -> specified
Maybe a helper method would help eliminate the redundancy of these methods? e.g. `return self._value_or_setting(self._location, settings.MEDIA_ROOT)`
`weak=True` is the default.
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
Oh are we creating the `_like` indexes even when `unique=True`? I wasn't expecting that.
I'm not sure I see a good use case for it. In any case, this check could be relaxed (or moved to the outer `get_response`, outside the middleware chain) later as a separate change (maybe after the old middleware system is gone, which would reduce the complexity of the change).
This is minor, but I'm curious -- any reason to use `[::-1]` over `reversed(settings.MIDDLEWARE)`? I think the latter is clearer, and if micro-optimization is a concern (shouldn't be here), I think it is better, as it just creates an iterator over the original list.
Yeah, and here you could again use the hypothetical `self.inner_exception_handler` context manager. Damn, it'll be nice to clean all this up once old-style middleware is gone!
Same as above; let's leave it alone for now.
Given the concerns raised on the ML I've removed the option of returning `None` from the latest draft of the spec.
Rather than having these two conditionals based on settings, what if we extract a new method that only does view middleware, calls the view, and template response middleware? Then that method can be the baseline "handler" in the new system, and we can have a wrapper method for the old system that does request middleware, calls the new method, then does response and exception middleware. For the sake of discussion, let's say we call the new method `_get_response` and the old one `_get_response_with_old_middleware`. When the old system is in use, `load_middleware could just do`self._middleware_chain = self._get_response_with_old_middleware`; that way the top-level`get_response`wouldn't need any conditionals at all, and all the old-vs-new logic would be encapsulated in`load_middleware`. I think this would make for a clearer separation of old vs new, and that would make the end of the deprecation path simpler too, since the only things that would change would be a) cut out half of `load_middleware`, and b) remove `_get_response_with_old_middleware`.
please use a semantic test name -- ticket reference are reserved for obscure issues that can't be easily described
ticket reference not needed
Ahh since the user is technically logged out redirecting to the actual request will take to redirect to the login page if desired. That looks correct.
I think you should be using `assertRaises` here.
This should be converted to backend generic way of figuring out that a session doesn't exist anymore.
Define a `CookieSessionTests.test_session_save_does_not_resurrect_session_logged_out_in_other_context` method decorated with `unittest.skip` instead to keep `SessionTestsMixin` backend agnostic. See #6203.
When you start with an `ElidableOperation` and you call `reduce()` with e.g. `CreateModel` `reduce()` of the `ElidableOperation` is called which correctly returns `CreateModel`. Whereas `CreateModel` tries to reduce with an elidable operation which is not possible (there is just no handling for that in `CreateModel.reduce()`).
What about this? ``` Returns a list with 0, 1 or 2 operations: the actual operation should be replaced by the list Returns None: the pair cannot be optimized Returns True: the operation doesn't affect another 2 operations when they are optimized Returns False: the operation does affect another 2 operations and they cannot be optimized ```
Exactly, but shouldn't the outcome of the two be the same, regardless of the first operation being a `ElidableOperation` or not? I think the logic is a bit the other way round. The reduction is implemented but not the optimizeable through.
No, it would be admin specific so it doesn't belong there. Just a private API mixin for the Django tests is that I was thinking. It might live in this file, for example.
please wrap docstrings at 79 characters
We could also check `response.context`. Something like (needs to be cleaned up a bit): ``` >>> field_line = [field_line for field_line in [fieldset for fieldset in response.context['adminform']][0]][-1] >>> for f in field_line: print(f.contents()) Brand New Plot ``` This is easier to debug when it fails than `assertContains`.
Actually `assertContains` checks the `status_code` too, so the other assertion is redundant.
fs -> fieldset
My preference is to describe the expected behavior in the docstring and include a ticket reference only if it's an obscure issue that benefits from the additional context of the ticket.
You can reuse the `PlotDetails` model instead of defining a new one as it slow downs the test suite execution.
I think that's fine.
I guess `get_admin_readonly_field()` could take `response` instead of `response.context['adminform']`.
It's ugly either way, but this way might make it slightly easier to debug if the test fails at some later point. ``` python plot_details_field = list(list(list(response.context['adminform'])[0])[3])[0] self.assertEqual(plot_details_field.field['name'], 'plotdetails') self.assertTrue(plot_details_field.is_readonly) self.assertEqual(plot_details_field.contents(), 'Brand New Plot') ``` I guess it we used the pattern more widely, it might be worth some helper functions to make it easy to extract fields without using magic numbers in the indexing.
Return the readonly fields for a given AdminForm. (following verb style of PEP 0257) -- similar for other docstrings
I don't think this assertion is necessary -- if it's None we'll get an error in the next assertion which should be just as easy to debug.
Yes it's related, "%s %s" % [1, 2] will give the error because the array is treated like the first argument of the expected tuple.
To fix the Oracle failure, rephrase this query as ``` CaseTestModel.objects.only('pk', 'integer').annotate(... ``` or even ``` CaseTestModel.objects.values('pk', 'integer').annotate(... ``` I don't have it in me to test myself now, but the issue is that if you don't do one of these, then `annotate()` over `fk_rel` implies `GROUP BY` all the fields of `CaseTestModel`; this model includes BLOBs (`TextField`, `BinaryField`) and Oracle refuses to compare them and so they can't be grouped over. By the way, doing this should also make your test faster on all databases except PostgreSQL (I think), because PostgreSQL (AFAIK) is the only one smart enough to realize that grouping over all the columns is really the same as grouping over the PK.
No need to wrap in `set()`
Oh, I must have missed the `not` in `is not None`. Yes, `.get()` is equivalent.
@shaib, this is your reported ticket -- what's your take on how it should work? Seems to me maybe the check in the executor is more appropriate after all.
I guess so.
Nitpicking: The current migration output uses both `('app_label', 'migration_name')` and `app_label.migration_name` scattered all over the place. I'll open a ticket to use the dot-notation across the board which I find easier to read / write. In the mean time I'd use that format here already.
"... know anything about this migration ..."
What @shaib said: `makemigrations` and `migrate` should fail, `showmigrations` should work.
Can you move the entire block into its own method on the `MigrationLoader`, e.g. `def check_consistent_history(self)` and call that from within `build_graph()`, please.
I don't see why you need to fall back to `recorder.applied_migrations()` here. At the beginning of `build_graph()` we ensure `self.applied_migrations` is set.
Furthermore, why do you construct `unapplied_parents` at all? Can't you just loop over `self.graph.node_map[migration].parents` and on raise an exception when the first one has an inconsistent history? That would safe some time in bigger projects. ``` python for x in self.graph.node_map[migration].parents: if x is unapplied # use the condition from above raise InconsistentMigrationHistory(...) ```
Sounds right to me too.
I think it would be more clear to write "check that there aren't any migrations applied before their dependencies."
I haven't tried it out, but I'm pretty certian this only happens when you use `__first__`: https://github.com/Uran198/django/blob/ticket_25850/django/db/migrations/loader.py#L148 which is silently ignored when adding dependencies given the dependent app is an app w/o migrations.
Ahh, that's gonna be more interesting. You'd need to look at `self.migrations_module(x[0]) is not None` for whether there are migrations for that particular app or if they are disabled.
Yeah, good question. I was confused when I read it the first time but had an idea why it might be enough. But on second thought that doesn't make sense to me.
I'd rephrase that to "Raised when an applied migration has some of its dependencies not applied."
use PEP 257 verb style "Check ... Raise .."
It's a little delicate... neither `makemigrations` nor `migrate` should work at this state, but I think `showmigrations` should work and this breaks it as well.
"its" add period
The reason `makemigrations` should fail is that the more likely reason for inconsistent history is a change in the migrations code (in particular, dependencies), rather than direct manipulation of the database. If the code of existing migrations is suspicious, we should avoid building more migrations on it.
I don't think this is correct. `settings.MIGRATION_MODULES` only contains user-defined migration modules -- presumably want the detection to work regardless of whether or not that setting is defined.
Why would we remove deprecation warnings for Django's own test suite? I think it's a good thing to help us write clean and not obsolete code (I mean by default, without having to specified -Wd).
I think I remember the context. This was a bit complex, but it might be simpler now if we stick with the Python policy about deprecation warnings.
The only other `isnull`filter I could find uses `'True'`. Lets be consistent and use `'True'` and `'False`' instead of `'1'` and `'0'`.
It looks like you made a typo in this name.
The correct syntax is `u'Norwegian Bokmål'` (unless we import `from __future__ import unicode_literals` at the top). It's also fine with Python 3 if we don't have to support Python < 3.3.
This actually returns a class, so the CamelCase is correct.
Use `setUpTestData` now that two models will be used by two methods.
Reverting this change and the one below doesn't result in any test failures. We should have tests for these cases too if they are indeed necessary.
I'd suggest to use a more descriptive test name, otherwise looks okay.
I don't think it's much of a "feature" (if you meant for 1.10) and I didn't see any justification for a backport (if you meant 1.9.2).
add trailing comma so if more items are later added, we don't have to modify this line again.
I don't understand why an explicit `app_label` is specified here. It looks strange to me that this model is supposed to belong to the `exoplanets` application but is created as part of the `migrations` apps migrations.
I wonder if the `isinstance()`condition results in any performance savings? I tend to think always casting might be simpler.
I think `force_text()` isn't needed but rather adding `from __future__ import unicode_literals` to this file.
I'd consider changing this to `if value is not None` - I don't know whether other mappables can be handled lower down the stack? It's an edge case though and may be irrelevant as higher levels would have already rejected it.
Yes -- does this change affect that case.
We should check the behavior with bytestrings too. I'm not sure how PostgreSQL stores them and if the change to force them to unicode will have any practical consequences.
``` # If the database returns a Decimal, convert it to a float as expected # by the Python geometric objects. ```
parenthesis to next line
single quotes for consistency
proxy model and won't ...
We usually put the closing parenthesis on the next line.
I'd use `model._meta.label` (which includes the `app_label`).
It's not a good practice to manually assign primary keys like this. It can cause problems with database sequences.
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
The `pk=1` additions still need to be removed.
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
This should be outside the try block as it's not expected to raise the exception.
You could put `text = format_html('<a href="{}">{}</a>', change_url, text)` in the "else" block, `pass` in the `except` block and then a single return statement at the end `return format_html(label, text)`.
Can you please rename it to `ModelManagerSerializer`. I think you just missed it.
Could you add a message here: ``` python raise NotImplementedError('Subclasses of BaseSerializer need to implement the serialize() method') ```
I think you mean `ByteType`
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
Gotcha! When you replace the `IterableSerializer` with the `TupleSerializer` in the factory you end up with this failing test. I think we can leave it as as. ``` python Traceback (most recent call last): File "/home/markus/Coding/django/tests/migrations/test_writer.py", line 362, in test_serialize_settings ("((0, 0), (1, 1), (2, 4))", set()) File "/home/markus/Coding/django/tests/migrations/test_writer.py", line 187, in assertSerializedResultEqual self.assertEqual(MigrationWriter.serialize(value), target) File "/home/markus/Coding/django/django/db/migrations/writer.py", line 308, in serialize return serializer_factory(value).serialize() File "/home/markus/Coding/django/django/db/migrations/serializer.py", line 46, in serialize format = self._format() File "/home/markus/Coding/django/django/db/migrations/serializer.py", line 303, in _format return "(%s)" if len(self.value) != 1 else "(%s,)" TypeError: object of type 'generator' has no len() ```
Can you please rename this one to `ModelManagerSerializer` and let it inherit from `DeconstructableSerializer`.
In accordance with the naming of `DatetimeSerializer` this should be `TimedeltaSerializer`.
Is this branch tested? No tests seem to fail (I tired SQLite & PG) if it's removed.
``` help_text='Supporting Bands.', ) ```
This should use hanging indent style: ``` python supporting_bands = models.ManyToManyField( Band, related_name='events_supporting_band_at', ..., ) ```
Looks like this should be `p.help` not `span`.
the active language's
I think you need to decorate the test method with `@override_settings` so that the original value value of `ROOT_URLCONF` is restored at the end of the test.
indent style: ``` self.assertEqual( rendered, '...' '...' ) ```
please use hanging indent to make better use of space, e.g. `context = Context({'content': '<b>"Escaped" content to try \'force_escape\ argument & check for errors.</b>'})` might be good here
This test seems to show that double-escaping happens, which is not what we might expect.
no need to reformat
remove trailing whitespace to fix flake8 warning
We try to avoid non 4-space indent. I'd do something like: ``` return ( connection.features.can_defer_constraint_checks and not connection.needs_rollback and connection.is_usable() ) ```
To fix the `unicode` issue, use `six.string_types` instead. https://pythonhosted.org/six/#six.string_types
This code reads a bit funny - is the ContentType to be inserted an instance of ContentType? It might be we don't have anything better for this, but if we have something in the ct._meta that would tell Django directly that this is a migration time model then this line would be easier to understand.
include trailing comma in kwargs
indent style: ``` @override_settings( AUTHENTICATION_BACKENDS=[ 'django.contrib.auth.backends.ModelBackend', 'django.contrib.auth.backends.AllowInactiveUsersModelBackend', ], ) ```
We might need to handle the case of custom users that don't have an `is_active` attribute.
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
We can move the test that involves `login()` to the other pull request.
`not user.is_active` not needed.
use parenthesis around the expression to avoid backslashes
What values would this condition have a different outcome than the current one? `is_active or self.allow_inactive_users or is_active is None`
try to make this as minimal as possible -- if we don't need all the validators, error_messages, etc. leave them out
prefer `setUpTestData` since that executes once per test class instead of once for every method
I'd make this a separate test and then you can decorator the test method instead of using `with ....`.
I guess the method probably isn't needed but if you want to keep it, please fix it like c62807968d7930bfd34afc2036c67921b943592f.
Isn't `is_active is False` redundant? We already check if it's truthy in the first condition so if we get here it must be falsey.
I tend to think of the user doesn't have an `is_active` attribute, it should be accepted regardless of `allow_inactive_users`. Should make the behavior clear in the docs.
as above, state expected behavior in a docstring
single line please
to ensure the a typo in the credentials isn't the reason for the failure, you could create a dict with them and verify authentication is successful before you set `self.user.is_active = False`. e.g. `self.assertEqual(authenticate(**credentials), self.user)`
add trailing comma
State the expected behavior, "An active user can't authenticate."
single line here should be fine
Don't think we need to worry about duplicates.
As long as you use `except Exception` and not a bare `except` this should be good.
This function is not used anymore.
Please give it a try, I'd like to see the new error.
If we remove this will the tests run on Jenkins? It might be fine.
sure, in `selenium.py` sounds okay.
a backward relation
single longer line is okay (we prefer up to 119 characters when it helps readability).
Add period and I usually put the space on the previous line.
Unnecessary white space addition.
I think the idea is `sortable_by = None` is the default case of all fields sortable and `sortable_by = ()` means no fields are sortable.
This doesn't seem correct -- we will call `get_orderable_by` redundantly if it's set to an empty tuple. I don't see a reason not to make `orderable_by` a positional argument and updating the tests.
I'll suggest `sortable_by` as a possible alternative name to `orderable_by`. I think the use case Ramiro suggested would be good to support.
I wonder if allowing users to specify `orderable = ()` would be something worth supporting. If the answer is yes then I suppose we should be initializing this to None so we can distinguish that use case.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
Just use: ``` datetime.utcfromtimestamp(ts).replace(tzinfo=timezone.utc) ``` This will be more efficient. You don't need `make_aware` here because UTC doesn't have DST. Sure, this is a micro-optimization, but I like avoiding overhead at the lower levels ;-)
I believe you can replace this whole block with: ``` tz = timezone.get_default_timezone() dt = timezone.make_aware(dt, tz) ```
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
FWIW I didn't find pytz required, except on Windows, but I might have gotten lucky with my particular configuration.
I used to know what was needed when, but I forgot, so now I'm cargo-culting from tests/timezones/tests.py :-(
This test won't pass when pytz isn't installed. For consistency with the timezone tests, you should declare: ``` python requires_pytz = skipIf(pytz is None, "this test requires pytz") ``` and then decorate it with `@requires_pytz`. This is a minor concern since the docs now encourage installing all optional dependencies before running the test suite, but I suppose it could save some headaches to people running the test suite without a virtualenv. on or systems that don't have `time.tzset` (that is, Windows). Have
``` return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc) ```
We're using PEP 257 verbs for new code "Return ..."
I'm going to try to work on Django tomorrow. I'll try to work on this.
You've got trailing whitespace on this line.
Every day I get to learn something new. Thanks.
My point wasn't the r prefix (I just copied that from above), it was moving the dash next to the close-bracket. But now that you mentioned it -- yes, the first and last (`'\.'` and `'\.?'`) need an r prefix, because without it the strings don't have a backslash in them and these expressions will just match anything. I think a test for this could use some invalid punctuation as the separator for the tld -- e.g. `http://unquoted~dot!`
Strike that: ``` In [1]: '\.' Out[1]: '\\.' ```
The optional trailing dot may "protect" an ending dash -- `xn--.` passes this. Is this intended? If not, switch the last two lines.
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
Also forgot to mention, I don't think I've seen many regex'es written this way before (using string constant concatenation and continuation lines), and I find it pretty neat.
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
`trimmed_something = True` would be more meaningful.
`trimmed_punctuation` would be more meaningful.
Nitpick but use `isinstance(other, Tag)`.
need a trailing comma to appease isort style
Yes, it would be good to add a docstring.
What I meant is, to leave the database in a clean state for other tests, we need: ``` self.assertTrue(Car.objects.exists()) Car.objects.delete() ```
Isn't the `Car` left in the database after this test? It should be deleted here too, I think.
simply this by just stating the expected behavior: ``` """ Initial data should be recreated in TransactionTestCase._fixture_teardown() after the database is flushed so it's available in all tests. """ ```
I feel like we shouldn't override "private" methods to test, I also don't see why that would be necessary here.
I mean you are running only one test anyway, so "running after each test" basically means "running once".
Maybe test it in `tearDownClass()` then? That method is executed after all tests.
The test should be possible by just having two test methods, that each test if the car is still there, shouldn't it? ``` python def test_first_car(self): self.assertTrue(Car.objects.exists()) def test_second_car(self): self.assertTrue(Car.objects.exists()) ``` Then you have the benefit that you don't have to override `_post_teardown()`.
Unnecessary trailing comma and white space.
The test failure is a non-deterministic dict ordering issue within "field".
Not sure either, I was thinking mostly about readability.
I think it would make sense.
This line doesn't need to change. Passing `function='Max'` as a kwarg will do the right thing, since the super implementation will do the mixing of `self.extra` and `**kwargs` for you.
As above. This line doesn't need to change.
I'm not sure that this particular call requires `**kwargs`. Check the actual function definition to see if it will require kwargs or not. I don't think it is overridable with `as_vendorname`.
I don't think this method requires `**kwargs` because it's not part of the expressions API, it just looks similar.
put the closing parenthesis on the next line
Is it best to remove common parameters like `function` and `template`? Seems to me it improves readability a bit to have common kwargs explicitly declared.
Removing `**kwargs` from the `as_vendor()` methods sounds good to me.
I guess the only disadvantage is the possibility to shadow the Python's built-in `copy`. If it's used elsewhere in the file, I'm okay with it.
This should just be `template_params = kwargs`. The `extra` in the signature that was removed is acting like a `kwargs` anyway.
What this should do here is something like: ``` c = self.copy() c.set_source_expressions(expressions) return super(Coalesce, c).as_sql(compiler, connection, **kwargs) ``` The theme here is to stop mutating `self` within `as_sql` or `as_postgres/oracle` etc, which is the major point of adding `kwargs`.
Remove `self.function = 'CONCAT_WS'` and the following line which mutates `self.template` and instead: ``` return super(ConcatPair, self).as_sql( compiler, connection, function='CONCAT_WS', template="%(function)s('', %(expression)s)" ```
Probably not a bad idea, but it does make the implementation slightly more complicated.
It would be better to make these renames in a separate commit since it's an unrelated cosmetic cleanup.
Ok, let's change this to: ``` def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context): ``` You'll need to conditionally add function to extra_context before merging it with self.extra: ``` if function is not None: extra_context['function'] = function arg_joiner = arg_joiner or self.arg_joiner template = template or self.template ``` etcetera. The docs for `Func` will need to call out the extra key word arguments for as_sql specifically.
It's mostly consistent with other copies in the same file, but `clone =` and `copy =` is also used. I think it's probably better to use `copy`.
This method should actually mix `placeholders` with `**kwargs`, which expands the usefulness of `**kwargs` to the `ordering` interpolation variable, but also any other interpolation variables that might be introduced in a subclass.
Yeah I think that's a good idea in general. I was thinking that a general `**kwargs` added to the signature in all cases was probably correct, but I've come around to your thinking. Most uses outside of `Func` expressions just ignore the `**kwargs` parameter and create noise. So this specific call should be (assuming "extra_context" is a good name): ``` def as_sql(self, compiler, connection, template=None, ordering=None, **extra_context): if template is not None: extra_context['template'] = template if ordering is not None: extra_context['ordering'] = ordering extra_context['ordering'] = ordering place_holders = { .. } place_holders.update(extra_context) ... ```
Remove `self.function = ..` and move it to a kwarg of the `as_sql` call below: ``` return super(Length, self).as_sql(compiler, connection, function='CHAR_LENGTH') ```
Remove `self.template = ..` and replace with: ``` return self.as_sql(compiler, connection, template='STATEMENT_TIMESTAMP()') ```
This and one above, replace `self.function = ..` with `function=...` in as_sql method call.
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
more like: `'^%(negative)s\d+(?:%(sep)s%(negative)s?\d+)*\Z' % ({'negative': '(-)?' if allow_negative else '', ...})`
I'd rather build regex string with interpolation so as not to repeat the other logic.
I think `test_decimal_parameter` would make more sense here.
Please move this field to an existing model (`Coffee` should do) in order to prevent the creation of a table for a single test
Unnecessary comma and whitespace.
"cannot" is one word. add period.
no comma needed and you can wrap the docstring closer to 79 characters
Well, I think the staleness issue could be easily addressed by having `Manager.contribute_to_class` invalidate the cache. But you're right, this is probably only worth it if we try my other suggestion of trying to reuse this at runtime instead of re-copying on every access. And _that_ is probably only worth it if we can show that the copying-at-runtime is a noticeable perf regression.
it's weird to me that we have to copy managers both here and in `ManagerDescriptor`. why couldn't the descriptor find the appropriate manager from `model._meta.managers` instead of re-copying it at runtime? Would require tracking managers by name in `Options`, but that doesn't seem like a big deal.
should this be a cached property? seems to do a fair bit of work
It's orthogonal to this PR but this `self._db` in place of just `db` looks wrong.
I usually just end the sentence with "(#26249)." instead of "Regression test..."
Just to make sure, did you account that `STATIC_URL` can be a fully qualified URL? (e.g. http://domain/path).
while you're here, you can use PEP257 verb style "Convert..."
`related_manager_name` not `related_model_name`
Note that ...
Making this a separate variable when it's unused elsewhere seems a bit odd. Also, I guess I wouldn't locate the test here since it's not testing the slice filter.
NVM I realized `default_related_name` uses the `model_name` syntax.
Use `'%s'` to avoid the `u''` prefix in the message on Python 2.
Please revise the try/except pattern in light of 7fec264e46d2a757f06f857e513072d72686cf9d.
no `u''` prefix -- use `from __future__ import unicode_literals` if you need it.
use: ``` msg = ( "Using model name %r in queryset lookup " "...." ) ``` to avoid backslashes.
this goes below `import copy` to fix the isort warning
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
missing period the message could be: "Query lookup '%s' is deprecated in favor of Meta.default_related_name '%s'."
Remove this blank line.
I would assert `len(warns) == 1`.
Implementation looks okay but should still check the response here and check that the "protected" page is displayed.
As you mentioned, the situation could occur when two users are using the admin simultaneously, one deleting the object and the other changing the foreign key. I think redirecting to the intermediate page which informs the user that the object is protected is most helpful in that case.
I'm not convinced we need such a fancy solution -- after all, this is only for users who manually bypass the delete confirmation page.
but -> and
Yes, that's better.
"nonexistent" would be the word
These checks should be run against `engine_cls.template_class` and not `engine_cls`.
This assert can go since we're not using exoplanets anymore.
Testing `load_template` should be enough.
What I meant was keep this test in the original PR (it passes there, right?) and move the other one that uses `login()` to https://github.com/django/django/pull/6124.
You should be able to pass `is_active=False` to `create_user()`.
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
I guess "relooking" is okay as a word without a dash, but maybe we could rephrase a bit: Cache shared by all the get_for_\* methods to speed up ContentType retrieval.
Whatever you think. As for me, I'm more concerned with understanding Django's test suite than using it to provide production-ready code samples. ;-)
I don't mind it as-is then.
or just `# CSS files shouldn't be touched...`
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
Better to describe the desired behavior than have to look it up in the ticket.
This can probably also be cleaned in existing cases but `BaseCollectionTestCase` inherits `BaseStaticFilesTestCase` so it looks like it's redundant here.
Not sure these asserts bring value ... they seem to test that `override_settings` works.
Single line seems fine for this assert. Triple quotes -> single quote should ease line length a bit.
I'd flow this to the previous line.
single line would be fine here
When updating the tests, please use the indentation style of the existing tests, e.g. ``` python self.assertQuerysetEqual( Number.objects.all(), [ '<Number: -1, -1.000>', '<Number: 43, 42.000>', '<Number: 1338, 1337.000>' ], ordered=False ) ```
`An expression` - no need for the `combinable` bit.
Maybe just put these tests in a separate TestCase to avoid useless creation and deletion of companies? Especially since you have two tests doing identical setup of alternate company data.
Usually we prefer for test names to describe the functionality, not reference the ticket. git blame can always be used to get back to the ticket if needed.
For joins, we might end up doing LEFT OUTER JOIN for cases where INNER JOIN would be optimal. I don't think that is a blocker. But if we do a INNER JOIN for a case where we should be using LEFT OUTER JOIN, then the query will produce wrong results. For testing a models structure like ``` class Timestamp(models.Model): at_time = models.DateTimeField() class Event(models.Model): start = models.ForeignKey(Timestamp, null=True) end = models.ForeignKey(Timestamp, null=True) ``` should be tested with range queries, where one or both of the start and end time are null.
I believe this to be broken. It shouldn't be possible for one of the rhs values to produce a new lookup which others didn't produce.
The check should be inside prepare_lookup_value, not in build_filter.
Perhaps I misunderstood Anssi's original intent somehow, but the fact that your filter expression uses INNER joins seems like you're maintaining the status quo at the minimum. @charettes I've just pinged you on IRC but if you've got some thoughts on this I'd like to hear them.
Make this and new_lookups sets.
`resolve_expression_parameter` maybe? You're not really dealing with combinables here (even though they are also combinable), so just go with expression based names I think.
I think what Anssi is asking you to do is prove that the following produces LEFT OUTER joins rather than INNER JOINs. ``` class Timestamp(models.Model): at_time = models.DateTimeField() class Event(models.Model): start = models.ForeignKey(Timestamp, null=True) end = models.ForeignKey(Timestamp, null=True) actual = models.DateTimeField() start_datetime = datetime.datetime(2016, 6, 2) end_datetime = datetime.datetime(2016, 6, 4) actual = datetime.datetime(2016, 6, 3) t1 = Timestamp.objects.create(at_time=start_datetime) t2 = Timestamp.objects.create(at_time=end_datetime) Event.objects.create(start=t1, end=t2, actual=actual) Event.objects.create(start=t1, end=None, actual=actual) Event.objects.create(start=None, end=t2, actual=actual) Event.objects.create(start=None, end=None, actual=actual) # this should produce LEFT OUTER JOINS, not INNER JOIN Event.objects.filter(actual__range=[F('start__at_time'), F('end__at_time')]) ``` I'm not sure what those results will be, but the joins should be LEFT OUTER.
I think this reads better as: ``` processed_values.append( sub_value.resolve_expression(self, reuse=can_reuse, allow_joins=allow_joins) ) ```
Possible I missed something but I'm not seeing any tests failing with this method removed.
could use single quotes here for consistency
It's a shame we register the `__iexact` lookup for all fields. I think `not isintance(..., (models.CharField, models.TextField))` would be more appropriate here.
Are you sure this change is required? From what I can see the `Exact` lookup will make sure to call `IntegerField.get_prep_value` on its right hand side value.
I was considering the question of whether or not the `handle_forward_references` option is needed and trying to think of a way to maintain backwards compatibility. I didn't study this very much, so the proposal might be unfeasible or incorrect.
According to the coverage report, this line isn't executed.
I would either remove this or add a helpful exception message.
According to the coverage report, this line isn't executed.
There should be a trailing comma and the parenthesis goes on the next line as it was before.
`settings.LANGUAGE_CODE` as you pointed out.
include a trailing comma
Return a tuple...
Unfortunately this is not a valid syntax on Python 2. Use `**kwargs` and `get('prefix_default_language', True)` from it.
No need to specify the `'introspection'` prefix here.
Put `ArticleReporter` after `Article` to appease isort.
I tested locally and confirmed the view creation is not necessary. Make sure you don't pass `only_existing=True` to the `django_table_names` call and the test will fail without the fix applied and pass with it.
I think `f.remote_field.through` should always be available.
All m2m fields should have `remote_field.through` defined.
Use the following style instead: ``` python tables.update( f.m2m_db_table() for f in model._meta.local_many_to_many if f.remote_field.through._meta.managed ) ```
You could avoid the two branches with: ``` self._options = params.get('OPTIONS') or {} self._options.setdefault('CLIENT_OPTIONS', {}) ``` on line 27.
Why `getattr`? The `if` clause doesn't use it.
True, it's good practice though cause at some point `_meta.fields` will contain all of the fields.
Same thing with `remote_field` being possibly `None`.
More "ForeignKey" in messages below.
the comma here isn't needed
Here if a field is not a ForeignKey, but have many_to_one=True then it will go through formfield_for_foreignkey(). If that method returns None, then [None will be returned](https://github.com/django/django/pull/6236/files#diff-3c42de3e53aba87b32c494f995a728dfR168) and [db_field.formfield()](https://github.com/django/django/pull/6236/files#diff-3c42de3e53aba87b32c494f995a728dfR178) won't have a chance to be called. In this case, the formfield [will be ignored by ModelForm](https://github.com/django/django/blob/master/django/forms/models.py#L182-L185). Shouldn't we have a way to use the custom field's formfield() method even if it has many_to_one=True ? Note that this concerned is similar to the one raised in #24227
Same as above, let's add `or ct_field.remote_field` to the mix.
This check will pass for a GenericForeignKey, but there is no remote_field in GFK (nor can there be one, as GenericForeignKey's remote field should be every primary key in all models). We need a field.remote_field is not None check here and likely in many other places, too.
I think `opts.fields` filters out GFK unless I read this incorrectly: https://github.com/django/django/blob/96ec67a7cf89a136e793305343c5bba8521cdb47/django/db/models/options.py#L380-L383
I'm wondering about `errors='replace'` here. The function below considers control characters. Is it possible that some of the bad characters we're trying to detect here will be turned into replacement characters, and then overlooked by `_is_safe_url` below? The Unicode replacement character is U+FFFD, which is category "So".
Do you still want to remove this when dropping Python 2? If there isn't something like `six.PY2` will we remember? I guess `force_text()` still has some value in resolving lazy objects but that's not why it's used here. Just wondering...
`@requires_tz_support` skips the test on Windows. Actually these tests work on Windows as long as pytz in installed (tested with SQLite and PostgreSQL). Without pytz installed on Windows: SQLite: `ImproperlyConfigured: This query requires pytz, but it isn't installed.` (as on Linux) PostgreSQL: `DataError: time zone "Eastern Standard Time" not recognized` (this situation works on Linux) MySQL: `ValueError: Database returned an invalid datetime value. Are time zone definitions for your database and pytz installed?` for trunc tests and assertion errors like `(datetime.datetime(2015, 6, 15, 18, 30, 50, 321, tzinfo=<UTC>), None) != (datetime.datetime(2015, 6, 15, 14, 30, 50, 321, tzinfo=<django.utils.timezone.LocalTimezone object at 0x03C73A10>), 15)` for the extract tests. (again, no problem on Linux)
I think ideally this file would be `base.py` and `__init__.py` would be modeled after https://github.com/django/django/blob/353d436e7cb33cb832a3e8c74b051e3d2ba76018/django/core/files/__init__.py
I usually write `msg = '...'`on the line before `with self.assertRaisesMessage(ValueError, msg):` to avoid the unusual indentation.
The code I've reviewed recently always has mixins on the left. I think it's easier to be consistent than have to think about it, but feel free to propose some different guidelines if you like.
Rather than writing some more complex skip condition, I think I'm inclined to skip these tests if pytz isn't installed.
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
chop "one of" add comma before "or"
I second Tim. Unless a very specific use case, mixins should be on the left.
Read also https://www.ianlewis.org/en/mixins-and-python
put closing parenthesis on the next line
`# Check that ...`
Perhaps "Cannot convert DateField '%s' to DateTimeField." (I'm not certain it's an issue here, but we're favoring '%s' over %r until we drop Python 2 support to avoid possible u'' prefixes.)
I'd rather not use `import *` since it prevents detecting unused imports. Alternatively, you could move functions.py -> base.py or something and make `__init__.py` only contains imports.
We should test that `datefield__year__(exact|gt|gte|lt|lte)` actually uses these lookups as the suite pass with them unregistered.
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
Could you sort those in reverse order (to be applied first: top ; to be applied last: bottom), please. Same for the other cases in this test.
Just to make sure, the previous behaviour would load the 'django.conf' package if packages is None? With this new change, you will load all installed apps and LOCALE_PATHS files, but 'django.conf' wouldn't be in it, so it may or may not be an issue, I can't really tell, since that package is used for the admin JS, so I don't think anyone would be relying on it for non admin pages. I actually like the change since in this way you don't have to manually specify the packages when all you want is your app's translations.
Oh yes the tests! You are right then.
Please "rebase" to pickup the changes in 44c0ecdd9226d039a8c666b36ae320af2046a1c1.
So the js18n view for admin, why does it still load django.conf on top of django.contrib.admin? Is it there because no one ever noticed there are no longer js ranslations for django.conf? If so it would be good to have it cleared also
explain why it needs to be copied
Might as well verify the output with `assertEqual` too. It would be appropriate to have a Trac ticket too.
I'm hesitant to remove "ManyToManyField" in the message since that's the common case. I'm not sure if adding "or a field with many_to_many=True" to all the messages is worth the additional verbosity.
If changing the messages, please update them in `docs/ref/checks.txt` as well.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
Put `db_field.many_to_many` first, please.
While you're here, please remove the comma.
Ahh `group_by` is [trie-valued](https://github.com/django/django/blob/master/django/db/models/sql/query.py#L157-L163). I think `isinstance(self.group_by, list)` has something to do with using `values()`.
I don't think you need to test this case as it's used to denote the existence of `group_by` (it defaults to `None`). From what I understand this instance check could be replaced by a simple boolean check `if self.group_by ...`.
Add a trailing comma.
I think this could benefit from being split in multiple test methods.
`test_sliced_conditionnal_aggregate()` Did this also fail without the patch applied? I see no mentions of it on the ticket.
I think these docstrings aren't needed.
This isn't passing on any backends. SQLite, for example: `OperationalError: misuse of aggregate function COUNT()`.
I find `return any(child.is_summary for child in self.children)` more readable.
I'd use a `kwargs = {}` variable and pass it to `self.as_sql(compiler, connection, **kwargs)` by making sure to set `kwargs['db_type']` if `type(self._output_field) in self.mysql_types`.
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
maybe: `# If no browsers were specified, skip this class (it'll still be discovered).`
`"Selenium browser specification '%s' is not valid."`
I don't have a strong opinion on this. When it was like that before, I didn't really like the blank browser popping up before the tests started to run. If we change it though, we need to include the original exception in the error message that's reraised. I think the current simple approach is okay.
I think it's something like: 'browser' contains the first browser to run the tests against and 'browsers' will contain the rest of the browsers (if more than one are requested).
could create a module variable so we don't have a second "magic string" in `runtests.py`: `SELENIUM_WEBDRIVER_PATH = 'selenium.webdriver.%s.webdriver.WebDriver'`
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
flow 'when' to previous line
the requested browsers "and raise appropriate exception" can probably be considered part of validation.
quit() .... to avoid a dead.... (chop "we" stuff)
Can we limit this to `ImportError`? I think the part about "corresponding WebDriver not installed" is obsolete now since there's not more attempt to instantiate it.
I think instantiating the browser to check if it works properly is also a part of the "validation" process. I don't see much gain in just checking that provided browsers are "importable" from selenium library. It will be better to keep that part of the error message and trying to instantiate the browsers here instead. Because there are other modules like `remote`, `support` in selenium which would get imported but do not have webdrivers - so these will give `WebDriverException` afterwards during the tests. Also if someone doesn't have the required drivers installed for a particular browser, it will again throw a similar Exception. So the `import_string` is just half of the validation.
I think there's no reason to prefer `smart_str` over `force_str` in these tests. Revised existing usage in https://github.com/django/django/pull/6290.
Hm, I removed it and saw some failures.
put closing ) on next lin
I'd suggest `PathNotImplementedStorage`.
I'm more inclined to put this in `tests/schema/test_logging.py`.
DRYer? ``` call = msg % args calls.append((call, kwargs) if log_kwargs else call) ```
Use hanging indent: ``` call_command( 'flush', verbosity=0, interactive=False, database=self.connection.alias, reset_sequences=True, inhibit_post_migrate=True, ) ```
Use hanging indent: ``` call_command( 'flush', verbosity=0, interactive=False, ... ) ```
What does the flush do? I would expect the tests to leave the database in a clean state already.
I'd chop every other empty line and group the `auto_now` and `auto_now_add`, but that's just cosmetics.
Even when restricted to tests and defined as an inner function, the name `assert...` for a function with a significant side effect (schema change) is disturbing. So is the use of the surrounding-function variable `editor` (which is done outside of the relevant `with` block). Please restructure this.
Oracle doesn't really have a date-without-time data type. If you're selecting data using raw SQL, you need to account for this yourself.
Since we eventually want to get rid of `auto_now` and `auto_now_add`, I'd stick to the `isinstance` check. 3rd party fields can instead inherit from the date and time fields Django provides.
I don't mind either way, it just took a second to spot the differences between the groups.
`from django.test import mock` -- this uses the package on Python 2 or the built-in version on Python 3.
`timezone.now()` should be used for `DateTimeField`.
You mean on Oracle? There's Django's CI infrastructure (I think Oracle is run for all PRs automatically, but it may need special invocation). Other than that, you can [set up an environment locally](https://code.djangoproject.com/wiki/OracleTestSetup) but it's a little involved if you only need it for one patch.
"any other input"
``` The ``default`` ... ```
If we don't and `USE_TZ=True` the default datetime used on column creation will be in the system timezone instead of UTC like Django assumes datetime are stored in the database.
Can you also check for `questioner.ask_auto_now_add_addition` to be called 3 times, please or is this something we don't do in here but in commands.
A few grammar fixes: `You are trying to add the field '%s' with 'auto_now_add=True' to %s without a default; the database needs to set a default value for existing fields.`
I won't audit every case in this review, but as above, it doesn't seem that `extra_context` provides any functionality that customizing the `template` doesn't already allow.
I think there's no reason that 'template' and 'arg_joiner' need to go into `data` -- they aren't meant to be interpolated into `template`, correct? Instead of the `data.get()` lines below, wouldn't this work: ``` python template = template or self.template arg_joiner = arg_joiner or self.arg_joiner ```
After looking at #6271, I think I'm seeing the use case for subclasses of `Func`.
`str` -> `six.string_types` for compatibility with Python 2.
I suggest "'string_if_invalid' in TEMPLATES OPTIONS must be a string (got (value) (type))." I think the part about "Change it.." isn't necessary.
`from django.utils import six` (by the way, try to do a few checks locally and not push a lot of changes to GitHub in quick succession since every push triggers a Jenkins build -- I canceled a few extra builds from this PR a couple hours ago)
A message similar to the one raised in `get_object()` would be more appropriate: ``` python raise ImproperlyConfigured( "%(cls)s is missing a Model. Define %(cls)s.model or " "override %(cls)s.get_model()." % { 'cls': self.__class__.__name__ } ) ```
I believe `super(ModelFormMixin, self).get_model()` should **always** have priority over `self.get_form_class().Meta.model`.
You'll need to catch `ImproperlyConfigured` errors raised by `get_model()` if you want the mention about `model` and `get_model()` to be meaningful. ``` python try: model = self.get_model() except ImproperlyConfigured: raise ImproperlyConfigured( "%(cls)s is missing a QuerySet. Define " "%(cls)s.model, %(cls)s.queryset, or override " "%(cls)s.get_queryset() or %(cls)s.get_model()." % { 'cls': self.__class__.__name__ } ) return model._default_manager.all() ```
I'm not sure how much of an issue it is but this will be backward incompatible with `SingleObjectTemplateResponseMixin` subclasses that define a `model` attribute but don't have a `get_model()` method. There is no such class in Django's provided CBVs.
Avoid calling `get_model()` twice here.
As above, since `process_request()` returns a response, the second test isn't needed (see 434d309ef6dbecbfd2b322d3a1da78aa5cb05fa8).
Since `process_request()` returns a response, the second part of the test isn't needed (see 434d309ef6dbecbfd2b322d3a1da78aa5cb05fa8).
`self.fields[self._meta.model.USERNAME_FIELD]`? I think it's a mandatory field.
Existing code isn't consistent, but we usually use single quotes in new code.
A concern is that if a custom field overrides these deprecated methods, they'll now be ignored.
Use PEP257 verb style for new docsrings: "Create... use..., etc."
I suggested it. Basically the raw sql could be just alias.col for some column of the query.
I'd rather see that change in `migrations_module()` so Django doesn't suddenly pick up a module somewhere else but just doesn't know about migrations for any apps.
This leaves a "dummy" SQLite database on the filesystem after running the tests.
As far as I can see you can instantiate the `MigrationLoader` in the questioner and writer with `connection=None` and `load=False` to achieve the same behavior there and drop the `@classmethod` from `migrations_module()`
This could be simplified as `{k: cleanse_setting(k, v) for k, v in meta.items()}`.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
`# Get the data for the set of fields that must be unique among the forms.`
`FinderTestCase` -> `TestFinders` (parallels `TestHashedFiles` / `TestDefaults`) or similar? Otherwise LGTM.
No as `User` and `Person` are registered to the global `apps` instance. The creation of the class is supposed to fail anyway so the `apps` cache won't get polluted.
I could be missing something, but I don't see a need for the function. ``` msg = "Proxy model 'MultipleAbstract' has more than one non-abstract model base class." with self.assertRaisesMessage(TypeError, msg): class MultipleAbstract(User, Person): class Meta: proxy = True ``` should be okay, I think? If so, we can make a separate commit to clean up the existing tests (and make them use `assertRaisesMessage` instead of just `assertRaises` too.
@charettes, do we need `@isolate_apps('proxy_models')` here and the test below? Some of the other tests have it but not these. Not sure the reason if there is one.
This would probably be better in the docstring. Maybe you want to say something about ducktyping instead of just "let's hope it has .get()" (guess you might want to add "filter()" too)
`# A model class or anything....` (chop coma)
Return... (I think the "Created to make..." sentence doesn't much."
Please put the test in `AdminActionsTest`.
How about checking for the `ValueError` on older versions? Would be nice to have a test for the `Nodata value must be numeric or None` error as well.
no dash needed for "recreated"
Add a trailing comma.
looks like the wording of this message should be updated in `docs/ref/checks.txt`
I think the norm is to use `apps` instead of `app_registry` to designate `Apps()` instances around the codebase.
prefer hanging indent: ``` model_signals = { signal: name for name, signal in vars(signals).items() if isinstance(signal, signals.ModelSignal) } ```
I would say "certain Python 2.7 versions" so we know that it's fine to remove when dropping support for it.
It would have been more appropriate if `run_checks()` took an `Apps` instance as a parameter instead of a list of `AppConfig`s.
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
"Return" (PEP257 style) for new docstrings.
Please use the indentation style of the existing warning.
This message should include some helpful information to debug the error. Currently it gives no information as to where the problem is. This is the idea behind the existing `describe_pattern()` function.
I think googling that term will give a sufficient reference if needed.
You can move this to the previous line (we are favoring slightly longer lines to avoid non-hanging indentation).
master is only supporting Python 2.7 and 3.4+
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
"or the user is inactive" can be removed too (should have been removed in 107165c4b04f4e5a830a60b6c66b2e5d8fb1d242)
I think it would be clearer if you removed the "else" and deindented the rest of the method.
Your test doesn't need to hit the database so you can inline the model in the test, decorate the test with `@isolate_apps`, and remove the model from the migration.
`.get(self.live_server_url + reverse('admin:admin_views_question_add'))`
please include a trailing comma in cases like this so if we add more items later, we don't have to modify the line again
Any problem with: ``` @property def media(self): ```
I think you can use `assertRaisesMessage` throughout these tests.
Raising a 404 with the same message as in the previous check would mask the issue. Then again I think we already leak a lot like that in other admin pages, will have to double check.
Slow or not, it is kinda pointless to do since we do not need the data -- so yeah, we should not count here
No need to use `get_user_model()` (don't think any of the other tests do that?), I think.
The message should only be visible when DEBUG=True so I don't think there's a concern about information leakage if you raise 404 with a message.
Docs for this method? Usually such methods take the `request` too.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
While this is technically correct I prefer ``` if not (many_to_many or foreign_key) ``` as it describes the intent better.
Use `elif` like in `formfield_for_foreignkey` above
Remove newlines here, paragraphs are to separate thoughts, those belong logically together
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Given that `model` also exists, it is weird that `field` refers to `original_model`. (Also where is `original_model` defined -- if nowhere then certainly tests seems to be missing). Maybe also rename to source & target model
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
@MarkusH Such a request should not change any state, so it should be `GET`. Using `POST` and `CSRF` wouldn't help against DoS there anyways (unless I miss something). If you are worried about querying the database, you can do the same with a normal request to the list views in the admin…
Does it need to be a separate test case from the one above? I don't see the distinction.
To avoid the interesting indentation: ``` msg = "<class 'admin_views.models.Question'> is not registered in the admin." with self.assertRaisesMessage(Http404, msg): ```
This will probably break for `zh-CN` and others because Django returns lower cased language names. I do not have a good idea on how to fix that though.
It's not obvious to me where limit_choices_to comes into play.
It seems this URL doesn't work anymore.
Cannot this information solely be extracted from the model itself? ie `.model._meta.app_label`.
reduce to: ``` and not isinstance(form_field.widget, (CheckboxSelectMultiple, AutocompleteSelectMultiple)) ```
Damn it, there is clear way to get this working. Ie there is no reliable way to determine the source_model_admin for a given URL :( I think we might have to relax permissions a bit and provide the autocomplete to any user for every model which has search fields defined and where the user has any permissions on it.
Can you please choose a new error code that is otherwise unused.
Will do, fwiw I think ``` url(r'^autocomplete_inline/%s/%s/(?P<field_name>.+)/$' % inline_info, ``` is not enough, two models could use the same inlines with different configs. EDIT: Or also in cases where the same model is registered as inline to multiple models.
Can you please choose a new error code that is otherwise unused.
Please wrap all docstrings at 79 characters.
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
Add a message please.
no restructured text (:class:) in docstrings please
Unused or untested according to coverage report.
should use ModelAdmin.get_search_fields()
I dislike this. Can we not do the check in the view but outside, please. This is how it's done for every other admin view. And until the admin is rewritten I'd rather follow one pattern not two.
I think `GET` is fine for that.
Use single quotes consistently.
I think `name.rsplit('-', 1)[-1]` is easier to read.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
I assume this isn't going to work with subclasses that override `get_inline_instances()`? Not sure if it's worth it, just mentioning it.
Wrap in `()` instead of using `\`.
Still missing test coverage here, I guess. `get_search_fields() missing 1 required positional argument: 'request'`
get_search_fields() not search_fields.
why an empty string? might as well use assertRaises at that point.
To keep the patch clean, please revert unrelated whitespace change.
I would remove the quotes, typically we only use a lazy reference if necessary.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
There is. Unless we enforce an ordering the result set for subsequent requests can be entirely different. This is unlikely what we want.
You are leaking information about whether somebody has access or something doesn't exist.
Yeah, this is a good point, reuse an ordering if possible (maybe even force it)
This function feels somewhat artificial. It seems to me that most of the problem solving in here is already solved on the ModelAdmin.
Both `has_perm()` and `has_change_permission()` take an optional `obj=None` argument for object-level permission checks as implemented by e.g. django-guardian. I think we should provide this here as well.
Do we really want this to be GET requests or are POST with CSRF better suited. Thinking about DoS here :-/
Is there a typo? I'm not sure what "hub" means in this sentence.
I'd follow the indentation pattern of the rest of this page, e.g.: ``` return [ checks.Error( 'An admin for model "%s" has to be registered to be' 'referenced by %s.autocomplete_fields.' % ( field.remote_field.model.__name__, type(obj).__name__, ), obj=obj.__class__, id='admin.E036', ) ] ``` Also, E036/37 are missing from `docs/ref/checks.txt`.
``` class Topping(models.Model): name = models.CharField(max_length=20) def __str__(self): return self.name class Pizza(models.Model): name = models.CharField(max_length=20) toppings = models.ManyToManyField('Topping', related_name='pizzas') ``` It looks like these existing models are equivalent. If needed, you can create a proxy model of one or more of them as needed, then register those with a separate ModelAdmin. (15b465c584f49a1d43b6c18796f83521ee4ffc22 is a past example of doing that.)
We could lowercase the vendored files, that would help at least for the `zh-*` variants.
should most likely be `model=self.model`, it does not support `model_admin` -- this also shows that the tests are still lacking!
Shouldn't that be `self.get_autocomplete_fields(request)`
Sorry, I couldn't figure out how to continue the conversation that I started here -- the fact that you changed the code seems to "trick" github into thinking that we are done here :) As you pointed out, `get_inline_instances` with no request is very weird and probably (tm) breaks existing code out there. What do you think about the following: Add only one (or two, if it makes handling inlines easier) autocomplete view to the urlpattern (statically) which disapatches to `self.autocomplete_view` and the returns `AutocompleteJsonView` accordingly. This way you'd have access to the request and would just need one view which you'd pass the information you need.
I think this test isn't working as expected -- it's resolving to `RedirectView`, same with `test_inline_urls` -- probably the result of the resolve should be checked.
Please remove this unrelated change.
It allows many new schemes that weren't allowed before.
Please remove the unrelated style changes.
Changing this list is outside the scope of this ticket and also backwards-incompatible.
Only do the regular expression check if `schemes == '__all__'`.
Actually the idea is to do this validation only if `schemes == '__all__'`. If the user provides some other scheme, then we might as well allow it.
Are these style changes intentional? Somehow they don't look like that.
Please remove this unrelated change.
There are still many unrelated formatting changes that should be reverted.
Yes, that's the idea. I'm not sure if we need to include a long list of schemes though. As Claude suggested on the ticket, some minimal validation like alphanumeric + period is probably sufficient. That way we don't have to maintain a list. Any projects that require such a list can supply it.
Please remove this unrelated change.
no u'' prefixes please (use `from __future__ import unicode_literals` if needed)
What's the purpose of the settings check here? ETag generation will become compulsory when the deprecation is over. Are there advantages in delaying it? With the current implementation, I'm not sure it'll be possible to set `settings.USE_ETAGS=True` to opt-in here while also avoiding the other deprecation warnings guarded by `if settings.USE_ETAGS`.
Seems like we may need a deprecation warning if `ConditionalGetMiddleware` is used but `settings.USE_ETAGS=False` since once the deprecation period ends, the behavior will change. It might be friendlier to use the system check framework (django/core/checks/compatibility) for the warnings. That way we can give the warnings up front and not have to wait until a request (and trigger a warning for most or every one).
This text should fit in one line (code line length is 119 chars). :wink:
Please wrap docstrings at 79 chars. Thanks :)
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
Could you a docstring along the lines of `test_file_url()`, please :smile:
I think wrapping in `Point()` is causing the test crash.
I think there isn't much organization there. Using an existing site should be fine.
I tried a similar approach while working on acfaec3db5ba39de52f6e607e74343dccf72fba1 and came to the conclusion that this approach can't work (due to something like module caching). As far as I know, you'll have to register the admin to a separate `AdminSite`.
Can we make any positive assertion? I'm a bit nervous about a negative assertion like this since, for example, a typo in the regular expression could cause the test to pass by mistake.
I don't think the intermediate `pattern` variable is needed.
I don't think the intermediate `pattern` variable is needed.
Is it possible to include the invalid specifiers in the message? That would probably make it easier to debug.
Do we need to check the `piece` in this branch too? If so, check it before the `if` statement.
Yes, maybe: "... time-related format specifiers (found 'a')."
Use `assertRaisesMessage()` to check the message too.
isvalid or is_valid? Not sure if there's any rationale about the existing discrepency (e.g. same_as vs. coveredby)
Up to you, but I think the tests are short enough that the blank lines don't help much.
It would be safer to assertEqual with False/True since these assertions pass on any truthy/falsey value.
You'll have to move this import before the `django.utils.translation` one to appease isort.
Is the URL/view needed? Test seems to be passing with them removed.
Empty -> Null
prefer hanging indent, also `status_code=302` is unneeded since it's the default: ``` python self.assertRedirects( response, 'http://testserver%s' % obj.get_absolute_url(), fetch_redirect_response=False, ) ```
Please use hanging indent: ``` python raise http.Http404(_("%(ct_name)s foreign key to Site is None for field %(field)s ") % { 'ct_name': content_type.name, 'field': field, }) ```
`request` is unused.
I'd prefer something that makes it slightly more obvious where the exceptions are expected to happen: ``` python try: site = getattr(obj, field.name) except Site.DoesNotExist: pass if site is not None: object_domain = site.domain ``` This is a slightly different issue, but it's not clear if `Site.DoesNotExist` can actually happen (no tests fail if it's removed).
no parenthesis needed / prefer single quotes
Fair enough, I assumed it was a small tweak to the stdlib version.
Is this code based on an existing implementation? If that's the case, we should specify it / link to it.
Interesting! I guess we could implement it at some point, but that seems like a fair amount of work.
please use this indent style: ``` _hextobyte = { (fmt % char).encode(): six.int2byte(char) for range in _decode_ranges for char in range for fmt in ['%02x', '%02X'] } ```
I'd rather call this something like `FormFieldAssertionsMixin` and have it inherit `object`.
Maybe: ``` @override_settings(INSTALLED_APPS=[ 'django.contrib.auth', 'django.contrib.contenttypes', 'migrations.migrations_test_apps.migrated_app' ]) ``` then remove admin and sites from assertion.
Is there some history on why this ended up moving inside a `try..catch`? I remember it being mentioned, but it's not clear to me why this behavior would have changed here, and I don't recall the reasoning given at the time.
> But since we're already adding len(field_name) + 2 on top of what we read this seems pointless now. Good point.
Having this around L152 would be very marginally cleaner from my POV. (Ie. it's similar to `num_post_keys` so makes sense for it to get initialized at same point in the codebase)
Yup it does seem to be a bit faster on both CPython 2 and 3 ``` py In [1]: microseconds = '1' In [3]: %timeit (microseconds + '000000')[:6] The slowest run took 37.44 times longer than the fastest. This could mean that an intermediate result is being cached 10000000 loops, best of 3: 134 ns per loop In [4]: %timeit '{:0<6.6}'.format(microseconds) The slowest run took 11.50 times longer than the fastest. This could mean that an intermediate result is being cached 1000000 loops, best of 3: 352 ns per loop ```
This will blow up if any backend returns >6 digits of sub-second precision MySQL can't do this, checking if SQLite can...
state the expected behavior, e.g. `The last choice is for the None value.`
I guess we could eliminate the `has_none` variable and simply check `if none_title` -- I don't think a user would define an expected title of an empty string.
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
I'd decorate the test method with `@override_settings(DEBUG=True)` instead to avoid extra indentation.
Add a trailing comma so if more items are added later we don't have to modify this line again.
I think the loop makes it look more complicated than it needs to be. How about something like: ``` python NullableFields.objects.bulk_create([ NullableFields(int_or_null=1), NullableFields(int_or_null=None), ]) ```
Oracle specifies restrictions on multi-table inserts: > Restrictions on Multitable Inserts Multitable inserts are subject to the following restrictions: > - You can perform multitable inserts only on tables, not on views or materialized views. > - You cannot perform a multitable insert into a remote table. So if we use this, the result would be "Django cannot do `bulk_create()` if the model is stored in a view on Oracle". I'd rather avoid this limitation unless there are very substantial benefits to be had.
+1 on just `ignore_patterns` since collectstatic isn't the only endpoint where this may come in handy (e.g. django-pipeline uses finders, too).
I'd say, "A custom ignore_patterns list, ['*.css'] in this case, can be..."
Could update this to use `assertRaisesMessage` while you're here.
Not sure if changes to these check methods are required -- was there a discussion somewhere about it? At least tests are missing for these changes.
maybe a module constant could make this slightly more readable? e.g. `RFC5322_EMAIL_LINE_LENGTH_LIMIT = 998`
has the side effect of shortening... (no dash needed)
Okay, perhaps it could be simplified slightly to something like: `Use ContentType.objects.get_for_id() so that lookups are cached...`
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
It's clearer to me.
I believe it's a reference to `ContentTypeManager`'s `get_for_*` methods cache. The actual `get_for_id()` call happens through `self.get_content_type()` below.
Usage of `template=None, **extra_context` params seems untested. Not sure if it's important.
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
no dash in "sub-query" Please wrap docstrings at 79 characters.
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
You can likely just resolve the F() expression using resolve_expression() once you have removed the outerq prefix from the F obj.
I needed to add a `set_source_expressions` method which sets `self.subquery = source_expressions` here to get relabelling to work.
MySQL/PostgreSQL test failure suggests this query isn't equivalent (unless it really only cares about `.count()` as you had previously). Let me know what you want to do here.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
`FieldError('This queryset contains a reference to an outer query, and cannot be evaluated on its own')` How's that? Same goes for OuterRef I guess. Maybe: ``` FieldError("This queryset contains a reference to an outer query, and cannot be evaluated without its' parent") ```
Yeah that's what I suspected too. Stupid SQL.
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
Interesting that this doesn't catch the `SubQuery(aggregation_qs)` case where I had to define the output_field. I guess it's because the select list is longer (aggregation + grouping column), but another property keeps track of what we're actually returning? It'd be really useful to correctly get the output_field for aggregated subqueries too.
The assertion argument order you've chosen is opposite of what we usally do, e.g. `self.assertEqual(qs.values('pk').filter(is_point_of_contact=True).count(), 1)`
Include a trailing comma so that if more items are added later, so we don't need to modify this line again.
Delete this blank line.
You can use `self.assertRaisesMessage(ValueError, 'error string')` rather than inspecting the exception args.
I think the `= true` is a byproduct of filter requiring a left and right hand side. This can be fixed when that restriction is removed via filter/expressions.
Please use `self.assertRaisesMessage` to verify this is the expected `ValueError` .
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
Revert this new line addition as it makes blaming harder.
I think we want to crash here if `bases` is not iterable.
The `CustomModelBase` class is not an actual `models.Model` subclass but a `models.base.ModelBase` subclass which is `type(models.Model)` (`models.Model`'s metaclass). We should use an actual `models.Model` subclass instead.
I didn't follow the discussion closely but was there a reason for not including the duplicate value in the message? I thought that was in the first version of the message.
Is there any more complication than adding `val` in the string interpolation: `duplicate %s (%s)`? Just seems like it's a trivial addition without any downside.
Add a trailing period.
Check against `(base._meta.label_lower if isinstance(base, models.base.ModelBase) else base.lower() for base in self.bases)` to catch mixed types bases duplicates (e.g. `bases=(MyModel, MyModel._meta.label_lower)`)
right, I missed that :)
Right, I'll sumit a PR shortly with the required changes.
It was in the initial version of patch when bases and managers were not also checked. If you think this must be present I can submit a PR with the previous changes.
I see. Adding an `if base is not models.Model` to the generator should do.
While we are at it, what about doing the same treatment for `initial`? (`return self.to_python(initial) != self.to_python(data)`? Another cleanup (probably separate commit) could be to harmonize `to_python` for `BooleanField` and `NullBooleanField`, except for the `None` difference.
If we have to multiline, usually we go with hanging indent like this: ``` call_command( 'loaddata', ... ... ) ```
Please revert unrelated cosmetic changes to keep the diff clean.
Yes, please rebase the branch and remove the try/fail pattern as done in 6729b96d8a15048b2295c916c5b881a59d9417a0. If you're unfamiliar with the process you might find https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/working-with-git/#rebasing-branches helpful.
I'd like if you made this change in a separate commit so it doesn't confuse this one.
I would assert for memory/time/parallelism here (and also in the other upgrade test) -- so we know that actually the version caused the upgrade. (ie like we do for the other hashers)
I'd also like to see a test which tests the upgrade from 0x10 to 0x13 just to be safe…
I would directly check against `argon2.low_level.ARGON2_VERSION`. What I want to prevent is a new argon version increasing the version number and we have to issue a new django release to take advantage of that.
This means that installing a new version of argon2-cffi might cause all passwords to be rehashed upon login, correct? Might be worth a mention in the docs about this.
Is there any good reason to specify the version? Ie I would assume we would always want the newest? Edit:// Gotta run, full review coming later.
Then we should drop this, according to https://github.com/hynek/argon2_cffi/blob/master/src/argon2/low_level.py#L58 it should already select the latest.
I remember issues with objects returning `unicode` in `__str__` and `__repr__` on Python 2. Better be extra safe and return `str('<Deferred field>')` in both cases.
The idea is that we could always have all field_names and values present for the from_db() call. The QuerySet iterator is using some extra effort to supply just the field_names and values which are non-deferred. Instead we could supply all field_names and have DEFERRED objs in the values for those fields which are deferred. This might make the logic in queryset iteration a bit simpler, though there isn't a guarantee of that. The real TODO is to check if this is actually a good change or not. Sorry I haven't been able to work on this issue, I have been too busy lately.
I searched a bit and couldn't find the exact ticket but the reported issue had something to do with Django's `lazy` logic and could be triggered even with ASCII only chars.
let's use a single line for this assertion as well as single quotes -- the rest of the file could be cleaned up later
Just state the expected behavior: "Joins shouldn't be performed for ...." rather than "Ensure that" or "Test that" which is the purpose of all tests.
To preserve the 1.11 move to HTML5 boolean syntax I believe this line should be changed to `checked_attribute = {'checked': True}`. Same for the `Select` class on line 690: `checked_attribute = {'selected': True}`
I think this test is obsolete now.
Maybe prepend final sentence with "Since you have set MIDDLEWARE, " -- otherwise it kind of reads as if MIDDLEWARE_CLASSES is _always_ ignored in 1.10.
I wouldn't use so many intermediate variables, e.g. `self.assertEqual(qs.update(another_value='foo'), 3)` seems fine. Also, you might include the tests that already pass on master in a separate commit so it's more clear exactly what's fixed.
use `with self.assertRaisesMessage(FieldError, "Aggregate functions are't allowed in this query."):`
If I understand correctly a `FieldError` should be raised in this case? You can use `self.assertRaisesMessage` to assert it's the case.
Generally we don't include the ticket numbers unless the issue is an obscure one that benefits from additional context that the ticket provides. If so "Sentence.... (#19513, #18580)." is the usual format
It might be nice to reorder this above _post_process so that lots of code doesn't appear as changed when it was only moved. It would certainly ease review.
It seems the original value of the class should be stored by setUp and then restored here in case the default value of 5 changes.
Returns -> Return It's not obvious to me what "real URL" means.
chop blank line
State the expected behavior as per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style. Also wrap docstrings at 79 chars.
Perhaps `assertPostCondition` would be a better name. A docstring about how it should be used may also help future test writers know whether or not to include it in new tests.
Please use `assertRaisesMessage` for exception checking.
Typically we've shied away from using `__repr__` for strings in messages because this may output the `u''` prefix on Python 2 which is a bit unsightly. I don't have a strong opinion about it, just mentioning off hand. Also we usually use this style to avoid backslashes and non-4 space indentation. ``` hint = ( '....' ) ```
Looks like this could be a single line.
I'd suggest: `get_warning_for_invalid_pattern`
no need for intermediate variable: `return [Warning(`
``` self.assertRegexpMatches(warning.msg, ( "..." "..." )) ```
Simplify: "describe_pattern() cannot be used here because the pattern might not have..."
Suggestion: "Found duplicate value %s in CreateModel managers/fields/bases argument."
Looks good, thanks.
Doesn't work if it's inlined in the test method, correct? LGTM
oh, and only models are allowed to be named with strings (in the migration itself) - right you are 👍
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
I might be missing something but I can't come up with a way `escape_isnt_last_filter is True` when reaching this branch as the only way to get in there is when `seen_escape_filter is True` which is only set in the `isinstance(obj, EscapeData)` branch below where `escape_isnt_last_filter` is immediately set to `False`.
I see, thanks for pointing that out.
This isn't related to your changes, but I'm intrigued by Django's behavior here. I would expect `|escape` to give `&amp;` and `|escape|force_escape` to give `&amp;amp;`. Not that this construct makes much sense anyway...
Ha! So it's actually related to your changes :-) Happy to hear that we'll eventually get the semantics that I would expect.
chop "we"; add period to second sentence
Use capitalization and periods
put import at the top of the method
chop blank line
fixme -> TODO
ATM is -> than with
as above, chop "Tests that"
chop blank line
chop blank line
chop blank line
chop blank line here and in the similar code below (the parenthesis on its own line provides whitespace)
What I mean is that no tests fail if I change this line to `f for f in model._meta.get_fields()`
chop blank line
use PEP257 verb style: "Send"
chop blank line (and below too)
Any disadvantage to making it a separate test method instead? I guess the signal connecting might be better is `setUpClass` at that point.
I would say, "A ContentType shouldn't be created..."
chop extra space after period, chop "we".
You could reword this to avoid the "we" stuff. "Start with get()..."
"Always clear..." would be sufficient
chop "we" 2x
I guess I would single line this for now.
It would be fine to put this in a separate test class so it can have a `setUpTestData` method to avoid the delete() and redundant object creation
include trailing commas
could chop "Make sure to" without any loss of meaning.
slightly simpler could be: "asking the user what ..."
no need for super calls
That's what we keep in the commit message. `git blame` is your friend to find the commit and thus the commit message.
Style: We can write this in one line like the other create_user examples in test_tokens.py.
I'd remove the ticket reference here.
As the checks are performed against `model_class._default_manager` the `connections[router.db_for_read(model_class)]` connection should be used.
Same potential issue with multi-db support here.
There is a `%s` in the exception message, but you forgot to pass `app_name`. A minor code style suggestion: ``` py raise ImproperlyConfigured( "Cannot import '%s', check AppConfig.name is correctly defined." % app_name ) ```
To that end, you should use `assertRaisesMessage` in the test to catch that mistake.
A cached property on the Operations class becomes problematic when migrations enter the scene (and there are tests with migrations, so the interaction is likely to exist already with the first use-case).
Oh, and you should expect even more fun with long names of automatically generated m2m tables. They have a slightly different shortening.
Assuming `tables` here comes from the apps, this will have a problem with long (>30 chars) table names. The Oracle metadata tables will hold the shortened names.
I don't think it's about `objects` as a name for the base manager / default manager. It's about if there's >= 1 manager that's used in migrations.
I think this might be a bit clearer: ``` python try: meta = new_field.remote_field.through._meta except AttributeError: pass else: rename_key = (meta.app_label, meta.model_name) if rename_key in self.renamed_models: new_field.remote_field.through = old_field.remote_field.through ``` It also avoids a few unnecessary attribute lookups.
Alright let's keep it as it is then. I just wanted to make sure this case was covered by a test.
I think it's better to stick to style used for the `remote_field.model` check just above for the sake of consistency.
This isn't safe unfortunately. Consider the following test results (which fail): ``` def test_empty_expression_char(self): books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value('Empty')), default=Value('Not Empty'), output_field=CharField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, 'Not Empty') def test_empty_expression_datetime(self): from django.utils import timezone from datetime import timedelta now = timezone.now() then = now + timedelta(days=1) books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value(now)), default=Value(then), output_field=DateTimeField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, then) ``` Depending on whether or not there are dbconverters run, these will fail with one of the following kinds of errors: 1. `TypeError: expected string or buffer` 2. `AssertionError: 0 != datetime.datetime(2016, 5, 23, 18, 59, 26, 409777)` For what it's worth, both of these tests fail without your patch too, except they fail during the count just like the report on the ticket says. This certainly needs fixing in some way, but we can't just use 0 as a value all of the time.
I think exceptions in `django.core.exceptions` are mostly things that a user might need to import. I don't think `EmptyResultSet` meets that criteria, at least in my experience I never needed it in a project.
Case expressions use Q internally which led me to writing the above tests. I think you're right that EmptyResultSet might be able to be caught directly, and then it could use the `default` argument in place of the static `'0'` you have above. The changes need to be made in tandem though.
The import usually goes at the top of the method.
I have no opinion, Django-MySQL doesn't touch `EmptyResultSet`
Good point, I didn't think of that module as being user facing. Perhaps django.db.utils would be a better place? It already contains various DatabaseError exceptions, so it wouldn't be totally out of place.
Yes there is a chance it may be needed by future expressions. The subquery expression that @schinckel is putting together may end up needing it too. Purity is also a reason though. The error isn't really sql specific so it shouldn't be pushed down into the sql implementation - much nicer to have it somewhere in the frontend. History tells me it used to live in `django.db.models.query` until it was moved into `django.db.models.sql.query` during the queryset refactor - but I think that was just because it was used only within the sql module at that point.
Since EmptyResultSet isn't necessarily related to SQL I think moving it makes sense. `django.core.exceptions` is probably a good place to move it to. The only question is whether we need to deprecate the old location, or at least provide an import in the old location. @akaariai @loic @manfre @adamchainz do any of you have an opinion here? I imagine non-core backends are likely to import this type but I haven't checked specifically. In any case, if the change is made, it should be in a separate commit to catch regressions in the future without impacting 26517 if it needs to be reverted.
I'm fine with core.exceptions then. Docs go in docs/ref/exceptions.txt.
should remove -> removes
put self._create_index_name( on the next line of put the suffix="_check") parenthesis on the next line for balance
Yes, we should really limit `force_text` usage to potential decoding functionality.
Oh, of course, but then it's definitely `str()` over `force_text()`.
better word choice: referring -> referencing (or "referring to" would also be correct)
Something like `self.assertGreater(len(editor.deferred_sql), 0)` might be appropriate to ensure there is `deferred_sql`. I'm always cautious about assertions within loops without something to check that the loop is executed.
Do you prefer `references.X` as opposed to importing each class? We've sometimes removed that pattern elsewhere.
universal (no capital)
use pep257 verb style for new docstring "Take... Return..."
use single quotes
Just a nitpick: The test name looks already readable to me so I'd drop the docstring.
This can be a one liner: ``` py self.assertEqual(rss_feed.latest_post_date().tzinfo, timezone.utc) ```
Django has already a helper to do the same thing (with addition of checking if settings.USE_TZ is True) at django/utils/timezone.py: django.utils.timezone.now.
please make the line a bit longer (breaking near 79 characters) and add a period.
plus use hanging indentation, e.g. ``` Person.objects.get_or_create( first_name="George", defaults={"last_name": "Harrison", "birthday": lambda: date(1943, 2, 25)}, ) ```
What do you think about this: ``` python try: key = getattr(value, source.attname) value_list.append(key) except AttributeError: value_list.append(value.pk) break ```
I should be able later today.
I couldn't came up with a test case. I suggest to be extra safe and `return (value.pk,)` immediately instead of appending to `value_list` just in case it end up containing values from other iterations (e.g. a model instance that happen to have a field/attribute with the same name as one of the looked up by `source.attname`).
I'm not sure this is correct when there's multiple sources as the the `pk` will be appended twice.
Yeah I also gave it a try by replacing the `return (value.pk,)` by `return tuple(getattr(value, field) for field in lhs.output_field.to_fields)` but the `place=restaurant_instance` test was failing. I suppose we'll require input from @akaariai.
You might want to use `isolate_apps('model_fields')` to avoid polluting the global `apps` cache.
Use `asserRaisesMessage` for the message part, keep `cm` around for the `code` assertion.
``` python msg = 'Input should resemble a dictionary.' with self.assertRaisesMessage(exceptions.ValidationError, msg) as cm: field.clean('["a", "b", 1]') self.assertEqual(cm.exception.code, 'invalid_format') ``` Note that the assertions must be run outside the context manager else they will never be executed as the `ValidationError` raised by `clean()` will force an immediate `__exit__()`.
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
I see now. I think a more readable structure would be to rename `SimplePoFileTests` to something like `PoFileAssertionMixin` and use that as well as `SimpleTestCase` in the subclasses.
My only question is if this skip logic is still correctly applied (i.e. none of the other classes that inherited `ExtractorTests` require it)? If you verify that, ship it.
no blank line needed after docstrings
no blank line needed
This is fine as is.
use a single line instead
This is fine as is.
include a trailing comma so if more args are added later we don't have to modify this line again
This is fine as is.
This is fine as is.
put "Input..." as current docstring does
should wrap as close to 79 chars as possible. also convert to the more usual style: ``` """ Parse ... ... """ ```
I mean `chunk = handler.receive_data_chunk(chunk, counters[i])`
rephrase: Don't continue if ...
should wrap as close to 79 chars as possible.
I don't think touching docstrings for wraps at 80 characters instead of 79 is worth the churn.
``` number_equal = len([ current_number for current_number in self._unget_history if current_number == num_bytes ]) ```
use a single line instead
This is fine as is.
This is fine as is.
rephrase: "Don't continue if..."
... remote URLs (got %s).
"Use assertRedirects(..., fetch_redirect_response=False) instead."
put the closing parenthesis on the next line
I think raising an exception like `ValueError` might be more appropriate.
Please use hanging indent: ``` LookupError( e.args[0] + ' You may be missing this app in your ' ''INSTALLED_APPS setting and have a migration which ' 'depends on it.' ) ```
Use hanging indent has above.
No need for the docstring as the test is fairly straightforward.
Not if you're using a client subclass with an overridden default `SERVER_NAME` which is a common pattern when testing projects using `django-hosts`. I suggest we use `response.client.defaults.get('SERVER_NAME', 'testclient')`.
`response.client._base_environ()['SERVER_NAME']` would be better but it might be a bit overkill.
"or in UTC."
`email = EmailMessage('Subject', 'Content', 'bounce@example.com', ['to@example.com'])`
I guess you probably want `from django.test.utils import requires_tz_support` instead.
HeadersCheckMixin seems unneeded
single line here is okay (lines up to 119 chars are fine when it improves readability)
Can be simplified to `ItalianRestaurant.objects.defer('serves_gnocchi').get(pk=italian_restaurant.pk)`.
Just state the expected behavior by chopping "assert that..." since all tests assert things.
a single line for these queries should probably be okay
Can be simplified to `ItalianRestaurant.objects.only('serves_gnocchi').get(pk=italian_restaurant.pk)`.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
can we create the `ItalianRestaurant` and then get the related entites we need from that? I think that would be a bit nicer than `save_base(raw=True)`.
try to avoid "we", e.g. "Because it's a parent link, all the data is available in the instance, ...
Please drop the "Tests that" preamble in favor of stating the expected behavior.
I think it would be much preferred if the tests didn't introduce a dependency on the template system.
Wrap docstrings at 79 characters. Try to avoid "we... " (often this results in simpler language).
put the closing parenthesis on the next line
Perhaps you'd like to import the messages from django.middleware.csrf to reduce the repetition and the need to edit all the tests if a message changes.
It think you should be returning `repr(self.__cast())` as this might crash if the proxied object is not and instance of `str`.
I think this change really indicates the need for a second test for wrapping a non-string object.
The `Foo` model as no `foos` field. As `Foo` is not `auto_created` it should have a similar message to `test_m2m_table_name_clash`.
As the `db_table` is attached to an `auto_created` model the message should be `Field is using a table that has already been registered by 'invalid_models_tests.Baz.foos'.`. The intermediary model `Baz_foos` is an implementation detail and shouldn't be referred to, plus it has no `foos` field.
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
I'd use the preferred style so at least future tests might copy it.
No need to create a `set()` here.
I'd use: ``` self.assertEqual(Bar.check(), expected) ``` to save a line.
This assertion will fail on Python 2 as the `repr`esentation of locally defined classes is not the same.
`Bar.bar` isn't a field. The message should be `Field is using a table that has already been registered by 'invalid_models_tests.Bar'` as the `db_table` is declared on a non-`auto_created` model (`_meta.auto_created is False`).
Abort early if `self.db_table is None`
Shouldn't you exclude `self.rel.through` from here? Else your automatically created table will always be present in `registered_tables`.
I would use the model `_meta.app_label` and `object_name` instead of its representation.
From a second read on the ticket it looks like we should always validate the table name even when not explicitly specified. You can remove this early return.
You should use `self.m2m_db_table` instead of `self.db_table`.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
`if m2m_db_table in registered_tables` should do!
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
I would stick to `%` formating for the sake of consistency with other `_check` methods.
Use outer double quotes to avoid backslashes.
Use `settings.ALLOWED_HOSTS = settings.ALLOWED_HOSTS + ['testserver']` to avoid altering the original list assigned to `request._original_allowed_hosts` above.
Return... (use PEP257 verb style for new docstrings)
I think `request` should be optional.
"Log errors..." not "Logs errors..."
What if we make `level` default to "info" or "debug" instead? That way if you call `log_response` on a non-error response you'd just get an info/debug log, instead of getting a confusing "module logger has no attribute None" error (or whatever the wording actually would be)
I'm tempted to suggest making `response` the first argument (before `message`), making the calling signature more concise and allowing Python to handle it as a normal required argument. The downside of course is that it makes the signature less like a normal logging call. I don't have strong feelings, ok with however you prefer to paint this bikeshed.
This bare `except` will catch anything, including the exception that marks a failing test, I think :-) Better to use `assertRaises` and explicitly assert that the specific expected uncaught exception bubbles up.
chop blank line
chop blank line
prefer hanging indent: ``` self.assertEqual( len(calls), 1, "..." ) ```
We usually model these names off of the unittest came case convention, e.g. assertRequestLogs
no blank line
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
response (no cap) unless you mean to write HttpResponse
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
no blank line
Please use `with translation.override('xyz'):` instead of the `activate`/`deactivate` couple.
If a language doesn't have a catalog, use the Germanic default for pluralization: anything except one is pluralized.
I think I would not mix the tests and better create a separate test, if possible.
You don't need to add a new unexisting language, 'xxx' should already play this "role".
Include a trailing comma so if more items are added later, we don't have to modify this line again.
In general, I think the `get` / `set` style APIs are familiar enough that we don't need to use keyword arguments with every call. But I don't feel strongly about it.
Yeah, the caching is usually only about related fields.
The whole setup with related fields and their related fields is really confusing :) I tried to do an improvement in here some time ago, but not sure if it just got things worse... A major cleanup would be welcome, but unfortunately these fields and attributes are used all over the place, and thus it's really labour-intensive to actually fix this.
I see thanks, I missed it because of the `is_cached` removal.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
Adding a default kwarg doesn't mean we have to use it everywhere, and doesn't necessarily mean it defaults to None either. We could default to a sentinel object causing a raise. You would only get a default of None of you explicitly specify one. It's true that would be different from `dict.get`. Still seems potentially worth it to me, but I'm happy to go with your preference.
Yeah, I think that falls into YAGNI territory. Better to just do the simpler and faster thing for now, and add indirection later if/when we actually need it.
Yeah we don't want that. If we did modify this to use a default value instead of raising, it'd need to be a unique sentinel default, not None. I don't feel strongly that that's an improvement, though.
:+1: We could really use some clearer naming there :)
The other benefit of reversing the sense of this flag is that it makes the "normal" case be `False` and the unusual case `True`, which I think is generally preferable for boolean flags.
Another case where a `default` arg would help slightly.
Fine by me. I think we could probably omit the keywords in a lot of places and include them only where it's potentially confusing, but probably that's already what you're doing.
What is the benefit of having these `set_fields_cache` and `get_fields_cache` methods, over just accessing `instance._state.cache` directly? The only apparent reason is so that you can pass in a field and have `field.get_cache_name()` automatically called, but that could just as well be handled in the field mixin (and it's better handled there, as that keeps the encapsulations cleaner).
This would be clearer (to me) if the sense were reversed and it were named `is_descriptor` instead of `is_cache`. Would that naming be wrong in some way that I'm missing? I find this naming confusing because it's named `is_cache` but isn't really describing whether anything is (or is not) "a cache." An alternative to `is_descriptor` if you want to keep the same sense would be something like `is_cache_safe` -- but I still think `is_descriptor` is clearer.
Function calls are also quite expensive in Python, so the burden of proof is to demonstrate that these accessor methods add significant value over just directly accessing the attribute.
I'd drop the "prefetched_" prefix on the variable name to keep things more readable.
use assertEqual (with the "s" is a deprecated alias)
Also fits on a single line.
I think you want `options['indexes'].remove(idx_name)` here. That would simplify this code, and I think together with the change in signature mentioned above, remove the need for `get_index_by_name` as well. [List.remove](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)
Why does `DropIndex` take name, but `CreateIndex` takes an `Index`? That seems a little counterintuitive.
You shouldn't need to set the model here? You wouldn't have access to it in the migration file anyway. I think `state_forwards` should set up the connection for you
Any problem with allowing `self.model = None`. I think conditional attributes which require `hasattr` isn't the best design.
I don't think we should hijack `*args` for fields, a `fields` kwarg makes more sense to me. `model` should be assigned by `Options` just like `Field.model` is. What do you think of the `name`, `db_name` approach suggested above? In this case the signature should look like `(name, fields, db_name=None, **options)` and there would be no need to validate `name`.
This should _never_ be the case. `ModelState` should have a default `indexes = []`
It's solving the issue about `DropIndex` taking a name mentioned above and should make a lot stuff easier to deal with (such as index renames) as indexes will be identifiable by a user defined string. Either all `Index` should have a user defined name like field or we should not try to mimic the `RemoveField` API and make `DropIndex` take an `Index` instead of a system generated name.
I'd move these methods above "def alter_unique_together" so those alter methods aren't separated from their helper, _delete_composed_index.
Does the ordering of indexes on a database matter? I'm not talking about the order of fields an index applies to, but the indexes itself.
Although using only the name might cause usability issues in the case of an auto-generated name. The user will have to inspect the database or something in order to determine the index name if they're writing the migration by hand.
It parallel's AddField/RemoveField (the latter takes only the name).
You can't assume the presence of `self.name` here
Since index name generation is deterministic, I don't think this is needed. `test_name_auto_generation` already checks for a specific name. If this index is truncated is some different way, then it would be okay to keep it but check for the actual name rather than testing the length.
I guess none of these lines aren't tested since I don't see any new tests that use `db_tablespace`.
I think this could be `@cached_property` so it doesn't have to be calculated on every access.
The hexdigest will always be a fixed length so this only happens if the provided suffix is too long, correct? In that case, I think it would be better to raise an error that the provided suffix is too long.
I think the name should be generated as part of the index class and should be database backend independent, otherwise your migrations would yield different names depending on the database used to generate the migrations.
Mind renaming `schema` to `schema_editor`, please (and in all the other places)
We can't really make this backend dependent if we want to store the index name as part of migrations. Migrations are potentially run on any db backend and should work on any.
Either add `self` or make it `@staticmethod`
I'm not following exactly what the idea is and what problem it's solving.
I think this if statement can be removed as it doesn't seem to ever evaluate to False when running the test suite.
I was expecting to raise a ValueError if these conditions aren't met, similar to what we do with "Index names cannot be longer". I don't think it's a good idea to modify the user provided value as it seems like that would only cause confusion.
It sounds like maybe index_type could be used as the suffix and this method doesn't need that argument. I guess the question is whether index_type should be limited to 3 characters or if truncating the first 3 characters of "index_type" as the suffix is okay.
Would be better if this were delegated to the database backend rather than requiring a limit based on one particular database.
I'm wondering if it makes sense to have `self._name` default to `None` and a property `name` that either returns `self._name` or automatically generates one and stores it on `self._name` which is then returned. With the current implementation the following won't easily be possible to deconstruct for migrations: ``` python class MyModel(models.Model): class Meta: indexes = [Index('id')] ``` because `indexes[0]` doesn't have a name which we always want to add to the deconstructed index class to ensure we can change the way index names are generated and not break other people's code.
I briefly remember that there was an issue with wrong index names a while ago, that _somehow_ got in people's projects. I can't recall the details, but all migration operations should enforce a deterministic index name present. That is, `AddIndex` checking for `self.index.name` and `RemoveIndex` checking for `self.name`.
Use PEP257 verb style for new docstrings: "Create", "Delete", "Return", etc..
Use single quotes
I think the constructor signature of this operation should only use the index name and not require an instance of an Index class
I think we can drop this docstring. We don't need to repeat it for every object that implements deconstruct().
Use single quotes consistently.
No need to multiline statements like this which will fit on a single line.
Alright, let's keep this change for another PR then.
Initialize `models_to_check` with `list(self.bases)`.
Move view above change for consistency.
In fact, this should be moved into the definition of `context` above: ```python 'can_change_related': self.can_change_related, ```
In fact, this should be moved into the definition of `context` above: ```python 'can_view_related': self.can_view_related, ```
Remove this line as `preserved_filters` is already added by `ctx = Context(context)`.
Move `has_add_permission` above `has_change_permission`.
Except the message displayed isn't quite right in this case: ``` The X "Great new X" was added successfully. You may edit it again below. ``` It's not true that it may be edited.
Remove this line - unnecessary addition.
Possibly change this to `model_dict['view_only'] = not perms.get('change')` as it doesn't harm for the value to exist and be False...
Remove this line as `opts` is already added by `ctx = Context(context)`.
This can be part of `test_login`, directly above.
Yes as the standard response is to redirect to the login page
Can this test case be moved into the first section of `test_history_view`, directly above? It doesn't look like the "can't change" bit is being tested.
This section of this test looks broken—or at least misleading. It's really just checking `is_staff` and `has even id`: there's no point putting all the different staff users through it. The `# Test redirection when using row-level change permissions. Refs #11513.` looks like it belongs in a separate method. (Same with matching code in `test_change_view` above.) (Not necessarily a complaint about this PR!)
This should be part of `test_has_module_permission`, directly above.
Remove this line as `is_popup` is already added by `ctx = Context(context)`. The local variable is just for convenience.
Move `has_view_permission` above `has_add_permission` for consistency.
Move `view` above `add` for consistency.
Can we not just extend `self.readonly_fields` and not add the extra `self.viewonly_fields`? Also, this line will likely result in duplicate column names - I'm not sure that necessarily matters here, but it's not very tidy...
Minor rephrasing: `... and the user does not have permission ...` Also, typo: `exlcude` → `exclude`
Rename this variable to `readonly_fields`. Let's not pollute the code with three things that mean the same thing, i.e. the `uneditable_fields` here and the aforementioned `viewonly_fields`.
Again, it shouldn't be necessary to provide `None` here? (I realise that the existing version of this line did so.) Please fix all cases of this, but only for lines modified by this PR. Other cases can be dealt with by a separate PR some other time.
The parentheses on this line are unnecessary.
I think you missed this one in your recent updates.
I don't think this is needed (probably accidentally copied from line 327).
`if not ... and not ...` for consistency with other similar statements...
Move `has_view_permission` above `has_add_permission` for consistency.
Should we add `has_view_permission` for consistency here? I'm not sure I like that we assume that users have these permissions by default. Should these not be added after `model_admin` to not break backwards compatibility of parameter ordering? Currently only `has_add_permission` gets used in this class and all three of these flags are used at the same time outside of the class definition. Would it make more sense to pass in a `view_only=True` or `editable=False` flag if we do not need the granularity? As previously mentioned, I think that the overlap between `readonly_fields` and `uneditable_fields` is messy. I don't know whether we can make this work with `readonly_fields` alone or whether we need to come up with another solution.
I notice that there is a check here on `has_add_permission`. Should the `InlineAdminForm`s above this check for `has_change_permission`? Also I don't understand why we would only need to check for the add case and not the change case when adding view permissions...
Move above `can_add_related` for consistency.
Move this above `has_add_permission` for consistency.
This test case should be part of `test_overriding_has_module_permission` immediately above.
Also put `self.adduser` back in front of `self.changeuser`...
No need to wrap this. 118 chars is fine.
`.all()[0]` -> `.first()`
I see the old tests do this, but (AFAICS) there's no reason to to store `post_data` on `self`. (It's not accessed outside this test case.)
Please use `"""` for docstrings.
Why is this conditional addition of `original` necessary? In fact, I don't see why `preserved_filters` or `opts` need to be added either. They are already added to `ctx` from `context` when `ctx` is instantiated.
I haven't run the tests, so I could be off here, but if having the _change_ permission effectively grants you the _view_ permission for backwards compatibility, is having the same criteria here a good idea? It could potentially mask problems with the new _view_ permission in the tests as the user would always have both.
Avoid the _if truthy return true else return false_ anti-pattern; use: `return perm == 'modeladmin.view_band'` Please also fix this for `MockUser`, `MockAddUser`, `MockChangeUser` and `MockDeleteUser` cases in a separate commit.
Move `MockViewUser` above `MockAddUser` to keep consistent ordering...
Also put `self.adduser` back in front of `self.changeuser`...
Please remove the blank line.
These two permissions are never used. Please remove them. `cls.permissionuser` is only used in `test_simple_inline_permissions`. Create it inline there rather than on the class.
Remove unnecessary hanging indent, simplify: `context['can_view_related'] = True`
Remove unnecessary hanging indent, simplify: `context['can_change_related'] = True`
This doesn't seem right. Surely `show_save_and_continue` should only be available if you can change an existing item. If you only have the _add_ permission and not _change_, once you have added an item, you can no longer change it.
Remove unnecessary hanging indent, simplify: ```python context['change_related_template_url'] = self.get_related_url(info, 'change', '__fk__') ``` (This makes the line 99 characters, but I think it is clear enough.)
(It's kinda hilarious to recommend a case change on a name that's literally case insensitive.)
I believe the name should be `CITextField` for Case Insensitive Text Field.
Should this follow the same capitalization style? `CITextExtension`
please wrap docstrings at 79 characters use 1 space between sentences use "PostgreSQL" rather than "postgres"
Would this message make it more clear about what argument of the field is problematic? ``` "The 'to_field' '%s' doesn't exist on the related " "model '%s'." % (to_field, self.remote_field.model._meta.label), ```
chop blank line
Just because Django doesn't automatically put relational fields inside `CreateModel` operations doesn't mean they are not supported. I can still have a manually created migration with `CreateModel('app', 'A')` and `CreateModel('app', 'B', fields=[('aaa', models.ForeignKey('app.A'))])` that would not be valid to optimize across for `app.A`.
You should be able to use `SimpleTestCase` (which prevents any queries) by setting an `id` manually on your score instance, avoiding the `save()` call and passing a singleton list containing `score` to `serializer.serialize()`: ``` python data = serializer.serialize([Score(id=1, score=3.4)]) ``` With this approach you should be able to hardcode the `"pk": 1` below as well.
You might want to `assertIsInstance(serializer.stream, File)` to make sure the `stream_class` attribute was actually used.
I think this means: "only the date part is ignored," drop "make sure to"
values are stored
Just state the expected behavior (no "Ensure that" prefix needed) and include the explanation about password managers. In that case, the ticket doesn't offer any additional info, so we can remove the reference to it.
two spaces before #
Extract units declared ...
You might use parenthesis to be explicit about the groupings and improve readability in these longer expressions.
`# GDAL's semiminor calculation.`
use single quotes for consistency
There are a couple assertions like this one that maybe should be updated to assertEqual/NotEqual
we usually don't include super for setUp/tearDown
isort rewrites this to `convert_exception_to_response, get_exception_response,`
could omit the blank lines since these tests are only a few lines
the link for Python 3 might be https://docs.python.org/3/library/io.html#io.IOBase
I think the test names and the tests themselves are straightforward enough that we can skip the docstrings.
I'd only use mock as a last resort and instead pass some email that will be affected by the normalization.
Might want to account for the possibility of a custom manager with something like `self.__class__._default_manager.normalize_email`.
I would reduce the test to a simpler expression: ``` python with obj.normal as normal: obj.normal.open() obj.normal.open() obj.normal.file.seek(0) ```
And add `obj.normal.close()` at the end to fix the failure on Windows.
names like view1/view2/View3 might be more readable
I guess I'm not strongly -1 but multiple variable assignment on one line is an uncommon style that I'm not sure we want to encourage.
, remove it to check that ConditionalGetMiddleware readds it.
Alternatively, I had decorated this class with: ``` # CommonMiddleware sets Content-Length too but is ConditionalGetMiddleware is # tested here. @modify_settings(MIDDLEWARE_CLASSES={'remove': 'django.middleware.common.CommonMiddleware'}) ```
Test failure is because this is missing `geography=True` on PostGIS.
From looking at the code the call could differ from Python 2 to 3 and is really an implementation detail which is not worth testing after all. My initial reflexion was more about the fact `assert_not_called()` was used below instead of `self.assertFalse(ref.called)` but now I realize there's no `assert_called()` method. LGTM
I'd use `ref.assert_called_once_with()` here.
Maybe also assign to request.resolver_match in the same line (if it works with the line limit)
``` "...when `extra_context` is passed to all admin urls." ```
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Did you consider combining this with the above test? Seems like it would be okay but maybe there's something I'm missing.
uppercasing (one word)
We might want to use `field.one_to_one` rather than `isinstance`. Maybe it depends on where the "it will be considered as editable" comes from.
Ok thanks, deleted the question below. I think it's good then
As `clean()` can also raise `ValidationError` if overridden I would avoid calling it here and stick to calling `normalize_username()`.
I'd add parenthesis to make the grouping clear: `(mysql and not connection.ops.returns_invalid_geometry_collection)`
I think a trailing underscore rather than a leading one might be a more common convention in Django for this case.
I suggest renaming the variable to `validators`.
I suggest you use the `for`/`else` construct here. ``` python for validator in validators: if isinstance(validator, validators.MinValueValidator) and validator.limit_value <= min_value: break else: validators.append(validators.MinValueValidator(min_value)) ```
As you'll already be storing validators in `validators` you can remove this variable.
You could create a new field instead of requiring an extra column with an arbitrary default on existing models. e.g. `field = self.model._meta.get_field('value').__class__(validators=[MinValueValidator(1), MaxValueValidator(3)])` And remove `ranged_field` from all the models.
No need for the list comprehension here, you can drop the `[`/`]`.
Simply return `validators`.
Ditto about the `for`/`else` construct.
``` MigrationAutodetector( self.make_project_state(before_states), self.make_project_state(after_states), questioner, ) ``` Even if `questioner` is None, there is no harm is passing it to the autodetector, that's the default value anyway.
use the same style as before: ``` self.get_changes([ [...], [...], ) ```
migration_questioner -> questioner
Should be changing double quotes to single, if at all. I wouldn't really worry about it though.
the blank line here seems to be separating logical parts of the test so I wouldn't remove it
Please wrap docstrings at 79 characters. Ticket references are only needed for obscure issues that benefit from the additional context of the ticket. Not sure that's the case here.
I think it would be better to put these tests in `tests/auth_tests` unless there's some reason that's not feasible.
To avoid creating an extra table, it seems you could use a local test model without any trouble. `s.serialize([ScoreDecimal(score=decimal.Decimal(1.0))], cls=CustomJSONEncoder)`
According to [Wolfram Alpha](http://bit.ly/29bAENj) that's the same as this and slightly more understandable? ``` python (not old_field.db_index and not old_field.unique and new_field.db_index) or (not old_field.unique and new_field.unique) ```
Ah right, the 1-1 point you made is the interesting part
A better name might be: get_constraints_counts
It might be useful to make these assertions in tuple form so that if something goes wrong, it's slightly easier to see what might be wrong, e.g. `assertEqual((fks, uniques, indexes), (1, 1, 0))`
`and not (new_field.db_index or new_field.unique)` should be easier to parse.
A docstring might be helpful. In particular, I had to study the tests to figure out what value "to" is expected to take.
It might improve readability to return a dictionary, `{'fks': x, 'uniques': y, 'indexes': z}` rather than having to remember the order.
Why do you continue here? `app_label` might still be invalid.
I'd chop "new" so we don't have to remove it later
could you follow the message style of login/logout? e.g. 'The logout() view is superseded by the class-based LogoutView().'
Not sure it makes a difference but before it looks like we got `form=None` in the context.
, -> . (for consistency with same message in operations/models.py)
Can you use `['indexes']` here? If not, the list comprehensions in the next lines have a `not in None` and will fail.
no need for a `list()` casting.
No `list()` casting needed here.
generate_removed_indexes() and generate_added_indexes() (add parentheses)
That looks correct to me.
Set the name of _meta.indexes. This can't be done in Options.contribute_to_class() because fields haven't been added to the model yet.
"This avoids the same computation...."
names -> name
Isn't this comparing column names (`.column`) to field names in `index.fields`? I think it should be `delete_fields[0].name` instead.
chop afterwards, add period
I don't understand why this is needed.
reordering (chop dash)
Use: ``` python raise ValueError( "Indexes passed to ModelState require a name attribute, " "%r doesn't have one." % index ) ``` While we allow longer lines, we typically break up long strings like this.
chop spaces next to """ for consistent with other docstrings
Rebase and add `model` argument.
Maybe with "with_model" rather than "using_model" would be a bit shorter? Otherwise, seems okay to me.
Missing a test that fails if `(?i)` is removed. Actually as little as `r'^[a-z]+:'` will allow the tests to pass.
I think `schemes.css` would be a more explanatory name.
`# Replace any %(model_name)s / %(verbose_name)s placeholders.`
chop this second sentence
Did you consider calling this verbose_name? It could be confusing have the same name (`'class'`) in codename/name that get different values.
`codename %= ...`
I'd call the variable `interpolated_perms` -- "translated" gives the idea that some translation happens.
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
chop the second comma
A semantic test name or a docstring could be useful. (e.g. "A {% with %} tag shouldn't reset the {% cycle %} variable.")
chop trailing ", " in list
Returns -> Return
Rename to something which clearly depicts what it is supposed to return, ie like `get_session_auth_hash` below. The current name is not showing a clear intent.
I would be more descriptive... something like `get_password_reset_token_hash`.
Why is `force_text` needed here? `%s` should already call the correct methods.
Not that we are aware of, but who knows :D
"Create" (use PEP257 verb-style for new code)
Was a previous iteration of the code more complicated? Not sure the intermeidate `css_classes` variable has much benefit.
With this change, can the entire `clean()` method be removed from `EmailField` and `URLField`? The parent implementation already [calls `to_python()`](https://github.com/django/django/blob/415ae960bb9f1bdae798023fdce3247d2c938eec/django/forms/fields.py#L158).
I think the test is simple and straightforward enough that a docstring isn't needed. We only mention ticket numbers for complex issues where the context of ticket might be helpful in understanding what's going on.
I would suggest replace for second part with same from `KeyError`: `Named cycle %r does not exist` It's more transparent then fast that 'ticks is not defined', for cycle called ticks.
use pep257 docstring verb style "Reset... "
It doesn't seem particularly necessary to mention "No named cycles in template." .I think "Named cycle %r does not exist." seems like enough.
"reset it with {% resetcycle %}"? (and add period)
Just state the expected behavior rather than 'Ensure that...' (all tests ensure and test things).
Original code had space prepended, so I'd suggest to leave it and remove space in template `django/contrib/admin/templates/admin/change_list_results.html`
Similarly, I don't see much advantage to creating indirection with a method.
A bit DRYer? ``` python value = self.rhs if isinstance(value, datetime.datetime): output_field = models.DateTimeField() elif isinstance(value, datetime.date): output_field = models.DateField() else: output_field = None if output_field: value = models.Value(value, output_field=output_field) self.rhs = value.resolve_expression(compiler.query) ```
Use hanging indent: ``` python RangesModel.objects.create( ints=None, dates=(cls.dates[0], cls.dates[3]), timestamps=(cls.timestamps[0], cls.timestamps[3])) ) ```
is this needed? no tests are failing with it removed.
Can the new tests go in a separate test case? I think that would make things simpler.
I think storing ordering in extra is ok unless it needs to be retrieved in `get_source_expressions` for some reason. I don't think it does though. As long as the ordering parameter is exposed on `__init__` I think that's fine.
The ordering expression needs to be handled at least when aliases are relabeled (that is, when the query is used as subquery). I believe the safest approach is to return it from get_source_expressions and assing back when set source expressions is called Whether to store this in extra or somewhere else doesn't matter. But set/get should be aware of the expression.
perhaps `ordering_sql` is better name
don't need variables here
return here -- no need for intermediate variables
I don't think "then remove use_for_related_fields" is needed. Removing usage of the deprecated feature is always implied by deprecation warnings. Can the two options not be used together though? That might be problematic for projects that want to support multiple versions of Django.
include a space at the end of the string
how about more simply: "with a through model." (add period)
Add a trailing comma.
Add a trailing comma.
While you're at it could you initialize the `expected` list with all the warnings once instead of calling `append()` twice.
Add a trailing comma.
add comma at end of line
I felt like a refactor of index name generation was more appropriate place for an alteration of the signature of the affected method but I can take care of it in #6643 it it's deemed more appropriate.
As the method doesn't require anything from the model except its `_meta.db_table` could we alter its signature to accept a `table_name` instead? It would be more consistent with the `column_names` argument instead of an hypothetical `fields` one. This is a change planed in #6643.
Creative, but `'l%sng' % ('o' * some_number)` would fit one line nicely.
Please use `SimpleTestCase` here as no database query is performed.
move the string to the next line as done in other tests in this file
I think we'll need to keep the `if obj.pk is None` condition to fix the test failure.
use single quotes
chop blank line
The class name seems a bit specific -- not sure any other tests would fit in this class (the existing organization is a bit poor).
chop ticket number
chop "Make sure" in favor of simply stating the expected behavior. The ticket reference isn't really needed -- we reserve that for obscure issues.
a single line is fine here (up to 119 chars is okay if it helps readability)
chop blank lines here and below
I like your option 2 of `get_lookups`, I think it improves clarity over what we already have. You could also introduce some caching within the `get_lookups` to improve perf for classes that are looked up multiple times.
This doesn't strike me as an appropriate place given it's not reused anywhere. I'd put it in the file in which it's used, even possibly as a staticmethod next to the method in the class where it's used.
bust -> clear
Remove this and the previous blank line to compress it all. Same goes for the subclasses method below. This is just a matter of taste and is entirely subjective.
"... concurrently but not more than once per thread ..."
chop "Verifies that"
chop first comma and "we"
I see you just copied the docstring above but it seems like "Return a list of all..." would be simpler.
The extra queries could be generated in this line (199), as this is where the instancies are created, so so you should check the number of queries is one.
No need to use `any`... instead: `getattr(create_field, 'primary_key', False) or (a and b) ...`
Seems okay to me. I don't think `Meta.db_table` can be any other falsey value.
I meant `self.table or '(default)'` seems more neat and intuitive, but this way it is more explicit. :)
It looks like both `__init__` method can be removed as they simply delegate to `AlterFooTogether.__init__`.
I think the new tests should be in new test methods.
I'm not sure why the existing test uses `dict(...)` -- let's use `{'k': 'v'}` for the new tests.
Maybe: "To bypass ...., don't use person.houses.all() here."
I'm a bit tired right now but I had trouble understanding this. Maybe "as using" -> "because" would be clearer.
If I remember correctly there was discussions about making sure `ready()` is always idempotent as it can be called multiple times (during testing when using `allowed_apps` or overriding `INSTALLED_APPS` if I remember correctly). Now both alternatives aren't technically idempotent but closing all opened connections looks like it has more chance of having undesirable side effects then executing queries on already opened connections in a testing scenario given how Django's testing infrastructure uses transactions for example.
It would be better to use `extra_context=_sentinel` similar to what was done in 9a30acad8a1996c914351bad981d937de4db29a4.
"The unused `extra_context` parameter for `logout_and_login` is deprecated." Also, you can move this into the view rather than creating a decorator since it's only used once.
Okay, then lets not pass on the parameter to give the impression that it is used.
Yes, that's more helpful for me.
Perhaps this could be a docstring? You might elaborate a bit more -- as someone not familiar with MySQL, it's not clear to me what "improved" means.
These two lines are indented 4 spaces too much. Also chop the blank line above.
Move this part outside part outside of the `try` branch just like in `_sqlite_date_trunc`.
I meant after the `try`/`else` construct.
Could you remove this outer try/except (it was only for debugging)? The build is failing because `print` needs to be `print(e)` for Python 3 compatibility but that can be removed anyway.
``` python if 'required' in attrs: del attrs['required'] ``` or `attrs.pop('required', None)` might be better here unless I am missing something or you want to handle `KeyError` specifically.
I think the motto apply in the case where you let the exception propagate, when you catch it anyway I see no harm in using `attrs.pop('required', None)` instead.
Needed? No tests are failing with it removed.
When declaring models in test methods, you need to use [`@isolate_apps()`](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/unit-tests/#django.test.utils.isolate_apps).
It's more common to use `from django.db import models` and refer to `models.Model` and `models.EmailField`.
chop blank line
Can we remove the `email` field and the tests around it? It looks to me like that's not important for the issue that's solved.
Could you wrap this as ``` python if2 = models.IntegerField( validators=[validators.MinValueValidator(10), validators.MaxValueValidator(100)] ) ``` please.
Not sure if this might mask some exceptions, but here's what I came up with for now: ``` python for db in connections: connection = connections[db] try: connection.cursor() except ImproperlyConfigured: # Raised by the dummy backend. pass else: loader.check_consistent_history(connection) ```
I think this should work: ``` python connection = connections[db] if connection.settings_dict['ENGINE'] != 'django.db.backends.dummy': loader.check_consistent_history(connection) ```
I guess those exceptions would be reraised later on at some point though. I think the consistent history checks aren't so critical that some small chance of incorrectly skipping them will cause big problems (after all, we've had migrations since 1.7 and the chance of inconsistent history is fairly low in the first place). Unless someone has an alternate proposal that isn't too invasive, I'm inclined to go with the exception catching that I proposed. We might revisit the issue in 1.11 if needed.
Another option is to remove the `check_consistent_history` call from `makemigrations` in 1.10 and revisit it in 1.11.
Yea, I think we need a better way to identify the dummy backend. I haven't found one yet.
> Unless someone has an alternate proposal that isn't too invasive, I'm inclined to go with the exception catching that I proposed. We might revisit the issue in 1.11 if needed. Sounds good to me
This is probably not that important, but the `password is not None` part is not tested.
I think `__str__` can be omitted here. If it needs to stay, `CustomUserWithIntegerUsername` should be wrapped by `@python_2_unicode_compatible`.
Do you think it could be worth deprecating the `host` parameter of `is_safe_url` in favor of an `allowed_hosts` one now that it accepts multiple values? This function is not part of the public API but a lot of third-party applications rely on it.
self->same_host (I think that's what's meant)
I think the `app_configs` need to be initialized if they're `None` so that overridding `INSTALLED_APPS` has a limiting effect here. E.g.,this might work: ```python if app_configs is None: apps.get_app_configs() ```
The change is fine, I'm just asking that it be a be separate commit similar to 31098e3288595c13f165935f2579f1af744e5240 so that the refactoring isn't mixed in with the new feature.
Same 'mutually' typo here.
Use: ``` msg = '...' with self.assertRaisesMessage(ValueError, msg): ```
My think was that the `setUpTestData` changes would be the first commit and changes like this would be included there so that the bug fix commit doesn't have to make changes in unrelated tests.
Add a trailing comma.
chop "check that" and just state the expected behavior.
Use: ``` self.assertSequenceEqual( Article.objects.order_by(F("author").desc(nulls_last=True)), [self.a4, ...] ) ```
Please make this change and the test changes unrelated to the bug fix in a separate commit for clarity.
Add a trailing comma.
single line looks better here
Rather than using tuple indexes, it's more readable to use tuple unpacking: `[model._meta.get_field(field_name) for field_name, order in self.fields_orders]`. I made that change when committing.
I suggest using a `global` boolean variable instead of a `dict`.
no blank line here
Please chop the comma here.
I'd put `=self.get_resultclass()` and skip the intermediate variable.
return here without a `kwargs` variable.
Yes, we don't need a try/except/fail. Hiding the original exception makes debugging more difficult and I've removed this pattern wherever I found it in Django's test suite. Please see the build failure for the JSON test failure and uncheck "Patch needs improvement" on the ticket when things are passing.
_Minor:_ `JsonStr` could be renamed to `JSONStr` or `JSONString` to be consistent with the naming of `InvalidJSONInput` class above.
State the expected behavior: MigrationLoader.check_consistent_history() should ignore unapplied squashed migrations that have all of their `replaces` applied.
chop the blank lines before each attribute
Same style as above.
chop "Make sure that" prefix. e.g. "Non-ASCII characters encoded as valid UTF-8 is correctly transported and decoded." (better yet, explain what "correctly" means)
Use PEP257 verb style (Encode, return, etc.)
I guess this means that the line below could be replaced when only Python 3.5+ is supported. It would be nice to be more explicit about that.
chop blank line
chop blank line
chop blank lines
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
chop blank lines
DatabaseError is raised if a ....
If ...., the locked row is skipped resulting in Person.DoesNotExist.
I'd rather if you made these changes including rewriting existing docstrings in a separate commit.
A bit simpler? ``` python python_startup = os.environ.get('PYTHONSTARTUP') python_rc = os.path.expanduser('~/.pythonrc.py') python_rcs = [os.path.expanduser(python_startup)] if python_startup else [] if python_rc != python_startup: python_rcs.append(python_rc) ```
Maybe something like: `RuntimeError("setup_test_environment() was already called and can't be called more than once.")`
@timgraham I was the one who suggested storing `db` in a locale variable to prevent multiple attribute lookups in the primary assignment loop. Might be overkill as you both pointed out.
I suggested using zip now that we do multiple index lookips in `objs_without_pk` which we can assume to be relatively large given `bulk_create` was used instead of `create`.
It might be worth storing `objs_without_pk[i]` in an intermediary variable to avoid 3 key access. Using `zip` would look even better IMHO: ``` python db = self.db for obj_without_pk, pk in zip(objs_without_pk, ids): obj_without_pk.pk = pk obj_without_pk._state.adding = False obj_without_pk._state.db = db ```
Is this just a stylistic thing? If so, I don't see much advantage to it.
The `zip(objs_without_pk, ids)` change seems unrelated to this fix? If it's more efficient or something, it would be better to make the change in a separate commit.
Oh, not sure. I'm not a micro-optimizer. :-)
@sjoerdjob let's remove the `db` optimization to keep the patch concise. On the other hand I still think we should use `zip`.
I think I'd put `output = str(form['point'])` in the context manager and leave the assertions outside, just for maximum clarity.
I don't think so -- the autodetector isn't a public API that's meant to be extended.
I'd probably go with operators instead of functions: ``` python added = new_value - old_value removed = old_value - new_value ```
Which spec is that? Is there an RFC to cite? We might omit this until the validator uses HTML5 validation.
It looks like `ugettext_lazy` is now unused.
I didn't see the first version of the PR which might have addressed this but it looks like `self._initial_value` is emulating `@cached_property`. To be improved on master...
Difficult to say... I cannot decide myself between the twos for now.
I'm favoring contractions lately, e.g. "Don't", "shouldn't".
I'm still conflicted. I suppose we can keep the currently implementation for now.
It seems a bit awkward to pass `initial` to this method when it's only need for one widget. I'm not sure if there's a better approach. I thought of passing the entire `BoundField` which might be useful for other use cases, but that might end up with a poor separation of concerns. To be decided.
Use single quotes for consistency.
The fields that aren't broken could be added in a separate commit just to make it clear which fields are fixed.
I guess all fields should be tested to prevent a line in `BulkInsertMapper` from being inadvertently removed.
Maybe a final comma. I caught you :-)
Do Django's automated tests ensure backward compatibility? If not I probably don't have enough familiarity with Django to do so. Glad I'm not taking crazy pills, though. :)
I'm not sure if this remains an appropriate test if it doesn't hit this block anymore? https://github.com/django/django/blob/d4eefc7e2af0d93283ed1c03e0af0a482982b6f0/django/core/handlers/wsgi.py#L161-L168
The URL may be incorrectly encoded....
Since it's impossible to decide...., it's left ...
I've briefly audited the `WSGIRequest` constructor, technically a `UnicodeDecodeError` is still possible from `get_script_name()`. Replacing `environ['PATH_INFO']` with `environ['SCRIPT_NAME']` should hit the same codepath. Regarding removing the exception catching, that's for another ticket, but we need to check whether the RFCs expect us to repercent `SCRIPT_NAME` as well. If we did that, the exception catching could go.
Looks good. You could use this style for the docstring: A non-UTF-8 path populates ... and produces...
Slightly more concise? ``` options = {'cls': self.encoder} if self.encoder else {} return json.dumps(obj, **options) ```
Up to you but I think we usually put error cases in a separate method.
I'd use .objects.create
Similar to above, the `options =` could be outside the try block.
I haven't used `autospec` before and it's used just once in Django's test suite. If you could give a quick description of why it's useful here, that'll help me learn something.
I think you're talking about the other test. This one passes and fails without `autospec`.
What about using `types.SimpleNamespace` on Python 3 and defining `class SimpleNamespace(object): pass` for Python 2? Or doing only the latter for both PY2/3 with a todo? Seeing an `argparse` import in this code is a tad confusing, I think.
Yes, I think we should be able to distinguish between automatic indexes and manual indexes. It might not be possible to cover all possible cases (inspectdb doesn't aim for perfect output), but let's try our best. For example, a single-column GIST index on a geometry field is considered as the default index.
Now my question is if that's the right behavior. Django currently assumes that any geometry field has a spatial index by default. So IMHO the introspection should not add a `models.Index` in that case.
I'm not sure the docstring adds any value here.
Are all the `six.text_type` needed? Tests seem to be passing with at least the first one removed. Shouldn't there be tests with lazy versions of args, kwargs? It looks like these tests are mainly testing `str.format()`.
I think an explicit loop that mutates the dict might be clearer here, and avoid the overhead of a function creation and call. I believe we already do this elsewhere (but I haven't double checked).
Possibility - but as discussed I can't think of a nicer way other than maybe prepending the classname to the id.
omit the blank line
You end up cloning twice (the first original one, then this one) through this code path. Consider an else clause which handles the original case of just calling _clone.
I'd inline the queryset here.
Maybe it's a separate issue (or no issue at all, since this message is similar to the existing one), but as a non-GIS user, this error doesn't make it obvious to me where the problem lies. It could be tougher in a more complex queryset also. What do you think? ``` ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/tim/code/django/tests/gis_tests/rasterapp/test_rasterfield.py", line 339, in test_db_function_errors RasterModel.objects.annotate(distance_from_point=Distance("geom", rast)) File "/home/tim/code/django/django/contrib/gis/db/models/functions.py", line 239, in __init__ super(Distance, self).__init__(*expressions, **extra) File "/home/tim/code/django/django/contrib/gis/db/models/functions.py", line 94, in __init__ raise TypeError("Please provide a geometry object.") TypeError: Please provide a geometry object. ```
You can drop the `[]` as `any()` will take a generator.
A single line is okay here as per line length guidelines at https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style.
I believe the test shouldn't be skipped on SQLite, it's failing locally because you're closing overridden connections which are used when using in-memory SQLite databases. You should be able to remove this `skipIf` after adjusting the `finally` block to only close non-overriden connections.
I see, I didn't know the SQLite backend `close()` method was already dealing with this case internally. I suggest you only skip the test if an in-memory backend db is used in this case. If you can't do this using `@skipIf` raise a `SkipTest` exception in the test instead.
I think ideally we could refactor this so that SQLite doesn't get some special treatment (`conn.vendor == 'sqlite'` check) in `TestCase`. Maybe we can leave thing as-is for now (don't introduce this method) since that's outside the scope of this ticket.
Sure. Sometimes I mark a ticket RFC if only relatively trivial updates remain. Then I'll just make those updates myself if the contributor doesn't do so.
Only non-overriden connections should be closed. See the `self.connections_override` block above.
chop blank line
so we can -> to
chop blank line
You could use lambda to save some lines defining the function
`# With form data. ...`
`# Without form data` seem sufficient.
Could you try to write these tests at a lower level, without the `as_ul()` output methods? They're difficult to debug now.
For the second sentence, maybe: "Use initial data from the form or the field, in that order."
This error message is confusing. A `Car` instance doesn't have a `car` field. Should it refer to the `make` field instead? The `CarDriver` through table has a `car` foreign key with `to_field='make'`.
save is not needed : objects.create returns an already saved instance. Tests succeed without the save
Use hanging indent: ``` raise ValueError( '"%r" needs to have a value for field "%s" before ' ... ) ```
save is not needed : objects.create returns an already saved instance
Not sure, clearly the issue isn't `to_field` specific. Since the fix involves lookups my instinct was to look at `tests/lookup` or another test app that's lookup related. I think of "queries" as anything that doesn't fit in a more specific app, but if it's easier to keep it in here, I guess it's okay.
It usually isn't a problem. There always the option to add another field to that model if making the existing field nullable causes an issue.
Could you try to find a better place for the test? The previous test uses that lame naming because it's truly some strange queries. In simpler cases, we usually try to use a more meaningful test name and it doesn't need its own test case.
It would be nice to align the various `FROM`s and `JOIN`s with there corresponding `SELECT`s (like in all other queries of the file) for better readability. Also, all other queries seem to prefer putting `AND`s at the beginning of the line.
I can't make a meaningful difference between this name and the other `is_in_memory_db` method. Do you intentionally name the methods differently? Should we make it a `@staticmethod` since `self` isn't used? Prefer single quotes for the strings.
I guess it's fine (about method location).
I don't know of any nuances about staticmethod and inheritance. If anyone's subclassing the SQLite backend, I've never heard about it.
Do you think this would be an improvement: ``` python if can_share_in_memory_db: if test_database_name == ':memory:' return ... elif 'mode=memory' in test_database_name raise ... ```
URL seems to be unused
The guideline is "don't include unrelated cosmetic changes in bug/feature patch."
Please revert whitespace change.
It would be appropriate to make the renames in a separate commit unless this is the only one to be fixed in which case it's probably not worth separating it.
use single quotes for consistency
Chop "We" "now invalid" -> "invalid according to RFC 7232"
prevent ETags in the old RFC 2616 format
return without intermediate `etags` variable
When changing docstrings, we are updating them to use PEP 257 verb style: Parse / Return, etc.
It would be better not to make whitespace changes like this.
Could you annotate the regex similar to: ``` tld_re = ( '\.' # dot '(?!-)' # can't start with a dash '(?:[a-z' + ul + '-]{2,63}' # domain label '|xn--[a-z0-9]{1,59})' # or punycode label '(?<!-)' # can't end with a dash '\.?' # may have a trailing dot ) ```
> For the sqlite3 case the connection will never close (it can't) so the test will fail. The bug can only be reproduced with postgresql oracle and mysql so testing sqlite is pointless to me. Keep in mind that while the default test settings use an in memory SQLite database running the suite with a file based SQLite database is a valid setup that should be accounted for.
would it be simpler to call `ensure_connection()`? (no context manager needed)
Yes, never mind re: my alternative suggestion. As written that of course wouldn't work. :)
Yes, that's what I had in mind. This is why I suggested the idea of including this logic in the base implementation (to eliminate having to copy the logic into three different places). Alternatively, you could do something like this at the beginning: ``` try: conn = self.connection except AttributeError: return False ```
Also, if you are using a context manager, it seems like you want to assert calling `is_usable()` right before you close (so after the context manager closes).
> because with sqlite3 the in-memory test database cannot be closed. I said in the test for all backends, you can check that calling the method doesn't raise an exception.
`# Storing language in sessions is deprecated - RemovedInDjango21Warning` (for greppability when doing the removal)
If line length isn't an issue... `self.assertEqual(self.client.session[LANGUAGE_SESSION_KEY], lang_code) # RemovedInDjango21Warning` or something like "The following assertion is RemovedInDjango21Warning"
replace "will be removed..." with "RemovedInDjango21Warning"
I would if a message like this might be more intuitive? "The client language will no longer be stored in `request.session` in Django 2.1. Read it from `request.COOKIES[django.utils.translation.LANGUAGE_COOKIE_NAME]` instead."
chop "Check that"
I think it would be clearer if `_get_view_func` did the exception handling and returned `None` for this case.
`pass` might be fine here since we don't need the return value
Is it correct that this `args` is different from the previous test? I'd expect the same test for both Python 2 and 3 with something like `self.assertEqual(response.status_code, 200 if six.PY3 else 404)` but maybe I missed something.
Would probably be nice to check the results and the proper number of queries.
A separate test file, e.g. `test_multitableinheritance.py` might be nice.
Use hanging indent: ``` special_people = models.ManyToManyField( 'Person', through='ProxiedIndividualCompetitor', related_name='special_event_set', ) ```
It's not clear to me if some of the extra fields like `disqualified` are needed. In general, it's nice to keep things minimal.
I'd move fake_initial to the next line and include the trailing comma
maybe drop spaces around =
variable seems unneeded
I'd like a docstring, especially to explain the applied_migrations parameter.
See also my recent Trac ticket suggesting to normalize behavior across Python versions.
I wouldn't have reflowed this line since you didn't make any other changes and it would simplify the diff.
Please check with Python 3.6, no exception is raised here (see a7a7ecd2b026c61a39a46d2d7eced0e06a92c970).
I think this works fine and is a bit simpler: `with mock.patch('django.utils.timezone.now', return_value=aware):`
State the expected behavior, e.g. "Prototypes are registered only if their respective driver counts aren't zero."
You can drop the "04".
chop blank line
The main issue here is that overriding `DATABASE_ROUTERS` doesn't allow passing initialization arguments to the specified classes hence why I suggested overriding `routers` directly. Another solution could be to make `Router` depend on a class attribute instead and override it in the loop: ``` python class Router(object): target = None def db_for_read(self, model, **hints): return self.target db_for_write = db_for_read @override_settings(DATABASE_ROUTERS=['admin_views.test_multidb.Router']) def test_foo(self): for db in connections: Router.target = db ... ```
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
And I would rename this attribute `superusers` as it's meant to contain multiple users.
`['%s.Router' % __name__]`
use `reverse()` rather than a hard coded URL.
use single quotes for consistency
include a trailing comma
You should keep the `csrf_protect_m` decorators on the `change_form` and `delete_view` instead as preserves the actual nesting ordering and avoids beginning a transaction in the rare case CSRF validation fails.
While we support Python 2, use `from django.test import mock`. Also, you may squash your commits when updating.
You can use `mock.atomic.assert_called_with(using=db)` here instead.
Or use the `self.settings()` context manager if you can't decorate the class since you have a loop.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
I think the `hasattr` is unnecessary as the check is after `super().__init__()`. A child class of `BaseForm` will always have a `fields` instance variable, right? Removing the `hasattr` does not cause any tests to fail.
I'd say: `fields = ('email',) # without USERNAME_FIELD`
The wording we usually use is "django.utils.translate.string_concat() is deprecated in favor of django.utils.text.format_lazy()."
It would be better to mention that in the release notes. :-)
Could be removed I think. If there's a use case for any third-party backends we can add it back later.
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
The `index_type = indexes['reporter_id'].pop('type', None)` pattern from the old test should be used rather than a loop -- otherwise, if there' some mistake in the if-condition or if the loop is empty, it's not certain that this assertion will ever run.
To avoid the index name, how about this: ``` index = {} for key, val in constraints.items(): if val['columns'] == ['headline', 'pub_date']: index = val break self.assertEqual(index['type'], 'btree') ```
Ddon't think this is needed since the next line would raise KeyError anyway
"its" (but could chop "and it's type" I think)
I don't expect index names to change radically in the future, if at all, but even if it does, I think simplifying the test is worth the "risk" of having to update it in the future, which seems like no big deal.
Ditch all usage of `six`.
You can use `self.assertCountEqual` as of b5f0b3478dfcf0335f8ac2038d59f54b4a05f2a0.
You can use built-in `django.contrib.auth.backends.BaseBackend` instead of custom `BareModelBackend`.
Please add a trailing comma.
Please add a trailing comma.
Please add a trailing comma, and in all other assertion method calls below.
Collapse this decorator into a single line.
Collapse this decorator into a single line.
I think you could use `self.assertSequenceEqual` rather than this.
This should likely use the `storage.exists()` method.
I removed the NotIn assertions in my edits because they are brittle since a typo in the message means they would inadvertently pass. I suppose if error messages were class attributes that would make it more robust, but it seems unlikely to me that a regression could be introduced such that both messages are displayed.
I think it would be more clear to put this in the `if self.is_local_storage() and self.storage.location:` block
We could add a `files_copied_msg = "static files copied"``attribute and`self.assertIn(self.files_copied_msg, output)` so that something in the output is verified.
I'd put these tests below the other cases since they aren't use the mock input method.
You can remove these `u` prefixes as they are made redundant by `from __future__ import unicode_literals`
I think the prompt should still happen if `destination_path` is None since we don't check existence in that case. Only skip the prompt if we're certain the destination doesn't exist.
Use hanging indent: ``` destination_exists = ( self.storage.exists(destination_path) and ... ) ```
Docstring not needed, I think.
Parentheses not needed
I think the warning should happen in this case, since we didn't check if files exist or not, it's better to be safe.
That could be a set: `{}`
Style mistakes. -70 points
add trailing comma
What I meant about splitting the tests in a separate commit only applies to the tests that already pass before the fix. The tests that are fixed by the change should go in the second commit along with the fix. Actually, I only see this assertion failing before the fix, so it might be that the other tests need adjusting so that they're proper regression tests: `self.assertIsNone(g('/de-simple-page/'))`
I tend to include trailing punctuation in messages.
@aaugustin, hopefully you aren't using such responses in your projects?! :smile:
You could use `{!r}` so that `repr()` is called to include the quotes on strings.
It might be better to omit the quotes around status since that's making everything seem like a string.
`not 100 < status < 599` might look simpler
I'd tend toward checking at the boundaries rather than some random value.
Combining this commit with the next one seems fine. It works the same as override_settings, but you can use `with self.settings`.
Oh I see, it would fail with pylibmc. Sure you can remove this commit.
Use a single line `self.assertEqual(caches[cache_key]._cache.pickleProtocol, pickle.HIGHEST_PROTOCOL)`. I see this is changed in a later commit but it seems the skipUnless isn't needed? Maybe we could just skip this commit since it's immediately moved anyway.
"... indicating if the module is specified in settings.MIGRATION_MODULES."
I'm not sure this should be committed.
", the login process starts and the appropriate exception..." (chop "this checks that")
Use hanging indent: ``` request = WSGIRequest({ 'REQUEST_METHOD': 'POST', ... }) ```
This doesn't look appropriate for `BuildAbsoluteURITestCase`.
Making use of the arguments, perhaps by asserting their values, may be useful.
I think `queryset` would be a more natural name.
AppConfigTests "TestCase" designates that this is meant to be subclassed and doesn't contain any tests itself.
I think we should use assertions like `self.assertIs(CallableTrue | CallableTrue, True)`. That'll reveal that `__or__` should return `bool` rather than `CallableBool`.
Perhaps something like this would avoid the interesting indentation: ``` params = {'BACKEND': self.base_params['BACKEND'], 'LOCATION': location} with self.settings(CACHES={'default': params}): ```
... that doesn't _allow_ migrating ...
This logic seems a little convoluted. Consider: ``` python conns = connetions.values() if settings.DATABASE_ROUTERS else [connections[DEFAULT_DB_ALIAS]] for conn in conns: if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(router.allow_migrate(connection.alias, label) for label in labels)): ```
Right (actually there's a bug in that code, the `ImproperlyConfigured` can never be raised).
actually, one needs to be a little more careful: ``` python conns = (connetions.values() if settings.DATABASE_ROUTERS else [connections[DEFAULT_DB_ALIAS]] if DEFAULT_DB_ALIAS in connections else []) ```
I had some trouble understanding exactly what this meant. Suggestion, "If this pattern is targeted in an include(), ensure the include() pattern has a trailing '/'." There is also "docs/ref/checks.txt" to update with the new message.
No comma needed since "creates an..." isn't an independent clause.
Chop "Test" and just state the expected behavior (all tests test things).
could move this to the previous line
Do you feel strongly about not including the rest of the Base classes as defaults here? That would save having to import them in the dummy backend and perhaps make it more clear all the attributes that should be overridden.
I think the `conn` intermediate variable could be omitted.
State the expected behavior. No "Check that" or "Test that" prefixes since all tests do that.
Sorry about that, I was looking at the imports and forgot they are subclassed in that same file.
Wording suggestion: "Rendering {% include (template_name) %} raised (error)."
rather than silenced and rendered as an empty string.
The template name should have quotes around it.
We should also test for `events = Event.objects.filter(group__in=groups.query)` to test both `isinstance(self.rhs, QuerySet)` branches.
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
I don't think "qry" is advantageous over "query".
Use tuple unpacking rather than indexing: `model, rhs, obj_dict = state`
> Wonder why having queryset class is so important here. I believe it's required because of the way [`SubqueryConstraint` deals with a `QuerySet` rhs](https://github.com/django/django/blob/1ec1633cb294d8ce2a65ece6b56c258483596fba/django/db/models/sql/where.py#L201-L213).
Where in the process of replacing these constructs with `self.assertSequenceEqual`, see #7226.
We should also test loading the queryset doesn't perform any queries either.
Just state the expected behavior such as "Pickling a QuerySet with an `__in=inner_qs` lookup, shouldn't evaluate inner_qs." We're reserving ticket references for obscure issues that can't be easily described in docstrings (the above tests aren't a good example, unfortunately).
Using `query` directly should be safe here. `QuerySet` is really just a wrapper around `Query` to expose a public API.
_shadown_ looks like a typo to me.
I would be surprised to see that behavior for any method called `getlist` but maybe it's not unusual.
It helps readability to include the kwarg name rather than only a boolean param, i.e. `force_list=True`.
Use PEP257 verb style, "Return ..."
single line looks okay for this and the next test
I don't think there is any requirement for `default` to be a sequence. Previously, this code would work: ``` python >>> MISSING = object() >>> foo = MultiValueDict().getlist('foo', MISSING) >>> foo is MISSING True ``` Following the patch: ``` python >>> MISSING = object() >>> foo = MultiValueDict().getlist('foo', MISSING) Traceback (most recent call last): File "<console>", line 1, in <module> File "/tmp/venv/src/django/django/utils/datastructures.py", line 149, in getlist return list(self._getlist(key, default)) TypeError: 'object' object is not iterable ``` I think we perhaps need to do something like this: ``` python def _getlist(self, key, default=None, force_list=False): try: values = super(MultiValueDict, self).__getitem__(key) except KeyError: if default is None: return [] return default else: if force_list: values = list(values) return values def getlist(self, key, default=None): """ Returns the list of values for the passed key. If key doesn't exist, then a default value is returned. """ return self._getlist(key, default, True) ```
I lean toward repeating the `skipUnlessDBFeature` decorator rather than creating a separate test case since it'll require less refactoring when dropping support for 9.3.
I would omit that part. Git history should allow us to get back to the original ticket if needed.
We have to use `six.string_types` until we drop Python 2 to support unicode names under Python 2.
I'm a bit surprised if there aren't any existing file upload tests we could reuse. Maybe in tests/test_client_regress if not here? It would be nice to test that the upload works, not just that no exceptions are raised.
We generally omit `Test that...` in docstrings. You could start by `No exceptions are generated...`
I think `Parent` and `Child` model names would be more in line with other model names I've seen.
I'd like if you could rework the assertion so it always runs. Currently it looks a bit brittle in that if the if condition never evaluates to true, the assertion won't be executed and the test will still pass.
It's fine to include this test but since it's already passing without the fix, it's better in a separate commit.
Removing this 'if' and leaving the return doesn't result in any failures.
chop blank line
Looks like a few tests are missing. If I remove this if/else and just leave `return _not_modified(request, response)`, no tests fail.
Seems like there might be some opportunity to share similar logic in `_if_match_passes` and `_if_none_match_passes` but I'll leave it up to you as to whether or not it'll complicate things.
Yes, please, and take into account the pull request title changed by Tim.
Some unrelated changes seem to have crept in.
Please swap the order in the assertions and put `response` on the left, `self.assertEqual(response['Expires'], 'Sun, 17 Jul 2016 10:00:02 GMT')`
I think the docstring isn't adding any value, since it's basically the same as the method name.
could this be SimpleTestCase? I guess the errors are raised before any queries happen.
chop "valid" add period
use single quotes throughout params also, if the params fit on the same line as `Thing.objects.get_or_create(` that's fine. You could change "does_not_exist" to "nonexistent" and "some_value" to "b" to save a few characters if it helps with line length.
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
Not related to your changes I know, but I think these docstrings could go since they duplicate the test method names.
I think these names are more often of the form "OperationTestCase".
Don't want to add a db feature for that? (Just wondering about you're thinking since I thought we're trying to avoid vendor checks.)
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
Could omit the `email_field_name` variable and inline `UserModel.get_email_field_name()` instead.
"and email field name" is obsolete now.
email_field_name -> email_address to make it more realistic
State the expected behavior rather than including a "Test that" prefix. All tests do that. For example, "send_messages() shouldn't try to send messages if open() failed to connect."
`assertEqual` (the version you have now is a deprecated alias)
That's actually the last name of a character in the comic these tests are based upon :-)
add trailing comma
I'd single line these.
"Mixin for combining with a lookup"
I guess I was thinking something like example SQL would be useful.
I'm usually fairly conscious of higher level abstractions accessing very detailed properties or methods from lower down the stack. I would prefer a method within the `sql/query.py` Query object so that other implementations that may or may not yet exist have access to override this behaviour. I'd consider pushing everything from retrieving the inner query into a method and returning on that. ``` return obj.query.as_subquery_filter(obj) ``` Method name and args probably need work but that's the kind of thing I'm considering.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
What I tried didn't work out that well, so let's go with forced_pk.
I'll quickly check if an idea I'm having works here.
Is `SetupDefaultLoggingMixin` needed? Tests seem to be passing without it.
I guess most test classes have a blank line after the class and before the first test method.
chop blank line
chop blank line
I don't think it's worth changing elsewhere.
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
I just wonder if `self.formset.non_form_errors == self.form.non_form_errors`.
Hi, I was looking for a domain validator in Django and I've found this PR. I think a domain name should also be checked against a max length, as `URLValidator` does (https://github.com/django/django/blob/master/django/core/validators.py#L137).
IPs can be used in URL, so I guess that's what they mean here. Doesn't shock me.
I would create a separate `TestMySQLFeatures` class.
Link is unneeded, I think.
"All MySQL storage engines engines except MyISAM support transactions."
You don't need `record` here.
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
Usually we're using single quotes for strings unless the string contains single quotes.
Including a bit more of the message might help readability to understand exactly what `TypeError` is raised..
I don't have a strong preference about the method name, if someone else thinks `_raise_when_not_picklable` as originally proposed is more clear, we can stick with that.
I would clarify, "After pickling, this class" or "This class fails unpickling (after pickling) with".
I would be in favor of including the full exception text for the two cases with `if PY2`, etc. It's more cryptic than it needs to be. And when switching to Django 2, the `PY2` block can simply be deleted rather than having to remember to fill in the fuller message.
I don't think this `\nb#` is actually correct. There should be double quotes after the `b` before `#`.
For the sake of clarity with the bug report, can you check for `'b"' not in output` :)
Remove the parentheses, please.
This file is mostly for unit testing the `LogEntry` model, so I would limit the tests to `LogEntryManager.log_action()`. Similarly, could you try to unit test the `ModelAdmin` methods rather than having complete request/response tests? Maybe in `tests/modeladmin`. p.s. when sending or updating a pull request, please also update the ticket as I just did.
I think it would be enough to test that the default implementations return the `LogEntry`. You're indirectly testing it now by calling `super()` but the custom methods don't seem necessary.
You could replace the `resolve_method` variable with `elif getattr(resolver, 'resolve', False)` here.
Not sure if ``` def check(self): return self._check_pattern_startswith_slash() ``` is better or not.
You're still iterating over `resolver.url_patterns`. Another URL resolver might not have an `url_patterns` attribute.
I think you should either make that an `or`, or drop checking `reverse_method`. A resolver without `resolve` makes no sense. A resolver without `reverse` might.
Prefer single quotes unless the string has single quotes in it.
I would say: `pass # psycopg2 isn't installed`
Other tests use naming like: `test_json_agg_empty`
`assertEqual` the 's' version is a deprecated alias
You could avoid the delete query with: `AggregateTestModel.objects.none().aggregate(...)`. (I guess the other tests could use the same pattern, not for this PR though.)
put `RegrSXX,` on the next line to wrap imports at 79 characters.
Could you create a ticket and add it here: `# state.apps (#xxxxx).`
Could we also pass `exc_info=True` to the logger? It makes me wonder why we don't simply register a logging handler on the `'django.db.backends'` loggger in the first place instead of relying on `connection.queries`.
Oh, it turns out this wasn't what I thought at all; my bad (I've seen some place in SQL where you can use column numbers instead of column names; apparently, here, like in most of SQL, this is the constant 1, not the first column). I am torn between "remove objection to use `count(1)`" and "Now I object because of ambiguity" -- but frankly, I don't know where that place was, and it is possible the ambiguity is only in my head.
Why do you prefer `count(1)` to `count(*)`? Personally, I think column ordering (and the ability to reference a column by number) a bug in SQL, which one should avoid using wherever possible.
count(*) means it will count all records i.e each and every cell BUT count(1) means it will add one pseudo column with value 1 and returns count of all records is it correct? http://stackoverflow.com/a/280605
I'd use hanging indent as we do for Python code: ``` WHEN EXISTS ( SELECT 1 FROM user_indexes WHERE user_indexes.index_name = user_constraints.index_name AND user_indexes.uniqueness = 'UNIQUE' ) ```
That's weird -- `timezone.utc` is a `tzinfo` instance, not a subclass, like `timezone.UTC` was.
Extra space introduced before `If`.
It seems consistent with the changes below but it's still weird...
No strong feelings! Whatever works.
We standardize on `# -*- coding: utf-8 -*-`.
Please wrap at 79 chars.
I would add a note to explain why we need this, e.g. ``` If 'fail_on_restricted' is False, error won't be raised even if it's prohibited to delete such objects due to RESTRICT, that prevents ... <<explanation>> ```
Moved fail_on_restricted to the next line and use hanging indentation.
Do we need to use `self.restricted_objects` multiple times? I would simplify this, e.g. ```python for model, fields in self.restricted_objects.items(): for field, objs in fields.items(): for obj in objs: raise RestrictedError( "Cannot delete some instances of model '%s' " "because they are referenced through a restricted " "foreign key: '%s.%s'" % ( model.__name__, obj.__class__.__name__, field.name, ), objs, ) ```
IMO it's more readable without `get(model, {})`, e.g. ```python def clear_restricted_objects_from_set(self, model, objs): if model in self.restricted_objects: self.restricted_objects[model] = { field: items - objs for field, items in self.restricted_objects[model].items() } ```
IMO it's more readable without `get(model, {})` I would also collect `ID`'s in the first step, e.g. ```python def clear_restricted_objects_from_queryset(self, model, qs): if model in self.restricted_objects: ids = [ obj.pk for objs in self.restricted_objects[model].values() for obj in objs ] self.restricted_objects[model] = { field: items - set(qs.filter(pk__in=ids)) for field, items in self.restricted_objects[model].items() } ```
Do we need this change? If yes then tests are missing. IMO it is not necessary.
This seems unnecessary.
Yes we should test a real use case instead of emulating this path.
Please move `fail_on_restricted` to the next line.
chop blank line
chop blank line
This doesn't feel very efficient - there will be a query per loop. You should be able to fetch all objects in a single query, grouping by the field.
Please revert this white space change.
Invert the logic of the if statement and indent the two lines above, as the implicit return will be fine here. (Other cases of this should only be done in a separate clean up commit if you get tempted.)
```python objs_to_clear = {field: items - objs for field, items in self.restricted_objects.get(model, {}).items()} ```
This could be described in more detail. Fore example, by explaining what restricted objects are.
Line line is preferred here (lines up to 119 chars are allowed if it helps readability.
Imports should be wrapped at 79 characters.
chop blank line
State the expected behavior rather than "Test ...." (all tests test things). No need for a selenium test as no JavaScript is involved. See 3aad955ea8db1592fad0012155eaa25b72e50dc5 for similar changes.
Unneeded, I think.
chop "we". Explain "Oddly".
Please revert these unrelated whitespace changes.
Please revert these unrelated whitespace changes.
Looking at the diff, there are still unrelated whitespace changes.
prefer single quotes unless the string contains a double quote
No blank lines needed (try to follow the style of nearby tests)
Try to state the expected behavior rather than "Ensure that" or "Test that" since all tests do that. Ticket references are only needed for obscure issues that can't be explained in the docstring. I'm not sure that's the case here.
please chop the rest of the blank lines
Is it possible that the header can be duplicated? If not, I don't see the value in the NotIn assertions (perhaps you can explain).
GZipMiddleware makes a strong ETag weak.
I think the blank lines could be chopped in this test.
GZipMiddleware doesn't modify a weak ETag.
They should always be the same but you might want to use `model._meta.object_name` instead.
have to -> must
Can you please run `pages_per_range` through `quote_value()` (internal function on the schema editor).
Could you please follow the previous indentation style :)
chop blank line for consistency with `GinIndex`
I'm not sure this is needed since class doesn't have a custom `__repr__()`, we're just testing the base class.
decorate the class instead
The proposed implementation isn't exactly what I had in mind, but I'll have to look a bit later to see if the idea I had in mind is any better. For `BrinIndex`, I guess those features weren't considered by the patch author. Probably no reason not to add them.
I don't think it's important to mention PostgreSQL version details in the docstring.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Seems like BrinIndex would be consistent with GinIndex.
If a custom `__eq__()` method isn't necesary, then it seems like these tests aren't needed.
I'm not sure if `isinstance(pages_per_range, int)` is required. I think Python/Django doesn't do strict type checking like that in general.
Use single quotes
You need to wrap the second instantiation in its own assertRaises to actually test it.
I am curious if there is any particular reason for this change.
Can you elaborate on this except branch. Trying to figure out when this happens.
This shouldn't be needed once you add the custom `deconstruct()`.
"for BRIN indexes" doesn't seem consistent with usual error messages.
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
Suggested name: `get_sql_create_params`. `BrinIndex` should override this function rather than overriding `create_sql`.
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
Do we want to return even before conditionally setting `Content-Length`? (I didn't mention `Date` as it's going away in #7392).
Ticket references are typically reserved for obscure issues that can't easily be described in the docstring. Not sure that's the case here.
I'd use single quotes throughout.
Since this is testing a change in `Field`, it might be better in `forms_tests/field_tests/test_base.py` and named something like `test_field_deepcopies_widgets`.
We don't have strict guidance about this, but I think the test you've written is sufficient. Some `Field` tests will inevitably require more specific classes.
Oh I see, looks good then.
The docstring should state the expected behavior rather than including preambles like "Tests that", "Verfies that..." (that is the purpose of all tests).
The "1" and "2" confused me initially, like it were numbered steps. I'd use "one" and "two".
Please follow the test docstring guidelines in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style
Use single quotes for the names.
It would be more correct without the comma in the empty case, and I think a test wouldn't hurt.
URL->path would be more correct, I guess.
In the case of `admin.site.register(Model)` (without a `ModelAdmin` subclass, this shows something like `polls.ModelAdmin`. which could be confusing.
The wording doesn't seem quite right: "<model> for <registered admin>" seems like it should be "Cannot register <model> because <model> is already registered with <registered admin>."
chop blank line
use `.objects.create` rather than .save()` (works the same, it's just a bit shorter)
please wrap docstrings at 79 characters
I wouldn't rename the model.
chop blank line
can not -> cannot (we usually opt for "can't")
We typically use `assertRaisesMessage` to make it easier to track where the exception originates.
Raising -> Raise
Yes, I like that wording better.
Reduce to 20% of the lines and avoid multiple updates to the set: ```python return {loader.get_dirs() for loader in self.loaders if loader is not None} ```
Remove extra spaces around docstring.
Pass `True` as a keyword argument for better readability.
remove "should", e.g. "debug() bubbles up exceptions before cleanup."
This will fail if `result` is `None`.
Did you consider using mocking and assertions such as `assert_called_once_with()`? This might be a bit cleaner and more self-explanatory than introspecting `_running_test`.
Remove `debug=False` since that's the default.
It would be nice to reflow the docstrings in cases like this (wrapping at 79 characters) so that the lines aren't unbalanced.
might want to add a `and isinstance(self.upload_to, six.string_types)` as `upload_to` can be a callable.
Ticket reference isn't needed.
Ticket reference isn't needed; only for obscure issues.
`WEEKOF` is not defined in the `Oracle`. You should use `TO_CHAR` with `IW` param ``` diff --- a/django/db/backends/oracle/operations.py +++ b/django/db/backends/oracle/operations.py @@ -84,6 +84,9 @@ WHEN (new.%(col_name)s IS NULL) if lookup_type == 'week_day': # TO_CHAR(field, 'D') returns an integer from 1-7, where 1=Sunday. return "TO_CHAR(%s, 'D')" % field_name + elif lookup_type == 'week': + # TO_CHAR(field, 'IW') returns an integer from 1-52 or 1-53, week of the year based on the ISO standard + return "TO_CHAR(%s, 'IW')" % field_name else: # http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions050.htm return "EXTRACT(%s FROM %s)" % (lookup_type.upper(), field_name) ```
1-52 or 1-53. For example 2017 will have only 52 weeks (based on ISO). IMO it should be clear, that week 53th doesn't always occur.
no comma needed (and the commit can be squashed)
I would like to see that the round trip works too, e.g.: ``` + self.assertSerializedEqual(uuid.uuid1()) + self.assertSerializedEqual(uuid.uuid4()) ```
Could you use `"uuid.%s" % repr(self.value)` here instead, as in the other serializers? ``` - return "uuid.UUID('%s')" % self.value, {"import uuid"} + return "uuid.%s" % repr(self.value), {"import uuid"} ```
Why not just put the actual string here, as in the model serialization below? E.g.: ``` self.assertSerializedResultEqual( uuid_a, - ("uuid.UUID('" + str(uuid_a) + "')", {'import uuid'}) + ("uuid.UUID('5c859437-d061-4847-b3f7-e6b78852f8c8')", {'import uuid'}) ) self.assertSerializedResultEqual( uuid_b, - ("uuid.UUID('" + str(uuid_b) + "')", {'import uuid'}) + ("uuid.UUID('c7853ec1-2ea3-4359-b02d-b54e8f1bcee2')", {'import uuid'}) ) ``` This also keeps the test consistent with other tests.
Other than in error messages, the rest of this file calls `repr()` explicitly, FWIW.
On second thought, I'm actually in favour of expliciting follow=False, it prevents the test to pass if the redirection to the 404 page occurs.
I don't think `follow` is necessary here, since you should receive a 404.
There is no need to check `i18n_patterns_used` here, it's already checked above. I believe the cast to `str()` is unnecessary.
IMHO, it's clearer if you use: ``` python if not prefixed_default_language and language == settings.LANGUAGE_CODE: language_path = '/%s' % (request.path_info) else: language_path = '/%s%s' % (language, request.path_info) ```
could switch to single quotes for consistency
You should be able to use direct attribute access here: `remote_field.through`
I think this could be simplified to save some lines now the `return`s are gone: ```python domain, port = bits if len(bits) == 2 else (bits[0], '') ```
Urgh. My bad.
This is indented 4 spaces too much.
I guess you'll have to test the `split_domain_port()` function since it'll be impossible to write a regression test using `HttpRequest.get_host()` since the fix is moving logic around in that method.
Use single quotes please. (We use single quotes if the string itself doesn't contain them, existing code isn't consistent in this convention.)
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
single line please
no need for separate args now
Since utilities functions can be called in tight loops it's best to minimize the number of Python function calls when readability doesn't suffer too much.
We prefer hanging indent like this: ``` self.assertContains( response, '<div class="readonly">Multiline<br />html<br />content<br /> with allow tags</div>', html=True, ) ```
single line here looks okay
Please use periods
exists, (add comma, chop "it")
seems to be missing a placeholder at the end
include trailing comma
`CleanFilesTests` (TestCase implies the class doesn't contain any tests and is meant to be used a test base).
Use `from django.utils.six.moves import _thread`
please use periods
don't add this blank line.
setUp/tearDown should go at the top of the class.
No need to call `super()` in setUp/tearDown.
Un-needed as described below. It should also solve the isort errors.
Use `SimpleTestCase` as this is not executing any queries.
sort mock before override_settings to fix isort build failure
Use `from django.test import mock`
I'm against providing `float` (see my email to django-developers. The regex for UUID must enforce the location of dashes to avoid the "duplicate URLs for the same view " problem.
I'm not sure. A - is much more likely to be an error than a negative number. I can't remember seeing a URL with a negative number.
Let's stick with positive integers and wait for complaints.
I don't think there isn't a better alternative. Talking about "positive integers" means we still defer thinking about positive and negative ints to the end user. ``` path('articles/<posint:year>/', views.year_archive), ``` ... isn't at all as nice. Since MOST people still won't have to care about negative ints, I still think keeping "int" as the name is a good default, even though not 100% accurate. Also: there seems to be a common case for negative FLOATS, namely coordinates. But since the DEP says floats shouldn't be included that use-case is nicely sidestepped. There's also two nice workarounds to all this: just specify str as type and do the typecasting in the template, or specify your own type that supports negative floats/ints.
What is the point in providing an empty base class? Is that in case we want to add some logic to all converters, both built-in and third-party, in the future? Also you can drop `(object)` since the master branch no longer supports Python 3.
Perhaps the base class could look like: ```python class BaseConverter: @property def regex(self): raise NotImplementedError("BaseConverter subclasses must provide a regex") def to_python(self, value): return value def to_url(self, value): return value ``` to prevent duplicating these two methods in most subclasses.
That is also consistent with `SlugField.allow_unicode` which defaults to `False`.
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
```python return {**DEFAULT_CONVERTERS, **REGISTERED_CONVERTERS} ``` Python 3 FTW
Note to self: the DEP specifies a delayed deprecation.
Let's not block the merge on this. The current implementation matches the DEP which was largely discussed. I'm brainstorming to avoid future problems. Seeing the code sometimes gives new ideas.
Yes, it's redundant to have both. To be honest I'm unsure about the type check here. Perhaps at some point someone will ask to support duck-typing... In the current state of the path, this is also the only reason why the `BaseURL` class exists — it provides no behavior. Perhaps removing this and the base class is the best solution? I don't know how confusing the stack trace looks if there's this kind of error in the URLconf.
I'm going to be a +1 to just dropping `converters`
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
This was the test failure: ``` ====================================================================== ERROR: test_contains_tuple_not_url_instance (urlpatterns.tests.InvalidURLsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/usr/lib/python3.5/unittest/case.py", line 58, in testPartExecutor yield File "/usr/lib/python3.5/unittest/case.py", line 600, in run testMethod() File "/home/vagrant/django/tests/urlpatterns/tests.py", line 77, in test_contains_tuple_not_url_instance resolve('/') File "/home/vagrant/django/django/urls/base.py", line 27, in resolve return get_resolver(urlconf).resolve(path) File "/home/vagrant/django/django/urls/resolvers.py", line 505, in resolve sub_match = pattern.resolve(new_path) AttributeError: 'tuple' object has no attribute 'resolve' ---------------------------------------------------------------------- ``` This test has now been removed, I guess because the check for `BaseURL` instances has been removed from `_populate()`. I think it's safe to remove.
Not supported on Python 3.4.
Should use `assertRaisesMessage()` to verify the string also.
Reference to old style url()
This is moved from a system check -- should the system check be removed then? (code and docs in ref/checks.txt)
According to the DEP, this should be usable as a class decorator, but I don't see this here... Something like ```python def register_converter(converter, typename=None): if typename is None and isinstance(converter, str): # We're used as a decorator return functools.partial(register_converter, typename=converter) else: ... # current body ``` Alternatively, make `typename` an attribute of the converter class -- then `register_converter` takes a single argument and can trivially be used as a decorator. Making the name accessible in the converter is probably better anyway, for error-reporting in any non-trivial `to_python()` or `to_url()` method.
I think you can safely remove this.
Wrap docstring at 79 chars
Also please keep it as HttpResponseNotFound as bug only occurs when that view throws 404.
Usually, the first condition is put on the same line as the if statement.
@urbaniak yes you are right, nevermind
I beleive `skipUnlessDBFeature` is appropriate here.
@manfre knows better than me here :)
This test should use `@skipUnless(connection.vendor == 'sqlite', "This is an sqlite-specific issue")` because it is specifically testing a regex in the sqlite backend's introspection.
IMO, `%r` might be an improvement (to avoid quoting integers) except for the `u''` prefix that would be added for strings on Python 2...
Shouldn't we handle these situations? ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[['', 'zero']]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ``` Or this: ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[(None, 'zero')]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ```
Wouldn't that break with `choices=(0, "zero")`
I understand what you wanted to do here, naming is fine for this case.
This is a bit unclear to me. When you say "for select itself" do you mean the `Select` widget class? Does "its children" mean subclasses? `NullBooleanSelect` seems to be at least one subclass that doesn't pass these checks.
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
In the case of an empty select (`choices = []`), this will still output the `required` attribute, which is still not valid: ``` >>> class TestForm(Form): ... some_field = forms.ChoiceField(choices=[]) ... >>> t = TestForm() >>> print(t['some_field']) <select id="id_some_field" name="some_field" required> </select> ``` ``` html <!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Validation test</title> </head> <body> <select id="id_some_field" name="some_field" required> </select> </body> </html> ``` Check it here: https://validator.w3.org/nu/#textarea
I'd use a single line here since it'll fit.
Naming this method `choice_has_empty_value` would be more appropriate.
You are right! I assumed `render_option` was always converting falsy values to an empty string. It might be worth keeping the method in this case.
Use `django.utils.string_types` instead of `str` here.
Use `next(iter(self.choices), None)`
No need for an `else` branch as the `if` returns.
I don't think it's worth adding a method for this purpose. `first_choice is not None and first_choice[0]` should do.
No need for ticket reference.
"Always return False if the field is disabled since self.bound_data always uses the initial value in that case."
`Return false if field is disabled` instead of `or when field is disabled`
I'm more inclined to put the test in `test_base.py` rather than create a new file for behavior specific tests. The tests look like they're organized by class here.
It looks that it will not work correctly if other is `'SRID=0;...'`.
As for me, I don't think that compare geometries with strings is a good idea, but once we have such feature I don't see a problem to use EWKT instead of WKT for it.
http://postgis.net/docs/using_postgis_dbmanagement.html#EWKB_EWKT > every valid WKB/WKT is a valid EWKB/EWKT I think we could leave only EWKT for simplicity.
While `_AssertSignalSentContext` is an implementation detail of `assertSignalSent` and should be considered a private API I think it would be preferable to initialize `signal_sent` and `received_kwargs` in `__enter__()` as this allows instances to be reused.
We usually try to keep `expectedFailure` usages for tests we plan to fix in the future as the test runner doesn't consider _unexpected success_ as failures. Using `self.assertRaisesMessage(AssertionError, 'Signal was unexpectedly sent.')` would be more appropriate here.
Defining a `Signal()` instance for testing purpose would be better than relying on model signals IMHO as it would be more explicit. This would also have the nice side effect of not requiring database queries to be run, allowing you to subclass `SimpleTestCase` instead of `TestCase`.
@timgraham that's neat but that looks really fragile. Think `return Signal(providing_args=["app_config", "verbosity", "interactive", "using", "apps", "plan"])` where the name would end up being `'return Signal(providing_args'`) which can lead to more confusion than the actual situation. We could also make `assertSignalSent` accept a `msg` argument (like other `assert` methods do) to allow the user to disambiguate the origin of the failure. From my point of view the traceback is explicit enough to point the users at the correct location in their code base and figure out which signal was unexpectedly sent or not.
No trailing blank line in docstrings please.
Yea, it wasn't an entirely serious proposal. If the request comes up again, I think adding an optional `name` argument to `Signal.__init__()` might be the way to go.
I'd use a single line.
This should be `RemovedInDjango21Warning`.
SimpleTestCase should be fine. I would use a separate test file so it can be deleted when the deprecation ends.
no need for docstring
It would be fine to use `@ignore_warnings` on this test class.
No, they aren't public.
Are the check method names considered part of the public API? Can they be changed or will it break backwards compat? This function has been in Django since 1.8.
We're a couple months away (Jan. 15) from dropping Python 2 so it would be nice to avoid adding more work to do when dropping it. Have an invalid secret key seems like such an obscure issue, I don't know if it justifies all the time we're spending on it. Maybe we can just update the docs and be done with it.
This needs clarification about what an "invalid string" means. It could probably be a single sentence if you phrase it like "SECRET_KEY must be ..."
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'mysql', 'MySQL specific test.')`.
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'postgresql', 'PostgreSQL specific test.')`.
IMO you should move `LoggingCursor`, `LoggingCursorFactory` inside backend specific test (`tests/backends/tests.py` or separate `tests/backends/test_cursors.py`) and create base mixins for `LoggingCursorMixin`, `LoggingCursorFactoryMixin` e.g.: ``` python class LoggingCursorMixin(object): def __init__(self, *args, **kwargs): bucket = kwargs.pop('bucket') super(LoggingCursorMixin, self).__init__(*args, **kwargs) self.bucket = bucket def execute(self, sql, *args, **kwargs): self.bucket.append(sql) super(LoggingCursorMixin, self).execute(sql, *args, **kwargs) ... @unittest.skipUnless(connection.vendor == 'mysql', 'MySQL specific test.') class MySQLCursorOptionsTestCase(TestCase): class MySQLLoggingCursor(LoggingCursorMixin, Cursor): pass ... @unittest.skipUnless(connection.vendor == 'sqlite', 'SQLite specific test.') class SQLiteCursorOptionsTestCase(TestCase): class SQLiteLoggingCursor(LoggingCursorMixin, SQLiteCursorWrapper): pass ... ``` etc.
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'sqlite', 'SQLite specific test.')`.
Technically may be able to make this break, although it might not have any reason to ever actually happen in the wild.
It seems a bit confusing to have this docstring here without any `return` statement, perhaps some clarification would be helpful.
Please use a period.
Use `[]` (it's actually faster!)
This doesn't look too nice. I'm not sure if mocking as suggested on the original PR would be better.
Use a single line (we allow up to 119 characters when it helps readability)
Perhaps this test can be in `BaseMemcachedTests` and the subclasses can have attributes like `client_library_name = 'pylibmc'`; the test can use `'%s.Client.set_multi' % self.client_library_name`.
Use single quotes unless a string contains double quotes. Also, this looks fine to fine on the line above.
chop blank line
New docstrings should use PEP257 verb style "Returns -> Return". I'd write something like "On backends that supported it (memcached), return a list of keys that failed insertion."
Use a single line (we allow up to 119 chars when it helps readability) or we use hanging indent.
Setting `self.__dict__['regex']` doesn't work with `@property` (tested on 2.7). I don't think it's even possible to override the return value of a property like this. You'll have to dynamically return the right value in the `regex` getter.
Yeah, we will need a testcase either way ;)
It doesn't work with `property` as it defines a `__set__` method. Using a readonly descriptor (only defining `__get__` à la `cached_property`) should work here and be worth it as it would prevent a function call in what seems to a be a performance critical path.
The major difference between `migrate` and `showmigrations` is that the former only ever takes a single app name. What are your thoughts about having support for multiple app labels as you did right now? Is this by coincidence. Intentional. I would have thought of just mimicking the `migrate` API with a single app label as opposed to multiple.
Chop "Makes sure" prefix in favor of stating the expected behavior as described in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/.
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
can you call `sort` on the invalid_apps before joining them, please.
Copy / paste? I would have expected the ordering to change for the `duth1` and `duth2` arguments.
Since the same result is expected as above, wouldn't it be clearer to save the output in a variable? Something like: ``` expected = ( "[ ] author_app.0001_initial\n" "[ ] book_app.0001_initial\n" "[ ] author_app.0002_alter_id\n" "[ ] mutate_state_b.0001_initial\n" "[ ] mutate_state_b.0002_add_field\n" ) ```
Swap the apps in `call_command()` but leave them sorted in the error message.
Why's that? It's non-obvious at first glance.
Yes and no. Keeping the output explicit feels easier to read.
It would help readability to use a name like "nonexistent_app" rather than "duth..".
non existing -> nonexistent
You could use single quotes in all strings for consistency (don't worry about existing tests).
no comma needed
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
Single quotes for all of these as well.
Python2 does not support `super()`.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
Not necessary if you subclass `IntegerField`.
I saw that you're now handling this at the database level. It makes more sense to me.
Wouldn't be required if you subclasses `IntegerField`.
Subclassing `BigIntegerField` and `SerialField` should do here.
Might be worth testing for the actual type.
chop blank line
Unwrap this if statement, please use single quotes.
Use a single line (we allow up to 119 characters when it helps readability
initialize (American spelling)
chop "We", e.g. The _next_serialized_rollback attribute is initialized ....
no need of inheriting from object
Drop the blank line, avoid the unnecessary temporary variable for the return statement.
Drop the blank lines in this function - there are really only five lines which isn't hard to read.
Flatten to a single line - code wraps at 119 characters.
I'd skip the blank line at start of every class to keep things more compacted.
just calling super() should be ok for python 3.
chop blank line
`for data in json.loads(...):`
Here's another place where an unnecessary line break is inserted after the period.
Line wrapping looks odd with each new sentence as a separate "paragraph."
`Klass` → `model`
Wrap at 80 characters.
Drop the blank line.
`long` doesn't exist on Python 3. You would want to use `six.integer_types` but as Simon said, this fix doesn't look elegant.
Chop blank line.
I'd use: `def strip_quotes(table_name)` (considering the leading quote is removed also, not just the trailing one).
suggested wording: ``` Strip quotes off of quoted table names to make them safe for use in index names, sequence names, etc. For example '"USER"."TABLE"' (an Oracle naming scheme) becomes 'USER"."TABLE'. ```
Doesn't seem required now that the test is skipped on non-Oracle.
I wonder if it would also be possible to test the namespacing on other backends. For example, we could use the database name on MySQL and create a schema on PostgreSQL. I'm not sure if this is testable on SQLite.
Please remove `:` from the end of line.
All those `self.function` definitions are used by `GeoQuerySet` which is currently deprecated. I wouldn't touch them and would concentrate only on function names.
Use single quotes for consistency (and below)
Keep the `update()` syntax (like below).
A better improvement throughout the PR would be to move away from one letter variable names, e.g. `lookup` here.
Yes, I guess we'll want to fix those errors.
Include a trailing comma in lists like these to allow adding more items later without having to modify this line again. Also, use single quotes rather than double. (We're using single quotes in new code except if the string contains a single quote.
`self.assertIsNone` except for that the patch LGTM.
While you're here, I wouldn't mind if you single-lined all these: ``` cls.a1 = Article.objects.create(headline="Article 1", pub_date=datetime(2005, 7, 26)) cls.a2 = Article.objects.create(headline="Article 2", pub_date=datetime(2005, 7, 27)) cls.a3 = Article.objects.create(headline="Article 3", pub_date=datetime(2005, 7, 27)) cls.a4 = Article.objects.create(headline="Article 4", pub_date=datetime(2005, 7, 28)) ```
Does the next patch use the fifth `Author`? If so, it might be more maintainable to replace this hardcoded list with something like `list(range(1, Author.objects.count() + 1))`
put closing ) on the next line
chop blank line
`)` on new line
using `assertCountEqual` would save all the fuss with ordering here
s/non empty/non-empty/ (twice)
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
one line ```py return ( isinstance(other, self.__class__) and self.relation_name == other.relation_name and self.alias == other.alias and self.condition == other.condition ) ``` `and` shortcuts, so it won't try get `other.relation_name` if it's not an instance of the same class 😉
ditto, "alias must be different to relation_name"
ditto, "alias cannot be empty"
Generally we don't repeat the name of the class/function in which the error occurred in the message, this information is already in the traceback. Also I'm not sure `FieldError` is much better than `ValueError` here I suggest "relation_name cannot be empty" as the message
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Check existing tests for the style to use for `assertRaisesMessage`.
no blank lines needed
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
The closing parenthesis should always go on the next line.
This should use `connection.ops.quote_name()` so a separate test for MySQL isn't required.
`None` in `getattr` is already default.
Don't inherit from `object`.
@timgraham already pointed the code formatting of the tests. Please don't make newlines at dots, `tests/annotations/tests.py` has good examples of the style.
This file isn't following the indentation style of other tests. Please use hanging 4 space indent.
I'd single line these to save lines: `[self.a4, ...]`
Is there any more graceful way we could do this? It seems odd to make `request.POST` immutable, but then to get past that by replacing it with a mutable instance in this cases. (May not be a show stopper, but worth considering)
I think verifying the results wouldn't hurt, e.g. `self.assertSequenceEqual(groups2.filter(id__gte=0), [g])`
single line looks okay here
I think this test would be fine without the blank lines, it's fairly short.
This could be simplified to use `m.groups()`...
Using `str('name=Hello%20G%C3%BCnter')` would also work here but using `six.PY2` could be a nice reminder to remove the `b'...'` branch.
@adamchainz - of course... hadn't had my morning coffee!
Please use more specific assert methods where available, in this case: `self.assertIsInstance()` Having said that, it looks as though the `isinstance()` check here still causes the tests to fail...
you need to drop the `__class__`, the `object` itself should be an instance of `Author`
I guess this line isn't adding much value since we wouldn't put it on every date_interval_sql docstring.
I wasn't suggested that, but perhaps it would make the test more readable/clear, lest someone copy the current pattern.
:+1: using a single query with `annotate()` should help here.
@felixxm I think what Tim means is using different aliases for each annotations.
When there are only two coordinates, the for loop doesn't seem to be so much better...
State the expected behavior in test docstrings and wrap docstrings at 79 chars per [Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ``` """ ORM queries are allowed after an error and a rollback in non-autocommit mode (#27504). """ ```
As far as I know, non-automcommit mode hasn't been usable since 1.6. The docs say something that boils down "you're on your own and you aren't going to have fun" because no one could offer a use case for running a web app without autocommit so I didn't put effort into supporting that. If there's an additional regression from 1.9 to 1.10 (unclear to me), the fix should be backported. If not, I don't think it should be backported.
Oh. Interesting :-| Bisecting the regression on Django's master branch with your test will show where the regression happened. Depending on what this reveals, a backport could be in order, even if the regression is old.
I didn't see any indication this is a regression. Please add details about where the regression was introduced to the ticket.
The deliberate error in the reproduction script (`u.is_active = False, # assigning a tuple to a boolean field`) doesn't raise a `ValidationError` until that commit.
Bisected to 388bb5bd9aa3cd43825cd8a3632a57d8204f875f. I didn't finish investigating to understand why that's relevant here.
Move this line to line 15 and you're good :smile:
Possibly. In general we've been moving toward `SimpleTestCase` but I don't know if requiring it is worth the effort.
Again this is mostly unrelated, but it's mildly inconvenient when deprecated tests are removed because it often creates backport conflicts due to removal of `import warnings` and the tests themselves. I was thinking maybe a policy of putting deprecation tests in a separate file (e.g. `dispatch/test_removedindjango20.py`) could mitigate this a bit while also easing removal of deprecated tests.
If the assertion above fails, they signal won't get disconnected. I think it could affect test isolation, correct? I guess some existing tests have that issue also. Maybe a future enhancement could be a context manager to allow connect/disconnect without having to write try/finally everywhere? I'm not insistenting on using try/finally now.
I think `assertRaisesMessage` should work here and works on py2/3.
Lately, we're using single quotes except for strings that contain single quotes. I guess it's not worth being inconsistent in the new tests though.
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
Might want to move the `not chunked_fetch` local variable checks before performing a double attribute lookup with `self.connection.features.can_use_chunked_reads`.
Did you consider updating the `def create_cursor` definition on the other backends so if/else isn't needed? This could be mentioned in the "Database backend API" changes in the release notes. If we want to keep both signatures, something like `return self.create_cursor(*(name,) if name else ())` might be less repetitive. I see this pattern is used a few times.
We might want to avoid storing this flag in `self.query` as iterating over this same queryset later on (by invoking `self.__iter__()`) would also use `chunked_fetch`. As you've mentioned this doesn't change anything now since `self._fetch_all()` calls `iterator()` under the hood but I don't think we want to use server side cursors for every query. I suggest we pass `chunked_fetch` as a parameter to `self._iterable_class()` and make `_fetch_all` uses `list(self._iterable_class(self))` instead of calling `iterator()`. Passing the _chunked_ parameter on `BaseIterable` subclasses instantiation could also us to define a `BaseIterable.__del__` method to delete the named cursor in cases where the iterator is not completely exhausted but falls out of scope in autocommit mode.
pushed the cosmetic edits
I'd rather be explicit here and refresh from the database. On that note, there's `u.refresh_from_db()` :wink:
`max_length` can be `None` for non-`CharField` instances of `Field`. You might want to assign the attribute only if it is not `None`.
Use `self.username_field` instead.
No, I mean that `clean_<fieldname>()` should take care of it. https://docs.djangoproject.com/en/stable/ref/forms/validation/
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
This is, we already have `username = UsernameField`.
Please don't make unrelated whitespace changes.
I'd suggest a name like `_get_sitemap_full_url`
Oops, I misread the diff and see that you only modified the existing archives. Still an explanation of exactly what going on would be nice as it's not obvious to me.
We usually use the `opts` variable to store `_meta` locally.
Might as well switch these to hanging indent while you're changing them: ``` pre_save.send( sender=origin, instance=self, raw=raw, using=using, update_fields=update_fields, ) ```
I've personally used and seen third party apps use `_state` to store extra details about model instances. For example, it can be useful to store the schema the instance was retrieved from in PostgreSQL multi-tenancy app.
chop blank line
I'm curious if there's a guideline about when to use these techniques. I'm particularly surpised at things like `_setattr = setattr`, though I haven't done much micro-optimization.
Use another lookup instead of `epoch` e.g. `second`.
Please use a single quote.
Please use a single quote.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
I'm not sure if there's much benefit to this warning. Removing it would allow third-party apps that set it to have warning free backwards-compatibility.
You can remove the `bool` wrapper while you're a it,
Wrap strings at 79 characters. ``` '....' '....' ```
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
`# Filter out fields contributed....` (chop comma before as)
Put the close ] on the next line.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ``` values = AggregateTestModel.objects.aggregate( arrayagg=ArrayAgg('char_field', ordering=ordering) ) ```
``` # Transform minus sign prefixed strings into an OrderBy() expression. ordering = [ (OrderBy(F(o[1:]), descending=True) if isinstance(o, str) and o[0] == '-' else o) for o in ordering ] ```
`ordering=()` might simplify things.
Turn (capitalize) add period. sql -> SQL
Use `super()` since Python 2 is no longer supported. Single line looks okay.
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
Perhaps some refactoring using `subTest` as done in https://github.com/django/django/pull/7822 would be better.
`"""Return the index at which the ordering expressions start."""`
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
Maybe this should be `OrderableAggMixin` and not inherit `Aggregate`? I'm thinking that other mixins could be added at some point.
So [`time.sleep()`](https://docs.python.org/3/library/time.html#time.sleep) supports floats. Even halving the values would be better assuming the `timeout` argument supports floats.
Multiline is fine, but please use hanging indent: ``` cursor.execute( "UPDATE %s SET expires = %%s " ... ) ``` The other places could be changed later.
Put "Touch..." on the next line as the other docstrings do.
Use `self.assertIs(cache.touch('something'), True)` since `assertTrue()` passes if `bool(value) is True`.
I don't know if this is a "must", it might not be the case that all cache backends out there can sensibly support it
Instead of defining `success`, just return directly in the above code. I think it is simple enough.
I think you can put all the SQL on one line, up to 120 chars are allowed on django if it makes it neater and string continuations aren't that neat. But Tim will know the exact policy
ditto no need for `else`
no brackets required
isn't this still subject to the race condition discussed in implementation on the base backend? something else could `set` the key in between the `get` and `set`.
Now that Django only supports Python 3.5+ this can be much more simply defined: ```python try: ... except FileNotFoundError: return False ``` You don't need to catch any other type of `IOError` as it is just re-raised. Also don't forget to remove the `errno` import that was added.
Perhaps simplify this to reduce the indentation (or equivalent): ```python if result and mode == 'touch': ... elif result and (mode == 'set' or (mode == 'add' and current_expires < now)): ... elif mode != 'touch': ... else: return False ```
This implementation has a race condition if another thread does `set` / `delete` on the same key in between the set and get here. I would feel more comfortable with it just raising `NotImplementedError` and allowing the backends to pass through to their proper `touch` command.
Return (chop 's')
Remove the blank line here.
I think the `else:` could be removed here.
Remove the blank line here.
Docstrings should be triple-quotes.
This can be condensed into a single line.
Nonexistent is one word.
best python style is to not use the `else` here and just continue
Again here, condense by removing the assignment to `touched`.
Use `assertIs(touched, False)` since `assertFalse` passes even if `bool(touched)` is `False`.
No blank line needed in cases like this.
The closing parenthesis should be balanced, visually (on the next line).
The closing ) goes on the next line.
You can update this after 08654a99bbdd09049d682ae57cc94241534b29f0, I believe.
Using a semantic name like `Employee` looks better.
Use single quotes.
The trailing comma looks unneeded.
I'd put `hire_date` on the next line -- the longer line isn't helping readability here. Maybe it would be DRYer to put the data in a list of tuples, e.g. `'Williams', 37000, 'Accounting', datetime.datetime(2009, 6, 1),` and use a comprehension to create the objects.
I think that should be `hire_date` (two words).
I don't think the docstring is needed -- the comparison is straightforward.
what slides? Not sure it's important in which case that sentence could be removed. "To test for window functions." seems redundant with the purpose of the module.
Well, mariadb support in the mysql backend. Will get on to that soonish.
I've got an idea for how we can separate MySQL/MariaDB on the DB backend coming...
You do more type checking below, you could put this error into those clauses instead of doing it twice
Actually the `filterable` attribute would have a different meaning here, scratch that.
It seems I was wrong - there are so many examples in the code that override init just to force the output field it's not worth worrying about here. Maybe in the future we can make it easier, but not necessary for this patch.
Defining `__init__()` to specify a default `output_field` is required until we re-arrange `runtests.py` to avoid importing settings dependant modules before calling `django.setup()`.
I think having a separate base class for setting a single flag is probably overkill. If there are future changes that require more customisation then we can introduce a base class to keep things tidy. In the mean time let's not.
I might have suggested it, but I don't think arity is useful in this type.
I think this can be single lined, and since the filter clause doesn't matter we can use sth shorter, e.g.: ```python WindowTestModel.objects.annotate(dense_rank=Window(expression=DenseRank())).filter(dense_rank=1) ```
"start argument must be a negative integer, zero, or None, but got %s."
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`). Please check also other tests.
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
I've opened a separate [ticket](https://code.djangoproject.com/ticket/28560) for that.
It seems that ordering is an issue, therefore: ```python qs = Employee.objects.annotate(nth_value=Window( expression=NthValue('salary', nth=20), order_by=F('salary').asc() )) self.assertListEqual(list(qs.values_list('nth_value', flat=True).distinct()), [None]) ``` will work properly.
Since you don't actually need the instances of all those models, can you use `WindowTestModel.objects.bulk_create()` please.
How about this ```python def __str__(self): return self.arg_joiner.join(str(arg) for arg in self.source_expressions) ``` I don't see a need for a `.format()` call.
i think you should use `NotImplementedError` instead on `NotImplemented`, moreover this proves that it's untested 😞.
The last parenthesis should be moved to the next line due to hanging indentation.
The last parenthesis should be moved to the next line due to hanging indentation.
I'd locate this in `tests/backends/base/test_operations.py`.
rm 'postgres' 😉
I'm pushing an update to this... can you refactor the rest? Also, maybe it's worth moving the non-query tests to a separate SimpleTestCase that's not decorated with skipUnlessDBFeature.
The test seems to work.
The last parenthesis should be moved to the next line due to hanging indentation, i.e.: ```python qs = WindowTestModel.objects.annotate(dense_rank=Window( expression=DenseRank(), partition_by=F('department'), order_by=[F('salary').desc(), F('name').asc()], )).order_by('department', 'dense_rank') ```
Remove the last comma: `...dense_rank))`. Please remove it also from other examples.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
Might be better to define this as separate method like this: ``` def window_frame_start(self, start): if isinstance(start, int): if start < 0: return '%d %s' % (abs(start), self.PRECEDING) elif start == 0: return self.CURRENT_ROW elif start is None: return self.UNBOUNDED_PRECEDING raise ValueError('Illegal argument for start, must be either a negative integer, zero or None') ```
We usually avoid hanging indents, and prefer this: ``` WindowTestModel.objects.create( name='Jones', salary=45000, department='Accounting', hiredate=datetime.datetime(2005, 11, 1) ) ```
( #7778 )
Please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style)
Use single quotes.
`for_save` is True for inserts and updates, so you can remove this and put the fielderror into the resolve_expressions that make sense.
Please round to the greatest common decimal precision i.e. `15`: ```diff diff --git a/tests/expressions_window/tests.py b/tests/expressions_window/tests.py index 70cc48c..e8fb660 100644 --- a/tests/expressions_window/tests.py +++ b/tests/expressions_window/tests.py @@ -411,7 +411,7 @@ class TestWindowFunction(TestCase): self.assertQuerysetEqual(qs, [ ('Moore', 'IT', 34000, 0.0), - ('Williams', 'Accounting', 37000, 0.0909090909090909), + ('Williams', 'Accounting', 37000, 0.090909090909091), ('Smith', 'Marketing', 38000, 0.181818181818182), ('Johnson', 'Marketing', 40000, 0.272727272727273), ('Jenson', 'Accounting', 45000, 0.363636363636364), @@ -422,7 +422,7 @@ class TestWindowFunction(TestCase): ('Wilkinson', 'IT', 60000, 0.818181818181818), ('Johnson', 'Management', 80000, 0.909090909090909), ('Miller', 'Management', 100000, 1.0), - ], transform=lambda row: (row.name, row.department, row.salary, row.percent_rank),) + ], transform=lambda row: (row.name, row.department, row.salary, round(row.percent_rank, 15))) ```
Or split the args over two lines if it passes 119 chars.
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
You can omit these parentheses: `if start and start < 0 and end and end > 0:`.
I think you can remove temporary `msg`, also dot is missing and probably `preceding` should be uppercased and `n` should be lowercased. ```python raise NotSupportedError( 'PostgreSQL does not support RANGE BETWEEN n PRECEDING AND n ' 'FOLLOWING.' ) ```
Dot is missing. `as source expression` -> `as a source expression`.
Maybe `# If the expression can be used in a WHERE-clause.`.
This line can be removed since `Func` already has `arg_joiner`.
`ExpressionList.__repr__()` can be removed because `Func.__repr__()` works in the same way.
Dot is missing. Please add a dot to all exception messages.
Maybe it will be better to raise `NotSupportedError` instead of `NotImplementedError`. I would say `Window expressions are not supported on this database backend`.
In the `test_nthvalue` Oracle returns empty string `''` instead of `None` for char fields.
It's weird, because Oracle interprets empty strings as nulls.
Maybe `# If the expression can be used in a WHERE-clause.`.
`return corresponding text for use in an OVER-clause window-frame.` Might also be worth noting that `start` is the preceding offset from the current row, where `end` is the following offset from the current row.
`An expression containing multiple expressions. Can be used to provide a list of expressions as an argument to another expression, like an ordering clause.`
A list of expressions can be represented by a Func expression that only has arguments and no function call. See: ``` class ExpressionList(Func): template = '%(expressions)s' arg_joiner = ', ' def __init__(self, *expressions, **extra): if len(expressions) == 0: raise ValueError('%s requires at least one expression' % self.__class__.__name__) super().__init__(*expressions, **extra) ```
Ok, this is our first serious issue. I don't think window functions should be inheriting from `Aggregate`. `Aggregate` implies grouping and `GROUP BY`, but also has other properties (which might be relevant). By inheriting from `Aggregate`, the query is getting a GROUP BY added to it. ``` In [9]: books = Book.objects.annotate(before=Window( ...: expression=Lag('pages'), ...: order_by=F('pages').asc(), ...: partition_by='publisher') ...: ) In [10]: print(books.query) SELECT "aggregation_book"."id", "aggregation_book"."isbn", "aggregation_book"."name", "aggregation_book"."pages", "aggregation_book"."rating", "aggregation_book"."price", "aggregation_book"."contact_id", "aggregation_book"."publisher_id", "aggregation_book"."pubdate", LAG("aggregation_book"."pages", 1) OVER ( PARTITION BY "aggregation_book"."publisher_id" ORDER BY "aggregation_book"."pages" ASC ) AS "before" FROM "aggregation_book" GROUP BY "aggregation_book"."id" ``` That GROUP BY doesn't affect the query results, but it will (I think) add unnecessary overhead to the query execution. Now, since any Aggregate can also be used as a Window function, and those aggregates already inherit the same properties we're concerned with here, the Window function has to cater for that. It might be enough to define `contains_aggregate = False` and `def get_group_by_cols: return []` on `Window`, but you'd need to play around with that. Any window functions that can't be used as aggregates should inherit from `Func`.
If you set the class attribute `arity = 1` you can remove the `__init__` altogether. Actually, if you do that, then you can drop this base class and just set `arity` on the subclasses.
`arity = 1`
class attribute `output_field = FloatField()` * fairly sure that's acceptable Then drop the `__init__`
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
Co-locate this with Lag and the base class rather than defining alphabetically. Same as First/LastValue.
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
`arity = 1`
They are helpful when using (i)pdb.
> In the face of ambiguity refuse the temptation to guess ;)
`abs()` is redundant since `end` is greater than 0.
I think this can be single lined: ```python # Does the backed support window expressions (aggregate OVER (expression))? ```
`if not getattr(reffed_expression, 'filterable', True):` Although you should probably be able to just check filterable. If non-resolved F expressions get here, consider adding the filterable attribute onto the F expression class so that you can assume it's always available.
This `raise` seems redundant. I would remove these two lines (617-618) and leave only `raise ValueError(...)` at the end of this method.
`else` can be removed, i.e.: ```python ... elif end is None: return self.UNBOUNDED_FOLLOWING raise ValueError('Illegal argument for end, must be either a positive integer, zero or None') ```
Same as above - separate into distinct error messages.
Isn't this equivalent? ``` if (start and start < 0) and (end and end > 0): raise ... ```
This `raise` seems redundant. I would remove these two lines (629-630) and leave only raise `ValueError(...)` at the end of this method.
I'd prefer to see two separate conditions/error messages here.
I think normally we don't `raise NotImplemented` but just return `False` so ```py return ( isinstance(other, CheckConstraint) and self.name == other.name and self.constraint == other.constraint ) ```
Put this on the previous line.
This *is* a lot of stuff to duplicate, especially as you note below that you don't understand everything. I'm concerned that future expression refactors/features will be missed in constraints and things will asplode.
I don't see any change here.
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
but it's faster because there's no function call overhead ``` In [1]: from itertools import chain In [2]: a = ['1', '2'] In [3]: b = ['buckle', 'my', 'shoe'] In [4]: %timeit list(chain(a, b)) 506 ns ± 2.19 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [5]: %timeit list((*a, *b)) 313 ns ± 4.46 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
```python kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins} if isinstance(value, F): kwargs['simple_col'] = simple_col value = value.resolve_expression(self, **kwargs) ```
I think you can use `django.utils.deconstruct` to decorate the class, the `path` argument can be passed explicitly. Since Django 2.0+ is Python 3 only, you can use keyword-only arguments with `*, arg1=None, arg2=None`.
For example, `_force_pk` (duplicated below) was removed in ec50937bcbe160e658ef881021402e156beb0eaf.
`using` argument is unused and IMO can be removed (the same in `create_sql()`).
This should use the same logic in `_check_long_column_names()` rather than only examining the default database connection.
Use a single line docstring.
You can use `connection.display_name` to get the database's name.
I'm out of my depth here; my instinct would be to figure out what the responsibilities of Q / Query / etc. are, which bits are needed for constraints, and refactor to share these bits. Malcolm's "Dungeon Master's guide to Django's ORM" talk may help.
Ah, so MariaDB *does* support them... I guess this'll help push me to get first class MariaDB support into Django after this gets merged. Also there are some wonderful hacks to make them work as blogged by the MySQL team here: http://mysqlserverteam.com/new-and-old-ways-to-emulate-check-constraints-domain/ . I think the generated column method could potentially be used by Django, it means making very different SQL on MySQL though. Not sure if it's worth it, at least initially.
This can be single-lined.
I think we can use unpacking generalization instead of `chain`, i.e. ```python sql = self.sql_create_table % { 'table': self.quote_name(model._meta.db_table), 'definition': ', '.join((*column_sqls, *constraints)), } ```
`path` is unused, so we can use a `_` instead.
I was confused by this briefly, I think you should change the below to be ``` if ( not connection.features.supports_table_check_constraints and any(isinst... ): errors.append( ```
`quote_name` is a temporary variable that's used only once, therefore I think we can remove it and use `schema_editor.quote_name` directly, i.e.: ```python 'name': schema_editor.quote_name(self.name), ```
come on, no need to pick on MySQL... "Check constraints are not supported on your database backend"
I'm not sure about "Please modify..." considering that Django doesn't support constraints like the one you encountered.
Should we use `reverse()` instead? ```python reverse( 'password_reset_confirm', kwargs={ 'uid': urlsafe_base64_encode(force_bytes(user.pk)), 'token': INTERNAL_RESET_URL_TOKEN, } ) ```
I think combining this with the previous test case is okay.
Technically there is no guarantee that this is the name of the view, though that should be accessible from resolver_match
Use `url = reverse('password_reset_confirm', kwargs={'uidb64': uidb64, 'token': token}))` to avoid the funky indentation (we prefer hanging indent).
@romgar If you find the time that would be great!
`if not (user and token)` looks more readable to me.
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
I think this is an argument to switch to the test client for those tests so you do not manually handle the session
I'd split up the URL name and the session name, especially I'd use something more descriptive ala `_password_reset_token` as session name.
@collinanderson That is a good point, at first I wanted to be safe against leaking anything (just to be on the safe side), but the DOS argument is more important.
I had a similar thought though I wasn't sure if the change would be an improvement or not. "pr" me think "pull request". I haven't reviewed this in detail yet.
You should fetch the arguments and url name from `request.resolver_match` here to ensure that we redirect to the same view, if someone hooks up `password_reset_confirm` with a different name you'd get an error here.
I didn't look at the tests yet when I wrote that, so if there are already tests covering that, it should be fine.
I think so, btw please do `resolver.kwargs.copy()` to leave the original kwargs in place on the resolver object.
Ok, but please ensure that there is at least one test testing if the redirect works properly too.
I am not really convinced that we need a specialitzed client like this, the normal test client can follow redirects, and I'd rather have the tests explicit instead of emulating part of the feature in the test client.
(Ment the lines above :D)
yeah, `request.session.get` would return none for the token and this wouldn't pass the comparision (which would be perfectly fine)
immediatelly -> immediately
do we really need that `is not None` check? `check_token` should return `False` for None tokens.
This throws a 500 if the token is not set!
PEP 8 recommends breaking before binary operators: https://www.python.org/dev/peps/pep-0008/#should-a-line-break-before-or-after-a-binary-operator
`HttpResponse()` (empty string not needed)
I thought the if style of the old PR was a bit better (with more equal line lengths).
put `self.object.pk` on the next line include a trailing comma
add trailing comma
single line looks okay here
Not for a single line, the idea is to add one for things like multi-line dicts/tuples so that if more lines are added later, we don't have to modify the last line and add a comma.
We allow lines up to 119 characters if it helps readability, or we use hanging indent like this: ``` return "<%s: %s>" % ( self.__class__.__name__, ..., ) ```
I feel like `if settings.USE_TZ and not timezone.is_aware(value)` may be simpler rather than adding another place that the function returns from.
Try to minimize the test that demonstrates the regression. I think this part isn't important -- assigning a value when creating the model should work just as well.
I think this can go in `NewDatabaseTests` rather than a new class.
Yes, I think Django would be obviously broken in such a configuration anyway.
I don't think there's a use case for `settings.AUTHENTICATION_BACKENDS` without any backends that have a `get_user()` method.
Unless I'm missing the purpose of the rest of the test, it seems sufficient to replace from here down with `self.assertEqual(self.u1.backend, 'django.contrib.auth.backends.ModelBackend')`.
Our convention is to include a trailing comma in places like this so if more items to the list later, we don't have to modify this line again.
reword: "force_login() skips authentication backends without a get_user() method."
It seems appropriate to remove `and callable(backend.get_user)` then.
double -> single quotes
of -> than the
Using tuple unpacking such as `... for a, b, ... in cursor.fetchall()` rather than indexing should help readability.
If all bulit-in backends are adding 'default' now, might as well put it in the the base FieldInfo, I think.
Possibly a docstring could be useful? `"""GEOSGeometry may be subclassed ....""""`
Explaining that in the docstring would be great.
`# If a list of input formats from one of the format_modules was retrieved, make sure...`
Check line length (79) chop "we" "If it's not there or if l10n is disabled, fall back.."
I'd use `self.assertSequenceEqual(fields['has_fooled_today'].queryset, [self.threepwood])` so two assertions aren't required. I'll change the other cases separately.
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
be more specific than Django -- e.g. "CommonMiddleware"
It might be better to say "or null" rather than "or None" since that's the value a user would enter if editing the raw JSON.
I don't know if changing the key is a good idea since would be backwards-incompatible.
`self.assertIsNone(x.getlist('a'))` seems okay.
Can be removed now.
Usual style is: ``` msg = '...' with self.assertRaisesMessage(TypeError, msg): ``` to avoid the unusual indentation.
`self.assertEqual(catalog['{count} plural3'], ['{count} plural3', '{count} plural3s', '{count} plural3 p3t'])` may help debug the test more easily if it fails.
No need for "Make sure" prefix -- just state the expected behavior per [test docstring guidelines](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
It's not required here. It was used in f179113e6cbc8ba0a8d4e87e1d4410fb61d63e75 because we were handling a possible `IntegrityError`.
chop trailing ", "
Ah, didn't know this existed yet. I see that this PR is mostly a "copy" of the ContentTypes one. Sounds alright for now, then.
I guess some tests might be needed for the router stuff.
Having the migration name hard-coded in here doesn't strike me like the cleanest solution. I don't have an alternative right now, tho.
This inserts the `RenamePermissions` operations _after_ the `RenameModel` operations. That's correct for forwards migrations. However, if you're rolling back a model rename you'd need to rename the permissions afterwards as well, hence add it _before_ the `RenameModel` operation into the migration.
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
) on next line
I'd use rename_forwards/backwards for consistency with other methods like database_forwards.
Put the } on the next line and add a trailing comma on this line. That's our convention to ease later adding more items to a dictionary, tuple, etc., if needed.
I'd skip the `assertIsNotNone` since `None.name` will error our later anyway.
else isn't needed
Something like this may be an improvement: ``` if not isinstance(context, dict): raise TypeError('context must be a dict rather than %r.' % context.__class__) ``` At least the error message can be improved to explain the expected type.
Is this check only applicable to the `if request is None` branch? I'm not sure.
Using the decorator form would be a bit more concise: ```python @DecimalField.register_lookup class DecimalLessThanOrEqual(DecimalComparisonLookup, LessThanOrEqual): pass ```
See my previous review for indentation style of this. Perhaps the common qs stuff before the last filter can be moved to setUpTestData.
You can define an `as_sqlite` method for this case.
Aha I found what you should be using for both: `django.utils.captured_stdin` and `django.utils.captured_stdout` 😉 You could also open a second PR removing the hack from `createsuperuser` and change its tests to use `captured_stdin` 👍 Presumably
these aren't necessary, you can pass `StringIO`s for `stdout` and `stdin` to `call_command` instead. there are lots of examples in existing tests e.g. https://github.com/django/django/blob/master/tests/i18n/test_compilation.py#L41
no need for breaking this over multiple lines now
not exactly true, its select() works, but not on file objects like stdin
It's unclear to me why you need this `try / finally` block. If an exception happens `populate()` in an "inner" call — and any inner call will raise an exception just below — `_populate_running` shouldn't be reset to `False` until the "outer" call terminates. In fact I don't think we need to reset `_populate_running` at all. I think it will be just as easy to make it a simple boolean that starts at `False` and moves to `True` when `populate()` is called for the first time. That will be consistent with `(apps_|models_|)ready`. I'd just call it `loading` or `started` and not bother reset it.
See below for a more drastic suggestion to improve the behavior of this flag.
used to prevent -> prevents
I'd go with `return self.dirs if self.dirs is not None else self.engine.dirs` -- it's possible that someone might instantiate the loader with an empty list (say in a debugging scenario if they are temporarily removing the one entry in the list to test something), and it's surprising to fall back to engine-dirs in that case.
This is exceeding the limit for docstrings (79) so please use multine style: ``` """ Return "app_label.model_label.field_name" for fields attached to models. """ ```
I find it odd that this does't appear as `('django.template.loaders.filesystem.Loader', ['dirs'])` while the `POST_APP_DIRS` does.
Oh, right, of course; it's because of the default behavior of FS loader to look back at the engine's dirs.
Oh, I see your answer to @charettes below.
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
This seems to be a change in Oracle 12. Oracle 11 works with SDO but also doesn't pass the `self.assertIn` later. This affects the deprecated GeoQuerySet test also. I'm happy to merge this as is and leave it up to you as to whether or not it's worth fixing separately. ``` ====================================================================== FAIL: test_asgml (gis_tests.geoapp.test_functions.GISFunctionsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/tim/code/django/django/test/testcases.py", line 1119, in skip_wrapper return test_func(*args, **kwargs) File "/home/tim/code/django/tests/gis_tests/geoapp/test_functions.py", line 116, in test_asgml self.assertTrue(gml_regex.match(ptown.gml)) AssertionError: None is not true ====================================================================== FAIL: test_gml (gis_tests.geoapp.tests.GeoQuerySetTest) Testing GML output from the database using GeoQuerySet.gml(). ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/tim/code/django/django/test/testcases.py", line 1119, in skip_wrapper return test_func(*args, **kwargs) File "/home/tim/code/django/tests/gis_tests/geoapp/tests.py", line 645, in test_gml self.assertTrue(gml_regex.match(ptown.gml)) AssertionError: None is not true ```
single line looks okay to me here
"makes sure any deferred checks..." -> "runs any deferred checks to allow dropping it in the same transaction."
That makes sense, but the check itself will already be run many times in Django's test suite with different urlconfs, so it's pretty much guaranteed it passes with plain urls.
`url.urlconf_name` is, more often than not, a URLconf name or module, not a list of patterns. It would be better to use `url.url_patterns` here as well.
you should accumulate all warnings into a list and return that at the end of the function. At the moment this returns early, if there are two non-unique names in use, only the first one will get a warning. If the user fixes that, they run the checks again, and get a new warning about the second non-unique name. Not a great workflow if there are many to fix.
I think this can be made faster and clearer by using a `collections.Counter` across all the namespace names
This seems to check resolvers nested up to a fixed level, rather than checking resolvers and namespaces nested to an arbitrary depth.
Does this url affect the test in anyway (and ditto below)? If not, I think it should be removed, as test cases should be as simple as possible
Why the `!= 'app'`? This seems to hide some test failures in `test_check_unique_namespaces`.
I think a `Warning` is more appropriate here, something like "URL namespace {} is not unique, you may not be able to reverse all URLs in this namespace". Errors prevent management commands from running, which is a bit severe for this case.
One of these should have an explicit instance namespace other than `'app'`, otherwise the nested namespaces are not unique.
You should probably check `if getattr(settings, 'ROOT_URLCONF', None)`, similar to the `check_url_config()` check.
` isinstance(param, (Database.Binary, datetime.timedelta))`
It would be better to factor out shared elements such as these variables and MultipleLocaleActivationTests setUp/tearDown into a `base.py`.
Please use the same ` -*- coding: utf-8 -*-` in all files.
Could you please revert the unrelated line length changes? I pushed some fixes to your branch before I realized that this file is also changed. Maybe your IDE went wild? We allow longer lines per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/.
Wrapping wasn't reverted here (I didn't check the patch exhaustively perhaps you can give it another look).
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
I think that you should use `connections[self.db].set_operators['union']` (resp. `'intersect'`, `'except'`) instead of `UNION`(resp. `INTERSECT`, `EXCEPT`) constants and maybe feature flags check can be helpful.
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
What about accepting a `all=False` kwarg here instead of relying on the `distinct()` method to make the distinction? Else we'll have to make sure not to allow `*expressions` passing to distinct (for `DISTINCT ON`) and limit us if we want to allow `DISTINCT ON` support in the long run. For example, I could see the following query being useful: ```sql SELECT DISTINCT ON field, ... FROM ( SELECT field, ... FROM t1 WHERE ... UNION ALL SELECT field, ... FROM t2 WHERE ... ) ```
Would it make sense to have union_all as separate method? That way there would be no need for unbounded kwargs. If not, at least assert here that there are no other kwargs than 'all' given here.
Small nit: I would suggest using a name that is not a built-in. Perhaps `all_` or `_all`.
How did you choose the defaults? I think it would be simplest to default to True and have backends opt-out as needed (that eliminates the risk that a backend fails to opt-in) but feel free to explain your thinking.
stuff -> attributes
dunder dun dunnnnn
we should consider blacklisting versus whitelisting, disabling filtering is kind of a blacklist operation as it stands, rather than a whitelist
Again, the `.all()` seems to be unnecessary, and will add a lot of overhead on combined QS's.
This could have been `clone._prefetch_related_lookups += lookups`.
without the blank lines would be more readable, I think
@Ian-Foote thanks for the clarification I always mix up the two terms.
You could put only two spaces before the `#` while you are around.
`self.tables += (alias,)`
This can also use `+=`.
`group_by = list(self.select)`
The list comprehension may be slightly more performant. I don't know if we care enough to profile it.
It's not actually a comprehension - this could just use a tuple literal.
Unnecessary list comprehension, `tuple(self.model._meta.pk.get_col(inner_query.get_initial_alias()))` should do.
What about ```python if rhs.select: self.set_select(col.relabeled_clone(change_map) for col in rhs.select) else: self.select = () ```
a single line looks okay here
I try to avoid "we", e.g. The check allows a double slash, presuming the user knows....
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
I'd chop the blank lines in this function.
I suggest: "The {} setting must end with a slash."
I'd say no.
a nice line to see gone
We usually follow this style when querysets take multiple lines ```python Book.objects.filter( name='Practical Django Projects', ).annotate( discount_price=F('price') * 2, ).values( 'discount_price', ).annotate(sum_discount=Sum('discount_price'))
You can use `assertSequenceEqual()` here ```python self.assertSequenceEqual( values, [{'discount_price': Decimal('59.38'), 'sum_discount': Decimal('59.38')}], ) ```
I'd rename this parameter to "unify_by_values" or something like that, which is a better description of what is happening here, and also explains better why it isn't relevant for execute_many.
I think most assertEqual don't include a comma on this line.
The parenthesis look unnecessary
`order_by` only needs to check for slice thus it can call this method like `check_queryset_method_allowed('order_by', combinator_check=False)`
It might be worth making the name a bit more descriptive such as `check_queryset_method_allowed`.
I don't like how a mistyped action will pass silently.
The dict can be removed if this method is only called by those methods which have to make sure slice has not been taken or union, intersection, difference has not been applied. Then this method can be shorten to. ``` def check_queryset_method_allowed(self, action_to_msg, slice_check=True, combinator_check=True): if slice_check: assert not self.query.has_limit(), 'Cannot use %s ' % action_to_msg + 'once a slice has been taken' if combinator_check: assert not self.query.combinator==None , 'Cannot use %s ' % action_to_msg + 'once %s has been applied' % self.query.combinator ``` Now methods like _filter_or_exclude, count, extra etc will have to just call this method to make sure they can execute. As we only have restrictions on query combinators (union, intersection and difference) and slice, the two keyword arguments are passed to this method.
Seems okay to me.
tests for the `repr`s of `HttpResponseNotAllowed` and `HttpResponseRedirect` already exist in `httpwrappers/tests`, please move these tests there
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
It would be less duplication to do something like: ```python if 'content-type' in self: content_type_bit = ', "{}"'.format(self['content-type']) else: content_type_bit = '' return '<{cls} status_code={status_code}{content_type_bit}>'.format( ... ``` ditto below I think moving to `str.format` is better but idk Django's current policy since there's a lot of `%` formatting around still.
Either store `content_type` in a local variable or only perform an `in` lookup in `self`: ```python content_type = self.get('Content-Type') if content_type: return '<%(cls)s status_code=%(status_code)d, "%(content_type)s">' % { 'cls': self.__class__.__name__, 'status_code': self.status_code, 'content_type': content_type, } ```
Perhaps it would be clearer to repeat this line: ```python if ch in "iLmsu#": warnings.warn( "Using (?%s) in url() patterns is deprecated." % ch, RemovedInDjango21Warning ) # All of these are ignorable. Walk to the end of the # group. walk_to_end(ch, pattern_iter) elif ch in "!=<": # All of these are ignorable. Walk to the end of the # group. walk_to_end(ch, pattern_iter) ```
yeah, as long as we don't create a function on every single call.
@charettes thanks for the idea. I made PR #7755 with regression fix.
Maybe it will be better to move `force_text` to the return line ```python return force_text(query, self.charset), self._format_params(params) ``` instead of repeating it in each case.
Any reason to pass `False` here? The default behaviour of `get()` returning `None` seems to be enough.
Presumably the intention is that `secrets` might one day use a different PRNG's on some OS's
I'm not sure what Aymeric had in mind but I see that `secrets.py` does `from random import SystemRandom` so as far as I can tell, this doesn't change any behavior or add security.
I'm in favor of adding this if the benefits become more than theoretical or when only Python 3.6+ is supported.
This allows for backports to exist and makes the code easier to maintain
In the long run I think we should deprecate `get_random_string` in favor of similar functions provided by the `secrets` module. I didn't check whether there was a sensible transition plan to make use of `secrets` on Python 3.6 while still supporting older versions. Since this PR adds complexity without changing the behavior, I don't think it's on the right track.
Why is this on two lines? Why not just...? ```python data_altering_methods = getattr(cls, 'data_altering_methods', ()) ```
I think it would be safer to teach `add_to_class` how to deal with `data_altering_methods` itself instead as introducing an intermediate class in the type hierarchy could break third-party apps.
You could modify the existing `return_json_response` view to extra `content_type` from `request.GET` to allow more tests without creating a separate view for each one.
Would be better to put this as a module constant to avoid compiling it over and over.
I'd skip the blank line after the class docstring changes. Focus on changing the verbs only.
If there aren't any content changes required, don't bother changing a docstring like this.
, -> , and
"Log out the user by removing the cookies and session object." (remove second sentence)
Should these by one liners ? e.g. """Obtain the current session variables.""" -- we currently don't have consistency about that.
Pep257 says, "Triple quotes are used even though the string fits on one line. This makes it easy to later expand it."
The `params` argument is ignored? I guess it might be appropriate to raise an error if both are provided to prevent obscure issue if this cannot be done better.
Yeah, default_site makes sense to me. - and good idea with passing a callable.
Maybe only instantiate if it's not already an instance? (That way you could pass in an instance rather than a class?) Or at least make it clear in the docs that default_site needs to be a class, not an instance.
probably just need parentheses :) a dotted path to a (class or callable). (kidding, of course)
Oh I see, I made a minor wording tweak.
Having `not full_path or full_path` in the middle of this expression is extremely confusing. Could you add parentheses instead of relying on operator precedence? `(a and b) or (c and d)` takes significantly less effort to parse than `a and b or c and d`.
You're right. I prepared separate PR #7787.
I think that I found complex solution for all binary operators in `MySQL` that return an unsigned 64-bit integer. We can simple convert return value to `SIGNED` integer. I don't know why, but it doesn't work for right shift operator. ```diff --- a/django/db/backends/mysql/operations.py +++ b/django/db/backends/mysql/operations.py @@ -202,8 +202,14 @@ class DatabaseOperations(BaseDatabaseOperations): + lhs, rhs = sub_expressions if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) + # MySQL's binary operators return an unsigned 64-bit integer. + elif connector in ['<<', '|', '&']: + return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) + elif connector == '>>': + return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs} return super(DatabaseOperations, self).combine_expression(connector, sub_expressions) ```
whether certain aggregates
I meant I thought it should change to `raise ShellImportError()` to be clearer
Could unpatch in just that one test
This still hides any `ImportError` if it's raised during the startup of IPython. I think you need to raise `NoSuchShell` when importing specific IPython versions fails, but before trying to initialize the shell, and let any other errors during initialization (including `ImportError`) bubble up.
Maybe "Couldn't import <shell>." would be slightly better wording.
I think it's impossible to reach this since the `python` shell doesn't raise `NoSuchShell`.
Please use `assertRaisesMessage()`.
The usual pattern is ``` try: import IPython except ImportError: IPython = None ``` No need for an extra variable.
chop blank line
The second half of the sentence no longer works grammatically.
Use a single line docstring if it fits: ``` """GET on the add_view.""" ```
Add a period if it's missing.
Use ticket style described at https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style, e.g. "Annotated column name is properly quoted (#18333)."
I'd say, "MySQL (except MariaDB 10.2+) doesn't ..."
Missing `self` :)
I think `[:2]` is unnecessary.
@ellmetha some checks look at the suitability of the model class for the admin, rather than just attributes on `ModelAdmin`, it's rather presumptive to skip them...
Oh yes. I don't know why that is, it's an odd restriction, I remember now I didn't keep it in #6980 because I didn't understand why it existed.
I think the setup/teardown is obsoleted by my PR only running checks for models in installed apps
This isn't great and invites test state leakage - it's directly touching the internals of the code under test and not resetting it to the way it was after the tests. It would be best if a copy of `all_sites` was made and then in `tearDown` it was reset to the original state, at least Possibly fixed by #6980 anyway
how about: "Run the system checks on all ModelAdmins, except if they aren't customized at all."
The lines below do not belong into the try block, since they don't raise the exception. ```python try: errors = checks.run_checks() else: expected = [] self.assertEqual(errors, expected) finally: admin.site.unregister(Book) admin.site.unregister(Author) ```
Also this doesn't need to be a list. A generator will do, since you loop only once over the result.
Yes, we'd need a separate test for check registration. Possibly https://github.com/django/django/pull/7781 will come up with a template to use.
Would calling `admin.site.check()` work, e.g. `self.assertEqual(admin.site.check(), [])`? That avoids running checks for all installed apps which should be a speed improvement. Other tests could be refactored later.
We typically use an underscore prefix in a case like this: `self._previous_sites`
`self._registry[model] = admin_class(model, self)` looks fine now
I think you should use `type` not `__class__`. At least in python 2 this will break if the class does not inherit from `object`.
chop blank line
I think that's a good name if the code were more complicated but `modeladmins` and `for modeladmin in modeladmins:` seems okay to me.
I'd keep the current version without `type()` since it's unrelated. If there's a need for this change, create a ticket with a corresponding test.
No need to call super in setUp/tearDown
Does that mean something like `admin.site.register(Choice, list_display=['question'])` isn't checked? If so, I that seems like an incorrect restriction.
This could go in an else block of try/except to keep the try block minimal.
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
Remove since this file doesn't contain non-ASCII chars.
We prefer hanging indent like this (with some suggested wording): ``` raise NotImplementedError( 'subclasses may provide a check() method to verify the finder is ' 'configured correctly.' ) ```
Please remove empty line.
Probably the check functions should be called directly rather than invoking them through `run_checks()` (otherwise, this runs all registered checks across all installed apps which doesn't provide good isolation) -- see `tests/check_framework`.
I think that word `anymore` is unnecessary. `'FileSystemFinder should not raise ImproperlyConfigured.` sounds better to me.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
I think this test can be removed.
Please rebase your branch. Master now supports Python 3 only, so `unicode_literals` may be removed.
It's quite interesting how Python handles the two cases under the hood. Since tuples are immutable, the whole object can be cached as a 'const' variable for the function, but as lists aren't, it must reconstruct the object (from const 1 and 2) on each invocation. You can see this using the `dis` module and looking at the bytecode: ``` In [1]: import dis In [2]: def foo(): ...: [1, 2] ...: In [3]: def bar(): ...: (1, 2) ...: In [4]: dis.dis(foo) 2 0 LOAD_CONST 1 (1) 2 LOAD_CONST 2 (2) 4 BUILD_LIST 2 6 POP_TOP 8 LOAD_CONST 0 (None) 10 RETURN_VALUE In [5]: dis.dis(bar) 2 0 LOAD_CONST 3 ((1, 2)) 2 POP_TOP 4 LOAD_CONST 0 (None) 6 RETURN_VALUE ``` Anyway, it's mostly a micro optimization, but if it's always faster, it can't hurt!
use a tuple as it's faster to construct
directly after _get_called_qs().
should not this be: qs = qs. _get_called_qs().update(foo='bar')
Any reason not to do the following? ```python return ( clean_lookup in valid_lookups or LOOKUP_SEP.join(relation_parts + [part]) in valid_lookups ) ``` A better approach would be to make `valid_lookups` a `set()` in the first place (using `add` instead of `append` above) and do: ```python clean_lookups = {LOOKUP_SEP.join(relation_parts), LOOKUP_SEP.join(relation_parts + [part])} return clean_lookups & valid_lookups ```
Chop "Make sure we also"
I think shorter lines would enhance readability. ``` clean_lookups = { LOOKUP_SEP.join(relation_parts), LOOKUP_SEP.join(relation_parts + [part]) } ```
Use `assertIs(... True)` since `assertTrue()` passes for anything `bool(x) == True`.
It's not clear to me why it's valuable to change the semantics here so that this validation doesn't happen first if `fail_silently=False`. I don't think the message must be changed to add "like".
Use single quotes consistently.
It might be better to add a new field (something like `expires` could be fine). `default=datetime.date.today` isn't compatible with `DateTimeField`.
Could use single quotes for consistency.
`for ....` could go on the next line to balance things out
Assuming we move forward with this solution, it might be better to use `*args, **kwargs` and `kwargs.setdefault('content_type', '...')` so we don't have update the signature here if `TemplateResponse` changes.
It's not safe in general, as there's nothing to reset `content_type` back - really a subclass would be needed here, and in the other places this has been dnoe
Please use spaces rather than tabs for indentation.
The proposed text makes sense but leaves me wondering where I can read more about this limitation and if it might be addressed someday.
It seems a bit odd to be that we assign a new value to `self.rhs` at SQL compilation time. Isn't it something that can be done at initialization time? ```python def __init__(self, lhs, rhs): if isinstance(rhs, datetime.date): output_field = models.DateTimeField() if isintance(rhs, datetime.datetime) else models.DateField() rhs = models.Value(rhs, output_field=output_field) super(self, DateTimeRangeContains).__init__(lhs, rhs) ```
I think it's "Transaction isolation level" i.e. no capitalization of every letter
TextInput -> Input? I suppose a `test_input.py` file would be better. I wasn't sure about the `test_no_trailing_newline_in_attrs` test -- it's meant to test a template rather than Python code -- probably I could have clarified that. `strict=True` isn't needed since the newline isn't being tested.
The docs talk about URL pattern names a lot, so I guess it's clear.
Use hanging indent: ``` msg = ( "..." ) ``` Are the new messages tested? I think you could avoid the repetition of the two branches by interpolating "keyword " in the message and varying args/kwargs in the params with a variable.
I think I would use `response.read().decode()` instead of `str()`, that would prevent the `b'` appearing in the test result above (`"subview calling view: b'subview'"`). The same for the view below.
I tend to think this style is a bit easier to read: ``` url = '/subview_calling_view/?%s' % urlencode({'url': self.live_server_url}) with self.urlopen(url) as f: ```
Please remove the leading trailing space to be consistent with other docstrings. I'm not sure if there are other classes that are empty without using `pass` (`django/core/exceptions.py` comes to mind). I'm not sure if there's any style guide for doing it one way or another.
Smart... This only works because `shell.py` does inner imports, but that does seem unlikely to be refactored
What about keeping the old logic and just changing the message to `raise CommandError("Couldn't import the %s interface." % shell)`. The error should only be trigger when specifying a specific shell anyway.
Here's an idea I found [on stackoverflow](http://stackoverflow.com/questions/28346798/python-testing-simulate-importerror) so the skip isn't needed: `@mock.patch.dict('sys.modules', {'IPython': None})`
Is this test applicable to the patch anymore? It doesn't seem to me that overriding `attrs` with `render()` is related to what this patch fixes.
On 1.10, the output is: `'<input type="number" value="1" name="code_0" />' '<input type="number" value="2" name="code_1" />' '<input type="number" value="3" name="code_2" />'`.
What happened to `{'attrs': 'date'}`? On 1.10, the output is `'<input attrs="date" name="code_0" type="number" value="1" /><input attrs="date" name="code_1" type="text" value="2" />'`.
I don't usually include a blank line here.
Is there a reason you used `None` here rather than `constants.GET_ITERATOR_CHUNK_SIZE`? As I was amending the docs with 'The default of ``None`` uses a value of 100." I thought further explanation about that reasoning might be useful.
Please use single quotes and a period.
You shouldn't use the string representation of the query but someting along the lines of what `django.db.models.fields.related.related_lookups.RelatedIn` does.
`self.assertSequenceEqual(qs.values_list('field', flat=True), [(['hello', 'goodbye'])])`
You could rewrite this as: "Create content types that weren't in the cache or DB."
You also need to update `SplitHiddenDateTimeWidget.__init__()` to add and pass `date_attrs` and `time_attrs` so that attributes can be correctly altered for that widget too. You mentioned this widget in the ticket but didn't make the changes in this PR.
Not from the top of my head, but since Python 3 provides better traceback for these kind of failures I'm not sure it's worth silently failing here.
I believe you can shorten that to `return self.children[:]`.
I tried saving this model in from admin page, I get the following validation error: ``Select a valid choice. ['a1', 'b1'] is not one of the available choices.``
This attribute does not exist if `isolation_level` has not been specified in `OPTIONS`, AFAICT
single line would be consistent with the other migrations
I think it's related to the `predicate = inspect.isfunction if six.PY3 else inspect.ismethod` line and can be removed (31fadc120213284da76801cc7bc56e9f32d7281b).
rewrap and reword: "Replace the behavior where Non-ASCII values in the WSGI environ are arbitrarily ..."
remove "but we can't do...."
Please remove `weakref_backports.py` and its mention in `setup.cfg`.
single line looks okay here
Might want to move the `)` to the next line and add a trailing comma while you are around.
I don't think you can assume ordering here.
Make sure you're using the newest version of isort. The check passes on Jenkins because of https://github.com/timothycrosley/isort/issues/423.
I'm not sure about the organization here. It would be nice to first do a PR that splits up the existing file into things like `test_checks.py`, `test_views.py`, etc.
Please run isort, this line is exceeding the line length limit.
Perhaps a nice alternative is: ``` result = json.loads(Question.answer_set.field.value_to_string(question)) self.assertCountEqual(result, [answer1.pk, answer2.pk]) ```
Usual style to avoid non-hanging indent is: ``` msg = "...." with self.assertRaisesMessage(Exception, msg): ```
Unrelated: this might be obsolete after 8f97413faed5431713c034897cda486507bf0cc3.
I think so (although some of the formatting improvements are welcome). A second opinion from someone who worked more with the new style wouldn't hurt.
I also made this change in https://github.com/django/django/pull/7912 if you want to merge that first to have a separate of concerns (I could make the misc. six removal there also).
I wonder if you made any conscious choice between `exc` and `err`. Just seems odd to change this one when other places use `exc`.
Of course, I like a lot more the result after the PR. It's just a bit unfortunate if it will trigger some "fake" migrations (which I'm not sure it will, it was just a guess).
It doesn't trigger an extra migration in my testing.
Is there a behavior changed here since `attr = bytes` changed to `attr = str`? I'm not sure what the consequences are.
Please don't make unrelated whitespace changes.
Leave ```: # For backwards-compatibility in Django 2.0 from contextlib import ContextDecorator # noqa ```
Unnecessary whitespace change.
This removal will have to go through a deprecation period.
If you could give a try at rewriting this docstring to conform to our guidelines about stating the expected behavior, that would be nice.
Use `__bool__` as master is Python 3 only.
Might want to pass an explicit empty string here or make `UndefinedVariable.string_rep` default to it and don't pass any arg along.
Not required as `__ne__` defaults to `not self.__eq__(other)` on Python 3.
Make `__str__` return `self.string_rep` and nuke `__unicode__`.
member -> attribute
You can use `assertRaisesMessage` here rather than checking the message separately.
Use: ``` msg = "Got this from the 'nonexistent' variable" with self.assertRaisesMessage(TemplateSyntaxError, msg): ``` `assertRraisesMessage
I think `var_repr` is more explanatory than just `rep`. Also, use single quotes rather than double quotes unless the string contains a single quote.
members -> attributes
I created https://code.djangoproject.com/ticket/27753 to track the eventual removal of these functions.
It seems you'll need to check the patch by hand. This is an obvious syntax error.
And also fix formatting in cases like this. Use hanging indent:: ``` super().__init__( server, param, library=pylibmc, value_not_found_exception=pylibmc.NotFound, ) ``` or a single line if it fits in 119 characters.
You might add something like "(did something different for Python 2)" similar to django.utils._os.
I think the whole test can disappear, as we are no longer considering bytesstrings on Python 3 for this sort of stuff.
You could move this to the previous line while here.
Oh no, sorry, I see now.
Unless I missed something: - before: all `OSError` exceptions are converted to `CommandError`; in addition a specific message is added when the file already exists - after: only `FileExistsError` is converted to `CommandError`
IIRC raising CommandError prevents management commands from displaying a stack trace. This doesn't seem very important but I wanted to point out the change in behavior in case it was accidental.
Won't `symlink_path` and `original_path` be removed automatically as part of the cleanup? `tempfile.TemporaryDirectory` says "On completion of the context or destruction of the temporary directory object the newly created temporary directory and all its contents are removed from the filesystem."
I think `finally` isn't needed also.
It would be nice to be consistent: either `temp_dir` or `tmpdir` (although if an existing test is using some other form and is otherwise unmodified, I wouldn't change it).
consolidate this a bit: ``` file1.seek(0) response = self.client.post('/unicode_name/', {'file_unicode': file1}) self.assertEqual(response.status_code, 200) ```
The `if iterator is None` branch a few lines later seems unused.
I would suggest not using `_` as a variable name as that may conflict with gettext imports.
Using `_` for unused variable is a common idiom.
I think the `TestStringAggregateDistinct` class could be reused considering the setup methods are the same -- just remove `String` from the class name.
I don't think `list()` is needed. `self.assertEqual(sorted(values['arrayagg'], ['Bar', 'Foo', 'Foo'])` looks good to me.
Use `super()`, master is Python 3 only.
Using a subclass isn't correct. That will cause the tests in the super class to be executed again.
Small reword: "This is the algorithm from section 3.1 of RFC 3987, slightly simplified since the input is assumed to be a string rather than ???." (same wording could be used in docs)
That wording is good.
(and yes, it could do with some more test coverage so we can figure that out)
Python 3 does indeed use this branch as `__qualname__` is a 3.3 and up feature, I believe. This code triggers for an object that is in a global scope (so it can give a full import path), and the code below it triggers for Python 2 and objects in a local scope. If anything could be removed, it's some of the code below, but I'm not sure which combination at the moment, as some of it is definitely used. In short, though, don't remove this!
single line looks okay here
using hanging indent: ```` template_values = { '...': a, '...': b, }
What do you think about ```python def __repr__(self): template = "<%(name)s: fields='%(fields)s'%(fastupdate)s%(gin_pending_list_limit)s>" template_values = { 'name': self.__class__.__name__, 'fields': ', '.join(self.fields), 'fastupdate': '', 'gin_pending_list_limit': '', } if self.fastupdate is not None: template_values['fastupdate'] = ', fastupdate=%s' % ('True' if self.fastupdate else 'False') if self.gin_pending_list_limit is not None: template_values['gin_pending_list_limit'] = ', gin_pending_list_limit=%d' % self.gin_pending_list_limit return template % template_values```
How about removing the `GIN_` prefix? It's already defined on the `GinIndex` class.
I'd initialize GinIndex with some values so None isn't here.
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
Do you see much value in Django validating this? The error message from PostgreSQL seems clear: `django.db.utils.DataError: value 1 out of bounds for option "gin_pending_list_limit" DETAIL: Valid values are between "64" and "2147483647".
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
single line looks okay here
I don't see much need for the class attributes.
Do you think we're adding value with such complicated `__repr__` methods? I've thought maybe we should ditch worrying about including of Index's params in them and just let `Index.__repr__` show the basics. Does the repr should up anywhere important? I can't think of anywhere.
Right, I think we could use model fields as a parallel -- we don't include all options a field is initialized with in the `__repr__()`. Here's the implementation: ``` def __repr__(self): """Display the module, class, and name of the field.""" path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__) name = getattr(self, 'name', None) if name is not None: return '<%s: %s>' % (path, name) return '<%s>' % path ``` So I'm +1 to not implementing a custom `__repr__()` for each subclass unless someone can present a counter argument. \cc @akki I created https://github.com/django/django/pull/8643 to remove `BrinIndex.__repr__()`.
I'd sort these tests under the existing test for gin_index.
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
use hanging indentation: ``` self.assertEqual( kwargs, { 'fields': ['title'], 'name': 'test_title_gin', 'fastupdate': None, 'gin_pending_list_limit': None, } ) ```
I think that `2**31 - 1` instead of `2147483647` is more readable.
If you make this: ```python with self.assertRaises(VariableDoesNotExist) as exception_ctx: ``` then later on when you need the exception you can just do: ```python self.assertEqual( str(exception_ctx.exception), ... ) ``` which looks a bit cleaner than the `exc_info[1]` stuff.
I was thinking you could instantiate `VariableDoesNotExist` directly rather than creating it indirectly with `Variable/resolve()`. Not sure about a better place for this test considering there's no logging involved at this point. Maybe `tests.py` is for miscellaneous tests.
The more typical way to test `__repr__` or `__str__` is to use `repr(app)` or `str(app)`.
This test and `test_special_prefix` might not be self-evident so a docstring wouldn't hurt, e.g. `"""No URLs are served if DEBUG=False."""`
I think checking attributes of the `LocaleRegexURLResolver` would be more straightforward than testing indirectly via the `__str__()` method.
Three things. First I think a more appropriate solution would be to raise a `TypeError`. Second it shouldn't special case the `noinput` and `interactive` cases but compare `kwargs` to the parser arguments's `dest`s. Third It would be very neat if the `TypeError`s message would mention the allowed `kwargs` just like `filter()` does when you try to reference invalid fields.
`unrecognized_options` instead of `unknown_options`, also test is needed.
suggested wording: "Kept in Django 2.0 for usage by apps supporting Python 2. Shouldn't be used in Django anymore."
Doesn't `get` add a `LIMIT 2`? That might change the semantics of the locking
`Reporter.objects.select_for_update().get(id=1)` would make more sense here.
"Raise ValidationError if the address is invalid."
I guess the `ipaddress` module does these things? I'm not sure if it's behavior should be reiterated in detail.
The comma isn't needed.
IMO we can simplify condition: ```not self.blank or (self.blank and not self.null)``` to: ```not (self.blank and self.null)```
The docstrings are describing how things are were broken rather than stating the expected behavior such as "Can use count() after extra() with params."
Some docstrings like this one are doubled.
There's a typo 24278 should be 24279 -- if you put some thought into it, you'd see this has nothing to do with squashmigrations.
I think the test is more readable with `type(s)` -> `SafeData`, but I'll leave the choice to you.
Please test this method (coverage report indicates that the other methods in this class aren't tested so don't look for existing similar tests.
Oops, you can add that back. I got mixed up on what changes you had made there.
I'd suggest this style: ```python has_meta = hasattr(request, 'META') return {k: cleanse_setting(k, v) for k, v in request.META.items()} if has_meta else {} ```
I'd use an approach from other tests that iterates over the key/values and checks the key is there but not the value.
Some tests seem missing as removing this line entirely doesn't result in any test failures.
I guess it's not intentional to decorate bot the class and the method with this? (test seems to be passing without both).
I guess the `LoggingCaptureMixin` addition isn't related to this patch? It could be added in a separate commit that explains it.
i think this would be cleaner as ```py if not hasattr(request, 'META'): return {} return {k: cleanse_setting(... ```
Could you remove the `DOGECOIN` references? Also, I don't think this needs to be a module constant. It probably doesn't need to check 6 values either.
In this case you could skip the intermediate `name` variable.
oh, I like the idea of this being simple enough to not require more changes. I'm a little concerned about whether this swapping here could potentially cause circular loops. I think the reduction operations currently assume that things will always be added to the front of the operation list, so keeping that consistent might prevent weird optimizer loops like `[A, B] -> [B, A] -> [A, B] -> [B, A]`. I don't think that affects the core reasoning here
I believe this was meant to be a `references` check instead of a `reduce` check? Since `reduce` returns operations, not a boolean. Something like "`not op.references(other)`" so that we can ensure that `other` can properly be pulled forwards
should this be super()
Ah I see. I wasn't aware of the different signatures available for this.
I'm not sure this `next()` dance is really required, I find the following much easier to read ```python for engine in engines.all(): if isinstance(engine, DjangoTemplates): return engine.engine raise ImproperlyConfigured('No DjangoTemplates backend is configured.') ```
Yes, your version is simpler, Simon.
I'd put this test after the next one, so you get the very logical order 0 engines, 1 engine, 2 engines. Also, you might want to explicitly set the `TEMPLATES` setting for this test, too * as to not rely on the number of engines in the global setting (although that is unlikely to change) * (more importantly) to communicate to the reader what scenario is being tested in comparison to the other two tests
Phrase that imperatively ('return' instead of 'return**s**'), analogous to the [change you supersede here](https://github.com/django/django/commit/4696078832f486ba63f0783a0795294b3d80d862#diff-2ec90d8b6d7f44124689729e42876209R61).
Is `string_only=True` required here? If it is, it's not tested.
Use `getattr(field.model._meta, 'concrete_model', None)`.
Use `self.assertSequenceEqual(lengths, [3, 7, 8])`.
Propose to clean this up in https://github.com/django/django/pull/8008.
Maybe a `self.patch_execute_statements(self._execute_raise_tablespace_already_exists)` helper method could avoid repetition and long lines requiring unusual indentation.
... error is ignored when...
suggested wording: "SystemExit is raised if the user answers "no" to the prompt asking if it's okay to delete the test tablespace."
I guess we have poor organization where some tests are organized by class (test_creation/features) and others are organized by database (test_mysql). I'm not requiring a change here but it would be nice to think about how we want to do this going forward.
"Simulate test database creation raising..."
The oracle error code names looked right when I read them here, but then when reading the code that uses them in the test I had to pause and say, "wait, what's ora-01031"? So I think they would be better named something like `_execute_raise_user_already_exists()` etc
I think you're probably right about these four lines. The only reason I see for a separate PR, though, is if that PR were to include a battery of tests (using mocking as @timgraham suggested) for the different combinations of pre-existence of user & tablespace and values of the `keepdb` flag.
I'd split this line in two
I think this check should go before `if keepdb:` in line 40; with the current code, if the database doesn't exist and `keepdb` was specified, and anything went wrong, creation will be silently skipped and this is incorrect.
`len(statements)` => `statements`
assertEqual -- the version with "s" is a deprecated alias.
What's this line? Looks similar to what `TransactionTestCase._pre_setup()` does -- I don't think both should be needed and writing code that executes in the class body is a suspicious..
Did you intentionally keep the unused `TemplateEncodingError` for backwards compatibility? I think it could be removed.
No need to add a new ticket number here. However could you add an assertion about the post response? We would have catched the issue with a proper assertion.
For master, `super()` is enough. The parameters will be added by the committer in the backport for 1.11.
Why is this changed? I think replacing `pass` with `return None` would be more explicit if that's really the correct logic.
Here again the try block isn't minimized.
OSError will happen... os.rename()
Not certain, but it seems like maybe only this line should be in the context manager.
Is some test failing without this change? I don't see how it's related to this PR.
Overall, the changes are mostly fine, I just wonder if we might use this as an opportunity to tighten up large try blocks and use try/except/else instead (such as here).
And once more :). These tests that deliberately mix encodings seem more obvious with the encoding explicitly stated
I've fixed this in the latest revision. The failing test needed a small adjustment.
put the closing ) on the next line
A ticket reference isn't needed -- that's only for obscure issues where the behavior isn't straightforward.
Use `assertRaisesMessage` to also verify the error message..
Maybe something like "call_command() received unrecognized option(s) for the <foo> command: .... " I think listing all the options in the message might not be a bad idea either if it doesn't look too cluttered.
> What about forms etc. for that field? I'm open to the idea. Right, I didn't think about that!
What about making it a `CITextField(models.Field)` so it's usuable as is? It would still be reusable for subclassing.
These could be alphabetized.
max_length could be omitted, the default is 245.
Use `isinstance(exc, (TooManyFieldsSent, RequestDataTooBig))`
I don't think a superclass defines this attribute.
comma could be chopped no blank line after docstring
no "ensure" . docstring could be a single line version
Give the new `FieldInfo` a different name. Or give the standard `FieldInfo` a different name (`import ..., FieldInfo as BaseFieldInfo, ...`), if you're sure all use of this `FieldInfo` is local and it is never passed to generic methods.
I think I mentioned this before -- I find this name rebinding a bit odd. I'd like it better if the `FieldInfo` from `base.introspection` was imported as `BaseFieldInfo`.
I'd use: `return 'BigAutoField' if description.is_autofield else 'BigIntegerField'`
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
Given that the index is named `title_lower_id` this `LOWER` check could check against that as well as `lower(xxx)` -- please rename the index so there is only one match for `LOWER` (same for `TITLE`)
This test is cute <
`self.assertTrue` -> `self.assertIn` above and below as well.
FYI - so does Oracle. But I don't think that distinction matters here because we aren't guarding functionality behind the decision, just the test. Generally Django prefers skipping based on features rather than vendors, but this isn't worth a feature flag IMO.
In c70ffeeb8b70b42693a340724f00eba656c6e51a you made me name the test file `test_removedindjango20`, by that logic this could be called `test_removedindjango30.py`
Fair enough, makes sense though this doesn't seem to have been done in the past, e.g. b6ea059b4ab7a4ed7e84cad639df95fc9d61dd81 only put the warning in `Settings`
I guess, I thought it was neat naming all the files the same way so they could be quickly found
Chop blank line.
Chop blank line.
I guess you're right. It will be nice to change these assertions in a separate PR.
I'm not sure if using assert is best since that's ignored when using `python -O`.
I think that `AssertionError` is the most common in the `Query`. It's also used with the same check in other methods e.g. `Query.extra` and `Query._earliest_or_latest`: ```python assert self.query.can_filter(), \ "Cannot change a query once a slice has been taken." ``` therefore it will probably be better to keep consistency.
change -> reverse? I'm not sure if `TypeError` is the best exception.
Use a descriptive name, not Ticket22550.
"Shorten" would be PEP 257 verb style.
I'm not sure what "use name without username" means. It seems to suggest USERNAME"."TABLE because become TABLE but I don't think that's the behavior.
I think this renaming can be omitted.
Why is VERSION capitalized? Maybe something like: Return a tuple of version numbers (e.g. (1, 2, 3)) from the version string (e.g. '1.2.3').
`get_version_tuple(geos_version_info()['version'])` is okay
"from VERSION if present" seems inaccurate
Switching to `assertTrue()` seems incorrect.
missing a 't'
I'm not sure if these docstrings are adding much value.
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
Use single quotes unless the string contains a single quote. Also, this could be combined with the previous line -- we allow up to 119 characters when it helps readability.
include a trailing comma so if more arguments are added later, this line doesn't have to be modified again
The thing is that this is testing `Sitemap.get_urls()` -- nothing `GenericSitemap` specific -- that's why I was wondering if the test could be rewritten not to use `GenericSitemap`.
+1, this test was also removed in my force_text audit WIP branch.
Might want to mention the whole `make_interval(...)` SQL it should be replaced with.
Is this still simulating a read-only database if the mocking is removed? This test might be obsolete considering the exception catching in `check_migrations()` is removed. Some low level tests for the modified `MigrationRecorder` methods might be in order instead.
I think the old indentation style was fine -- it allows for longer lines.
Is this still simluating a read-only database if the mocking is removed? Chop "Ensure" per https://code.djangoproject.com/ticket/27392.
Chop blank line
While here, might as well switch this to use single quotes per our coding style.
suggested wording :`# The django_migrations table must be present to record applied migrations.`
`"""Return True if the django_migrations table exists."""`
--file-name or --filename? Something like --squashed-name might be more intuitive.
I guess "@" is some convention I don't know about.
Chop ":param "
"Return" would be PEP 257 verb style.
The Python datetime module assumes a Gregorian calendar (https://docs.python.org/3.4/library/datetime.html#date-objects). We do not yet support other calendar systems in Django.
Is it possible to convert year type? (e.g. 2006 &rarr; 2549)
Sure, if you can provide a patch in another ticket, it would merit consideration.
In Thailand it’s customary to use the [Thai solar calendar](https://en.wikipedia.org/wiki/Thai_solar_calendar) system (as it’s the official legal calendar in Thailand). Dates and months are the same as the common Gregorian Calendar, but years are in Buddhist Era instead of the Christian/Common Era. Just add 543 to the year number when displaying, and subtract 543 from the year number when parsing.
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
The name "WrongBackend" isn't very descriptive about its purpose.
My understanding is that `raise Exception` doesn't matter here -- it could just as well be `pass` -- the important thing is what arguments `authenticate()` takes.
Single line looks fine here, otherwise you'd want to include a trailing comma on the last line.
single quotes please
Sorry just browsing here but there's a typo : `NoAuthenicateArgumentsTest` instead of `NoAuthenticateArgumentsTest`
Same typo as above :)
Theis changes isn't needed, we allow longer lines up to 119 characters.
Import specific classes rather than `from django import http`
By single line I meant put everything on line 430.
Please remove the added trailing comma -- there's little usefulness in making a change like that.
A single line looks fine here.
A single line looks okay here.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
It's helpful to describe the issue with a few words, e.g. "Inserting non-ASCII values longer than X characters (#22144)." (I'm not certain that's a correct description of the issue).
I'll update this... try/except isn't needed -- that just makes debugging in the case of a failure more difficult since it hides the traceback.
The flake8/test failure is because the above `help` is missing a closing parenthesis, hence a `SyntaxError`. You can always repush to the branch to rerun the tests.
About Josh's suggestion, we've considered try/except/fail an antipattern because it hides the original exception and thus makes fixing a failure more difficult. There's no problem with a test erroring rather than failing.
how about: ``` try: query_that_shouldnt_fail = ... except ..ProgrammingError: self.fail('Appropriate Error Message') ```
Use hanging indent please: ``` inner = Company.objects.filter( num_chairs__gte=OuterRef('ceo__salary'), num_employees__gte=OuterRef('point_of_contact__salary'), ) ```
I think I would compose the string before the condition ```python exc_msg = 'database %s already exists' % parameters['dbname'] if exc_msg not in str(e): ... ```
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
I'd chop this blank line since the } on its own line is providing whitespace.
I'd change this to: `If the database should be kept, ignore "database already exists".`
Would it be better to put the helper methods near the tests they're used in? (I'm not sure whether or not they'll be reused for other tests or if there are any guidelines about this ordering).
_execute_create_test_db to fix the tests.
param -> params
``` ====================================================================== ERROR: test_case_valid_in_filter_if_boolean_output_field (expressions.tests.BasicExpressionsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/tim/code/django/django/db/backends/utils.py", line 85, in _execute return self.cursor.execute(sql, params) File "/home/tim/code/django/django/db/backends/oracle/base.py", line 510, in execute return self.cursor.execute(query, self._param_generator(params)) cx_Oracle.DatabaseError: ORA-00920: invalid relational operator The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/tim/code/django/tests/expressions/tests.py", line 602, in test_case_valid_in_filter_if_boolean_output_field ordered=False File "/home/tim/code/django/django/test/testcases.py", line 931, in assertQuerysetEqual items = map(transform, qs) File "/home/tim/code/django/django/db/models/query.py", line 267, in __iter__ self._fetch_all() File "/home/tim/code/django/django/db/models/query.py", line 1171, in _fetch_all self._result_cache = list(self._iterable_class(self)) File "/home/tim/code/django/django/db/models/query.py", line 53, in __iter__ results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size) File "/home/tim/code/django/django/db/models/sql/compiler.py", line 1053, in execute_sql cursor.execute(sql, params) File "/home/tim/code/django/django/db/backends/utils.py", line 68, in execute return self._execute_with_wrappers(sql, params, many=False, executor=self._execute) File "/home/tim/code/django/django/db/backends/utils.py", line 77, in _execute_with_wrappers return executor(sql, params, many, context) File "/home/tim/code/django/django/db/backends/utils.py", line 85, in _execute return self.cursor.execute(sql, params) File "/home/tim/code/django/django/db/utils.py", line 89, in __exit__ raise dj_exc_value.with_traceback(traceback) from exc_value File "/home/tim/code/django/django/db/backends/utils.py", line 85, in _execute return self.cursor.execute(sql, params) File "/home/tim/code/django/django/db/backends/oracle/base.py", line 510, in execute return self.cursor.execute(query, self._param_generator(params)) django.db.utils.DatabaseError: ORA-00920: invalid relational operator ====================================================================== ERROR: test_exists_in_filter (expressions.tests.BasicExpressionsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/tim/code/django/django/db/backends/utils.py", line 85, in _execute return self.cursor.execute(sql, params) File "/home/tim/code/django/django/db/backends/oracle/base.py", line 510, in execute return self.cursor.execute(query, self._param_generator(params)) cx_Oracle.DatabaseError: ORA-00920: invalid relational operator The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/tim/code/django/tests/expressions/tests.py", line 591, in test_exists_in_filter self.assertCountEqual(outer_2, outer_1) File "/opt/python3.6.4/lib/python3.6/unittest/case.py", line 1165, in assertCountEqual first_seq, second_seq = list(first), list(second) File "/home/tim/code/django/django/db/models/query.py", line 267, in __iter__ self._fetch_all() File "/home/tim/code/django/django/db/models/query.py", line 1171, in _fetch_all self._result_cache = list(self._iterable_class(self)) File "/home/tim/code/django/django/db/models/query.py", line 53, in __iter__ results = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size) File "/home/tim/code/django/django/db/models/sql/compiler.py", line 1053, in execute_sql cursor.execute(sql, params) File "/home/tim/code/django/django/db/backends/utils.py", line 68, in execute return self._execute_with_wrappers(sql, params, many=False, executor=self._execute) File "/home/tim/code/django/django/db/backends/utils.py", line 77, in _execute_with_wrappers return executor(sql, params, many, context) File "/home/tim/code/django/django/db/backends/utils.py", line 85, in _execute return self.cursor.execute(sql, params) File "/home/tim/code/django/django/db/utils.py", line 89, in __exit__ raise dj_exc_value.with_traceback(traceback) from exc_value File "/home/tim/code/django/django/db/backends/utils.py", line 85, in _execute return self.cursor.execute(sql, params) File "/home/tim/code/django/django/db/backends/oracle/base.py", line 510, in execute return self.cursor.execute(query, self._param_generator(params)) django.db.utils.DatabaseError: ORA-00920: invalid relational operator ```
Here's what I came up with https://github.com/django/django/pull/11641.
"Boolean Expression object" looks a bit unusual to me. What do you think of "a boolean expression"? I assume this means an expression with output_field=BooleanField.
`F` doesn't inherit from `BaseExpression` so currently it doesn't have `conditional` property and cannot be used in `filter()` or `exclude()` we can change this in the future.
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
This seems a bit of an abuse of _this expression cannot be used by itself_ (e.g. it should be disallowed in `.annotate`) as well but that should do for now.
We're tending towards single quotes everywhere so when things get touched best to update :)
Do you think we should build the "is this a boolean field" logic as a method within the expression? It'd hide the mess a bit.
Ah yes I see. Exists being a subclass of Subquery.
Definitively. Thank you!
It's looking much better! @charettes Do you have a better name in mind? I can't manage to come up with something better and simple.
I think so :neutral_face:
Should this be? ```suggestion for_where=False): ```
@NyanKiyoshi if either of the above PR get merge we can completely remove the `for_where` kwarg juggling as it would become unnecessary.
And a another alternative in #11642
It's only in two places and I don't think it cleans up that much, you'd just end up with `if isinstance(filter_expr, Expression) and filter_expr.is_output_field_boolean():` which is slightly less explicit and slightly slower
You should use `1` instead of `True`, sorry for misleading. If you will use `True` as a param than it will be automatically converted into `1`.
FWIW `Q(Exists(is_ceo)) | Q(Exists(is_poc))` already works and `Exists(is_ceo) | Exists(is_poc)` doesn't require much changes. ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 5b82ae97a7..d18de75e9a 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -101,6 +101,8 @@ class Combinable: return self._combine(other, self.BITRIGHTSHIFT, False) def __or__(self, other): + if getattr(self, 'conditional', False) and getattr(other, 'conditional', False): + return Q(self) | Q(other) raise NotImplementedError( "Use .bitand() and .bitor() for bitwise logical operations." ) diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py index 6c00f813d9..d3d75f1ce1 100644 --- a/tests/expressions/tests.py +++ b/tests/expressions/tests.py @@ -595,11 +595,9 @@ class BasicExpressionsTests(TestCase): def test_case_valid_in_filter_if_boolean_output_field(self): is_ceo = Company.objects.filter(ceo=OuterRef('pk')) is_poc = Company.objects.filter(point_of_contact=OuterRef('pk')) - outer_1 = Employee.objects.filter(Case( - When(Exists(is_ceo), then=Value(True)), - When(Exists(is_poc), then=Value(True)), - default=Value(False, output_field=models.BooleanField()) - )) + outer_1 = Employee.objects.filter( + Exists(is_ceo) | Exists(is_poc) + ) self.assertQuerysetEqual( outer_1, ['<Employee: Joe Smith>', '<Employee: Frank Meyer>', '<Employee: Max Mustermann>'], ```
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
Please use hanging indentation due to the [coding-style](https://docs.djangoproject.com/en/1.11/internals/contributing/writing-code/coding-style/).
@schinckel this workaround shouldn't be necessary once #9765 is merged.
Please use hanging indentation due to the [coding-style](https://docs.djangoproject.com/en/1.11/internals/contributing/writing-code/coding-style/).
Please use a single quote.
The added blank lines aren't needed.
Maybe `LoggingCursorMixin` instead of `LoggingCursor`.
~~IMO you should also pass args/kwargs to `FormatStylePlaceholderCursor.__init__` and change `FormatStylePlaceholderCursor` initialization e.g.:~~ ```diff diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 29ae2a6..8c1fe35 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -383,8 +383,8 @@ class FormatStylePlaceholderCursor: """ charset = 'utf-8' - def __init__(self, connection): - self.cursor = connection.cursor() + def __init__(self, connection, *args, **kwargs): + self.cursor = connection.cursor(*args, **kwargs) # Necessary to retrieve decimal values without rounding error. self.cursor.numbersAsStrings = True ```
Dot is missing: `cursor.`
I think that will be better to move import inside each backend specific test.
I think that we should keep `skipUnless`, to omit `import` that will not work for other databases.
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
~~You should pass args/kwargs also to Oracle cursor.~~
Django docstrings usually follow [PEP0257](https://www.python.org/dev/peps/pep-0257/), I would keep `"""Create a cursor. Assume that a connection is established."""`.
`def make_cursor(self, cursor)` -> `def make_cursor(self, cursor, *args, **kwargs)`
IMO `scrollable=False`, `withhold=self.connection.autocommit` should be add to `kwargs`.
If `cx_oracle` is installed, there's an error: ``` File "/home/tim/code/django/tests/backends/test_cursors.py", line 33, in OracleCursorOptionsTestCase class OracleLoggingCursor(LoggingCursorMixin, Database): TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases ``` Also, is this file doing anything useful? I don't see any test methods.
Unswap `cursor` and `self`.
This check is also redundant.
This check is also redundant.
This check is redundant. `skipUnless` already guarantees that we have MySQL. You can remove the `try ... except` leaving only `import`.
No, args should remain. I was talking about: ```python kwargs.setdefault('scrollable', False) kwargs.setdefault('withhold', self.connection.autocommit) cursor = self.connection.cursor(name, *args, **kwargs) ```
You should add args/kwargs to the Oracle `create_cursor` as in the `BaseDatabaseWrapper.create_cursor` e.g.: ```python def create_cursor(self, name=None, *args, **kwargs): return FormatStylePlaceholderCursor(self.connection) ``` Warning message will be helpful if someone pass args/kwargs.
This check is also redundant.
Sorry for the confusion. I mistook the `try ... except` as being in test methods. Yes, you should `try` the import. Also, you'll need to define `Cursor` in case of `ImportError` to make the rest of the code syntactically correct. Maybe something like this: ``` try: from MySQLdb.cursors import Cursor except ImportError: class Cursor: pass ```
Instead of this line, put `bucket` into parameters, like `def __init__(self, *args, bucket, **kwargs):`
Passing args/kwargs to `make_debug_cursor` and `make_cursor` is unnecessary.
This line is indented too much.
Since code is being deleted, this test can be removed.
`# This backend is specified in the url().`
skip the blank line
The existing text looks correct to me. If validation is skipped (skip_validation=True), the calling code should call validate_consistency() to do that instead of having this method do it.
Use `import sys`, `sys.stderr` instead.
`s/ exists/ exist`
Put the model near the model it relates to.
Join aliases are reused in order. This shouldn't non-deterministically raise AssertionError because change_map contains a circular reference (#26522).
chop blank lines
I'd simplify a bit: should be -> is
I'd omit "Make sure" in the spirit of https://code.djangoproject.com/ticket/27392.
Should this be `old_field.db_index or old_field.unique` since `unique=True` also creates indexes? (at least until https://code.djangoproject.com/ticket/24082 is fixed)
More simply: `# Drop indexes on varchar/text columns that are changing to a different type.`
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
Use single quotes consistently (could be done above and below also).
this should be phrased as a "x should do y" sentence, like it was before
You could add a trailing comma for consistency.
Use this style: ``` self.assertEqual(field.check(), [ ]) ```
I think it would be clearer without both context managers on the same line.
move this to the previous line (we favor longer lines over non-hanging indent)
You could also put this data in separate tuples as other tests do as this indentation isn't the prettiest.
For simplicity, I think `db=db` I fine.
I think these tests don't belong in this patch considering they already pass and `ChoiceWidget.format_value()` isn't modified.
Try to avoid two branches and lots of code duplication here. You should be able to handle both cases in single path.
You might have thought of this already, but it might be helpful to try to pass along the first error message, though it wouldn't be quite as clean, and it gets caught anyway.
These lines could be removed or moved to the docstring or class-level
I think this line isn't needed, tests seem to work fine without it.
Heh. This line was an `assertRaisesMessage` before, I recommended that it be changed to assertRaises to make the test less prone to break on trivial code changes. The message's content is essentially just "Not supported" anyway, so I think we should leave it this way.
"Reinhardt" (the name of the first user here) is the last name of Django (the guitarist). Use `name="Grappeli"` (Stephane, who used to play with Reinhardt).
`get()` adds redundant noise here IMO (outside of Oracle, `get()` adds its own slicing IIRC). I'd prefer: ``` qset = Person.objects.all().order_by('pk').select_for_update()[1:2] person = list(qset)[0] ```
Assuming you use `NotSupportedError`, I think checking for the exception class is enough and is more robust.
I typically use this style to avoid such long strings near the length limit: ``` raise NotSupportedError( '...' '...' ) ``` (could also be applied in the other file)
`s/allowed/supported/` -- and coming to think of it, use `django.db.NotSupportedError`.
Doesn't matter much, but I don't think it's common practice to include a trailing comma on single line tuples of length > 1.
I think this is just as readable on a single line: `(internal_size, desc[4] or 0, desc[5] or 0,) +`
We could crop the table name or field names with respect to the suffix when generating the index name.
I understand, thanks for explanation.
I think a more extensible solution would make `MAX_NAME_LENGTH` usage in `set_name_with_model()` a class attribute of the index which this subclass could override.
The idea is to limit the length for indexes that might be used across different databases. If a third-party app author is using PostgreSQL, for example, they should create index names <= 30 so that the app is usable on Oracle. The indexes in `contrib.postgres` don't need this limit since they are only usable on PostgreSQL.
Maybe a new `Index` property (without special treatment for the `BrinIndex`) will be a more universal solution, i.e. sth like: ```python @property def max_name_length(self): return connection.ops.max_name_length() or 30 ```
This goes against the ideas proposed in [#27135](https://code.djangoproject.com/ticket/27135). If we change the suffix, we need a mapping somewhere so that introspection continues to return `BrinIndex.suffix`.
That's absolutely right. I'm wondering if it might be helpful to implement `Index.clone()` which does a deconstruct/reconstruct a la https://github.com/django/django/blob/master/django/db/models/fields/__init__.py#L463-L469
You need to copy the `model._meta.indexes` list, otherwise you're reusing the same index instance across multiple models which could lead to other errors. I suggest `indexes = model._meta.indexes[:]`.
I think you could skip the views file and use `lambda req: HttpResponse('OK')` instead.
Sorry, was thinking of something else.
You can check `str(response.context['exception'] is '"No sitemap available for section..."` to improve these 404 tests.
You don't know what a docstring is? Trying googling "python docstring".
Only the docstring is the same, obviously the test is different.
I'm trusting you and the tests in this case!
Using tuple unpacking is a bit more readable: `pt1_x, pt2_y = ...`.
This is the only change that should be required.
I think that you should partly restore behavior before https://github.com/django/django/commit/b484f167bed61f4cff215208eddf98a0655239d4 i.e. ```python cursor = self.connection.cursor() try: cursor.execute(self.ops.set_time_zone_sql(), [timezone_name]) finally: cursor.close() ``` instead of ```python with self.connection.cursor() as cursor: cursor.execute(self.ops.set_time_zone_sql(), [timezone_name]) ```
I'm not sure what you mean.
I'll be dividing this to smaller chunks to be easier to review and to ensure I don't skip steps. Thank you!
The current version I have does not contain this file. `test_views.py` was maybe moved to another directory but I can't find it despite my efforts. I tried searching by name (ctrl-p in vim), by content using the fuzzy finder and there's nothing under contenttypes_tests named as `test_views.py`.
Putting `_j` before `_m` seems close enough.
Do you want to alphabetize the order of the attributes? (looks like that's the current ordering)
I want to say this is okay, but it might introduce edge cases since `render_context.template` isn't set back to it's original value. I can't identify a specific issue, but it might be safer to mirror the behavior of `RenderContext.push_state`, minus the calls to `self.push()` and `self.pop()`: https://github.com/timgraham/django/blob/3c4944bec3935342871ced38242ae1492b5504d3/django/template/context.py#L206
I think it would improve the readability of the test to use the approach of `test_unique_history_per_loader` and put the templates in the Python rather than having to look up those templates to see what's going on. Also, please use single quotes throughout, unless a string contains a double quote. You can squash commits when updating.
All tests ensure expected behavior ;-). Our preference is to use test docstrings to state and explain the expected behavior.
Hey @Stranger6667. No problem. With the changes from https://github.com/Stranger6667/django/pull/1 (suitably tidied) my concern over this point is ≈resolved. For me, now, it's just a test on the new `Lookup` API in core and then a final nitpick.
Use a single line here.
Would this be clearer? ``` max_query_params = connection.features.max_query_params if max_query_params is None or max_query_params >= len(numbers): ```
You could use `subtest()` for the loop.
`# The database's limit on the number of query parameters.`
Not sure why this line is required, we don't seem to be creating any `Number` in `setupTestData()` 🤷‍♂️
These assertions can be single lined.
Should `template=None` be a local variable rather than an (unused) kwarg? I don't think the `as_vendor()` methods typically take any kwargs. Similarly for `function=None` for `as_postgresql/sqlite()`.
blank line not needed
It might be a tiny bit faster to create `TEST_RANGE - Author.objects.count()` objects rather than deleting the existing ones.
I think upper case is usually reserved for module constants.
I think you can just use `signal.SIG_IGN` instead of this lambda.
If we hit an exception in the block before the default_handler is recorded, then I think we will hit an `UnboundLocalError` here because `default_handler` is not assigned. This is obviously pretty unlikely, since there aren't many exceptions that can be thrown from the previous block. However, it would be slightly safer to have a narrower `try ... finally` block just around the signal-handling stuff.
From a quick check on SQLite, `AttributeError` can be removed here without any test failures. Might be missing test coverage.
I wouldn't edit this just to change the quote style.
I don't see the need to move this into the try/except block. Generally we try to minimize what's in a try/except to make it clear what code is expected to raise the exception. I think the old version in `aggregate()` with `arg.default_alias` only in the block is clearest.
This `if` can go outside the try/except.
I'd say something like: ``` # The default_alias property raises TypeError if .... or AttributeError if ... ``` I'm not sure what the second sentence means. It seems like you're saying `hasattr(arg, 'default_alias')` raises an exception if `'default_alias'` isn't a string.
I wouldn't include a blank line here.
That can fit on a single line. Prefer single quotes when possible.
Single quotes, trailing dot.
@charettes Do we have convention for preferring single quotes? If so, I guess it should be added here https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/.
The usual style is (wrapped at 79 chars): ``` msg = ( "Cannot resolve " " " ) ```
Don't need to change this.
``` self.assertIn( 'Conflicting migrations detected; multiple leaf nodes ' 'in the migration graph:', exception_message ) ```
multiline messages much longer than 79 chars please
use `msg="..."` style
no blank line before class attrs needed
I forget if there was a reason to prefer the current version but yes, we don't need the check twice.
Could go on the class-level to avoid duplicating it in two tests.
No, it's not.
use a msg variable
use a msg variable
Please use this style in places like this: ``` msg = "..." with self.assertRaisesMessage(FieldError, msg): ```
Use `%r` in the message.
I'd use `assertRaisesMessage()` with `msg = 'backend does not support timezone-aware datetimes when USE_TZ is False.'`. There's a small chance that messages from third-party backends might not match the `connection.vendor` convention and I don't think it's a critical part of the assertion.
That can be a class-level attribute -- no need to assign it in `setUp` for each test. Probably should have a more descriptive name like `no_attribute_msg`.
No need to interpolate `'abc'` in the message -- this might be done in some existing tests for Python 2 compatibility to account for u'' prefixes on Python 2 but could be removed now.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
I'd use `assertRaisesMessage()` with `Cannot resolve keyword 'foo' into field. Choices are:` -- there's not much value in a regex for the choices, I think.
You could use `%r` or just hard-code the repr of the class in the expected message.
Instead of "set expressions to that field" maybe it would be better to say, "group by that field, HAVING expressions, and ..." since it's more useful to explain what the assignment means.
Caching SRID data makes sense to me (not for you?), but we may use a more modern caching method, like lru_cache.
Ah yes, and if we `lru_cache` the main `get_srid_info`, we can get rid of that caching.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I'd be mildly tempted to change it to say that the model field ought to be unique, because a single value (say, "slug") is always unique. Perhaps `field argument `fieldname` must have unique=True` or some such? Perhaps its not necessary.
Yeah if `FieldDoesNotExist` is raised, I think that's fine, I just couldn't remember what `.get_field` (or whatever it calls internally from there) would return, `None` or an error.
Why do you need this sleep function? If `RandomUUID` returns the same UUID for two consecutive calls at the same second that seems to be a bug in PostgreSQL.
This test would be better if we updated the whole model with the expression, like in the PR
Then it's settled, I think. Thanks :)
unchecked -> unselected
" allowed to be deleted permissions" seems like a typo.
`response = ` (don't think the abbreviation helps much)
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
Wrap docstrings at 79 characters.
I don't think this test is needed. The default implementation is already tested as well as overriding the method.
To help conform to our style guidelines, put the ) on the next line and adding a comma after using.
must be -> is e.g. -> usually
This test belongs with the tests for the delete action in `tests/admin_views/test_actions.py`.
(suggesting to delete this test anyway, however, this could fit on the previous line and if not, use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style)).
This line seems unnecessary as it's apparent from looking at the code.
add a trailing comma
Please wrap docstrings at 79 characters.
I'm not sure what the use case "customizing the format of the list of strings" means. I think this would be sufficient: ``` Hook for customizing the delete process for the delete view and the "delete selected" action. ``` In my opinion, we don't need to repeat the docstring from `get_deleted_objects()`.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Any particular reason why you mock this method? Is that because you want to test the correct method is called? Why don't you just remove real objects from the database? I think I like your thinking here, but want to be sure that this is what you had in mind :smile:
Single line here is fine (as the style guide says, we allow up to 119 characters if it improve readability).
I think that you can remove brackets `deleted_objects, model_count, perms_needed, protected = ...`
Following the existing docstring pattern of wording like "Hook for..." seems useful.
This can be single lined.
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
Blank line not needed.
Please add blank line before `class BandAdmin`.
@MarkusH I don't have a strong opinion on this, but I wouldn't classify this change as a backwards-incompatible, I guess. @rebkwok Maybe we can keep previous indentation i.e.: ``` python deletable_objects, model_count, perms_needed, protected = modeladmin.get_deleted_objects( queryset, opts, request, using) ```
put this tuple on a single line
Please add comma: `By default, return...`.
"Return" would be PEP 257 verb style.
Exactly as @charettes says.
What about using the global user model's `normalize_username` method while returning an instance of `self.model`? ```python GlobalUserModel = apps.get_model(self.model._meta.app_label, self.model._meta.object_name) username = GlobalUserModel.normalize_username(username) password = GlobalUserModel.hash_password(password) user = UserModel(username=username, email=email, **extra_fields) user.password = password user.save(using=self._db) return user ```
> This is fine because managers are by definition working on the real model. I thought adding the `use_in_migrations` flag to managers was done specially to allow working on models created in migrations? This is going to break any migration that uses the return value of `create_user` as it will no longer be an instance of the user model class at the particular state the operation is run at. e.g. ```python def forwards(apps, schema_editor): UserModel = apps.get_model('auth', 'User') user = UserModel.objects.create_user('Ms X', password='secure') assert isinstance(user, UserModel) ``` This is really problematic for migrations that use the returned user instance to assign foreign key values as they'll fail with `TypeError`.
Crap, I assume this is caused by `IntegerField.validators` computation.
@sir-sigurd `output_field` could also work, I suggested using `_output_field` because I knew it would work from my past experience implementing `Func` subclasses.
Are you planning to remove these lines in the same PR? It looks to me that this whole `__init__` could be replaced by a simple `_output_field = fields.IntegerField()`.
`Substr.__init__()` does. I think it might provide some value. It looks like the other functions don't have parameters that need much explanation.
I'd be inclined to reflow this so it fits on three lines: ``` 'AsGML', 'AsKML', 'AsSVG', 'BoundingCircle', 'ForceRHR', 'MakeValid', 'MemSize', 'Perimeter', 'PointOnSurface', 'Reverse', 'Scale', 'SnapToGrid', 'Transform', 'Translate', ```
missing trailing comma
I guess I'd say, "No queries are performed if a field default changes and the field's not changing from null to non-null." The "unless" phrasing may give the idea that case is also tested here.
"SQLite naively remakes the table"
read directly chop "we know"
Please wrap these lines at 79 chars.
I guess this is like `assertEqual` where the "Equals" version is a deprecated alias.
I'd use the `msg = '...'` style here to shorten this line.
Use double quotes and wrap docstrings at 79 characters.
missing point at the end
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
See if you can find an existing test case to use. There should be existing tests for log entries that this test could be located with.
Please don't make unrelated whitespace changes.
Please don't use double spaces here.
I'm not entirely sure about this name. I don't have any better suggestions right now though.
Having `self.validate_number` being called twice doesn't matter too much, I think.
Can you undo this change, please.
Please add this line back, it's unrelated to the remaining patch.
To follow the style of other models: `(Series, models.CASCADE null=True)`
I tried something similar but it turned out to be more annoying that I felt it was worth. I think the chances of someone changing one value and inadvertently not changing the other value is low. As for what the test values should be... whatever works.
Would be fine I guess. I'm not too sure about the safety margin aspect in the first place, but it's SQLite so whatever works, I guess.
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
Maybe the following will be more explicit: ```python first_author_books = result[0].books.all() self.assertEqual([self.book1], [first_author_books]) self.assertEqual([self.reader], [first_author_books[0].read_by.all()])) ```
Maybe use `self.TEST_SIZE` to avoid storing the large list of authors.
Avoid using "we" (https://github.com/django/django/pull/8284/files#diff-50c5e52240e2649c752f13682164fd60R55)
This is not the most explicit way to chain those lists. I recommend to use `itertools.chain.from_iterable(batch_querysets)`.
I would remove this sentence and let the person who changes this code in the future decide of the way to implement it.
Should be ``self.weight``
This should be: ``params = config_params + params``
Yeah, looking at those test modules, I think they deserve some cleanup.
True, but they test the behavior of the respective operations. It's true that `test_state.py` has a few tests that check for the correct `state_forwards()` behavior, though those tests are focused on the bigger picture of how `ProjectState` and `ModelState` work. Whereas `test_operations.py` tests for the particular implementations of the different migration operations, and as such should hold (regression) tests that focus on a particular implementation of such an migration operation. Thus, `test_operations.py` sounds like the right choice to me.
I think it's fine where it is, in the operations tests.
I think so -- all code changes should be tested unless it's infeasible to do so.
https://code.djangoproject.com/ticket/27655 > Use single quotes for strings, or a double quote if the the string contains a single quote.
I'll try to move the test to `test_state.py` and commit this patch without this untested line unless there's further feedback.
`# Using the __icontains lookup with ArrayField is inefficient.`
I think there's a constant for `'self'` as well somewhere in `django.db`.
@orf we don't have [flake8-mutable](https://pypi.python.org/pypi/flake8-mutable) installed on CI.
I never think mutable keyword arguments are a good idea, even in this case where they will never be (currently) mutated. I am surprised `flake8` didn't pick this up.
I wonder if we could enumerate valid options like we do for `select_related()`/`prefetch_related()`.
Dot is missing: `'Choices are: %s.'`.
Maybe it will be better to use `django.db.NotSupportedError` instead of `DatabaseError`.
You're right. I created a separate PR #8341.
I guess `self` probably can't be used as a field name very well, e.g. ``` >>> MyObject.objects.create(data='bar', self=my1) TypeError: manager_method() got multiple values for argument 'self' ```
I think that `self.select_for_update_of` should be a tuple rather than a dictionary.
I think that: ```python return 'FOR UPDATE%s%s%s' % ( ' OF %s' % ', '.join(of) if of else '', ' NOWAIT' if nowait else '', ' SKIP LOCKED' if skip_locked else '', ) ``` is more readable.
I think that `result` should be a tuple `result = ()` rather than list.
should lock -> locks
We generally use this indentation style for `assertRaisesMessage()`: https://github.com/django/django/blob/3297dede7fce4b190f7b3bf0b0fc29a734151b61/tests/many_to_one/tests.py#L111-L116
I think you can simplify this expression removing the `default` and using `const='full'` instead of `const=True`: ```python '--add-location', dest='add_location', choices=('full', 'file', 'never'), const='full', nargs='?', help="Control '#: filename:line' lines. The optional type can be either 'full', " "'file', or 'never'. If it is not given or 'full', it generates the lines " "with both file name and line number. If it is 'file', the line number " "part is omitted. If it is 'never', it completely suppresses the lines " "(same as --no-location).", ) ``` This would avoid having to treat the `options['add_location'] is True` below.
This doesn't act as a regression test because it tests if `"'lastname'"` is in the exception message which it already is. You want to test if the quotes are removed. This would do it: ```python with self.assertRaises(MultiValueDictKeyError) as cm: d.__getitem__('lastname') self.assertEqual(str(cm.exception), "'lastname'") ```
Actually that can be one line `SET @_tmp_sql_notes := @@sql_notes, sql_notes = 0;`
what if it was set to 0 by connection init or server param? We should just reset it back to the original value... ```sql SET @_tmp_sql_notes := @@sql_notes; SET sql_notes = 0; CREATE DATABASE IF NOT EXISTS ... SET sql_notes = @_tmp_sql_notes; ```
I think that you can add `filter` to `kwargs` in `__init__` method and remove redundant `__repr__` (see #8759).
We might want to mention we use `super()` to avoid checking against `self.filter`.
This one as well.
This could be a bare `super()`.
I think chaining `filter`/`exclude` should be an `AND` not an `OR`. It makes more sense to me and I'm pretty sure that what queryset `filter`/`exclude` do.
This will also have to take into account `filter(m2m__field=val1, criteria=m2m__otherfield=val2)` != `filter(m2m__field=val1).filter(m2m__otherfield=val2)` as explained in [spanning multi-valued relationships](https://docs.djangoproject.com/en/1.11/topics/db/queries/#spanning-multi-valued-relationships)
I think you should should avoid altering `self` in this case, you should clone `self` and call `set_source_expressions` on the clone.
Passing `filter` to kwarg will cause it to be in `self.extra` as well which could interfere `as_sql()` formatting.
Use single quotes.
Please undo this change (it's the only double-quote to single-quote change left).
Dots are missing i.e.: `..., e.g. Count('id').` On the other hand I think we can remove an example.
Please use hanging indentation due to the [coding-style](https://docs.djangoproject.com/en/1.11/internals/contributing/writing-code/coding-style/): ```python self.assertEqual( repr(Variance('a', sample=True, filter=filter)), "Variance(F(a), filter=(AND: ('a', 1)), sample=True)", ) ```
Please use single quotes.
Shouldn't be part of this PR, but it looks like redundancy in `__repr__()` methods would be a good candidate for a refactor.
@orf Please rebase from master and use `_get_repr_options()` instead of `__repr__()`.
You're right, thanks. I proposed `Aggregate.__repr__()` refactoring in #8759.
Please revert this unrelated change.
"and PostgreSQL's interval format." (no comma)
Did you consider trying to factor out the common code between the two `if match` branches? Not sure if that would help or hurt readability.
I'd use: ``` test_values = ( ('1 day', timedelta(1)), .... ) ``` along with a loop and `self.subTest` to avoid the need to copy/paste `self.assertEqual(parse_duration` so much.
"Replace" (captialize) chop comma since "so that ..." isn't an independent clause (couldn't be a sentence on its own). Add period at the end of the sentence.
We usually use hanging indent: ``` with self.settings( USE_L10N=False, DECIMAL_SEPARATOR=',', USE_THOUSAND_SEPARATOR=True, THOUSAND_SEPARATOR='.', ): ```
I think "as expected" can be chopped.
I'd call it "mulitable" drop underscore and 's' (precedent: tests/m2m_through_regress/test_multitable.py).
Might be worth forward porting the test to `master` even if it already passes. The commiter will take care of that.
should not -> doesn't
I wonder if you might add an assertion that the `_iterable_class` for `Teacher.objects_custom.all()` is `ModelIterableSubclass` just to be sure that isn't inadvertently refactored away in some future change.
Perhaps this would be more succinct: ``` return ( '....{field_name}' ).format(field_name=field_name) ```
This looks unexpected per isort.
It's not obvious what this removal has to do with this patch.
+1 always better to eliminate a temporary variable
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
On master, I'd rather see a simple `str()`. Of course, the backport for 1.11 should keep `force_text`.
(order as suggested above)
I'd order the test with the other `check_html()` tests (above `test_use_required_attribute`).
There's [a ticket](https://code.djangoproject.com/ticket/27795) for auditing existing `force_text()` usage.
Yes please. I think that's worth the effort.
I think this else could be removed and deindent the following return.
on the model an index
The DEFAULT_INDEX_TABLESPACE setting can't be tested...
I'm surprised if `str()` is doing something here since `capfirst()` also has some `str()` calls.
I think `return str(self.success_url) # success_url may be lazy` as you did elsewhere looks good.
use set comprehension (I guess it might be better to defer this task to a separate commit)
This could use set comprehension also. There was another commit that converted most places but perhaps this slipped through.
This could fit on a single line: `# Subqueries must use a different set of aliases than the outer query.`
Would it be better to raise `NotImplementedError()` so backends don't overlook implementing it? They can always return an empty list if it's not supported.
`# MySQL allows only one auto-increment column per table.`
Add blank line above per isort.
You'll have to leave the `or` above to appease `flake8`.
Use `not isinstance(self.max_length, bool)` and wrap the statement in parenthesises instead of using `\`.
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
Use single quotes.
Use single quotes.
Master supports Python 3 only, so there's no need to use six anymore.
; -> ,
My instinct would be to use a `sub_` prefix for these names (possibly confirmed by an existing sub_params name in other code).
Ditto about the `keys()` call. I'd also try to avoid cloaking the `dict` builtin while you are around. ```python set(chain.from_iterable(dict_ for subcontext in self for dict_ in subcontext)) ```
You can remove the `keys()` call as `iter(dict.keys())` yields the same results as `iter(dict)`. That is `update(base.__dict__)`.
Just out of interest, `dict.keys()` is a **set-like** object providing a **view** on a dictionary's keys in Python 3. So the cast to `set` was only needed for Python 2 where `dict.keys()` returns a list. Thus the options here are changing to use `set.update()` and passing the dictionary as-is - as has already been committed, or to just drop the cast to `set` as it already is set-like which might look a bit less magic. No strong opinion on this however.
Use double quote docstrtings.
"Called for each db column fetched from cursors. Return numbers as strings so that decimal values don't have rounding error."
Might be worth moving to a `/tests/utils.py` submodule (alongside `runtests.py`) instead of defining it here since it's not meant to be a public API.
It should be good as long there's no foreign tests or models that get imported along the way. From what I can see it should be good!
I do like the solution where you can opt-out per query, or force opt-out for all queries on given connection. This way Django and library code can use cursors without a risk of being incompatible with pgbouncer.
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
Citing @holvianssi on Trac. > The complex solution is to add both the opt-in flag and database settings. The default for the opt-in flag is None, meaning use the default from database settings. True forces this feature on, and False forces the feature off.
this isn't the same! you should do `**{method: 'value'}`
could leave this as multiple lines
No, the dict's key is not `'method'` but whatever is in the variable `method` 😉
Sure, I just found the original version more readable. There is a soft limit on 79 chars meaning if it looks fine you can break.
The other alternative would be to avoid performing analysis of the migration files. FWIW I personally find set literals to be better looking and easier to parse particularly in cases where the set doesn't contain many elements and the `set([])` boilerplate accounts for half the length of the whole statement.
We should remember that migration files are auto generated code. They first and foremost need to not have syntax errors. There was a discussion on running some form of isort on migration files while generating them. We decided against that for the sake of migration files being auto-generated. Furthermore, lines in migration files can easily end up having lines way past 79 or 119 characters. And I'm against starting to linebreak those lines with some other tool. Users should exclude migration files from linting, IMO.
These might be caused by you editor but avoid unecessary whitespace changes.
`necesarily` -> `necessarily`
I'd chop "Note that"
or "don't necessarily" -> "may not"
add trailing ,
Maybe you can use `subTest` here, e.g.: ```python for model, pk_pos in ( (Book, -1), # Unmanaged origin model. (Author, 0), # Unmanaged related model. ): with self.subTest(model=model, pk_pos=pk_pos): with mock.patch.object(model._meta, 'managed', False): _, _, grouping = queryset.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(grouping), len(model._meta.fields) + 1) self.assertIn(Author._meta.pk.name, grouping[pk_pos][0]) for index, field in enumerate(model._meta.fields): self.assertIn(field.name, grouping[index + pk_pos + 1][0]) assert_queryset_results(queryset) ``` but I'm not convinced that it isn't less readable.
`skipUnlessAnyDBFeature` -> `skipUnlessDBFeature`
This changes the return value of `_urlparse`. I think it would be more appropriate to catch the `ValueError` in `_is_safe_url` instead and return `False` there.
add trailing comma
Restoring the inner import fixes the errors when psycopg2 isn't installed.
I'm not exactly sure what "straight away" means here. I wonder if something like this could be an improvement: ``` # Registering new type handlers cannot be done before the extension is # installed, otherwise a subsequent data migration would use the same # connection. ```
Maybe this inheritance should be refactored a bit as it's not obvious if `PostgreSQLWidgetTestCase` is now using `TestCase` from `PostgreSQLTestCase` or `SimpleTestCase` from `WidgetTest`? e.g. `PostgreSQLTestCase.tearDownClass()` might be moved to a mixin that `PostgreSQLTestCase` and `PostgreSQLWidgetTestCase` can use.
chop blank line
`to_python()` (add parens)
I would like a test that fails if this is removed from the try block.
Although fast, it's an order of magnitude slower than attribute access: ```python In [1]: from decimal import Context In [2]: %timeit Context(prec=1) The slowest run took 29.15 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 613 ns per loop In [3]: %timeit dict.update The slowest run took 19.66 times longer than the fastest. This could mean that an intermediate result is being cached. 10000000 loops, best of 3: 53 ns per loop ``` Not to mention the poor garbage collector!
I noticed a different behavior for floats lower than `1`, they aren't rounded e.g.: ```python >>> f = models.DecimalField(max_digits=4, decimal_places=2) >>> f.to_python(0.0625) Decimal('0.0625') >>> f.to_python(0.00625) Decimal('0.006250') >>> f.to_python(0.000625) Decimal('0.0006250') >>> f.to_python(0.0000625) Decimal('0.00006250') ``` Maybe that's ok and I missed something.
Ah, well then we can use `@cached_property` 😉
Please move this inside the if.
I would return directly rather than creating an intermediate `value` variable.
could this instead go before the try/except? ``` if isinstance(value, float): context = decimal.Context(prec=self.max_digits, rounding=decimal.getcontext().rounding) return context.create_decimal_from_float(value) ```
to_python() "properly" could be chopped
Does delegating to `super()` by adding a `not getattr(self.lhs.field.target_field, 'primary_key', False)` to the `if not getattr(self.rhs, 'has_select_fields', True)` instead also works? I think it would make more sense to let `In.as_sql` deal with this case.
`'Boolean (True, False or None if nullable)'` ? cf. `NullBooleanField.description`
The nested if statements seem excessive. Could this whole thing just be simplified to the following: ```python def formfield(self, **kwargs): if self.choices: include_blank = not (self.has_default() or 'initial' in kwargs) defaults = {'choices': self.get_choices(include_blank=include_blank)} else: form_class = forms.NullBooleanField if self.null else forms.BooleanField # In HTML checkboxes, 'required' means "must be checked" which is different # from the choices case ("must select some value"). # required=False allows unchecked checkboxes. defaults = {'form_class': form_class, 'required': False} return super().formfield(**{**defaults, **kwargs}) ```
Should `to_python()` also have the following to mirror the behaviour from `NullBooleanField.to_python()`? ```python if self.null and value in ('None',): return None ```
`response.request.method` would be more idiomatic.
Oh, that surprises me too...
what "it" refers to is ambiguous
For these columns, MySQL doesn't:
Should this use `skip_default()`? Or perhaps the condition should be moved into some private method with a more semantic name and used here and in `skip_default()`.
omit the intermediate variables: ``` self.assertEqual(model.check(), [ ]) ```
Perhaps this would be better as a single test: ``` assertion = self.assertIn if connection.features.supports_index_on_text_field else self.assertNotIn assertion('text_field', self.get_indexes(AuthorTextFieldWithIndex._meta.db_table)) ```
Perhaps the duplicated code between this and the MySQL backend suggests a need for some refactoring.
Perhaps the tuple should be a module constant somewhere so it can be reused in `validation.py`.
I'd omit the whitespace change.
indexing a TextField
'MySQL does not support a database index on %s columns.' (it's not that the database backend doesn't support it but that the database itself supports it) hint='An index won't be created. Silence this warning if you don't care about it.'
Oracle doesn't support a database index on these columns.
Looks like this could be a 1 line docstring.
I'd use this indent style: https://github.com/django/django/blob/98b3b14a648a128d409b8f6169c1a4ff9d71c1a4/tests/invalid_models_tests/test_ordinary_fields.py#L231-L234
types -> type
chop trailing ,
chop trailing .
should be -> is "if the database supports it."
That could be a single line docstring.
The parameter to this method seems odd to me. As it stands, no caller is explicitly using the parameter in a call to the method and I can't see many legitimate uses for it in derived classes. I think you're effectively just using the default value as a space to store a class-scope variable. Would it be simpler to just assign a member on the class? Or on the instance, if you prefer.
use US spelling (behavior)
Use single lines for all these asserts -- we allow up to 119 characters when it improves readability.
Having an overridable method seems like the most orthodox OOP solution (it's what a Java programmer would do :-) ) but I'm not convinced it really gives a useful abstraction: by coincidence it's the right place to make this one change, but I'm not sure there's a useful class of future modifications it opens up, so it feels like overkill to me. My thought with an instance variable was just to set it in the constructor in the base class, and overwrite it in the subclass constructor (not exposing it as a kwarg). I'm not sure there's any advantage to this; I think I was thinking about this because it's what I'd do in C++. I don't have a particularly strong feeling on this. I think if I were writing it I'd go with the class-level attribute.
`type_` -> `invalid_type`
These assertions are not related with this patch. Personally I don't see much value in adding them.
Use single quotes.
* Please use `assertRaisesMessage` here. * `flake8` will require whitespace after the `:` in the lambda.
Omit the outer `[]` to use a generator instead of list comprehension.
`# Field is picklable with this cached property populated (#28188).`
use single quotes
Chop blank line.
FYI, `errno.EPERM` maps to errno 1 so this is the errno we will check for instead of an integer like we originally submitted in the PR.
Ok, will do.
@djackson-saa and I investigated the `PermissionError` and it was only added to Python in version 3.3 as a subclass of `OSError` and **not** available in Python2.7. In order to make this Python2.7 compatible, we are going to change the class we are excepting to `OSError` to cover all bases.
Chop blank line.
@timgraham wilco. As new contributors, it's difficult to know which direction so I appreciate the explanation.
I think so. It would be better to use `errno.EPERM` instead of `1`.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python error = PermissionError(errno.EACCES, 'message') with mock.patch('django.core.files.move.copystat', side_effect=error): ```
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python with mock.patch('django.core.files.move.os.rename', side_effect=OSError()): ```
Chop blank line.
Don't worry about inconsistency with existing code, there is a lot of code that doesn't conform to our latest style.
Please use `PermissionError` for this PR and I'll change it when backporting to 1.11.
I think it would be safe to access `e.errno` directly in this case. The `winerr` attribute is only present on Windows platform hence the `getattr()`.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python error = PermissionError(errno.EPERM, 'message') with mock.patch('django.core.files.move.copystat', side_effect=error): ```
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
Use `drop=True` rather than an arg for better readability. Use a different var for `sql`here, maybe `changes_sql`? It's a little confusing to have the `sql` name reused in the next line.
I'd say, "Return a (sql, params) fragment to add or drop (depending on the drop argument) a default to new_field's column."
I'd drop the blank line here and 2 lines below.
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
Use `drop=True` rather than an arg for better readability. Use a different var for `sql`here, maybe `changes_sql`? It's a little confusing to have the `sql` name reused in the next line.
This could be moved closer to where it's used or even eliminated as an intermediate variable.
You might want to write some tests to prove that the new query search subclasses combine correctly with SearchQuery.
Are you sure that this actually creates a mixed-case column name? In the past, we needed to do things like `'"TeA_iD"'` to get this effect, otherwise the name would be uppercased or lowecased along the way.
I'm inclined to use a model name that's more explanatory about its purpose such as `MixedCaseIDColumn`.
With a different model name, this could be `queryset = `
`# Sphinx 1.6+` is enough
Workaround is one word, no dash needed.
Use `super()` as master only supports Python 3.
Instead of two sentences for these docstrings, I'd say: "Return ...., or 2 if ..."
, or None...
I think that we can squash this to two cases, i.e.: ```python if not self and other: return copy.deepcopy(other) elif not other: return copy.deepcopy(self) ```
I believe you'll want to use `self.assertIs` so there are better error messages, and for consistency with other parts of the test suite.
or more simply: ```python if not other: return copy.deepcopy(self) elif not self: # bool(other) is implied to be True by the previous condition return copy.deepcopy(other)
I think the suggestion is to maintain the "Invalid field name(s) for model ..." error message a property that doesn't have a `setter`.
Might want to rename that to `test_ptr_accessor_assigns_state`.
I think splitting this to more lines would increase readability. Probably the same for the above with `self.relname`.
The docstring on `setup_joins` gives a list of the returned fields of `JoinInfo`. That should be updated to include the new `final_transformer`, or reference `JoinInfo` instead/as well.
Thanks @MatthewWilkes. It was only that sentence/paragraph that needs fixing here, since it's adding the new value that will be unpacked. Any other clean up can wait.
I think I'd keep the `fields` parameter as a list, perhaps passing `None` for `params` here.
You changed the first `_` to capture `field`, but it's not subsequently used.
I'd rather see the docstring updated in this one: just so it's not forgotten. With the change, the paragraph beginning `Return...` isn't right. My worry is if we leave it then it'll be forgotten.
I think we prefer the closing paren on a newline
My only concern here is for 3rd party backends that might need to support different returns depending on the versions they support. @manfre I know you're not doing much with mssql these days, but would this change affect mssql much, and would a solution be difficult? I'd imagine it'd be something along the lines of: ``` if version >= (2, 0): return sql, params return sql ```
Drop the unneeded parentheses.
Drop the unneeded parentheses.
```python if not hasattr(final_field, 'resolve_expression'): final_field = final_field.get_col(alias) try: final_field = self.try_transform(final_field, name) ... ```
Is the class name correct? I don't see any F expressions -- maybe I misunderstood what "FLookup" means.
`.as_sql()` is the default implementation. `as_{backend.vendor}` is the backend specific implementation *if it exists*. `compiler.compile` checks if a backend specific implementation exists first and uses that, falling back to `as_sql` if one does not exist. So, `self.compile(transform_function(..))` I think would be correct.
Does this make a difference to the tests? I'm not a fan of the bilateral attribute - it was introduced before expressions were a thing. Not sure we want to propagate their use.
This is getting out of hand, especially considering callers ignoring so many of the return values. Does it make sense to create a type to model these values? At a minimum I think we should consider namedtuple.
`def transform(field, alias, *, name, previous)` ? Makes the partial application further down more obvious that name and previous are supplied by keyword args. Not certain this is better, but I had to double check the partial applicability worked correctly.
Please don't suggest doing unrelated cleanups along with bug fix or feature work. We try to avoid that as it confuses things when studying a patch.
Now you're using `subTest`, the docstring isn't quite right.
This exchange is a little bit curious (coming to review). I try with `None` as default for both parameters. I get two failures in `test_follow_307_and_308_redirect`, both with the same trace ending: ``` File "../django/django/core/handlers/wsgi.py", line 83, in __init__ self.content_type, self.content_params = cgi.parse_header(environ.get('CONTENT_TYPE', '')) File "../lib/python3.6/cgi.py", line 319, in parse_header parts = _parseparam(';' + line) TypeError: must be str, not NoneType ``` So it has to be `''` when we get right down to it. Plus we're passing `**extras` around in most methods, and there's no real place where we're checking that. `_base_environ` may be a candidate, but that's way out of scope for this ticket.
It's a small detail, but I think the variable naming could be improved here. `request_method` and `req_method` are very similar names (one is just a shortening of the other) but they mean very different things. I might rename `request_method` to `req_method_name` or something. Or you could probably just turn this into a single line and avoid a temporary variable.
Add trailing comma.
Flatten to a single line.
It is not the status code that needs to preserve the request method. Perhaps the following reads better: `# Preserve request method post-redirect for 307 and 308 responses.`
Use `subTest()` in this and the other new test methods below to reduce copy-paste.
You can remove the try/except here.
I think `assertNotEqual` is sufficient -- that would be if display_name is None.
You might assert `BaseDatabaseWrapper.display_name == 'unknown'`, that would make the `assertNotEqual` more meaningful.
The skip condition should be removed as it's not possible to run the tests with an unknown vendor, I think.
If size can be `None`, I suggest to make it an optional parameter like `def batches(iterable, size=None):`
As with the old `_batched_insert` code, I think we should pass the db alias here `self._insert(objs_without_pk, fields, using=self.db)`, it defaults to that but passing it seems more explicit.
Hi, this name should be assert_foreign_key_exists
A common style in `unittest` docstrings is "Fail if ..."
'concerned about' reads better than 'concerned with'
Even though `AuthenticationMiddleware` is no longer useful, it needs to remain as a stub and go through a deprecation.
Maybe `subTest` to make tests less repetitive e.g.: ```python msg = 'Geotransform must consist of 6 numeric values.' for geotransform in ([1, 2], [1, 2, 3, 4, 5, 'foo'], [1, 2, 3, 4, 5, 6, 'foo']): with self.subTest(geotransform=geotransform): with self.assertRaisesMessage(ValueError, msg): rsmem.geotransform = geotransform ```
I'd put this in a separate test method.
I'm not seeing what the benefit of that would be. `self.addCleanup(self.temp_dir.cleanup)` calls `cleanup()` which removes the finalizer so there isn't a warning.
Thanks for that.
"with an index"
It seems that the third "WGS_1984" on this line is normalized to "WGS_84". With that change, this is passing for me on ubuntu 14.04/16.04.
I think: `_, ext = os.path.splitext(name)` is a bit more readable than "magical" indexing.
the same suffix as the original file
Can you elaborate on "because the latter behaves more like an integer"? I'm not sure exactly what that means.
What's magic about the value of 8? Seems like it can be changed to other nearby integer values without any tests failing.
Use hanging indent as mentioned before.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). e.g. ```python self.assertEqual( nformat(Decimal('1e16'), '.', thousand_sep=',', grouping=3, force_grouping=True), '10,000,000,000,000,000' ) ```
Might want to the following to avoid the attribute lookup while you're at it. ```python prepare_value = super().prepare_value return [prepare_value(v) for v in value] ```
I guess `collapse` isn't needed, is it? Then you don't need the selenium test change.
I'd use Child rather than Descendant as this seems like more common terminology in the test models.
This is because `'tests'` will be used for `app_label` if not explicitly specified.
I don't understand why this is required to avoid `RuntimeError: Model class schema.tests.Author doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS.`. I thought `isolate_apps` takes care of that.
In the original review of this file, I missed the fact (unless I'm missing something now) that there's no need to call `list()` inside of `len()`.
, combine all nonempty querysets.
I wonder if it would be simpler and more efficient to filter out all empty querysets. from self and other_qs, then use `qs[0].self._combinator_query('union', qs[1:], all=all)`, accounting for the case where qs might have zero or one elements.
I'd use more descriptive variable names, e.g. `nonempty_qs_index, nonempty_qs = `
I don't see a need for the `ingredients` variable.
There's no need to put the ticket number in the model name. If possible to reuse any existing models, that's ideal.
Chop the blank lines
, keeping a reference to the cyptes object so that the vsimem file...
You can use `sr1.ingredients.set([i1, i2, i3])` to make that less verbose.
Docstrings should state the expected behavior. It doesn't need to describe an old, incorrect behavior.
Nitpick, but shouldn't these be assertEqual()? This would be consistent with `if len(queryset) == 2` instead of `if len(queryset) is 2`.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Please revert this line removal.
Maybe *`The model name ``<name>`` is longer than 100 characters.`*.
I would say, 'Model names must be at most 100 characters (got %d).' I don't think a hint is needed.
I wonder if this might be bit more readable: `model = type('A' * 101, (models.Model,), {'__module__': self.__module__})`
I think it would be better to make a single check e.g. ```python self.assertEqual(check_model_name_lengths(), [ checks.Error( 'Model name is too long.', hint='Model name should not be longer than 100 characters.', obj=ModelWithNameOfOver100CharactersModelWithNameOfOver100CharactersModelWithNameOfOver100CharactersModel, id='contenttypes.E005', ) ]) ```
I think it would be better to make a single check e.g. ```python self.assertEqual(check_model_name_lengths(), [ checks.Error( 'Model name is too long.', hint='Model name should not be longer than 100 characters.', obj=ModelWithNameOfOver100CharactersModelWithNameOfOver100CharactersModelWithNameOfOver100CharactersModel, id='contenttypes.E005', ) ]) ```
I'm pretty sure you want to keep using `isolate_apps` here.
only() works with proxy models
"Make sure" is a phrase to avoid
Well `.all()` will definitely add a query because it will create a new `Queryset` without `_results_cache`.
Since we don't use the results `.count()` is definitely more appropriate here.
In which cases does `__len__` gets called by the form layer? I'm asking because if it's only to allow third party to do `if field.choices` we better be implementing an optimized `__bool__` as well because `.count()` can perform bad on large resultsets. ```python def __bool__(self): return self.field.empty_label is not None or self.queryset.exists() ```
An optimized `__bool__` definitely makes sense. On the other hand (as mentioned in the ticket), the queryset is (now, since 1.11) only shared per form instance, and not per form class. Given that, an alternative approach would be to remove the `.all()` in `__iter__`, and indeed reuse the queryset for the lifetime of the form-instance.
perhaps this should be moved to a class constant so it doesn't have to be repeated.
Docstrings should generally try to state the expected behavior, be a single line if they are short enough (within the 79 character limit), and end with a period.
Perhaps this test could mock `random.randint` to be more useful.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Perhaps this could mock `random.choice('?.')` to test both scenarios.
Please add a trailing comma.
Please add a trailing comma.
Please add a trailing comma.
This can be single lined: ```python self.assertEqual(Media.merge([1, 2], [2, 1]), [1, 2]) ```
Use a single quote.
This can be single lined: ```python '%s\n%s' % (combined_list[prev], combined_list[k]), ```
Use a single quote.
This is the same test as above.
I'm okay keeping the copying stuff if we have a test to show why they're needed. Also, `dict()` might need to be `deepcopy` instead.
Please use a single quote.
Maybe: `if '\x00' in str(value):`
You can drop `(object)` as master only supports Python3.
Is `text` used? If unused, you can remove.
You can drop these parens as well: ```python class NullCharValidator: ```
I'd use something like `null_character_not_allowed`
Please use single quote. `message` can be single lined.
I would say: _"""Validate that the string does not contain null characters."""_
`ValidationError` can be single lined.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Something along these lines would break on tables that haven't been rebuilt and still have `IMMEDIATE` foreign key constraints: ```python with transaction.atomic(): # The following line will immediately fail now that foreign key # constraints are enforced and were created as IMMEDIATE # instead of INITIALLY DEFERRED. Book.objects.create(author_id=1) Author.objects.create(id=1) ``` We might want to mention that constraints used to be built as `DEFERRABLE IMMEDIATE` in the _Foreign keys are now created with ``DEFERRABLE INITIALLY DEFERRED``_ section and might require a rebuild to allow the above pattern to be used.
I wonder how this will play with existing SQLite tables that don't have `DEFERRABLE INITIALLY DEFERRED` constraints. At this point I think the best course of action would be to mention it in the release notes.
I think the `is_valid()` assertions can be removed. The `formset.errors` assertions will fail if the formset is valid.
I think the `pk_field` variable could be removed here and below.
I think data is usually not passed as a kwarg, at least it's not needed here.
This test is already passing without the changes in this PR so perhaps better to omit or put in a separate commit? non_existing -> nonexistent
Could switch to single quotes as long as this is being modified.
Doesn't matter much, I guess.
Traditionally we've checked for `resolve_expression`, yes.
I'd drop the list comprehension, `sorted` accepts a generator.
Explicit cast to `str` is unnecessary.
Use `True` instead of `'True'` as value will be implicitly cast to `str`.
It might help readability to pass `method_name='aggregate'` -- otherwise the meaning of that string isn't so clear without looking up the method's signature.
Use `True` instead of `'True'` as value will be implicitly cast to `str`.
Explicit cast to `str` is unnecessary.
I was thinking all of this could be in a method like: ```python def validate_values_are_expressions(values, method_name): invalid_args = sorted(str(arg) for arg in values if not hasattr(arg, 'resolve_expression')]) if invalid_args: raise TypeError( 'Queryset.%s() received non-expression(s): %s.' % ( method_name, ', '.join(invalid_args), ) ) ```
Since the args/kwargs aren't used directly, would this be simpler to maintain as `*args, **kwargs` instead? (I can just see a case where it ends up out of sync with `BaseMemcachedCache`)
Oh `value` is used, I can't read! (There are some methods that don't use the passed arguments, but perhaps they should all be specified for consistency)
`in self.query.alias_map` should be faster.
You can remove the `keys()`.
cleaner as a triple quoted string (`"""`), SQL isn't whitespace sensitive
A bit simpler could be "Clear cached, stale oids."
I don't have a strong opinion about the quote style but use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
These args could be wrapped closer to 79 chars.
used to decide -> indicating
I would structure this like this: ```python fields = fields_for_model( opts.model, opts.fields, opts.exclude, opts.widgets, formfield_callback, opts.localized_fields, opts.labels, opts.help_texts, opts.error_messages, opts.field_classes, # limit_choices_to will be applied during ModelForm.__init__(). apply_limit_choices_to=False, ) ```
I think "if needed" rather than "if it and the....exist." is sufficient given the code is straightforward.
Put import at top of file.
which again brings the question :)
May be he wanted to catch system exiting exceptions - BaseException, SystemExit, KeyboardInterrupt and GeneratorExit. But i fail to see the reason for this
IMO, the test is simple enough that the docstring isn't needed.
I'd multiline this.
I meant all branches.
It's a bit of a shame that we have to resort to full scan of the project state but I'm afraid it's the only solution to detect `to_field` references without rendering the model states.
I'd drop it, and reintroduce the test later on in branches where we'll be able to backport #9383.
As I was trying to point out on the ticket, I'm confused on why this is an issue at all. When using `sqlmigrate` Django produces the correct SQL. However, when running `migrate` Django seems to be doing the wrong thing. I'm think it would be worth investigating in that direction a bit further to see why and where those differences come from, before removing the delayed rendering (entirely)
FWIW in #9383 this is handled by the `RenameField` operation -- no `AlterField` operation will be generated by the auto-detector just like none are generated on a model and `to` rename.
This needs an update following 831358f23d545b8dba017c6b26bd295ba9f6c17d.
I think there's a mistake in `GinIndex.deconstruct()` also... these should be guarded with, e.g. `if self.fillfactor is not None` similar to logic in model fields' `deconstruct()`.
You can combine the `_should_delete_form` check using `self.can_delete and ...` above.
I'm not sure if there are lookups where it's not the case, but comparisons such as `Choice.objects.filter(votes__gte='2')` seem to work fine with the value as a string so the "transform" stuff seems unnecessary, at this for the first version of this.
Okay, it can be done separately consider this is an existing error message.
This is probably better in `tests/modeladmin`. How about a test for `AdminSite.admin_index_url()`? The tests are lacking in the fact that there's nothing to guarantee these methods are used throughout the admin views and templates. I guess that would substantial testing.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) (as you did in `admin_history_url`).
It seems like it would be more consistent if the methods were prefixed with `get_` as `get_view_on_site_url` is. Without the prefix, I'd expect a name like `admin_index_url` to be a property. I don't see the usefulness of `admin_viewonsite_url` as a layer of indirection to `get_view_on_site_url()`.
Might want to use a generator here to make it more readable `(field for field in self.get_source_fields() if field is not None)`.
single line docstring is okay if it fits
wrap docstrings at 79
single line looks better IMO
Remove the blank lines.
Slightly faster: do `suppress_AttributeError = suppress(AttributeError)` at the module level then use `with suppress_AttributeError` here, avoid reconstructing it each time.
Ah, good point. I don't think it's cleaner in general, I was just trying to keep `QuerySet` / `Query` fast like my optimization efforts. Since it's a fairly small here I don't feel that strongly about the global, you can leave it as-is
I guess we could go with just ._clone() and ._chain(). If we want to allow for "in place" querysets, we could just add `clone` argument to chain. If set to False, it effectively does what ._pre_next_op() does right now.
with UNION and with DIFFERENCE if the first queryset is nonempty.
I'd chop the blank lines around `for_update_part`.
I'd omit the blank lines.
By the way, [looking up `SpatialOperator`'s implementation](https://github.com/django/django/blob/31a2af1c0101081a3950dab0e66fa41bbbf6d34f/django/contrib/gis/db/backends/utils.py#L7-L27) I think you could probably go away by simply overriding `default_template` instead. ```python class SpatialiteNullCheckOperator(SpatialOperator): @property def default_template(self): return '%s > 0' % super().default_template ```
Probably it could be reworked this way: ``` sql, params = super().as_sql(connection, lookup, template_params, sql_params) return '%s > 0' % sql, params ```
This seem to be duplicated for some reason.
It might be worth adding some sort of hook to the superclass so that so much copy/paste from the parent `as_sql()` is required.
`list` is unneeded here. As an alternative you could use: ``` qs = State.objects.filter(pk=null.pk) self.assertFalse(qs.filter(poly__intersects=LineString((0, 0), (1, 1), (5, 5)))) ```
https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style > In test docstrings, state the expected behavior that each test demonstrates. Don’t include preambles such as “Tests that” or “Ensures that”.
You could use a loop and subTest to make the test less repetitive. e.g. have a list of dicts like `{'poly__equals': Point(1, 1)}` and then use `qs.filter(**filter_kwarg)` within the loop.
You can provide a pastebin link with the failures? Feel free to ping me (timograham) in #django-dev.
This `operation.atomic or (self.atomic and operation.atomic is not False)` expression can be replace with `operation.atomic`.
Why 70? "sha256" = 6 + "$" = 1 + "<sha256 hash>" = 64 would give 71.
I believe `key` should also be coerced.
I know that this is only meant to land in `1.11.x` wonder if using `u''` prefixes/`force_text()` would make what we're testing more clear.
I guess this is going to crash if the value contains non-ASCII chars? Maybe we should be using `force_bytes(s, encoding=SYSTEM_ENCODING)` instead of a bare `str()` call? I'm not a Windows expert but I think we have similar handling of data the localization tools.
I guess it could be better as a database feature in case any third-party databases also have that limitation.
Clarify "might"? Or simply say `# Silence "Truncated incorrect CHAR(1) value: 'Bob'".`
I'd make it a separate method: `test_cast_to_char_field_without_max_length`
Use `raise .. from ...` as in 6e55e1d88a5c4453e25f0caf7ffb68973de5c0ba to get the benefit of exception chaining. Perhaps the original exception type should be preserved rather than converting ValueError to TypeError, otherwise that change could be backwards-incompatible (although it might be more helpful in the long run if user code only has to catch TypeError). For the message, perhaps something along the lines of `"Field '{}' expected a number but got {!r}"` would be more clear. Some test updates are required.
Use a single line. I think two CharField()s should work just as well and make the line shorter.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
It's better to use `assertIs(..., False)` since `assertFalse` will also pass if `bool(result) is False`.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Drop the blank line.
Drop the blank line.
As far as I see, it's possible to test the model fields the same way as the others: ``` field = forms.ModelChoiceField(Author.objects.all(), disabled=True) self.assertIs(field.has_changed('x', 'y'), False) ```
I don't think repeating the docstring on every subclass is needed.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
This could become a class attribute so it needn't be repeated.
`self.assertEqual(f.choices), [])` looks simpler to me (plus if the list isn't empty, another debugging step isn't needed to see what the list contains).
Perhaps the full list could be a class attribute so it doesn't have to be repeated several times.
I'd use `return a if b else c` but it's up to you.
I'd omit a blank line here.
Could be nice to fix and test this typo separately.
Drop the comma/space in `[FakeFieldFile(), ]`
"is_required=False and an initial value that's a file, renders..."
What's the purpose of these lines? When I run the script, the suffix is always ".js" so this condition is always True.
Is `expanduser()` needed? Seems like it's done automatically.
Fine with me.
`AttributeError: 'PosixPath' object has no attribute 'with_suffic`
Don't change that per https://code.djangoproject.com/ticket/27878
To match the old code this should be: ``` if (zoneinfo_root.exists() and not zoneinfo_root.joinpath(*self.TIME_ZONE.split('/')).exists()): ``` You are missed the second `.exists()`.
might be worth using `Model._meta.pk.name` instead of explicit `'id'`
trailing comma is syntax error on Python 3.4 (build didn't trigger on the PR)
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Worth some unit tests for `from_ewkt()`? This line isn't tested based on the coverage report for PostGIS and if the other exception raising in this method is removed, the only failure is in `gis_tests.test_geoforms.GeometryFieldTest.test_field_string_value` which wouldn't be very easy to track down, I'd think.
This doesn't pass on Oracle: `<QuerySet [<City: Houston>, <City: Dallas>, <City: Oklahoma City>, <City: Wellington>, <City: Pueblo>, <City: Lawrence>, <City: Chicago>, <City: Victoria>]> is not false`.
Maybe store the data type instead of getting it twice? ```python db_type = connection.ops.cast_db_types(self.get_internal_type()) if db_type: return db_type % self.db_type_parameters(connection) return self.db_type(connection) ```
Oh, I see `raise_last_exception` also looks like it moved. Maybe it makes sense to do some reordering to keep the diff a bit smaller. Maybe not.
Some docstrings for these methods could be useful.
This fails for me: ``` AssertionError: <MagicMock name='WatchmanReloader()' id='140033332456584'> is not an instance of <class 'django.utils.autoreload.StatReloader'> ``` perhaps that's the failure that Jenkins encountered.
remove "0" in {0}
Not need to use assertDictEqual as far as I know? (Of the assert<type>Equal methods, Python docs say, "Note that it’s usually not necessary to invoke these methods directly.")
chop blank line
chop "should" (just state the behavior)
Omit 0/1. There was a past commit that removed all usage of that since it just adds verbosity.
Please add a docstring explaining this.
single line looks more readable here
Returns -> Return use period
This change doesn't look necessary. We prefer assertIs in most cases because assertTrue passes for bool(value) which might not be what we want.
Maybe it would be better to change 'path' to 'file_path' for consistency with the rest of the references to the signal arg.
It's possible we need to guard this code with `if settings.USE_I18N` is some way. Also, I'd like to make sure we are not interfering with the `Trans/_trans` black magic this module performs by putting this signal receiver here.
I think this should error somehow get printed or a warning given or something (maybe only with verbose?). (in my case it's happening if pywatchman is installed, but not watchman.): `pywatchman.WatchmanError: "watchman" executable not in PATH (%s), while executing [Errno 2] No such file or directory: 'watchman': 'watchman'`
Yeah, only on the first load if possible, otherwise maybe pass in verbosity from the runserver command and only show it if a higher verbosity is passed in. I think it would also be neat if instead of saying "Watching for file changes with StatReloader" it could figure out the common error and just say something like "Watchman client not available, watching for file changes with StatReloader". That way it's more clear what's going on, but not spamming the console either.
This addition of LOCALE_PATHS seems redundant with the one three lines below.
It's slower, about 10 times.
Please replace this with a regular `try/except`.
Please revert the whitespace addition.
Use single quotes.
It would be nice to keep the page translatable. I'm not sure the strings need to be translated in Python, perhaps the template could `{% load i18n %}` and use the regular template translation tooling, with appropriate tweaks to the `DEBUG_ENGINE` configuration.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
revert the whitespace change
My concern with adding `copy()` is that it is adding in redundant work for most cases to appease a small subset of very specific use cases.
I'm not sure we need to do this as the default behaviour. A subclass can do it's own `.copy()` (or whatever other method you want to do to build the state)
`pos_list` could be changed to be a generator now that it is only unpacked into `itemgetter`: ```diff -pos_list = [row_pos for _, _, row_pos in reorder_map] -self.reorder_for_init = operator.itemgetter(*pos_list) +self.reorder_for_init = operator.itemgetter(*(v[2] for v in reorder_map)) ```
It looks okay to me to do in the same commit.
I also noticed that in the first commit you did for this ticket there is ```operator.itemgetter(*[…])``` which could also be changed to use a generator to avoid the list instantiation.
I'm not a fan of aliasing builtin names.
@timgraham adding a method call will definitely affect performance on CPython. Assigning `self` attribute to a local variable is a common pattern to avoid `self.__dict__` lookups in a loop.
I meant changing the signature of `apply_converters()` to: ``` @staticmethod def apply_converters(self, connection, rows, converters): ``` I guess that change doesn't make much sense given `apply_converters()` is called in some other places.
It looks like `(' %s' % order).strip()` can simply be `order` now.
``` if name is None: name = self._create_index_name(*args, **kwargs) return self.quote_name(name) ```
A bit unrelated, but I would move the closing parenthesis to improve readability: ``` statement.parts['extra'] = ' WITH (pages_per_range={})'.format( schema_editor.quote_value(self.pages_per_range) ) + statement.parts['extra'] ```
I'm not sure if you intentionally reordered the kwargs. Maybe it makes sense to add a `*` in there to catch bugs in case code is passing kwargs as args.
@sir-sigurd it's needed to prevent accesses to `ModelState.fields_cache` from crashing which is something some IDEs do under the hood for introspection. See dc1ad69f30f48d3c27406373f62f87e93550cdc5 and b88abd684041ffa66bfe445e1ac26164e803d488.
Past commits standardized the signature for descriptors with `cls=None`.
Please wrap: ``` # If true, uniqueness validation checks will consider this a new, unsaved # object. Necessary for correct validation of new instances of objects with # explicit (non-auto) PKs. This impacts validation only; it has no effect # on the actual ```
I think a test could go in a new file: `tests/model_regress/test_state.py`.
Not sure, discussion is https://groups.google.com/d/topic/django-developers/3eSHhZUzxv4/discussion.
not sure if this really passes the django style guide, compared to plain if/else statements
We should try cache the `namedtuple` classes that come out of this, they can take about half a millisecond to instantiate, which is a lot of time - if a view invokes 10 queries that's 5ms, or 10% of a tight performance budge, gone: ``` In [14]: %timeit namedtuple('Row', ['a', 'b', 'c', 'd']) 1000 loops, best of 3: 417 µs per loop ``` If you make `names` a tuple (so it's hashable) then you can just have: ```python @lru_cache() # using default maxsize, i don't think it would need tweaking really def create_namedtuple(names): return namedtuple('Row', names) ``` Also the temp name `rows` isn't needed, I'd move it into the map call, leaving: ```python return map( create_namedtuple(names)._make, super().__iter__(), ) ```
I'm still not sure what "tuple_class._make() is inlined here" means.
For similarity with other messages (e.g. 'The nowait option cannot be used with skip_locked.') you might change 'passed' to 'used'.
``` # Cache namedtuple() with @lru_cache() since it's too slow to be # called for every QuerySet evaluation. ```
I think the test should be split into multiple test methods, one per thing-being-tested, as above
`maxsize=None` is a bad idea like Aymeric says in #8825.
If only `QuerySet.extra()` is affected, we can skip it since `extra()` usage is discouraged.
It looks okay to me.
Did you consider using `queryset.model` instead of 'Row'? I don't know if that would cause confusion with model instances.
Please report bugs at https://code.djangoproject.com/.
Maybe something like: SQL to create a procedure for use by the Django test suite. The functionality of the procedure isn't important. (not sure if that second sentence is correct -- feel free to revise)
maybe create_and_call -> "test" to be a bit shorter
I was thinking `CursorWrapperTests` might be useful for future tests.
Generally I think we want to use `TestCase` for any test that accesses the database, especially in light of the possibility of https://code.djangoproject.com/ticket/28478.
I'm curious if the slashes are needed. Both on MySQL and Oracle, the tests seem to pass without them.
@claudep, does this look okay for translators? I'm not sure if it allows apply localization formatting to the numbers.
I'd suggest not changing these as it's not related to the patch.
Use assertRaisesMessage to verify the message also.
For translators, it would be better to use named placeholders, so languages which need reordering can do it nicely.
Start the sentence "Duration's number of days..." Also, add a trailing period.
Oops, didn't saw it.
The `__init__()` method? There are ~15 lines below `super()` that seem to be used.
This changes such behavior: ``` In [18]: RandomUUID(1, output_field=None) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-18-7594cbdb3c8e> in <module>() ----> 1 RandomUUID(1, output_field=None) TypeError: __init__() got multiple values for argument 'output_field' ```
That's how it works after the change: ``` In [8]: expr = RandomUUID(1, 2, TextField()) In [9]: expr.output_field Out[9]: <django.db.models.fields.UUIDField> In [10]: expr.source_expressions Out[10]: [Value(1), Value(2), Value(<django.db.models.fields.TextField>)] ```
I think that's OK too. It simply looks a bit odd that all that `Func` machinery is used to output constant string.
I think this `__init__()` could be removed too.
This could be removed now.
The problem is not about `output_field`. `RandomUUID` didn't accept any source expressions previously, but it accepts any number of them now. I think that behavior should be preserved here. Also I think it could make sense to inherit directly from `Expression` and define `as_sql()` to simply return `'GEN_RANDOM_UUID()'`.
It seems that `math.isfinite()` checks for both `NaN` and `Inf`. I don't think cast to `float` is needed here.
casted -> cast
Generally we would rather expand the docstring with sufficient explanation rather than include a ticket reference (or at least keep the mention limited to a simple "(#18247)" as in tests).
Not a huge deal, but it might be nice to have this user-configurable, defaulting to 191, because some people may configure mysql to have a longer maximum length.
Ah I see
Yeah, maybe in OPTIONS for the database. Maybe MAX_INDEX_CHARACTER_SIZE.
This skip condition could be removed.
I'd omit the blank line since the ) on its own line provides space.
aren't supported in PEP 249, but the database driver may support them (e.g. cx_Oracle).
The current idiom might be required because some backends (perhaps third-party ones) choke on empty `params`. I'd keep it.
`_get_no_autofield_sequence_name` doesn't exist in `stable/1.11.x` branch. Please use `_get_sequence_name` instead.
I'd suggest this for the indentation: ```python return [ force_text( capi.get_field_name(capi.get_field_defn(self._layer._ldefn, i)), self.encoding, strings_only=True, ) for i in range(self.num_fields) ] ``` Any concern about having no tests for the `self.encoding, strings_only=True` bit? I'm not sure we would expect non-string values in the first place? Also, at least on my system, there are no failures with it removed here or in `layer_name` above.
Use the following indentation ```python authors = Author.objects.filter( name__in=[self.author1, self.author2, self.author3], ).prefetch_related('bio') ```
It would be worth checking if these field changes render other tests relying on the `Bio` model moot.
You need to remove the underscore prefix from the test name to allow the test to run.
Maybe: `return ("%" + str(arg)) % (str(value) if isinstance(value, tuple) else value)`
Please use single quotes.
You've added seven asserts, but only two are related with this fix, so I think it will be better to send: ```python self.assertEqual(stringformat([1, None], 's'), '[1, None]') self.assertEqual(stringformat({1, 2}, 's'), '{1, 2}') self.assertEqual(stringformat({1: 2, 2: 3}, 's'), '{1: 2, 2: 3}') ... self.assertEqual(stringformat(object(), 'd'), '') self.assertEqual(stringformat(None, 'd'), '') ``` in advance in a separate PR.
Pushed that in a64f88f5be0f680a7.
"this is allows bigints" sounds wrong.
What is that check for? I think `is_valid()` cannot be `True` if there is an error in the form. In other words, the `non_field_errors()` check is performed as part of `is_valid()`.
I think this blank line can be removed.
It should be fine to check the complete warning similar to: https://github.com/django/django/blob/4d60261b2a77460b4c127c3d832518b95e11a0ac/tests/check_framework/test_model_field_deprecation.py#L17-L23 I forget if there was a reason the existing test doens't use that approach.
I'd reverse the ordering and say "use list instead of []"
I think this method could be moved to a mixin and shared between the two classes. Using the same 'id' seems fine the the hint text could be customized with a class attribute. For the warning, I'd say something like `"%s default should use a callable instead of an instance so that it's not shared between all field instances." % self.__class__.__name__`
My recommendation was to make "`list` instead of `[]`" customizable in subclasses so you say have "use `dict` instead of {}` for JSONFIeld..
No, at least not part of this PR.
The test should probably use `subTest()` similar to 272f685794de0b8dead220ee57b30e65c9aa097c so that all HTTP methods are tested (at least if the change to every method is required).
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
The rest of Django's test use `@mock.patch` so I think we should use that.
Docstring shouldn't have a trailing space. Docstring sentences should end with a period.
Same here, not following order `(value, expected)`
Same here, not following order `(value, expected)`
Same here, not following order `(value, expected)`
Guess it's better to use `self.assertGreater(len(para), 0)` instead
I guess it's better to have ` self.assertEqual(words(2, False), 'exercitationem perferendis')` to follow the pattern of `(value, expected)`
, -> ;
It's not obvious to me why you put the class here -- it looks like it's in the middle of two collectstatic test classes, perhaps it could be better ordered.
"Specify encoding to support unicode in DSN."? Maybe it would be better to to change `kwargs` -> `conn_params` and the existing `conn_params` to something like `user_params`. The `kwargs` name seems off to me. Sorry for the back and forth over a simple patch!
Client encoding may be changed in OPTIONS.
Makes sense. I'd say that a test could be useful but since this isn't going to master, I don't mind if it's omitted.
I don't think it's useful to include `value=v` in `subTest()` since that would appear in the failing assertion. (Similarly, for `output` in the other tests.)
`str(self.band)` doesn't seem like a realistic value for the message.
In this case, I think a ternary is more complicated to read than: ``` if srid == -1: srid = None ```
one space after period
What's your thinking on removing this? I think it might help readability in the test rather than putting the the mysql version check there. I don't know if it might be used elsewhere later.
Yes, on `GeometryField`.
Add an exception message similar to the other methods.
objects. It may take...
"is used to specify" -> specifies
You could update the verbs tense to the convention used elsewhere: "Handle", "set", etc. rather than the "ing" versions.
This is quite inefficient. how about this instead: ```python for error in self.error_list: if not error in other.error_list: return False return True ``` There's no need for making a copy of the other error list and removing items from it. Since you've already established that the two lists are of same length, if every item from one list is in the other, both lists are identical with regards to their content.
Missing test for this change.
Are these tests checking something that the `m2m_through` tests aren't? It looks odd that the results of these calls aren't verified.
Sure, I will push those change, except the suggestion for `add()` gives invalid syntax.
`mus` → `must`.
Can replace `**dict(through_defaults, **{…})` and use unpacking generalisations: `**{**through_defaults, **{…}}`.
I guess `**through_defaults, **{…}` would work as well given surfacing a `TypeError` if any of the ids properties are provided through `through_defaults` is probably a better idea than simply dropping them.
Also the `%s_id` is probably going to break for fields that define different `db_column`s. This wasn't an issue before because this branch could only be reached with auto-created intemediary models but now that we allow all forms of `through` we should use `attname` or directly `*_name` here.
Oh. Strange. Not sure why that doesn't work. Thanks.
I noticed that we use keyword-only arguments for `def set(self, objs, *, clear=False, through_defaults=None):` Do we want to so something similar for other methods: - `def add(self, *objs, *, through_defaults=None)`: - `def create(self, *, through_defaults=None, **kwargs):` - `def get_or_create(self, *, through_defaults=None, **kwargs):` - `def update_or_create(self, *, through_defaults=None, **kwargs):`
Is `EmailMessage` correct? When running tests, I see `body_msg` is something like `SafeMIMEText` or `SafeMIMEMultipart`. Please use a period at the end of the sentence.
must include -> includes
How about: ``` return super(JSONField, self).has_changed(initial, data) or str(initial) != str(data) ``` I think there's no need to repeat the docstring from the superclass but explaining why the `str()` comparison is needed would be useful.
Remove arguments from `super().`
This can be simplified to `return []`.
`# Check for subtags, e.g. 'ab-cd-x-informal'.`
Checking `'exp' in locals()` looks a bit hacky and unconventional to me. Why not simply assign `exp` in the `EOFError` case? For example: ```py try: exp = pickle.load(f) except EOFError: exp = 0 ``` You could use a sentinel other than 0 if you prefer.
Recently, we've been using `self.assertIs(..., True)` as `assertTrue()` could hide a bug.
does_not_throw_exception -> considered_expired
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Don't add a blank line.
Remove unused import.
I don't see a need for string interpolation in cases like this.
`assertTrue(value)` will pass for `bool(value) is True` which is different than checking for `True`.
Was this intentional? Doesn't seem to be related to the task...
if I pass `attrs={'multiple': False)` and init with multiple=True, they are out of sync.
Why not showing list of links here? Like this you don't actually know what files you're clearing...
`assertIs(... , True)`
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
``` return files.getlist(name) if self.multiple else files.get(name) ```
Would be handy if this tells which was was empty. Or change the message to - "One of the submitted files was empty".
What happens if `multiple=True` but `attrs={'multiple': False}`? If things break, it would better to raise an exception here than to allow it
How about only including the name in the "multiple" case? (Add a new 'empty_multiple' error message and leave this one alone.)
a single file or a list ...
I think at least the latter is worth it - it's confusing to submit two files and be told "the" file is empty.
@codingjoe the issue with `assertTrue` is that it's more of an `assertTruthy`; any value that evaluates to `True` will pass (e.g. `1`, `'hello'`, ...).
fair enough, I was just taking a very narrow view here
looks to me like it could actually be a set comprehension for more speed again since it's only used for N `not in` checks below
This looks like the only test failure that's fixed so the other tests should go in the first commit of "existing passing tests". Similarly, the commit message could be improved to describe more specifically what situation is fixed considering some scientific notation seems to already work.
Isn't this off by one? If I construct ``` x = Decimal("1.1e1") val = DecimalValidator(2, 20) ``` then `val(x)` throws, even though `int(x) == 11`
You're right, I misunderstood what was going on here. For some reason (I think because I hadn't loaded settings) my exceptions weren't printing messages, which didn't help.
drop the new line please
Generally, your coding style uses many more blank lines than the rest of Django.
`clean` is not only for validation, but also for data modification in a form.
This migration will be very slow. I would recommend using the `F` object to perform the migration in a single update statement rather than looping over all rows.
Breaking up the tests into separate files looks good, but please offer that as a separate PR (moving existing tests without any functionality chagnes) that precedes this change so that it's easier to see the changes here.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
I would suggest to merge this and the `0002` migration into one.
I would recommend putting this inside a `clean` function, not in save.
Why does it need to be installed in this migration? This migration doesn't even do anything. It's not given that all new migrations are applied at the same time.
`site` is a field on `Redirect` therefore it will be displayed even if `django.contrib.sites` is not installed.
Same here, the unique constraint is only removed in the ORM but will still persist in the database.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
This will only work for up to 3-5 sites. I would recommend using a select input.
I am not so sure about that change. This is not an integer field, but a FK. It's not nullable, it has an index and some databases have other pseudo tables to reference a FK field. I am not sure if this actually works using all Databases. I would recommend to be extra careful when changing old migrations.
python 2 code here
Yes I hope people do read help texts, but the help text doesn't imply the current behavior. It overwrites the domain provided in a form, no matter what.
You are silently overwriting a value displayed in a form. You should exclude it entirely form the form or set it dynamically using JavaScript.
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
This is a long list of migrations. I would recommend to try to get as many operations into one migration as you can. Loading a lot of migrations will slow down Django during startup and all migration commands.
ok, fair enough
This should use longer lines (up to 119 characters) or hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
How is the schema change related to data loss? I would recommend to have those checks in the next migration, the data migration.
That implies that the constraint cascased, again I don't know if this is the case of all DBs.
I presume who ever put it there had a different opinion ;) I would recommend to leave it be.
Boolean fields have check constraints on their values.
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
Could move `executable = '/usr/bin/python'` to a class attribute.
Maybe it would be nice to put the shared test logic into a helper method.
You're quite right, sorry, not sure how I came up with that idea.
If I understand correctly, `AbstractBaseUser._password = x` could update all instances, however, that doesn't seem like code a developer would write.
These might be sorted somewhere above `gis_operators` for similarity with the ordering in `spatialite/operations.py`.
This could be indented inside the `if conn.vendor` to avoid a redundant check.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
``` if conn.vendor == 'postgresql': conn.introspection.data_types_reverse.update({ ... if conn.connection is not None: ``` (register_type_handlers() also checks `conn.vendor == 'postgresql'` so that avoids that same check for the non-postgres case)
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
I've realized something about this - if, for whatever reason (perhaps custom subclassing??), multiple apps are installed that can introspect these types, if this pattern is copied it's the *last* app in `INSTALLED_APPS` that take precedence, even though the general rule with Django is apps earlier in `INSTALLED_APPS` take precedence. Idk if it's a huge issue though.
Good suggestion, updated.
This would be better styled as: ```python try: import MySQLdb except ImportError: pass else: # ... warnings.filterwarnings(...) ```
Need a trailing space here I think.
Although it's default, `TEXT` is also a supported format.
You can skip this check, as MySQL 5.5 is not supported anymore, and maybe it's better to move into a class-variable.
`NotSupportedError`, and please use single-quotes, and add a dot at the end.
I think the style is not to have a blank line between the feature-flags, except in the base-backend. Please also see the MySQL feature flag.
Adding hooks in `as_sql` in the different compilers to check whether the query should be executed or explained might be an option? I think it's necessary to do changes in those methods.
Trailing space in string not required.
I think it is worth just spewing it out as a complete text blob. Otherwise we would be adding specialised parsing which is not worth it for a textual output.
Trailing space in string not required.
Lose the `params` temporary and simplify: ```python prefix += ' (%s)' % ', '.join('%s %s' % i for i in extra.items()) ```
I queried whether we needed to validate `options` here, but the DB does it for us. e.g. Using `SUMMARY` on Postgres <10: ``` EXPLAIN (ANALYSE true, TIMING true, SUMMARY true) ... ERROR: unrecognized EXPLAIN option "summary" ``` The error message is clear enough.
Oops. I think you meant to put the space to the _**right**_ of the quote!
Use hanging indent and remove temporary variable: ```python result.append(self.connection.ops.explain_query_prefix( self.query.explain_format, **self.query.explain_options )) ```
`**kwargs` → `**options`
`output_format` → `format` `**kwargs` → `**options`
`output_format` → `format` `**kwargs` → `**options`
`output_format` → `format` `**kwargs` → `**options`
`TRADITIONAl` → `TRADITIONAL` (You let go of your shift key too early!) Perhaps reword to `# Add TEXT as an alias of TRADITIONAL for consistency with other backends.`
~~Worse is that this is potentially vulnerable to SQL injection attacks as `value` could be user-provided input...~~ Just seen that options are converted to `'true'` or `'false'` above (which works as all options are currently booleans).
I'd change `TRADITIONAL` to `TEXT` here as we are now implicitly converting `TEXT` to `TRADITIONAL` in your latest change to `explain_query_prefix()` for MySQL. `TRADITIONAL` is just a formatted text-based output in MySQL, and a silly name. I think it is better to provide a more sensible and consistent name for Django to use.
Something like this comes to mind: ```python with transaction.atomic(): transaction.set_rollback(True) print(queryset.explain(analyze=True)) ```
Yeah. There are quite a few, and this is anything but standard across backends. The advantage is being able to access all of this information without needing to pop out to the database shell and restricting the flags may cripple the use of this feature for some. Adding support via kwargs sounds sensible. The irritation may be determining the default state of the various flags based on the value of `verbose`. So it may be easier to keep the interface simple and just "enable all the things" if `verbose` is `True`, where they are not costly in terms of execution time, and then provide `analyze` separately in kwargs.
Does this mean that support for this is limited to `SELECT` statements? - PostgreSQL supports `SELECT`, `INSERT`, `UPDATE`, `DELETE`, and others that are irrelevant to Django... - MySQL support `SELECT`, `INSERT`, `UPDATE`, `DELETE`, `REPLACE`.
Sort these formats alphabetically.
Move the leading period to the initial definition of `msg`.
Is this condition necessary? Surely all backends will support a default `TEXT` format? (Even if it can't be explicitly provided in the query...)
Chop "we" per our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Would `None` be more semantic than an empty string? Then `supports_explaining_query_execution` could check `is not None`.
Best to be conservative and error rather than silently swallow mistyped arguments :) I think `ValueError` or `TypeError` are more appropriate, they're normally used for argument validation.
no need to pass `options` up since they are all being consumed here
What about erroring if `options` is non-empty at this point? Subclasses should have already consumed their arguments from it, and if there's anything left it's probably a mistake, like `explain(formatt='json')`
{0} -> {} (I prefer the less verbose %s, actually) recognised -> recognized
Hanging indent please, and it should be possible to remove the temporary `prefix`.
In the current implementation if ``supported_formats`` evaluates to ``False``, then there would be a trailing space at the end of the error message. Probably it would be better to remove it from this string and add it to the string below: ``` msg += ' Allowed formats: {0}'.format(', '.join(supported_formats)) ```
has a limited
This is only the case if a pattern name is passed in, and the result of `reverse()` is returned, other urls are returned as-is.
`self.__dict__.copy()` is more explicit also it looks like `obj_dict` is the 'standard' name for `self.__dict__.copy()` in django `__getstate__` methods.
you can just `del` it instead, it will then fall back to the class level attribute, and save space on pickled state objects
"cannot" is one word. Also, add a period.
Clarify 'we', if possible.
".. on pop so that get_default() isn't evaluated and then not used (#12057)."
Probably , "We rely on this, so don't change the order without changing the logic." can be removed or else just say, "Don't change the order without changing the logic."
`num_fields` / `num_args` seems more natural.
This could become: `# IndexError error is used for historical reasons.`
I would use `if kwargs:` and swap the branches unless you see a reason not to. In that case "# Slower, kwargs-ready version." may not be needed.
If a related instance was passed, set it...
You'll want to make sure this is in `FORWARD_PROPERTIES` so `_expire_cache` clears it up.
single quotes, I guess.
The master branch supports Python 3 only so there shouldn't be a need to use six.
@rmtobin are you referring to the unpickling logic of `ModelBase`? Are `models.Model` subclasses even pickleable if they haven't been discovered/loaded yet? What I'm saying is that doing the following and removing the `copyreg.pickle` stuff should just work? ```python if attached_to: class_dict['__qualname__'] = '%s.%s' % (attached_to.__qualname__, name) ```
Prefer `assertIs` in this case.
Not sure if it's safe to do that as it creates a circular reference between `model` and the class. What about setting `__qualname__` directly instead by generating it from `'%s.%s' % (attached_to.__qualname__, name)`.
Hanging indent looks like this: ``` msg = ( "Filtered relation 'alice_favourite_books' cannot operate on " "foreign key 'author__favourite_books__author'." ) ``` In general, indentation should always be a multiple of four.
The blank lines in this method aren't needed.
wo -> without
No need for `keys()` here.
I think tests for `filtered_relation` and `GenericRelation` are missing. I don't see any failures if this is changed to `filtered_relation=None`.
No need for `keys()` here.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
An alternative is to make the signature `__init__(self, relation_name, *, condition=Q())` to force passing the `Q` as a kwarg. This could be advantageous if more kwargs are added later.
`)` onto the next line.
I think the `lambda` could go on this line.
Last `)` on the next line.
You turned the arguments into keyword arguments in one other place. Could you also do this here and below? I don't know if it makes sense to also do this in the tests.
I overlook this myself, but hanging indent, please.
btw `reversed(x)` doesn't actually iterate the whole list in reverse in python 3, you just get a `list_reverseiterator`... ``` In [1]: reversed([1]) Out[1]: <list_reverseiterator at 0x105098b70> ``` :)
fair enough, I guess I'm just a bit too obsessed with optimization :)
the `reversed` call isn't free, it's slightly more optimal to put the wrappers in the list in the way you want to iterate them
`{'connection': self.db, 'cursor': self}` is faster and imo clearer. `dict(foo=bar)` actually goes through two dict creation steps: first it creates the keyword args dict, then it finds the global name 'dict' (which could refer to anything), then it calls that name which creates the final dict.
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
It would be more readable to pass boolean arguments as keywords, e.g. `many=False`.
``` # executemany() must use an update query. Make sure it does nothing # by putting a false condition in the WHERE clause. ```
🦅 eagle eye award
It doesn’t feel right to me to just silently drop things. I think it’s better to fall back to pulling the filesystem in this scenario.
I’m not comfortable with how this is calculated. There ought to be a better way to handle this, e.g. by inspecting `sys.path` for common ancestors.
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
I think `*args, **kwargs` are unexpected.
Move the first two lines out of the context manager so it's more clear which line is raising the exception.
Is this refactoring a needed part of this patch? Can in be done in a separate commit that precedes the bug fix? I see that at least the `process_request()` additions have to be in the fix.
I'd use a more specific name and/or docstring that describes what's special about this error handler to trigger the regression since I could imagine future tests may want to use error handlers that have different features. Similar for the `urls.py` and test naming and/or docstring.
Unrelated, but perhaps the default kwarg should be `exclude=()` to allow removing the `exclude is not None` check.
maybe better to just do `if connection_alias not in connections` ? This feels like it's jumping some encapsulation. Could also be done in `register_type_handlers` to avoid duplication
You can change it in a separate commit in the same PR.
Is there a difference between using `BaseDatabaseOperations(connection=connection)` and `connection.ops`? I guess we should use one style consistently.
Nicer would be: ``` expected = ( " geom..." "\n" ) ```
`self.assertSequenceEqual(trans_real.parse_accept_lang_header(value), expected)` (switch order)
`with self.subTest(value=value):` is sufficient -- if a test fails, `expected` will appear in the exception.
At least it isn't `None`, which would have been a security vulnerability ;-)
Could you switch this around so it's `value, expected` -- that's consistent with other tests.
Having child class initialization delete parent attributes won't fly. What if your parent has two children ```python class A(models.Model): foo = True class B(A): foo = models.TextField() class C(A): pass assert C.foo # AttributeError. ```
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
I would use `%s` formatting consistently.
``` When the object has a ManyToManyField to Site, redirect to the current site only if it's attached to the object.
Is there a need to hardcode pks? This is generally to be avoided, I think.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
`expected_url` is more consistent with naming elsewhere. Also, I would use `%s` formatting consistently rather than `format()`.
I'd omit the `shortcut_url` variable and put this directly in the `get()`.
I'm not sure if waiting until `save()` is the best approach. Wouldn't you expect this assertion to pass after the `reporter_id` assignment and before the save? `self.assertEqual(self.a.reporter, self.r2)`
Use `assertIs(..., False)` to check for boolean attributes.
I'm not sure that a separate test class is needed.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
this doesn't look right
We generally try to describe the issue sufficient so that a ticket reference isn't needed.
`.keys()` can be removed throughout ala 21046e77734278cea871dce922220bf29aa5b7b4.
This message should be updated also in `migrate` command.
Are we considering defaulting to using utf8mb4 for the connection? I wonder if it would make sense just to assume 191 if mysql_version < (5, 7, 7) and 767 if newer.
Yeah, thinking about it more, I think either approach makes sense.
Don't take my remark as a blocker, it was just a check that this wasn't an oversight.
This is only used once, so I don't see why it needs to be a method.
omit the blank line
Yes, or whatever minimal test is needed for the change.
Only change your own code, please. We don't like to mix unrelated cleanups with bug fixes.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
More descriptive test names would be welcome. The existing names are merely from a big test refactoring.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
It might be better to describe how ISO-8601 or give a reference. I'm not sure that the example helps much. I think a description for `ExtractIsoYear` should be added to the docs as well.
Oracle restricts the number of parameters in a query.
Please add `urls.W004` to the `ref/checks.txt`.
I think we should return a list of all warnings, e.g.: ```python def check(self): warnings = self._check_pattern_startswith_slash() if self._route.startswith('^') or self._route.endswith('$'): warnings.append(Warning(...)) return warnings ```
Please use single quotes.
Dot is missing _"... for Django 2.x."_.
The test won't run if it's in the database router.
Please use the indentation style of `co_mapping`. If someone were to fine an autoformatter that could fix the `inter_mapping` style throughout Django (it's rare), that would be nice.
argument ordering should be reversed
I don't see any test failures with that change so it seems fine.
If you do the unrelated alignments, please push them in a separate PR.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
I'm not sure what you mean.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
I'd use `.objects.create()`
You can omit `for_tag_` in the test name. Having it on every test name in the class seems silly.
Add trailing comma please. Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Use single quotes please.
on_conflict_suffix_sql? When I see "postfix" I think of a mail server.
`assertRaisesMessage()` (this test is broken) as it doesn't pass` on_conflict='ignore'`.
I don't see a strong argument for accepting case-insensitively.
As the Python `urlencode()` already handles scalars, I think this could be slightly simplified to: ```py if isinstance(value, (list, tuple)): query_val = [ item if isinstance(item, bytes) else str(item) for item in value ] else: query_val = value ```
Missing a test that fails if ` and not doseq` is removed here.
I'd use "get" instead of "prepare".
It would clear ambiguity if you added some parentheses here and on the next line: `(' LIMIT %d' % limit) if limit ...`. Initially, I thought the grouping was `% (limit if limit else '')`.
Usually we don't repeat the docstring from the base class.
Please rebase your branch on master and remove `http.` after 0e212a705e6b2e49a246b16286036c40ec2ac4f8.
I don't think the number of tests is an issue, but since the check depends on a variable, the test should also reflect this, or it'll break at some point.
`date=rfc850date` isn't needed in the `subTest()` -- since will appear if the assertion fails.
Don't include `date=rfc850date` in the `subTest()`. That string will already be displayed if the assertion fails.
`transform.lookup_name` isn't needed (same in unregister)
I think this pattern is more readable: ``` tests = ( (LTrim, 'John '), ... ) for transform, trimmed_name in tests: ```
Maybe `Ntile`, but I can't figure out what it stands for...
Can they be named LTrim, RTrim, LStrip, RStrip? I don't think we ever have lowercase words ("trim", "strip") in class names. Admittedly they are classes that are used more like functions, but the same is true for all the existing ones.
I've suggested https://github.com/django/django/pull/9232 to avoid redundant `version_info` in Django.
If it doesn't provide any useful functionality, I'd omit it.
Dict literals are preferred (0d74c41981687598d3fa0a7eb9712ce4c387ca19).
A test is missing for this change.
Is `test_doesnt_work_with_init_subclass` meant to test this change? I still don't see any test failures if this change is reverted.
I think "comparison.py" is fine.
While moving this, chop "we".
"Postgres'" looks odd to me. Use "PostgreSQL's" instead.
Sure, just wanted to be clear
drop 'this will" / "it will"
Should be `application/json`
I'd drop that last line since it doesn't really escape according to the rules suggested there.
Please add a trailing comma.
Typo in both test names: `relatedobjectcoesnotexist` -> `relatedobjectdoesnotexist`
How about `An incorrect implementation of get_queryset.`
Collapse to `elif`
You don't really need a docstring at all, IMO. The test itself explains it well enough.
maybe `AuthorListInvalidGetQueryset` would be clearer
Perhaps be explicit and return `None` here.
Also rephrase to a single sentence to avoid mentioning `QuerySet` twice.
Not sure whether this is the right exception - should be `TypeError`.
`QuerySet` instead of `queryset` for all instances of it in this exception message.
the indentation on this line is incorrect - I'm not sure why pep8 didn't catch this :(
Python functions implicitly return `None` if return is not called. I feel being explicit is better for a test.
Fair enough if there is precedence for it. I thought `ImproperlyConfigured` was usually used for settings or something affected by a setting being incorrect.
How about: ``` if self.nulls_first or self.nulls_last: self.nulls_first = not self.nulls_first self.nulls_last = not self.nulls_last ```
Please have a look at https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
Much clearer, thanks!
```suggestion raise self.exception_class(f'The connection {alias!r} doesn't exist.') ```
I presume it was intentional to change this to `.update()` so that `self._settings` is modified? I expect that could just do this instead: ```python databases[DEFAULT_DB_ALIAS] = {'ENGINE': 'django.db.backends.dummy'}
Again, I suspect we could use `__slots__` here: ```suggestion __slots__ = ('_connections', '_settings') ```
```suggestion raise NotImplementedError('Subclasses must implement create_connection().') ```
```suggestion msg = 'Subclasses must implement create_connection().' ```
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
This came from the connection proxy for the cache connections -- for checking whether a key is in the cache -- and isn't really applicable to the database connections. I'm not sure that's a problem though -- it'll just complain that the connection is not iterable... This is just an observation.
Do we want to use `__slots__` to keep this as thin a layer as possible as it'll probably never have anything else added? ```suggestion __slots__ = ('_alias', '_connections') def __init__(self, connections, alias): super().__setattr__('_connections', connections) super().__setattr__('_alias', alias) ```
I think we can safely remove this. It was overlooked in the post-deprecation removal of `django.core.cache.get_cache()` in d038c547b5. We should do that in a separate commit w/ `Refs #21012 -- ...`.
```suggestion raise self.exception_class(f'The connection {alias!r} doesn't exist.') ```
```suggestion raise self.exception_class(f'The connection {alias!r} doesn't exist.') ```
That's fair, the number of these created should be quite limited.
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
Pushed to a separate PR #13753.
```suggestion params = self.settings[alias].copy() ```
I think we should use `self.exception_class` in the `ConnectionHandler` and keep this import only for backwards compatibility.
... and if can, we should do this in advance.
Handlers are not frequently created and can be monkey-patched so I don't think we should use `__slots__` here, see ticket-12826.
I think it's fine to leave it.
For consistency, use a tuple instead of a list.
Use a more descriptive name? Looks like this would fit on a single line.
Drop the docstring I think,
``` is_multipart = context['adminform'].form.is_multipart() or any( admin_formset.formset.form().is_multipart() for admin_formset in context['inline_admin_formsets'] ) ```
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
How about adding `self.assertIs(response.context['is_multipart'], True)` before the `assertContains()` (since those can be difficult to debug)? (Might be worth adding a similar assertion somewhere for the False case.)
Right, so that if the `assertContains()` ever changes, the "not contains" version will also be updated.
I'd make `'enctype="multipart/form-data"'` a constant or class attribute to avoid typos since `assertNotContains` is fragile with respect to that.
Okay, then I think you could skip the `is_multipart` variable and put the calculation directly in the dict.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
this is probably cleaner as one line
And I'd put the actual method after `_check_unique_together` too, to match the order above :)
no `, ` in def of `fields`
on second read, could be a set so the `not in` check below is slightly faster - just swap `[]` for `{}`
I'd put this after `_check_unique_together` here, so it's grouped with the other callers of `_check_local_fields`
so i think it would be better if there were actual nested for-loops: ```py for index in cls._meta.indexes: for name, order in index.fields_orders: # avoid the '-' logic in the check, it's already done in Index.__init__ ``` and if we used `obj=index` then the message should be clearer as it shows which index is referred to
this doesn't need a separate test class, insert the test after `test_name_contains_double_underscores` which tests E024
Please use single quote.
Misspelling -- should be `test_default_defer_fields`
Misspelling -- throughout this pull request, this should be `defer_fields` instead of `deffer_fields`.
Has `refresh_from_db` ever worked properly? From my personal experience we found the built in function buggy. We tend to just reload via `Model.objects.get(id=old_object.id)` in our code.
I'd make the message (with a placeholder for the key) a module constant so it's not repeated.
I see your point and can't think of anything sensible either. Assertion-less tests just seem pointless other than to put a tick in the coverage box.
I'd use `return []` for the initial commit and have a separate commit that does the method removals as that's really a separate issue that's less needed for a backport to 2.0.
Use the more succinct `a.upper is None or a.upper > b`
I don't know if this is the best solution. It seems to add overhead (extra iteration) for a problem that's only present on PostgreSQL.
Not sure that's needed (it's the implicit default) -- anyway, as noted above, it's never executed.
According to the coverage report, this always evaluates to True.
This could be a single line: [...]
This is never executed.
This should be wrapped at 79 characters.
This might be able to fit on a single line after updating it, otherwise use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). (Also, need a test that fails if this change is reverted).
There still isn't a test that fails with this change reverted.
I think the original PR was only intended to work with `django.urls.path` (which the only part that uses `RoutePattern` and its `_route` attribute. With your edits, it seems the improvement has a broader scope and does not need this anymore.
hmm, I think we should also be recursing on the `sub_match.route` here :thinking:
I don't think adding this makes sense. Perhaps similar logic to the migration consistency check could be used.
If the columns list is limited, ...
I think that leading and trailing `"` is missing, i.e. `'"%s"."%s"' % (namespace, table_name)`.
I'd use `namespace, table_name` instead of string indexing. (or _ instead of namespace if unused variable names is a problem with the first suggestion).
It could be useful to give an example in the docstring of what "identifier" might be.
should be -> are
The signal approach would hopefully eliminate the need to call `reload()` manually.
Yes, this code looks a bit suspicious. Perhaps a signal handler that listens for `setting_changed` might be appropriate.
I'm a bit worried about this `reload()` with overridden settings to trigger the `UserCreationForm` to be recreated with a custom model. It obviously works for this test case, but I think it will leave the customised `UserCreationForm` loaded at the end of the test, won't it? Doesn't this mean that we will potentially have dependencies between this test and other ones that also use the `UserCreationForm`? If so, I think we should find a way to do a `reload()` at the end of the test (in `tearDown()`?) after the settings have been put back to the default.
You could add "until #28670" to that sentence.
You lost a ] in here.
Hah. You just got ahead of me!
Tests are failing because you dropped the `]`.
Still, I wonder if so many tests are needed. I think it would be enough to have one test for ForwardManyToOneDescriptor and ReverseOneToOneDescriptor. In other words, every place that the descriptor is called doesn't need to be tested. Testing the each descriptor once is enough, I think. Please use the context manager version of assertRaisesMessage and follow the style of similar assertions in this file.
I'll investigate this later.
I see. I guess I would like to understand the test failure a bit better -- what's causing the cross database relation in the first place. I see it's something to do with content types and permissions (probably unrelated to what's being tested here).
good point, this avoids my laziness on the ticket :)
this now generates invalidate SQL if both assignments happen: ``` chainz@localhost [7]> set session transaction isolation level read committed, sql_auto_is_null = 0; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'sql_auto_is_null = 0' at line 1 chainz@localhost [8]> ``` Instead we should generate two statements, they can be sent as a single sql string to avoid roundtrips though by using a `;` delim: ``` chainz@localhost [8]> set session transaction isolation level read committed; set sql_auto_is_null = 0; Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec) chainz@localhost [9]> ```
The tests are failing with: ``` + flake8 ./django/core/management/__init__.py:320:16: F821 undefined name 'ModuleNotFoundError' ``` and rightly so. I think the exception is removed in Python 3 from what I can see on Google.
Just checked, it's safe to only catch `ImportError` as `ModuleNotFoundError` is a subclass of it: https://docs.python.org/3/library/exceptions.html#ModuleNotFoundError
so it turns out using `mock.patch.dict` isn't necessary, because `run_django_admin` is actually setting up `os.environ` for the sub-command. so you can refactor this test to just: ```py out, err = self.run_django_admin(['startproject'], 'bad_settings') self.assertOutput(err, "You must provide a project name", regex=True) ```
suggestion: "commands that don't need settings succeed if settings file doesn't exist"
Please include the entire message.
Maybe using single quote is more compatible.
I think we prefer a different indentation style in docstrings, i.e.: ```python """ A Q object with an empty condition should be rejected as the conditional expression in a Case(). """ ```
technically your test only needs to do: `When(Q(), then=Value(True))` :) The queryset isn't even being constructed as the exception is happening before.
`max_age` is not being passed into `signing.loads()`, nor is `self.serializer`. `session_dict` should be `session_data`.
Is the method necessary for this? If it can't be a class attribute then make it a property.
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
Why the method for this? Just make it a class attribute called `salt`.
Positional arguments cannot follow keyword arguments.
`from django.core import signing`
No need to check for `bits.scheme` and `bits.netloc` again as this block is fenced by `if not (bits.scheme and bits.netloc)`
`if (bits.path.startswith('/') and not bits.scheme and not bits.netloc and '/./' not in bits.path and '/../' not in bits.path):` Could potentially be rewritten to (but will probably make it slower, defeating the purpose of this PR): ``` path_bits = bits.path.split('/') if (path_bits[0] == '' and not {'.', '..'}.intersection(path_bits)): ```
The wording *I* would use is probably `Handle the common case: If the location ...` as the suggestion is that a) it happens far more frequently b) its not the pathological case (being the one which calls `urljoin`, now) I'm not going to endlessly bikeshed over it. It's basically fine and does its job as is.
Does `current one` means *scheme relative* or *host relative* here? Looking at the test, I think its the latter, but I'd originally guessed the former.
The trivial case is now less trivial, with this change :) [I get the jist of what you're saying, though]
This check doesn't catch a location that ends with `/.` or `/..`
I don't get this, if location is `//foo` then `bits.netloc` will be `foo`. The only way to get here is if location is prefixed by 4 (or more) forward slashes i.e. `////foo` or `/////foo` etc. which seems like uncommon input and should probably just be handled by `urljoin`
Maybe should use "multi-table inheritance" instead of MTI as I noticed the acronym isn't used much.
Thanks for investigating, so simply raising `exc_info[1]` seems the way to go, unless some test can demonstrate the opposite.
Yes, I remember `raise` vs. `raise e` being a point of confusion in the past. If it's just `raise`, then lines 3-4 below are omitted in the traceback: ``` File "/home/tim/code/django/django/db/models/query.py", line 489, in get_or_create return self._create_object_from_params(lookup, params) File "/home/tim/code/django/django/db/models/query.py", line 528, in _create_object_from_params raise e File "/home/tim/code/django/django/db/models/query.py", line 521, in _create_object_from_params obj = self.create(**params) ``` It could possibly be unclear without those lines, but I'm not sure if it matters.
I don't think the explicit `raise e` is required on Python 3.5+. ```python (tmp-70aba34da671918e) ➜ tmp-70aba34da671918e ipython Python 3.5.2 (default, Sep 17 2016, 14:04:19) Type 'copyright', 'credits' or 'license' for more information IPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: def func(): ...: try: ...: raise KeyError('foo') ...: except KeyError: ...: try: ...: raise Exception('test') ...: except Exception: ...: pass ...: raise ...: In [2]: func() --------------------------------------------------------------------------- KeyError Traceback (most recent call last) <ipython-input-2-bd1982955a12> in <module>() ----> 1 func() <ipython-input-1-e80913097bf5> in func() 1 def func(): 2 try: ----> 3 raise KeyError('foo') 4 except KeyError: 5 try: KeyError: 'foo' ```
Makes sense, let's stick with `raise e`.
I believe you can move this import to the top of the module. Doing so does not cause any tests to fail for me.
For verifying booleans, `assertIs` is preferred. From the [unittest docs](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertTrue) > Note that [`assertTrue`] is equivalent to bool(expr) is True and not to expr is True (use assertIs(expr, True) for the latter). ```py self.assertIs(is_safe_url(url), expected_answer) ``` In other words, `is_safe_url()` is expected to return the object `True`, not just something equal to `True`.
Thanks for checking the usage elsewhere. If the same pattern exists elsewhere (you're right, it does), then its needlessly pedantic of me. It's fine as is.
I don't think we should deprecate it until we drop support for PostGIS 2.3.
The problem is that when people get the deprecation warning, they are supposed to update their code to be the most up-to-date as possible. Then, if they are on PostGIS >= 2.4, they will render their code incompatible with PostGIS < 2.4 systems without noticing. And if they are on PostGIS < 2.4, they will obtain a runtime error when talking to the database.
If that works that way, then sorry, I'm taking back my reservation.
I thought the change in `postgis/operations.py` is meant to alias `ForcePolygonCW` to `ST_ForceRHR` on older PostGIS versions to avoid the problem you described.
Use single quotes consistently.
Use single quote consistently.
Could we just use `elif value is None or value == ''` here? As I can see, they have the same result.
I do't think these changes are needed, since the empty value can be handled by display_for_value function.
IMHO specifically this change worsen readability. Something like this might look better: ``` if app_labels: if len(app_labels) == 1: ... else: ... else: ... ```
Usually we've preferred list comprehensions as more readable than map.
ah, dont read me .. its mocked :) so I'm blind:)
Indeed, then `obj.tags = obj.tags.union(tags)`, it's a bit faster.
This has been mentioned previously, we can't do it because updating the set in place would update the inherited tags as well. e.g. ```python @tag('foo') class Foo: pass @tag('bar') class Bar(Foo) pass ``` Using `update` would add `'bar'` to `Foo.tags`.
@sir-sigurd this would update the parent tags as well.
> [...] So the system check error will only be raised if value is an iterable. Yeah so I was basically trying to figure out whether integer values (ie: `IntegerField() `with `choices`) etc were still supported, and the combo of boolean logics got me confused. All I've done is add noise, sorry.
should not b einterpreted as -> isn't
Can you put ``` except ValueError: # Containing non-pairs break ``` up here rather than nesting the next try block inside it? Tests are passing there but I'm not sure if `value, human_name = group_name, group_choices` might raise `ValueError`. Maybe a test case is missing there. If that exception is possible there, I'd opt for a separate try/except to avoid such a large one.
Wrap at 79 chars: ``` "'choices' must be an iterable containing (actual value, " "human readable name) tuples.", ```
add trailing comma
Use single quotes here.
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
I'm not sure if this was generated by your editor but please avoid cosmetic changes in such patches.
I guess the problem is that this crashed before the patch but perhaps an assertion like `self.assertForeignKeyExists()` would be the test look more complete.
Is it possible to use something from `connection.ops` or similar to avoid a vendor check? Otherwise, looks good.
With unpacking generalizations in Python 3.5 you don't need to concatenate the tuples: ```python .format(*REQUIRED_PYTHON, *HAS_PYTHON) ```
The usual convention is to put flags before positional arguments. Move `--upgrade` before the packages.
Oh yeah... That was silly of me :blush:
Also, doesn't this fail on Windows? Best use `python -m pip ...` to be safe...
It's not really a warning, given the user cannot continue.
I'm not sure "This should not have happened." adds much. Also, use 1 space between sentences.
The setuptools version is (in practice) not an issue: In the rare case that someone force a source-install (by using the `--no-binary`) flag, then pip will get the sdist, try to build it, which will fail on too-old setuptools. This is/was more of an issue for project like numpy, that do not have universal wheels, and thus for most linux users where pip would get the sdist (by default of not finding a compatible wheel). Now that there is the manylinux1, it not really an issue. And anyway django have an universal wheel. Python version check also happen before setuptools version matters, so users that have old setuptools may not even see that. So IMHO the setuptools is unnecessary. The only potential help is the correlation between setuptools version and python version, so Python 2 users are more likely to have an old setuptools. I can't judge how frequent this may be in the Django community.
This crashes: ``` Complete output from command python setup.py egg_info: Traceback (most recent call last): File "<string>", line 1, in <module> File "/tmp/pip-K04os1-build/setup.py", line 36, in <module> """.format('.'.join(REQUIRED_PYTHON), '.'.join(HAS_PYTHON))) TypeError: sequence item 0: expected string, int found ```
pip >= 9.0 and setuptools >= 24.2
running -> trying to install
I think it's required to quote 'django<2': ``` $ pip install django<2 bash: 2: No such file or directory ```
As I understand `python_requires` works only with pip >= 9, is this correct? If so I think it could happen because Python 3.4 users could have pip < 9.
Maybe `_` instead of `seq`, because it's unused.
I think this can be removed as it's now defined above.
I would consider tuple unpacking in the line before: `constraint_table, constraint_column = constraint['foreign_key']`.
A reason for the longer suffixes was to simplify inspectdb. Using different names would require mapping the names that PostgreSQL returns to whatever names we picked.
I see. Thanks @pope1ni and @timgraham
As above -- it seems somewhat useless to implement this test for every subclass. At the least, maybe there could be a base test class that implements some common tests if that's warranted.
I have been trying to think of cases where this could lead to an infinite loop and the following simplified scenario , while unlikely, could cause issue. ```python class A(Model): b = models.ForeignKey('B', CASCADE, primary_key=True) class B(Model): a = models.ForeignKey('A', CASCADE, primary_key=True) ``` Since this is going to be backported to a LTS I'd favor we rely on a memo to prevent this from happening just to be extra safe. ```python to_python_field = pk seen = set(to_python_field) while to_python_field.remote_field: to_python_field = to_python_field.target_field if to_python_field in seen: break seen.add(to_python_field)
@morganwahl yes please!
Unnecessary `()` wrapping I believe.
Just wanted to point out https://github.com/django/django/commit/770b9ea77fb5e39d616e62b54c06755e6d4f4d36 which was committed recently.
1. Given that we have `pylibmc` below, is `memcached` the right key here? 2. Given that there are choices here, is this something we want to have an opinion on? (It doesn't seem as clear to me as e.g. databases.)
Perhaps `.message()` could be done on the previous line after the ) since the `email` variable is otherwise unused.
I think a docstring would be useful.
This test is passing without any changes.
I think so. Ideally in a separate commit.
Something like `test_header_omitted_for_no_to_recipients` may be more descriptive.
What if `self.to` is empty and `self.extra_headers` contains a `To` header? Weird use case, but still…
will be -> is
Maybe `_output_decimal_converter` to keep consistency of converters names.
Use `django.utils.timezone.make_aware` instead.
You can drop this assertion, the way `from_date` is constructed and that this branch is behind the `if day` one makes it impossible to reach.
I think we should protect this filter against invalid inputs from users, e.g.: ``` {}__year=a {}__year=0 {}__month=a {}__month=0 {}__month=13 {}__day=a {}__day=0 {}__day=32 ``` Currently it throws `ValueError` in most cases.
Yes, will fix it.
It should be `Decimal(1)`, not `Decimal(10)`, not sure why tests pass.
Did you consider `decimal.Decimal(1).scaleb(-abs(p))`? It seems that it could be faster when `p != 0`: ``` In [81]: %timeit decimal.Decimal(10) ** 0 347 ns ± 7.74 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [82]: %timeit decimal.Decimal(1).scaleb(0) 470 ns ± 3.89 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ``` ``` In [83]: %timeit decimal.Decimal(10) ** -1 661 ns ± 5.87 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [84]: %timeit decimal.Decimal(1).scaleb(-1) 481 ns ± 4.66 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
I think just `Ordering of query string parameters is ignored for distinct names. For example...`
This has been around since Django 1.0 (b3b71a0922334c70bbc646a4873010f808196671). I think the method should be fine to remove if Django no longer uses it. If we get complaints about it, we can add it back or start a deprecation.
Might want to join both branches now that they are mostly similar. ```python select_list = [] cols = self.query.default_cols or self.query.select for col in cols: select_list.append(select_idx) select.append((col, None)) select_idx += 1 klass_info = { 'model': self.query.model, 'select_fields': select_list, } ```
Test coverage lacking here? Don't see any failures with just `order_type = 'desc'`
Single line looks fine here. For consistency with other code, I'd pass`epoch_seconds` as an arg.
Remove blank line.
`# psycopg2 raises ValueError if a field contains NUL characters (0x00).`
This should also include the "Could not load .." part of the error message -- otherwise the test passes without the change.
Please change to single quote.
Please chop this blank line.
Please use `GLOBAL_PERMISSIONS` instead of `GLOBAL_PERMS` everywhere.
This doesn't look correct... Did you mean something like: ```python ctypes.add(None) searched_perms.extend((None, perm) for perm in getattr(settings, 'GLOBAL_PERMS', [])) ```
This is not testing the new functionality, merely that an arbitrary permission object created manually is accessible in the user's permissions.
``app_labem`` -> ``app_label``
Drop `on_delete=` for consistency with other code. I think the ForeignKey could be to 'self' to avoid the need for the other model.
This can just be `pass` since the functionality doesn't matter.
Add trailing comma.
"foreign key id" may not be the best wording. For example, this also applies to subclasses like OneToOneField.
It looks like should use `f.get_attname()` instead of rebuilding that here.
I guess this should be `cursor.fetchone()[0]` since in the "not installed" case, this is `(None,)` which evaluates to True.
Generally you have too many blank lines. Please try to follow the style of existing tests, and when in doubt, don't include a blank line.
This won't happen because the tests couldn't start running on PostGIS.
You can assume that PostGIS is enabled, otherwise, the tests won't run at all.
use `self.assertIs(..., False)` (`assertFalse` checks `bool(val) is False`)
0 is uneeded
While this duplicates, it seems like an improvement in readability since `j` is eliminated.
Should this be in a try/finally in case the assertion fails? I see some other test errors in that case.
an INSERT a RETURNING
@felixxm Are you picking these up by eye or linting the diff programatically? If the latter, can I ask your incantation? `flake8` comes out clean with the project config. Ta!
Please add trailing comma.
Please use single quotes.
Please use single quotes.
@carltongibson By eye, there is no black magic behind 😃 .
Please use single quotes.
@felixxm OK. Thanks. I will just continue to sharpen the nit-picker then 😃
Not sure we should be special case `replacement` direct string passing. We usually consider strings as field references in all the existing expressions. I wouldn't mind allowing `replacement` to be optional and defaulting to `Value('')` if it's missing though.
`George. R. R. Martin` → `George R. R. Martin` (Remove the extra period, and throughout below.)
Avoid calling `self.get_source_expressions()` twice and it becomes clearer: ```python ... expression1 = self.get_source_expressions()[0] if isinstance(expression1, Value) and expression1.value is None: raise ValueError('Oracle does not allow Value(None) for expression1.') ... ``` I've also tweaked the exception message to make it based on the argument provided in Python.
`acquire_lock` was added for internal usage in 6448dd833524ac3fc503506b624841c9d642de8a, so I don't see a need for a deprecation.
FYI, you can exclude filenames in github search - I find this very useful for excluding copies of Django code: https://github.com/search?utf8=%E2%9C%93&q=django.utils.synch+RWLock+-filename%3Alocmem.py+-filename%3Asynch.py+language%3APython&type=Code Two pages of usages in a few modules, not too much.
We use triple quotes for new docstrings.
Line 41. By the way, it would make the patch a bit easier to review and see what has changed if you didn't reorder methods (e.g. set is moved above _set) and delete above _discard). Perhaps the reordering could be done in a separate commit afterwards if it's needed.
I tried with 'Path' on the advanced search dialog but it didn't seem to allow inverse, thanks for showing me the right syntax @jarshwah one of the uses is actually in kogan/django-lrucache-backend 😉
I think maybe ```py dummy = object() def get(self, key, default=None, version=None, acquire_lock=dummy): if acquire_lock is not dummy: warnings.warn( ``` I still think this arg fits in the grey area for deprecation timeline, would like someone to weigh in e.g. @jarshwah
Ok thanks Tim
I take this back and have a deeper look at the tests.
You can remove semicolon.
Please use single quotes. You can use directly `out.getvalue()` instead of a temporary variable, e.g.: ```python self.assertNotIn('class InspectdbPeopleView(models.Model):', out.getvalue()) ```
Please use hanging indentation and capitalize `SQL` syntax, e.g.: ```python cursor.execute( 'CREATE VIEW inspectdb_people_view AS ' 'SELECT name FROM inspectdb_people' ) ```
Please remove the unnecessary trailing comma and space.
Please remove the unnecessary trailing comma and space.
I wouldn't transform the whole class to TransactionTestCase, but rather create a new class containing transaction-dependent tests. On some setups at least, TransactionTestCase is heavily slowering tests.
You don't have to initialize `out` twice. This line can be removed.
You risk getting this excerpt optimized like this: ``` if any(ti.name == table_name and ti.type == 'v' for ti in connection.introspection.get_table_list(cursor)): constraints = {} else: raise e ``` (or similar, modulo indentation) by our idiomatic code wizards :smile: . See e.g. #9493 and #9532
Add a space after comma: `SELECT sql, type...`.
@ramiro .. and `else` is unnecessary :smile:
IMO we can omit catching this exception.
Django supports GEOS 3.4+ (docs/ref/contrib/gis/install/geolibs.txt), so this isn't needed.
Please try to follow the style of existing docstrings -- we don't want all the type annotation stuff.
Single line looks okay here, in the next test and in the assertEqual of the test.
It might be useful to continue allow passing `None`. That feels a bit more natural to me than passing `set()`.
Both `with` should fit on the same line, `with self.subTest(value=value), self.assertRaisesMessage(ValidationError, "'Enter a number.'"):`
I'm not really sure this docstring is necessary as the implementation is obvious.
Move this `# math` section above `# text` to keep sorted in the same fashion as the imports.
I think it can fit on one line.
Due to hanging indent, `).first()` should be on the next line.
Any case where the method raises a `TypeError` which is not caused by the missing argument
This seems overly simplistic, we should at least be sure to the extend that we should check the signature of the function on whether or not it supports more than two arguments.
The classes should be sorted alphabetically in the file.
These should be sorted alphabetically, i.e., `'Chr', 'Concat' ...` and wrapped at 79 chars.
You can ditch the temporary variable, and just the arguments directly `__init__`.
I've also noticed a warning in Pycharm that the signature of `as_sqlite` and `as_oracle` doesn't match the superclass. I'd guess it's better to deal with this in a different PR.
This should always be the case when you have `arity` set.
As far as I see, this change is unrelated to this PR, so please remove it.
I'd suggest a `ValueError` instead. And this requires also a test. You can see what `Substr` does.
`Abs` is already proposed in #9577.
I'd add a docstring along the lines of "verify that a valid query is generated when fields fetched from joined tables include FKs whose names only differ by case"
either that or leave the attribute name alone and define a `db_column='CaTeGoRy'` to put more emphasis on it.
The coding guidelines suggest to omit prefixes like "Verify that" since all tests verify things, otherwise the patch looks fine.
Actually I think the test with `db_column='CaTeGoRy'` is a slightly different test, and one we may want to include as well.
I don't think so
Given what you've said, I think we can't use the checks framework
`)` on new line
Should this not raise a `ImproperlyConfigured` error, as it's down to a user configuration error? That's what we raise in the cases above this.
You're writing to the database. You need those changes to be reset. You need to be using Django's `TestCase`, rather than `unittest.TestCase`.
You have a spelling error here. It's `DATABASES`. Even if you correct that, this would raise a warning: ``` tests/settings_tests/tests.py:472: UserWarning: Overriding setting DATABASES can lead to unexpected behavior. with override_settings(DATABASES=databases): ``` I'm not at all sure you can use this here. At the very least it would need to decorate the test method (or whole test case), but the databases are set up at the beginning of the test run, so instead of using `override_settings` I think you will need to declare a new alias just to serve as the mirror here.
Since this only works for instances with an pk, do you think that `bulk_update` would be a better name? The regular `save()` method can either create or update depending on pk status which may confuse users here.
When referring to `bulk_save()` in messages, include parenthesis (and periods).
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Separate rename: I think `fields` -> `update_fields` to keep in-line with `Model.save()` is probably good for sanity
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
@raphaelm This line is correct. We use `pk` twice for each object, once in a `WHEN id = ... THEN` clause and once in a `WHERE id IN (...)` clause to filter rows for update.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Do we need to call `list(fields)` here? :thinking:
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Oh yes, there definitely was some confusion. When looking at the code, I saw references to `obj.pk` and thought we were potentially dealing with a QuerySet (which I guess that _technically_ we _could_ be, but that wouldn't be the right way to use it). My apologies! Carry on. 😋
keep in mind new_ids could be smaller than objs, messing up index order so intermediate_values won't match up, right? Also, new_ids is a _set_, so order is lost.
We should check to be sure len(intermediate_values) == len(objs).
`self.assertEqual(Model._meta.get_field('field').check(), [])` is fine.
It's fine to put this all on one line (same with common/others in the next test).
I haven't had time to look, but we should see what additional arguments `ROUND()` can take in different backends.
Could you also change this line for me? ```diff - Cast(expression, FloatField()) if not isinstance(expression.output_field, FloatField) + Cast(expression, FloatField()) if isinstance(expression.output_field, IntegerField) ``` Don't forget to import `IntegerField`.
I'm not sure why the change I suggested to add `ATan2.as_sqlite()` targeting SpatiaLite >= 4.3.0 resolved this issue for me locally and not on Jenkins. Could you confirm the version of SpatiaLite on the xenial and bionic boxes, @timgraham? (Maybe a build just needs to be re-triggered.)
Sorry - I could have done this more cleanly: ```python if not getattr(connection.ops, 'spatialite', False) or connection.ops.spatial_version < (4, 3, 0): return self.as_sql(compiler, connection) ```
Sorry - I should clarify - the tests were failing for float and decimal. This was fixed by inverting the order of the arguments, but that caused integer to fail: ``` ====================================================================== FAIL: test_integer (db_functions.math.test_atan2.ATan2Tests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/usr/lib/python3.6/unittest/case.py", line 59, in testPartExecutor yield File "/usr/lib/python3.6/unittest/case.py", line 605, in run testMethod() File "/home/nick/Sources/django/tests/db_functions/math/test_atan2.py", line 32, in test_integer self.assertAlmostEqual(obj.atan2_sn, math.atan2(obj.small, obj.normal)) File "/usr/lib/python3.6/unittest/case.py", line 878, in assertAlmostEqual raise self.failureException(msg) AssertionError: 1.5707963267948966 != 0.0 within 7 places ``` Casting the arguments to float seemed to then make the integer test pass. If somebody else could scrutinise my suggested fix, that would be great.
Please import `FloatField` directly instead of the `fields` module.
Not needed due to `arity`.
Please remove, it's redundant.
Please try to follow the indentation style. Same goes for blank lines between the function definitions.
Should be lowercase.
This is clunky - the extra function, assignments, unnecessary casting to `float()`. Regardless, this will not work. What if the source expression is `Value(5.5)` or some other complex expression? I think this is what you are looking for: ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='((%%(expressions)s) * %s / 180)' % math.pi) ```
```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template=str(math.pi)) ```
```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='((%%(expressions)s) * 180 / %s)' % math.pi) ```
Argh. Thanks :man_facepalming:
`DEGREES` doesn't exist on Oracle.
`RADIANS` doesn't exist on Oracle.
`PI` doesn't exist on Oracle. It is a constant, therefore we can use `math.pi`.
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
`Cot.__init__()` is unnecessary.
You're right :+1:. I missed that.
`COT` doesn't exist on Oracle, please emulate it by `1 / TAN(%s)`.
You should use the `CEIL` function instead of `CEILING` on Oracle.
I think `Sqrt` needs `output_field = fields.FloatField()`.
IMO it works exactly the same way in [Oracle](https://docs.oracle.com/database/121/SQLRF/functions169.htm#SQLRF00698) and [MySQL](https://dev.mysql.com/doc/refman/5.7/en/mathematical-functions.html#function_round) database, am I missing sth? 🤔
`FloatField` can be imported from `django.db.models`, so merge with the line above.
I meant: `from django.db.models import FloatField, Func, Transform`
Maybe it could be generalized by always passing the explicit argument `D` to 0, if not called differently.
This looks as though it works, but we can make it much more straightforward: ```python def as_postgresql(self, compiler, connection): # Cast FloatField to DecimalField as PostgreSQL doesn't support # MOD(double precision, double precision) by default. clone = self.copy() clone.set_source_expressions([ Cast(expression, DecimalField()) if isinstance(expression.output_field, FloatField) else expression for expression in clone.get_source_expressions() ]) return clone.as_sql(compiler, connection) ``` The other issue is that your implementation was basing the decision to cast on the `output_field` of this function and not the input source expressions which may be different.
This looks as though it works, but we can make it much more straightforward: ```python def as_postgresql(self, compiler, connection): # Cast FloatField to DecimalField as PostgreSQL doesn't support # LOG(double precision, double precision) by default. clone = self.copy() clone.set_source_expressions([ Cast(expression, DecimalField()) if isinstance(expression.output_field, FloatField) else expression for expression in clone.get_source_expressions() ]) return clone.as_sql(compiler, connection) ``` The other issue is that your implementation was basing the decision to cast on the `output_field` of this function and not the input source expressions which may be different.
`from django.db.models.functions import Cast`
no blank line please
OK, so this is the worry. We're adding `copy_for_child()` API here.
These settings should be defined per-`DATABASES` entry and not as top level settings. e.g. ```python DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'NAME': 'mydatabase', 'USER': 'mydatabaseuser', 'PASSWORD': 'mypassword', 'HOST': '127.0.0.1', 'PORT': '5432', 'ATOMIC_REQUESTS': True, 'AUTOCOMMIT': True, } } ```
@ziima OK That's fine. Thanks. I created a new ticket for the (query) logic error here. https://code.djangoproject.com/ticket/29089
Do you mean a comprehension, @auvipy? That would only be making a shallow copy, which `dict()` does above. However, I'd suggest `credentials.copy()` as it is more explicit.
What about using keyword-only args? ```python def __init__(self, *, json_encoder=DjangoJSONEncoder, **defaults): ```
Same as above use keyword-only args ```python def __init__(self, enforce_csrf_checks=False, *, json_encoder=DjangoJSONEncoder, **defaults): ```
Try refactoring the tests to using a loop and subTest and it doesn't look nice to duplicate so much code..
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
@NDevox I'd be very happy for you to do that. 🙂 (If it's just a single file cleanup, you can just make a PR, without the Trac ticket)
This and the few following cleanups are strictly unrelated to this patch. Presumably, they're here because of the feedback for similar items on #9636. There are lots of inconsistencies left in this file, around both docstrings and formatting of simple (e.g.) `post_data` dicts. Despite being strictly unrelated, I'm inclined to leave these few changes as they are here, and include them.
We use CamelCase for assert methods to follow `unittest` convention, e.g. `assertJSONResponse`. Maybe it will be better to pass `method` and `data` instead of `response`, e.g.: ```python def assertJSONResponse(method, data, method_name): response = method('/json_view/', data, content_type=JSON_CONTENT) self.assertEqual(response.status_code, 200) self.assertEqual(response.context['data'], 37) self.assertEqual(response.templates[0].name, '{} Template'.format(method)) self.assertContains(response, 'Viewing {} page.'.format(method)) def test_json_post(self): assertJSONResponse(self.client.post, {'value': 37}, 'POST') def test_json_put(self): assertJSONResponse(self.client.put, {'value': 37}, 'PUT') ... ``` Please also try to avoid temporary variables like `post_data`, `put_data`, etc.
It might be better to put the content type check in _encode_json for consistency with _encode_data and to avoid duplicating that in every put/patch/etc. method.
Unfortunately, I don't have a good answer for that. I think now that Django is Python3 only, the project is in a better position to decide if SECRET_KEY is always either bytes or str. That would require some consensus from interested people, though. As long as both types are allowed, some utility function is required. I guess at the moment that is force_bytes/force_text.
According to the [docs](https://docs.djangoproject.com/en/2.0/ref/settings/#std:setting-SECRET_KEY) and ticket https://code.djangoproject.com/ticket/24994 the type of `SECRET_KEY` can be either bytes or str. > Uses of the key shouldn’t assume that it’s text or bytes. Every use should go through force_text() or force_bytes() to convert it to the desired type. So a call to `.encode()` may not always work.
Why not have this happen for default verbosity? Looks look a good change otherwise!
Please test the entire message.
Yeah. For me that would be fine.
I think `get_internal_type` is better to use.
I think a mixin is a bit complicated. The attribute sounds simpler - it could be a function instead of just a boolean, then it could return the transform if applicable, else `None` for non-sliceable fields (default implementation).
How about `SlicedF`? It's not 'sliceable' at this point, it has actually been sliced.
Wouldn't this approach fix the slicable fields to just these types? A mixin along with `slicable = True/False` on `F` may be an approach. Besides, I believe the policy is to keep `django.contrib.postgres` as separate as possible.
😃 Yeah, I can see that. But I was scanning the code and looking for the definition. I wanted to find all the helpers in one place. (As ever, there are different ways of wanting to read it. That's OK.) If you feel strongly you can leave it for now. Tim will have a look before merging it anyway so he can input.
This is only used once. Can we move it back to the `color` module? (That way `termcolors` is still only ever used by `color`)
This is only ever called once. Do we need the default? (Same with SQL version)
I think I'd add a note on the return 2-tuple here to the docstring.
Can we move this function up by `get_traceback_highlighter`. (That way we keep the two related helper functions next to each other.)
Thanks. You're right too much `and` 😄. The second version is more readable for me.
The trailing space can be removed.
`pk` is twice. I think the last `and pk` can be removed.
should be `disable`
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I don't think this is needed. Or `requires_system_checks` or the non-required arguments -- try to simplify this as much as possible and remove unused things like `if options['verbosity'] > 0:` (I assume this was copied from another command).
Please remove the leading/trailing spaces in docstring.
Yep. Looks fine. I've marked it Ready for Checkin. Most likely Tim will have a look and merge it if he's happy.
No problem. I think it’s OK as is. (Adjusting it would be done separately anyway)
Hey @felixxm. I looked at both of these and thought them OK because they aided readability. (Just a small visual separator between the blocks). Is your objection that to the lines themselves, or that they're unrelated to the change per se? If the latter would a separate commit be better? (Thanks!)
Please chop this unrelated blank line.
These checks aren't quite independent. When this one is first it fails. But I guess it's OK.
Remove this blank line. (Those above and below, separating the `last_login` check are fine.)
I wouldn't add the extra lines for both reasons. Not to say that mistakes aren't made, but generally if we merged a previous patch without them (at least recently when code style is more standardized than in the early days), then blank line changes probably aren't needed. Certainly putting unrelated blank line additions in a patch doesn't help keep things clean and I don't think the blank lines are so important that they deserve a commit.
Please chop this unrelated blank line.
Is this import here necessary to avoid a circular import, or can it be moved to the module scope? Also I'm not sure that we need to alias this as `V`. I believe most uses in the Django code use `Value`.
This feels rather clunky - can you not use string formatting, e.g.` '{%s}' % hierarchy` and `'"%s"' % val`? Also, we prefer use of single quotes - this whole PR seems to do quotes inconsistently. Come to think of it, I'm not very keen on the way that this is constructed. What if `hierarchy` contains a mix of string and numeric values as keys? Does that make a difference to how this is constructed? What about `val`? It looks as though the value is always quoted as a string, but we should be able to pass integers or floats here... I would like to see more tests with all the data types supported by JSON and have them re-fetched from the database for comparison.
The parentheses around `','` are unnecessary.
Please follow the style of existing tests and don't use your name for test values.
Please use `LOOKUP_SEP` from `django.db.models.constants` instead of `'__'`.
Why not just use `JSONBSet`? We already use `JSONBAgg`, it is PostgreSQL-specific so referring to JSONB is fine and it makes it clear that this is the `JSONB_SET` function.
Use [PEP 257](https://www.python.org/dev/peps/pep-0257/) verb style: "Update..."
Given it's now all `__pycache__`, do we need this workaround? (i.e. could we just revert https://github.com/django/django/commit/51673c146e48ff6230eace39bac18fd555607bee)
Use meaningful test names, e.g. `test_no_arguments`. Also I would have 3 tests and use a loop a `subTest()` to test the three cases for each template. For example: ``` tests = (('0', 'votes'), ...) for value, expected in tests: with self.subTest(value=value): output = self.engine.render_to_string('pluralize01', {'value': value}) self.assertEqual(output, expected) ```
`self._queryset = None if queryset is None else queryset.all()`
@akulakov - that may seem to be a more common pattern, but it is only because unpacking generalisations have only been available since Python 3.5, which is now the minimum version supported by Django. Unpacking generalisations also have the advantage that they have a dedicated operation that has less overhead than the function call, `dict()` in this case. The proposed change is more concise and perfectly clear according to the syntax of the language.
Fine, but not as part of this PR. If you can change these cases systemically, that would be great.
The `foo_attrs` variables could be removed.
I'd put `for key, value in kwargs.items()` on the next line to decrease length a bit.
I don't think you should re-number the existing tests.
There's already a single test for the `yesno`-filter in `django/tests/template_tests/syntax_tests/test_filter_syntax.py`. However, it's probably better to move it into a separate test-class. Please do this in a separate commit. Please see 7fce4dc5ff2d23bf43ee645f5bc0d6024ff1627f for an example.
I'm trying to pin this down. It's **not** state between calls (like the `cycle` example). Rather, I'm viewing the change list from App A, whilst someone else is viewing the change list from App B. (We have the same template, with the same `AdminInclusionNode`.) My thread sets `self.filename` to the `app-a` `app_label` just as their thread goes to instantiate the template in `super().render()`. They get the override template for the wrong app. (i.e. it is a race condition.) It's pretty tight but it's there. (Or so it seems) I'm trying out @collinanderson's suggestion. I can't see how to test this.
Hmm. Maybe it would work to pre-cache the template? It's kind of a hack though. template = context.template.engine.select_template(filenames) context.render_context[self] = template
Oh, it's a PY2 relics...
I really don't know. It should be fine because it doesn't change every time it is run (or better: it could change with the same opts values). And users cannot really use a custom template_name without rewriting tags and templates. But threading what happen with you can't know really.
@carltongibson I see the potential problem here (oh, I try to never use threads in first place). The proposed solution is basically what InclusionNode.render does: I like it :+1:
Do we need to use `Subquery` here? (If I remove it the test still functions — i.e. fails without patch, passes with it.)
Seems okay, although I wonder if `isinstance(username, str)` would be fine? A test is also required. Possibly the problem could be reproduced with `tests.auth_tests.models.IntegerUsernameUser`.
`s/_managed/_unmanaged/` I think.
`migration_loader.graph._generate_plan(nodes, end_at=True),` (omit intermediate `graph` var and pass True as kwarg for readability.
`_generate_plan() doesn't readd migrations already in the plan (#29180).`
Please use single quotes consistently in new code.
Given the logic of this method, I'd reverse the conjuncts here: ``` If the lookup is simple (no double underscores) and the node is carrying generic foreign key lookup... ``` Also, the project doesn't make use of `:param lookup:` and `:return:` annotations.
Is there a more specific name that `_prepare_lookup`? (I can't instantly come up with something ideal but it would be nice to not have to look at the implementation to see what this is for...)
I think this should be `if not self._reader` - that covers the same expression, but it's the call that's ultimately failing in the original bug. With this fix, if there were a change to the implementation of `_reader` the original bug would return.
Minor spelling tweak - "must contain a", not "must contains a".
Is there a reason to add a `pass` statement here? The docstring should be enough, you can take a look at [Why does python allow an empty function (with doc-string) body without a “pass” statement? (stackoverflow)](https://stackoverflow.com/a/17735171).
My view is that Python design specifically allows to omit 'pass' when docstring is present, in other words it's not some corner case or side effect, it's a style and design decision that a docstring is considered as "body". It's not a strong preference, but I'd prefer if django did not enforce adding 'pass'.
I think Django has generally included `pass` (perhaps a full audit could be done). I'm not sure that omitting is considered "an obscure feature" and I don't have a particular preference one way or another.
I think invalidating the `size` cache would make more sense than re-computing the size on every single write. ```python self.__dict__.pop('_size', None) ```
I think this is unneeded as per c9ae09addffb839403312131d4251e9d8b454508.
I'd rather fix this for as many languages as possible. Let's talk to our users :-)
For Polish no change is needed. `X days ago` is `X dni temu` and `X days from now` is `za X dni`. Those prefix and suffix doesn't change for any number of days.
Thanks to @mxmerz for writing to the django-i18n mailing list, Hungarian is such an example: - `X days ago` can be translated as `X napja` or `X nappal ezelőtt` while - `X days from now` can be translated as `X nap múlva`
Please put on a single line.
Use `{}` rather than `set()`
I'm not sure about including the find command here and in the release notes. What about Windows users? :-) I think it's easy enough to search "delete pyc files" and find a solution.
single line for some of these? Fine to pass `data` as the first positional arg rather than as a kwarg, I think.
could use a single line here
This should just fit on one line I think. (It's exactly 120 characters. 🙂)
I'd write this block a little differently: ```python if isinstance(list_filter, (tuple, list)): # This is a custom FieldListFilter class for a given field. field, field_list_filter_class = list_filter if isinstance(field_list_filter_class, str): title = field_list_filter_class field_list_filter_class = FieldListFilter.create else: ... ```
`path` is also unused.
We can fix this condition without nested parentheses, i.e. ```python if not compiler.query.values_select and not compiler.query.annotations and self.query.values_select: ```
Relying on pk might be problematic since we shouldn't assume the values that the database might assign.
...or is the empty string. I wonder if it's worth adding that to the check above? (ln 39.) There's no point passing `''` to `identify_hasher`.
I'm not fond either of this semantic change of the `is_password_usable()` API. I think we need two APIs for two different use cases: 1. tell if the current user password is usable (as current `is_usable_password`), 2. tell if the current user password is voluntarily disabled.
Fair, but then I think a `versionchanged` is missing in the docs + maybe a backwards incompatibility release note.
Hmmm. `start` was unused anyway...
I think, given the way how you rewrite the test function, it's time to split the individual cases into individual test functions.
Could you please keep the cross-app reference that we had before.
Could you please keep the cross-app reference that we had before.
Please use triple double quotes around docstrings. ([PEP 257](https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring))
Use single quotes for strings, unless there's a nested single quote. ([Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style))
I'd make this a lambda or use `operator.mul`.
Are we sure a `delete` is required because a truncated value will be set when it overflows? I guess we should also wrap `super().set()` instead of duplicating its body.
technically 1MB is just a default and can be reconfigured, so you could write only "memcached's limit"
funct -> func -- I think? or "function"
I guess this does follow other existing methods, but: ```python return force_text(value) if isinstance(value, bytes) else value ```
I wonder why `ordered=False` with a result of length 1.
Hey @rubgombar1, thats right. Thanks for the reference. I take comfort in the fact that I wasent the only one who didn't think about it :)
Can we use `cl.result_list` as in the next elif clause below? At any rate there should be a more direct way of getting the objects we're displaying on the page vs. using regex on POST items, which is too brittle and complex.
Hey, if the problem is that the entire queryset is fetched to generate the formset - instead of fetching only the relevent objects using regexp, have you considered fetching just the current page instead? You have the paginator and you have the request. Obviously fetching only the neccesary objects to update is ideal but as @akulakov said, it's a bit brittle. Using the page is not the the best solution but it should contain the performance regression. Hope this makes sense :)
Please use a `msg`-variable to reduce the line-length.
Please use `assertRaisesMessage`. You can convert existing instances in the test files you touch in the same commit.
put the trailing ) on the next line as done in `ValueError` below.
Django only supports Python 3 now so six isn't needed.
simpler: "must be a string"
Please put it on the next line and include a trailing comma.
My suggestion is: ``` Convert CharField results from bytes to str. MySQL returns long data types (bytes) instead of chars when it can't determine the length of the result string. For example: LPAD(column1, CHAR_LENGTH(column2), ' ') returns the LONGTEXT (bytes) instead of VARCHAR. ``` I'm not sure if it would make a meaningful difference, but a feature flag might be useful since `isinstance` can be somewhat expensive, I think.
`CharFieldMixin` looks a bit too simple of a name. It's more like `MySQLReturnsBytesForCharFieldFix` (somewhat joking). As I just mentioned on the ticket, it would be nice if we found or filed a MySQL ticket for this to better understand the behavior and to see if it might change someday. That might help dictate how elegant we want to make the fix.
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
And `\r` or `\n` -- I dunno if Django protects from header injection
No, not necessary.
I'd suggest a name like `test_list_filter_is_function`.
Please put the closing ) on the next line as in other tests.
This seemed to include svg as well but django does not accept svg file input.
Why is it `ClearableFileInput` and not `FileInput`? Tests are also required.
`# Add support for the SameSite attribute (obsolete when PY37 is unsupported).` I think the link to the PR isn't needed.
", or" Please use periods.
use a single line
This is the default, it is needed? Perhaps another test for a non-default would be useful.
Confirm that. (An `assert False` thrown in here is never triggered.)
Ahh nvm, the function accepts an iterable and not `*args` 🤦‍♂️
not_annotated -> unannotated
Use single quotes.
I think this assertion isn't needed.
``isinstance`` call would be better
I think we could make use of `self.subTest` here.
Please wrap docstring at 79 chars.
Please use single quotes, and remove the unnecessary semicolon.
Please remove the unnecessary semicolon.
I would move tuple unpacking to the `for` loop, i.e. ```python for column, expected_string in testable_column_strings: ... ```
remove extra blank line
No need to change `msg` to `warning_msg`.
A better approach might be to pass `'^%s$' % re.escape(expected_warning))` to `assertWarnsRegex` instead of manually escaping.
please remove the unrelated change
Verify the message as well, please.
Use the context manager version, please.
I would change this to `# Prevent logging from appearing in test output.`
You can just use a generator, without the `[` and `]` here: ``` if sum(1 for f in cls._meta.local_fields if f.primary_key) > 1: ```
I think this is a bit vague. Perhaps `_check_single_primary_key`.
Please remove the added blank line.
multi-line as other messages: ``` "The model cannot have more than one field with " "'primary_key=True'.", ```
The model cannot have more than one field with 'primary_key=True'.
No need to try/except/fali... just test that the method works properly for each choice value.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Blank lines aren't needed.
I'm not sure if the docstring adds much -- at least the ticket reference isn't needed.
Could be reduced to a list comprehension ```python return [ value for key, value in request.POST.items() if regexp.match(key) ] ```
Ah yes. It no doubt will. (That's too much DRF that is. 🙂) We need to handle this. 👍
I would organize these methods else (inside of in the middle of the views) and prefix them with an underscore to indicate that they're helpers, not public APIs.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
True, just thought I mention it.
aaah, ok, now I get it.
Same here, it may just drive complexity.
I don't see a use case for the new argument right now. If you want to replace the strings, it seems more commen to provide your own PO gettext files/translations. That way you can provide your own strings, while not changing the place holders.
I know you didn't write the self.humanize_test, but I would suggest to use subtests here: ```python with self.subTest(i) ```
Since negative years or negative plurals do not make sense, how about limiting number to 0 and 1.
In English only 1 is singular. This should be `0 years`.
This is the version of mysqlclient, not of MySQL. Look at `self.connection.mysql_version` in this file for the correct version.
I don't think this test is needed. It's enough that we'll run the test on MySQL 8.
These also need changing to properties like `can_introspect_foreign_keys` because you can't inspect the database version at import time
function -> method
Based on how the Python docs declare enums, it seems that text, var, etc. should be capitalized.
This should use `with self.setttings(LANGUAGE_CODE=...)` to test the `True` case.
It would be fine to call the function with `None` since `r` isn't used. Again, use `self.settings` to verify that `settings.LANGUAGE_CODE` is returned.
I think that `ASC` is unnecessary.
Unrelated to this change but this `else` branch is unnecessary given we return on `IndexError`.
I'd be great if we could avoid calling `get_ancestor_link` if `not has_value` given it will be unused anyway.
It could be `url_uname=url_name` but I don't think it matters much as it's only cosmetic.
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
`dest='plan',` is unneeded as that's the default value from `--plan` (eac9ab7ebb1ce0cbbc79c4cf65e8f70b0635a240)
Please use single quotes throughout the patch except if the string contains a single quote.
Yes, for new code we're trying to follow the [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Please use single quotes throughout the test.
Remove the blank line.
I think "ordered" is also unnecessary (i.e. why would they be out of order ;-) ).
It looks like `operation.reverse_code.__doc__` will fail with `AttributeError` if `operation.reverse_code` is `None`.
Please use also use single quotes in the test where possible.
Remove the blank line
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
OK then, thanks for the references.
'--version argument does not yet exist'
This is getting hard to read, I would recommend to name the separate parts, e.g.: ``` has_alias = getattr(expr, 'alias', None) is not None ```
@codingjoe unless I'm missing something that would require stopping to use a list comprehension. I guess the `alias` checking could be broken to a new line ```python expressions = [pk] + [ expr for expr in expressions if expr in having or ( getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases ) ] ```
You can drop the `all()`.
you can drop the `False` to getattr here, `None` is also not true.
`self.returning = returning or primary_key`
seems there are conflicts here
Is there a reason not to favor the previous approach and pass `returning_fields=self._meta.returning_fields` instead? That seems like a better separation of concerns to me than having the insert compiler lookup `returning_fields`.
I'd vote for making `returning` a `property` instead of a stealth field option at least for now because this is not something we've done in the past. ```python @property def returning(self): return hasattr(self.default, 'as_sql') AutoField.returning = True ``` That would make `DateTimeField(default=Now)` work and avoid the ambiguity of `default=Now, returning=False`. We'd still have to deal with backends that don't support returning fields.
Maybe something along the lines of: For databases which do not support returning clause we need to ask the database for the id. Generally last_insert_id is only supported for serial/auto_incr columns, hence we guard it for auto field. \# TODO: Maybe add a marker to fields that their value can be returned by last_insert_id instead of a type check. +/- typos and style cleanups ;)
I guess this should be something like `returning_fields` -- `returning` looks like a boolean attribute as used elsewhere.
Again, this could be a class level attribute.
Maybe we need a field property. It doesn't look nice to put `isinstance()` special cases here.
Simplify to the following? ```python columns = ['%s.%s' % (self.quote_name(f.model._meta.db_table), self.quote_name(f.column)) for f in fields] params = tuple(InsertVar(f) for f in fields) ```
Please make this a list comprehension.
```python return value if isinstance(value, list) else [value] ```
Please use single quotes everywhere in this method.
This could be `', '.join('%s' for i in len(columns)),` to avoid needing to create `into_params` up front.
I don't think that we need to pass a table name because `_insert()` is a `QuerySet` method so it already contains `self.model` with a table name :thinking: but yeah let's leave it for a separate discussion.
`RETURNING` from `UPDATE` is out of this ticket scope.
The default implementation will be more complicated in the future when we will add db defaults. I think we can leave it is as a property.
I guess I find comprehensions more legible than loops like this, especially with single item tuple appends which are syntactically ugly. Comprehensions are fast with dedicated operations in bytecode, calling methods like `.append()` multiple times in the loop is slow. In terms of performance, it should be negligible anyway as I expect this to be called once before the query executes, not per row returned, and typically I expect the number of fields to be very small...
Single quotes please.
Can we always assume we are getting a list returned? I believe `SQLInsertCompiler.execute_sql()` always returns a list now? (Although we may need a note in the backward incompatibility section for database backends?) If all that were the case, we could possibly condense this whole section to something like the following: ```python returning_fields = None bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert if bulk_return and not ignore_conflicts: returning_fields = self.model._meta.db_returning_fields return list(itertools.chain.from_iterable( self._insert( item, fields=fields, using=self.db, returning_fields=returning_fields, ignore_conflicts=ignore_conflicts, ) for item in (objs[i:i + batch_size] for i in range(0, len(objs), batch_size)): )) ```
Prefer a set (or tuple) to list for containment check.
I tried to address Simon's request in the da4dd37f5fbb4bf9489f45803ffc0a91d0ac0592, this change also replaces some misleading variables' names.
Sorry, I meant `range()`, not `len()`. (Or just ditch the `len()` and iterate over the elements.)
@codingjoe I'm going to check why `test_insert` and `test_bulk_insert` fail on Oracle with the current implementation :thinking: .
It feels like something is missing here. 1. `ids` is now a list of list of returned values, so the name is misleading. 2. Setting all values returned should also happen for `objs_with_pk` so that non-id/pk values are correct. For that matter, do we also need this to happen for `.bulk_update()`, `.get_or_create()`, and `.update_or_create()`? I've not looked into that in too much details and maybe I'm getting ahead of myself with these as I guess that some of these would be using `RETURNING` from `UPDATE`. (We could potentially look at supporting that, and thus generated/virtual fields next cycle...)
inner import for new model not required
Could we check if we actually need this `with` statement again? Maybe the one above is just fine? :man_shrugging:
* Please wrap this so each `else` begins a line. (Then each clause is easily identifiable.) * Use hanging indent.
Use single quotes.
You're already calling `super()` above.
Use `if isinstance(d, list)` to handle subclasses which are likely to be unhashable as well.
Instead of this file dance, it would be easier to use a `tempfile.NamedTemporaryFile`. It is also safer wrt parallel test runs.
The first condition is superfluous. line is a str and therefore `'charset=CHARSET' in line` will be False if line is the empty string.
This import can live in the above line.
start the string with `(` and then you don't need the ending backslashes.
On thing to keep in mind is that this is going to be introducing double work.
I'd be great to assert the permission and content types were appropriately created as well!
There's a space between `.` and `_meta`.
In any case, we cannot simply remove that without understanding what is happening under the cover.
remove unused `as exc`
`', '` (since quotes)
I'm not sure I would even write an assertion for such a broken output. Just ignore? Same below.
It looks like only `IndexError` is exercised in tests.
Use the indentation style of the other tests. Actually, you can use `assertCountEqual()` instead. Maybe it makes sense to create another Article with a different year to test that the results are correct and not just returning everything.
Remove `()` -- that's a fixed default which gives a check warning when running the tests.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
`stderr = ...` (and move above assertRaisesMessage)
I wouldn't refactor the other test but `stderr` instead of `err_buffer` is more consistent with the majority of tests.
single line looks okay here and in the next test (it's shorter than the previous line, at least)
Use single quotes where possible.
Add trailing commas in call_commands.
Ahh right just read through the whole discussion. I wonder if this could be an opportunity to solve the issue. e.g. ```python def __set_name__(self, owner, name): if self.name is None: self.name = name self.func = self.real_func elif name != self.name: # Re-assignment of a cached property to a class # creates a new instance. instance = type(self)(self.real_func, name) setattr(owner, name, instance) ``` That would make ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = is_postgresql_9_5 ``` The equivalent of ```python @cached_property def is_postgresql_9_5(self): return self.connection.pg_version >= 90500 has_select_for_update_skip_locked = cached_property( is_postgresql_9_5.real_func, 'has_select_for_update_skip_locked' ) ``` And address the bug preventing the `__dict__` level caching bug discovered by @sir-sigurd.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
I think silently failing to cache the property should be considered not working.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
I also still don't understand why it's useful to allow writing code that doesn't work.
@graingert `cls` is passed here.
I think it's the right class: ``` In [38]: class desc: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: return instance.__dict__['_%s__mangled' % cls.__name__] In [39]: class A: ...: d = desc() ...: ...: def __init__(self): ...: self.__mangled = 42 ...: In [40]: A().d Out[40]: 42 ```
Wrap this into previous paragraph so we only have one explanation of ``name``? ``` On Python <3.6, the ``name`` argument should be passed to make a cached property from another method without a name collision, e.g. ``url = cached_property(get_absolute_url, name='url')``. ```
@graingert Probably it doesn't worth it, but still doable :-) ``` In [85]: class desc: ...: def __init__(self, f): ...: self.name = f.__name__ ...: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: ...: for cls in cls.__mro__: ...: name = '_%s%s' % (cls.__name__, self.name) ...: if cls.__dict__.get(name) is self: ...: return name ...: ...: class A: ...: @desc ...: def __x(self): ...: pass ...: ...: ...: class B(A): ...: pass ...: In [86]: a = A() ...: a._A__x ...: Out[86]: '_A__x' In [87]: b = B() ...: b._A__x ...: Out[87]: '_A__x' ```
I think a plain warning would be fine.
I think we'd normally call this `check_cached_property` or similar Also I'd prefer a longer class name than `A` whilst we're refactoring these tests
Could be a plain `warnings.warn` Also not sure that the 'people like to copy this file' argument holds for Django's codebase. There's `pip install cached-property` for an implementation of this outside of Django.
Might make sense to check explicitly set name too, because '__name' obviously will not work.
Can you just do `name.startswith('__') and not name.endswith('__')`? Simpler is better
Might make sense to raise exception in this case: ``` class Test: @cached_property def a(self): pass b = a ```
``` class A: __print = cached_property(print, '__print') ``` This will not work and we can easily detect it too.
I'll push my edits tomorrow.
> No exception for Python 3.5 but docs say name='_Person__friends' is required. It's required because it won't be cached and no exception is raised because there is no way to detect it.
I would consider that as not working
You'll want to branch off `< 3.6`.
I'd say `on Python < 3.6`
Ditto about the class `__name__` change.
What's the rationale for changing this test class name? It looks like unnecessary noise to me.
I feel like this _helper_ is making the assertion harder to reason about. Inlining `getattr(source, attr)` calls would be easier to read IMO.
Python < 3.6.
You'll want to branch of lesser than Python 3.6 here.
You'll want to branch off greater or equal to Python 3.6 here.
We typically follow the camel casing of unittest assertions, e.g. `assertCachedPropertyWorks`. Try to split out test refactoring in a separate PR to ease review.
But with GDAL 1.11, the following lines will execute (note `>` and not `>=`).
This should be kept, as GDAL 1.11 is still supported!
I'd extract the `epilog` string into a variable and re-use it to get the line length down.
What about just adding `**kwargs` here? It should be the same but without the need for the creation of an intermediate dictionary.
My thought was to wait and see if a use case was presented before adding that.
This should be handled by the fields themselves, what you've written here is what a special cased `JSONFieldGinIndex.create_sql` implementation would look like.
I would call this `_field_became_primary_key`.
Remove trailing comma.
Collapse into the line below to avoid the temporary variable.
Now we can call this `test_migrate_app_name_specified_as_label` (and similar for the similar test).
This isn't needed, I think.
> Or should I just check that those settings doesn't exist outside the context? I think that'd work.
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
You are right I missed the fast that exceptions raised during `__enter__` are not going to go through `__exit__` sorry for that. That makes these tests unnecessary.
I think something like `SETTING_BOTH` will be fine. No need to memorialize the bug number.
This needs to use hanging indent.
Can you re-warp this block to 79 chars? (First line is too short.)
Minor point: There are a couple of these blank lines after docstrings that I'm not sure about.
I don't think we need this here. In `disable()` we `raise self.first_exception` (when `not None`) so this line will be unreachable.
Define at the class level.
This will cause `disable` to be called twice if `override_settings` is used as a context decorator because `TestDecorator.__exit__` always executes `disable()` https://github.com/slafs/django/blob/0d9284b305f417f584a9ed4fd1ca8397a1eed49d/django/test/utils.py#L338-L339 This is an issue because this will cause the `setting_changed(enter=False)` signals to be fired twice and the traceback will be really odd to users as it will be of the form `__enter__` -> `enable` -> `disable` -> `__exit__` -> `disable` -> `(signal receiver trace)` It should be off the form `__enter__` -> `enable` -> `(signal receiver trace)` You should be able to assert this works correctly by inspecting the `__cause__` and `__context__` attributes of exceptions.
Use `self.addCleanup(...)` in `setUp` to avoid overriding `tearDown`
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
I might be tempted to call this `enter_exception`.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Use `as e` or as `as exc` to match other code.
I'd use complete variable names and maybe _ for `rcv` since it's unused.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
Yeah, fine. (It's your bike shed 🙂)
One solution here would be to make `enable`/`disable` idempotent by having a class level `enabled = False` attribute that gets set/unset and checked for early return in both methods or to override `__exit__` to deal with `exc_value == self.enable_exception` in a special way.
You can use a literal here: ```py allowed_hosts = {allowed_hosts} ```
I guess if it is a supported interface, it isn't fair to call it a mistake.
Move to the top.
I don't think both tests are required.
Would `functools.partial` work here? ```python from functools import partial bound_method = partial(method.__get__(self, type(self))) ```
I think you can prepend `admin/js/` and simplify the line below
Reuse the most recent alias of the joined table (a many-to-many relation may be joined multiple times).
i don't know what the official Django community's take on ternary operators or `or` assignment is, but you could consolidate these three lines into: `object_list = self.count_object_list if self.count_object_list else self.object_list`, or better yet: `object_list = self.count_object_list or self.object_list`
This isn't correct as it will return `None` if `x` or `y` were a string. It should only return `None` if x, y or both are `None`.
That would be cleaner.
Sounds very sensible!
Ah. Yes, quite right. So this could be simplified to: ```python return None if None in args else func(*args, **kwargs) ```
Please add `@functools.wraps(func)` to this.
I find the wording `any of the argument to a function` a but awkward. Maybe `Returns None if any of the arguments are None.` Definitely not a big deal.
I don't think that SQLite can pass kwargs, so I think that this can be replaced by `if None in args`.
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
Makes sense, thanks for the investigation!
I guess it wouldn't hurt to test it against all backends.
No need to include a ticket reference as the test name is self describing.
You can pass `key_map` directly as `dict.__iter__` yields keys.
Perhaps we should continue to test the simpler case where we don't provide a `name` or `condition`.
I don't know much about the tablespace feature, but I'd expect to see an assertion that interacts with it somehow.
Do we need the `tzinfo` bit for the test? I'm worried relying on `get_current_timezone` could make the test flaky.
I don't see where this test has anything to do with `tbl_space` - it looks like a duplicate of the previous test.
It is slightly more correct to have this line before the `try:`. If registering the lookup fails, we don't want to also try to unregister it.
Yes, this is how third-party database backends would skip those tests.
I think we should add this to the opclasses as well then.
I think you should use `None` as a default value here to avoid having potentially mutable default.
I think you could inline this function call on make it an instance method that expects `model` and `schema_editor` to be passed along.
I think this would be slightly cleaner: ```python if self.condition is None: return '' query = Query(model=model) query.add_q(self.condition) compiler = query.get_compiler(connection=schema_editor.connection) # Only the WhereNode is of interest for the partial index sql, params = query.where.as_sql(compiler=compiler, connection=schema_editor.connection) # The base schema editor does the same map on the params, but since it's # handled outside of that class, the work is done here return ' WHERE ' + (sql % tuple(map(schema_editor.quote_value, params))) ```
yeah, we probably should replace these intances of the `register`/`try`/`finally: unregister` pattern with `register`/`self.addCleanup(unregister)` as well.
I'm not sure if this skipping logic is correct -- it seems to skip on MySQL but not MariaDB.
How about: ``` if storage_engine == 'InnoDB': return self.connection.mysql_version >= ( (10, 2, 2) if self.connection.mysql_is_mariadb else (5, 7, 5) ) return storage_engine in ('MyISAM', 'Aria') ```
Might make sense to rework this function as method.
Since this is just a type check which should apply to all environments, not just production ones, it doesn't need the `deploy` flag
`None` is being passed for the `app_configs` argument - even though the check ignores `app_configs`, `[]` should be used as a more valid test value. I think it's worth looking into refactoring these tests in general, as you're write these property inner-imports are a bit confusing, made a note to self.
I see the other tests are doing it but, I don't see why we're declaring `func` as an `@property` here and/or passing `None` when calling it. (Would not a normal method do? Why pass any argument at all? `self` would be fine, but is unused.)
It's the pattern that django-secure used. Not sure if the reason is still relevant. \cc @carljm
yeah I don't see a reason why the imports are not top-level and we don't call the functions directly.
I think we should check it's iterable AND not a string, there's always the possibility of other mistakes than the one that lead to the ticket, e.g. missing brackets on a function call
I don't think Django has existing workarounds for this issue, e.g. https://github.com/django/django/blob/f021c110d02fd7ca32ae56f511b46e5d138b6c73/django/core/handlers/wsgi.py#L83 I think it adds necessary complexity.
trailing ) goes on the next line (check your entire patch for this style)
```suggestion 'Accept': '*', 'Host': 'example.com', ```
```suggestion 'Accept': '*', 'Host': 'example.com', ```
blank line not needed
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
Does this need to be a separate method? Seems unnecessary to me.
This isn't actually Immutable. I didn't trace far back enough to see if the WSGI `environ` is immutable but cursory inspection would indicate that `.META` is not actually immutable although it would probably be a bad idea to manipulate it (I might be wrong on this point).
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Chop blank lines.
I would use a simpler dictionary that covers all the cases.
Chop blank line.
@santiagobasulto What are your thoughts on renaming this to `CaseInsensitiveMapping`? `Mapping` being the stdlib ABC you're implementing. (c.f. `ImmutableList.complain()`: we're taking measures there to avoid mutation. I don't think we want or need to get into any of that here.)
Mapping allowing case-insensitive key lookups. Original case of keys is preserved for iteration and string representation.
Use a single line throughout where possible.
I'd expect to see a test for this. Please audit test coverage carefully and make sure all lines are covered.
chop blank line
This could be made more DRY: ```python for option in ('unique_together', 'index_together'): ... ```
Now needs to be `…i.e. is empty, has an order_by()...` (and wrapping)
Looking at other test methods I believe this can be reduced to a simple line. ```python self.assertEqual(User.check(), []) ```
Thanks, done in a4d8e412e0295ac7d40bb87ee6e5f44649f97816.
I think we can move `msg` to the assertion, I don't see much value in creating a temporary variable here.
Please start a docstring from a new line ``` """ alternate... ... """ ```
Dot is missing, _"... used together."_.
Chop blank line.
Maybe _"The 'no_color' and 'force_color' cannot be used together."_.
Please wrap at 79 chars.
Please wrap at 79 chars.
Do we need `requires_system_checks` flag? All tests pass without this line.
* `--force_color`? (i.e. with `--`) * ~~Re-wrap?~~ (Sorry diff view confused me: you already did this.)
Please use single quotes (here and below where a string doesn't contain single quotes).
Please add a trailing comma.
Please wrap this output (and similar outputs below) at 79 chars.
Trailing dot is missing.
This can be singe-lined.
Please wrap at 79 chars.
Please wrap at 79 chars.
Not sure about the value of the docstring here.
I'd use `cannot` rather than `can not` here and below
Please wrap at 79 chars.
Please wrap at 79 chars.
This can be single-lined.
Please wrap this output (and similar outputs below) at 79 chars.
`out` and `err` are unused in the second call. IMO we can simplify this call, e.g.: ```python with self.assertRaises(CommandError): call_command(Command(), no_color=True, force_color=True) ```
Please use single quotes.
Please wrap at 79 chars.
No trailing comma (see also 83a36ac49a98d5d8801ed8428612e9a56aeb8699).
Forms don't validate unique_together constraints when only part of the contraint is included in the form to allow using form.save(commit=False) and then assigning the missing field(s) to the model instance.
I would use `.objects.create()` rather than separate save calls.
Is there a reason not to use `@skipUnlessDBFeature('supports_default_in_lead_lag')`? You'll have to add the feature to the default database features.
Some behavior has changed here. On the file-backend, the output of `get_payload(decode=True)` is now `b"Je t'aime tr\xe8s fort"` as opposed to `b"Je t'aime tr\xc3\xa8s fort"` originally (and with the other backends). I guess this might be a bug but I don't have much expertise. 5dfd824d38ec7d1f695494e46d603e89cae68661 may be relevant.
This can be simplified and put in place of `format_string` below: ```python '= %s' if len(key_map) == 1 else 'IN(%s)' % ', '.join(['%s'] * len(key_map)) ```
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
Please add a trailing comma to this line.
Please add a trailing comma to this line.
This feels like a copy-paste of `delete_many()` that you have proposed in #10258. Perhaps this could be rebased on top of that branch and all of this expiry code can condense to use: ```python self.delete_many(self, expired_keys, version=version) ```
This test runs on database cache only
I think it's fine to tidy up here, we're basically just inverting the reuse where previously `delete_many` reused `delete`
please move this test next to the the `get_many` one
please insert tests on line 1029, after the `setUp`/`tearDown` helpers `create_table` and `drop_table`
No need to construct a new `dict` and call `dict.update()` here. Also the key ought to exist in the map or something has gone drastically wrong, so no need to use `dict.get()`. ```python return_dict[key_map[key]] = value ```
I see now that a lot more was going on here than I initially thought. I am coming around to being fine with your approach here @MyungSeKyo
@pope1ni I am still reviewing, but it looks like the `get_many()` function performs `validate_key()` on line 60, so they removed it here. I am still looking at `get_many` more closely, but I suspect it will work fine, though I personally think we should revert these two lines so that future developers do not have to read through the entire `get_many()` function to understand the only thing that is happening here is that `validate_key()` is being run.
This could rely on tuple unpacking and there is no need to assign to `rows` above: ```python for key, value, expires in cursor.fetchall(): ```
similar to `get()` above, I appreciate the code reuse, but I personally would prefer if `get()` and `delete()` were not touched.
I think this is doing what it should, but a minor suggestion, perhaps use `key_map.keys()` instead of `list(key_map)`, they are equivalent, but do not test the developer on whether a calling `list()` on a dict returns a list of keys or values. Not a blocker for my approval, but a personal preference. Take it or leave it.
huh, TIL. Transitioning to Python3 from 2.7 for my personal projects and I didn't know they had changed that. Thanks for pointing it out.
Use literals please - `[]` for `list()` and `{}` for `dict()`. Also, something like `result` would be a better name than `return_dict`.
Use literals rather than functions, i.e. `{}` not `dict()`. This should come at the top of the function as the stuff before it does not need to happen if it is empty.
I am not sure this change is beneficial.
could also assert they are all gone Also *if* we leave 1 item with `=` as a special case (which I don't believe is necessary, as I wrote above), it will need its own test for 100% coverage
An error the database
, -> .
I wonder what the purpose of `strip_quotes()` is -- usually that handles table names on Oracle.
`If the database should be kept and it already exists, don't`
@orf both work, `raise ExceptionType` is common when you don't want to specify a message.
The parentheses aren't required. https://stackoverflow.com/questions/16706956/is-there-a-difference-between-raise-exception-and-raise-exception-without
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
Getting an error about an index when creating a constraint is confusing unless you understand the implementation details.
We're generally preferring `assertCountEqual()` and `assertSequenceEqual()` over `assertQuerysetEqual()` to remove the need to put a bunch of `__str__()` strings.
I prefer more explicit test method names, don't know if Tim/Carlton have the same opinion.
As far as I know, formsets always ignore forms that haven't changed. The test that fails with these lines removed is: https://github.com/django/django/blob/64e1a271f50d921a54388539b6ff7102a31c3d29/tests/admin_views/tests.py#L3858-L3902
Thanks for looking that up @timgraham, as long as have tests asserting that this is working as expected it should be fine.
This line can be removed :thinking:.
Please remove trailing comma and space.
`seprate` -> `Separate`, also trailing dot is missing.
Chop blank line.
You're right, thanks :+1:
IMO this line is unnecessary, and above `iter()` call can be removed.
Chop blank line.
Please wrap at 79 chars.
Please add trailing dot.
I think `continue` is unnecessary.
Comma before 'or' per https://en.wikipedia.org/wiki/Serial_comma.
This could be PostgreSQLSimpleTestCase I believe.
I would remove this temporary variable and move `split()` directly into loop ```python for part in field.split(LOOKUP_SEP): ```
I think this should probably be `"'ordering' refers to the nonexistent related field or lookup '%s'." % field` to match the other error messages.
To match other model `check()` tests, use `self.assertEqual(TestJSONModel.check(), [])`
related fields (add 's') non-related (add dash)
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
What if something else throws this `TypeError`? If we want to give a message like this at all, I think we need to find a better way of ensuring the case you mentioned is causing it.
Please collapse this down to a single line as it will easily fit in the 119 character line length limit. And do so for all of the other changes in this PR.
You can remove parentheses.
makes sense to me. if `self.join_cols` is a tuple, you don't even need those parentheses.
This branch doesn't seem to be tested.
Please add a docstring and remove this blank line. Also, this block is indent 8 spaces instead of 4.
This line can go in "else" of try/except/else since it isn't expected to raise an exception.
Only `list` and `tuple` only would be fine by me, you're right it's unclear the other default json types would be used.
I feel similarly. Maybe it's better just to add support for list and tuple as originally proposed. It's unclear to me if other types would actually be used.
I think a few basic types are enough to test. This isn't testing anything particular in Django as far as I can tell.
Simpler could be: ``` if JSON_CONTENT_TYPE_RE.match(content_type): try: return json.dumps(data, cls=self.json_encoder) except TypeError: pass return data ```
This can be a single line.
example -> data
Do we need to actually test the changelist_view HTML here? (It's a bit yucky.) * It was `get_queryset()` that was of interest, and that's tested above. * Presumably we can rely on `get_queryset()` being called by the view, since that's tested elsewhere.
just a thought, but I feel like this might be slightly easier to follow if the `if not isinstance(obj.manager_name, str)` portion wiere in the `else` portion of the `try/except/else` and the outer `if/else` were removed. Not a blocker, just an opinion :)
I guess `operator.itemgetter(1)` could be used here.
I think you could remove the example of an ellipsis in the docstring here and below.
I second Nick's proposal, but that could also the object of a following commit in another PR.
In Python3, `super()` is enough.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I think that this docstring should be simplified. There is no need to mention that this originated from the admin site.
Can we replace this with `ELLIPSIS = '…'` rather than some unrelated marker character? This makes it easier for consumers of the new paginator to use the correct character.
Thanks, I forgot about that.
I would use `deferrable` to be consistent with foreign keys.
IMO we don't need a `NOT_DEFERRABLE` constant. I would remove it and use `''` here and `None` in `UniqueConstraint.__init__()`), e.g. ```python constraint = self.sql_unique_constraint % { 'columns': ', '.join(map(self.quote_name, fields)), 'defer': defer or '', } ``` ```python class UniqueConstraint(BaseConstraint): def __init__(self, *, fields, name, condition=None, defer=None) ```
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint` (the same in all new tests).
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Good catch, I will remove it before final squash.
You can reuse `self.connection.ops.deferrable_sql()`.
If the connection becomes unusable at this point this will obscure the original exception.
Looks like this should live on the connection.
Manipulating `second` here is not strictly necessary, `first.save()` raises the `IntegrityError`. I believe the reason for `second` to be manipulated here is to show the difference with initially deferred constraints behavior. If that's the case, perhaps a function could show that the same code passes under initially deferred constraints but not under immediate constraints. Something like: ```diff diff --git a/tests/constraints/tests.py b/tests/constraints/tests.py index 067b38cfb6..b3257b6789 100644 --- a/tests/constraints/tests.py +++ b/tests/constraints/tests.py @@ -196,17 +196,17 @@ class UniqueConstraintTests(TestCase): first = Product.objects.create(name='First', shelf='Front') second = Product.objects.create(name='Second', shelf='Back') + def swap(): + first.shelf = 'Back' + second.shelf = 'Front' + first.save() + second.save() + with self.assertRaises(IntegrityError): with set_constraints(unique_shelf=IMMEDIATE): - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() first.refresh_from_db() self.assertEqual(first.shelf, 'Back') ```
I'd avoid allowing passing any form of raw SQL here, I'd suggest the constants are some form of slugs and that the actual SQL generation is handled at the backend level.
Given `initially_deferred=True` implies `deferrable=True` both flags are unlikely to be used together. `initially_deferred=True` translates to `DEFERRABLE INITIALLY DEFERRED` `deferrable=True` translates to `DEFERRABLE INITIALLY IMMEDIATE` That seems like a more consistent API with the rest of the ORM to me as we've generally avoided to expose flags pointing to constants. The only exception I can think of is `on_delete` but it's actually accepting callables and not some raw SQL defined as constants.
Might want to assert the message as well.
Any thoughts about using a `Deferrable(Enum)` for this purpose? ```python class Deferrable(Enum): DEFERRED = 'deferred' IMMEDIATE = 'immediate' ``` The same enum could be used to replace the `DEFERRED` and `IMMEDIATE` below and to enforce a valid value is passed to `UniqueConstraint.__init__`.
Not sure which of `defer` or `deferrable` makes more sense. The latter might be preferable if we choose the `Deferrable(Enum)` solution.
Sorry yes I meant `transaction` 🤦‍♂. I think there's `connections[using].in_atomic_block` or something like that.
I'm not certain `Warn` is the best word now that this is an `Error`, but I'm not sure how to phrase it instead.
The word `generally` doesn't add any value in my opinion.
We should use `override_settings` for this, to ensure we clean up after ourselves once the test is complete, avoiding breaking unrelated tests.
You can combine these tests.
) goes on the next line.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Not sure an intermediate variable is needed.
Please wrap these lines at 79 characters.
Please wrap docstrings at 79 characters. The second sentence is missing a period.
Again, I think keep alphabetical please.
Can you move this above `...checks.urls` please? (Presumably we're skipping isort here to stop it putting these imports amongst the other _actual imports_ but they're alphabetical within that.)
I'm thinking it might be better to use the approach in `test_caches.py` rather than repeating the error message here twice.
I'd go with `assertEqual(check_setting_language_code(None), [])`. That's a bit easier to debug in the case of a failure since the error will be visible as opposed to just, e.g. 1 != 0.
Use single quotes.
I think I'd make this an `Error` - I don't think translation works at all if this is wrong.
Does it work if you use `override_settings` for this too? That would be cleaner.
I'm not sure there's much value in testing two invalid codes instead of just one.
We can't add a reference to a project specific field in `models/base.py`
I think that you meant to put `'f'` here? Please also sort the values alphabetically.
Needs a blank line below to maintain the spacing.
Needs a blank line below to maintain the spacing.
I think this could be made more DRY: ```python function = 'phraseto_tsquery' if self.phrase else 'plainto_tsquery' if self.config: ... else: ... ```
I think `assertIsNotNone(req.session.get(CSRF_SESSION_KEY))` would better express the existence assertion here.
Avoid the conditionals woridng-- _The session is not modified if not necessary._
`language_code_re` might be a bit permissive for the original ticket use case, but Django has nothing better included. The difficulty here might be to find an appropriate POSIX locale regex, strict enough but excluding false positives.
Rephrase: `# Normalize locale strings input by the user.`
The log message makes no sense. You are trying to normalize (or rather kludge) something that should be a locale to be a language code/tag, to then convert to a locale. But you are saying the locale has been normalized to a language code/tag which is incorrect. A language code/tag is not a locale, and here we *should be providing a locale*, hence my misgivings already stated about this whole thing. Regardless, you probably want to do this: ```python def normalize_locale(original, stdout): """ Normalizes incorrect locale strings, e.g. zh-cn, zh_cn, ZH-CN are converted to zh_CN. """ corrected = to_locale(original.lower().replace('_', '-')) if original != corrected: stdout.write('Normalized %s to %s.' % (original, corrected)) return corrected ```
`out` would be clearer as `stdout`.
This is just not true - there is no "normalization" happening here. If anything it is an incredibly lax check that the locale folder name starts with two lowercase characters. This makes no guarantees.
Before adding the warning, I would have said that it wasn't really worth adding a whole function for this. It could have been wrapped into the list comprehension below.
``` """ QuerySet.count() on a many-to-many relation doesn't include an unnecessary JOIN. """ ``` Ticket references should be reserved for obscure issues (not needed here, I think).
Pass models.CASCADE as a positional argument for consistency with the rest of the test models.
Move the exists assertions to another test.
The optimization should also be disabled `if not connections[db].features.supports_foreign_keys`.
You could assert the `count()` value as well.
Could you create a separate test case so we don't have extra objects created for all the other tests? For that new class, setUpTestData can be used instead.
You'll want to only perform the optimization `if self.target_field.db_constraint` as `backends.tests.DBConstraintTestCase.test_many_to_many` shows. Also the filtering is wrong, it should be by `self.source_field` because now you're filtering by the primary key of the intermediate table's `pk`. ```python def count(self): # If the through's target field's foreign integrity is enforced # the COUNT can be performed against the through table instead of # INNER JOIN'ing the target table. if self.target_field.db_constraint: hints = {'instance': self.instance} manager = self.through._base_manager.db_manager(using=self._db, hints=hints) return manager.filter( **{self.source_field_name: self.instance.pk} ).count() return super().count() ```
Oh I realize that asserting against the results is problematic given all the engines we're testing against support foreign keys. In this case yes, using the same `JOIN` check against `captured_query` should do!
I would personally have broken this test in two (`test_count_join_optimization`, `test_exist_join_optimization`) and asserted against the results instead of testing the `constrained_target` implementation details but I guess this works fine.
Ditto about `__str__()`.
Ditto, I'd remove.
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
Might want to only test for `JOIN` presence as this wouldn't fail if `LEFT JOIN` was used.
Maybe: _"Ensure the last element is a field or a transform."_ :thinking:
Running `test_incorrect_field_expression_in_join()` without a fix, doesn't behave like it's described in the ticket on the PostgreSQL database. It raises: _"django.db.utils.ProgrammingError: operator does not exist: character varying = integer"_ IMO using `ceo__pk` instead of `ceo_firstname` should fix this issue.
This is clearly incorrect: * This will blow up if you don't have exactly two parameters. * If you had two, the output would probably be something like `?['a', 1]=['b', 2]` * The issue is due to the generator in the arguments to `str.join()`. * Why a list comprehension? I think it should remain a generator expression. A correct fix would be: ```python ('%s=%s' % (k, v) for k, v in params.items()), ```
Insertion order is maintained from Python 3.6 onwards so sorting is only required for 3.5: https://www.python.org/dev/peps/pep-0468/
I don't think we can rely on `kwargs.items()` to be ordered. I suggest using `sorted` to enforce an ordering.
You could just put `(#11154)` in the docstring.
Two things here: * The `s/klass/Model/` change is unrelated/unnecessary. It's arguably more readable but if we revert it, it reduces this diff to just this line. * This can be single-lined: it's 101 chars, or 100 with `klass`. (You don't need the trailing comma.)
Specifically, without the change to `contrib/auth/management/__init__.py`, `admin_views.tests.AdminViewProxyModelPermissionsTest.test_can_view` errors: ``` django.contrib.auth.models.Permission.DoesNotExist: Permission matching query does not exist. ``` Not instantly clear to me why we don't get 4 errors here. Shouldn't we expect that? It's only removing the change to the get_perm() helper in this file that we see 4 failures.
Leave the `.` (Makes the diff smaller if nothing else. But it's probably OK for it to be a fully-formed sentence. 🙂)
Why this refactoring? (Touches a lot of the other tests...)
I would keep this on multiple lines. IMO, readability is better with the multiline version.
Please add a trailing comma.
`fix_this` is misleading, because there is nothing to fix here.
Please remove temporary variable `actions`, also IMO it will be clearer to unpack `action` e.g. ```python names = [name for _, name, _ in obj._get_base_actions()] ```
Please remove the blank line.
Would `obj.__class__` not be more helpful? (That way I get the full import path, rather than just the name, which may not be unique.)
Please us single quotes.
This argument can be single-lined. (It's only 111 chars so. Shorter if using `obj.__class__`)
I might just call `first()` here too. (That way you can drop the `get()` later...) ``` fan = Fan.objects.annotate(fan_for_day=Cast("fan_since", models.DateField())).first() ```
Since `fan_since` is None at this point, the test cannot pass! Same below.
I'd be to test `is_dst=True` as well!
Update the test to use something that's not serializable.
Using -> Use add period
case -> cast in all test names
`).values()` on next line
line saver? ``` format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' extra_context['format_string'] = format_string ```
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
Ideally this would be passed as a parameter instead of being baked into the SQL. Maybe adding a `%%s` placeholder and inserting the format string at `params[0]` would work? ```python template = "strftime(%%s, %(expressions)s)" sql, params = self.as_sql(compiler, connection, template=template, **extra_context) format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' params.insert(0, format_string) return sql, params ```
Is there any need for these separate methods? I could understand if it were required for testing, but that doesn't seem to be the case. If we are to keep them separate, could we not do the following to avoid the nested method calls? ```python is_ccw = property(_is_ccw_py if geos_version_tuple() < (3, 7) else _is_ccw_geos) ```
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
counterclockwise (no dash)
Drop the " or not".
chop blank line
```python """Return whether this linear ring has counterclockwise orientation.""" ```
Simon, did you fix this issue in your branch? Feel free to push an update here.
@Ian-Foote I discovered an issue with this approach is that it will include inlined named foreign key and primary key constraints as well. https://www.sqlite.org/syntaxdiagrams.html#table-constraint Django doesn't create such constraint itself but usually the introspection module is supposed to be able to deal with any form of schema. I'll include the adjustments in a following commit. Thanks for the parsing logic by the way, this is really neat.
yeah please do, that'll save me doing the rebase.
@timgraham I wasn't sure how to push to this branch. Here's the commit to cherry-pick https://github.com/django/django/commit/4a89f24b9bb7a2b2b9a5a4d143fa80ad3871ce88
Cool I'll do that later tonight.
I know what's causing it. Let me rebase #10337 on top of this branch. That's where the `token.match(Token.Keyword, 'UNIQUE')` should live anyway.
Thanks. There might be a bug because when I rebase https://github.com/django/django/pull/10337, `self.assertIn('unique_name', constraints)` fails on SQLite.
Please remove unnecessary space i.e. `(validator,)`.
`call_count` isn't really necessary any more, as accessing `user` or `password` would be an `AttributeError` if the function hadn't been called, but this is a minor issue
This needs to be done at `__init__` as well, right now it happens at import time.
`set_urlconf(None)` is probably more appropriate, it just resets to a 'blank state' which is where Django starts
Maybe I missed sth but why not add this inside the `_create_index_name()` :thinking: . Probably other indexes names are also affected.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Could use double-quotes for these strings only to avoid the backslash while keeping the diff noise small.
`return (.... >= 12, 2)` The unused `oracle_version` property could be reworked to return the complete version tuple and then used here.
One space after period.
the restriction in Oracle 12.1
This should be something like `self.assertEqual('migrations\n (no migrations)\n', out.getvalue().lower())` (perhaps adjusted a bit to match the output of showmigrations for other apps) (no SystemExit).
This should be `self.assertEqual('migrations\n (no migrations)\n', out.getvalue().lower())` as in the above test (no SystemExit).
I don't think this first test situation should be deleted and the new behavior should match the new test cases (stderr instead of CommandError) -- `test_showmigrations_unmigrated_app` should be updated similarly
(was fixed in b916c27f9a83c019ff85132712267508f126ca83)
I would put this in the one test they're used in unless you think they have potential to be used in future tests.
Personally yes. (But maybe the examples in the docs will be enough)
I think `if not hasattr(...)` and raising an exception would be more in line with Django's style.
You can omit the tuple and just put this on the previous line.
I've solicited input: https://groups.google.com/d/topic/django-developers/7bZbYVV6hg4/discussion
You preach to a convert! However it's not about not being able to encode in UTF-8, but about the common file encoding on some platforms, especially Windows. I'm not using Windows for a long time now, so I can't say if UTF-8 is a common encoding nowadays or if it needs a special handling (say change a program preference) in most Windows text editors.
Here I would also limit the change to https.
look, you added unique true to last name not in email
We use hanging indent: ``` indexes = [ constraint['columns'] ... ] ```
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Was going to suggest the same, but see that @charettes got there first. > Yes, but IMHO it's worse for readability. Fair enough.
I guess we could `return list(itertools.chain.from_iterable(admin_form))` as well. https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable
Looks like this should have used `self.using`, I'll submit a PR for it.
Not sure it's worth creating a possibly large list for the sole purpose of fetching the first object. Maybe `deque([], 2)` could be used of the following logic used below ```python if len(self.data) == 1 and len(instances) == 1 and self.can_fast_delete(instances[0]): with transaction.mark_for_rollback_on_error(): count = sql.DeleteQuery(model).delete_batch([instances[0].pk], self.using) return count, {model._meta.label: count} ``` That's possible because `len(self.data) == 1` implies `model` and `instances` were necessarily assigned here.
this would be better as a multiline if
Python 3.7 provides `nullcontext` so I suggest this be at least called `nullcontext` if not placed in a backportsy place so it can be dropped when we support only 3.7+ https://docs.python.org/3/library/contextlib.html#contextlib.nullcontext
Python 3.7 provides `nullcontext` so I suggest this be at least called `nullcontext` if not placed in a backportsy place so it can be dropped when we support only 3.7+ https://docs.python.org/3/library/contextlib.html#contextlib.nullcontext
Well spotted :+1:
```python if not meta.parents: context_manager = transaction.mark_for_rollback_on_error(using=using) else: context_manager = transaction.atomic(using=using, savepoint=False) ```
use a comma instead of "-", it will read better
better to do `if alternatives: ... else: suggestion = "."` (on multiple lines) so `suggestion` is assigned only once
yeah you got it
Not sure this is desired, as it will create a `DjangoTranslation` instance for each `translation` call while the previous code wasn't. As you can see above `DjangoTranslation.__init__` isn't cheap.
IMO we do not need this hook.
Please chop blank line.
I do not think it is important and I'm not sure if it is possible :thinking:
I don't think we need these two lines: ```python if not self._is_db_exists_error(e): raise ``` because if an exception other than `"database exists" (1007)` is raised in `super()._execute_create_test_db()`, then tests will be stopped earlier by `sys.exit(2)`.
Maybe this could be a module constant so as not to repeat it 3 times.
``` # Show a warning if the setting is used outside of Django. # Stack index: -1 this line, -2 the caller. ```
`The expressions argument is mandatory.` -> `At least one expression is required to define an exclusion constraint.`
`name` and `expressions` shouldn't be optional: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ```
Chop this line.
You can also drop the parentheses :wink:
Are we always going too assume a GiST index by default as currently implemented or force people to choose consciously? If the former, then we need not include `index_type` here when it is the default value.
Most of these operators overlap with range lookups, I think we should use the same names for consistency, i.e. - `LESS_THAN` -> `LT`, - `GREATER_THAN` -> `GT`, - `LESS_THAN_EQUAL` -> `LTE`, - `GREATER_THAN_EQUAL` -> `GTE`, - `IS_CONTAINED_BY` -> `CONTAINED_BY`, - `NOT_EXTEND_LEFT_OF` -> `NOT_LT`, - `NOT_EXTEND_RIGHT_OF` -> `NOT_GT`, - `STRICTLY_NOT_EXTEND_LEFT` -> `FULLY_LT`, - `STRICTLY_NOT_EXTEND_RIGHT` -> `FULLY_GT`, - `IS_ADJACENT_TO` -> `ADJACENT_TO`. Maybe we can also reuse this operators in lookups :thinking: , e.g. ```python @RangeField.register_lookup class FullGreaterThan(lookups.PostgresSimpleLookup): lookup_name = 'fully_gt' operator = RangeOperators.FULLY_GT ```
I think we can use the same check like in `UniqueConstraint`: ``` if not isinstance(condition, (type(None), Q)): raise ValueError('ExclusionConstraint.condition must be a Q instance.') ```
Is the first element here meant to be a 1-tuple? You're missing the required comma.
Do we expect users to use strings like `&&` and `&` directly anywhere else? It seems like we're exposing an implementation detail we'd usually hide.
I think the values provided need to be validated. It would also be nice to accept and parse a string containing both bounds... But that gets me thinking that this current approach is rather verbose...
Ok. Either way we need to lose the trailing comma.
All tests work without it that's why I'm wondering if we need it.
It will be `django.contrib.postgres.constraints.XXX` but I don't think that's an issue for core constraints we return `django.db.models.XXX`.
Should we be manually substituting parameters here or leaving it to the backend? This feels like SQL injection territory to me, but I could be wrong...
Remove the blank line.
It is more usual to use `i` or `idx` than `inx`. With `i` this may fit nicely in one line. Some sort of string formatting is preferable too.
I'm not sure there is any benefit assigning this local variable here when it is only used once.
I don't think we need the extra assignment here as this is only used once.
I don't think we need the extra assignment here as this is only used once.
Remove the blank line.
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
No point in assigning to `path` when used once. Also this doesn't seem right. I think you meant `__qualname__` rather than `__module__`? Which probably also means some tests are lacking...
Prefer a set to a tuple here and order elements alphabetically.
This shouldn't have the trailing comma which is making it a tuple in a tuple. I'd go back to using a list...
It's safe IMO.
It's fine to manually substituting parameters here.
Ok. Thought it was worth asking the question. Better safe than sorry. :man_shrugging:
Also make the comparison case-insensitive, i.e. ```python if self.index_type.lower() != 'gist': ```
Also here: ```python if self.index_type.lower() != 'gist': ```
Yeah, just mentioned as this was pointed out to me in the past: https://github.com/django/django/pull/11059#discussion_r266598250
From https://www.postgresql.org/docs/12/sql-createtable.html#SQL-CREATETABLE-EXCLUDE only GiST and SP-GiST are supported in practice.
We could even do this in advance in a separate commit/PR (introducing `RangeOperators` with docs and using them in lookups) :thinking: .
This makes we wonder if passing `expressions` as a list of 2-element tuples would be more appropriate. I guess the current break down of `expressions` and `operators` is more coherent with the actual expressions interface and the exclusion constraint syntax.
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
IMO it will me more readable to move `base` outside, also we resolve `F()` expressions twice (line 28 & 29), so maybe, e.g. ```python if isinstance(expression, str): expression = F(expression) if isinstance(expression, F): expression = base.resolve_expression(query=query, simple_col=True) else: expression = expression.resolve_expression(query=query) ``` Moreover I think we don't need to iterate twice over the expressions: ```python for expression, operator in self.expressions: ... expressions.append('%s WITH %s' % (sql % params, operator) return expressions ```
Why we don't use `super().deconstruct()`? ```python def deconstruct(self): path, args, kwargs = super().deconstruct() kwargs['expressions'] = self.expressions if self.condition is not None: kwargs['condition'] = self.condition if self.index_type != 'GIST': kwargs['index_type'] = self.index_type return path, args, kwargs ```
I don't see a reason for the `order_by` here.
Use a set since it's only used for containment checks.
This docstring needs rewording. It should focus on what the function is doing and not on what the caller should do with the returned value.
This seems overly complicated and probably also wrong with tables that are JOIN'ed more than once as the following JOINs will have aliases that are not `db_table`. ```python > from django.contrib.auth.models import User > User.objects.filter(groups__name='foo').query.alias_refcount {'auth_group': 1, 'auth_user': 1, 'auth_user_groups': 1} > User.objects.filter(groups__name='foo').filter(groups__name='bar').query.alias_refcount {'T4': 1, 'T5': 1, 'auth_group': 1, 'auth_user': 2, 'auth_user_groups': 1} ``` Also you probably don't need to build the `from_to_tables` set as it's really inneficent. You should use a loop and exit the function as soon as a matching alias is found.
Use set literals, `{...}` here and above.
We usually only keep reference to ticket in tests when it's hard to express the complexity of the issue in Python. In this case the issue and resolution is pretty trivial so you can drop it entirely. `git blame` and the commit message should do a good job at pointing at the ticket if it's required in the future.
remove it from here.
Avoid using `Test that` prefixes in docstring, this is necessarily testing something as it is a test. ``` Teardown functions are run when run_checks raises SystemCheckError. ```
You current approach will silence any `SystemCheckError` raised by `run_checks` if `teardown_databases` and `teardown_test_environment` fail. What about ```python run_failed = False try: self.run_checks() result = self.run_suite(suite) except Exception: run_failed = True raise finally: try: self.teardown_databases(old_config) self.teardown_test_environment() except Exception: # Silence teardown issues if an exception was raised during runs to avoid # shadowing it. if not run_failed: raise return self.suite_result(suite, result) ```
You can probably simulate that with having `run_checks` raise a `SystemCheckError` error instead.
Exceptions on teardown are surfaced if no exceptions happen during run_checks.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
I know I suggested it but I think _shadowing_ is the correct term.
Use `gettext` instead of `ugettext`
Use form.changed_data directly and remove the alias as recommended by Tim.
I wonder if testing the `LogEntry` items instead of calling the view would be a bit more precise testing. To be evaluated.
I don't think this and the lines below are useful. We can simply use `force_login` in the test as far as the login process itself is not significant in that test.
I'm not sure special-casing the password field is a good idea, as you might as well have user code presenting such cases, and then the function would crash badly. I think a try/except clause catching the KeyError when f is not find in form.fields, defaulting to the raw field name in that case, would be a safer approach.
It used to be that way (in Python 2 era). Now gettext is an alias to ugettext and the latter will be deprecated in the future.
Isn't that going to inhibit the previous lines you have added ? Setting sub_message['changed']['fields'] over again twice in a row. Thanks for sharing some of your insight.
Didn't you have a version of your patch where you called a method to get the labels? I guess we might have the same issues here than above (label=None or field name not in fields).
`and Historique` does not look right. It should give the untranslated `History` here (we are outside of the override).
I think the test is not in the right class (`AdminViewPermissionsTest` should be limited to test permission-related stuff). We may need a new test class.
I think reorganization of the admin views tests deserves its own patch outsie of this ticket.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
I think I would put `change_message = []` below the new code so it's not separated from where it's used.
This alias doesn't seem needed as it's only used once.
If there's a purpose for `label_form_field` at this point, I can't easily spot it.
Test -> Tests (and I suggest a new `test_history_view.py` file since this file is quite large already.
`state=state` is more typical than assigning `state_id`.
Adding new code in a good location is fine.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
I'm not sure what you have in mind, but `django/contrib/admin/utils.py` doesn't contain any public APIs (and this code doesn't seem to be admin-specific). I think to make it a public API (e.g. in django.forms) we would want to see it used outside the admin.
Nope. In the second case `sub_message['changed']['fields']` is fetched again. This could certainty be made less clunky though as `sub_message['changed']['fields']` is referenced 4 times in 6 lines...
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
The temporary variable could be avoided here by merging this line into the one using the variable below.
Remove this blank line.
Extra wrapping and `str()` call are unnecessary: `… for city "%s".' % city`
Will this statement will fit on a single line? (119 characters is permitted.)
Will this statement will fit on a single line? (119 characters is permitted.)
Perhaps combined into a single pass, something like... ``` sub_message['changed']['fields'] = get_text_list( [gettext(field_name) for field_name in sub_message['changed']['fields']], gettext('and') ) ```
Remove ticket number. Capitalise first word of sentence.
I believe this line can live within the with statement below without issue.
This `except` block is never tested in the `formsets` case.
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
You can drop the `.all()` here.
```suggestion if self.migration_name and not self.migration_name.isidentifier(): ```
I feel like it's ok.
Avoid using conditional wording in test docstring, also use the identifier wording.
You can completely drop this regex search now, it's covered by the `isidentifier` check.
I think the default should be True so that database backends have to opt out rather than opt in.
Odd. In all cases we avoid doing unrelated style changes in such feature PR so I'd still revert.
The important assertions here is that the operation changes were rolledback as well. You want to make sure to call `self.assertTableNotExists('migrations_foo')`.
You want to run this test only if the backend has `can_rollback_ddl` instead. The reason for this is that when the feature is false the operation and the record won't be performed in a transaction and your test will systematically pass. https://github.com/django/django/blob/58d1e9aa8ab505912389e7cd019a6f21785ad4bf/django/db/backends/base/schema.py#L86-L100 That should be `@skipUnlessDbFeature('can_rollback_ddl') instead.
Migrations are applied and recorded atomically.
I'd name this `APPLY_RECURSION_ERROR_MESSAGE` or at least mention _apply_.
I'd say _unapplying_ is a form of _applying_? My main concern is that is attribute is not bound to any method right now, it could be the message of a recursion error happening during the `mutate_state` method for example.
@arthurio I think doing the clone here makes sense. You could have conditionally done it in `emit_post_operation_signal()` only if there was some `post_operation` receivers to avoid the `clone()` if it wasn't the case but given we're planning to add a few receivers for `auth` and `contenttypes` and at least one of them is going to be installed in 99% of projects I don't think it's worth doing the optimization.
Could these functions be defined as methods instead? It feels like it would make the execution flow easier to follow and be more in line with the usual coding style; _private_ methods are usually defined instead of relying on internal functions.
This should always be true if the receiver is connected with `sender=migrations.RenameModel` as it is right now.
@arthurio sorry for the delay here. We really want to be executing operations inside the loop as you suggested here and referred to as LNR, DFS. Else, as you've described, you could end up in a situation where the content types and permissions are missing.
@arthurio yeah I'd suggest we stick to only `post_operation` for now because we have a use case for it. Adding a _pre_ signal could be useful but adding features for the sake of it only complexify the implementation for unknown benefits.
Number prefix could be done separately as other files are affected. (And I think `init` (method name) is fine rather than `initialization`.)
It looks like the `lon_lat()` and `coords()` methods are no longer tested directly.
I think in the first version of the patch you had something like `assertIsInstance(lat, float)` which seemed better to me.
OK, so after #11490 `add_select_col()` works properly because `self.query` is created by a compiler so it is not reuse and doesn't mutate combined queries.
I've submitted patch https://github.com/django/django/pull/11490.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
This causes a test failure: ``` FAIL: test_order_raises_on_non_selected_column (queries.test_qs_combinators.QuerySetSetOperationTests) ```
capture its arguments
OracleDbshellTests ("TestCase" implies this is meant to be subclassed.)
We should find a way to reduce the duplication between the two blocks. What about ```python form = 'int' if isinstance(value, int) else 'hex' try: return uuid.UUID(**{form: value}) except (AttributeError, ValueError): raise exceptions.ValidationError( self.error_messages['invalid'], code='invalid', params={'value': value}, )
This approach is problematic, this will cause a double roudtrip to the cache server. A better approach would be to pass a _sentinel_ object to `get` that is different from `None` so you can differentiate between the two.
We usually define these a `cached_property`s on the `DatabaseWrapper` objects. https://github.com/django/django/blob/0b1b1eac78362b3aff9b41e9af350bc1d0d7e41e/django/db/backends/mysql/base.py#L328-L339
Using the version number should be fine!
We usually define these on `DatabaseWrapper` objects, that is `django.db.backends.sqlite3.base.DatabaseWrapper`. You'll be able to refer to it using `self.connection.sqlite_version`.
Use single quotes for all strings (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
This should be: ```python try: cursor.execute('SET standard_conforming_strings TO ON;') ... finally: cursor.execute('...') ``` so that if the assertion fails, the "tear down" in finally still happens. The second query shouldn't assume the original value of standard_conforming_strings is "on".
) goes on the next line as in other tests
Remove try/except as that hides the original exception and makes debugging more difficult (see c9ae09addffb839403312131d4251e9d8b454508).
Chop blank line.
Docstrings should state the expected behavior and omit prefixes like "Make sure" since all tests make sure of things.
IMO we should add to operations a new method e.g. `query_sql()` with base implementation (`BaseDatabaseOperations`): ```python def query_sql(self, sql, params): return sql % params ``` and use `mogrify()` on PostgreSQL: ```python def query_sql(self, sql, params): with self.connection.cursor() as cursor: return cursor.mogrify(sql, params).decode() ```
OK, so here I'm expecting to just call a backend function — `as_sql_str()` or something. (_Naming!_) * The base implementation would just do the existing `sql % params` — although that's the suboptimal(?) "return something that looks valid but isn't" strategy discussed above. * Then each backend overrides appropriately. The `mogrify` call is then just in the Postgres version. ([There's a wontfix on Python for adding similar to pysqlite](https://bugs.python.org/issue9506).)
Can we make these multi-line, such as... ``` 'SELECT "postgres_tests_hotelreservation"."id", "postgres_tests_hotelreservation"."room_id", ' '"postgres_tests_hotelreservation"."datespan", ...' '...' ``` ...and so on.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
This should be `models.E028` as `E020` maps to ``The `<model>.check()` class method is currently overridden.``.
Use [`model._meta.label`](https://github.com/django/django/blob/f091ea35150d95fc6732bbf0c27b971dd445509a/django/db/models/options.py#L134-L136) instead of `__name__` as `label` is namespaced by `app_label` which will make it easier to identify collisions between apps. Also you only want to consider [managed models](https://docs.djangoproject.com/en/2.1/topics/db/models/#differences-between-proxy-inheritance-and-unmanaged-models) here so you don't want to add values to `db_table_attr_map` in the case of `not model._meta.managed`.
It's not worth doing an existence check or a double list construction. Simply iterate and `continue`. ```python for db_table, model_labels in db_tables.items(): if len(model_labels) == 1: continue ...
It cannot possibly be `< 1`, else the key wouldn't be in the dict. Using `<= 1` instead of `== 1` only makes it more confusing IMHO.
The second set of single quotes look odd to me.
or... ? ``` if len(model_labels) != 1: errors.append(...) ```
I feel like `obj` should be `db_table` here, `model` is a reference to the last value of the `for model in models` loop above and is completely unrelated.
Good catch with proxy models, completely forgot about them.
Not a big fan of the variable name. What's the rationale behind the `attr` suffix? I feel like `db_table_models` or something similar would make more sense.
I guess you could use `self.assertIs(child.parent, parent)` to make sure the object was not recreated as well.
That'll create unnecessary empty dicts if empty data is passed.
Use single quotes. Capitalized "unknown". Add "Choices are: ...".
The master branch only supports PostgreSQL 9.4+.
The blank lines aren't needed.
Ticket references should be reserved for obscure issues (not needed here).
This would be a good opportunity to use `subTest`.
I don't think this is necessary? It should default to an empty string.
```suggestion self.assertCountEqual(queryset, [self.jack, self.john]) ```
```suggestion self.assertCountEqual(queryset, [self.guitar_book]) ```
```suggestion self.asserCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
```suggestion self.assertCountEqual(queryset, [self.guitar_book]) ```
```suggestion self.assertCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
This test should verify the correct results of the Filter rather than just checking that an exception isn't raised.
You didn't want to capture the response content and assert that here? (Just wondering your thoughts...)
Good. Super. Thank you!
I guess you should follow the indentation of the other tests.
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
It also says: > It may also be known that project A follows semantic versioning, and that v2 of ‘A’ will indicate a break in compatibility, so it makes sense to not allow v2: I guess the real question is then whether `sqlparse` really uses semantic versioning, and since it's "Development Status :: 5 - Production/Stable" at 0.2.4 potentially not. You're probably right to err this way, let's leave it as-is. :)
I'd say it's less likely to cause problems if Django pins `<1.0.0` for the time being, and then if there is a breaking release, users without very good pinning won't be affected. Django can always issue a patch release to move the pin if a new sqlparse comes out and it is compatible.
I think you should leave it as it seems to be the docutils interface for these methods. The `if content is None:` block can go though.
It also doesn't make sense to pass them to the admin change view though, since prepopulating only works in the add form.
`# For backwards compatibility with Django < 2.2.`
Please check test coverage carefully. I don't see any tests failing with this line and the one below it removed. I didn't check the rest of the changes.
Your IDE is getting it wrong. `process_exception_by_middleware` is expected to be called within a an `except` block.
I think we can run this only if database has native UUID field i.e. `connection.features.has_native_uuid_field` :thinking:
Might want to only run `replace` on `str` params or use `str(param).replace('-', '')`.
Please use a db-feature `@skipUnlessDBFeature('has_native_uuid_field')`.
Should `params` be a tuple? i.e. ```python params = tuple(param.replace('-', '') for param in params) ``` Just want to make sure we avoid issues such as the one in #11784.
`'''` -> `"""`
The [`Subquery` wrapping should not be necessary here](https://github.com/django/django/blob/024abe5b82d95ee60cb18a77ebf841ad715467fa/tests/queries/tests.py#L2057-L2069).
The new test covers the other change (which was already tested by the other test changes) but I still don't see any failures with this line reverted.
Wrap docstrings at 79 characters.
chop blank line
Not related to this changes but this should probably be a `set` since it's only used for containment checks.
Ditto with `existing_tables`.
I still don't like the `issubclass_skip_raise_exception` name. It just feels cumbersome. I suggest: ``` def _issubclass(cls, classinfo) """ issubclass() variant that doesn't raise an exception if cls isn't a class. """ ``` I think the purpose is clear enough.
Wrap lines at 79: ``` "The value of 'list_filter[0]' refers to 'RandomClass', which " "does not refer to a Field.", ```
No need for trailing , in lists. That only applies to tuples. You can use lists throughout the patch.
Please remove the leading blank line in all tests.
It might not be possible. As far as I could tell, the original patch just did a find/replace without any analysis.
I think can be a separate test method, it doesn't seem to depend on anything above.
No trailing whitespace after , (there was a past PR that removed all cases like that)
Follow existing style and don't include a blank line at the start of each test.
Don't see a test failure with this reverted.
Is this required? Don't see a failing test with it reverted.
Don't see a test failure with this reverted.
I'd change the comma to a period.
A test is missing to show why this change belongs in the PR.
`contrib.postgres` stuff shouldn't go outside of `tests/postgres_tests`. That said, the related modules stuff should be tested here by recreating a similar setup with a custom field.
Iterating over `sys.modules` is going to be significantly slow for any medium sized Django projects.
This is the sole `BaseSerializer` subclass that returns `None` on `serialize` failure.
This is not performing any identity check so if a related module happens to have a class the same name (it's not that uncommon to have classes with the same name namespaced in different modules) then it would be considered to be the same class.
The fact that you have to call `serialize` to determine if the serializer is appropriate differs from the pattern used with the other ones. To me that's a code smell that hints at the fact we're abusing the serializer pattern here.
You can probably use `SimpleTestCase` with `allow_database_queries = True` since this isn't performing any database level alteration. That should save you two 4 queries (`BEGIN; SAVEPOINT, ROLLBACK TO; ROLLBACK`).
`atomic=False` would save you some commit related queries as well.
That makes me wonder if making `effective_default` a class method and allow passing of `connection` would make it more easily testable. It's kind of a shame that we have to create a database connection and transactions to test this simple method.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
This can be single-lined.
`ChoiceFormSet` -> `ArticleFormSet` You mixed `Article` with `Choice` in few places.
I don't think that creating a custom `ArticleForm` or setting `initial` data is required for this test, we should be able to simplify this, e.g. ```python def test_formsets_with_order_custom_widget(self): class FormSet(BaseFormSet): ordering_widget = HiddenInput ArticleFormSet = formset_factory(ArticleForm, formset=FormSet, can_order=True) formset = ArticleFormSet(auto_id=False, prefix='articles') self.assertHTMLEqual( ... ```
I would move above three lines to the `assertHTMLEqual()`, i.e. ```python self.assertHTMLEqual( '\n'.join(form.as_ul() for form in formset.forms), ... ```
We could keep tests more DRY and use loop (maybe with `subTest`) e.g. ```python def test_formsets_with_order_custom_widget(self): class OrderingAttributFormSet(BaseFormSet): ordering_widget = HiddenInput class OrderingMethodFormSet(BaseFormSet): def get_ordering_widget(self): return HiddenInput for formset in (OrderingAttributFormSet, OrderingMethodFormSet): ArticleFormSet = formset_factory(ArticleForm, formset=formset, can_order=True) ... ```
Unless `flake8` complains, I would take this blank line out.
Use `self.assertIs(wrapper.is_hidden, True)` since assertTrue passes for bool(value) is True.
I left a reply on the trac ticket addressing some of your questions. It might be worthwhile to post your questions there as well.
For Pillow it would make sense to specify version `>= 5.2.0` as the [support matrix](https://pillow.readthedocs.io/en/latest/installation.html#notes) for that version lines up with Django pretty well.
`tests_require` is deprecated in [setuptools](https://setuptools.readthedocs.io/en/latest/setuptools.html#new-and-changed-setup-keywords) since [41.5.0](https://setuptools.readthedocs.io/en/latest/history.html#v41-5-0) (27 Oct 2019). (It is also being unused by Django anyway.)
This can be simplified to the following to reduce the number of `isinstance()` calls when finding a serializer: ```python MigrationWriter.register_serializer( (DateRange, DateTimeRange, DateTimeTZRange, NumericRange), Psycopg2ExtraSerializer, ) ```
This should verify the output.
You should also add an assertion for the imports provided in the second value of the tuple.
Please test for all of the extra registered range types - you should be able to make use of `self.subTest()`.
You can skip this test on MySQL with `@skipUnlessDBFeature('allows_auto_pk_0')`.
What about testing with a non-sequence primary key instead so we can get MySQL coverage as well? I was initially thinking about suggesting the use an empty string which is also falsy but we'd loose Oracle coverage.
The `Order` model should do https://github.com/django/django/blob/594cf9bff82e4d840862c2526c29d725d5bf07f0/tests/queries/models.py#L592-L599
IMO we can remove this line.
Maybe just :thinking: : ```python falsy_pk = 0 if connection.features.allows_auto_pk_0 else '' ```
Ahh ok nevermind :smile: I misunderstood. It will work for primary keys that are not auto fields on MySQL :+1:
Please use single quotes.
You have to set up the iterator in each loop executed by `%timeit` otherwise it only consumes on the first loop after which it is empty... I guess it depends on the size of the response being consumed. If you used `HEAD` on a response which was reasonably large, then the plain for loop is going to be slower.
Perhaps the following? ```python collections.deque(self.result, maxlen=0) # consume iterator quickly. ``` Some performance numbers: ``` Python 3.7.0 (default, Sep 15 2018, 19:13:07) Type 'copyright', 'credits' or 'license' for more information IPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: from collections import deque ...: from itertools import repeat ...: n = 10000 ...: %timeit -n1000 [__ for __ in repeat(0, n)] ...: %timeit -n1000 for __ in repeat(0, n): pass ...: %timeit -n1000 list(repeat(0, n)) ...: %timeit -n1000 deque(repeat(0, n), maxlen=0) 195 µs ± 5.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 74.3 µs ± 204 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) 53.2 µs ± 4.66 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 43 µs ± 428 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) ``` So even calling `list()` seems better than an empty loop, and `collections.deque()` is fastest because it is written in C.
Thanks for checking :+1:
This doesn't feel right.
@maguayo do you have a better suggestions on how to consume an iterator without materializing it? That seems the most elegant way of doing it to me.
`article_inline_formset` -> `formset` would be fine, I think.
Should it consider "has_delete_permission" also? Maybe a method that encompasses this condition would help readability and ultimately be used elsewhere.
This looks simpler to me: ``` return ( inline.has_delete_permission(request, obj) and '{}-{}-DELETE'.format(formset.prefix, index) in request.POST ) ```
I'd suggest: `user_deleted_form` `if user_deleted_form(...)` looks more readable.
chop blank line
`# Valid POST creates a new article.` (instead of 'New Article should be created.' message)
more than one automatically generated field.? sounds better and more natural with the changes.
I think we should add `SmallAutoField: (-99999, 99999)` to the `DatabaseOperations.integer_field_ranges` in the Oracle back-end.
I don't think that we won't have this restriction anymore for non-integer auto-field (at least not in all databases because PostgreSQL and Oracle support `RETURNING` clause with multiple fields). Let's leave `auto-generated` for now.
`AutoFieldMixin.validate()` is missing , I think we should restore `AutoField.validate()` implementation, i.e. ```python def validate(self, value, model_instance): pass ```
Maybe: ```python if internal_type in self.integer_field_ranges: return self.integer_field_ranges[internal_type] return self.integer_field_ranges[override.get(internal_type)] ```
If the line length bothers you, I think dropping "database" would be fine.
no dash for "test suites" and similarly I would write "create view" and "create materialized view" with quotes instead of dashes.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
```python if ordering_fields.issuperset(field.attname for field in fields): ```
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
```python total_ordering_fields = {'pk'} | { field.attname for field in self.lookup_opts.fields if field.unique and not field.null } ```
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
"ordering, rely" (add comma & chop "we")
add trailing comma
All the blank lines don't add much for me but I won't insist.
Fine. They're gone. 😀
https://github.com/django/django/pull/10692/commits/deadb225ccb703b24ee685e079930541149e2370 (which is a `fixup`)
OK. That makes sense. Let me have a go at re-writing that.
The hook idea was twofold: 1. Encapsulate the logic, to make the flow ~~clearer~~ easier to read. 2. Allow overrides, for say a DateTimeField. (Not really unique but often good enough...) and so on.
Errr... 😃 it’s part of the old ticket in my view. (That may not be canonical.) A new ticket might help in case we need multiple reviews, but having come across this today, I kind of thought it would be good to get in for 2.2 if that’s realistic on you end. Tl;dr: don’t really mind. My initial thought on the code structure would be to go for the minimal change here. Add the helper (even private) to encapsulate this logic, and call it quits. We can always allow a restructuring later. However, if you have ideas for something better I wouldn’t object. 🙂
Could everything from here be extracted into a helper function? So we'd just pass in the `ordering` and return whatever came back. (This would give a hook for opt-out/customisation that both 17198 and 29943 hint at.)
I'd remove this blank line.
I think this should use `ordering` because `expected` will already appear in the output if the assertion fails.
We try not to include ticket references in docstrings unless the ticket has a lot of context that the test cannot convey.
Stick with single quote strings.
Do the tests pass if you completely remove this `if` statement? That looks like it would be more appropriate in this case as I can see how it can ever be `True` at this point.
Unless you can include a test showing why `force_text` is needed, use `str` instead. Following the removal of Python 2 support, there are many commits removing `force_text()` usage.
Could be reduced to `yield from iter(clone._result_cache)`.
It'd be great if we could avoid this and all of the following `if not self._prefetch_related_lookups` e.g. ```python # Avoid materialization of chunks of objects if no prefetching must take # place. if not self._prefetch_related_lookups: yield from self._iterable_class(self, chunked_fetch=use_chunked_fetch, chunk_size=chunk_size) return ``` That'll make sure the exact same behavior is preserved when no prefetching is involved and allow you to revert the `test_server_side_cursors.py` changes.
Could use boolean `not clone._result_cache` check as well.
This conditional clause can be dropped once we perform an initial `not self._prefetch_related_lookups` as described above.
Looking back at it this can probably all be reduced to ```python iterable = self._iterable_class(self, chunked_fetch=use_chunked_fetch, chunk_size=chunk_size) if not self._prefetch_related_lookups: yield from iterable return iterator = iter(iterable) while True: results = list(islice(iterator, chunk_size)) if not results: break prefetch_related_objects(results, *self._prefetch_related_lookups) yield from iter(results)
Keep using single quote strings.
You can pass `verbosity=0` instead to completely silence the command instead of creating an unused `StringIO` container.
Given these methods are all wrapped in `assertTrue` calls they should probably be converted to `assert_all_exists` and `assert_none_exists` that perform the assertion themselves. e.g. ```python def assert_all_exists(self, dir, langs): self.assertTrue(all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ))
Ditto ```suggestion return all( not os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
Convert to a `set` since it will only be used for containment checks.
Just on this test case: would it work to group the tests using `subTest()`? (They seem quite repetitive.)
Under which circumstances is this useful? I'd expect that value to be correct all the time and if it start with a blank so be it.
@jrwdunham I think you can drop this if, yes
Does this check make sense now that we only handle it if it starts with a relative path? (ie if the prefix where there it would start with a slash anyways)
Removed, see #11564
@jrwdunham I'm not an expert here, but from what I read the true assumption is that `SCRIPT_NAME` **never** ends with trailing slash. So in case you do not have subfolder, `SCRIPT_NAME` should be just empty/unset.
it is not obvious that `test_sqlite` file is base settings when you just look in file tree, I suggest moving base settings file to `base.py` and also do you think naming test settings files like `test_mysql.py` is redundant? Why not just `mysql.py`
Single quotes please.
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
`# Avoid infinite loop if there's a cyclic reference (#29393).`
I think this could be increased to 10 just in case the system is really slow. The important thing is that it doesn't loop forever.
I see this is copied from the other test, but single quotes should be preferred per the style guide.
OK. Thanks for taking the extra time to explain. I'll have a think. It's evening for me now. Either way: thank you for your effort!
I don't suppose it actually makes a difference, but would we not do this in the other order? (i.e. the `super()` call at the end.)
Use parentheses instead of backslash escaping ```python msg = ( 'Window expressions are not allowed in this query ("Max(Col(expressions_window_employee, ' 'expressions_window.Employee.salary)) OVER (PARTITION BY Col(expressions_window_employee, ' 'expressions_window.Employee.department))" on expressions_window.Employee.salary).' )
What about ```suggestion raise FieldError('Window expressions are not allowed in this query (%s=%r)." % (field, value)) ```
What about ```suggestion raise FieldError('Aggregate functions are not allowed in this query (%s=%r).' % (field, value)) ```
What's the point of switching to outer double quotes if you have to escape them? Stick to single quote and use `%r` instead of double quote wrapping ```suggestion raise FieldError('Infinite loop caused by ordering (%r on %s).' % (join_tuple, field)) ```
I think an output like `num_employees=(Max(Value(1))` would be more readable. That's what Simon suggested as well.
Ditto regarding quotes and the `%s=%r` format.
Ditto about `msg` in both cases.
variable could be omitted
I don't think it's worth having two options here. I understand that the Django version is less likely to change but my point is that for the rare cases where the header content causes issues (you have to admit your setup is uncommon) one can do without a complete header. Adding two options only makes the code more complex for little benefits.
It feels like having non-negated arguments defaulting to `True` would be more appropriate ```python include_header=True ```
You should could use `action='store_false', dest='include_header'` to have the CLI parsing logic deal with the double negation logic.
My thinking is that there are many ways that the assertion could inadvertently pass. Sort of like if you use `assertNotContains()` but there's a typo in the string that you're asserting isn't present.
It feels like `MigrationWriter` shouldn't have to deal with a negated option and it should be the commands responsibility to deal with the fact the flag is negated. That's the main reason why I suggested `include_header=True` in the previous PR.
We don't often use the `msg` param with `subTest()`. Maybe: `"Migration file includes header: %s." % include_header` or just: `include_header=include_header`
I think this migration should always start with `from django.db import migrations` and I would find that assertion much simpler.
`self.include_header` once the double negation logic is handled by `argparse`.
That's a double negation the writer shouldn't have to deal with as it's a side effect of the fact the CLI facts are negated.
It feels wrong to pass a negated option to `MigrationWriter`. It feels like `include_header=self.include_header`
I haven't read the RFC but I assume we want to be using UTC's today? Right now this using what ever timezone is configured on the server's today.
This should also use UTC now. The test should used a fixed year and find a way to mock `parse_http_date`'s way of obtaining a current year.
Is this supposed to be `sqlite_version_info` rather than `version_info`? I guess other usages in this file might be incorrect also.
It looks like this pattern would benefit to be applied as a method decorator, as that would limit code duplication.
We tend to favor the dict formatting as: ``` some_dict = { 'key1': 'value', } ```
And move _"only"_ to the start - the sentence flows better.
I would remove _"We should"_.
You don't need the parentheses around `var, val`. In fact this line could also be merged below: ```python context.update({var: val.resolve(context) for var, val in self.extra_context.items()}) ```
I wonder if it's worth adding two class attributes constants for these defaults.
We can ignore `name`, `path`, and `args`, e.g. `*_, kwargs = field.deconstruct()`
Please add trailing comma.
This can be single-lined.
Right, this was more a of suggestion open to discussion given the composite nature of `(-180.0, -90.0, 180.0, 90.0)`. I kind of wish `Field.deconstruct` was more smart wrt to `__init__` defaults by relying on `inspect` reflection in the first place.
Chop blank line.
You probably want to use the verbose name of the app instead through `model._meta.app_config.verbose_name`.
You could avoid the object creation and use `SimpleTestCase`. ```suggestion g = Group(name='Users') ```
`Returns` -> `Return` due to the PEP 257.
It'd be great to test this branch as well.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
The purpose of this class isn't obvious to me. Is this code adapted your use case? Maybe you can add a bit more explanation to the ticket. I'm not sure what "custom default settings" are.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
It's not obvious to me that the template approach is the best solution for readability as opposed to just creating another test settings file.
I'd think `write_configured_settings()` could be responsible for doing this.
Not sure but they might require tests for all backends that this patch supports, and then refactor the said tests.
Can you explain why this method may be called with an already parsed URL ? And is this something you really want to support ? After all, the caller could also do `url = url if isinstance(url, dict) else Service.parse_url(url)`. Note that i'm not defending one pattern or the other, but just wondering about how you made your choice.
I would remove this reference. IMO adding a note to the ticket [18867](https://code.djangoproject.com/ticket/18867) about open PR in PyYAML would be more appropriate.
Did you try the ORM rather than raw SQL? I'm not sure if there's a reason the test above doesn't use it.
I feel like it should be `_delete_unique_sql`'s decision to do the bool casting. Maybe some backends will need access to the condition to appropriately delete it. Lets just pass `condition=condition` and let database backends do `if condition`.
That's too naive. It has to consider whether or not `self` matches the condition in the first place.
Could use `bulk_create` ```suggestion Product.objects.bulk_create([ Product(name='p1'), Product(name='p1', color='red'), ]) ```
Please check test coverage carefully. I didn't spot a test for this change.
sure, you can add it here.
Okay, as before, the other cleanups can be in a separate commit.
Would be better to do unrelated cleanups like this (I saw another rename in schema.py) in another commit.
Should it be `condition=None` or `condition=''` in all signatures (currently some inconsistency)? I'd lean toward the former.
For those of you following along at home, the problem is that `None` is a valid value for a kwarg (check to see if the value from the database is `NULL`). That wasn't obvious to me so I thought I'd clarify. One solution would be to not add a parameter at all, and see if `"update_condition"` is in `kwargs`.
I'd add a note about why "condition" is special.
Keep what's done in `try` to the minimal expected to raise `self.model.DoesNotExist`. Move this after `except:` block.
That would hide the `update_condition` kwarg from signature, that's why I suggested a sentinel should be used.
We can also import `include()` from `django.urls` instead of `django.conf.urls`.
Any required changes in this file should have corresponding test changes. For example, I reverted this change and didn't see any test failures.
Not sure :thinking: I would prefer to use `BaseFieldInfo` approach in this PR, and to unify introspection for PostgreSQL and MySQL in a separate PR.
I think we can import standard `FieldInfo` as a `BaseFieldInfo`, it seems to be cleaner for me (like in `oracle/introspection.py`).
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
`LISTAGG` will not work properly without `GROUP BY` clause, it returns reversed string from first row i.e. `htimS nhoJ` for all rows. I would also use `LEVEL` instead of `ROWNUM`, e.g. ```python template=( '(SELECT LISTAGG(s) WITHIN GROUP (ORDER BY n DESC) FROM ' '(SELECT LEVEL n, SUBSTR(%(expressions)s, LEVEL, 1) s ' 'FROM DUAL CONNECT BY LEVEL <= LENGTH(%(expressions)s)) ' 'GROUP BY %(expressions)s)' ) ```
I nearly missed the `not` before `options['sitemap_uses_http']` while reading.
Yeah, that would certainly be a better idea, rather than using `not` here for negation.
Yup, this extra line won't hurt, IMHO.
I guess the `add_argument` could be `action='store_false', dest='uses_https'`
This isn't working where it's used (Oracle).
Just had to move `field.check()` to the mocked context.
I should have been clearer but `firstname` and `lastname` can be omited as they'll default to `''` if missing.
Not necessary AFAIK; `values('cnt')` infers it.
You can drop all the `firstname`, `lastname` above and default to `''`. Also could create a single `Employee` and use `cnt__gt=0` below.
Let's make the test name aggregate function agnostic, what about the following? ```suggestion def test_subquery_filter_by_aggregate(self): ```
Could do `self.assertEqual(qs.get()['float'], 1.2)`
I would expect to see the setup/teardown methods at the top of the class.
model -> table might be better
`# Render template (even though there are no substitutions) to allow inspecting the context in tests.`
:man_facepalming: Ah, ok. Thanks :+1:
I checked and this logic (in other form) is there since 2005. I don't think it's required.
Should we remove the same from `method_get_order()`? :thinking:
Sorry for the double post, but just to be explicit, something like: ```py @classproperty def migration(cls): if cls._migration_class is None: class Migration: ... cls._migration_class = Migration return cls._migration_class ```
I think @carltongibson's suggestion is a good one. The `Migration` class should only ever be created once. Using the `classproperty` decorator in `django/utils/decorators.py` may make the code simpler.
In the suggested command list, `'python'` should be `sys.executable` to ensure the same Python that is running the tests is used in the subprocess.
Thanks @jdufresne. I knew there has to be a nicer way... 🙂
Is that correct? ``` >>> def a(): ... class A: ... pass ... ... return A ... >>> a1 = a() >>> a2 = a() >>> a1 __main__.a.<locals>.A >>> a2 __main__.a.<locals>.A >>> a1 is a2 False >>> a1 == a2 False ``` Whereas if `Migration` is a `@property` that lazily creates `Migration`, storing the reference on the class, it'll always be the same. (Next time past we return the class we already created.) I'm not 100% sure it'd raise any problems but, `ModelBase.__new__()` is a little bit hairy, and dynamic model creation isn't really supported, I think for that reason. Hence my query.
You can call `['python', '-m', 'django', '--settings', 'integration_settings', 'check']` instead to avoid creating a dedicated `manage.py` file.
> I can do it, but it would skip for other contributors locally. There is no use for a test which gets skipped. @nasirhjafri other contributors do run tests again other backends even if they are not using django-box.
you can use django-box, It is very useful to run tests with other vendors. (https://github.com/django/django-box)
This test passes when testing against an SQLite or MySQL backend as long as psycopg2 is also installed. For this test case, I think the check `connection.vendor == 'postgresql'` skips the test too aggressively.
The note should be generic -- describe the sort problem as it could happen to any app -- a reference to contrib.postgres isn't needed.
I know -- there are other tests on `contrib.postgres` that could run without a database, but we ran into other requirements like `django.contrib.postgres` must be in `INSTALLED_APPS` that made it inconvenient. I think it was 36e90d1f45a13f53ce25fdc2d9c04433b835c9af.
Did you consider using `PostgreSQLSimpleTestCase`? I would favor that for consistency.
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
Test -> Tests (for future expansion)
It looks to me like this test should verify the SQL rather than verifying that there isn't any deferred SQL.
I think we can use `%(deferrable)s` instead of `DEFERRABLE INITIALLY DEFERRED`.
IMO `%(deferrable)s` is missing :thinking:
Chop blank line.
Please use single quotes.
Trailing dot is missing.
Trailing dot is missing.
Thanks for your effort :+1:. It is a kindly request for the first option. Trailing dot should be at the end of a sentence but there is no point in doing unrelated refactoring of existing code.
Could be simplified to `self.assertFalse(editor.deferred_sql)`.
I think the attribute should speak in terms of _column_ instead of _field_ to be coherent with the other ones e.g. `sql_add_column_inline_fk`
Thinking out loud here but do you think the fact the constraint is now deferred before index creation could cause an issue? I think it shouldn't be given RDMBs usually create an internal b-tree to maintain referential integrity.
I guess it could assert that the foreign key does exist but that another index doesn't through introspection.
chop "still" and "in our tests"
There's no need for the `disconnect` function. ```suggestion self.addCleanup(signals.post_init.disconnect, post_signal, sender=Book) ```
Move this to the top.
Ah ofcourse, my bad, you're right. Looks good to me.
Splitting params creates extra lists in memory which should not be needed, `param.count('\x00')` does not work? Actually a simple `param.find` would also do it since we just need to know if there is any null byte in there.
Don't bother changing now but please use single quotes in the future.
I like it!
The kwarg name should probably be more generic given this will surface _middleware_ exceptions as well.
Oh, it's because `SEARCH_VAR`, etc. are variables.
[This validator is added by default, no need to specify it](https://github.com/django/django/blob/ac956dae1d06ce2ebff7a2966bcaf8a5ecdbb861/django/forms/fields.py#L219). We'll probably want to pass `strip=False` as well to preserve backward compatiblity. Given you have to branch on `var == PAGE_VAR` anyway I don't think there's much value in using a loop here. You could define fields by directly assigning to `self.fields` ```python def __init__(self, *args, **kwargs): self.fields = { SEARCH_VAR: forms.CharField(required=False, strip=False, initial=''), PAGE_VAR: forms.IntegerField(required=False, min_value=0, initial=0), TO_FIELD_VAR: forms.CharField(required=False), } super(ChangeListForm, self).__init__() ``` The `initial` usage will make the `clean()` below unnecessary. ```
[`get()` takes a default to return as a second parameter](https://docs.python.org/3.7/library/stdtypes.html#dict.get).
Simply access `form.cleaned_data` instead.
I think this is problematic as it will result in an unhandled exception instead of displaying an error to the user.
Any reason not to just use a list or explicit tuple here? (The `\` continuation is a little strange.)
@timgraham I confirm this was my intent to make sure that constants are used as fieldnames.
I'm not quite following the BC concern...
Using messages might work.
The output here is suboptimal. e.g.`* p * Ensure this value is greater than or equal to 0` We need to provide custom error messages that make sense when displayed as `messages`. We should maybe add the individual messages, in a loop, rather than the list.
Rather than `str(next(iter(...` maybe: ``` messages = [m.message for m in request._messages] self.assertEqual(1, len(messages)) self.assertIn(error, messages[0]) ```
I'd inline this helper within the subTest()
yeah that'd work as well, good idea!
I'm a bit worried about the side effect of reloading this module given how much stuff depend on it indirectly. Tests are passing which is a good sign but that'll make yet another global side effect to think about when debugging weird issues with the test suite. I don't have any other idea of how to test this in another way but maybe raising the error on `DatabaseWrapper.__init__` instead could bring the same benefit while being easier to test? FWIW [we haven't tested such errors](https://github.com/django/django/blob/88619e6129fd8c6668242f1acc1465ca175d2948/django/db/backends/mysql/base.py#L35-L36) in the past and I would be ok with doing the same here.
I would use ```python exc_type, *_ = sys.exc_info() ``` or ```python exc_type, _, _ = sys.exc_info() ``` :thinking:
Please order alphabetically.
Collapse these onto one line and order alphabetically.
Collapse these onto one line and order alphabetically.
May as well flatten to one line and use `sys.exc_info()[0]`.
I think we can use a more specific subclass i.e. `ConnectionError`.
That's fine. I tend to lean toward concise, and in this case `sys.exec_info()` is a well-known function, but am happy either way.
Please wrap at 79 chars.
Typo `separator` instead of `seperator`. I would call it `sign`, TBH.
Offset cannot have seconds and milliseconds, so this workaround is unnecessary.
`getattr()` rather than calling a dunder method
Please add trailing comma.
IMO SQLite solution is too complicated and contains a lot of unnecessary workarounds. Please find below my proposition: ```python def _sqlite_datetime_parse(dt, tzname=None, conn_tzname=None): ... if tzname is not None and tzname != conn_tzname: for sign in '+', '-': if sign in tzname: tzname, offset = tzname.split(sign) if offset: hours, minutes = offset.split(':') offset_delta = datetime.timedelta(hours=int(hours), minutes=int(minutes)) dt += offset_delta if sign == '+' else -offset_delta break dt = timezone.localtime(dt, pytz.timezone(tzname)) return dt ``` Probably it could be even simpler.
A docstring describing the purpose of this test may be useful.
Both `keys()` calls are unnecessary, `dict.__iter__` yields keys. Also not sure why the `filter(None, ...)` is required.
Can this be rewritten as ```python from functools import reduce return reduce(self.merge, filter(None, self._js_lists)) ``` By the way, how can entries be `None` given the checks in `__init__`? If it's not necessay than this can be reduced to ```python return reduce(self.merge, self._js_lists) ```
Unneeded since it's the default.
I would chop the blank line.
Either lookup works as a regression test. The important thing is that `lookup_name != 'exact'` as the docstring says.
I remember looking at this test when merging 233c70f0479beb3bff9027e6cff680882978fd4d. I just tested this now and if you use `with register_lookup(field, Exactly, lookup_name='exact'):`, then this is the state at the end of the test: ``` >>> Author._meta.get_field('birthdate').get_lookup('exact') <class 'custom_lookups.tests.Exactly'> ``` With the current code, the output is `<class 'django.db.models.lookups.Exact'>` which looks correct to me. So I'd leave this as is and remove the unused `CustomExactLookup`.
Thanks for the sleuthing folks!
Hmm it's not clear to me what this test is trying to accomplish, what's the purpose of `CustomExactLookup` in the first place since it's `Exactly` that is registered.
I think you could use `django.test.utils.register_lookup()` here as well.
This returns instances rather than _classes_ so is misleading at best.
Since dicts are ordered in Python 3.6+, the `list()` could be kept and the `sorted()`s removed, I think.
`timeit` on Python 3.7 suggests that the iterator version is slightly faster: ``` $ python3 -m timeit -s 'import sys' 'sorted(list(sys.modules.items()), key=lambda i: i[0])' 20000 loops, best of 5: 10.8 usec per loop $ python3 -m timeit -s 'import sys' 'sorted(sys.modules.items(), key=lambda i: i[0])' 20000 loops, best of 5: 10.5 usec per loop ```
I don't believe so, this does seem unneeded. As a whole, this and the two lines below are pretty performance critical to the reloader but I don't see how removing `list()` would cause any issues with that.
This would be more readable and consistent with our indentation style with something like: ``` foo_constraints = [ name for name, details in constraints.items() if details['columns'] == ['name'] and details['unique'] and name != custom_constraint_name] ] self.assertEqual(len(foo_constraints), 1) ``` (choosing a different name than "foo"
I think we'd want more details about why this hack is needed.
I wonder :thinking: if we could move this repetitive logic directly into `_constraint_names()`, e.g. ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index 0522abcaad..daeb210ad7 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -1116,15 +1116,17 @@ class BaseDatabaseSchemaEditor: with self.connection.cursor() as cursor: constraints = self.connection.introspection.get_constraints(cursor, model._meta.db_table) result = [] + meta_constraint_names = {constraint.name for constraint in model._meta.constraints} + meta_index_names = {constraint.name for constraint in model._meta.indexes} for name, infodict in constraints.items(): if column_names is None or column_names == infodict['columns']: - if unique is not None and infodict['unique'] != unique: + if unique is not None and (infodict['unique'] != unique or name in meta_constraint_names): continue if primary_key is not None and infodict['primary_key'] != primary_key: continue - if index is not None and infodict['index'] != index: + if index is not None and (infodict['index'] != index or name in meta_index_names): continue - if check is not None and infodict['check'] != check: + if check is not None and (infodict['check'] != check or name in meta_constraint_names): continue if foreign_key is not None and not infodict['foreign_key']: continue ``` It works for me.
Rather than skipping it, I'd rather see the test updated for how memcache behaves so that if it starts failing, we know the issue is resolved in python-memcached.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I'd rather put this in the base cache tests and override for python-memcached until it's fixed.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
Rather than introducing a new method, I would rather remove `if val is None: return default` from `BaseMemcachedCache.get()` and override `MemcachedCache.get()` with the workaround -- then that method can be removed when https://github.com/linsomniac/python-memcached/pull/158 is addressed.
The [`Accept-Language` format](https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.4) and `LANG` environment variable also don't share the same format. For example, I've got `LANG=fr_CA.UTF-8` defined locally while `Accept-Language` should be `fr-ca`.
Ahh never mind then, I assumed it was the same function based on the name.
This was a problem before as well but I guess it should be fixed while you are around. In the case where `showmigrations` is not called with an app label (or called with multiple ones) this will incur `len(app_names)` queries since each access to `loader.applied_migrations` incurs one. It might be worth assigning a `applied_migrations = loader.applied_migrations` variable outside of the loop.
`postgres_tests` is for testing `django.contrib.postgres`. Use `tests/bulk_create` and `@skipUnlessDBFeature('can_return_rows_from_bulk_insert')`.
I believe the reporter suggested that this should be -61 seconds. If this is correct, it seems that existing cases like '-15:30' also need to be changed.
This is the only case that fails if the patch is reverted.
Use single quotes.
Can we adjust the test name. We know this is `modelchoicefield`, because the whole `TestCase` is called that, so we can drop that. Maybe... `test_initial_accepts_model_instance_for_validation_when_field_disabled`? It's a bit long and horrible but... (???: suggestions welcome!)
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
Right, but it's the `disabled` bit that breaks right? (Wasn't the weirdness from the ticket that exactly the same thing worked or not depending on that value? So a regression test for that is worth having.)
Ditto with `.values_list`/`assertSequenceEqual`.
Please order this in the same way as the import above.
Could drop the `alias` in `setUpTestData` and `order_by('pk')` or simply use `assertCountEqual` since ordering isn't that important.
Not even if you pass an expression? Just trying to avert a common problem we've had to fix numerous times. If you think there is no expression that could be an issue, I'm happy to ignore this.
Add a trailing comma. (Supported by Python 3.5+ — [flake8-commas](https://pypi.org/project/flake8-commas/) is a neat extension...)
Could use `assertSequenceEqual` with `values_list` ```suggestion authors = Author.objects.annotate( md5_name=MD5('name'), ).values_list('md5_name', flat=True).order_by('pk') self.assertSequenceEqual(authors, [...]) ```
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
How about changing `second` to args/kwargs like `cols, primary_key=False, 'unique=False, ...` and then the assertion becomes `assertDetails(constraint, ['up_votes'], check=True)`. No need to repeat all the other values.
I wonder if adding a similar `assertDetails` helper would be worthwhile to reduce verbosity here.
I pushed a commit with some edits, let me know if it looks okay.
Perhaps it would be less verbose to consolidate more cases into a single test with something like: ``` tests = ( ('"ref" integer UNIQUE,', ['ref']), ... ) for sql, cols in tests: with subTest(sql=sql): ... ``` Use`self.subTest()` in the loop.
Stick to `.format` for now. Until we settle to switch to f strings for the whole code base we should stick to format.
yeah `.format` crept in while we were supposed to stick to `%`. anyway lets make sure we don't have three ways of formatting strings across the code base 😅 .
This should be a filter by `_slice_by__in` and not `pk__in`.
> Since different people use different naming for primary keys in their model so we need to specify that by `_slice_by`. I don't understand your reasoning, why not use `'pk'` in your `.values` call then? The way you defined your API any field can be specified for `slice_by` which I thought has merit because if your queryset is ordered by anything but `pk`, e.g. another unique field, then it might be more efficient to retrieve rows by this field.
You could do solve this recursively, but I don't know if this better readable really. meh
Why don't you make unique_items a `set` too? This would save you the whole `not in` clause. You just do `Set.add` which will add the item if it's not in the present anyways ;) That being said, since you are adding all items of the list to a set. Just create a set from the list. This will be a lot faster, since the `in` clause performs only at `O(n)`.
You are also filtering empty lists in your merge method. That double trouble, isn't it ;)
I guess `deps` could be a `defaultdict(set)`
I don't know if you need to actually create all the Medias. At this point a unit tests calling merge is sufficient. What I would like to see is: ```python assert list(merge([1,2],[1,3],[2,3], [5,7], [5,6], [6,7,9], [8,9])) == [1,2,3,5,6,7,8,9] ```
The whole test should be updated to a list of list and a result list. eg: ```python ([[1,2],[1,3],[2,3], [5,7], [5,6], [6,7,9], [8,9]], [1,2,3,5,6,7,8,9]) ```
again, why not just return a generator
why cast this into a list, normal brackets (generator) will do
instead of using `lst[0]` and `lst[1:]` I would recommend: ```python head, *tail = lst ````
Use `django.utils.datastructures.OrderedSet` to make it clear what you are using this datastructure for.
You might want to consider returning a generator yourself. In which case you should just `yield from` the generator instead of returning a list.
this is assuming you always get a list. I would call them `iterables` and treat them as such. Therefore you will be only able to iterate over them once.
I don't know if this is an overkill, but we could log the exception.
Unnecessary call to `.keys()`.
I would filter that first, via a generator. I think this might be more readable. ```python lists = (lst for lst in lists if lst) ``` or ```python lists = filter(None, lists) ```
Unnecessary `.keys` call ```suggestion return list(unique_items) ```
why cast this into a list, normal brackets (generator) will do
Can we customize this class to check if it really works? e.g. ```python class MyExceptionReporter(ExceptionReporter): def get_traceback_text(self): return 'My custom traceback ' + super().get_traceback_text() ```
Please drop these unrelated changes.
Can we move the default value? ```python def __init__(self, include_html=False, email_backend=None, reporter_class=None): ... self.reporter_class = import_string(reporter_class or 'django.views.debug.ExceptionReporter') ```
This can raise a `LookupError`
AdminSelect used to take the related model. It now takes the field.
@codingjoe it's the remote field in test and not the local one. The URL is `'autocomplete_admin:admin_views_question_autocomplete'` (which is bound to the `Question` model) and `'question_with_to_field'` is an `Answer` field. What I'm suggesting we do instead is pass `?field_name=uuid` which is a field local to `Question` and have `Answer` admin pass `field.remote_field.name` in `AutocompleteMixin.build_attrs` instead which is `'uuid'`. That's what the other admin views are doing and doesn't require you do extra `model` and `app_label` sanitization when walking your way back to the local field from the remote one.
I see. Any thoughts about passing the _local_ field instead of the remote one and the model it's from? e.g. in the case of tests below `field_name` would be `'uuid'` instead of `'question_with_to_field'`. That's how the other `to_field` enabled admin views work and what `to_field_allowed` expects. It also feels like a nicer API to me and would allow you to stop passing `app_label` and `model_name`.
This should be removed in a separate commit if it's unused.
Hey @codingjoe — so I think I would restructure this section slightly, through to line 59. * I'd create a method to configure three attributes on self: `source_field`, `model_admin`, and `to_field_name`. It'd need to take the `request`. In there I'd include all the `try:except:` blocks and raise an `AutoCompleteSetupError` (or similar) if any of them occur. * Outside that method I would have a single `try:except:` to log the error, and return the JSON 403 response. (I'm thinking about how I'd debug this if there's no logging, and all I have to go on is a 403...) I think we should also move the `has_perm() -> 403` check **above** the `get_search_fields() -> 404`. (That last if nicely informative for users but we shouldn't hand out that info to someone without the permissions to access the modeladmin at all… 🤔)
Not sure who marked this as resolved, because it isn't.
As far as I'm aware, this can create duplicates on multi-value relations, see related fix for forms 556fa4bbba5ba86bc1646a86fb11ab55405d4aa4.
"Django" doesn't add much: ```suggestion # Retrieve objects from parameters. ```
Chop blank line.
I think we should raise `BadRequest` instead of `PermissionDenied`, because missing parameter in `GET` has nothing to do with permissions. Maybe, I'm picky :shrug:
```suggestion type(model_admin).__qualname__ ```
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
```suggestion Question.objects.create(question='Not a question.') ```
If I understood the above code correctly, then `self.field` is on the source model, whereas `self.model_admin` points to the target admin, I think we should really rename those to avoid confusion.
The issue here is that we can't do the proper permission check (`if not self.has_perm(request) ...`) until after we've assigned `self.model_admin`, which we return from this method. _Maybe_ it's OK. But… it seems like we have the exact kind of _"Folks can probe the autocomplete view to find out the structure of the application"_ issue that we spend a lot of time thinking about and trying to avoid. If we just raise `PermissionDenied` for all of these cases we don't leak any info. Such exceptions are logged and a developer can use that to debug. Given that this is an ajax view, they're not going to see the debug output page anyway (without taking steps). I'm not convinced the different status code is worth the additional exposure (or even the effort justifying why it's OK). > 🤷 Yes. 🙂
Why 403 instead of 404 (in all occasions, not just this one)? If there is a good reason, maybe a commend would be helpful.
You can drop the `or module.__spec__ is None`, both are now contained in the `module.__spec__ is None` check.
You can pass `set()`, no need to create a list to initialize an empty `frozenset` (or `set`), it be great to assert the return value as well.
`getattr(module, '__spec__', None) is None` is more concise.
Single quote strings ```suggestion module = types.ModuleType('test_module') ```
Yep. That swings it for me. Leave it as is. Good one. Thanks.
I think I might prefer `scope` (or similar) to `from_name`. (As ever with naming...) Maybe make it kwarg-only so we'd call it like this: ``` _user_get_permissions(self, obj, scope='user') ``` Otherwise, _"What's the string for?"_ — but this function is only used in this files, so maybe it's clear enough.
You could assign `start_transaction_sql` to a variable to avoid calling it twice.
This must use `mock.patch` else it will leak between tests as the connection. Also it should be `connection.features.can_rollback_ddl` and not `connection.can_rollback_ddl`.
That must be `connection.features.can_rollback_ddl` and doesn't have to rely on a default value ```suggestion self.output_transaction = migration.atomic and connection.features.can_rollback_ddl ```
This should not be added; instead the assertions below should be adjusted to skip `connection.ops.start_transaction_sql().lower()` lookup `if not connection.features.can_rollback_ddl`.
This can be simplified: ```python self.output_transaction = migration.atomic and getattr(connection, 'can_rollback_ddl', True) ```
You need to make the changes.
I'm not sure we need to test implementation details of `MultiValueDict`. It seems like the following test should be enough ```python def test_empty_data_files_multivalue_dict(self): form = Person() self.assertIsInstance(form.data, MultiValueDict) self.assertIsInstance(form.files, MultiValueDict)
I'm not following the expected usage here. Surely (?) I'm only applying this to filters `needs_autoescape=True` (It seems overly complex…)
```suggestion if autoescape: args[0] = conditional_escape(args[0]) return func(*args, **kwargs) ```
Ah yes, you are correct sorry.
This isn't a related field at all; related fields are the ones referenced through the `__` notation and involve JOINs
It would be more helpful if the name were included, e.g. "Setting 'foo' must be uppercase."
Please wrap at 79 chars.
Sorry. 😬 I thought they made more sense together, but let's go with what Tim said. (Would have needed a full-stop anyhow...)
So probably just, ["use hanging indent"](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) here.
This line is horrible. 😄 Simon mentioned this in his review before but, maybe leaving up until the `and\n` as is and putting the new check on the next line, to keep the diff that bit smaller...? (I don't mind this as it is per se — whichever way we do it, it is long and horrible.)
This and the check below can be single-lined.
Hey @felixxm. In the end we went for not having the "or subclassed" so these changes will disappear. (`checks.txt` did previously have this adjustment, but it's gone now. These are just leftovers to be removed.)
Please update error message for `admin.E409` in `docs/ref/checks.txt`.
I think the `_module_exists` and argument name could be improved. What about ```suggestion def _contains_subclass(subclass_path, candidate_paths): ```
`middleware` might not be the best variable name since it's used for authentications backend as well. What about ```suggestion subclass = import_string(subclass_path) ```
@carltongibson Ahh sorry :man_facepalming: I should check discussion.
`import_string` can raise `ImportError` which is probably not the best place to be surfaced if you made a typo in your `MIDDLEWARE`. ```suggestion try: candidate_cls = import_string(candidate_path) except ImportError: continue if _issubclass(candidate_cls, subclass): return True return False ```
Doesn't matter much, but something like `AuthenticationMiddlewareSubclass` would be more descriptive about the purpose.
I understand the motive behind the reformatting of the conditionals but I'd stick to the previous one to reduce the patch noise ratio.
This doesn't depend on anything above, so use a separate test: `test_middleware_subclasses`
Please wrap at 79 chars.
Why should an import error pass silently? This doesn't seem to be covered by a test. Assuming it's not needed, this could be simplified to `return any(_issubclass(import_string(path), subclass) for path in candidate_paths)`.
The messages corresponding to these will need updating in `docs/ref/checks.txt`.
I would move it to `as_oracle()` in `SHA224` and remove parentheses: ```python def as_oracle(self, compiler, connection, **extra_context): raise NotSupportedError('SHA224 is not supported on Oracle.') ```
Maybe: ```python # Enable pgcrypto extension to support digest() on PostgreSQL. ```
We can remove `bases` from all `migrations.CreateModel()`.
```suggestion msg = 'SHA224 is not supported on Oracle.' with self.assertRaisesMessage(NotSupportedError, msg): ```
Please wrap at 79 chars.
Please wrap at 79 chars (like in "_test_sha512.py_").
Please chop `Note that the`.
I think we can remove casting to `int`, i.e. ```python template='SHA2(%%(expressions)s, %s)' % self.function[3:], ```
Ah, ok I missed that. Looks good now :+1:
I didn't notice that above lines have 82/83 chars :smile:, but I'm ok with that. Multi-line strings should be wrapped at 79 chars, IMO. I would wrap `alias__sha512` at 79 chars.
Chop blank line.
Again, the inheritance chain looks questionable to me if this is needed.
I guess the docstrings should follow PEP 257 verb style "Error if..."
Generally I'd multiline this since it's long. ``` msg = ( 'You have provided a value for the LANGUAGE_CODE setting that is ' 'not in the LANGUAGES setting.' ) ```
You could also use `self.settings()` (it's a bit shorter) -- doesn't matter much though.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
We can single-lined this docstring.
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
Ok, I'm a bit disappointed :smile:
Good point :+1: @pope1ni All tests pass with `{}` instead of `{!r}`, so I think we can simplify messages and use `{}`.
Ah, ok so maybe we can check both in one call, i.e. ```python self.assertEqual(check_language_settings_consistent(None), [ Error( ... ), Warning( ... ), ]) ```
This docstring can be single-lined.
We thought that for some unexpected non-string data types if may be better to return their representation. I think it is not necessary.
What about `None` tags? I think we should add `tag is None or ...` to all checks. Maybe we can add one line hook in the _"django/utils/translation/trans_real.py"_ which we will reuse everywhere, also in the [check_for_language()](https://github.com/django/django/blob/master/django/utils/translation/trans_real.py#L376-L377).
This docstring can be single-lined.
I would keep `if not ...` in the same line.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
`join()` accepts generators, you don't need to create a list `[...]`.
I would remove a temporary variable (`clauses`), e.g. ```python return ' '.join(sql for sql in ( ('LIMIT %d' % limit) if limit else None, ('OFFSET %d' % offset) if offset else None, ) if sql) ```
Would this improve readability rather than using "magic indexing"? `filter_lhs, filter_rhs = filter_expr`
Consider using a single test and `subTest()` to avoid the same boilerplate in each test.
no blank lines please
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
This seems to merit an explanation of why Django's behavior should be different than Python's.
Doc changes required in `topics/testing/advanced.txt`.
Could be fixed with `{convert_test_name_pattern(p) for p in test_name_patterns or ()} or None`
Let's rename these test methods to be `test_html_autocomplete_attributes`.
Alphabetical order please: `autocomplete` before `autofocus`.
Just missed one `.get()` here.
Alphabetical order please: `autocomplete` before `autofocus`.
I'd drop these extra blank lines.
Don't forget the trailing commas! However, I also expect that this can fit on one line - we allow 119 chars, and it is not too complicated to understand.
Missing another trailing comma here - please check all of these final elements in tuple, list and function arguments.
Use normal dictionary access instead of `.get()`. It is fine for us to blow up with a `KeyError` here and helps debugging because it is clearer whether the attribute is missing or the value is incorrect.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
I thought `formset = ChoiceFormSet(self.data, auto_id=False, prefix='choices')` could go in `setUp()` also.
I'd rather a setUp method and keep the assertions in separate tests since they're not dependent on each other.
I would simplify condition e.g. `condition=Q(pk=-1)`.
Creating a new empty instance of related `model` doesn't look like a proper solution for me. IMO we should just omit `set_cached_value()` when `from_obj` is not available e.g. ```python def local_setter(obj, from_obj): if from_obj: f.remote_field.set_cached_value(from_obj, obj) ```
We can remove `'book_join'` from `order_by()`.
I don't see any value in testing the number of queries in this test.
This message can be condensed onto one line.
I think this assertion has been copied from another test. I would use ```python constraint_name = 'ints_between' self.assertNotIn(constraint_name, self.get_constraints(RangesModel._meta.db_table)) ```
Seems to fine on a single line.
We should convert column name i.e. `connection.introspection.identifier_converter('large_field')`.
``` 'BinaryField default cannot be a string, use bytes content ' 'instead.' ```
Please wrap at 79 chars.
I don't see much value in using `self.subTest()` here.
We can remove quotes around the `default`. Please also wrap at 79 chars.
Maybe `_check_default_is_not_str()` -> `_check_str_default_value()`?. Please remove unused `kwargs`.
I would use unpacking generalization, e.g. ```python return [*super().check(**kwargs), *self._check_str_default_value()] ```
We can use one model with two fields instead of two models.
Define `arity = 2` as well.
Flatten this to one line. The temporary variable doesn't add anything.
`obj=None` -> `obj`
This docstring doesn't have any value, IMO.
This can be single-lined. Please use `tuple`.
It isn't used, yes, but compare to `get_exclude` which also doesn't use it in the default implementation. Having it allows overriding implementations to choose the inlines based on the instance. Not having it may well result in a future request to add it. It also neatly propagates down from `get_inline_instances()`.
Sorry for being unclear. I was talking about `None` as a default value for `obj`: ```python def get_inlines(self, request, obj): ```
There should also be an assertion for the output of the new `get_inlines()` method.
I think we want a test with some actual content.
I would chop blank lines and test these in a loop, e.g.: ```python for name, inline_class in ( ('alternate', AlternateInline), ('media', MediaInline), ): request.name = name self.assertEqual(ma.get_inlines(request, None), (inline_class,)), self.assertEqual(type(ma.get_inline_instances(request)[0]), inline_class) ```
`obj=None` looks unnecessary.
This doctring can be single-lined.
We can use here `assertEqual` instead of `assertCountEqual`.
Please use single quotes.
For new code, we're using single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Yes, trailing period.
Add trailing comma.
Chop _"Ensure we can"_.
I think we cannot use decorator here. IMO we should use `property()`, e.g. ```python def property_year(self): return self.date.year property_year.admin_order_field = 'date' model_property_year = property(property_year) ``` (see similar patch for `short_description` cec9558fba1bc6401ea2ec6d71b816b4dfd31b28).
Maybe `# Set ordering for attr that is a property, if defined.` :thinking: .
Please chop blank line.
@pydolan Thanks for update :+1: I'm sorry but I think that this fix doesn't qualify for a backport based on our [supported versions policy](https://docs.djangoproject.com/en/dev/internals/release-process/#supported-versions).
Maybe we can add also `, n2__sign=0`.
Please chop blank line.
IMO, we can use `assertEqual` instead of `assertAlmostEqual` in all tests.
I think this feature would be hard to get right for the rare case where it's useful. It also go against our stance on trying to _disconnect_ `Meta.ordering` from aggregation as this PR demonstrates. I'd be in favour of won't fixing the ticket as well for these reasons. It feels incoherent with the ongoing deprecation motivated by observed user confusion over the years from the interactions between these two features.
Use the `msg = ` format to avoid awkward indentation.
I'd use `rstrip('.ModelAdmin')` rather than a regex.
I'd say omitting `__class__.__name__` is more useful as it'll include the `app_label`. I would just omit `'.ModelAdmin'` if the string ends with that, since that's probably `register()` without a `ModelAdmin` subclass. So in case 1, the error would look like: The model %s is already registered with app 'admin_registration'. In case 2: The model %s is already registered with 'admin_registration.PersonAdmin'.
Please use single quotes `'none'`.
Maybe ```python self.assertEqual(form.fields['username'].widget.attrs.get('autocapitalize'), 'none') ``` to prevent crash when `'autocapitalize'` is not in `widget.attrs`.
Since the behaviour of the `autocapitalize` attribute has nothing to do with django itself, you'll probably have to write some sort of a test that the field/widget renders that attribute.
This test passes without changes in the `UsernameField`.
You don't need to pass `None` (in all tests).
You should just check for the presence of the attribute. See tests in #11070.
:thinking: As far as I'm concerned it will not change a level of indentation: ```python if name in self.annotations: if not allow_joins: annotation = self.annotations[name] ```
I would use the same message like in similar exceptions: ``` Joined field references are not permitted in this query ```
This whole logic can be simplified to ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index 4e120d2741..0d39671f0b 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1620,17 +1620,22 @@ class Query(BaseExpression): _resolve_cols(self.annotations[name].get_source_expressions()) return set(cols) + @classmethod + def _gen_col_aliases(cls, exprs): + for expr in exprs: + if isinstance(expr, Col): + yield expr.alias + else: + yield from cls._gen_col_aliases(expr.get_source_expressions()) + def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False, simple_col=False): if not allow_joins and LOOKUP_SEP in name: raise FieldError("Joined field references are not permitted in this query") - if name in self.annotations: - if not allow_joins and self.annotations[name].contains_column_references: - for alias in ( - {getattr(self.annotations[name], 'alias', None)} - if isinstance(self.annotations[name], Col) else - self.resolve_cols(name) - ): - if alias and isinstance(self.alias_map[alias], Join): + annotation = self.annotations.get(name) + if annotation is not None: + if not allow_joins: + for alias in self._gen_col_aliases([annotation]): + if isinstance(self.alias_map[alias], Join): raise FieldError('Joined field references are not permitted in this query') if summarize: # Summarize currently means we are doing an aggregate() query @@ -1639,7 +1644,7 @@ class Query(BaseExpression): # that case we need to return a Ref to the subquery's annotation. return Ref(name, self.annotation_select[name]) else: - return self.annotations[name] + return annotation else: field_list = name.split(LOOKUP_SEP) join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse) ```
Remove a level of indentation by flattening this if statement into the previous.
Add a period to the end of the exception message.
We used the same message as in other places that's why I don't want to add a period only in this case.
All `Col` should have an `alias`.
We could simplify this, e.g. ```python if not allow_joins and self.annotations[name].contains_column_references: alias = getattr(self.annotations[name], 'alias', None) if alias and isinstance(self.alias_map[alias], Join): raise FieldError('Joined field references are not permitted in this query') ``` but unfortunately your solution doesn't cover all cases.
You can drop the `.contains_column_references` as it's wasteful in this case because of the way it walks the expression tree given we'll have to walk it anyway below.
Ah, sneaky 🤗 Too early in the morning!
That's not actually resolving anything it's only collecting aliases.
Maybe you've missed `if summarize` branch (below).
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Quick link: https://github.com/django/django/pull/8714/files
I think we should convert only when time-zones are different (like in the original patch).
OK, it's necessary, see `migrations.test_commands.MigrateTests.test_showmigrations_no_migrations`.
Do we need to take into account `self.ignore_no_migrations`? I don't see any tests failures after removing this check. IMO it's unnecessary.
We usually use `get` to avoid the try boilerplate ```python user_agent = request.META.get('HTTP_USER_AGENT') if user_agent is not None: for user_agent_regex in settings.DISALLOWED_USER_AGENTS: if user_agent_regex.search(user_agent): raise PermissionDenied('Forbidden user agent')
I think we can remove this sentence.
Strictly speaking the issue is that Django templates use what looks like attribute access to access dictionary items, so hyphenated keys are inaccessible. It is nothing to do with the variable itself.
`headers` should be `request.headers` in both cases, but I'd be inclined to simplify this: ```python """Allows header lookup using underscores in place of hyphens.""" ```
I think we can return directly without creating a temporary variable (`value`).
I think at this point we can safely just use this to get the `'path.to.view'` string: ``` getattr(self.urlconf_module, 'handler%s' % status_code) ``` `resolve_error_handler()` already handled the fallback to `django.conf.urls` (and we can presume that didn't raise the exception). So that would give us (e.g. with the test values), `'check_framework.urls.bad_error_handlers_invalid_path.bad_handler'` to inject into the message. (If we do this I'm not sure we need to inspect the exception further.)
Please remove this blank line.
These two tests are not related with this fix, please move them to a separate commit.
Few naming suggestions: `ordering_element` -> `expr` `ord_sql` -> `expr_sql` `ord_sql_params` -> `expr_params` `additional_sql_params` -> `ordering_params` `ord_clauses` -> `ordering_expr_sql`
I think we can move entire `ordering` logic to a separate branch i.e. ```python if self.ordering: ... sql, sql_params = super().as_sql(compiler, connection, ordering=( 'ORDER BY ' + ', '.join(ordering_expr_sql) )) return sql, sql_params + ordering_params return super().as_sql(compiler, connection, ordering='') ```
Please chop all unnecessary blank lines.
`depth a recursive subquery references adds` → `depth recursive subquery references add`
`based of how` → `based on how`
There is functional change here, is it? I'd rather avoid it then, to not cause unnecessary conflicts, in particular with https://github.com/django/django/pull/11291/files, which removes this altogether.
This is not a functional change, it's just a simplification.
And this can be reverted.
And this can be reverted.
IMO we don't need to create new objects (`objs = [...]`), we should be able to change queries and reuse existing ones, e.g. ```python def test_ordering_grouping_by_key_transform(self): self.assertSequenceEqual( JSONModel.objects.filter(field__d__0__isnull=False).order_by('field__d__0'), [self.objs[8]], ) qs = JSONModel.objects.filter(field__isnull=False).values('field__d__0').annotate( count=Count('field__d__0'), ).order_by('count') self.assertQuerysetEqual(qs, [1, 10], operator.itemgetter('count')) ```
Thanks for explanation, I just want to minimize test, so your version with `id` looks good :+1:
```suggestion hash(NoHash()) ```
```suggestion self.assertEqual(hash(ParentHash(id=1)), 1) ```
I'm not sure if this assertion is necessary :thinking:.
`Model.__hash__()` returns an object `id`, so by using `self.assertEqual()` I thought that maybe we will partly cover both test lines (`hash(...) self.assertIs(...)`) with single assertion :smile:
@charettes Many thanks!
Maybe there is a smarter way to recursively collect all parents? e.g. some hook that I missed :thinking: (\cc @charettes ).
I think `Furrow long` should be an alias instead of `Furlongs`, also please alphabetize.
This docstring is unnecessary.
Please chop blank line and remove temporary variable (`furlong`), i.e. ```python d = D(m=201.168) self.assertEqual(d.furlong, 1) ```
Entry in `ALIAS` is missing.
Use single quotes.
Chop blank line.
This would be backwards compatible in the sense that it select the active language and not the one that is the default in the settings right? which is probably okay since the feedparsers are most likely not the users browser anyways and have their own session
Please add a note in the 3.0 release notes (`Backwards incompatible changes in 3.0 -> Miscellaneous`).
`getattr` will throw a `ValueError` if the `to_field` does not exist, this has to be handled.
We can remove this check after fixing the `Field.slice_expression()`.
Please provide a message, e.g., `TypeError('Slicing must be of type made either int or slice.')` and write a test as well similar.
please use longer/more descriptive names than `f` and `k`, like `f_obj` and `slice`
```An object that contains a slice of F expression.```
Chop blank line.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
Please use f-strings as Python 3.6+ is now the requirement More information is available including some benchmarks. https://cito.github.io/blog/f-strings/
Casting `int` to `int` is not necessary.
I would prefer to keep a slice logic with `start` and `stop` instead of `low` and `length`.
Using `int` is untested and doesn't work as expected, because it uses 1-based indexing instead of 0-based indexing.
Single-quotes, unless double quotes are needed because you're mixing them.
TODO: Use new `_set_content_type_params()` helper.
Ahhh, yes, thanks!
FYI: we have also [`HttpHeaders`](https://github.com/django/django/blob/fc2536fe66c519b306f673672b795d16f87ed57d/django/http/request.py#L359-L374) class that have reserve logic, I'm not sure if we can reuse it somehow :thinking:
(In response to Mariusz' question.) `HttpHeader` is doing [exactly the reverse operation](https://github.com/django/django/blob/fc2536fe66c519b306f673672b795d16f87ed57d/django/http/request.py#L382): `replace('_', '-')`. They're clearly related, so maybe there's a refactoring available, but I think it should follow later (if at all). What's interesting here is that we're doing the header mapping in the request for ASGI, where a WSGI server already provides the headers, as part of the spec. ([Here's where `gunicorn` does it](https://github.com/benoitc/gunicorn/blob/dc7b5d5c4876b49f86ea2460698a335d0f5ef7c9/gunicorn/http/wsgi.py#L119-L140).) I'd say it's just _interesting_; I don't think we need a change here.
I added this hook in #11471.
Chop blank line.
Does this still apply? Daphne started sending headers as tuples in May 2016 (https://github.com/django/daphne/commit/81d99a34d35f1ad6fa8254a1cc1d1dd7f22f42af)
More importantly I think our wsgi handler currently has the oddity to always normalize to at least /, you will never get an empty path_info iirc
I would remove `else` since it is unnecessary after `raise`.
`scope` is a dict, isn't the `None` already the default anyways? Same below.
epecting -> expecting
Any reasons for such `chunk_size`? (`2^19`) why not `2 ^ 16` or `2 ^ 31 - 4`.
Should this be mutable? (`mutable=True`). `QueryDicts` handles `None` so `self.scope.get('query_string')` should work.
Maybe: ```python return self.scope.get('scheme') or super()._get_scheme() ```
I wouldn't have thought so as `request.GET` is immutable in the WSGI implementation? At least I recall having to `.copy()` it first...
Maybe: ```python for name, value in self.scope.get('headers', []): corrected_name = name.decode('latin1').upper().replace('-', '_') if corrected_name not in ('CONTENT_LENGTH', 'CONTENT_TYPE') corrected_name = 'HTTP_%s' corrected_name ```
We have exactly the same (similar) code in `WSGIRequest.__init__()`. Maybe we can add an internal hook to the `HttpRequest`? (in a separate commit) e.g. ```python def _parse_content_type_params(self, meta): self.content_type, self.content_params = cgi.parse_header(meta.get('CONTENT_TYPE', '')) if 'charset' in self.content_params: try: codecs.lookup(self.content_params['charset']) except LookupError: pass else: self.encoding = self.content_params['charset'] ``` after that we could just call: ```python self._parse_content_type_params(self.META) ``` Let me know if it works for you, I can handle this.
rquest -> request
Here you have a choice between `bytes` and `bytearray`. I ran this crude benchmark (Python 3.7, Linux, glibc): ```python import time CHUNK = b'\x00' * 1000 NUM_ITERS = 1000000 print('num_chunks,bytes_time,bytearray_time') for num_chunks in range(1, 21): start = time.monotonic() for i in range(NUM_ITERS): body = b'' for i in range(num_chunks): body += CHUNK finish = time.monotonic() bytes_time = time.monotonic() - start start = time.monotonic() for i in range(NUM_ITERS): body = bytearray() for i in range(num_chunks): body += CHUNK body = bytes(body) bytearray_time = time.monotonic() - start print(f'{num_chunks},{bytes_time},{bytearray_time}') ``` The result is: ![bench](https://user-images.githubusercontent.com/1223550/56269664-d69ab900-60fc-11e9-9393-ba4fd3998b87.png) At least with the parameters I used, bytearray is slower for a small number of chunks, but looks linear, while bytes looks quadratic.
Please use single quotes.
is there a reason to use `sys.stdout.write` instead of just print? also error messages should probably go to `stderr`
Let me know if you need assistance with that. You should be able to achieve it by using a `mock('django.utils.http.datetime.datetime.utcnow')` context manager with a `return_value=datetime(...)`.
I think this fails for some cases in the current year as well as for some in the future. ``` python def get_year(year, current_year): assert 0 <= year < 100 if year <= current_year + 50: year += 2000 else: year += 1900 return year assert get_year(19, current_year=2019) == 2019, "same year" assert get_year(20, current_year=2019) == 2020, "next year" assert get_year(18, current_year=2019) == 2018, "last year" assert get_year(40, current_year=2019) == 2040, "21y hence" assert get_year(80, current_year=2019) == 1980, "39y ago, not 61y hence" # fails! assert get_year(10, current_year=2019) == 2010, "9y ago, not 91y hence" assert get_year(69, current_year=2019) == 2069, "50y hence" assert get_year(80, current_year=2070) == 2080, "future 10y hence" assert get_year(60, current_year=2070) == 2060, "future 10y ago, not 90y hence" assert get_year(10, current_year=2070) == 2110, "future 40y hence" # fails! assert get_year(21, current_year=2070) == 2021, "future 49y ago, not 51y hence" assert get_year(20, current_year=2070) == 2120, "future 50y hence" # fails! ``` Can I suggest an alternative implementation? ``` python def get_year(short_year, current_year): assert 0 <= short_year < 100 current_short_year = current_year % 100 delta = short_year - current_short_year if delta < 0: delta += 100 # assume future if delta > 50: delta -= 100 # then shorten if too far in the future return current_year + delta ```
Please use single quotes in added or changed strings.
Trailing dot is missing.
I don't see any value in this docstring please remove it.
Please add trailing comma.
Just to make sure, this test fails before the change? (It's hard to know with a "negative" test and a hard-coded hash).
This test is passing even without a fix.
Remove this empty line, to keep the style consistent.
`saved_name` is unused, so we can leave only ```python if self.keep_intermediate_files: self._save(hashed_name, content_file) ```
Jenkins doesn't do anything specific, and yes this test passes locally for me without a fix.
The name `test_doesnt_keep_intermediate_files` would be better, to make it come up in a grep for `keep_intermediate_files`.
I don't think we want to subclass `base.Deserializer`. Instead, we can just do `self.object_list = object_list` and use that instead of `self.stream` below.
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
`field_names` are used only when `self.ignorenonexistent is True`, so we can optimize this part, e.g.: ```python field_names = set() if self.ignorenonexistent: if Model not in field_names_cache: self.field_names_cache[Model] = {f.name for f in Model._meta.get_fields()} field_names = self.field_names_cache[Model] ```
Please leave 1 blank line between summary line and description: ```suggestion Deserialize simple Python objects back into Django ORM instances. ```
We can start using f-string ```suggestion raise base.DeserializationError( f"Invalid model identifier: {model_identifier!r}" ) ```
In `_handle_m2m_field()` and `_handle_foreign_key_field()` we can avoid of temporary variables (`value`) and return directly, e.g. ```python def _handle_foreign_key_field(self, field, field_value): return base.deserialize_fk_value(field, field_value, self.using, self.handle_forward_references) ```
`field_names_cache` should be moved an initialized in the `__init__()`, currently we clean it for each `obj`.
`else` is unnecessary, I think we can leave: ```python if self.ignorenonexistent: continue raise ```
This can be single-lined.
I would keep the previous name for a class attribute: ``` self.ignorenonexistent = ignorenonexistent ```
Should we add sanity-check for duplicates in `bases`, `_check_for_duplicates()`? (e.g. [`CreateModel.__init__()`](https://github.com/django/django/blob/ef082ebb84f00e38af4e8880d04e8365c2766d34/django/db/migrations/operations/models.py#L55-L59)).
`name` should be used to follow `ModelOperation.__init__` signature and `super().__init__(name)` should be called.
I would rename `self.model_name` -> `self.name` (like in `CreateModel`, `DeleteModel`, or `RenameModel`).
Please use single quotes.
Please remove blank line.
Please add a trailing period.
Please remove blank line.
Django doesn't currently use f-strings, but 3.0 will certainly be capable of doing so. @felixxm, @carltongibson - are we happy to start allowing use of f-strings, or do we want to hold off? Perhaps this could be: ```python except ValueError as e: raise e.__class__(...) from e ```
Why does the message need to be passed into the class method? (Maybe there is a good reason I've missed.) I also think we want to state which choice enum and what value caused this to happen, e.g. ```python @classmethod def validate(cls, value): try: cls(value) except ValueError as e: raise exceptions.ValidationError('Invalid choice: %s.%s' % (cls.__name__, value)) from e ```
This reassignment is pointless as `source_value` is not reused later. Perhaps: ```python value = classdict[key] if isinstance(value, (list, tuple)): try: value, display = value except ValueError as e: ... else: display = ...
**For me** I'd be happy to start using them, in new stuff, where appropriate. (I don't really want to see a changes of existing code just for the sake of it, if that makes sense.) (There was a thread on django-developers: I think it was, "shall we go through and replace all uses..?" — To which the answer was "No. We're happy even with the old `%` usage..." IIRC)
A docstring that merely describes the class signature provides no benefit.
but its standard too have a doc string
I wonder, maybe in future we should introduce a `django.conf` setting for this regexp
Maybe, on the other hand forcing people to use a specific (relatively) small set of names for sensitive data might be actually not so bad.
`test_foreign_key_GFK` -> `test_prefetch_GFK_fk_pk` Please move this test below `test_prefetch_GFK_uuid_pk()`.
Returning a dict would save you the sorting and the string parsing later in the tests, and environment variables are not sensitive to ordering, anyways.
`# PostgreSQL environment variables.`
Please revert this whitespace change.
Please add a trailing comma.
Collapse this list to one line - we allow up to 119 chars.
`- The dictionary of PG* environment variables, or {}.`
Can you revert this change? It seems unrelated.
I think that this comprehension could be collapsed to a single line.
Please add trailing comma.
I think you miss a test for this change.
We should check if it is supported and raise exception if it's not, e.g. ```python if no_key and not self.connection.features.has_select_for_update_no_key: raise NotSupportedError('NO KEY is not supported on this database backend.') ```
`has_select_for_no_key_update` -> `has_select_for_update_no_key`
Just a thought... Do we want to `::varchar` or `::text`? Both use the same underlying data type for storage, so `varchar` is no faster, and most of PostgreSQL's text manipulation functions will return `text` regardless of string types input.
Cool. I forget every time... 🥴
Trailing dot is missing.
I'm not sure if ternary fits here :thinking: , I would use ```python if extra_params.pop('unique', False) or extra_params.get('primary_key'): rel_type = 'OneToOneField' else: rel_type = 'ForeignKey' ```
`startswith()` accepts tuple, so we can use ```python if field_type.startswith(('ForeignKey(', 'OneToOneField(')): ```
@Jacobkg the place to make this change would be in the definition of the `client` property: ```python @cached_property def client(self): return pywatchman.client(timeout=5.0) ``` but neither place affects the client used to test for `pywatchman` availability, inside the `check_availability` method: ```python client = pywatchman.client(timeout=0.01) ```
the call with the `0.01` timeout in `check_availability` does fail for me sometimes on startup :)
Chop blank line.
This line and `os.mkdir(bad_target)` are unnecessary, we don't need to create directories for this test.
I would move test for conflict with an existing Python module to a separate test e.g. `test_importable_target_name`
I would use ```python with tempfile.TemporaryDirectory() as app_dir: for bad_target in ('invalid.name', '7invalid_name'): os.mkdir(os.path.join(app_dir, bad_targer)) ... ```
Might want to avoid `id` shadowing.
No need to create a `dict` if you're simply iterating over values.
Use a set here to perform containment checks.
IMO we can remove `_repetitive_name_errors()` hook, and move entire logic into `check_all_models()`, e.g. ```python for index_name, model_labels in indexes.items(): if model_labels: model_labels = set(model_labels) errors.append( Error( "index name '%s' is not unique %s %s." % ( index_name, 'amongst models:' if len(model_labels) > 1 else 'for model', ', '.join(model_labels), ), id='models.E030' if len(model_labels) > 1 else 'models.E029', ) ) for constraint_name, model_labels in constraints.items(): if model_labels: model_labels = set(model_labels) errors.append( Error( "constraint name '%s' is not unique %s %s." % ( constraint_name, 'amongst models:' if len(model_labels) > 1 else 'for model', ', '.join(model_labels), ), id='models.E032' if len(model_labels) > 1 else 'models.E031', ) ) ```
Might want to avoid `type` shadowing.
This whole function can probably be redefined as ```python repetitive_index_names = {k for k, v in Counter(names).items() if v > 1} return ( Error(...) for model, index_name in zip(models, names) if name in repetitive_index_names ) ```
I would use the same mechanism as for the `E020` and models' labels instead of `__name__`'s, i.e. ```python indexes = defaultdict(list) constraints = defaultdict(list) ... for model_index in model._meta.indexes: indexes[model_index.name].append(model._meta.label) for model_constraint in model._meta.constraints: constraints[model_constraint.name].append(model._meta.label) ```
I don't think it a good place for this, I would rather add loop by `self.constraints` and `self.indexes` below ```python self.index_together = normalize_together(self.index_together) ```
You don't need to specify `app_label`.
For an index I would use other field e.g. `name = models.CharField(...)` because `id` is a primary key, hence it already has an index on most of databases.
Which proves that it doesn't work properly because names of indexes should be `check_framework_model1_index` and `check_framework_model2_index`, currently it is `check_framework_abstractmodel_index` in both cases.
Constraints always have names.
It should use model's class instead of constraint's class. ``` 'class': cls.__name__.lower() ```
`"""` -> `'`
In American English, the punctuation usually goes inside the quote.
`"""` -> `'` etc.
`"""` -> `'`
In all such cases we can change to single quotes.
Yes, consistency matters :-) Maybe @timgraham can bring his expertise here.
Looks like in English the period is inside the quotes (see grammar sites).
I would chop `Do not crash in this case. `.
We can simplify this with `captured_stdout()`, e.g. ```diff diff --git a/tests/auth_tests/test_migrations.py b/tests/auth_tests/test_migrations.py index 4b4fe4bda2..56494d58d1 100644 --- a/tests/auth_tests/test_migrations.py +++ b/tests/auth_tests/test_migrations.py @@ -6,6 +6,7 @@ from django.apps import apps from django.contrib.auth.models import Permission, User from django.contrib.contenttypes.models import ContentType from django.test import TestCase +from django.test.utils import captured_stdout from .models import Proxy, UserProxy @@ -178,12 +179,6 @@ class ProxyModelWithSameAppLabelTests(TestCase): codename='display_proxys', name='May display proxys information', ) - - stream = io.StringIO() - old_stdout = sys.stdout - sys.stdout = stream - - update_proxy_permissions.update_proxy_model_permissions(apps, None) - - sys.stdout = old_stdout - self.assertIn('A problem arose migrating proxy model permissions', stream.getvalue()) + with captured_stdout() as stdout: + update_proxy_permissions.update_proxy_model_permissions(apps, None) + self.assertIn('A problem arose migrating proxy model permissions', stdout.getvalue()) ```
I would reduce indentation: ```python WARNING = """ A problem arose migrating proxy model permissions for {old} to {new}. Permission(s) for {new} already existed. Codenames Q: {query} Ensure to audit ALL permissions for {old} and {new}. """ ```
IMO ticket reference is not necessary.
We can add color to make it more visible :male_detective: , e.g. ```diff diff --git a/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/django/contrib/auth/migrations/0011_update_proxy_permissions.py index 79a3782bde..985e462118 100644 --- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py +++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py @@ -1,5 +1,6 @@ import sys +from django.core.management.color import color_style from django.db import migrations, transaction from django.db.models import Q from django.db.utils import IntegrityError @@ -18,6 +19,7 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False): Update the content_type of proxy model permissions to use the ContentType of the proxy model. """ + style = color_style() Permission = apps.get_model('auth', 'Permission') ContentType = apps.get_model('contenttypes', 'ContentType') for Model in apps.get_models(): @@ -44,7 +46,7 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False): except IntegrityError: old = '{}_{}'.format(old_content_type.app_label, old_content_type.model) new = '{}_{}'.format(new_content_type.app_label, new_content_type.model) - sys.stdout.write(WARNING.format(old=old, new=new, query=permissions_query)) + sys.stdout.write(style.WARNING(WARNING.format(old=old, new=new, query=permissions_query))) def revert_proxy_model_permissions(apps, schema_editor): ```
I noticed that `fwd_ref_str` is unused, #11312.
IMO splitting this with a new `RecursiveAsymmetricalM2MTests` class is not necessary.
I think we can add ``` sym_friends = models.ManyToManyField('self', through='SymmetricalFriendship', symmetrical=True) ``` to the `PersonSelfRefM2M` without creating a new model.
Can we use custom `date_friended`? and check is it set properly on an intermediary object.
It feels like unrolling the loop by accessing `where.children[]` and inlining `_test` like in other tests do would make the actual assertions simpler to interpret in the case of future failures. I'll let the committer make the last call here though since the assertions are actually correct.
Maybe: `logger.debug('Watchman error: %s, checking server status.', ex)`.
I haven't followed the entire logic, but I think you can minimize the mutable state a bit by instead keeping `health_check_delay` (immutable) and `last_health_check_at: Optional[float]`, where `None` means same as `health_check_done == False` and otherwise `health_check_at` is `last_health_check_at + health_check_delay`.
You might want to add 2 checks to the `check_settings` in the previous file (or maybe should be a system check?): 1. If `CONN_MAX_AGE == 0` then `CONN_HEALTH_CHECK_DELAY is None`. 2. If `CONN_HEALTH_CHECK_DELAY is not None` then `CONN_HEALTH_CHECK_DELAY < CONN_MAX_AGE`.
[Python 3 defaults `__ne__` as the opposite of `__eq__`](https://docs.python.org/3/reference/datamodel.html#object.__ne__). So I think we could drop this method.
Is this a typo? ```suggestion def __ge__(self, other): ```
This will be slightly different contrary to what is stated in your commit message. Here it was overriding `__str__` with `cls.__text_cast` which is effectively `func(*self.__args, **self.__kw)`. After your change it'll be relying on the original `__str__` which resolves to `str(func(*self.__args, **self.__kw))`. Perhaps this isn't a problem after the following commits though - I'll continue reviewing, but this is noted here.
Please change this `elif` to `if` so that there is not a `SyntaxError` when checking out this commit.
As already mentioned, this should be fixed in the earlier commit.
Am not sure that I follow the argument for this.
```python kwargs['min_value'] = max(value, kwargs.get('min_value', value)) ```
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
Does it not render with `placeholder="False"` then? Seems strange to me...
I think you can remove the blank lines as the helpers for checking HTML should ignore whitespace between tags.
In each of the three cases, can you change `False` to `None` and add a trailing comma. (I think we *could* also move the placeholder line to the top to allow it to be overridden by the context, but it may not be worth it as I'm not sure the attributes passed down can be specified for each select individually...)
Use `self.assertIs` and `self.assertIsNot` as these boolean expressions are noop.
Move import to top.
This change isn't right. `Derived.mro()` is ``` [Derived, DescendantOne, DescendantTwo, AbstractBaseOne, AbstractBaseTwo, django.db.models.base.Model, object, ] ``` The existing test is correct that `Derived` should inherit the `name` field from `DescendantTwo`. i.e. `max_length` should be 50.
Some time later... 🙂 About to mail the list re whether this change is acceptable.
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
I'm pretty sure you can make the abstract bases once in the test case class level: ``` class ...Tests(...): class SomeBase(models.Model): ... ``` Then reuse them appropriately in the individual test methods, which should only need to create the "bottom" classes? I grepped for `\btype\(` and found a few uses, but none are for "quick" building. I personally think the "tonnes of vertical scrolling" is a small concern compared to having to grok how `type()` works.
I think it's fine. Separate test cases are normally a good thing since they can fail individually.
We should use `column` from `get_attname_column()` instead of `name` because fields may have a custom `db_column`. I would also use only `local_fields` from parents. Moreover current `break` doesn't work if `RawSQL` contains field from different parents. Maybe sth like: ```python def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False, simple_col=False): # Resolve parents fields used in raw SQL. for parent in query.model._meta.get_parent_list(): for parent_field in parent._meta.local_fields: _, column_name = parent_field.get_attname_column() if column_name.lower() in self.sql.lower(): query.resolve_ref(parent_field.name, allow_joins, reuse, summarize, simple_col) break return super().resolve_expression(query, allow_joins, reuse, summarize, for_save) ```
This import is unnecessary.
`00` is not necessary, `friday_night_closing=datetime.time(21)`.
We should check if this statement works instead of returning `name` field, e.g. ```python def test_raw_sql_with_inherited_field(self): DepartmentStore.objects.create( name='Angus & Robinson', original_opening=datetime.date(2014, 3, 8), friday_night_closing=datetime.time(21), chain='Westfield', ) tests = ( ('name', 'Angus & Robinson'), ("case when name='Angus & Robinson' then chain else name end", 'Westfield'), ) for sql, expected_name in tests: with self.subTest(sql=sql): self.assertSequenceEqual( DepartmentStore.objects.annotate( title=RawSQL(sql, ()), ).values_list('title', flat=True), [expected_name], ) ```
This solution introduce really unexpected behavior, i.e. change every raw SQL that contains name of any column from a parent model with that column, e.g. if a parent model contains column `name` then following examples will be replaced by `"annotations_store"."name"`: - `case when name='foo' then 'oof' else 'foo' end` -> `"annotations_store"."name"`, - `concat(chain, 'name')` -> `"annotations_store"."name"`, - `other_column_with_name_in_it` -> `"annotations_store"."name"`, etc.
`regex` will be clunky. IMO unnecessary `JOIN`'s are acceptable in this case, there is not much we can do.
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
What I mean is that if you call this method twice on the same `SchemaEditor` instance and the `if` pass all conditions on the first time but not on the second the assignment to `self.sql_alter_column_type` will be used on the second method call's to `super()` when it shouldn't.
I didn't dig much into this ticket, but is it still possible to have a value type not in the list handled in `_resolve_output_field`? If yes, could we keep a test for such a value (maybe in expressions tests).
No as you are removing that test, I'm just asking to test somewhere the `Cannot resolve expression type` error with some Value having another type that those we are now automatically handling.
I would move it to the previous line i.e. ```python elif isinstance(value, (str, bytes)) or not doseq: query_val = value ```
I know it's a bit weird but I think to keep it, since we want to ensure that the `doseq=False` behaviour is correct. (I guess that's covered elsewhere but having both means the test, and what hangs on the switch, is easy to read.)
`OrderBy` expression can be more complicated e.g. it can contain different kind of expressions e.g. `Value()`, `Case()` etc. We will not be able to predict all use cases with regexp. Moreover IMO we don't need to provide message that can be copy & paste directly into queryset. Using `repr()` should be enough for clear message, e.g. ```diff diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py index 23bc339e78..83c10183a3 100644 --- a/django/db/models/sql/compiler.py +++ b/django/db/models/sql/compiler.py @@ -553,9 +553,9 @@ class SQLCompiler: # order_by = None warnings.warn( "%s QuerySet won't use Meta.ordering in Django 3.1. " - "Add .order_by('%s') to retain the current query." % ( + "Add .order_by(%s) to retain the current query." % ( self.query.model.__name__, - "', '".join(self._meta_ordering) + ', '.join(repr(f) for f in self._meta_ordering), ), RemovedInDjango31Warning, stacklevel=4, ``` ```
`pixeltype |= BANDTYPE_FLAG_HASNODATA` looks unrelated to the fix. Can you split your PR into two commits, first with refactoring (unrelated to fix) and second with a fix and tests. I will be easier for me to review this ticket.
This constant is unused.
Please move this ref below, to the place when we actually use it (for defining flags).
Merged typo fix in 5ec44973dc2add8ced1ba50659344b52cec845e5.
And accordingly. ```python # Encode pixeltype into 4 bits with leading zeros. pixeltype = format(pixeltype, '04b') # Set flags with is_offdb, is_nodata, and reserved flags always set to zero. if band.nodata_value is not None: # Turn has_nodata flag on. flags = '0100' else: flags = '0000' # Convert to final integer number. pixeltype = int(pixeltype + flags, 2)
Thanks @ivorbosloper now it makes sense to me and works fine. I got confused with upper and lower bits wording. Interesting that bits are counted from right to left from that point of view, and that the mask operation works. It would not work the same way with the `BANDTYPE_FLAGS_MASK` as my example shows.
You are right here as well. Your version is clearer for people that understand bitwise operators the flags structure, plus its shorter. For me he more "explicit" version is easier to follow, and probably true too for other people that do not have experience with the postgis bites structure or bitwise operators. But the conciseness of your version is convincing so lets use it.
Yes, sounds good, thanks :+1: I checked only new tests.
You can move it to a separate (first) commit in this PR.
`Grab` -> `Use`.
I think we can reuse `Parent` instead of `Author` and maybe add `ChildNullableParent` instead of `Book`.
I think we can reuse `Parent` and `ToFieldChild` models in this test, also this test is not falling without a fix so it has been fix earlier (do you know when?). Please move it to a separate commit.
IMO this is not a proper solution because it simple ignores all models, except the queryset's model.
Please move this test to the `select_for_update/tests.py`.
IMO this is not a proper fix because `CustomPK` doesn't appear in a `FOR UPDATE OF` statement, so this can cause a data loss. Both models should be included.
Right, sorry, forget about `encoding`, should be `gzip.open(str(password_list_path), mode='rt')` according to [the doc](https://docs.python.org/3.7/library/gzip.html#gzip.open). (Notice it's `rt`, not the usual `r`).
I think `{line.decode().strip() for line in f}` reads a little better. Also for the one below. BTW, since Django no longer supports Python 2.7, you can remove the explicit `decode()` step by passing `encoding='utf-8'` to `gzip.open()`, then you'll get a text-mode file rather than a binary-mode one. Finally, if you want to keep the previous idea of not duplicating the set/strip logic, you can write it like this: ```python try: f = gzip.open(str(password_list_path), encoding='utf-8') except OSError: f = open(str(password_list_path)) with f: self.passwords = {line.strip() for line in f} ```
I think this change should be undone. Python 3 (normally) defaults to `utf-8`... and when it doesn't, this change introduces the chance of a regression. The default file isn't the only possible gzipped file.
Huh, I assumed that the default is `utf-8`, but seems like it's not. So yes, should pass `encoding='utf-8'` to keep the previous behavior (for `bytes.decode()`, 'utf-8' is the default).
If anything is raised besides `OSError`, it will propagate, it won't continue to the `with` part. This is the same as the existing behavior.
From the stacktrace you pasted, it looks like the problem was that we assumed that it is `gzip.open()` that would throw `OSError` if the file is not a gzip, but in fact it only happens when the file is first read. So, it's not the `encoding` that's the problem (this should stay). So I think this is what we want - this time I did try it out :) ```python try: with gzip.open('test', mode='rt', encoding='utf-8') as f: self.passwords = {password.strip() for password in f} except OSError: with open('test') as f: self.passwords = {password.strip() for password in f} ```
I think `annotation` or `expr` might be a more appropriate variable name.
Could use `assertSequenceEqual` to avoid the `itemgetter`
This can be single-lined.
This class is unnecessary.
This can be single-lined.
Chop blank line.
We can register model without defining `OfficeAdminWithOrdering` with the same effect: ```python site.register(Office) ```
I think we can use one line examples, e.g. ```python xml1 = '<?xml version="1.0"?><!DOCTYPE root SYSTEM "example.dtd"><root />' xml2 = '<?xml version="1.0"?><!DOCTYPE root SYSTEM "example.dtd"><root />' ```
Only question would be whether `reverse_ordering()` should do the copying internally or not, rather than the copying happening outside. Long time since I've worked on this code, and I'm guessing your day spent debugging this could answer better than I :)
Tests shouldn't rely on internal APIs to trigger a bug.
Please use hanging indentation and avoid using of `\` (here and below), e.g. ```python subquery = AggregateTestModel.objects.values('char_field').annotate( stringagg=StringAgg('char_field', delimiter=';', ordering='-char_field'), ).exclude( char_field=OuterRef('char_field'), ).values('stringagg') ... ```
`output_field` is not necessary.
`OrderableAggMixin` contains `_get_ordering_expressions_index()` hook so you don't need to calculate this again. I would also simplify this and remove temporary variables, e.g. ```python def set_source_expressions(self, exprs): # Extract the ordering expressions as ORDER BY clause is handled in # a custom way. self.ordering = exprs[self._get_ordering_expressions_index():] return super().set_source_expressions(exprs[:self._get_ordering_expressions_index()]) ```
> this test is checking the support for a possible object that is seekable but has no `.tell()`. > `tempfile.NamedTemporaryFile()` has `.tell()`. Just as an aside, whether there is any change here or not, but you could do: ```python with tempfile.NamedTemporaryFile() as tmp: del tmp.tell # Emulate seekable file handle without .tell(). ... ```
Can you combine these 2 tests using `subTest()`
Are we really testing the Content-Type setting here? It strikes me this test is really about the Content-Disposition behaviour. We should focus it to that. (With a separate case for testing 'Content-Type' branched (such as guessing the content type from the filename.)
This is already covered by `test_file_from_disk_as_attachment()`
I'm thinking a single test setting the `custom_name` would be enough.
Please revert this unrelated change.
I would leave only `opt_name` and use `replace()` in `print()`, it should be more readable.
Maybe: `'Aborting: --start-at and --start-after are mutually exclusive.'`
Please add trailing comma.
`print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-'))`
IMO `else`is unnecessary i.e. ```python if '.' in opt_val: ... setattr(options, opt_name, os.path.normpath(opt_val)) ```
I think `if opt_val:` is sufficient.
Please add trailing comma.
Checking `found_start` looks unnecessary, maybe: ```python else: continue ```
We use the same logic in at least three places, I would add internal hook, e.g. `_module_match_label(self, module_label, label)`.
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
Do we need to check if `token` is an instance of `Mailbox`? I couldn't find an example that needs this check.
Please add edge cases to cover caching `IndexError` and `HeaderParseError`: ``` # Other invalid addresses. '@', 'to@', '@example.com', ```
I think we can leave the list of exceptions.
I found that it is valid as a tuple: `('To Example', 'to@other.com@example.com')` :thinking:
Nothing, it is just my personal preferences and it was just a suggestion.
I think we can move this under `try ... except`, e.g. ```python try: token, rest = parser.get_mailbox(addr) if rest: # The entire address must be parsed. raise ValueError nm = token.display_name or '' localpart = token.local_part domain = token.domain or '' except (HeaderParseError, ValueError, IndexError): raise ValueError("Invalid address '{}'".format(addr)) ```
Maybe shorter `# The entire email address must be parsed.`.
@pope1ni no, it's heavily cached as it's using `ContentType.objects.get_for_model`.
No need for `iter`, a generator expression works just fine.
Could use `reduce` here. ```python reduce(operator.or_, content_type_queries) ```
I might be worth sorting instances by content type first to avoid duplicates `Q` clauses; `groupby` expects objects to already be ordered by group.
This can be a generator expression, no need to materialize to a list.
Ahh right, I forgot about it. Thanks!
This hook can be added in a separate commit (used also in `GenericRelatedObjectManager.__init__()`).
I would leave it as a `lambda`.
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
`git pull --rebase` on your branch should be enough.
It looks that this change is not required. All tests pass without it.
This can be single-lined.
Please revert unrelated changes.
I think a specialized class is not required for this test case as you can rely on `.args` ```python try: raise Exception(2) except Exception as e: try: raise Exception(1) from e except Exception: exc_info = sys.exc_info() ... self.assertEqual(cm.exception.args[0], 1) self.assertEqual(cm.exception.__cause__.args[0], 2)
Just reverting this chunk should be sufficient.
I would override `clean()` as described in the ticket, e.g. ```python class PubForm(forms.ModelForm): mode = forms.CharField(max_length=255, required=False) mocked_mode = None def clean(self): self.cleaned_data['mode'] = self.mocked_mode return self.cleaned_data class Meta: model = PublicationDefaults fields = ('mode',) default_mode = 'di' pub_form = PubForm({}) pub_form.mocked_mode = 'de' pub = pub_form.save(commit=False) ... ```
TBH this is not what I suggested, I wanted to use `mocked_mode` to keep code DRY. I pushed edits.
I think that there is no need to check all empty values, so maybe: ``` # Default should be populated on an empty value. pub_form = PubForm({}) pub_form.mocked_mode = '' pub = mf2.save(commit=False) self.assertEqual(pub.mode, default_mode) ```
IMO we should re-use existing `form[f.name].field.empty_values` instead of `(None, '')`.
This can't be in `base`
Please remove this docstring, it doesn't have any value IMO.
> Is there any reason to explicitly prefer lowercase? Well, not really anything critical. Elements, attributes, etc. in HTML tend to be case insensitive and I tend to lowercase the lot - more similarity leads to better compression in transit. Granted this isn't going to make much difference for such a short string, and your point about implementation detail is fair. (Hence I didn't press for it...)
I would use `assertIn` instead of `self.assertContains` and `self.subTest`, e.g. ```python def test_error_pages(self): request = self.request_factory.get('/') for response, title in ( (bad_request(request, Exception()), b'Bad Request (400)'), (permission_denied(request, Exception()), b'403 Forbidden'), (page_not_found(request, Http404()), b'Not Found'), (server_error(request), b'Server Error (500)'), ): with self.subTest(title=title): self.assertIn(b'<!DOCTYPE html>', response.content) self.assertIn(b'<html lang="en">', response.content) self.assertIn(b'<head>', response.content) self.assertIn(b'<title>%s</title>' % title, response.content) self.assertIn(b'<body>', response.content) ```
This can be single-lined, e.g. ```python return HttpResponseServerError( ERROR_PAGE_TEMPLATE % {'title': 'Server Error (500)', 'details': ''}, content_type='text/html', ) ``` The same in `bad_request()` and `permission_denied()`.
`<head>` and `<title>` are missing if we want to have a valid HTML5 page, maybe ```python ERROR_PAGE_TEMPLATE = """ <!DOCTYPE html> <html lang="en"> <head> <title>%(title)s</title> </head> <body> <h1>%(title)s</h1><p>%(details)s</p> </body></html> """ ```
I'd also go for `<!doctype html>` (lowercased).
Yep. Looks good @felixxm
Maybe @felixxm or @carltongibson can guide, but I believe it'd be good practice to use a `warnings.warn` in `__init__`, although a deprecation timeline has not been determined for `django.contrib.postgres.field.JSONField`.
@CruxBox Please fix also `aggregation.tests.AggregateTestCase.test_combine_different_types`.
Use hanging indentation ```python raise FieldError( 'Expression contains mixed types: %s, %s. You must set ' 'output_field to %s.' % ( output_field.__class__.__name__, source.__class__.__name__, source.__class__.__name__, ) ) ```
Please restore the second sentence `You must set output_field.`. It should remain untouched.
`source` will be `None`.
`source` will be **always** `None` so it is not a proper solution.
Maybe: ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 16df317631..36f88f99ec 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -286,8 +286,15 @@ class BaseExpression: """ sources_iter = (source for source in self.get_source_fields() if source is not None) for output_field in sources_iter: - if any(not isinstance(output_field, source.__class__) for source in sources_iter): - raise FieldError('Expression contains mixed types. You must set output_field.') + for source in sources_iter: + if not isinstance(output_field, source.__class__): + raise FieldError( + 'Expression contains mixed types: %s, %s. You must ' + 'set output_field.' % ( + output_field.__class__.__name__, + source.__class__.__name__, + ) + ) return output_field @staticmethod ```
We should add short release note about this change in the `Backwards incompatible changes in 3.0 -> Database backend API`.
Chop blank line.
We use `field` only to find `internal_type`, so maybe instead of storing `field` we can find and store `internal_type` in `__init__()`? What do you think? ```python def __init__(self, field): self.internal_type = getattr(field, 'target_field', field).get_internal_type() ```
Oracle doesn't support primary keys on `LOB`, so `TextField` or `BinaryField` cannot be a primary key. We can remove it from this mapping.
`DATE` -> `DATETIME`
I think we can use `int` instead of `str` as a default value, because that's the most common use case. After that we can remove all types mapped to `NATIVE_INT` from `InsertReturnParameter.types`.
I would remove `get_field_name()` hook and call it `internal_type` (`field_name` is confusing IMO), e.g. ```python internal_type = getattr(self.field, 'target_field', self.field).get_internal_type() ```
We usually avoid _should_ verbiage in tests. e.g. ``` # Closing file_to_stream calls FileResponse.close() even when # file-like object doesn't have a close() method.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
Condense this to the following? ```python filelike_close = getattr(filelike, 'close', lambda: pass) ```
Really? Surely in this context it should be fine as it is an argument to `getattr()`… (Personally I don't like that check at it leads to cases like this where we have five lines of code instead of a single readable line.)
OK , thanks @codingjoe, @cjerdonek both. On reflection, I think it's OK as-is.
I don't think that it is a proper solution because `get_order_dir()` returns only field name and direction, so it will not properly in case of using database functions in `meta.ordering`. I think we should fix this in `find_ordering_name()`, e.g. ```diff diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py index a44adfc760..fb2a4b23b1 100644 --- a/django/db/models/sql/compiler.py +++ b/django/db/models/sql/compiler.py @@ -716,6 +716,9 @@ class SQLCompiler: results = [] for item in opts.ordering: + if isinstance(item, OrderBy): + results.append((item, False)) + continue results.extend(self.find_ordering_name(item, opts, alias, order, already_seen)) return results ```
This change is not related with test and can be reverted.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
@CruxBox my point is that you are already returning in the case of an exception *and* in the `else` clause so the code is equivalent to ```python try: date_value = datetime.date(int(y), int(m), int(d)) except ValueError: # Return pseudo-ISO dates with zeros for any unselected values, # e.g. '2017-0-23'. return '%s-%s-%s' % (y or 0, m or 0, d or 0) date_value = datetime_safe.new_date(date_value) return date_value.strftime(input_format) ``` Again, this is minor but we usually avoid using `try/else` in the rest of the code base unless it's necessary.
Minor but the `else` clause wrapping is unnecessary here given you return in the `except`.
Chop blank line.
I don't think that this test is required.
`stderr` -> `stdout`
I would use `DJANGO_SUPERUSER_PASSWORD`.
`if it is present.` -> `, if provided.`
``` # Environment variables are ignored in interactive mode. ```
Ahh, I see! Thank you for the quick reply! Learning a lot from these PRs! :)
:+1: grrr, presence of items with `None` vs non-existence. Thank for the nudge.
Yeah, good point.
How about this? ```python for field_name in self.UserModel.REQUIRED_FIELDS: value = options.get(field_name, os.environ.get('DJANGO_SUPERUSER_' + field_name.upper())) if value is None: raise CommandError('You must use --%s with --noinput.' % field_name) field = self.UserModel._meta.get_field(field_name) user_data[field_name] = field.clean(value, None) ``` Alternatively, a bit more verbose: ```python for field_name in self.UserModel.REQUIRED_FIELDS: env_var = 'DJANGO_SUPERUSER_' + field_name.upper() value = os.environ.get(env_var) value = options.get(field_name, value) if value is None: raise CommandError('You must use --%s with --noinput.' % field_name) field = self.UserModel._meta.get_field(field_name) user_data[field_name] = field.clean(value, None) ```
You can replace the if condition and branch with this one liner. Set `username` to the value of the environment variable defined by `username_env_var` or to its current value. ```python username = os.environ.get(username_env_var, username) ```
But still it can be simplify, e.g. ```python for field_name in self.UserModel.REQUIRED_FIELDS: env_var = 'DJANGO_SUPERUSER_' + field_name.upper() value = options[field_name] or os.environ.get(env_var) if not value: raise CommandError('You must use --%s with --noinput.' % field_name) field = self.UserModel._meta.get_field(field_name) user_data[field_name] = field.clean(value, None) ```
I would remove this docstring.
`stderr` -> `stdout`
``` # Environment variables are ignored in non-interactive mode, if provided. ```
This also can be simplify: ```python call_command( 'createsuperuser', interactive=False, username='test_superuser', email='joe@somewhere.org', stdout=StringIO(), ) user = User.objects.get(username='test_superuser') self.assertEqual(user.email, 'joe@somewhere.org') self.assertFalse(user.has_usable_password()) ```
I think we can simplify this: ```python if username is None: username = os.environ.get('DJANGO_SUPERUSER_' + self.UserModel.USERNAME_FIELD.upper()) ```
In this test `stdin=MockTTY()` is still required.
This can be single-lined.
I was confused why we have two different queries in `get_key_columns()` and `get_relations()` that return the same columns but in a different format, so I unified them in #11577. What do you think? it should make this change much simpler.
It looks unnecessary to me.
Is all of this necessary?, why not just: ```SQL JOIN pg_class c ON c.relname = kcu.table_name WHERE kcu.table_name = %s AND tc.constraint_type = 'FOREIGN KEY' AND pg_catalog.pg_table_is_visible(c.oid) ``` You don't need to add `pg_catalog.`
If we skip sub-parsers as actions then all tests still pass and `if opt.option_strings` condition is not required anymore, e.g. ```python # Parser actions and actions from sub-parser choices. def get_actions(parser): for opt in parser._actions: if isinstance(opt, _SubParsersAction): for sub_opt in opt.choices.values(): yield from get_actions(sub_opt) else: yield opt parser_actions = list(get_actions(parser)) ``` That's because `dest` for sub-parsers is not a valid option and don't need to be in `dest_parameters`.
New tests pass without this change.
Is this required? I think we should collect parsers and choices from sub-parsers, e.g. ```python if isinstance(opt, _SubParsersAction): for sub_opt in opt.choices.values(): actions += get_actions(sub_opt) else: actions.append(opt) ``` After that we can remove `if opt.option_strings` from `parse_args += [...`
I don't think that we need an internal hook.
This assertion is not related with this fix so I would move it to a separate commit.
`parent_data` and `child_data` are `CharField`\`s, so maybe `'a'`, `'b'`, ... etc.
`assertNotIn` may pass from many reasons. I think it is better to check field value with `self._get_field_values()` hook, e.g. ```python self.assertEqual(self._get_field_values(child_data, 'parent_m2m'), []) ```
Yes, sorry, typo `... a list of tuples containing two values.`
Probably we should also allow for a `list` to do not create any regression, and raise: ```python raise ValueError( 'The ADMINS setting must be a list or tuple containing two values.' ) ```
This is exactly the same as the previous case, maybe `('test@example.com',)`
You can join these two lines, e.g. ```python tests = ( 'test@example.com', ('test@example.com',), ['test@example.com', 'other@example.com'], ('test@example.com', 'other@example.com'), ) for setting, mail_func in ( ('ADMINS', mail_admins), ('MANAGERS', mail_managers), ): msg = ( 'The %s setting must be a list or tuple containing two values.' % setting ) for value in tests: with self.subTest(setting=setting, value=value), self.settings(**{setting: value}): with self.assertRaisesMessage(ValueError, msg): mail_func('subject', 'content') ```
Maybe `statements` -> `operations`.
We can remove `-- ` prefix from all outputs.
```suggestion self.assertEqual(err.getvalue(), 'No statements found.\n') ```
You can mock return value in a decorator, e.g. ```python @mock.patch('socket.getfqdn', return_value='漢字') ```
I don't see much value in this docstring, please remove it.
Inner import is not necessary: ```python from django.core.mail import ( DNS_NAME, EmailMessage, EmailMultiAlternatives, mail_admins, mail_managers, send_mail, send_mass_mail, ) ```
Maybe `@xn--p8s937b>` to be sure that it is a domain part.
Please import `mock` from `unittest`, ```python from unittest import mock ```
You can use `self.assertXMLEqual`, e.g. ```python def test_xml_serialization(self): test_xml_data = ( '<django-objects version="1.0">' '<object model="postgres_tests.jsonmodel">' '<field name="field" type="JSONField">%s' '</field></object></django-objects>' ) for value, serialized in self.test_values: with self.subTest(value=value): ... self.assertXMLEqual(data, test_xml_data % serialized) ... ```
Name corrections should be moved into `set_name_with_model()`, e.g. ```python if self.name[0] == '_' or self.name[0].isdigit(): self.name = 'D%s' % self.name[1:] ```
This assertion should stay in the `Index` class.
I would use `choices` in `labels` and `values` to simplify implementation, e.g. ```python @property def labels(cls): return [label for _, label in cls.choices] @property def values(cls): return [value for value, _ in cls.choices] ```
I think we can use `in cls` instead of `in cls.__members__.values()` (here and in `names`).
`%s(%r)` -> `%s (%r)`
Ahh OK, so maybe `%s.%s`.
Add the `@skipUnlessDBFeature('supports_table_check_constraints')` decorator.
Yes we can add `_check_object_identifiers()` and share the same errors: ``` * **models.E033**: The index/constraint name ``<index>`` cannot start with an underscore or a number. * **models.E034**: The index/constraint name ``<index>`` cannot be longer than ``<max_length>`` characters. ```
Add the `@skipUnlessDBFeature('supports_table_check_constraints')` decorator.
This will work only for a simple use case, e.g. ``` python manage.py startapp test_four ../../main_directory/ticket_30618/ticket_30618/other_apps_3 ``` produces `name = '......main_directory.ticket_30618.ticket_30618.other_apps_3'`
Chop blank lines.
We should check `err`, also temporary variable `args` is unnecessary: ```python _, err = self.run_django_admin(['startapp', 'test_app', target_dir]) self.assertNoOutput(err) ```
You can remove this docstring.
You can encapsulate `tuple`: ```python for target, expected_name in test_args: ```
I think we should use `relpath()` but only if it is below the working directory, e.g. ```diff diff --git a/django/core/management/templates.py b/django/core/management/templates.py index c7252a5ad2..db417443b2 100644 --- a/django/core/management/templates.py +++ b/django/core/management/templates.py @@ -65,6 +65,7 @@ class TemplateCommand(BaseCommand): self.validate_name(name) # if some directory is given, make sure it's nicely expanded + app_python_path = name if target is None: top_dir = path.join(os.getcwd(), name) try: @@ -77,6 +78,11 @@ class TemplateCommand(BaseCommand): if app_or_project == 'app': self.validate_name(os.path.basename(target), 'directory') top_dir = os.path.abspath(path.expanduser(target)) + # Use a relative path if it's below the current working + # directory, or an app name otherwise. + rel_path = os.path.relpath(top_dir) + if not rel_path.startswith('..'): + app_python_path = rel_path.replace('\\', '/').replace('/', '.') if not os.path.exists(top_dir): raise CommandError("Destination directory '%s' does not " "exist, please create it first." % top_dir) @@ -101,6 +107,7 @@ class TemplateCommand(BaseCommand): context = Context({ **options, + **({'app_python_path': app_python_path} if app_or_project == 'app' else {}), base_name: name, base_directory: top_dir, camel_case_name: camel_case_value, ```
This can be single-lined.
`STATIC_ROOT` should probably be `MEDIA_URL`? `*_ROOT` refers to actual fs paths.
Please revert unrelated changes.
This should use `self.subTest`, I also don't think that we need a `namedtuple` and `self.script_name_test_cases` variable, e.g. ```python tests = ( # SCRIPT_NAME ends with no slash, settings start with slashes. ('/somesubpath', '/static/', '/somesubpath/static/', '/media/', '/somesubpath/media/'), # SCRIPT_NAME ends with no slash, settings start with no slashes. ('/somesubpath', 'static/', '/somesubpath/static/', 'media/', '/somesubpath/media/'), ... ) for script_name, initial_static_url, final_static_url, initial_media_url, final_media_url in tests: with self.subTest(...): ... ```
One minor change here, please don't use `os.path.join` but `'/'.join(…)`. `os.path.join` uses `os.sep` which doesn't have to be a slash always.
I think this category can be dropped
Please chop `Refs #25598.`.
As said in the previous PR already, I think we should drop this
We could remove `check` constraints from the previous query.
I think we can remove `unqote_name` and always add `token.value[1:-1]`.
I would add `import sqlparse`.
If you're slicing `[1:-1]` just to remove backticks (`` ` ``) around column names, I think you need to find some other way. While working on https://github.com/django/django/pull/11452, I tried this function to get the `JSON_VALID` constraint for introspection. After some debugging, I found out that it gets sliced into `son_vali`. Perhaps using ``.strip('`')`` is enough, but I'm not really sure...
Previously we always changed the last option to `source_database_name`, see ```python dump_args[-1] = source_database_name ``` so it keeps this behavior.
Sorry typo: ```python dump_cmd = ['mysqldump', *dump_args[:-1], '--routines', '--events', source_database_name] ```
I think we can simplify this, e.g. ```python dump_cmd = ['mysqldump', *dump_args[:-1], '--routines', '--events', source_database_name] ```
My proposition keeps all arguments.
Please position this up near `has_native_uuid_field` and `has_native_duration_field`. You also need to add `has_native_serial_field = False` to `django/db/backends/base/features.py`.
Remove this blank line.
Use unpacking generalisations and remove arguments to `super()`: ```python super().__init__(*args, **{ 'editable': False, **kwargs, 'blank': True, 'default': Default(), 'unique': True, }) ```
Remove as `empty_strings_allowed = False` is inherited from `IntegerField`.
`'Big serial'` (`BigIntegerField` has `'Big (8 byte) integer'`, but I think we can keep this description simple.)
You also need to add `has_native_serial_field = False` to `django/db/backends/base/features.py`.
`serial` columns in PostgreSQL have a `NOT NULL` constraint. You may want to force `null` to be `False`
Please make this `IntegerField` instead of `PositiveIntegerField`. Similar to `AutoField`, which uses `serial`, although the field usually increments from `1`, it is not forbidden to store zero or negative values. Indeed, this is sometimes useful.
This change looks unrelated.
Please try to insert these alphabetically. This was requested of me when I added `SmallAutoField`. (I know it isn't actually properly sorted - I'll see if I can knock up a PR to do that.)
We don't need this feature flag since it's PostgreSQL-specific feature available from `django.contrib.postgres.fields`.
We should move introducing `Default()` expression to a separate commit.
Wrap at 79 chars.
It would be a bit more clear like: ``` {field_name: (field_name_other_table, other_table) for field_name, other_table, field_name_other_table in self.get_key_columns(cursor, table_name)} ```
`choices` and `widget` are unnecessary for this test. I think we can simplify it, e.g. ```python def test_boundfield_index_with_non_int_non_slice(self): class TestForm(Form): name = ChoiceField(choices=[]) msg = 'BoundField indices must be integers or slices, not str.' with self.assertRaisesMessage(TypeError, msg): TestForm()['name']['foo'] ```
@jdufresne I don't think that it's worth to change existing code.
So I'm fine to leave `type()` calls.
Nothing specific, it's just a pattern commonly used in Django. Probably because it was not the same in Python2.
Did you check `%timeit`? It suggests that `index.__class__.__name__` is faster.
I'm just afraid that we're changing a current behavior that works properly :thinking:, but I'm fine with your proposition. Off-topic: Do we need `watch_file()` at all? It looks unused :thinking: .
Do we need these changes? :thinking: `Path.absolute()` raises `FileNotFoundError`, so why not catch it in `watch_for_translation_changes()`, e.g. ```python for path in directories: try: absolute_path = path.absolute() sender.watch_dir(absolute_path, '**/*.mo') except FileNotFoundError: logger.debug('Skipping watching file %s as it cannot be resolved.', path, exc_info=True) ```
Great, thanks! I will merge #11590 and rebase this PR :+1:
I have one concern :disappointed: Should we clear cached instance when a value is the same? because this leads to unnecessary queries. Maybe we should check value before clearing an instance, e.g. ```diff diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py index 346f67289e..0b51b68ebe 100644 --- a/django/db/models/fields/related_descriptors.py +++ b/django/db/models/fields/related_descriptors.py @@ -73,7 +73,7 @@ from django.utils.functional import cached_property class ForeignKeyDeferredAttribute(DeferredAttribute): def __set__(self, instance, value): - if self.field.is_cached(instance): + if instance.__dict__.get(self.field.attname) != value and self.field.is_cached(instance): self.field.delete_cached_value(instance) instance.__dict__[self.field.attname] = value ``` You can find below tests that don't work anymore after the second commit. ```diff diff --git a/tests/many_to_one/tests.py b/tests/many_to_one/tests.py index 5efe137730..cf3bea86d4 100644 --- a/tests/many_to_one/tests.py +++ b/tests/many_to_one/tests.py @@ -164,6 +164,8 @@ class ManyToOneTests(TestCase): self.assertFalse(Parent.bestchild.is_cached(parent)) self.assertEqual(parent.bestchild, child2) self.assertTrue(Parent.bestchild.is_cached(parent)) + parent.bestchild_id = child2.pk + self.assertTrue(Parent.bestchild.is_cached(parent)) def test_selects(self): self.r.article_set.create(headline="John's second story", pub_date=datetime.date(2005, 7, 29)) diff --git a/tests/one_to_one/tests.py b/tests/one_to_one/tests.py index 76f9d75417..0bc94bbb32 100644 --- a/tests/one_to_one/tests.py +++ b/tests/one_to_one/tests.py @@ -213,6 +213,8 @@ class OneToOneTests(TestCase): self.assertFalse(UndergroundBar.place.is_cached(b)) self.assertEqual(b.place, self.p2) self.assertTrue(UndergroundBar.place.is_cached(b)) + b.place_id = self.p2.pk + self.assertTrue(UndergroundBar.place.is_cached(b)) def test_related_object_cache(self): """ Regression test for #6886 (the related-object cache) """ ```
My only concern about this descriptor it that defining `__set__` makes it a data descriptor which means all getter accesses will go through `DeferredAttribute.__get__` and incur a function call while `DeferredAttribute` is a non-data descriptor and only gets `__get__` called on missing `__dict__` values. I guess that's a small penality to take in the name of correctness but I thought I'd mention it even if I don't have a better solution for the problem this patch solves.
I added this missing change to the first commit.
It's a bit :scream: to me. `filter()` doesn't change anything for combined queries so I think we should handle this in `get()`, e.g. ```python def get(self, *args, **kwargs): clone = self._chain() if self.query.combinator else self.filter(*args, **kwargs) ```
Clever use of the integer nature of `bool`, first time I've seen this pattern. It kind of hurts readability though IMO.
I would use `NotSupportedError`.
Maybe e.g. `Calling exclude() is not supported after union().`
Sorry for the previous suggestion but decorator looks weird to me :smile: Method would be better, e.g. ```python def _not_support_combined_queries(self, name): if self.query.combinator: raise NotSupportedError( 'Calling %s() is not supported after %s().' % (name, self.query.combinator) ) ```
I think we want to fail as soon as `combinator` is truthy ```suggestion if self.query.combinator: ```
We should add `annotate()` to the list, also please use hanging indentation.
Should we name this `is_sliced` instead? In the case of `[10:]` which translates to `low_mark=10;high_mark=None` there's no `LIMIT` on the query only an `OFFSET`. It also seems more in line with its current usages.
`add_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.add_index(model, self.index, concurrently=True) ```
Not a blocker or anything but `concurrently` seems more appropriate than `concurrent` for the kwarg name to me. e.g. `add_index(model, index, concurrently=True)`
We can revert changes in `_alter_field()`.
We can revert changes in `_delete_unique_sql()`.
@atombrella Do we need inner imports here? Imports at the top works fine for me.
Chop blank line (many blank lines in these tests are unnecessary).
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Chop blank line.
Chop blank line.
`_delete_index_sql()` accepts `sql` argument, so you can use `super()._delete_index_sql()`, e.g. ```python def _delete_index_sql(self, model, name, concurrently=False): sql = self.sql_delete_index_concurrently if concurrently else self.sql_delete_index super()._delete_index_sql(model, name, sql=sql) ```
`remove_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.remove_index(model, self.index, concurrently=True) ```
Add trailing comma.
We can revert changes in `alter_index_together()`.
Chop blank line.
I changed this and pushed some minor edits in the #11687.
I think we usually avoid _should_ wording in test docstrings.
`alter_index_together()` also uses `self.sql_delete_index` :disappointed:
This should be changed also in the `PostgresIndex`.
I would leave `INDEX` and add only `%(concurrent)`.
We want to change whitespaces in the traceback, so we should test these changes e.g. ```python self.assertIn( ' File "generated", line 2, in funcName\n' ' <source code not available>', text, ) ```
We should be able to use one of existing expressions.
We can move check to the [previous `if` condition](https://github.com/django/django/pull/11600/files#diff-0edd853580d56db07e4020728d59e193R1286-R1288).
yeah having an `Expression.nullable` flag that is also present on `Col` instance based on the `Field.null` they resolve would be useful for a few other things I've worked on in the past.
I would remove this docstring.
`Count(..., distinct=True)` is already tested in `test_count()` and it is not related with this patch, so we can refactor tests but in a separate commit, e.g. - 1st commit: _"Moved test for distinct Count() to a separate test case."_: ```diff diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py index ea11c02edc..2f667a0fe1 100644 --- a/tests/aggregation/tests.py +++ b/tests/aggregation/tests.py @@ -388,9 +388,6 @@ class AggregateTestCase(TestCase): vals = Book.objects.aggregate(Count("rating")) self.assertEqual(vals, {"rating__count": 6}) - vals = Book.objects.aggregate(Count("rating", distinct=True)) - self.assertEqual(vals, {"rating__count": 4}) - def test_count_star(self): with self.assertNumQueries(1) as ctx: Book.objects.aggregate(n=Count("*")) @@ -403,6 +400,10 @@ class AggregateTestCase(TestCase): ) self.assertEqual(aggs['distinct_ratings'], 4) + def test_distinct_on_aggregate(self): + books = Book.objects.aggregate(Count('rating', distinct=True)) + self.assertEqual(books, {'rating__count': 4}) + def test_non_grouped_annotation_not_in_group_by(self): """ An annotation not included in values() before an aggregate should be ``` - 2nd commit, fix and extra test cases (with `self.subTest`), e.g. ```python def test_distinct_on_aggregate(self): for aggregate, expected_result in ( (Count, 4), (Sum, 16.5), (Avg, 4.125), ): with self.subTest(aggregate=aggregate): books = Book.objects.aggregate(ratings=aggregate('rating', distinct=True)) self.assertEqual(books['ratings'], expected_result) ``` Also, I think that `Book.rating` would be better for testing `distinct` argument.
I don't think that we need `Approximate()`.
This assertion is not necessary.
I think the original `reffed_expression.__class__.__name__` should be used.
Hadn't considered this.
I don't think that we should change anything in the `resolve_expression()`, IMO the easiest way to implement this is to override `filterable` property for `CombinedExpression` and `Func`, e.g. ```diff --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -454,6 +454,10 @@ class CombinedExpression(SQLiteNumericMixin, Expression): c.rhs = c.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save) return c + @property + def filterable(self): + return self.lhs.filterable and self.rhs.filterable + class DurationExpression(CombinedExpression): def compile(self, side, compiler, connection): @@ -630,6 +634,10 @@ class Func(SQLiteNumericMixin, Expression): copy.extra = self.extra.copy() return copy + @property + def filterable(self): + return all(expr.filterable for expr in self.get_source_expressions()) + ```
This optimization is used only for backends with `allows_group_by_selected_pks` feature, we should use it here, e.g. ```python def allows_group_by_selected_pks_on_model(self, model): if self.allows_group_by_selected_pks: return model._meta.managed return False ```
I think we can remove this docstring.
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
Chop blank line.
Chop blank line.
`assertEqual` -> `assertTrue`
This is not related with `allows_group_by_pk`, it should contain two columns: ```python self.assertEqual(len(grouping), 2) ```
This is not related with `allows_group_by_pk`, it should contain two columns: ```python self.assertEqual(len(grouping), 2) ```
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
`assertEqual` -> `assertTrue`
``` # Unmanaged related model that is a table. ```
``` # Unmanaged origin model that is a table. ```
We cannot return `True` if a backend doesn't support it at all.
``` # Unmanaged origin model that is not a table. ```
``` # Unmanaged related model that is not a table. ```
This and `test_fk_to_bigautofield` above are a funny pair of tests. (`assert did_not_blow_up`... :)
Please use single quotes.
Please use single quotes.
`__str__` is not necessary.
Please alphabetize, add it before `SmallIntegerField`.
Yes only `BigInteger` breaks alphabetical order (in all backends), I don't want to break it more.
I think we should use `NUMBER(5)` on Oracle (I know that it is not consistent with `SmallIntegerField`), but in that way we will be able to introspect `SmallAutoField` and it would give a real optimization.
I was just curious why we chose them, it seems that we want to test creation with manually specified `ID`. It can stay.
I would add this dict above, e.g. ```python serial_fields_map = {'bigserial': 'bigint', 'serial': 'integer', 'smallserial': 'smallint'} if new_type.lower() in serial_fields_map: column = new_field.column sequence_name = "%s_%s_seq" % (table, column) return ( ( self.sql_alter_column_type % { "column": self.quote_name(column), "type": serial_fields_map[new_type.lower()], }, [], ), ... ```
Do we need to delete these models? I don't think that below tests are required,
I changed this to `SmallIntegerField` -> `SmallAutoField` conversion. Generally, changing `Integer` to `SmallAuto` is not sth that we want to support.
`__str__` is not necessary.
I don't think that we need a `source_value`. You can move `create_initial_data()` outside this loop to the previous place. This should reduce the diff.
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
Chop blank line.
Maybe: ```python raise CommandError( "Required field '%s' specifies a many-to-many relation " "through model, which is not supported." % field_name ) ```
`add()` accepts IDs so we can simplify this, e.g. ```python ... user.save(using=self._db) user.orgs.add(*orgs.split()) ```
I would use `Organization` IDs here and in `test_fields_with_m2m()`, e.g. ```python org_id_1 = Organization.objects.create(name='Organization 1').pk org_id_2 = Organization.objects.create(name='Organization 2').pk ... @mock_inputs({ 'password': 'nopasswd', 'Username: ': 'joe', 'Orgs (Organization.id): ': '%s %s' % (org_id_1, org_id_2), }) ```
`kwargs` are not necessary to raise an exception, e.g. ```python @override_settings(AUTH_USER_MODEL='auth_tests.CustomUserWithM2MThrough') def test_unsupport_fields_with_m2m_and_through(self): msg = ( "Required field 'orgs' specifies a many-to-many relation through " "model, which is not supported." ) with self.assertRaisesMessage(CommandError, msg): call_command('createsuperuser') ```
Chop blank line.
`CustomUserWithM2MAndThrough` -> `CustomUserWithM2MThrough`
Chop blank line.
At some point, I wondered if it would be easier to just let users do `.exclude(is_superuser=True)` when they need to.
I think `include_superusers`, even if longer, would be more clear.
... also we cannot use `User` in the `BaseBackend` so it will be hard to return something consistent.
I don't that we should do this. `BaseBackend` contains only basic methods.
I think it's more readable without multiple `message_*` variables, e.g. ```python if settings.DATABASE_ROUTERS: for db_table, model_labels in db_table_models.items(): if len(model_labels) != 1: errors.append( Warning( "db_table '%s' is used by multiple models: %s when ' 'database routers are installed." % (db_table, ', '.join(db_table_models[db_table])), obj=db_table, id='models.W029', ) ) else: for db_table, model_labels in db_table_models.items(): if len(model_labels) != 1: errors.append( Error( "db_table '%s' is used by multiple models: %s." % (db_table, ', '.join(db_table_models[db_table])), obj=db_table, id='models.E028', ) ) ```
Might want to avoid mentioning `PDB` since `ipdb` will be used if present? ```suggestion help='Runs the debugger on error or failure.' ```
Is this necessary? If not I don't see much harm in changing the type to a list internally or even to always convert it to a `tuple` to avoid hashing errors down the line.
Given that we're touching this, we should probably [use hanging indent](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I like this approach much better than #11641 ! At first I was a little concerned about checking the vendor attribute within a vendor neutral method, but it's easy to patch on classes you don't control and easy to modifying on ones that you do. If it ends up being an issue in practise moving forward we can look at better ways to make it more generic.
`CharField` should only accept strings, not integers. This should be `choices=[('1', 'One'), ('2', 'Two')]` and then there is no issue.
I feel like it might be a good idea to eventually require that one or both of these be set explicitly, rather than relying on these hardcoded defaults. (I can't completely articulate why, though, so maybe it's not that good an idea.)
Should these (this and the similar case below) be warnings instead of/as well as debug messages? They seem like potential performance pitfalls.
``` # Exit out to async mode, if needed. ```
This wouldn't happen on every request, just on server restart (when `load_middleware()` is called)
I moved `check_none_response()` to a separate PR #12474 and renamed it to the `check_response()`. I'm going to rebase this patch after merging.
This refactoring of this logic out into out into `check_none_response` is a nice bonus cleanup!
Is this possible? If so, it will be good to cover this scenario with tests.
I think this should use the `request['path']`.
I fixed this issue in fe0ddbc84e4d8836ce8d27a1218d360c5482c2be.
This looks like a leftover after rebase, `classproperty` is currently in `django.utils.functional`.
A system check seems a good option if the warning would be too noisy.
I wouldn't be shocked, but it really goes against "there should be one way of doing things". So all in all if anyone has ideas to finish what we started with the middleware move I'd happily use that over the status quo. Is the code of your efforts online somewhere? Maybe we find a way to fix decorators :)
@claudep Is "no idea, I hoped a clear answer" would emerge sooner or later enough? Joking aside, I do not have good answers :(
Sorry, wasn't trying to request a change, was thinking about how async middleware would be written and just seeking clarification.
the following with an async `__call__` works for me! ``` class Test: async def __call__(self): return True ``` and `inspect.iscoroutinefunction(Test.__call__) -> True`
Would it work to declare the async middleware like this? ``` class AsyncBaseMiddleware(BaseMiddleware): _is_async = True class AsyncTeapotMiddleware(AsyncBaseMiddleware): async def __call__(self, request): response = await self.get_response(request) response.status_code = 418 return response ```
What about the following? ```suggestion if asyncio.iscoroutinefunction(getattr(middleware, '__call__', None)): ```
Part of my work is https://github.com/django/django/pull/11828 (I'll rebase soon). But then I blocked on deprecating `MiddlewareMixin` due to decoration.
That's what `inspect.iscoroutinefunction(getattr(Foo, '__call__', None))` does above. What I mean is that it's probably an abuse of Python data model. For example, ```python def Test: async def __iter__(self): pass assert inspect.iscoroutinefunction(Test.__iter__) ``` Won't fail but `__aiter__` should be used for this purpose. There's no analogous `__acall__` for `__call__` and it's not clear to me whether `async def __call__` is an abuse or not.
No, they are not supported, because `BOOLEAN` datatype is available only in PL/SQL on Oracle, so `SELECT` clause cannot return it.
Please chop blank line.
Can you put this block in a helper? ``` context_kwargs = _adams_helper_with_a_good_name(...) ```
So maybe without cache, with a separate property we will be able to fix this in only one place after [30712](https://code.djangoproject.com/ticket/30712).
Maybe we could add a cached property with this check in `schema.py`, e.g. ```python @cached_property def _support_default_on_limited_data_type(self): return self.connection.mysql_is_mariadb and self.connection.mysql_version > (10, 2) ```
I would revert this, i.e.: ```python if self.connection.mysql_is_mariadb and self.connection.mysql_version > (10, 2): return True return self._is_limited_data_type(field) ```
Chop this link.
Chop this link.
Can we move tests for callable that returns `pathlib.Path` to a separate commit? It works before this change.
This path shouldn't change a default test settings.
We can chop `Only`. Please wrap at 79 chars.
For MySQL >= 8.0.13, `default` was not fully supported as other backends, for example: Alter a field with default value: ✅ `ALTER TABLE foo MODIFY COLUMN bar LONGTEXT DEFAULT("");` ❌ `ALTER TABLE foo ALTER COLUMN bar SET DEFAULT ('');` So unless we could tell what kind of action of this SQL is taken, otherwise we should always return `False` for safe.
Please wrap at 79 chars.
We should add parentheses only on MySQL > 8.0.13 and only for `_limited_data_types`. I don't think that a new class variable/property is a good solution. I would rather add a method ```python def _column_default(self, field): return '%s' ``` that can be override in a MySQL backend, e.g. ```python def _column_default(self, field): if ( not self.connection.mysql_is_mariadb and self._supports_limited_data_type_defaults and self._is_limited_data_type(field) ): return '(%s)' return super()._column_default(field) ``` This can easily be reused in `_alter_column_default_sql()`.
Please rename to `_column_default_sql()` it sounds better to me, also a docstring would be helpful, e.g. ``` """ Return the SQL to use in a DEFAULT clause. The resulting string should contain a '%s' placeholder for a default value. """ ```
```suggestion self._meta.pk.default and self._meta.pk.default is not NOT_PROVIDED ```
I think you can drop `title` entirely.
Ah, yes, obviously!
This looks unrelated.
Check constraints don't seem to be related with this issue, moreover `unique` is `False` for all check constraints. Please revert this unrelated change.
IMO this change can be reverted.
I checked related ticket [30152](https://code.djangoproject.com/ticket/30152) and I'm in favor of [Matthijs' proposition](https://code.djangoproject.com/attachment/ticket/30152/testcase_and_rough_fix.patch) because we don't need to go through all fields.
I don't think we need the blank line here.
```suggestion raise ImproperlyConfigured("URL route '%s' contains invalid whitespace." % route) ```
You want to use set operations here: ```suggestion if not set(route).isdisjoint(string.whitespace): ```
Let's go with `...cannot contain whitespace.` (I briefly considered that, so it coming up twice, we'll take as a message from the universe.)
Maybe without `invalid`? `"URL route '%s' contains whitespace."` or `"URL route '%s' cannot contain whitespace."`
Yep, I think 500 is massive™ delay. Let's try 250.
Backticks are unnecessary, IMO: ``` # Populate "fields" dynamically because SEARCH_VAR is a variable. ```
We don't use keys so maybe shorter: ```python messages.error(request, ', '.join(_search_form.errors.values())) ```
Ahh, right, so :wink: : ```python for error in _search_form.errors.values(): ```
We can also check the name: `self.assertTrue(name.startswith('__unnamed_constraint'))`
The following should be tested as well ```python .update(field__c='Test Value', field__b='Other Value') ```
``` Return an alternative filename, by adding an underscore and a random 7 character alphanumeric string (before the file extension, if one exists) to the filename. ```
``` # If the filename already exists, generate an alternative filename # until it doesn't exist. ```
This assertion doesn't fail without a patch, IMO we can remove it.
We could probably use more complicated expression to get rid of a temporary variable to make it more "atomic", e.g. ```python self._order = cls._base_manager.using(using).filter(**filter_args).aggregate( max_order=Coalesce( ExpressionWrapper(Max('_order') + Value(1), output_field=IntegerField()), Value(0), ), )['max_order'] ``` :thinking:
I don't think it's good practice to change instances created in `setUpTestData` as they should be identical for the whole test class.
Remove unrelated white-space change.
Single quotes please and wrap at 119 characters. (Please do this everywhere as appropriate.)
Use the `hint` parameter for listing valid values, e.g. ```python E023 = Error( 'You have set the SECURE_REFERRER_POLICY setting to an invalid value.', hint='Valid values are: {}.'.format(', '.join(sorted(REFERRER_POLICY_VALUES))), id='security.E023', ) ``` Also, the current convention is to not have independent numbering for warnings and errors, so use `E023` instead of `E001`.
It should be possible to specify multiple values to allow for fallback where a value is not supported by a user agent: https://www.w3.org/TR/referrer-policy/#policy-token
(Grrr. Always miss one... Done now.)
I think I'd rather leave this. Leading/trailing whitespace is allowed but in-between multiple values... Grrr. https://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4.2
The list is already sorted, so the sort is redundant.
I wonder if this check is a good idea. On the one hand, it can catch mistakes/misspellings. On the other hand, new values will surely be added in time, and once the programmer adds a value Django doesn't know about, it triggers the warning. I think the check is valuable, but will be better as a separate warning, so it can be disabled on its own.
It will be better to use an `in` check, so that the entire construction can be skipped if not needed.
Are you sure you want to skip if the header already exists? Another option is to append it (by setting the header twice -- don't know if Django/WSGI supports that -- or manually).
This allows the allow-list dict value to be either a string or a list of strings. IMO it will be better to only support one method (insert zen of Python reference here). I think only supporting the string would be better, because then the quoting of `self` etc. is explicit and there are less surprises.
I don't think that this header is whitespace-sensitive. :thinking:
I don't see much value in this docstring.
I don't see much value in this docstring.
Do we need to do this? it is confusing (at least for me) to split and then join by `','`, maybe: ```python response.setdefault( 'Referrer-Policy', self.referrer_policy if isinstance(self.referrer_policy, str) else ','.join(self.referrer_policy), ) ```
Please wrap at 79 chars.
Please wrap at 79 chars.
Please wrap at 79 chars.
Please wrap all message at 79 chars.
Might want to make this an `IntegerField` to avoid taking alteration to an incompatible type into account (e.g. uuid to int).
Why we use `max()` here? :thinking: i.e. ```python max_length = len(value) ``` works fine for me.
`max_length` and `choices` can be set also for other fields, e.g. `TextField` or `EmailField`, that's why I'm going to move this check to the `fields.E009`.
I think we can add check for `group_choices` to the `if` condition and simplify `max()`, e.g. ```python if self.max_length is not None and group_choices: max_length = max( len(value) for value, _ in group_choices if isinstance(value, str) ) ```
Chop blank line.
Please remove the extra line (also to make isort happy).
My spellcheck tool of choice (languagetool) suggests a little change. ```suggestion """Email this user and return the number of emails sent.""" ```
I don't think what we need to split this test to db-specific variants, the only difference is in tested SQL `RETURNING %s.%s, %s.%s INTO` (Oracle) vs. `RETURNING %s.%s, %s.%s` (PostgreSQL). IMO testing against `RETURNING %s.%s, %s.%s` is sufficient for both.
Note: binding multiple variables via `cursor.execute()` works with `cx_Oracle 6.0+` :+1: so we don't need to check version of `cx_Oracle`.
Please revert this change. We can get an unsupported combination of DB features in the future, so it's good to keep it.
I believe `params` should no longer contain any more `Expression` objects, and I ran the test suite with this change and didn't see any related failures. Trying to special case `Value` (and other expressions like it) seems like a losing battle because they may be nested inside other expressions. ```suggestion return sql % tuple(self.quote_value(p) for p in params) ```
Use `self.assertAlmostEqual()` rather than formatting as a string.
This looks like it will fail if `params` contains a mix of expressions and basic values. While I can't find anywhere that passes multiple `params` here currently, it seems like a caller should be able to do that.
Catching `AttributeError` like this may mask errors raised from inside `as_sql()` and make debugging difficult. I'd suggest: ```suggestion elif hasattr(node, "as_sql"): sql, params = node.as_sql(self, self.connection) else: sql, params = None, (node,) ```
I think it's a bit neater to invert the check for `node.as_sql` and return early: ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) sql, params = compiler.compile(node) return sql, tuple(params) ```
There's no assertion for `created_date`. You could check that is `datetime.date`and maybe also that `created_date == created.date()`? Alternatively you could drop `created_date`.
Rather than inherit from `SQLCompiler` (without initializing all of its member attributes) should we favor composition here? If I'm not mistaken, the only use of the `SQLCompiler` interface in this class is passing `self` to `as_sql()` and similar functions in `prepare_param()`. I tested retrieving an instance with `compiler = self.connection.ops.compiler("SQLCompiler")(query=None, connection=self.connection, using=None)`, passing that object in place of `self`, and removed the inheritance. The test suite still passed under postgres.
[`assertEquals` is a deprecated alias](https://docs.python.org/3/library/unittest.html?highlight=assertequals#deprecated-aliases) ```suggestion self.assertEqual(obj.pi, 3.14159265358979) ```
This assignment and tuple creation / unpacking, etc. isn't used in the case that `hasattr` is true. I also noted this below, but the conversation is marked resolved.
We expect compileable to always have an `as_sql` method. e.g. see `effective_default`'s implementation. ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) return compiler.compile(node) ```
@InvalidInterrupt is right, this should map `params` using `quote_value` just like it's done on other backends.
We usually use duck typing for such cases ```suggestion return self.has_default() and hasattr(self.default, 'as_sql') ```
Use `sql, params =` instead of `s, p =` to match the typical naming used elsewhere in the code.
`max_length` -> `maxlength`
You can avoid the assignment. ```suggestion Author.objects.create(name='one') ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
`CheckConstraint`, `UniqueConstraint` and `ExclusionConstraint` inherit form `BaseConstraint` it should be fine to call `super().__eq__(other)` if an other's class doesn't match, e.g. ```python def __eq__(self, other): if isinstance(other, UniqueConstraint): return ( self.name == other.name and self.fields == other.fields and self.condition == other.condition ) return super().__eq__(other) ```
@felixxm Will have a look at this tomorrow.
`name` is always a string so we don't need to serialize it. I changed this.
We don't use `self.value.value` anymore so we don't need to serialize it, we should use name instead, i.e. ```python v_string, v_imports = serializer_factory(self.value.name).serialize() imports = {'import %s' % module, *v_imports} return "%s.%s[%s]" % (module, enum_class.__name__, v_string), imports ```
Makes sense. Falling back to `field.db_type(self.connection)` will cause silent truncation of `ArrayField(CharField(max_length=100)) -> ArrayField(CharField(max_length=50))` and `ArrayField(Field(), size=10) -> ArrayField(Field(), size=5)` though but I guess it's better than crashing.
Actually `return field.db_type(self.connection)` should be enough as it defaults to `connection.data_types.get(self.get_internal_type())` https://github.com/django/django/blob/ff5dfbc63a278219cd929449678b99ebec9a4b5f/django/db/models/fields/__init__.py#L684-L688
I think we should check also previous field i.e. ```python if part == 'pk' and not fld == _cls._meta.pk ``` because without this we will allow for e.g. `parent__pk__pk`.
It seems that we have two issues here, i.e. you can use fields from the same model multiple times, e.g. `parent__field1__field2__pk__field1`, and you cannot use `pk`. I think we should clean `_cls` if a field is not relation, e.g. ```python if part == 'pk': fld = _cls._meta.pk else: fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` I would split this into two fixes, first for using multiple times fields from the same model (with test): ``` fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` and second to handle `pk` (with test).
I don't think you need to guard against `_cls is None` here and you can skip the lookup in this case. ```python if part == 'pk': fld = _cls._meta.pk else: fld = _cls._meta.get_field(part) ``` Coincidentally this is another case where allowing `get_field('pk')` to work would have avoided this issue. Maybe it's time to revisit #8191.
I think we can simply reuse existing `TestCollectionDryRun` instead of creating a separate test, e.g.: ```python @override_settings(STATICFILES_STORAGE='django.contrib.staticfiles.storage.ManifestStaticFilesStorage') class TestCollectionDryRunManifestStaticFilesStorage(TestCollectionDryRun): pass ```
CurrentSiteMiddleware doesn't override `__init__()` whilst not calling `super()`, which is what gets you on this list.
We have a few different approaches for a stub `get_response()` method: - `lambda req: HttpResponse()`, - `get_response()` inside a test case, - `empty_response()` at the module level, etc. Can we unify them? I don't have a strong opinion, I think `empty_response()` is the most readable, but ... :thinking: ```python def empty_response(request): return HttpResponse() ```
These kind of changes are not related and should be reverted, IMO. They're also based on a `MiddlewareMixin` behavior that we can remove in the future, that's why I would prefer to keep `process_request()`/`process_response()` tests.
I think that you need to increase `stacklevel` to `3`.
Not sure I have the energy for this...
It looks that this method is unused since its introduction in 71a03e01aa19cbde08e915d156abf39b67d904ef. I moved this to the #12450.
On balance I will leave this one as it is.
I thought about this. It's a much bigger change, just for a deprecation. Inserting a deprecation is one thing. Adjusting method calls is something else: `MiddlewareMixin.__init__()` calls `super()` so there's a potential logic change. Don't know where exactly, but I didn't want to risk a regression just to save the extra lines here implementing this deprecation.
This is a nice clean-up 👍
Head is starting to explode. 🤯. `None` is allowed here because we overrode `__init__`, even though we're extending from `MiddlewareMixin`... which means the warning is kind of soft. I think this is OK, but it might be clearer to pass a view function.
I think this test, we need to call `process_response` explicitly. This from the middleware: https://github.com/django/django/blob/75daea2fc24da1c987d4fd979adb31a2c5a29d22/django/contrib/messages/middleware.py#L20-L25 By passing through `process_request` we set the `_messages` attribute... (Not sure what's going on here makes 100% sense. Middlewares don't return requests...)
This now raises a warning, so I adjusted to use a view.
I think keeping the explicit `process_response()` call here would make sense. By changing to `__call__()` we're running through `process_request()`, which is not a no-op, which is perhaps fine but it's subtly changing the intent/behaviour of the test. (I guess this is something we'd have to think about removing the `process_x()` hooks, but not in this PR) Same for line 677 below. **Update**: Tests in `csrf_tests` are more explicit about this... (So maybe the small change here is OK)
Wrap at 79 chars.
Multiple values should be allowed only for the `no-cache` directive, this change allows for multiple values for all keys what is not desirable.
`SetCookie` -> `Set-Cookie`
I don't think extending `Subquery.__init__` to allow any `QuerySet` some method (e.g. `filter`, `order_by`, ...) is desirable.
Could be a personal or project preference for all I know, but does this re-assignment need to occur, instead of just having `return _format_string(f'{number:f}', ...)`? Doubt it matters much, of course.
You're repeating `not grouping`, I am sure there is a way to rearrange the if statements a bit.
You can also use `f-strings` down below. We only support Python versions that implement `f-strings`.
I don't think you necessarily need this _here_ (if at all, but I get the historic reasoning) fwiw. In the original (if I'm reading the side-by-side correctly) it ends up marked as safe when `dec_pos` is _Falsy_. But in this changed version, it becomes a `SafeString` _before_ checking `if decimal_pos`. If there 's _truthy_ `decimal_pos` you end up doing `SafeString` + sep (presumably str, but could be another `SafeString`) + `str` so you ultimately get back a `str` type regardless, because `'0' * decimal_pos` is the final addition and `SafeString` only defines `__add__` for another of it's kind. If you were able to defer making it a `SafeString` until _after_ the `decimal_pos` check, you can avoid 1 or possibly 2, accounting for sep) in the _wants decimal_ case, because `str` + (potentially) `SafeString` yields `str`. NB: that's all off the top of my head from reading the diff, caveat emptor :)
IMHO I would simply use `_` not `,` and always replace. Reduces complexity and a replacement isn't too slow. In fact, it's probably faster than the if clause. If clauses can significantly slow down code execution, since your processor doesn't know which instructions to preload until you reached that particular instruction and decided where to go from there.
Besides, this change doesn't improve speed. From experience, any change will slow down reviews and hinder this from being merged ;)
IMHO I don't think you should use 0 values as boolean. If you want boolean, use boolean. Besides, `grouping` may have too many types now. I can be an integer, a tuple and boolean. I would stick with a separate variable called `use_grouping` here. It's more descriptive.
Or you can still use f-strings for this too: ```python number = f'{number:_.{decimal_pos}f}' ```
`as defined by the arguments` is not really telling me anything. I would either add a longer more descriptive doc string or none.
IMHO the size check adds more complexity. Let python's format handle this. I believe it will very efficient if the value has only 3 digits.
Why don't you do the decimal precision as part of the format expression? Something like: ```python number = ("{:_.%sf}" % decimal_pos).format(number) ```
You don't need to import `builtins`, because they are built in 😛 ```suggestion ``` If you worry about overloading, just change the name of the method and assign the name `format` at the end of the file, like so: ```python def _format(): pass # other code format = _format # EoF ```
I believe it still makes sense to make the return value as safe, to avoid escaping.
I would like to avoid using of regexp here, it is always clunky. We should take into account that only the `ArrayField` is affected but it's more complicated then it looks like, e.g. if we decrease a size and change a `base_field` in a single alteration then we still have a data loss: - `_field_data_type(ArrayField(IntegerField(), size=5))` returns `integer`, - `_field_data_type(ArrayField(CharField(max_length=16), size=4` returns `varchar`. So for `ArrayField` we should cast only when `base_field` is different and `size` (in any dimension) is not smaller than the previous one. It's complicated :disappointed: and would require a very special treatment of `ArrayField`'s. (\cc @charettes )
We shouldn't import `ArrayField` here, please use `get_internal_type()` instead, e.g. ```python new_internal_type = new_field.get_internal_type() if new_internal_type == 'ArrayField' and new_internal_type == old_field.get_internal_type(): ... ```
Both `current_year` and `assumed_year` contains `current_century`, hence I think we can simplify this implementation, e.g. (IMO it's also more readable) ```python current_year = datetime.datetime.utcnow().year current_century = current_year - (current_year % 100) if year - (current_year % 100) > 50: # year that appears to be more then 50 years in the future are # interpreted as representing the past. year += current_century - 100 else: year += current_century ```
I would move mocking `datetime` to a decorator, after that we will be able to test different dates, e.g. ```python @mock.patch('django.utils.http.datetime.datetime') def test_parsing_rfc850(self, mocked_datetime): mocked_datetime.side_effect = lambda *args, **kw: datetime(*args, **kw) utcnow_first_fifty = datetime(2019, 11, 6, 8, 49, 37) utcnow_second_fifty = datetime(2051, 11, 6, 8, 49, 37) date = ( ('Tuesday, 31-Dec-69 08:49:37 GMT', datetime(2069, 12, 31, 8, 49, 37), utcnow_first_fifty), ('Monday, 10-Nov-70 18:49:37 GMT', datetime(1970, 11, 10, 18, 49, 37), utcnow_first_fifty), ('Wednesday, 31-Dec-71 18:49:37 GMT', datetime(1971, 12, 31, 18, 49, 37), utcnow_first_fifty), ('Thursday, 31-Dec-99 08:49:37 GMT', datetime(2099, 12, 31, 8, 49, 37), utcnow_second_fifty), ('Thursday, 10-Nov-50 18:49:37 GMT', datetime(2050, 11, 10, 18, 49, 37), utcnow_second_fifty), ('Sunday, 31-Dec-00 18:49:37 GMT', datetime(2000, 12, 31, 18, 49, 37), utcnow_second_fifty), ) for rfc850str, expected_date, utcnow in date: mocked_datetime.utcnow = mock.Mock(return_value=utcnow) with self.subTest(string=rfc850str): parsed = parse_http_date(rfc850str) self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date) ```
`S_IROTH` is "other read", not "owner read".
``` """Return Monday=1 through Sunday=7, based on ISO-8601.""" ```
This is really hacky, moving to the previous day should work as expected ```python return "TO_CHAR(%s - 1, 'D')" % field_name ```
Fixed in 67e7dffe9543aff259f63c8f12d15642fe7be100.
Good catch, thanks. I will fix this
I'd move this test under the existing `test_contains` method and name it `test_nested_contains`.
This use case is already tested in `test_icontains()`.
I've checked and `icontains` is not affected, we can remove this test. Sorry I should checked this first.
Since we would be shipping the default `.txt` template, it would never be missing, even if the user had previously overridden the old `.html` template, so this exception would never be raised, so their override would never be picked up.
I don't think that we should pass `memo`.
Well that's unfortunate. I see a few options. - Make the `python-memcached` client call `_deletetouch(expected=[b'DELETED'], ...)` directly. - Report an issue upstream to change the behavior of `delete` - Report an issue upstream to allow `delete` to accept a kwarg to change what gets passed to `expected`.
`python-mecached` should return the right value as long as we don't pass `noreply=True` to `delete` which we don't. https://github.com/linsomniac/python-memcached/blob/bad41222379102e3f18f6f2f7be3ee608de6fbff/memcache.py#L548-L575 And `pylibmc` should work as well https://github.com/lericson/pylibmc/blob/d8bafe91f57ebdd73f76eb80bdb4d4a515c7fc48/src/_pylibmcmodule.c#L1445-L1451
```suggestion cursor.execute( ```
```suggestion return bool(cursor.rowcount) ```
We want to avoid a `GETS ` here. What's the rationale for not simply returning `self._cache.delete(key)`? This is prone to race conditions anyway.
I think `response.streaming` should be tested first which will avoid accessing content for such responses.
Also what's the reason for using `getvalue()` over `.content`? ```suggestion if not response.streaming and response.content: ```
`if not relations:` is a sufficient check here I think
`self.assertQuerysetEqual(self.a1.publications.all(), [self.p1])` is a way to remove these repetitive assertions in all the tests below
The parenthesis here are unneeded
Both `local_setter` and `remote_setter` could be defined outside the loop and `remote_setter` could be closed over `name` with a `partial` e.g. ```python def local_setter(obj, from_obj): ... def remote_setter(name, obj, from_obj): setattr(from_obj, name, obj) for name in list(requested): ``` ```suggestion 'remote_setter': partial(remote_setter, name=name) ```
Perhaps dropping this blank line.
This is already tested in `test_args_kwargs_request_on_self()`, I'm going to remove these assertions.
This test is not related with the patch, so I'll move it to a separate commit.
And all the blank lines in this test.
And this one.
This test passes even without the patch applied. Did you mean to use the id of the `Happening` created in `setUpTestData`? I guess you could assign the `cls.happening` there and use `self.happening.id` here.
It should at least be made in a different commit.
Ahh I see, the test is the other way around; if the filter wasn't applied all results would be returned 👍
Something similar should be done in `prefetch_one_level` before calling `_apply_rel_filters` when a `Prefetch(queryset)` is provided. Of maybe it should be done in `_apply_rel_filters` itself.
I think these tests could the rare cases where a docstring explaining what it tests could be valuable given the large amount of boilerplate required. What about ``` """Related filtering of prefetched querysets is deferred until necessary.""" ```
I wish `mock` has a less verbose interface to count the number of calls while keeping a function around.
```suggestion request.META["CSRF_COOKIE"] = _get_new_csrf_token() ```
This values needs to be invalidated on `settings_changed` for `MIDDLEWARE` for testing purposes.
This will perform a full scan over a list and doesn't handle `CsrfViewMiddleware` subclassing.
Leave this as it is, and make the changes inside `rotate_token()`. (There's no reason for `auth.login()` to know the details of the CSRF implementation.)
only super() should be OK
Please wrap at 79 chars.
Please revert this unrelated change.
Constraint definition is missing in `data_type_check_constraints`.
Please move this below `PositiveIntegerField`.
Please use single quotes.
Chop blank line.
Use single quote.
```suggestion positive_big_integer = models.PositiveBigIntegerField(null=True) ```
I'm afraid that's backward incompatible, this should be handled in #11900.
Yup. This is where we'd need to define `PositiveBigAutoField` which would have this set to `PositiveBigIntegerField`.
I stand corrected. Thanks. I didn't expect that ``` $ python -m timeit 'tuple(i for i in range(10000000))' 1 loop, best of 5: 620 msec per loop $ python -m timeit 'tuple([i for i in range(10000000)])' 1 loop, best of 5: 556 msec per loop ```
Thanks. Good point.
I think we can get rid of the list comprehension, can't we? ```suggestion self.wrapper_classes = tuple( wrapper_cls for wrapper_cls in self.wrapper_classes if wrapper_cls is not Collate ) ```
I think, making it clear that it's a database name would help. ```suggestion 'Database "%s" does not support indexes on expressions.' ```
Shouldn't this be named? ```suggestion collate_as_index_expression = False ```
I don't get yet in which cases this occurs / why we need this. Shouldn't `quote_name` only be called for columns and table names and such? Calling it with an expression seems wrong.
How about making these two flags `False` by default, thus making the feature not causing backwards incompatible changes.
I'd suggest defaulting to True so databases have to opt-out rather than opt-in. It would be good to mention this in "Database backend API" under "Backwards incompatible changes in 3.2" like other new features are.
Trailing commas :)
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
Ah yes. Sorry for missing this.
You have `quote_name` and `quote_value` so you don't need to write vendor specific quotes. Anyway, it was meant as a thought, because I think it looks a bit weird with those sequences of `x < y`.
It seems that the convention is to use a `msg`-variable and keeping `assertRaisesMessage` on one line.
Remember the trailing comma.
You aren't changing here, except for the style. Please revert.
Trailing commas are there to minimize future diffs.
Could `Columns` or some other DDL class be used? I think this was originally written before the DDL classes were introduced.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
I think it's fine.
That looks awesome @hannseman 💯 🏅 Regarding `django.contrib.postgres.indexes.OpClass` I guess we could add a `IndexedExpressionWrapper.register_wrapper` and have `django.contrib.postgres.apps.PostgresApp.ready` register `OpClass` to avoid coupling there.
```suggestion editor.remove_index(Scene, index) ```
This is not a PostgreSQL-specific test. I moved it to the `tests.model_indexes`.
Yes, much better, thanks.
Also, I think it would make sense to subclass `TableColumns` instead of `Reference`, e.g.: <details> ```diff diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py index e1e6deb4c8..2f9fbf64c8 100644 --- a/django/db/backends/ddl_references.py +++ b/django/db/backends/ddl_references.py @@ -203,7 +203,7 @@ class Statement(Reference): return self.template % self.parts -class Expressions(Reference): +class Expressions(TableColumns): def __init__(self, table, expressions, compiler, quote_value, opclasses): self.table = table self.compiler = compiler @@ -212,25 +212,17 @@ class Expressions(Reference): ] self.quote_value = quote_value self.opclasses = opclasses - - def references_table(self, table): - return self.table == table - - def references_column(self, table, column): - columns = (col.target.column for col in self.compiler.query._gen_cols(self.expressions)) - return self.table == table and column in columns - - def rename_table_references(self, old_table, new_table): - if self.table == old_table: - self.table = new_table + self.columns = (col.target.column for col in self.compiler.query._gen_cols(self.expressions)) def rename_column_references(self, table, old_column, new_column): if self.table != table: return expressions = [deepcopy(expression) for expression in self.expressions] + self.columns = [] for col in self.compiler.query._gen_cols(expressions): if col.target.column == old_column: col.target.column = new_column + self.columns.append(col.target.column) self.expressions = expressions def __str__(self): ``` </details>
We could always wrap collations in parentheses :thinking: ```diff diff --git a/django/db/models/functions/comparison.py b/django/db/models/functions/comparison.py index 8a1c34430b..8b4d499c89 100644 --- a/django/db/models/functions/comparison.py +++ b/django/db/models/functions/comparison.py @@ -79,7 +79,7 @@ class Coalesce(Func): class Collate(Func): function = 'COLLATE' - template = '%(expressions)s %(function)s %(collation)s' + template = '(%(expressions)s %(function)s %(collation)s)' # Inspired from https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-SYNTAX-IDENTIFIERS collation_re = _lazy_re_compile(r'^[\w\-]+$') ```
Unfortunately, we cannot remove `Collate` from `wrapper_classes` because it will break, e.g. ```python Collate(F('title').desc(), collation=collation) ```
In the current state, it's not reusable for other lists of expressions, so I would rename it to the `IndexExpressions`
Implemented in #13738.
OK I pushed fix.
We cannot pass `connection` in the `__init__()` because it breaks e.g. `deepcopy()`. I decided to add a separate hook `set_wrapper_classes()`, it is not the cleanest solution, but it's not the end of the world :globe_with_meridians: , and we don't have much time before the feature freeze :clock1: .
But we don't mutate `IndexExpression.wrapper_classes`.
The current form is consistent with messages in similar checks. Also, we use here `display_name`, e.g. `MySQL does not support indexes on expressions.` so I don't think that `Database` adds much value here.
I know that this may be surprising but it is better performance to provide a list up front. This is probably not a big deal in this particular case.
I think we should remove them.
IMO, this is not related with `index_xinfo` but with naive parsing in introspection on SQLite. I added `_get_index_columns_orders` to fix this issue.
This is not strictly related with functional indexes, I'm going to move it to a separate PR.
This seems out of place. Is this branch really specific to MySQL? Is there a way we could avoid the `Col` import in the first place.
As long as they both equals it shouldn't make a difference. By that I mean you should have a test asserts `Index('foo') == Index(F('foo'))` An alternative could be to defer that to `create_sql`.
I've pushed changing `fields` to an optional kwarg-only to a separate PR, #13802.
Indexes on `TextField`s are not supported on Oracle (see `supports_index_on_text_field` feature flag), that's why it fails. Including a `TextField` in this index is not crucial so I will remove it.
Ahh, sorry we cast it to the `NVARCHAR2(2000)` so that's not the issue. Nevertheless, it fails on my local instance with: ``` django.db.utils.DatabaseError: ORA-01450: maximum key length (6398) exceeded ``` because I have a 8K block size. I will remove `TextField` to avoid issues on such configurations.
Also this test is a bit redundant with `test_index_with_collate_f_expressions`. I think we can remove it.
Merged and rebased.
I think that most of the expression special casing and resolving should be done at the `Index.create_sql` level. The only purpose of `ddl_references` is to hold references to identifiers and allow renaming if necessary, it shouldn't have any knowledge about `django.db.models` abstractions.
That'll be an interesting one to address when we move the schema editor to use model states instead. A problem for later :)
Could we maybe use a name that doesn't conflict with `django.db.models.indexes.IndexExpression` since this one has about no knowledge about _indexes_ per-se.
Minor but pep8 suggested using double quotes instead of escaped single ones ```suggestion "Multiple references to %s can't be used in an indexed expression." % ( ```
You need to register it: ```python with register_lookup(CharField, Upper), register_lookup(CharField, Lower): Index(F('name__lower'), F('name__upper'), name='lower_upper_func_idx') ```
I wonder if we should pass already resolved expressions instead.
@hannseman I see what you mean! Going through the `set_source_expressions` route would be very hard as you'd have to set it for all the nested expression leading to the `Col`. I guess `copy()`'ing all expressions preemptively would be best way forward ```suggestion if self.table != table: return renamed_expressions = [] for expression in enumerate(self.expressions): renamed_expression = expression.copy() for col in self.compiler.query._gen_cols(renamed_expression): if col.target.column == old_column: col.target.column = new_column renamed_expressions.append(renamed_expression) self.expressions = renamed_expressions ```
Is there a reason this can't be implemented as `BaseExpression.ordered = False` with a `OrderBy.ordered = True` override like other properties are dealt with? (e.g. `filterable`, `window_compatible`). This seems like unnecessary bi-directional coupling.
I think we should move this and `_validate_supports_expression_indexes()` to a system check `_check_indexes()` with `hint` that _"An index won't be created. Silence this warning if you don't care about it."_ (like we do for constraints).
```suggestion if sql: ```
We need to add the same check to `remove_index()`.
I would add a flag to `Index`, e.g. `is_functional` that could be used here together with `supports_expression_indexes` to skip such indexes, e.g. ```python if not index.is_functional or self.connection.features.supports_expression_indexes: output.append(index.create_sql(model, self)) ``` Also we should return `None` in `_create_index_sql()` and `_delete_index_sql` if `index.is_functional` and `self.connection.features.supports_expression_indexes`
We could move this hook to a separate PR, and change current checks in few places e.g. `db/models/sql/compiler.py`.
Adding `is_value()` method can be misleading, maybe `_choices_is_value()`.
We'd only put the ticket number for a particularly tricky ticket. I don't think it's necessary here.
Note that this makes `restype` etc not kw-only anymore.
We can use `Path(f_name)` to check `storage.delete()` support for `pathlib.Path`.
I would use `os.path.splitext()`, e.g. ```python def get_available_name(self, name, max_length=None): """ Append numbers to duplicate files rather than underscores, like Trac. """ basename, *ext = os.path.splitext(name) number = 2 while self.exists(name): name = ''.join([basename, '.', str(number)] + ext) number += 1 return name ```
No need for formatting here. ```suggestion return str(self.value) ```
Maybe ```python @skipIf(sys.platform == 'win32' and PY38 and sys.version_info < (3, 8, 1), 'https://bugs.python.org/issue38563') ```
These assertions are not related with a bugfix, please move them to a separate commit.
Since `self._remove_trailing_nulls` is not meant to `raise ValidationError` I'd only call `to_python` in the `try` block ```suggestion try: data = self.to_python(data) except ValidationError: pass else: data = self._remove_trailing_nulls(data)[0] ```
I'd call this `remove_trailing_empty_values` to reflect the containment check on `self.base_field.empty_values` below.
I think `index` will be fine here instead of `null_index`. It would be good to avoid the association with `null` which feels like `None` translated to Python-speak. (Aside from that I could only come up with `first_trailing_empty_value_index` which, while clearly descriptive, is silly... 🙂)
I think we can add an internal hook `_remove_trailing_nulls()` to the `SplitArrayField` that can be used in `clean()` and `has_changed()`: ```python def _remove_trailing_nulls(self, values): errors = [] null_index = None if self.remove_trailing_nulls: for i, value in reversed(list(enumerate(values))): if value in self.base_field.empty_values: null_index = i else: break if null_index is not None: values = values[:null_index] return values, null_index def has_changed(self, initial, data): data, _ = self._remove_trailing_nulls(self.to_python(data)) return super().has_changed(initial, data) ``` Please add it in the 1st commit, the 2nd commit will contain a bugfix.
Sorry, I misinterpreted it as a new flag. I also see above that this was all copied so ignore this. While not the best naming, we're stuck with it.
That actually makes sense. I forgot `reversed()` is a bit special because you typically have to have consumed the whole iterator to know the last element.
Do we need all these tests? IMO these two should be enough: ```python obj = IntegerArrayModel(field=[]) form = Form({'field_0': '', 'field_1': ''}, instance=obj) self.assertFalse(form.has_changed()) obj = IntegerArrayModel(field=[1]) form = Form({'field_0': '1', 'field_1': ''}, instance=obj) self.assertFalse(form.has_changed()) ```
Yes, we should use the same approach as in `SimpleArrayField`, e.g. ```python def has_changed(self, initial, data): try: data, _ = self._remove_trailing_nulls(self.to_python(data)) except ValidationError: pass if initial in self.empty_values and data in self.empty_values: return False return super().has_changed(initial, data) ```
I'm not sure is this really helpful and needed :thinking: because it'll catch only checks with the same order of conditions, so only copy&paste issues. For example, it will not raise a warning for: ```python models.CheckConstraint(check=models.Q(models.Q(id__gt=0) | models.Q(id=0)) models.CheckConstraint(check=models.Q(models.Q(id=0) | models.Q(id__gt=0)) ``` (that's of course only a simple example). In the same time I would not like to add any complicated logic here.
> Is that something that might appear some time soon, or is it just a thought? 🙂 At the moment just a thought… 🙂
@codingjoe I'm not sure we're taking about the same thing. This is about avoiding duplicate check constraints being defined on a model.
Check constraints can add significant overhead to insert/update queries. Adding duplicates (whether identical or in a different form) compounds that and is probably worth highlighting. I wouldn't have thought that dealing with ordering and logical equivalence was a deal breaker. Yes, it requires some thought, but a well-defined `simplify_q()` function that can normalize a `Q()` object would make sense. I also don't see this being limited to check constraints - partial indexes can also make use of `Q()` objects for the `condition`. Duplicate indexes also have an impact on insert/update as well as wasting valuable disk space.
Honestly, I'm not in favor of another system check, but I'll try to confirm this with Carlton tomorrow (who accepted this ticket).
It is not only about ordering. Condition can be more complicated, e.g. ```python check=Q(Q(field_1='a') & Q(Q(field_2='b') | Q(field_3='c'))) check=Q(Q(Q(field_3='c') | Q(field_2='b')) & Q(field_1='a')) ``` Moreover they can be logically equivalent, e.g. ```python check=~Q(Q(field_1='a') | Q(field_2='b')) check=Q(~Q(field_1='a') & ~Q(field_2='b')) ``` etc. Users can assume that Django protects them against duplicate constraints. Furthermore I'm afraid that someone somewhere in the universe :alien: uses a subclass of `CheckConstraint` where the same conditions make sense (we had regressions in many checks).
This can use set comprehension ```suggestion reverse_fields = { ```
I removed these assertions.
I don't think testing against the invalid (missing quotes) introspection SQL is necessary given the assertions below already fail without the `get_filters` changes.
IMO this tests should be moved to the `tests.backends.tests.BackendTestCase`, also we don't need to mock a database, checking for a `connection.alias` in a logger should be enough, e.g. ```diff diff --git a/tests/backends/tests.py b/tests/backends/tests.py index da20d94442..5f6e02d91d 100644 --- a/tests/backends/tests.py +++ b/tests/backends/tests.py @@ -3,6 +3,7 @@ import datetime import threading import unittest import warnings +from unittest import mock from django.core.management.color import no_style from django.db import ( @@ -492,6 +493,23 @@ class BackendTestCase(TransactionTestCase): BaseDatabaseWrapper.queries_limit = old_queries_limit new_connection.close() + @mock.patch('django.db.backends.utils.logger') + @override_settings(DEBUG=True) + def test_queries_logger(self, mocked_logger): + sql = 'SELECT 1' + connection.features.bare_select_suffix + with connection.cursor() as cursor: + cursor.execute(sql) + params, kwargs = mocked_logger.debug.call_args + self.assertIn('; alias=%s', params[0]) + self.assertEqual(params[2], sql) + self.assertEqual(params[3], None) + self.assertEqual(params[4], connection.alias) + self.assertEqual( + list(kwargs['extra']), + ['duration', 'sql', 'params', 'alias'], + ) + self.assertEqual(tuple(kwargs['extra'].values()), params[1:]) + def test_timezone_none_use_tz_false(self): connection.ensure_connection() with self.settings(TIME_ZONE=None, USE_TZ=False): ```
How about putting alias in front of 'sql' and 'args', in a form like, ```"(duration) [alias]: ...sql...; args=(...)"```
Please use single quotes throughout.
```suggestion if sign and d: ```
Could this use the operator instead of the function? So `%(expression)s IS NULL`. It may need some parentheses round the expression, not sure.
That would also mean that this could be `%(expression)s IS NOT NULL`, getting rid of the `IF()` here too...
We should take into account the `PSYCOPG2_VERSION` version, e.g. ```python @unittest.skipIf(PSYCOPG2_VERSION < (2, 7, 5), 'https://github.com/psycopg/psycopg2/issues/325') ```
Running query is not necessary, I think we can check field value instead, e.g. ```python self.assertEqual(instance.field, [[None, None], [None, None]]) ```
I don't think that we need a separate model, I would add ``` field_nullable = ArrayField(ArrayField(models.IntegerField(null=True))) ``` to the `NestedIntegerArrayModel`.
All fields have default entries (2 bits) in columns, that creates a similar limitation for the list of fields, e.g. ```python django.contrib.postgres.indexes.BloomIndex(fields=[ 'field_int_1', 'field_int_2', 'field_int_3', 'field_int_4', 'field_int_5', 'field_int_6', 'field_int_7', 'field_int_8', 'field_int_9', 'field_int_10', 'field_int_11', 'field_int_12', 'field_int_13', 'field_int_14', 'field_int_15', 'field_int_16', 'field_int_17', 'field_int_18', 'field_int_19', 'field_int_20', 'field_int_21', 'field_int_22', 'field_int_23', 'field_int_24', 'field_int_25', 'field_int_26', 'field_int_27', 'field_int_28', 'field_int_29', 'field_int_30', 'field_int_31', 'field_int_32', 'field_int_33', ], name='test_bloom_index'), ``` will fail with ``` django.db.utils.OperationalError: cannot use more than 32 columns in an index ```
I think we can raise an error in this case.
I would chop `_support`.
I think I'm happy with it. It declares the intention.
I'm not sure it's really necessary to use `strict=True` after `tempfile.TemporaryDirectory()` as it should raise if the path cannot be created. Not that it really hurts.
I think we should wrap this in a `try... except...` in order to catch any final lingerers: ``` try: from django.utils.deprecation import RemovedInDjango40Warning except ImportError: raise Exception( 'django-admin.py was deprecated in Django 3.1 and removed in Django ' '4.0. Please manually remove this script from your venv and use ' 'django-admin instead.' ) ``` (Since a `pip install -U Django` isn't ever going to actually delete it.)
Meh... I think, if after 4.0, someone is still running this, we should fail hard. (Exception, rather than warning.) But open to arguments... — this is just the last safety net. I don't think we should spend too much time here.
Drop the ` (django-admin.exe on Windows)` (One would just type `django-admin ...` same as elsewhere.)
`# TODO: Remove when dropping support for PY37.`
I've changes to `django.utils.inspect.func_supports_parameter()`.
Grrr... I think I probably preferred the `if PY38` version then. (Let me confer with Mariusz.)
A small oversight I noticed in an old Python 3.7.0 virtualenv: https://github.com/django/django/pull/13393
```python cache_params['LOCATION'] = Path(self.dirname) ```
With this reinstated, it looks as though a test is needed as you didn't remove one...
These lookups should be available for all `RangeField`'s not only for `DateRangeField` and `DateTimeRangeField`.
TBH I'm not sure if we need to check message in this case. It's not our message, and this can cause other (OS/versions) adjustments in the future :thinking: .
```suggestion if sys.platform == 'win32': ```
This test works without a patch, please move it to a separate commit.
I think we can use `Article.headline`, chop blank lines, and simplify these tests, e.g. ```python def test_create_index_with_desc_suffix(self): index = Index( fields=['-headline'], name='whitespace_idx', opclasses=['text_pattern_ops'], ) with connection.schema_editor() as editor: self.assertIn( '(%s text_pattern_ops DESC)' % editor.quote_name('headline'), str(index.create_sql(Article, editor)), ) ```
One of the `self.GT` elements should be `self.GE`.
I still missed one!
Sure. A test to check for the issue above, for example!
Changing DB parameters in tests is not something that we should do, IMO. We can rather use `round()`, e.g. ```python # Round result of distance because PostgreSQL 12+ uses greater precision. ... transform=lambda instance: (instance.field, round(instance.distance, 6)), ```
Not related to these changes but this code is `O(2n)` by making a list and then performing a containment check on it. The following would be better IMO ```python columns = self.connection.introspection.get_table_description( self.connection.cursor(), table ) for column in columns: field_column = field.column if ignores_table_name_case: column = column.casefold() field_column = field_column.casefold() if column == field_column: found_add_field_migration = True break else: return False, project_state
Not related to these changes but we should probably turn the `existing_table_names` iterable to a `set` if it's only used for containment checks.
Could we maybe give these migrations a name that includes the fact they are related to case sensitivity issue? e.g. `migrations.test_fake_initial_case_insensitive` I'd also give a proper name to `1` and `2`.
Does the `if model._meta.db_table not in existing_table_names:` check at line 344/347 needs the same treatment? I'm surprised the tests pass without case folding there. Any idea why? Also this might be a more readable ```python through_db_table = field.remote_field.through._meta.db_table if ignores_table_name_case: through_db_table = through_db_table.casefold() ```
[I'd use `casefold()`](https://docs.python.org/3/library/stdtypes.html?highlight=casefold#str.casefold) and it looks we're not performing `lower()` in the `model._meta.db_table` and `field.remote_field.through._meta.db_table` containment checks below either. The `through` case is also untested.
Might be worth using a different name since it's also used for column detection. What about ```python fold_identifier_case = self.connection.features.ignores_table_name_case ```
You'll want to make this a set as well ```suggestion existing_table_names = {name.casefold() for name in existing_table_names} ```
Looks like we favor `type` in similar cases in the ORM ```suggestion return type(value)( ```
This docstring is the same as for `wait_page_loaded()`. Do we even need it in either case? Or perhaps the docstring should explain the difference between these two methods.
Add a trailing comma.
I removed the try...except... — Thanks both.
The changes here seem to break the assertion on this line. (Ref e00d77c4834b40f06f9bf271da5fdfb526ad8f56) ``` ... vvvv File "...tests/admin_widgets/tests.py", line 1119, in execute_basic_operations self.assertSelectedOptions(to_box, [str(self.jason.id), str(self.john.id)]) ... AssertionError: Lists differ: ['14', '10'] != [] ```
You missed a backtick at the end of the line.
I'm not sure if this is a good solution, because `p.mugshot.storage != loaded_mugshot.storage` and in the same time `loaded_p.mugshot.storage == p.mugshot.storage` :thinking:
I think it's fine to leave it inside a `try` block.
New tests are failing on Oracle. I think we should avoid creating a test database, maybe by mocking `_create_test_db()` :thinking:
Please add trailing comma.
We already have a `reverse_ordering()`. Moreover this solution mutates `OrderBy` expression, so maybe: ```python if isinstance(order_field, OrderBy): if pfx == '-': order_field = order_field.copy() order_field.reverse_ordering() ordering.append(order_field) ```
I think that property name i.e. `order_by_expression`, `order_by_f_expression`, or `order_by_orderby_expression` is a sufficient description.
`OrderBy` should also support reverse ordering.
Why? IMO using regexp is less readable. This is not a really complicated comparison, I can imagine only one case when this can be broken in the future i.e. when Oracle unify their implementation with other dbs. Honestly I would like to catch this.
I was close to restore a regexp :wink:, but let's leave it as it is. Thanks :+1:
Only `OneToOneField` can be `parent_link` so this can be reduced to the following at least. ```python parents = set(self.query.get_meta().get_parent_list()) return [ c[0] for c in self.select if c[0].target.related_model in parents and c[0].target.remote_field.parent_link ] ```
Jinja raises `jinja2.TemplateSyntaxError` in `render()` not in `get_template()` when an error is in the included template, so that's the real usage. We don't need to mock anything here.
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
Maybe `**kwargs` instead of `subindex=None, attrs=None`.
Some tests are really old and it's not always the best to follow their style. > Why? To avoid mistakes, e.g. in the most recent push you fixed the next line: ```python option = super().create_option(name, value, label, selected, index, subindex, attrs) ``` that wouldn't be necessary if we used `kwargs`. But OK, it's fine.
Ah, fine. I'm happy with that. :+1:
Is this tested? It wasn't apparent to me from the changes in the tests.
Using elif is slightly clearer
This test is also already in the `backends.base.test_creation` and it's unrelated with this fix. Please remove it.
These tests are specific for the SQLite back-end. We don't need this hook.
We should run these tests only on SQLite: ```python @unittest.skipUnless(connection.vendor == 'sqlite', 'SQLite tests') ```
This test is already in the `backends.base.test_creation` and it's unrelated with this fix. Please remove it.
This line looks backwards... (If I add a `required` to the select, the HTML validator will trigger on the lack of the empty value.)
Wrap docstrings at 79 chars.
Yes, thanks. I missed that :+1:
Do we need this? I don't see any failures without it, I think we can simplify this method, e.g. ```python def r(self): if self.timezone and is_naive(self.data): self.data = make_aware(self.data, timezone=self.timezone) return format_datetime_rfc5322(self.data) ```
This is not strictly related with a bugfix. Can we move this to a separate commit? also test is necessary.
TBH even now it's confusing :thinking: _"explicit is better than implicit"_ 🧘‍♂️ so I decided to move it to the `DateFormat.r()`.
We don't refer tickets in tests anymore, please chop `#9762`, also maybe: ``` # Changing the locale doesn't change the "r" format. ```
I think we should skip this test on other backends, because only on Oracle we execute a SELECT query.
Fine, you persuaded me :smile: :speaker:
It'd be great if this was implemented as an `Operation` method that defaults to returning `None` and overridden when available. It would make testing easier and remove this chain of instance checks.
`AddConstraint()`/`RemoveConstraint()` patterns should be consistent with `AddIndex()/RemoveIndex()`. We can mention a model name in both cases.
I think it makes sense to use the same order like in `describe()`.
These entries are redundant; they cover the same line of code. A single one should suffice ```suggestion valid_hosts = ['localhost', 'subdomain.localhost', '127.0.0.1', '[::1]'] ```
You can use the new `self._bound_items()` here, which is now in `main`.
```suggestion Return context for form rendering. ```
This should be `RemovedInDjango50Warning` I think.
I don't think we need the blank line.
I think you meant to use `self.get_context()`.
We'd likely want to accept `renderer=None` here and default to `get_default_renderer()`.
I believe there is a typo here. ```suggestion '`django.forms.BaseForm._html_output` is deprecated.' ```
```suggestion functions.FromWKT(Value(g.wkt)), ```
As of 1e38f1191de21b6e96736f58df57dfb851a28c1f, `output_field` doesn't need to be defined here. ```suggestion functions.FromWKB(Value(g.wkb.tobytes())), ```
```suggestion from django.db import NotSupportedError, connection from django.db.models import Sum, Value ```
I don't think that we need to call `django.setup()`. I would prefer to load only necessary apps, i.e. ```python try: import asgiref from django.conf import settings from django.apps import apps except ImportError: pass else: settings.configure() apps.populate(['django.contrib.contenttypes', 'django.contrib.auth']) ```
```suggestion sql_params = (*lhs_params, *rhs_params) ```
They aren't misleading IMO and we try to avoid trivial changes.
After a quick look I _think_ these can be considered deterministic as well because they don't rely on a connection state directly; they expect `conn_tzname` to be passed as argument.
In theory a locale dependant pattern could be provided and `locale.setlocale` be called but this is really unlikely.
Grrr... I'd much prefer an explicit wait (for a known condition) then keeping the straight asserts...
No, really no. The assertions in the bottom should be replaced by waits until the result have the right length. Sleeping will just slow down the test suite artificially and could still fail on some systems. This is also part of my pull-request. I am not so sure about this ticket. A lot more tests fail for me locally when I run against FireFox. I believe we should consider running selenium tests all the time, as suggested in my GitHub actions patch, to make sure we a stable reference.
Is this the best way to handle this? (cc @codingjoe)
We likely want to be forcing the usage of `schema_editor.connection.alias` in the `ContentType` query above and the `Permission` one below as well else they could be against different database. Given you run `migrate --database=other` with the current code a transaction/savepoint will be created against `other` but these queries will be run against either `default` of whatever `db_for_write` routes to.
We can use `cast_db_type()` instead of `db_type()` and remove `serial` data types from mapping.
Are you sure these are necessary? I think they can be removed because `Field.get_lookup` respects MRO and these fields extend the appropriate `IntegerField` since 21e559495b8255bba1e8a4429cd083246ab90457.
Since `SmallAutoField` extends `SmallIntegerField` this can be reduced to ```suggestion elif isinstance(self.lhs.output_field, models.SmallIntegerField): ```
Chop blank line.
Since everything inherits from `IntegerField` it should be enough to only register lookup for it. In short `models.BigIntegerField.register_lookup(RangeContainedBy)` is redundant.
Chop blank line.
Ahh just realized that `AutoFieldMixin.output_field` doesn't return it's implementing `IntegerField` subclasses so it's likely not fixed in 3.0 without these lines like I wrongly assumed.
We don't need a new model here, please move these fields to the `RangeLookupsModel`.
These test should be moved to the `TestQueryingWithRanges`.
`CharFieldModel` -> `RangeLookupsModel`. You don't need to create new objects.
I was about to suggest to move this line within the `if objs` branch but doing an early return on `if not objs` like we do in `_remove_items` is likely even better for readability. That should likely be done in another commit.
Why do you accept argument here, if you don't pass them to super. Maybe you can just the the correct default for `local_hostname` here and pass the variable. ```suggestion def __init__(self, host='', port=0, local_hostname='[127.0.0.1], **kwargs): super()__init__(host=host, port=port, local_hostname=local_hostname, **kwargs) ```
Please wrap at 79 chars: ```python raise ValueError( 'You cannot use -b/--buffer with parallel tests; pass ' '--parallel=1 to use it.' ) ```
Moving this line is not related with a bugfix. Please revert it and add ```python if check_filterable: ... ``` in both places.
Good catch, this cleanup should be moved to a separate commit.
IMO it's more an internal method but I don't see much harm in keeping it _public_.
Please use hanging indentation per our [coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). Maybe small rewording: ```python raise TypeError( 'sensitive_variables() must be called to be used as a decorator, ' ' e.g., use @sensitive_variables(), not @sensitive_variables.' ) ```
I think it's better to test a "normal" function instead of `lambda`, e.g. ```python with self.assertRaisesMessage(TypeError, msg). @sensitive_variables def test_func(self, password): pass ```
Maybe: ```python raise TypeError( 'sensitive_post_parameters() must be called to use it as a ' 'decorator, e.g., use @sensitive_post_parameters(), not ' '@sensitive_post_parameters.' ) ```
We shouldn't raise errors about private APIs, we can error nicely when using `Prefetch` with `raw()`, e.g. ```python if queryset is not None: if isinstance(queryset, RawQuerySet) or ( hasattr(queryset, '_iterable_class') and not issubclass(queryset._iterable_class, ModelIterable) ): raise AttributeError('Prefetch querysets cannot use raw() and values().') ```
Yes, `ValueError` sorry.
`related_name` is not related with this issue, so I think we can drop it and use a generic name.
We can chop `FK`.
Chop blank line.
We can drop meta ordering and add it to the queryset: ``` self.assert_pickles(c.concrete_events.order_by('event)) ```
`~` is not a supported operator, this should be `-`.
This should be moved to the `CursorDebugWrapper`, e.g. ```python def commit(self): with self.debug_sql(sql='COMMIT'): return super().commit() ```
This should be moved to the `CursorDebugWrapper`.
You don't need to wrap a connection, you should be able to use `CaptureQueriesContext()` with `commit()` and `rollback()` and test captured queries.
This should be logged also in `self.queries_log` with the time taken to execute. I think we can add a context manager similar to the `debug_sql` but to the `BaseDatabaseWrapper`.
This ticket is about recommending a `fk_name`, so we should rewrite this message, e.g. ```python raise ValueError( "'%s' has more than one ForeignKey to '%s'. You must specify " "a 'fk_name'." % ( model._meta.label, parent_model._meta.label, ) ) ```
I had to read it 3 times to understand it, maybe the wording could be improved here. Alias and aliased is just very similar.
TBH, I couldn't find a better wording.
I guess it would be easier to understand, if you'd name the separate boolean expression first before combining them, eg: ```python is_join = isinstance(table, Join) is_base_table = isinstance(table, BaseTable) clone.external_aliases[alias] = is_join and not is_base_table ``` Something along those lines.
The current form is fine, IMO. I don't think that ```python is_join = isinstance(table, Join) is_base_table = isinstance(table, BaseTable) clone.external_aliases[alias] = ( (is_join and table.join_field.related_model._meta.db_table != alias) or (is_base_table and table.table_name != table.table_alias) ) ``` is more readable.
I haven't checked out the code but I don't think this test is appropriate; [`deferred_sql` is only executed at `editor.__exit__`](https://github.com/django/django/blob/57a3d96ff57abffa8e7fbe3fd972a5ee39bd0fec/django/db/backends/base/schema.py#L112-L117) which means `SET CONSTRAINTS` will not be executed before the `UPDATE schema_node`.
It has to be switched back to `DEFERRED` afterwards ```suggestion sql_column_inline_fk_immediate = 'SET CONSTRAINTS %(name)s IMMEDIATE;SET CONSTRAINTS %(name)s DEFERRED' ```
`next_` -> `next_url`
This change is unrelated so we can revert it.
I know but we shouldn't mix unrelated cleanups with bugfixes.
`get_for_update_part()` -> `get_for_update_sql()`. We could move this hook in to a separate commit/PR.
It's not used only for combined queries so we should call it only in `not combinator` branch.
We should leave here `for_update_part = None` (in the same line as it was previously) and calculate it only in `not combinator` branch, because it's not used for combined queries.
There's likely a way write a test for this without involving a many-to-many relationship which just makes it harder to reason about. From my understanding the issue happens when `Subquery` is involved.
This test doesn't fail with or without the patch applied so it's likely unnecessary.
I think we should keep the previous behavior. An original exception was always in a traceback. It's easier for users to have it in the most recent message and don't force them to search for a real cause in the traceback.
And basically that's how it works even now, because `msg` for `KeyError` contains a nonexistent key. We can use `raw_converter`.
Here too -- I'd prefer to see `raw_converter` replace `e` in the exception message
And this one.
I think we can drop the empty line here.
Per new code guidelines, can we use `assertIs`? :)
IMO this check is unnecessary.
To sum up, the following code should work, IMO: ```python def _set_pk_val(self, value): for parent_link in self._meta.parents.values(): setattr(self, parent_link.attname, value) setattr(self, parent_link.target_field.attname, value) return setattr(self, self._meta.pk.attname, value) ```
Wrap imports at 79 chars.
Can we test both `Person` and `Political`?, e.g. ```python def test_create_new_instance_with_pk_equals_none(self): c1 = Congressman.objects.create(state='PA', name='John', title='senator 1') c2 = Person.objects.get(pk=c1.pk).congressman # Create a new congressman by setting pk = None. c2.pk = None c2.name = 'Bill' c2.title = 'senator 2' c2.save() self.assertEqual(Congressman.objects.count(), 2) self.assertEqual(Person.objects.get(pk=c1.pk).name, 'John') self.assertEqual(Politician.objects.get(pk=c1.politician_ptr_id).title, 'senator 1') ```
> I was under the impression that only `AutoField`'s were to be made `None`. You can also set `pk` that is an `AutoField` to a string value, in all such cases Django raises `ValueError`, so I don't see any issue in it. Moreover we can have a primary key that is not an `AutoField` but has a default value, e.g. `UUIDField(default=uuid.uuid4)` and this should also work.
`parent_link` and `field` is the same field, you can use `self._meta.parents.values()` without `zip` and `.items()`, e.g. ```python for parent_link in self._meta.parents.values(): ... ```
I don't think that we need this check. I would rather remove from docs [note](https://github.com/django/django/blob/77d335e5abec889b15323975187a8d5b10bfcb0f/docs/topics/db/queries.txt#L965-L979) about setting `id` to `None`. That is outdated after this patch. \cc @spookylukey
yeah we should stick to setting `pk`s.
I think we should add `'%Y/%m/%d'` format to the `DATE_INPUT_FORMATS` for backward compatibility.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
But `formats.get_format()` is not lazy, am I right? :thinking:. We can also use `yield from ... ` without `chain()`, e.g. ```python def __iter__(self): yield from formats.get_format('DATETIME_INPUT_FORMATS') yield from formats.get_format('DATE_INPUT_FORMATS') ```
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
I think we should update [DATETIME_INPUT_FORMATS docs](https://docs.djangoproject.com/en/dev/ref/settings/#std:setting-DATETIME_INPUT_FORMATS) and probably add a note to the `forms.DateTimeField.input_formats` docs.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
`DatetimeFormatsIterator` -> `DateTimeFormatIterator`.
``` self.assertHTMLEqual( f.as_table(), .... ) ```
We can remove `ClearableFileInput.use_required_attribute()` after this change.
I don't see much value in this docstring, please remove it.
> I'd prefer to return a list of errors rather than a single concatenated error. Is that the method I should change it to? Sorry - I didn't get around to replying, but yes, multiple works better.
This is a classic case where you may have duplicates of multiple action names but are only warned about the first one. You resolve that and then get nagged again about the next one. It would be better to list all of the duplicated names. It also probably makes sense to just count all of the names using `collections.Counter` and look directly for duplicates; to wit: ```python counts = collections.Counter(names) duplicates = [name for name, count in counts.items() if count > 1] if duplicates: return [checks.Error( ￼ '__name__ attributes of actions defined in %s must be ' ￼ 'unique. Duplicated names: %s' % (obj.__class__, ', '.join(duplicates)), ￼ obj=obj.__class__, ￼ id='admin.E130', ￼ )] ```
I don't think putting the name after "action" here makes sense. The issue is that there are _two_ actions with the same name.
Please move this to the top of the list of imports to fix the error from `isort`.
IMO using `subTest()` is not necessary here, e.g. ```python self.assertEqual(Child(foo='A').get_foo_display(), 'Child A') self.assertEqual(Child(foo='B').get_foo_display(), 'Child B') ``` is more readable.
I think we can remove `('B', 'Base B')` and `('B', 'Child B')` because it tests the same case as `A`.
Maybe: ``` # Don't override a get_FOO_display() method defined explicitly on # this class, but don't check methods derived from inheritance, to # allow overriding inherited choices. For more complex inheritance # structures users should override contribute_to_class(). ```
```suggestion with with self.subTest(tag), self.settings(LANGUAGE_CODE=tag): ```
append instead of creating a new list ```suggestion options_params.append(', '.join(options)) ``` All off the above could also be reduced to ```python options_params.append(', '.join( '%s=%s' % (option, psycopg2.extensions.adapt(value).getquoted().decode()) for option, value in options.items() ))
This test is really critical because without the whitelisting injection could take via malformed keys.
Should be a `frozenset` since it's only used for containment. From that point you use `set(options).difference(self.VALID_OPTIONS)` to determine `invalid_options`.
I wonder if we could add a `SearchConfig` expression :thinking: (maybe a subclass of `Value`): ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) ... def as_sql(self, compiler, connection): ... return '%::regconfig', params ``` This should simplify everything.
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
You don't need to declare `options` here.
`extra.get()` returns `None` by default, so we can simplify this: ```python self.options = extra.get('options') ```
Is there any reason to take `config` from a `query`? This should be rather a separate `config` as far as I'm concerned :thinking:
`resolve_expression()` implementation is the same as in `SearchQuery` and `SearchVector` so maybe we can add (in a separate commit) some mixin for this.
I would prefer to wrap value with `Value()` and compile `options` separately.
IMO we should check options against PostreSQL names.
So do we need to generate SQL with the same config in the `ts_headline` and an inline `tsquery`? (that's my main question) ```sql ts_headline('french'::regconfig, ..., tsquery(..., 'french'::regconfig), ...) ``` If not then I would prefer to leave config only in `tsquery` and don't duplicate its logic in `SearchHeadline`.
Well `self.field_name not in instance.__dict__` is not Python 2.3 compatible so I assume it was the reason 🤷‍♂ As of things are right now it's not possible for `DeferredAttribute` to end up in `instance.__dict__`.
In [the original patch](https://code.djangoproject.com/attachment/ticket/10695/defer.6.diff) provided by Alex Gaynor we have: ```python if self.field_name not in instance.__dict__: ``` but Malcolm changed this line to the ```python if data.get(self.field_name, self) is self: ``` That's why I assumed that it was possible that `instance.__dict__` contained a `DeferredAttribute` instance. :thinking:
@charettes Thanks :+1:
Fields can use custom encoders so it's better to use `get_prep_value()`.
This is here for appending to the follow-ups later. One or other is always appended so...
Good. Eagle eye. 😀
I like that it's a highly improbable edge case but you've handled it anyway :) Yep that text (or something like it) seems clearer to me, as it's giving instruction for resolution, should it ever happen to anyone.
Silencing far more exceptions than previously (where it was `ImportError`) ... is this intentional, and will it lead to people having a harder time debugging when their app config goes wrong? I guess it'd be somewhere higher up the chained stack traces, maybe? Same expansion of caught exceptions (`ImportError` -> `Exception`) happens at the `import_string` so I assume the answer to this also answers that.
`Django detects another configuration automatically` reads awkwardly to me. I assume it should be taken to mean Django detected another candidate to use as the default? Or put another way - the test case (elsewhere in the PR) which shows the full output of this warning being raised doesn't tell me (as someone seeing it for the first time) what the _actual_ problem is, nor what I should to do to fix it (beyond review my configuration)
`RemovedInDjango40Warning` -> `RemovedInDjango41Warning`
`app_config_class.__name__` -> `app_config_class.__qualname__`
Chop trailing space.
```suggestion 'Django now detects this configuration automatically. ' 'You can simply remove default_app_config.' ```
Wrap at 79 chars.
I would chop `simply`.
True, I missed this.
Merged in 1e0dcd6c8bfa4519c21014c73eb510620dd1a000.
This change is unrelated, I moved it to the #12328 and changed all hard-coded values to the constant.
We can reuse existing states.
This could be replaced by `self.remote_field.model._meta.label_lower` https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/options.py#L136-L138
Shouldn't we replace `and` with `or`? what about a file with a path like `'/vsimem/nonexistent.tif'`
What would you say for: ```suggestion raise KeyError(key) ``` ? That would make the error a bit more descriptive.
Do we need a custom exception class? Maybe `ValueError` would be enough, e.g. ```python ValueError('Unsupported algorithm %s' % algorithm) from e ```
This should be a subclass of `ValueError`, IMO.
I would add a docstring, e.g. ``` """Algorithm is not supported by hashlib.""" ```
```suggestion elif ( isinstance(f.remote_field, (ForeignObjectRel, OneToOneField)) and value is not None ): ```
```suggestion remote_field.model._meta.model_name, ```
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
I think this should take into account the `parent_link` attribute for `OneToOneField`s :thinking:
```suggestion readonly_fields = ('model_with_admin', 'model_without_admin') ```
True, I was thinking that maybe it's worth to cover them in tests, but you're right be don't need to test them separately.
We cannot use `id` because a model can have a custom primary key. I've changed to `pk`.
We should also use `quote()` because non-integer primary keys may not work properly, e.g. `_40`. Fixed.
This change is unrelated. Reverted.
You can reuse existing models, e.g. `ChapterXtra1` and `Vodcast`.
```suggestion chapter = Chapter.objects.create(title='testchapter', book=book) ```
```suggestion 'admin:%s_%s_change' % ( remote_field.model._meta.app_label, remote_field.model._meta.model_name, ), args=[remote_obj.pk], ```
We can move this check to the `BaseDatabaseOperations.window_frame_range_start_end()` and use a new feature flag in it.
@sir-sigurd I've already merged this patch, but we can relax this in future optimizations.
Ahh, yes thanks :+1: Now it crashes in both cases.
This is supposed to be the most used Accept content, however I don't think it contains those added spaces.
You don't like f-strings at all, do you? :-)
Sure, not this issue, however I don't think we interpreted the discussion the same. f-strings should be excluded in translatable strings, but I don't see what's preventing us to use them at other places.
We're touching this line. I'd be inclined to fix it...
Per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/ these could use `assertIs(..., True)`. I've done this for existing `.check_token()` tests in #12380.
I don't think that we would like to keep handling of `legacy_algorithm` when deprecation ends, that's why I'm going to simplify this. I hope you don't mind.
I have been thinking about this too, what happens if we were to deprecate sha256 at some point again? Do we want to leave legacy_algorithm around for that? (Porbably no)
> Do we want to leave legacy_algorithm around for that? (Porbably no) I don't think so.
Previous message was incorrect, IMO. We tried to delete a `P` instance so we should get a message about `P` even if restricted foreign keys are from other models (`R` in this case). Restricted foreign keys can be reached from a long and complicated paths so I don't think we can do much to improve this message.
The usual pattern is to implement `get_source_expressions` and `set_source_expressions`. ```python def get_source_expressions(self): return [self.config] def set_source_expressions(self, expressions): self.config, = expressions
The following is likely more readable given `config` works on `None` as well. ```suggestion if not hasattr(config, 'resolve_expression'): ```
```suggestion super().__init__() ```
```suggestion to_field.model != self.remote_field.model._meta.concrete_model ```
This can happen also for `OneToOneField` so we shouldn't put `ForeignKey` in a message, maybe: ```python exceptions.FieldError( "'%s.%s' refers to field '%s' which is not local to model " "'%s'." % ( self.model._meta.label, self.name, to_field.name, self.remote_field.model._meta.concrete_model._meta.label, ) ) ```
This also stands for non-`ForeignKey` such as `ForeignObject` the way it is defined right now. So I'd perform this check in `ForeignKey.resolve_related_fields` since it's the only one that has this restriction. That will allow `ForeignObject` to keep relying on this pattern and makes this patch slightly less backward incompatible. That means that `ForeignObject(ChildModel, from_fields=('ref_id',), to_fields=('key',))` would still be allowed since `ForeignObject` doesn't require the enforcement of a database level foreign key and can span multiple tables.
This should be `self.remote_field.model._meta.concrete_model._meta.label` as [pointed by Simon](https://github.com/django/django/pull/12383#discussion_r372421836).
Likely want to raise `FieldDoesNotExist` or `FieldError` here instead.
Use `self.remoted_field.model._meta.concrete_model` below instead
Are these two conditions really necessary? It feels like they could be removed.
I think we should revert this change (we reverted similar change in `django.core.cache.backends.basedefault_key_func()` in the past) because it will create a regression for non string values. The following example works in the current master: ``` >>> Signer('some_key').sign(1) '1:gJ9gvYHWvcR2rrXTSANB5b-IhU8' ``` but with this change it raises `TypeError`: ``` File "django/django/core/signing.py", line 162, in sign return self.sep.join([value, 'sha1', self.signature(value)]) TypeError: sequence item 0: expected str instance, int found ```
Any thoughts about joining by `self.sep` instead? I find it more readable ```suggestion return self.sep.join([value, 'sha1', self.signature(value)]) ```
I think I'd have this as: ```python try: import colorama colorama.init() except ImportError: colorama = None ``` Then below check `colorama is not None`.
That's my fault: in an earlier version, the `colorama.init()` was at the module level, but I didn't think having that there for everyone was a good placing. > ...use it here and in `color_style()` Makes sense.
I was quite surprise that `supports_color()` initialize anything. I would add `HAS_COLORAMA` on the module-level and use it here and in `color_style()` to initialize `colorama`.
```suggestion # winreg is available only on Windows. ```
`Determines` -> `Determine` `will support` -> `supports` This docstring can be single-lined.
Chop blank line, and also all blank lines in the `supported_platform()` hook.
I'm not sure that it makes any sense checking the registry. There is no guarantee that you are using a terminal that uses this. So it could just result in a blanket "on" if this is set. It would be better to take the `ctypes` approach mentioned to check whether currently enabled for the actual terminal in use.
```suggestion if os.environ.get('TERM_PROGRAM') == 'vscode': ```
It is also "Windows Terminal", not "Microsoft Terminal".
Do we really need this inner function? We could just shortcut out early if not a TTY.
```suggestion reg_key_value, _ = winreg.QueryValueEx(reg_key, 'VirtualTerminalLevel') ```
That makes sense, using `get_source_expressions` here was only performing a `contains_aggregate` check for the outer level expression while `get_group_by_cols` does it recursively as the expression tree is walked. https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/expressions.py#L346-L352
True, I mixed up sth when switching branches. Nevertheless they work on all databases except PostgreSQL, so we need to fix this.
This is covered by `test_lookups_with_key_transform()`.
`FIELD_TYPE.JSON` was added in `mysqlclient` 1.4.0rc2. I bumped `mysqlclient` requirement in a separate commit (see 9b938c20397d0ce0549f4796927ccaa2162d1360).
This is covered by `test_lookups_with_key_transform()`.
@laymonage No, it's a key value.
Cases from lines 361 and 363 work with the previous implementation.
Nitpick : can we remove the parallel assignment here? I have a draft blog post on why it's slower (tuple construction just to immediately deconstruct), and less clear (if an exception is raised, unknown which variable caused it)
`support` → `supports`
`CURRENT_DIR` is already a `Path` object, so we could join this with the `/` operator. ```suggestion html_template_path = CURRENT_DIR / 'templates' / 'technical_500.html' ```
We can use `create_a()` hook, e.g. ```python def test_protect_path(self): a = create_a('protect') a.protect.p = P.objects.create() a.protect.save() msg = ( "Cannot delete some instances of model 'P' because they are " "referenced through protected foreign keys: 'R.p'.", ) with self.assertRaisesMessage(ProtectedError, msg): a.protect.p.delete() ```
I think we don't need this test
Yes we can remove it, it's redundant with `test_restrict_path_cascade_indirect()` and `test_restrict_path_cascade_direct()`, i.e. we have tests for a path "restricted" deletion.
Yes it should be `R.p`, we didn't take into account nested protected relations in the ab3cbd8b9a315911248227208630a020cedca08f (probably my fault). Also casting to list is not necessary anymore after this change.
I think we should catch here only `core.signing.BadSignature`.
If you move this into the class scope it will not be duplicated below and might allow for easier customization
@felixxm Uf, now that we changed it I noticed that we might have a problem here. Shouldn't the `_legacy_hash` keep a hardcoded `key_salt = 'django.contrib.messages'` -- it never had a different salt…
You can just add `'blank': self.blank,` underneath `**kwargs,` below.
I will move this test to the `model_forms/tests.py`.
This behavior for `Select()` is already tested in multiple places e.g. `test_basics()` or `test_choices_freshness()`. IMO we don't need a direct test.
IMO this doesn't work properly, because it removes an empty option from `RadioSelect()` if `blank` **is allowed** which is incorrect. I also don't understand why we're checking `empty_label` :thinking:. I would expect sth similar to: ```python (required and (initial is not None)) or (isinstance(widget, RadioSelect) and not blank) ```
I don't think `except Exception` is appropriate here - it's too broad. This should probably be under a type check
Casting the list to a tuple, as my code example does, allows it to be a key in the cache. Tuples containing immutable objects are immutable, and therefore hashable: https://docs.python.org/3/glossary.html#term-hashable
I think we can simplify this: ```python with query.get_compiler(using).execute_sql(CURSOR) as cursor: return cursor.rowcount if cursor else 0 ```
I think we can simplify this: ```python with self.get_compiler(using).execute_sql(CURSOR) as cursor: return cursor.rowcount if cursor else 0 ```
This can be removed now that `values = list(values)` is done above.
Unnecessary whitespace change.
I think we should `warnings.warn('...', category=RemovedInDjango40Warning)` here.
If we do it the other way around by using an identity transformer `if isinstance(values[0], qs.model)` we would work around the `QuerySet.values_list('charfield', flat=True)` use case.
These two could be `and`ed.
@infosrabah PR is not the best place to ask support question. Please use one of [ support channels](https://code.djangoproject.com/wiki/TicketClosingReasons/UseSupportChannels).
Are you sure? Should this not be consistent with `SHORT_DATETIME_FORMAT`, i.e. `SHORT_DATE_FORMAT = 'j N Y'`.
Please chop trailing whitespaces.
This would no longer raise `ValueError` but `PageNotAnInteger` or `EmptyPage`. I think this PR needs some more consideration and tests.
Wrap at 79 chars.
I would chop `instead`.
Maybe: ``` View returning a FileResponse properly closes the file and http response when file_wrapper is used. ```
Trailing dot is missing.
``# The response and file buffers are closed.``
`# Sendfile is used only when file_wrapper has been used.`
We should clean `FILE_RESPONSE_HOLDER` in `finally` to ensure tests isolation, e.g.: ```python try: # Verify that sendfile was used which only happens if file_wrapper got # used. self.assertTrue(handler._used_sendfile) # Fetch the original response object self.assertIn('response', FILE_RESPONSE_HOLDER) response = FILE_RESPONSE_HOLDER['response'] # The response should have been closed ... self.assertIs(response.closed, True) # ... as well as all individual file buffers buf1, buf2 = FILE_RESPONSE_HOLDER['buffers'] self.assertIs(buf1.closed, True) self.assertIs(buf2.closed, True) finally: FILE_RESPONSE_HOLDER.pop('response', None) FILE_RESPONSE_HOLDER.pop('buffers', None) ```
You can reuse existing models, by adding e.g. `Entity`: ```python class Entity(models.Model): pass class Country(Entity): ... ```
You can remove the whole `else:` branch as `None` will be returned by the function implicitly.
Shallow copy i.e. `self.non_field_errors().copy()` should be enough. IMO. It doesn't work properly because `ErrorList` is a subclass of `UserList` but we can fix this easily with ```python def copy(self): copy = super().copy() copy.error_class = self.error_class return copy ```
This can be removed because we will get a field error from `Form.clean()`.
We don't modify `creation` so there is no need to create a new one.
Normally these objects will appear in a correct order because `serialize_db_to_string()` sorts dependencies. I've changed this to `Object` and `ObjectReference` with circular dependencies to create a real-life test.
When you will create an app with `Object` and `ObjectReference` as defined in `backends.models` then `serialize_db_to_string()` generates `data` with order that causes an `IntegrityError`. That is what I meant by a "real-life" example.
> I had avoided using ObjectReference, since its ForeignKey has db_constraint=False which I assumed would prevent the problem from triggering. Did you try your new testcase without the fix applied? Yes, it fails without this patch with an `IntegrityError`.
No need to assign to `self.widgets` ```python if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = [w() if isinstance(w, type) else w for w in widgets] ```
I would manipulate `names` in `__init__()` instead of doing this on every `get_context()` or `value_from_datadict()` calls, e.g. ```python def __init__(self, widgets, attrs=None): if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] self.widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = widgets self.widgets = [w() if isinstance(w, type) else w for w in self.widgets] super().__init__(attrs) ... def get_context(self, name, value, attrs): ... for i, widget in enumerate(self.widgets): ... widget_name = name + self.widgets_names[i] ... def value_from_datadict(self, data, files, name): return [ widget.value_from_datadict(data, files, name + widget_name) for widget_name, widget in zip(self.widgets_names, self.widgets) ] ``` What do you think? It looks simpler, IMO.
You could zip here as well ```python for i, (widget_name, widget) in enumerate(self.widget_names, self.widgets): if input_type is not None: widget.input_type = input_type widget_name = name + self.widgets_names[i] ```
`u'` prefix in unnecessary, please use also hanging indentation.
I would leave creating widgets' instances in a single line, e.g. ```python if isinstance(widgets, dict): self.widgets_names = ... self.widgets = widgets.values() else: self.widgets_names = ... self.widgets = widgets self.widgets = [w() if isinstance(w, type) else w for w in self.widgets] super().__init__(attrs) ```
This needs to incorporate `name` somehow else it will break when form prefixes are involved or on top level field names collisions.
Any thoughts about allowing `widgets` to be a `dict` mapping names to widgets now that we assume that `dict`s are ordered? That seems more elegant than introducing a `names` kwarg and _zip_'ing it with `widgets`.
`display_name` is missing, we want to raise a warning with `display_name`, not `%s`.
We can use `display_name` instead of `MySQL`. I would keep the previous wording, e.g.: ``` %s may not allow unique CharFields to have a max_length > 255. ```
We should update `id` to the `mysql.W003`. Please update also `docs/ref/checks.txt`.
We should state clearly what to use when deprecation ends, there is a risk that we'll remove logging of suspicious session: ```python def decode(self, session_data): try: return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer) # RemovedInDjango40Warning: when the deprecation ends, replace with: # except signing.BadSignature: # logger = logging.getLogger('django.security.SuspiciousSession') # logger.warning('Session data corrupted') # except Exception: # # ValueError, unpickling exceptions. If any of these happen, # # return an empty dictionary (an empty session). # pass # return {} except Exception: return self._legacy_decode(session_data) ```
We can add a dot a use `__qualname__`, e.g. ```python return 'django.contrib.sessions.' + self.__class__.__qualname__ ```
I think this test should set `SECRET_KEY` to a specific fixed value since `legacy_encoded` depends on that exact value of `SECRET_KEY`. (Granted the chances that we are changing the secret key in the test settings is rather slim, but I'd still feel better if this code does not break if one does).
This is a field error, so IMO it's fine to mention only clashing model in the hint, e.g. ```diff diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py index a2e939fa3d..b4babe30ac 100644 --- a/django/db/models/fields/related.py +++ b/django/db/models/fields/related.py @@ -1433,15 +1433,16 @@ class ManyToManyField(RelatedField): if field.remote_field.through is model: return field.name opts = model._meta.auto_created._meta - clashing_obj = '%s.%s' % (opts.label, _get_field_name(model)) + clashing_model = opts.label + clashing_obj = '%s.%s' % (clashing_model, _get_field_name(model)) else: - clashing_obj = model._meta.label + clashing_model = model._meta.label + clashing_obj = clashing_model if settings.DATABASE_ROUTERS: error_class, error_id = checks.Warning, 'fields.W344' error_hint = ( - 'You have configured settings.DATABASE_ROUTERS. ' - "Verify that '%s' and '%s' are correctly " - 'routed to separate databases.' + 'You have configured settings.DATABASE_ROUTERS. Verify ' + 'that %r is correctly routed to a separate database.' ) else: error_class, error_id = checks.Error, 'fields.E340' @@ -1451,7 +1452,7 @@ class ManyToManyField(RelatedField): "The field's intermediary table '%s' clashes with the " "table name of '%s'." % (m2m_db_table, clashing_obj), obj=self, - hint=(error_hint % (m2m_db_table, clashing_obj)) if error_hint else None, + hint=(error_hint % clashing_model) if error_hint else None, id=error_id, ) ] ```
Chop blank line.
Revert this change.
Chop blank line.
Please wrap at 79 chars.
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
I think we should raise a more descriptive error, maybe the same as in `add()` and `set()`.
We can move `msg` before assertions ```python msg = "'City' instance expected, got %s" % chicago.pk with self.assertRaisesMessage(TypeError, msg): ... with self.assertRaisesMessage(TypeError, msg): ... ```
`1` -> `chicago.pk`
I partly restored `dates_or_datetimes` (removed in e88d2dfcf4daa2b4ee451f518085413bb3b8deeb), it looks simpler IMO.
These lines should be removed; it's possible for `databases` to be an empty list during tests and when no `--database` is passed to `manage.py` check as you've mentioned. When this happens this check should be entirely skipped.
This is unused. Please remove it. It will fix `flake8` error.
You should omit partial unique constraints, please use [`total_unique_constraints()`](https://github.com/django/django/blob/0352a44dd61c19bebf0c0b305dbbc3f710ff9945/django/db/models/options.py#L830-L840).
```suggestion database='default', verbosity=0, skip_empty=True, ```
```suggestion def test_skip_empty_tables_one_row(self): City.objects.create(name="London") tables = connection.introspection.django_table_names() tables = connection.introspection.exclude_empty_tables(tables) self.assertEqual(tables, ['introspection_city']) ```
```suggestion def test_skip_empty_tables_zero_rows(self): tables = connection.introspection.django_table_names() tables = connection.introspection.exclude_empty_tables(tables) self.assertEqual(tables, []) ```
```suggestion skip_empty=True) ```
Unless merging into `.django_table_names()` with a `skip_empty` argument: ```suggestion def exclude_empty_tables(self, tables): ```
Unless merging into `.django_table_names()` with a `skip_empty` argument: ```suggestion def exclude_empty_tables(self, tables): ```
```suggestion tables = connection.introspection.django_table_names(only_existing=True, include_views=False) if skip_empty: tables = connection.introspection.exclude_empty_tables(tables) ``` Alternatively, because this is quite specific, I think that we could just make this a flag on `.django_table_names()`: ```suggestion tables = connection.introspection.django_table_names( only_existing=True, include_views=False, skip_empty=skip_empty, ) ``` But I'm happy either way if others think not.
```suggestion skip_empty=False): ```
```suggestion """Exclude tables with zero rows from the provided list of tables.""" ```
```suggestion skip_empty = options['skip_empty'] ```
Strictly speaking it should be `--only-non-empty-tables` which is a bit of a mouthful. How about we invert the negative? And we can also drop `-tables` as it is obvious that we are flushing tables. ```suggestion '--skip-empty', action='store_true', help='Only delete from non-empty tables.', ```
I'd split this into two tests s o they can fail independently: `test_only_nonempty_tables_empty` and `test_only_nonempty_tables_one` or similarly named
```suggestion skip_empty=skip_empty) ```
```suggestion """Exclude tables with zero rows from the provided list of tables.""" ```
Haha. Well… 😅 I've done the following before to hook up the ORM to a view in a separate schema in PostgreSQL: ```python class Meta: managed = False db_table = 'schema"."matview' ``` Yay for dodgy hacks and workarounds! 🙈 Slightly different to embedded single quotes though. Yuck. Hopefully nobody has tried to do that on purpose.
We can do much better here. We don't need to regenerate the `LIMIT 1` snippet for every table, as it never changes. The `AS has_rows` is unnecessary. ```suggestion limit = self.connection.ops.limit_offset_sql(0, 1) sql = ' UNION '.join([ "(SELECT '%s' FROM %s %s)" % (table, self.connection.ops.quote_name(table), limit) for table in tables ]) with self.connection.cursor() as cursor: cursor.execute(sql) return [row[0] for row in cursor.fetchall()] ``` I'm also wondering whether we should pass the table names string literals in the `SELECT` as params to avoid any sniff of SQL injection. I honestly don't know if there is a real risk here. The advantage of keeping it like this is that we don't need to batch for SQLite and the overridden version there can be removed.
@charettes Hmm. Maybe it doesn't... 🤔 My mum would call that "belt and braces".
Out of curiosity, when does `'E'` is present in `str(number)`? Trying to figure out when the `lower()` call is necessary.
Yes that's fair, I haven't used CBV's so much recently and forget there are mixins for the Template and Context behaviour.
`return HttpResponseNotAllowed()` should be all that's required.
> The browser resubmits the "logout" tab, and the user is logged out again. The browser asks whether it should resubmit POST requests no? But you are right it is not 100% nice if `next_page` is not used.
We need to remove `get` from `http_method_names` because `TemplateView` still defines it and I really don't want it to be callable :) Or We stop using `TemplateView` and inherit from `ContextMixin` ` TemplateResponseMixin ` and `View` ourself…
The `View` class does this by default for unimplemented methods ;) Hence I'd like a solution where we can just drop the `get` in 4.0.
Ah, CSRF changing on logout saves us, of course. Brilliant. Thank you for testing! Not the kindest user experience but at least nothing breaks, so good from me.
Yes they do, but I think on restarting and being presented with confirm on top of a blank screen, most people would just click "yes, resubmit".
> Why? 🤔 Do you mean that get() shouldn't be called in post()? We use this pattern in many places and I don't see anything wrong in it. Okay, maybe I'm not used to common flows in class-based views. > Is it not already applied when next_page is set? Yes it is applied in that case. Still, a user could: 1. Click "logout", see the "logged out" page 2. Open a new tab and login 3. Restart their browser 4. The browser resubmits the "logout" tab, and the user is logged out again. I guess this pattern was here before, and this could be a separate issue.
How would the code in 4.0 look then? Just removing `get` will not do the trick since `TemplateView` defines it. IMO we should write the code as it would behave in 4.0 and then add the deprecation to the `get` part.
That would be counter-intuitive, not implementing `get` in the first place would already give you the wanted behaviour. Changing from `TemplateView` to `TemplateResponseMixin, ContextMixin, View` would get rid of the method.
This is funky and looks wrong, couldn't we just do the two lines here instead? ``` context = self.get_context_data(**kwargs) return self.render_to_response(context) ``` Also I don't know if it's been mentioned but rendering during a successful POST shouldn't really be done, Django uses the [“post-redirect-get” pattern](https://en.wikipedia.org/wiki/Post/Redirect/Get) everywhere in normal forms to avoid refreshes causing repeat actions. Couldn't we apply that here? Perhaps complicating things a lot though...
`@method_decorator(csrf_protect)` is missing. When the deprecation ends we should move it to `dispatch()`.
> Yes they do, but I think on restarting and being presented with confirm on top of a blank screen, most people would just click "yes, resubmit". Resubmit raises 403 in such case, so I don't think it's an issue: https://user-images.githubusercontent.com/2865885/160332701-2a502657-ebe6-4a37-97d7-fa625856e9c9.mp4
@adamchainz Does it work for you? :point_up:
Model cannot have multiple `AutoField`. For `AutoField` you can use auto created `pk`, for `SmallAutoField` and `BigAutoField` you need to add separate models.
These are not a proper regression tests. ticket-31301 describes an issue with mixed types, i.e. empty and set foreign keys in a single `bulk_create()`, e.g. ```diff diff --git a/tests/bulk_create/models.py b/tests/bulk_create/models.py index 87203ac4f3..e97d106029 100644 --- a/tests/bulk_create/models.py +++ b/tests/bulk_create/models.py @@ -53,6 +53,7 @@ class Pizzeria(Restaurant): class State(models.Model): two_letter_code = models.CharField(max_length=2, primary_key=True) + country = models.ForeignKey(Country, on_delete=models.CASCADE, null=True) class TwoFields(models.Model): diff --git a/tests/bulk_create/tests.py b/tests/bulk_create/tests.py index 2fd9801d35..9b20acb15e 100644 --- a/tests/bulk_create/tests.py +++ b/tests/bulk_create/tests.py @@ -60,6 +60,15 @@ class BulkCreateTests(TestCase): ]) self.assertEqual(Country.objects.count(), 4) + @skipUnlessDBFeature('has_bulk_insert') + def test_empty_set_foreign_key(self): + country = Country.objects.create(description='test') + State.objects.bulk_create([ + State(two_letter_code='NY'), + State(two_letter_code='IL', country=country), + ]) + self.assertEqual(State.objects.count(), 2) + def test_multi_table_inheritance_unsupported(self): expected_message = "Can't bulk create a multi-table inherited model" with self.assertRaisesMessage(ValueError, expected_message): ```
I'm in favor of re-raising `subprocess.CalledProcessError` as a `CommandError`, e.g. ```python def handle(self, **options): connection = connections[options['database']] try: connection.client.runshell(options['parameters']) except OSError: # Note that we're assuming OSError means that the client program # isn't installed. There's a possibility OSError would be raised # for some other reason, in which case this error message would be # inaccurate. Still, this message catches the common case. raise CommandError( 'You appear not to have the %r program installed or on your path.' % connection.client.executable_name ) except subprocess.CalledProcessError as e: raise CommandError( '"%s" returned non-zero exit status %s.' % ( ' '.join(e.cmd), e.returncode), ) ``` which will end with: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: "psql -U djangoticket -h localhost -p 5432 djangoticket --asdasdad" returned non-zero exit status 1. ```
I wonder if we should suppress `subprocess.CalledProcessError` when arguments are not correct, to get e.g. ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. ``` instead of ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. Traceback (most recent call last): File "manage.py", line 22, in <module> main() File "manage.py", line 18, in main execute_from_command_line(sys.argv) File "django/django/core/management/__init__.py", line 401, in execute_from_command_line utility.execute() File "django/core/management/__init__.py", line 395, in execute self.fetch_command(subcommand).run_from_argv(self.argv) File "django/django/core/management/base.py", line 328, in run_from_argv self.execute(*args, **cmd_options) File "django/django/core/management/base.py", line 369, in execute output = self.handle(*args, **options) File "django/django/core/management/commands/dbshell.py", line 25, in handle connection.client.runshell(options['parameters']) File "django/django/db/backends/postgresql/client.py", line 55, in runshell self.runshell_db(self.connection.get_connection_params(), parameters) File "django/django/db/backends/postgresql/client.py", line 49, in runshell_db subprocess.run(args, check=True, env=subprocess_env) File "/usr/lib/python3.6/subprocess.py", line 438, in run output=stdout, stderr=stderr) subprocess.CalledProcessError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ``` We can also re-raise it as a `CommandError`: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ```
This is an unrelated cleanup. Please move to the separate commit.
No guarantees doesn't mean no efforts :-) However let others chime in and tell their opinion on this.
Sounds like there's no choice then? At least an additional note in 3.1.txt `Database backend API` section. (I've always imagined backend maintainers keep an eye on that for exactly this reason...)
Do you really want to make the `parameters` parameter mandatory? This might break third-party backends.
OK, both seem to work testing it... 👍
Happy for you to do it. 😃
I think the _through_ test failure has more to do with how `RemoveField.references_field` deals with through. For example, not saying this is the right solution here, but the following diff happens to make the tests pass as well ```diff diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py index 41c389f79f..d6cbd6b9c6 100644 --- a/django/db/migrations/operations/fields.py +++ b/django/db/migrations/operations/fields.py @@ -36,7 +36,7 @@ class FieldOperation(Operation): return field_references_model(self.field, ModelTuple(app_label, name_lower)) return False - def references_field(self, model_name, name, app_label=None): + def references_field(self, model_name, name, app_label=None, reference_through=True): model_name_lower = model_name.lower() # Check if this operation locally references the field. if model_name_lower == self.model_name_lower: @@ -53,11 +53,12 @@ class FieldOperation(Operation): (not hasattr(self.field, 'to_fields') or name in self.field.to_fields or None in self.field.to_fields)): return True - through = getattr(remote_field, 'through', None) - if (through and ModelTuple.from_model(through) == model_tuple and - (getattr(remote_field, 'through_fields', None) is None or - name in remote_field.through_fields)): - return True + if reference_through: + through = getattr(remote_field, 'through', None) + if (through and ModelTuple.from_model(through) == model_tuple and + (getattr(remote_field, 'through_fields', None) is None or + name in remote_field.through_fields)): + return True return False def reduce(self, operation, app_label=None): @@ -186,6 +187,11 @@ class RemoveField(FieldOperation): def describe(self): return "Remove field %s from %s" % (self.name, self.model_name) + def references_field(self, model_name, name, app_label=None): + return super().references_field( + model_name, name, app_label=app_label, reference_through=False + ) + def reduce(self, operation, app_label=None): from .models import DeleteModel if isinstance(operation, DeleteModel): ```
The previous return value was `not operation.references_field` which meant 1. `not True -> False`, if the operation refers to the field block optimizations through. 2. `not False -> True`, if the operation doesn't refer to the field allow optimizations through. You proposed change makes it the other way around.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
I wonder if we can just set `default_time_format` attribute.
Nice work on `validate` 👍
Yes, that's better.
I think we can make small refactoring in advance. I would move `MigrationExecutor.collect_sql()` (which is used only by `sqlmigrate`) to the `MigrationLoader`. With this change we'll be able to use here `MigrationLoader` and simplify changes.
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
This small optimization is not related with fix. Merged in e12fea24f06f8911ddc2af1d6cbfb1adb529c1f2.
Two tests i.e. `test_sqlmigrate_ambigious_squashed_migration_name()` and `test_sqlmigrate_squashed_migration()` work without this patch. It's fine to increase coverage but we should move them to a separate commit.
It looks that `test_sqlmigrate_replaced_second_migration()` and `test_sqlmigrate_replaced_migration()` are redundant. Please remove one of them.
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
It may not be possible without a database roundtrip. I'm just asking.
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
If look like could subclass `Func` and avoid any `resolve_expression` or `as_sql` overrides. ```python class SearchQuery(SearchQueryCombinable, Func): output_field = SearchQueryField() SEARCH_TYPES = { 'plain': 'plainto_tsquery', 'phrase': 'phraseto_tsquery', 'raw': 'to_tsquery', 'websearch': 'websearch_to_tsquery', } def __init__(value, output_field=None, *, config=None, invert=False, search_type='plain'): function = self.SEARCH_TYPES.get(search_type) if function is None: raise ValueError("Unknown search_type argument '%s'." % search_type) if not hasattr(value, 'resolve_expression'): value = Value(value) expressions = (value,) if config is not None: config = SearchConfig.from_parameter(config) expressions = (config,) + expressions super().__init__(*expressions, output_field=output_field, function=function) if invert: self.template = '!!(%s)' % Func.template ```
`_combine()` is unnecessary since its introduction, I moved it to a separate commit b62c58d5fccaeedc7bc4a064b4678e4ed1e77581.
This makes me wonder why `SearchQuery` is a `Value` in the first place given it needs to resolve `config` and `value` now.
`copy()` in unnecessary.
We can keep `invert` directly in the `SearchQuery` instead of `extra`, e.g. ```python ... self.invert = invert super().__init__(*expressions, output_field=output_field, function=function) ```
```suggestion Return a dictionary of {table_name: (table_name_other_table, other_table)} ```
These doesn't use hooks from `OperationTestBase`.
This is not necessary.
We can use `CaptureQueriesContext` instead of mocking `BaseDatabaseSchemaEditor.execute()`.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
Couldn't you just call `self.get_port` here to get the `server_port`? The rest of the code looks solid. ie: ``` if settings.USE_X_FORWARDED_PORT: server_port = self.get_port() if server_port != ('443' if self.is_secure() else '80'): host = ... ``` I think that should be enough if someone actually set USE_X_FORWARDED_PORT
The way I read the docs, it means that if `X-Forwarded-Host` contains a port already we should not attach `X-Forwarded-Port`. So imo we are left with two options: * Throw an error if `USE_X_FORWARDED_PORT` is set to `True` and the forwarded host already contains one. * Simply ignore `HTTP_X_FORWARDED_PORT` if the forwarded host contains a port. I am slightly leaning towards option 1) if it doesn't make the code to ugly (such things are always hard to debug if they don't raise errors)
IMO, we should use `self.decode` here.
I'm starting to think if this is an expected change :thinking: This can force updates each time when the password is checked for password created with a `salt` passed manually to the `make_password()`.
Really really minor nitpick; if flake8 etc do not complain maybe move `entropy.` up one line; looks really ugly like this especially if the code below is longer :)
While trying to push this PR over the finish line I noted that `salt_len` is not really the `salt_len` we want (it's the size of a string in bytes). I have pushed a new PR #13815 which adds the actual salt to `decode`. I'll update this PR once the other one is merged.
We should leave `None` here, an empty salt is not the same as not using salt. `must_update()` should return `False` if `salt is None`, e.g. ```python def must_update(self, encoded): try: salt = self.safe_summary(encoded)['salt'] return salt < self.salt_entropy / math.log(62, 2) if salt is not None else False except (KeyError, NotImplementedError): ... ```
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
Please add `default=False`.
Yup just caught that :P
`--ignore-app-config` is unclear for me, maybe `--include-stale-apps`.
Hm, I think I suggested this change on the new test, did not realize the existing test used `assertCountEqual`. Still, this looks like a good improvement, but then in a separate commit or PR (the commit history of this PR should probably be squashed anyway before merging).
It's not an improvement. We run tests on databases that support check constraints and on databases that don't support them. We want to check both cases.
Also, it seems that you are not actually calling your new function yet, which should be fixed (or will be automatically fixed if you integrate into `_check_constraints`, which I would prefer).
I would suggest integrating this code into `_check_constraints` above, since then the duplicate code up to here can be shared. The name of that function implies that it is expected to check *all* constraints (I' reading it as "check all constraints", not "do something about check-constraints"). There might even be some code sharing in the error generating (e.g. if the constraint-specific check code sets a `message` and `code` variable, some common code could fill in the rest of the warning (especially if the hints are made equal as I suggest below).
This warning ID was not updated after copy-pasting it.
This should use `assertEqual` and not `assertCountEqual`, otherwise there is no point in entirely recreating the expected warning, you could just hardcode 1 or 0.
The wording is a bit inconsistent with the one for check constraints, here there is some duplicate info between the warning and the hint, and it talks about "The constraint" without naming it. I would suggest: ``` checks.Warning( "%s does not support unique constraints with conditions." % connection.display_name, hint=( "A constraint won't be created. Silence this " "warning if you don't care about it." ```
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
This needs to be based of `databases` just like `_check_constraints` is.
> Right, I think the improvement part is that you're actually looking at the content of the errors, rather than just at the count. With the original code, there really is no point in recreating the full warning literally, you could also just say: > > ``` > expected = 0 if connection.features.supports_table_check_constraints else 1 > self.assertEqual(len(errors), expected) > ``` [`assertCountEqual()`](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertCountEqual) doesn't work that way, but do to the fact that we have list with only 1 element we can use `self.assertEqual(errors, expected)`.
Add trailing comma.
This change is not related with this patch, please revert it.
You can't use `connection` here, you need to pass `databases` to `_check_indexes` and follow what `_check_constraints` does.
Should the initial token generator not also use the mocked now to guarantee exact calculations? Above, any time that passes between the `now =` and the actual generation of the token will be *extra* lifetime of the token (which can still make the tests fail by keeping the token valid in the timeout + 1 test if this time is >= 1 second).
This one as well
This one as well.
I think this can be in single line: ``` url = reverse('admin:auth_user_add', current_app=self.admin_site.name) ```
Having said that, I'm immediately not even sure that we need the release note: `MultipleHiddenInput` is just broken no? (I guess it doesn't hurt...)
I think we don't need it. but lets @felixxm decide about it. Thanks for the patch :+1:
IMO we don't need a new parameter, the previous behavior was incorrect. We should use different `name`'s for all widgets (like `MultiWidget`). \cc @carltongibson
Do we really need this test? seems it doesn't relate to this change.
This won't work as is because `In.process_rhs` optimizes empty result sets which breaks vacuous truth in this case. In other words `.filter(field__notin=[])` won't return *any* results when it should return *all* results.
I don't think this test demonstrate _why_ this feature is required as this test passes with `exclude(id__in=[4, 5, 6, 7, 999])` and differences between both lookups is the main selling point of the feature.
Instead of putting this in `In`, I think it's better to override `process_rhs` in `NotIn` itself. Perhaps you could use `try` and call `super().process_rhs`, then `except EmptyResultSet`.
I would have simply written: "Please do not add spaces around commas".
How about using "parent" here instead of "master"? Seems like a better fit with "child processes".
Can we move subclassing `unittest.TestResult` to a separate commit? Is it a valuable optimization on its own? or it's strictly related with supporting `--buffer` with `--parallel`.
A set literal makes a tiny bit more sense here I think: `{'addError', 'addFailure', 'addUnexpectedSuccess',}`
> Paging @bmispelon for review since you wrote the first buffer PR #12169. I don't feel very confident reviewing this. My work on #12169 was mostly to write glue code to pass the option correctly to python's unittest. One thing I wonder is whether you've investigated actually extending the base `TestResult` instead of copy/pasting from it. The docstring of `RemoteTestResult` seems to indicate that the copy/pasting was done because Django didn't need the whole API of `TestResult` but I get the feeling that we're trying to implement that API now, so maybe it'd be worth it to extend rather than copy/paste. Relying on Python's implementation would also make me more confident about the lack of tests.
I don't think it would make a difference in memory efficiency. Seems fine to keep it as it is.
Oh, interesting. Is that because of mutability? What about a frozenset then? I'm not suggesting to change it here (I don't think it matters much) but you made me curious now :)
Try to avoid `We` in docstrings.
Chop blank line.
Maybe: ```suggestion state.pop('_stdout_buffer', None) state.pop('_stderr_buffer', None) state.pop('_original_stdout', None) state.pop('_original_stderr', None) ```
I don't think we need a separate hook. We can pre-calculate set of column names and reuse it for all aliases.
In such case we will need to calculate this multiple times because it is inside a loop. Moreover `if` is for a deprecated usage, so ...
> 1. we don't process a model which is processed already. I restored this. > 2. we don't process extra model when we find the `alias` in the join column names. Yes, but we're doing this multiple times (for each model), so :heavy_plus_sign: / :heavy_minus_sign: . I believe it's better to pre-calculate. > 3. we don't need to process model if `allow_aliases = False` Right, we can optimize this.
I changed tests to reuse existing models.
Now that I think of it you can likely avoid a full set materialization by passing `alias` to the function and having it return as soon as it has a match. e.g. ```python def _column_name_conflict(self, alias): models = {} for join in list(self.alias_map.values())[1:]: model = join.join_field.related_model if model in models: continue for field in model._meta.local_concrete_fields: if field.column == alias: return True models.add(model) return False
Could use `cache` here to be consistent with how the migration recorder does it. ```suggestion app_label = 'cache' ```
`deferred_sql` [will automatically be added to `collected_sql` on `__exit__` so iterating over it outside of the context should make it less awkward](https://github.com/django/django/blob/c1c361677d9400c8e2cdaddda0c16086bb358492/django/db/backends/base/schema.py#L112-L137). ```suggestion with connection.schema_editor(collect_sql=True) as editor: editor.create_model(CacheTable) for statement in editor.collected_sql: self.stdout.write(statement) ```
Minor but I'd move the `try` around the `with` since `editor.__exit__` will execute deferred SQL which could also raise `DatabaseError`. This is not something the previous code was accounting for but I guess it would hurt doing so here. ```suggestion try: with connection.schema_editor() as editor: editor.create_model(CacheTable) except DatabaseError as e: raise CommandError( "Cache table '%s' could not be created.\nThe error was: " "%s." % (tablename, e) ) ```
`self.actions` already contains action names so we don't need to wrap them in `get_action()`. Moreover for a nonexistent name it raises `TypeError: 'NoneType' object is not subscriptable`. We've already ignored them in `filter(None, actions)` so it's safe to use `self.actions`. I will adjust this.
I don't have a strong feeling about either, this approach avoids an unnecessary intermediary list creation though.
We can use generator.
Use a `set` if this value is only used for containment checks ```suggestion local_action_names = {self.get_action(action)[1] for action in self.actions} if self.actions else set() ```
Builtin tags already exist, so `versionchanged`.
Could we call it `async_safety` rather than `asgi`? I know `async` is a reserved word, but `asgi` is sort of misleading, this happens under synchronous environments too
I'm adding a little more explanation to the message, and making it more consistent with the others such as the DEBUG check
Minor but I'd move this control flow block after the `weights` one to match the args order.
That's the only thing that I think we should change here is too make the caller assign `subquery = True` and assert `query.subquery` here. Altering an argument is usually bad practice so I think `get_aggregation` should assign `inner_query.subquery = True` instead.
We use `new_default` only when `old_field.null and not new_field.null` so IMO it's fine to use ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index bfccf5e8fb..8cd5e11bbf 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -675,17 +675,17 @@ class BaseDatabaseSchemaEditor: # 3. Replace NULL constraint with NOT NULL # 4. Drop the default again. # Default change? - old_default = self.effective_default(old_field) - new_default = self.effective_default(new_field) - needs_database_default = ( - old_field.null and - not new_field.null and - old_default != new_default and - new_default is not None and - not self.skip_default(new_field) - ) - if needs_database_default: - actions.append(self._alter_column_default_sql(model, old_field, new_field)) + needs_database_default = False + if old_field.null and not new_field.null: + old_default = self.effective_default(old_field) + new_default = self.effective_default(new_field) + if ( + not self.skip_default(new_field) and + old_default != new_default and + new_default is not None + ): + needs_database_default = True + actions.append(self._alter_column_default_sql(model, old_field, new_field)) # Nullability change? if old_field.null != new_field.null: fragment = self._alter_column_null_sql(model, old_field, new_field) ```
We should avoid calling `self.effective_default(new_field)` twice (here and in [line 721](https://github.com/django/django/pull/12612/files#diff-b69190ab88f6c5737b2562d94d7bf36bR721)). Maybe we can make it lazy or refactor this change a bit.
``` @unittest.skipIf(connection.vendor == 'oracle', "Oracle doesn't support bitwise XOR.") ```
``` @skipUnless(connection.vendor == 'oracle', "Oracle doesn't support bitwise XOR.") ```
``` msg = '...' with self.assertRaisesMessage(NotSupportedError, msg): ```
`Bitwise XOR is not supported in Oracle.`
Ahh right :disappointed: I'm fine with raising exception on Oracle: ```python raise NotSupportedError('Bit-wise xor is not supported in Oracle.') ```
That shouldn't be an issue (see a workaround for `|`).
This is already handled for `&`, `|`, and `<<`, so maybe we can just add `#` to the list of connectors in the line 243, e.g. ```python elif connector in ('&', '|', '<<', '#'): connector = '^' if connector == '#' else connector return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) ```
You removed `'%y/%m/%d'` from the original PR, can you confirm this change.
Use `msg` variable and this style: https://github.com/django/django/blob/55cdf6c52db07f29128741b8734a523ed042e465/tests/many_to_one/tests.py#L53-L55
```suggestion 'Password must be string or bytes, got %s.' % type(password).__qualname__ ```
I wonder why it works without `list()` on PostgreSQL :thinking:
I would add a `return` when it's not supported (even if it shouldn't be called): ```python if not self.connection.features.can_return_columns_from_insert: return ```
I checked and on PostgreSQL we have a list of tuples for multiple rows and a tuple for a single row; on MariaDB we have a tuple of tuples for multiple rows and a tuple for a single row :confused: It's a really implicit logic, we should support both formats in: https://github.com/django/django/blob/8f2a6c76d19e4010c4683b20ed7f1eb4b07c17eb/django/db/models/query.py#L1257-L1260
Due to the [PEP-249](https://www.python.org/dev/peps/pep-0249/#fetchall) it can be any sequence, so we can change this in advance.
We can reuse `can_return_columns_from_insert` here: ```python can_return_rows_from_bulk_insert = property(operator.attrgetter('can_return_columns_from_insert')) ```
... or simply accept `tuple` if that's the case on MariaDB.
`becuase of` has a typo and looks incomplete
`redirect_to_login()` is a helper function, not a view.
`redirect_to_login()` is a helper function, not a view.
Oh, actually it looks like `test_runner.tests.AutoIncrementResetTest.test_autoincrement_reset2` is also failing on MySQL.
Chop blank line.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
I think it's better to filter out at the database level to avoid retrieving all table rows.
```suggestion SELECT table_name, table_rows ```
We dropped `sequence_reset_by_name_sql()` intentionally in d28396f5268f1974ef1e84d13bcf1ac107005ced. It's redundant after `TRUNCATE`, we should call it only in `DELETE FROM` branch.
In MySQL introspection we use `table_schema = DATABASE()`, I think we should use it here.
Chop blank line.
```suggestion def sequence_reset_by_name_sql(self, style, sequences): return [ '%s %s %s %s = 1;' % ( style.SQL_KEYWORD('ALTER'), style.SQL_KEYWORD('TABLE'), style.SQL_FIELD(self.quote_name(sequence_info['table'])), style.SQL_FIELD('AUTO_INCREMENT'), ) for sequence_info in sequences ] ```
```suggestion with self.connection.cursor() as cursor: cursor.execute(""" SELECT table_name, table_rows FROM information_schema.tables WHERE table_schema = %s AND table_name IN %s """, (schema_name, tables)) rows = cursor.fetchall() ```
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
```suggestion for table_name, table_rows in rows: ```
Is this necessary to get tests passing? I think it's already handled by `self.sequence_reset_by_name_sql(style, sequences)` below when `sequences` is specified. ```suggestion ``` Tests that require sequences to be reset should explicitly set [`reset_sequences=True`](https://docs.djangoproject.com/en/3.0/topics/testing/advanced/#django.test.TransactionTestCase.reset_sequences).
You want to filter by `table_name IN %` and pass `tables` in params else this will flush all tables instead of the ones specified by `available_apps`'s models.
Tests are failing for a different reason due to qwirks with our CI system; notice that SQLite tests are failing as well.
has been -> is
Is this is the right commit? I don't think the deprecation of the model field should require any changes. I would have deprecated the model field first, then tackled the question of whether or not to deprecate the form field separately.
I removed these decorators because we added a system check so they don't ignore anything.
Maybe: ``` """A property that can be accessed directly from the class.""" ````
I don't see much value in adding an example in this docstring. Please remove it.
I think leave the original `widget = widget or self.field.widget` here. Then do the `isinstance()` check, so that we're no repeating ourselves in the `else` block. `widgets` might then be clearer as `subwidgets`. (Or such.)
We need to factor this differently, as it's an exact duplicate of the added block above.
* We're still preferring single quotes, please use those throughout, unless there's a nested single quote. * This change is unrelated, please revert.
> We could rewrite it so cloning happens after system checks are run If that's easy enough I think it's a good idea. It means that check errors will be displayed and stop the test process sooner, speeding up feedback.
Some checks require database access e.g. mysql.W002 ( https://docs.djangoproject.com/en/3.0/ref/checks/#database ) , django-mysql's checks ( https://django-mysql.readthedocs.io/en/latest/checks.html ). Those I've linked to don't strictly need access to an existing schema but I think changing this could be considered a breaking change.
Well... `./manage.py test` would benefit across all DBs no? (The issue is can we make it work for that combo... — but also some macOS user who's got version IDK of SQLite — i.e. can we fallback gracefully.) My thought is just that maybe (**maybe**) we can opt for the easier path, if that's available after branching 3.2… (First preference is to get it in, but balancing effort/complexity to reward)
I moved this hook to a separate PR, see #15457.
I'm confused. Is there something incorrect here or can this just be: ```suggestion self.connection.settings_dict['NAME'] = worker_db ``` If the intent was to avoid mutating the original then do this (although I'm not sure it's required): ```python self.connection.settings_dict = {**self.connection.settings_dict, 'NAME': worker_db} ```
`VACUUM INTO` was [added in 3.27.0](https://sqlite.org/releaselog/3_27_0.html). This would bump requirements in `databases.txt` and `check_sqlite_version()` check in `django/db/backends/sqlite3/base.py`
Maybe I'm missing something, but why do these need to be wrapped with `str()` anyway? You could do `{alias!s}` instead of `{str(alias)}`, but if it isn't required, just use `{alias}`. In that case you can use f-strings.
```suggestion elif multiprocessing.get_start_method() == 'spawn': ```
OK, we're talking about https://bugs.python.org/issue27645 ~, so for this we should check both `SQLite` and Python versions~: ```suggestion can_clone_databases = PY37 ```
Also keep the style the same in this file.
Keep the style the same here and below
`setUpTestData` only runs once at the start of the test case, so I don't think this is particularly bad. But if we coudl avoid app labels being incorrectly marked as stale, tath would be better.
You can put this import at the top of the file
So it looks as though you've run `black` over this as there are changes other than quotes. We're not currently ready to use `black` as it is still in pre-release.
Similarly, it seems like `DiscoverRunner` shouldn't have to know about details like `suite.initial_settings`, `suite.serialized_contents`, and `multiprocessing.get_start_method()`. One alternative would be to make this a method of `ParallelTestSuite` called something like `initialize_suite()`. Then, inside `run_suite()` and before calling `runner.run(suite)`, `DiscoverRunner` could do a `hasattr` check for that method and call it if present.
We cannot bump to SQLite 3.27 because it will break all installations with Python 3.6.
I would do this in reverse, e.g. ```python if self.connection.mysql_is_mariadb and self.connection.mysql_version >= (10, 5, 2): return super().sql_rename_column return 'ALTER TABLE... CHANGE...' ```
I think this test can be entirely removed if `test_nested_subquery_outer_ref_with_function` covers the usage case appropriately.
We can strip `input` and `widget` (as Claude suggested).
`== 'checkbox'` now we strip widget and input.
No, I was thinking about `'input'` an `'widget'` strings, e.g. - `MultipleHiddenInput` -> `multiplehidden`, - `SplitHiddenDateTimeWidget` -> `splithiddendatetime`, - `PasswordInput` -> `password`. Does it make sense? :thinking:
`# Store ... warning message.`
Chop blank line.
Wrap at 79 chars.
I reverted `select.output_field` to `select.field` (I know that's the same) because it's not related with this patch.
Looks like adding this field changed the way some database returned unordered sets. You might need to add a `Meta.ordering = 'pk'` below.
Looks like this will need to do the following to deal with transforms. ```suggestion select = self.select[0] return getattr(select, 'target', None) or select.output_field ```
Same here: ```suggestion with self.assertRaisesMessage(ValidationError, 'Enter a valid duration.'): ```
I think we don't need to define `msg` variable: ```suggestion with self.assertRaisesMessage(ValidationError, 'This field is required.'): ```
Should always prefer a literal. ```suggestion return {} ```
This can go away now, but needs a new test that the warning is raised in the base hashers `decode`
Given that this explicitly tests the base hasher I'd replace `.*` at the beginning with the actual class name.
Yes please, for further reusability of the `decode` function it makes sense to use `int` where the underlying data is actually an `int`. As for consistency that imo went away once we switched `iterations` to `int`. And I still think this switch makes sense since we do not have to call `int` all over the place where we use it. If you think of our endgoal (ie something like a `salt_len` as result of `decode`) so we can update `must_update` to account for the salt, it makes even more sense to have integers. Imo the key->value relation is well defined and with python being as dynamic as it is, let's make use of that.
This warning text could include `type(self).__name__` to provide a bit of additional guidance.
I think this got copied from somewhere else by mistake and should be dropped (including the following line)
I'd call this `work_factor` as dictionary key and only in `safe_summary` it would be `work_factor`
This method returns a list and not a dict.
I would put "decode" into quotes or so (@felixxm can certainly tell us what the proper syntax is)
Wouldn't it make sense to call `int` on `interations` alread in `decode`? From the naming alone I think it would make sense to move it into `decode`.
Sorry, I had a typo in https://github.com/django/django/pull/12675#discussion_r418965162 -- what I ment to say was: keep `work factor` in safe summary (since it's for display and already translated) and `work_factor` in `decode`. This will also require less changes in the tests.
Not sure what the best option is, maybe ``` f'Method `decode`not fully…` ``` lets see if someone else chimes in.
Ah yes, makes sense, `argon` is to complicated in that matter most likely :/
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
No worries, try to keep the PR small. I will update the Argon hasher myself (updating to a new argon-cffi version) in a separate PR which should (tm) make this code nicer.
I am currently giving the PR a full final review and I think we can drop those assertions now that they are done in decode already, what do you think? (same for the assertion in `safe_summary` and other hashers)
For simplicity I think it would be better to revert this to the previous code, ie simply https://github.com/django/django/blob/69e0d9c553bb55dde8d7d1d479a78bfa7093f406/django/contrib/auth/hashers.py#L425-L427 -- I understand your motivation behind using `decode` here, but simplicity wins especially in security relevant code.
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
Since you moved the warning into `decode` you can drop the additions from `must_update`
Ah, I see. I looked for such a change in the original method, not in an override. Maybe that's a sign that such an override isn't the best approach in any case. Using a string might indeed be better, then :-)
@smithdc1 it does thanks!
I'd revert this as I don't think it is better and it isn't making this more consistent with code elsewhere. ```suggestion if isinstance(stored_backend, RemoteUserBackend): ```
This one is fine as `auth.load_backend()` is used in `clean_username()` above. ```suggestion request.session.get(auth.BACKEND_SESSION_KEY, ''), ```
Hey guys, `index_together` and `unique_together` have been fixed before in this BR: https://code.djangoproject.com/ticket/24757
I would recommend to call `super` here after overrides
@aryan9600 I have doubts about that. If you look at the user report it mentions that the issue happened when using `Meta.indexes = [models.Index(fields=['article', 'date'])]` which is equivalent to `Meta.index_together = [('article, 'date')]`. I wouldn't be surprised if `unique_together` and unique `constraints` were affected as well since these are backed by b-tree indices.
Sounds, good thanks for giving this ticket a shot by the way. It's a tricky problem with a few edge cases but you'll certainly learn a lot of things along the way.
The logic needs to be smarter than that. It needs to take into account that other indices might be covering this field (`index_together`, other `indexes` entries) as well. Under such circumstances it's not necessary to create another index. Also only the first field on `index.fields` need to be considered for the `ForeignKey` case. If a foreign key appears as a second element in a composite index MySQL won't be able to use it internally to enforce the constraint. Let me know if that makes sense to you.
Here we also should call `super` and not copy-paste code
I'd be great to have bit more clarity about which failure case we're handling here with `KeyError`. This seems like a complex routine wrapped in a catch all.
My gut feeling is that it's normal that these test assertions lost a bit of their original _intent_ now we're not using rendered models anymore. The reason for that is that `.field_name` gets assigned on model rendering which we completely avoid doing here. The fact _rendered_ model fields were making their way into operations breaks the `ModelState.__init__` expectations and was really just an implementation detail. Looking more at the ticket-23415 and the resulting patch 215aa4f53b6bbd07d5c1eecfa94e7fcd00da813e these particular assertions had little to do with the issue of unmanaged models not including their fields in the first place. It's true that the symptom that the reporter mentioned was improper foreign key references by models pointing at the unmanaged model but the true bug there was that unmanaged model fields were not tracked in migration state. TL;DR I think this is fine.
This seem a bit arbitrary, is it the original logic? I'd type check against `base` instead.
@David-Wobrock I checked out your branch to build an alternative to #13904 off model states and I noticed both `through_app_label` and `through_model_name` are unused which makes me believe something is off here.
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
Ditto, I'm pretty sure this will always be `True`.
Ditto, I think this will always be `True`.
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
Isn't the `s` at the end of support redundant? ```suggestion # MariaDB >= 10.5.2 and MySQL >= 8.0.4 support an ```
I think we should keep the original type.
Can use `asserIn` here for a more specific assertion method. Same for other tests. ```suggestion self.assertIn(expected, out.getvalue().strip()) ```
Oracle doesn't support multiple constraints on the same fields, so we need to skip this test on Oracle.
`get_constraints()` depends on database, e.g. on PostgreSQL unique constraints are reported as indexes. That's why I decided to move unique constraints assertions to a separate method `assertUniqueConstraintExists()`.
I will revert this changes. Test failure is related with invalid identifier, if we changed `named-group` to the `named_group` all works as expected and the current version of this warning is still valid.
I would change ```diff --git a/django/core/management/commands/dumpdata.py b/django/core/management/commands/dumpdata.py index df9eecc0f8..953f261ef4 100644 --- a/django/core/management/commands/dumpdata.py +++ b/django/core/management/commands/dumpdata.py @@ -67,7 +67,7 @@ class Command(BaseCommand): def handle(self, *app_labels, **options): format = options['format'] indent = options['indent'] - using = options['database'] + database = options['database'] excludes = options['exclude'] output = options['output'] show_traceback = options['traceback'] ``` to simplify this. We should also skip models with different `db` for read, instead of checking `router.allow_migrate_model()`, e.g. ```python using = router.db_for_read(model) if not model._meta.proxy and (not database or using == database): if use_base_manager: ... ```
Low-level tests are not necessary, it should be feasible to test using `Lexeme()` with special characters in a query.
As django 3.0 is only compatible Python ≥ 3.7, maybe we could start having some type hints? ```suggestion def make_token(self, payload: dict, valid_for=None): ``` Same for `valid_for`, would be nice if we had a direct hint that is a timedelta!
Type hints are not coming to Django (yet) https://groups.google.com/d/topic/django-developers/C_Phs05kL1Q/discussion
```suggestion salt = self.salt or f'{self.__class__.__module__}.{self.__class__.__qualname__}' ```
```suggestion For encryption and other more advanced use cases, you can use third-party packages like PyJWT. ```
I added `Square` without a sequence to show that delete is used in such case.
I don't think that we need 3 authors and 6 books for this test. I will remove the last author.
`allow_cascade` doesn't change anything on MySQL, so I'll merge this test with `test_sql_flush()`.
I think you'll want to define `GeometryField.from_db_value` instead.
I will move all early returns to a separate commit.
We made this change to prevent tests failures on Oracle (see ticket-31492).
`verbosity=0` is not necessary.
`verbosity=0` is not necessary.
I don't think `, 0` is needed. `get()` will return `None` in the case of no match, which is more appropriate, and still falsey for the below expression. ```suggestion prev_state_base_model = self.from_state.models.get((base_app_label, base_name)) curr_state_base_model = self.to_state.models.get((base_app_label, base_name)) ```
`ModelState.fields` are now stored into a `dict` since 06889d62063f0d12aaf618101dfc1b07333117be so this can be reduced to. ```suggestion if prev_state_base_model and curr_state_base_model: removed_base_fields = set(prev_state_base_model.fields).difference( curr_state_base_model.fields ).intersection(model_state.fields) ```
It's clearer to unpack the tuples rather than index with 0 ```suggestion prev_base_fields = set(name for name, field in prev_state_base_model.fields) curr_base_fields = set(name for name, field in curr_state_base_model.fields) removed_base_fields = prev_base_fields.difference(curr_base_fields) curr_model_fields = set(name for name, field in model_state.fields) ```
This makes me wonder if we should compare field beyond its name but I can't think of a scenario where that would be problematic given we don't allow MTI field collision.
IMO this should not raise a warning.
`must be an existing model object.` -> `must be saved.`
Have you checked ticket-7488? If admin filters by nonexistent objects then we need to fix this in advance.
IMO this should not raise a warning.
Maybe we should move this directly to the `RelatedLookupMixin` :thinking:, I don't have a ready answer.
In my searching, only group 1 is used, so perhaps can avoid unnecessary capturing: ```suggestion r'^(.*)\s(?:ASC|DESC).*', ``` Here are the results of the search: ``` django/db/models/sql/compiler.py 381 without_ordering = self.ordering_parts.search(sql).group(1) 394 without_ordering = self.ordering_parts.search(sql).group(1) ```
It might be worthwhile to include a test for a `UniqueConstraint` spanning two fields.
I think we also need to exclude [conditional constraints](https://docs.djangoproject.com/en/3.0/ref/models/constraints/#condition) here.
Ah! Maybe include a test for the scenario then.
+1 to some form of runtime warning.
Can we log a _warning_ here rather than raise a `CommandError`? That way you are able to run this command without a database connection at all. Right now you would be hiding the ugly traceback, which is good, but still preventing someone from running this if they don't have a connection.
`f-string`s should not contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
```python file_hash = ('.%s' % file_hash) if file_hash else '' ```
We should use a custom storage for this test (instead of mocking).
Is there a reason to add these as module constants? I would rather move them to the `HashingSessionBase`. Also we don't need to allow customizing delimiter.
If we want to change the default we can add a separate ticket and change it in Django 4.0. There is no need to use `VERSION`.
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
That's not a proper fix, because it doesn't test the same cases, see RFC-850.
Please revert this change, `verbosity` is necessary.
Here we display a message even with `verbosity=0`, so I think it's worth to leave it.
Only this parameter is unnecessary, rest of them is necessary to hide std outputs.
Please revert this change, `verbosity` is necessary.
Please revert this change, `verbosity` is necessary.
Please revert this change, `verbosity` is necessary.
Please revert this change, `verbosity` is necessary.
They can be equal, so: ```python raise ValueError("'absolute_max' must be greater or equal to 'max_num'."). ```
`assertEquals()` is deprecated, please don't use it.
Please chop unnecessary blank lines.
Chop this docstring.
I'm not sure if this assertions have value.
WDYT about adding `or self.title` here? ``` python self.title = title or self.title or self.lookup_title ``` This would add support for the following: ``` python class MyStaffFilter(BooleanFieldListFilter): title = "By can haz admin" # no effect :( overwritten in __init__ @admin.register(User) class UserAdmin(UserAdminBase): list_filter = ( ("is_staff", MyStaffFilter), ) ```
We need to consume the entire iterator: ``` Exception ignored in: <posix.ScandirIterator object at 0x7f5a9e95de10> ResourceWarning: unclosed scandir iterator <posix.ScandirIterator object at 0x7f5a9e95de10> ```
`title` is a `CharField` so `str()` is unnecessary.
`name` is a `CharField` so `str()` is unnecessary.
`make` is a `CharField` so `str()` is unnecessary.
this changes the semantics of the test, though the test name makes me think it's not actually testing the intended behavior... cookies are not distinguished by port number (https://tools.ietf.org/html/rfc6265#section-8.5) so I would expect this test to have a request with a different port number than the `Referer`
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
I thought you wanted to keep `_get_raw_host`
since there's no validation here and `get_port()` is relying on this code I would think you'd need to consider other malformed cases, such as `example.com:abc` or `1.1.1.1:443]`
to match the behavior of `_get_raw_host()` I think this reconstruction should only occur in the `SERVER_NAME` scenario.
since this is now a reconstructed host header, it will be different from the provided host header e.g. in the case the host header has a default port included: `Host: example.com:443` this will now be `example.com`
```suggestion port = port or '' ```
Use `assertEqual()`, e.g. ```python self.assertEqual( conf_url(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), re_path(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), ) ```
True, thanks :+1:
Why `stacklevel=2`? :thinking: IMO we can remove it.
`django.conf.urls.url` -> `django.conf.urls.url()` `django.urls.re_path` -> `django.urls.re_path()`
I added `stacklevel=2` back in #12960. IMO, it assists the library user with identifying the line they should modify. Without the argument, the warning points to Django code, but with the argument, the warning points to the user's code that must change. There is more detail in the PR too.
TBH, I don't think we need this test. I will chop it.
Also `favour` → `favor`.
Error message doesn't contain information about specific constraint so we can merge this to a single message.
Ah... That's irritating. I still think it would be better to improve the error message, but it looks like it'll require slightly deeper changes.
I think we can do better here: ```suggestion "CheckConstraint '{}'".format(constraint.name) ``` This would make the message look like: ``` "CheckConstraint 'constraint_name' refers to the nonexistent field 'missing_field'." ``` The same applies for `UniqueConstraint`.
`no_faulthandler=False` -> `enable_faulthandler=True`
`file` supports file descriptors so we can use the same workaround like `pytest`: ```python try: faulthandler.enable(file=sys.stderr.fileno()) except (AttributeError, io.UnsupportedOperation): faulthandler.enable(file=sys.__stderr__.fileno()) ```
I think we should check if it's not already enabled: ```python if not faulthandler.is_enabled() and enable_faulthandler: ```
undo unrelated change here (revert the comma)
1. It's best practice to name mocks after the function 2. You don't need `_ =`. Python discards unused return values by default. ```suggestion @patch('faulthandler.enable') def test_faulthandler_enabled(self, mocked_enable): DiscoverRunner(no_faulthandler=False) mocked_enable.assert_called() @patch('faulthandler.enable') def test_faulthandler_disabled(self, mocked_enable): DiscoverRunner(no_faulthandler=True) mocked_enable.assert_not_called() ```
Undo unrelated change.
@adamchainz Sorry for the late reply, didn't catch this in my emails. Definitely noting this and adding it to my forum post. I'm taking my time going through my original PR and trying to flesh out the PR more and noting the current blockers. Thanks for the catch.
Good point :)
Ah right. You noted on the ticket that's not the case with the 'spawn' mode, but I guess we shouldn't concern ourselves with that right now, as the test runner doesn't support that. @Valze - maybe make a note for your spawn-mode GSoC project? 😉
I would suggest changing the code so you're able to use the simpler `faulthandler=True` as the argument name. This will also simplify the code below that reads `if not no_faulthandler`. (You can still keep `--no-faulthandler` as the exposed option though.)
This test doesn't work properly because we check if `'' in 'The STATICFILES_DIRS...'` which is always true.
This will require a migration, run `makemigrations` for the app.
Oh, yes. We're not using pytest either. 👍
I changed to `isinstance(value, str)` because it worked properly for an empty string or strings without a scheme.
I think we should be more explicit here, maybe: ```python if not value or '://' not in str(value): raise ValidationError(self.message, code=self.code) ... ```
Chop blank line.
I think we should add also `lzma` format.
Note that you can use `match_obj[i]` instead of `match_obj.group(i)`. See ticket-30116, #12892.
I also think that you could shorten these variable names. That would avoid the wrapping below and the backslash line continuation.
Single quotes please.
Please revert this unrelated change.
With the change above this becomes: ```python match_obj = formset_query_regex.match(k) ```
Extract this logic to a helper function that can be tested independently.
Run isort on this file.
Compile the regular expression here as it'll be used multiple times below. Prefer `[0-9]` to `\d`. Expression should be anchored to avoid risk of partial matches. (Granted, you are using `re.match()` below, but it is always safer to be explicit.) ```python formset_query_regex = re.compile(r'^inlinemode_set-([0-9]+)-([0-9]+)-(.*)$') ```
I'd rename `subminor` to `patch`.
We should also change `\d+` to `[0-9]+` in all cases.
You're right. You know I both saw that and missed it too...
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
@sir-sigurd Is there any reason to change a regex? :thinking: You added `:`.
```suggestion return tuple(map(int, m.groups())) ```
`E411` -> `W411`
I was thinking about leaving it as a warning and disabling the sidebar when `request` is not provided, so about a soft requirement: - raise a warning (that will remain a warning in the future) if `enable_nav_sidebar`, e.g. ```python checks.Warning( "'django.template.context_processors.request' must be enabled " "in DjangoTemplates (TEMPLATES) in order to use the navigation " "sidebar in the admin application." id='admin.W411', ) ``` - disable a navigation sidebar (even in a template) when `request` is not provided.
I think we should add this check only if `enable_nav_sidebar` is enabled on any site and raise an error instead of warning :thinking:
OK. I'll adjust this now on that basis, so we can get it in this morning. Thanks both!
My thought overnight was just to have a warning and leave it at that. The sidebar still works without the request: we're just missing the CSS highlight for the current model, and an aria-role. 98% of projects have request context in play already. A warning is enough for the 2%. Discuss.
This could work: it's only the `current-app`, `current-model`, `current-page` attribute values that are dependent on `request`, and for the index page app list they're always not set anyway, so it's only when the side bar is set that `request` is serving any purpose.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
We should update `self.requires_system_checks` if it's a boolean, e.g. ```python self.requires_system_checks = '__all__' if self.requires_system_checks else [] ``` we can also add a module level constant: ``` ALL_CHECKS = '__all__' ```
We should validate `self.requires_system_checks`, currently we run all checks also for any truthy value e.g. `requires_system_checks = 'x'`, maybe ```python if not isinstance(value, (list, tuple)) and value != '__all__': raise TypeError(...) ```
We should move this check to `__init__()`.
This sentence ``` "To validate an individual application's models rather than all applications' models, call ``self.check(app_configs)`` from ``handle()``, where ``app_configs`` is the list of application's configuration provided by the app registry." ``` is still valid. I will restore it.
We wrap `response_for_exception` in an async context elsewhere: https://github.com/django/django/blob/f47d5aac622c334ebeba06b7460204aeb98661e2/django/core/handlers/exception.py#L34-L51
```suggestion self.assertFalse(Question.objects.exists()) ```
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
`GET` works without this patch. Extra tests are fine but should be moved to a separate commit.
As far as I'm concerned this should impact only `307` and `308` redirects, so maybe: ```diff diff --git a/django/test/client.py b/django/test/client.py index b26504f762..e4201bead4 100644 --- a/django/test/client.py +++ b/django/test/client.py @@ -827,7 +827,10 @@ class Client(ClientMixin, RequestFactory): if response.status_code in (HTTPStatus.TEMPORARY_REDIRECT, HTTPStatus.PERMANENT_REDIRECT): # Preserve request method post-redirect for 307/308 responses. - request_method = getattr(self, response.request['REQUEST_METHOD'].lower()) + request_method = response.request['REQUEST_METHOD'].lower() + if request_method != 'get': + extra['QUERY_STRING'] = url.query + request_method = getattr(self, request_method) else: request_method = self.get data = QueryDict(url.query) ```
@lothemar I realized that previous assertions were correct. The current tests work even without this patch. I will restore them, sorry.
So question, can the autoreloader take care of these registrations itself? (Haven't looked into it but...)
I think I got confused myself here. Will review.
On consideration, I'd take the first bit of that... ``` # Import the .autoreload module to trigger the registrations of signals. ``` (I'm reviewing now. I'll do it.)
Is this a separate change? (I've left it for now but... 🤔)
This doesn't look to be used? (vs `django.utils.autoreload.is_django_path)
So definitely part of this change. No problem. (Didn't know if it should be there anyway...) (Not a biggie)
I guess you could use a `pickle` or `deepcopy` roundtrip of `Subquery` as well.
One thing that worries me here is that it'll discard any `kwargs` so if `output_field` is provided, since we allow it to be passed as a positional argument it will be lost. e.g. `Subquery(queryset, models.BooleanField())`.
Will that work if `queryset` is specified as a kwarg? e.g. `Subquery(queryset=queryset)`.
We may consider such a change as a data loss. Even if `USE_TZ` is False, I think that a datetime input *with* timezone information should keep the timezone (and hence be aware). I think the docs might need to be updated to say that parsing a datetime with timezone gives an aware datetime even if USE_TZ is False.
Maybe I'm missing sth, but can we use `@contextmanager`? ```python class TestCase(TransactionTestCase): ... @contextmanager def captureOnCommitCallbacks(self, *, using=DEFAULT_DB_ALIAS, execute=False): self.callbacks = [] start_count = len(connections[using].run_on_commit) try: yield self.callbacks finally: run_on_commit = connections[using].run_on_commit[start_count:] self.callbacks[:] = [func for sids, func in run_on_commit] if execute: for callback in self.callbacks: callback() ```
The assignment to `self.choices` has no effect. Not being a subclass of `ChoiceField`, it's not used in validation. (Nothing fails removing it.)
This is already covered in `expressions` tests https://github.com/django/django/blob/9624703a06187060c1a494e533f3e27fed946de3/tests/expressions/tests.py#L749-L760
`assertEquals` is deprecated in Python 3. Also not sure if this test belongs in `expressions.tests`. ```suggestion self.assertEqual(instance.annotation, "1") ```
You could pass a literal boolean using `Value(True, output_field=models.BooleanField())`.
Please revert this unrelated change.
I thought about it, but it has some value to test this explicitly.
`IF NOT EXISTS` is not necessary anymore, I'll remove it.
_"Use single quotes for strings, or a double quote if the string contains a single quote. Don’t waste time doing unrelated refactoring of existing code to conform to this style."_
It's not an overkill. Mixing different kind of changes makes a project like Django extremely difficult to maintain. I added new PR #12972 .
```python with schema_editor.connection.cursor() as cursor: cursor.execute(... ```
I understand why you bumped indexes in below assertions, but changing `'uuid-ossp'` is not related with this PR and should be moved to a separate commit/PR.
We don't need columns, so I would use `SELECT 1 FROM ...`
Please chop all unnecessary blank lines.
Use single quotes.
Exactly, it's not **related**. That's why we should fix it separately in advance.
I'm not even sure we really need the extension to be created in this test, checking the SQL command correctness might be sufficient.
These check should respect `required_db_features`, so we need to omit checking conditions for `UniqueConstraint`\`s if `connection.features.supports_partial_indexes or 'supports_partial_indexes' in cls._meta.required_db_features`.
Do we need to change this? I would only add `set(chain.from_iterable(...`
Please fix indentation in these lines (see flake failures).
We don't need `skipIf` anymore, please amend assertion instead: ```python [Error(...)] if connection.features.supports_partial_indexes else [] ```
I think we can change this method to a generator: ```python @classmethod def _get_expr_references(cls, expr): if isinstance(expr, Q): for child in expr.children: if isinstance(child, tuple): lookup, value = child yield tuple(lookup.split(LOOKUP_SEP)) yield from cls._get_expr_references(value) else: yield from cls._get_expr_references(child) elif isinstance(expr, F): yield tuple(expr.name.split(LOOKUP_SEP)) elif hasattr(expr, 'get_source_expressions'): for src_expr in expr.get_source_expressions(): yield from cls._get_expr_references(src_expr) ```
This duplicates logic from `_check_local_fields()` and added unnecessary error `models.E042` which is already covered by `models.E012` in `_check_local_fields()`. I think we should pass fields from `references` to the `_check_local_fields()` and remove redundant logic, e.g. ```python for field_name, *lookups in references: fields.add(field_name) if not lookups: # If it has no lookups it cannot result in a JOIN. continue try: field = cls._meta.get_field(field_name) if not field.is_relation or field.many_to_many or field.one_to_many: continue except FieldDoesNotExist: continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None: errors.append( checks.Error( "'constraints' refers to '%s' which results a JOIN attempt, " "JOIN is not permitted in 'constraints'." % LOOKUP_SEP.join([field_name] + lookups), obj=cls, id='models.E042', ) ) errors.extend(cls._check_local_fields(fields, 'constraints')) ```
Looks like we just need to use `_meta._get_fields(reverse=False)`.
What if the rhs (`child[1]`) is not an F object, but another expression like`Lower('parent__name')`? Should we handle this as well? Another thing is we don't check the left side of expression when the condition is like ` check=models.Q(parrent__age__lt=models.F('age'))`.
What about m2m and reverse relationships? Something like `Q(cities=3)` will also produce the join.
Double-checked, `meta.get_field()` does actually work for m2m and reverse fields. Probably we need tests to verify `Q(m2m_field=3)` and `Q(reverse_field=2)`. As I understand, the code above won't emit the warning for the m2m or reverse ForeignKey field. ``` User._meta.get_field('cities') <django.db.models.fields.related.ManyToManyField: cities> User._meta.get_field('profiles') <ManyToOneRel: profile> ```
But it will still include m2m relations. I suggest something like this: ``` for field_name, *lookups in references: try: field = cls._meta.get_field(field_name) except FieldError: # handle missing field if not field.is_relation: # Only related fields can result in joins. continue if field.many_to_many or field.one_to_many: # Handle m2m / reverse ForeignKey if not lookups: # If it has no lookups it cannot result in a JOIN. continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None # This would result in a JOIN attempt, emit a warning ```
If it's an expression its source expression tree should be walked (recursive `get_source_expressions`) and when the expression `isinstance(expr, str)` then you'd need to use split it using `LOOKUP_SEP`. The first part should be used to retrieve the field (`_meta.get_field(parts[0])`). If it's a related field (`field.remote_field is not None`) then you are trying to `JOIN` and it's disallowed.
Something like ```python elif hasattr(child[1], 'get_source_expressions'): for expr in child[1].get_source_expressions(): if isinstance(expr, str): fields.add(expr.split(LOOKUP_SEP)[0]) else: fields.update(self._get_check_or_condition_fields(expr) ```
Might want to make `fields` a set to avoid having `_check_local_fields` run multiple time for the same field.
Ditto about using a set.
I think the function can be simplified to ```python @classmethod def _get_expr_fields(cls, expr): fields = set() if isinstance(expr, Q): for child in expr.children: if isinstance(child, tuple): lookup, value = child fields.add(lookup.split(LOOKUP_SEP)[0]) fields.add(cls._get_expr_fields(value)) else: fields.update(cls._get_expr_fields(child[1])) elif isinstance(expr, F): fields.add(field.name) elif hasattr(expr, 'get_source_expressions'): for src_expr in expr.get_source_expression(): if isinstance(src_expr, str): fields.add(src_expr.split(LOOKUP_SEP)[0]) else: fields.update(cls._get_expr_fields(src_expr)) return fields ``` And you call it directly with `constraint.condition` and `constraint.check`. An alternative would be to create a `sql.Query` object and try to add the where object while disallowing joins https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/constraints.py#L101-L102 https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1361-L1362 This will raise a `FieldError` if there's an attempt at joining https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1660-L1684 But the message won't include the name of the culprit which be a blocker here if we want to provide adequate hints.
@hramezani > The _get_expr_fields function will find fields={'age', 'parent'} and when we call: cls._check_local_fields(fields, 'constraints') This won't return any error because age and parent are model fields. As @alextatarinov said you can't rely on `_check_local_fields` to determine whether or not a join would occur. You need to use a solution relying on `.remote_field is None` and `get_lookup`/`get_transform`. That should do ```python @classmethod def _get_expr_references(cls, expr): references = set() if isinstance(expr, Q): for child in expr.children: if isinstance(child, tuple): lookup, value = child references.add(tuple(lookup.split(LOOKUP_SEP))) references.update(cls._get_expr_fields(value)) else: references.update(cls._get_expr_fields(child[1])) elif isinstance(expr, F): references.add(tuple(field.name.split(LOOKUP_SEP))) elif hasattr(expr, 'get_source_expressions'): for src_expr in expr.get_source_expression(): if isinstance(src_expr, str): references.add(tuple(src_expr.split(LOOKUP_SEP))) else: references.update(cls._get_expr_fields(src_expr)) return references references = self._get_expr_references(constraint.condition).union(constraint.check) for field_name, *lookups in references: if not lookups: # If it has no lookups it cannot result in a JOIN. continue try: field = cls._meta.get_field(field_name) except FieldError: # handle missing field if not field.remote_field: # Only related fields can result in joins. continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None # This would result in a JOIN attempt, emit a warning ``` This should thing such as `parent=2` (which doesn't involve JOINs because the local `parent_id` field would be used) but disallow things like `Q(parent__name='foo')` or `Q(local=Lower('parent__name'))`.
@charettes Thanks for the clarification. Wasn't sure about `_meta.get_field()` behavior.
Ticket describes an issue when `USE_L10N` is off, so I think we should check both combination: ```python with self.settings(USE_L10N=True, DECIMAL_SEPARATOR=','): ... with self.settings(USE_L10N=False, DECIMAL_SEPARATOR=','): ... ``` Please move tests for a thousand separator to a separate commit because they work without this patch.
``` # A string representation is returned for unlocalized numbers. ```
I will split them. At first glance I made a false assumption that all five affect `{% localize off %}` tag.
Historic moment! I don't see a reason why we shouldn't use them.
I'd've used `assertNotIn('SELECT', sql)`
Ahh looks like you'll need to keep passing `Value` in this case but you can drop the `output_field`. ```suggestion is_book=Value(1) ```
```suggestion "Cannot aggregate over the 'other_age' alias. Use annotate() to promote it" ```
Should we also have a pointer here of the form ```suggestion with self.assertRaisesMessage(FieldError, "Cannot distinct on 'other_rating' alias. Use annotate to promote it"): ```
What about ```suggestion self.assertNotIn('is_book', books.values().first()) ```
```suggestion raise FieldError(f"Cannot aggregate over the '{name}' alias. Use annotate() to promote it") ```
No need for `Value` wrapping since 1e38f1191de21b6e96736f58df57dfb851a28c1f ```suggestion is_book=1, ``` Ditto for all `Values` uses below.
Ditto I'd avoid asserting against the string representation of the query, and assert against the returned `.values()`.
Either use `subTest` or collect all the attributes and use `assertCountEqual`.
I improved messages for `values()` and `values_list()`. `distinct()` is more complicated because the exception is raised by `names_to_path()` that is used in many places, IMO we can leave the current message.
We can keep it in the same file.
```suggestion authors, [25, 34, 35, 37, 45, 46, 57, 29], lambda a: a['age'] ```
This is also unrelated, please revert it.
Please revert the unrelated change to an existing test.
```suggestion msg = ( "Cannot aggregate over the 'other_age' alias. Use annotate() to " "promote it." ) with self.assertRaisesMessage(FieldError, msg): ``` Use the same pattern in other `assertRaisesMessage`.
I think we should move all new tests to a separate class, e.g. `AliasTests`.
I don't think that we want to split a string using shell-like syntax. We should rather use `smart_split()` and `unescape_string_literal()` like proposed in the ticket, e.g. ```python for bit in smart_split(search_term): bit = unescape_string_literal(bit) if bit.startswith(('"', "'")) else bit ... ``` ```
`strip()` removes also other whitespace, e.g. `\t`. I think we should move `strip()` to the next line, i.e. ```python value = re.sub(r'[^\w\s-]', '', value.lower()) return re.sub(r'[-\s]+', '-', value).strip('-_') ```
We remove them in `re.sub(r'[^\w\s-]', '', value.lower())`.
I was just about to suggest this too :+1:
For the keys, I was thinking we should use the full field name (e.g. 'BigAutoField') rather than some other value like 'big_auto'. I think it would be less mental effort for the developer to have to convert camel case to underscore and remove "field". Let's alphabetize the keys too.
I don't like this suggestion. What do you see as the advantage? Here's why I'm concerned: - It's more verbose - typos in the key name are silently ignored - by implementing a mapping in the base features, it shows which fields are implemented in Django's tests (I don't think we should try to implement all fields proactively but accept PRs if a third party backends needs it)
I believe you can simplify all this stuff to lines like: ``` assertFieldType('pos_big_int_field', 'models.%s() % connection.features.introspected_field_types['PositiveBigIntegerField']) ``` I don't think the if statements are needed anymore (similar elsewhere in this file).
IPAddressField is removed from Django so shouldn't be listed.
I should have suggested introspected_field_types (plural, to match similar attributes in DatabaseOperations) rather than singular.
Yes, assuming it can be used in the test.
I would leave it empty (`introspected_field_types = {}`) by default and use `.get()` in tests, e.g. ```python connection.features.introspected_field_types.get('BooleanField') or 'BooleanField'` ```
I think all the defaults here should be mappings to the same type (e.g. `'PositiveIntegerField': 'PositiveIntegerField'`), so that backends have to specify the types they introspect differently.
```suggestion # Map fields which some backends may not be able to differentiate to the # field it's introspected as. ```
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
Chop unnecessary commas.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
OK, so maybe we can at remove `active()/deactivate()` round-trip with: ```diff diff --git a/tests/i18n/tests.py b/tests/i18n/tests.py index ccf4c242cf..c7be1f2634 100644 --- a/tests/i18n/tests.py +++ b/tests/i18n/tests.py @@ -390,12 +390,10 @@ class TranslationLoadingTests(SimpleTestCase): """Clear translation state.""" self._old_language = get_language() self._old_translations = trans_real._translations - deactivate() trans_real._translations = {} def tearDown(self): trans_real._translations = self._old_translations - activate(self._old_language) @override_settings( USE_I18N=True, @@ -423,8 +421,7 @@ class TranslationLoadingTests(SimpleTestCase): # All translations are loaded by the second pass. for rnd in range(1, 3): for language, nickname in tests: - with self.subTest(language=language, round=rnd): - activate(language) + with self.subTest(language=language, round=rnd), translation.override(language): self.assertEqual(gettext('local country person'), nickname) ``` It works the same for me.
We should test with a different expression since this might be fixed in the future ```suggestion expr = ExpressionWrapper(Lower('field'), output_field=IntegerField()) self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression]) ```
For `tuple` or `list` it will raise `ValueError`.
I would call `clean()` in validation tests, we should also move it to a separate tests, e.g. ```python def test_invalid_value(self): field = models.DecimalField(max_digits=4, decimal_places=2) msg = '“%s” value must be a decimal number.' tests = [ (), [], {}, set(), object(), complex(), 'non-numeric string', b'non-numeric byte-string', ] for value in tests: with self.subTest(value): with self.assertRaisesMessage(ValidationError, msg % (value,)): field.clean(value, None) ```
Please update your patch.
Please add also GDAL 3.1 library, and both libraries to the posix section.
IMO we don't need a list of all operations in this message, it's too detailed. If someone would like to check the list of operations they can always use `makemigrations --dry-run`. Adding a list of apps should be enough, e.g. ```diff diff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py index 81696f11c1..32b1462319 100644 --- a/django/core/management/commands/migrate.py +++ b/django/core/management/commands/migrate.py @@ -227,8 +227,9 @@ class Command(BaseCommand): changes = autodetector.changes(graph=executor.loader.graph) if changes: self.stdout.write(self.style.NOTICE( - " Your models have changes that are not yet reflected " - "in a migration, and so won't be applied." + " Your models in apps [%s] have changes that are not " + "yet reflected in a migration, and so won't be " + "applied." % ', '.join(changes) )) self.stdout.write(self.style.NOTICE( " Run 'manage.py makemigrations' to make new " ```
We should be able to assert `stdout`. You can find similar tests in `tests/migrations/test_commands.py`.
This is missing other likely candidates: `y` and `yes` I'd also argue it should be simplified to be case-insensitive so that `TRUE` == `true` (which requires you actually assert the incoming `val` is actuall stringy enough to have `.lower()`, rather than simply doing an equality match against any of the values)
This is an identity check: ```suggestion if default is NoDefaultValue: ```
This should probably clean up the environment after the test.
I typically use something like the following: ```python return str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'} ``` This works whether you pass a boolean, integer or string, although we are only expecting a string from the environment anyway. If we wanted to be strict, we should reject invalid values: ```python if str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'}: return True if str(val).lower() in {'0', 'f', 'n', 'off', 'false', 'no'}: return False raise ValueError('Non-boolean string provided.') ```
Use `assertIs` to check booleans: More details at: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/
Could be cheaper to `rhs.discard(None)` instead of performing a `is not` check against all elements. I have not tested it out though, only a theory. ```suggestion rhs = OrderedSet(self.rhs) rhs.discard(None) ```
We can add assertion for number of queries `self.assertNumQueries(0)` because that's the real impact of this optimization.
This is a separate issue, can we move it to a separate PR/commit? Also, test is required.
Yes I think we need a separate ticket. I'm not sure if there is a valid use for custom handlers that return files with empty filenames :thinking: I removed the 2nd commit.
If `getattr()` is not necessary, do we need this round trip at all? ```python if val is None: ... val = data[field_name] data[field_name] = val ``` It looks that we can remove [this line](https://github.com/django/django/pull/13036/files#diff-1e7fc0d7d1b36358e371fab97bd1ddb1R152) :thinking: , e.g. ```python if val is None: instance.refresh_from_db(fields=[field_name]) else: data[field_name] = val ```
Hmm, I think if it's not an instance of the model I'd expect it to raise an exception, not just ignore it, but I'm not sure.
I _think_ there's the potential for a slight discrepancy here - if the `_result_cache` is not None (it's an evaluated queryset) and you fall back to doing `__contains__` on the underlying list, you'd be comparing using `Model.__eq__` right? Ignoring the possibility that the user has overridden the method (and thus there's unavoidably nothing you can do), that method also checks the `concrete_model` meta attribute, for reasons I expect are nuanced but important (my guess: proxy models)
This a O(n) scan in `self._result_cache`, not sure this is desirable.
Revert this unrelated change.
I think we should return `False` instead or raising and exception, we're not going to implement any tricky workarounds for a different objects.
This docstring doesn't have much value, please remove it.
yes I think the `values.contains` point should be discussed on the mailing list if we don't want to explicitly error out in this case. I would personally expect `values.contains` to only accept `dict` instances and `values_list.contains` to only accept `tuple` instances.
If you want to raise an exception than `NotImplementedError` is not the right choice, IMO. I would use `ValueError`.
Use `assertRaisesMessage()`, e.g. ```suggestion msg = ... with self.assertRaisesMessage(TypeError, msg): ```
```suggestion raise TypeError( 'Cannot call QuerySet.contains() after .values() or .values_list().' ) ```
I would prefer checking `_fields` ```suggestion if self._fields is not None: ```
```python """Return True if the queryset contains an object.""" ```
```suggestion "'obj' must be a model instance." ```
Erroring out immediately `if not issubclass(self._iterable_class, ModelIterable)` is likely the easiest way to go here. Just wanted to point out that we need to handle this case one way or another.
Another thing about `self._result_cache` which is problematic is the chaining of `values` (and `values_list`, ..) which will store non-model instances in there. That will result in this strange behavior ```python entry = Entry.objects.get(pk=123) values_queryset = Entry.objects.values('id') values_queryset.contains(entry) # True list(values_queryset) values_queryset.contains(entry) # False ``` I would expect `.contains` to immediately error out `if not issubclass(self._iterable_class, ModelIterable)` or to support `values` and friends in a consistent way. e.g. ```python entry = Entry.objects.get(pk=123) values_queryset = Entry.objects.filter(pk=123).values('id') values_queryset.contains(entry) # Crash values_queryset.contains({'id': 123}) # True values_queryset.contains({'id': 456}) # False list(values_queryset) values_queryset.contains({'id': 123}) # True values_queryset.contains({'id': 456}) # False ``` If we want to go this way the best approach is likely to defer the validation of `obj` and the lookup creation to a new `BaseIterable.contains_lookup(obj)` class method so the implementation can be along the lines of ```python class BaseIterable: ... @classmethod def contains_lookup(cls, queryset, obj): raise NotImplementedError class ModelIterable(BaseIterable): ... @classmethod def contains_lookup(cls, queryset, obj): try: if obj._meta.concrete_model != queryset.model._meta.concrete_model: return False except AttributeError: raise ValueError( 'QuerySet.contains only supports Model objects. You passed in a {}.'.format(type(obj)) ) return {'pk': obj.pk} class ValuesIterable(BaseIterable): ... @classmethod def contains_lookup(cls, queryset, obj): if not isinstance(obj, dict): raise ValueError(...) names = { *query.extra_select, *query.values_select, *query.annotation_select, } if not set(obj) == names: raise ValueError(...) return obj class QuerySet: ... def contains(self, obj): lookup = self._iterable_class.contains_lookup(self, obj) if self._result_cache is None: return self.filter(**lookup).exists() return obj in self._result_cache ```
True, it's unnecessary since 58ad030d05fa50cfed327368ab61defca3303e02. It's not a copy&paste code in was done on purpose in the original patch, see a68ea231012.
It's done on purpose. We modify `attrs` in this loop so `list()` is used to create a copy.
I added `exc_value` to the message as suggested by Chris.
I'm not sure what's _obvious_ about this change. You turned three `O(1)` constant lookups (`dict`, `dict`, `set`) into a new object materialization (`chain`) that involves iterating over all objects followed by a `O(n)` lookup where `n = len(field_names) + len(new_class.__dict__) + len(inherited_attributes)`.
This code is less optimal in case where `name` is equal to `attname`.
Doesn't this mean, the tests are skipped all the time on mysql, not only when the `ONLY_FULL_GROUP_BY` is used? How about something like this: ```suggestion connection.vendor == 'mysql' and 'ONLY_FULL_GROUP_BY' in getattr(connection, "sql_mode", set()), ``` or whatever type `sql_mode` usually has.
I don't think you can depend on a None choice being defined for a nullable field, necessarily. I don't think you need to make a change here.
this hanging indent is intentional, you'll see it throughout Django
you have essentially built a list comprehension, see below
how about: `*[x for x in self.field.flatchoices if x[0] is not None]):`
We should avoid altering provided expressions ```suggestion if getattr(expression, '_output_field_or_none', True) is None: expression = expression.copy() expression.output_field = output_field self.expression = expression ```
~~Also use `%r` and not `repr()`.~~
Add trailing comma.
I think we should add extra checks, - raise `ValueError` if `self.include and index_type == 'spgist'`, e.g. _"Covering exclusion constraints only support GiST indexes."_, - raise `NotSupportedError` if `self.include and not schema_editor.connection.features.supports_covering_gist_indexes`, e.g. _"'Covering exclusion constraints requires PostgreSQL 12+.'"_.
You can use `schema_editor._index_include_sql()`, e.g. ```suggestion 'include': schema_editor._index_include_sql(model, include), ```
You can add a similar constraint but without `deferrable` and compare it with `constraint_2`.
Add trailing comma.
`include` is a tuple, that's why we need `repr()`.
You can remove also lines [161-163](https://github.com/django/django/pull/13052/files#diff-77d4793905e702bfe9a8fabac708dcc7L161-L163).
I strongly believe that using two booleans instead of these constants would be more readable. This should also reduce the number of changes in the existing API.
You should use `supports_update_conflicts_with_unique_fields`.
Revert unrelated blank lines.
You should use `supports_update_conflicts_with_unique_fields`.
Why `IntegrityError`? This should raise a `ValueError`: ``` raise ValueError('ignore_conflicts and update_conflicts are mutually exclusive.') ```
Please don't use double underscores in test method names.
```suggestion def _select_on_conflict(self, ignore_conflicts, update_conflicts, update_fields, unique_fields): ```
```suggestion def insert_statement(self, on_conflict=None): if on_conflict == OnConflict.IGNORE: return 'INSERT OR IGNORE INTO' if on_conflict == OnConflict.UPDATE and Database.sqlite_version_info < (3, 24, 0): return 'INSERT OR REPLACE INTO' return super().insert_statement(on_conflict) ``` Please also update to use a feature flag as mentioned in https://github.com/django/django/pull/13065#discussion_r668440287.
```suggestion def on_conflict_suffix_sql(self, opts, fields, on_conflict=None, update_fields=None, unique_fields=None): if on_conflict == OnConflict.IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflict == OnConflict.UPDATE: return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ', '.join(unique_fields or ()), ', '.join(f'{field}=excluded.{field}' for field in update_fields or ()), ) return super().on_conflict_suffix_sql(opts, fields, on_conflict, update_fields, unique_fields) ``` If we have `unique_fields` in the signature here, then it should also be in the signature of the super class, not falling back to `**kwargs`. As mentioned in https://github.com/django/django/pull/13065#discussion_r668635778 we should probably be quoting identifiers here properly too.
This looks rather complex and could be simplified: ```suggestion def on_conflict_suffix_sql(self, opts, fields, on_conflict=None, update_fields=None, unique_fields=None): if on_conflict == OnConflict.UPDATE: result = ', '.join(f'{field}=VALUES({field})' for field in update_fields or ()) return 'ON DUPLICATE KEY UPDATE ' + result return super().on_conflict_suffix_sql(opts, fields, on_conflict, update_fields, unique_fields) ``` We should probably also be quoting the field names properly (which I haven't done in the above).
Using the enum as suggested: ```suggestion def insert_statement(self, on_conflict=None): if on_conflict == OnConflict.IGNORE: return 'INSERT IGNORE INTO' return super().insert_statement(on_conflict) ```
Let's make this method name resemble the SQL that will be generated. Also, `update_fields` shouldn't have a mutable default. And `unique_fields` should be here too, not masked in `**kwargs`? ```suggestion def on_conflict_suffix_sql(self, opts, fields, on_conflict=None, update_fields=None, unique_fields=None): ```
```suggestion def insert_statement(self, on_conflict=None): ``` Also ensure that this change of signature, from `ignore_conflicts=False` → `on_conflict=None`, is mentioned in backward incompatible changes to database backends in the release notes.
When considering my above point please now target 4.1.
Was already highlighted [here](https://github.com/django/django/pull/13065#discussion_r684521409) but was missed.
Was already highlighted [here](https://github.com/django/django/pull/13065#discussion_r684521409) but was missed.
I think that we should also change `on_conflicts` → `on_conflict`. ```suggestion def __init__(self, *args, on_conflict=None, update_fields=[], unique_fields=[], **kwargs): ``` It makes sense to have `ignore_conflicts=True` and `update_conflicts=True`, but when combining into a single parameter we should make it singular. When using the enum as suggested this becomes `on_conflict=OnConflict.IGNORE`.
Getting rid of the unnecessary constant for the `None` case, `ON_CONFLICTS_NONE`, will simplify the diff and make review easier: ```suggestion if connection.features.can_return_rows_from_bulk_insert and not on_conflict: ```
This will crash for `pk` which should be allowed.
```suggestion if ( ```
Please make `update_fields` and `unique_fields` have `None` instead of using mutable defaults and do the following inside the function: ```python update_fields = update_fields or [] unique_fields = unique_fields or []
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
```suggestion result = ', '.join(f'{field} = VALUES({field})' for field in map(self.quote_name, update_fields or ())) ```
Spaces around `=` and PostgreSQL docs have `EXCLUDED`. ```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
Avoid using `IntegrityError` here. It is a `ValueError` to not provide `update_fields` with `update_conflicts`. ```suggestion if ignore_conflicts and update_conflicts: raise ValueError('The ignore_conflicts and update_conflicts flags are mutually exclusive.') if ignore_conflicts: self._check_on_conflicts_supported(OnConflict.IGNORE, unique_fields) return OnConflict.IGNORE if update_conflicts: self._check_on_conflicts_supported(OnConflict.UPDATE, unique_fields) if not update_fields: raise ValueError('The update_conflicts flag requires update_fields to be specified.') for name in update_fields: if name == 'pk': name = self.model._meta.pk.name try: self.model._meta.get_field(name) except exceptions.FieldDoesNotExist: raise ValueError(f'The update_fields list contains an unknown field: {name}.') return OnConflict.UPDATE return None ```
Please add a trailing comma: ```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
Please add a trailing comma: ```suggestion update_conflicts=False, update_fields=None, unique_fields=None, ```
```suggestion def __init__(self, *args, on_conflict=None, update_fields=None, unique_fields=None, **kwargs): ```
```suggestion insert_statement = self.connection.ops.insert_statement(on_conflict=self.query.on_conflict) ```
Please revert this unrelated whitespace change.
Please revert this unrelated whitespace change.
```suggestion def _insert( self, objs, fields, returning_fields=None, raw=False, using=None, on_conflict=None, update_fields=None, unique_fields=None, ): ```
Please uppercase the enum member names: ```suggestion IGNORE = 'ignore' UPDATE = 'update' ```
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
Use `self.quote_name()` to do the quoting of fields: ```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ', '.join(map(self.quote_name, unique_fields or ())), ', '.join(f'{field}=excluded.{field}' for field in map(self.quote_name, update_fields or ())), ) ```
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
Please move these above `test_collations` above and flip the order: ```suggestion supports_update_conflicts = True supports_update_conflicts_with_target = True ```
Use `self.quote_name()` to do the quoting of fields: ```suggestion result = ', '.join(f'{field}=VALUES({field})' for field in map(self.quote_name, update_fields or ())) ```
Both `update_fields` and `unique_fields` should be passed through. You can keep them as positional arguments: ```suggestion return super().on_conflict_suffix_sql(opts, fields, on_conflict, update_fields, unique_fields) ```
Please move this above `test_collations()`.
This replacement of `ignore_conflicts_suffix_sql()` with `on_conflict_suffix_sql()` should be mentioned under the `Database backend API` sub-section of the `Backwards incompatible changes in 4.0` section in `docs/releases/4.0.txt`.
This signature change should be mentioned under the `Database backend API` sub-section of the `Backwards incompatible changes in 4.0` section in `docs/releases/4.0.txt`.
```suggestion on_conflict = self._select_on_conflict( ```
```suggestion on_conflict=on_conflict, ```
```suggestion on_conflict=on_conflict, ```
Using `self.connection.features`: ```suggestion elif ( on_conflict == OnConflict.Update and self.connection.features.supports_update_conflicts_with_target ): ```
These flags are mutually exclusive and we need to set both to `False` to specify that `ON CONFLICT` is not supported. This complicates the API unnecessarily. I would use: ``` supports_update_conflicts = False supports_update_conflicts_with_target = False ```
No brackets needed again.
```suggestion with self.assertRaises((OperationalError, ProgrammingError)): ```
```suggestion on_conflict = self._select_on_conflict( ignore_conflicts, update_conflicts, update_fields, unique_fields, ) ```
```suggestion supports_update_conflicts_with_target = supports_update_conflicts ```
It's not resolved.
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
```suggestion with self.assertRaises((OperationalError, ProgrammingError)): ```
I'm not sure why these tests raises a `ProgrammingError` :thinking:
I would use an early return (in both cases): ```suggestion return OnConflict.IGNORE ```
This hook is unnecessary, IMO. I would move the logic to `_select_on_conflict()`.
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
Chop blank line.
A list comprehension is preferable here as `str.join()` converts to list internally anyway. ```suggestion ', '.join([ f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields) ]), ```
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
```suggestion on_conflict=None, update_fields=None, unique_fields=None, ```
Chop blank line.
`update_fields` should always be passed, so there is no need to use `update_fields or ()`.
Please assert an error message ```suggestion msg = '...' with self.assertRaisesMessage(NotSupportedError, msg): ```
A list comprehension is preferable here as `str.join()` converts to list internally anyway. It is better performance to provide a list up front. - https://stackoverflow.com/questions/9060653/list-comprehension-without-in-python/9061024#9061024 - https://github.com/adamchainz/flake8-comprehensions/issues/156 ```suggestion result = ', '.join([ f'{field} = VALUES({field})' for field in map(self.quote_name, update_fields) ]) ```
```suggestion name = self.model._meta.pk.attname ```
You don't need to add the brackets with `join()`.
This method implementation could be simplified by doing: ```python if on_conflicts == ON_CONFLICTS_IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflicts == ON_CONFLICTS_UPDATE: ... return result ... ``` This would also let you eliminate the `if-else` below and initializing `result` to `''`.
You can do what I suggested above here as well.
And here. (Also no brackets no needed.)
You can move the line above to an `else` clause below.
This can simply be `if` when the prior `if` block always returns or raises. There are a few more instances of this below.
`update_fields` should always be passed, so there is no need to use `update_fields or ()`.
I feel like this will break when the field is a reserved keyword (also for all other backends). At the minimum we should also have tests that will show that reserved fields will work as expected (ie are quoted properly)
I'm not sure why we changed this message :thinking: Please revert: ```suggestion message = 'This database backend does not support ignoring conflicts.' ```
... and here https://github.com/django/django/pull/13065#discussion_r668443543 :wink:
```suggestion 'conflicts with specifying unique fields that can ' ```
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
`VALUES()` was renamed to `VALUE()` in [MariaDB 10.3.3](https://mariadb.com/kb/en/values-value/), it's also deprecated in [MySQL 8.0.20+](https://dev.mysql.com/doc/refman/8.0/en/insert-on-duplicate.html). In [MySQL 8.0.19+](https://dev.mysql.com/doc/relnotes/mysql/8.0/en/news-8-0-20.html) we should use aliases for the new row and its columns.
You should also collect class based unique-constraints, you get can them from `opts.total_unique_constraints`.
`field` variable is unnecessary: ```suggestion msg = "TwoFields has no field named 'nonexistent'" with self.assertRaisesMessage(FieldDoesNotExist, msg): TwoFields.objects.bulk_create(self.data, update_conflicts=True, update_fields=['nonexistent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ```suggestion msg = ( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ```
```suggestion item, fields=fields, using=self.db, ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
`_select_on_conflict` name is misleading because this method mainly checks options. Maybe `_check_bulk_create_options(...)` :thinking:
```suggestion raise NotSupportedError( 'This database backend does not support updating ' 'conflicts with specifying unique fields that will ' 'trigger the upsert.' ) ```
```suggestion raise NotSupportedError( 'This database backend does not support ignoring conflicts.' ) ```
Chop blank line.
Chop blank line.
```suggestion with self.assertRaises((OperationalError, ProgrammingError)): ```
Chop blank line.
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive.' ```
I should be more precise. `update_fields` are always passed when `on_conflict == OnConflict.UPDATE`. We current signature is fine with me.
```suggestion unique_fields=unique_fields, ```
```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
> But I wonder that do we need to allow user to set pk as an updated field? Yes, we do. `pk`s are not only auto-fields.
`get_field()` will raise an error for `pk`, see ticket-27944. You need to always treat it as a valid field and don't rely on `get_field()` when `f == 'pk'`.
Maybe `argon2_hash` -> `rest`
```suggestion variety, *_, salt, data = argon2_hash.split('$') ```
```suggestion '' if not self.opclasses else ", opclasses='%s'" % ', '.join(self.opclasses), ```
I added the comma to be consistent with the `include` and `condition` attributes. Also, on `ExclusionConstraint` we separate attributes by comma but not on `UniqueConstraint`, so 🤷 indeed..
`"Script {} does not exist.".format(py_script)` -> `'Script %s does not exist.' % py_script`
Can we reorganize this a bit? ```python exe_entrypoint = py_script.with_suffix('.exe') if exe_entrypoint.exists(): # Should be executed directly, ignoring sys.executable return [exe_entrypoint, *sys.argv[1:]] script_entrypoint = py_script.with_name('%s-script.py' % py_script.name) if script_entrypoint.exists(): # Should be executed as usual return [*args, script_entrypoint, *sys.argv[1:]] raise RuntimeError('Script %s does not exist.'% py_script) ```
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
`can not` -> `cannot`, or better `may not `
I went with `addCleanup()` — Thanks for mentioning that @orf.
Use hanging indentation: ```python raise TypeError( 'Transform only accepts SpatialReference, string, and integer ' 'objects.' ) ```
Chop blank line.
This cleanup is not related with a patch please move it to a separate commit/PR.
That looks like much duplication just to change the passed `srs` value. I think I would have written a common `_test_raster_transform(self, srs)`, then calling from `test_raster_transform_int`/`test_raster_transform_str`/`test_raster_transform_srs` methods. An alternative would be to call `with self.subTest(...)` just above the transform part. @felixxm might have an idea too.
Wrap docstring at 79 chars.
```python mo_path = po_path.with_suffix('.mo') ```
```python mo_file_en.with_suffix('.po').touch() ```
I will change to `try ... except` (see ticket-27818).
There is in theory a chance of hitting a TOCTTOU case here anyway, in which case it is better to handle the exception to avoid a crash.
Maybe: ```python "File '%s' is already compiled and up to date." % po_path ```
`IntegrityError` will be raised by a database, because `ORDER BY` clause is omitted in this case. We don't need to do this manually.
```suggestion pass ```
It should be `number=F('number') + 1`.
This should be `+1` because `+2` works even without including `ORDER BY` clauses.
`u1` and `u2` variables are unused, we can remove them ```python UniqueNumber.objects.create(number=1) UniqueNumber.objects.create(number=2) ```
I would move this docstring to the class: ```python class MySQLUpdateOrderByTest(TestCase): """Update field with a unique constraint using an ordered queryset.""" ```
You don't need to raise an `IntegrityError`, database will do this for us if necessary.
This test should catch `IntegrityError`, e.g. ```python def test_order_by_update_on_unique_constraint_annotation(self): # order_by() with annotate references are ignored. with self.assertRaises(IntegrityError): UniqueNumber.objects.annotate( number_inverse=F('number').desc(), ).order_by('number_inverse').update( number=F('number') + 2, ) ```
We can chop this docstring.
You could use `self.subTest()`, e.g. ```python def test_order_by_update_on_unique_constraint(self): tests = [ ('-number', 'id'), (F('number').desc(), 'id'), (F('number') * -1,), ] for ordering in tests: with self.subTest(ordering=ordering): updated_count = UniqueNumber.objects.order_by(*ordering).update( number=F('number') + 1, ) self.assertEqual(updated_count, 2) ```
The `.all()` is redundant ```suggestion updated_count = UniqueNumber.objects.order_by('-number', 'id').update(number=F('number') + 1) ```
Also I think that `is_ref` will need to be handled in a special way. The reference will need to be resolved to inline the expression. This can be tested by with the following code ```python updated_count = UniqueNumber.objects.annotate( number_inverse=F('number') * -1 ).order_by('number_inverse').update( number=F('number') + 2, ) self.assertEqual(updated_count, 2) ``` In this case `number_inverse` will yield `is_ref=True` and `expr` will be an instance of `Ref` if I'm not mistaken.
You want to avoid interpolating params yourself as that could result in SQL injections. ```suggestion if self.query.order_by: order_by_sql = [] order_by_params = [] for _, (sql, params, is_ref) in self.get_order_by(): order_by_sql.append(sql) order_by_params.extend(params) query += ' ORDER BY ' + ', '.join(order_by_sql) params += tuple(order_by_params) ```
```suggestion Update a queryset using order_by on a unique constraint. ```
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
We can chop this docstring.
Could this test be moved to `BaseCacheTests` under `test_empty_cull` to make sure the implementation works on all backends instead of only the database one? https://github.com/django/django/blob/0bebe5266f2e52a76fcf6d23b76942399d087bf2/tests/cache/tests.py#L601-L622
I'd just rename this test to avoid references to _table_ since it doesn't make sense for non-database backends. ```suggestion def test_cull_delete_when_store_empty(self): ```
Please use hanging indentation: ```python GenericFormFormset = formset_factory( form=GenericForm, can_delete=True, extra=2, ) ```
Do we need a new form? I would reuse `Choice` in both tests: ```python ChoiceFormFormset = formset_factory(Choice, can_delete=True, extra=2) ```
Let's keep it.
I renamed the test and removed the docstring.
Could we use `PY37` here instead of `TODO`? (Thinking that when we come to remove the PY37 constant it'll at least show up in the search...) (Not a biggie.)
```suggestion ''', [os.devnull]) ```
```suggestion filename %s ```
As far as I'm aware this can be simplified to: ```python char_count = math.ceil(self.salt_entropy/math.log(62, 2)) ``` also there is no need to calculate this for each `salt`, so I would move it to the cached property ```python @cached_property def char_count(self): return char_count = math.ceil(self.salt_entropy/math.log(62, 2)) ```
Please change entropy to `71`. This cleanup should not change the current behavior.
I would chop this sentence, maybe: ``` # Salt with an entropy of at least `salt_entropy` bits. ```
Maybe: ```python def char_count(self): # A string of length: # N / log_2(26+26+10) # provide N bits of entropy. ... ```
```python raise ValueError( "ISO week directive '%s' is incompatible with the year " "directive '%s'. Use the ISO year '%%G' instead." % ( week_format, year_format, ) ) ```
```suggestion res = self.client.get('/dates/books/2008/week/40/iso_week_format/') ```
```python msg = ... with self.assertRaisesMessage(ValueError, msg): ```
According to the [Python docs](https://docs.python.org/3/library/datetime.html): > %V - ISO 8601 week as a decimal number **with Monday as the first day of the week**. Week 01 is the week containing Jan 4.
```suggestion self.assertEqual(res.context['week'], datetime.date(2008, 9, 29)) ```
```suggestion week_choices = {'%W': '1', '%U': '0', '%V': '1'} ```
New class is not required, please move a regression test to the `ExcludeTests`.
``` # If someval is a nullable column, ```
We can add a second nullable column to the `Number` model.
You should be able to reuse an existing model, e.g. `Number`.
This should be added only if column is nullable: ```python if isinstance(value, Col) and self.is_nullable(value.target): clause.add(lookup_class(value, False), AND) ```
We'll also be able to simplify this to the following when #11359 is merged ```suggestion other = Value(other) ```
I moved a cleanup part to a separate commit.
Glad to see this gone.
I would use `if not isinstance(self, (DurationExpression, TemporalSubtraction))` because custom subclasses of `CombinedExpression` can exist in 3rd party packages.
The check here should include `is_staff`. If you don't have permission to access the admin at all then we don't need to apply the redirect.
I'm not sure there's much practical difference here, but `CommonMiddleware` uses `path_info`, so I'd say let's keep that.
OK, that sounds/looks interesting. Let me have a play. Thanks @jdufresne!
OK, I pulled this in.
This is the unauthenticated case yes? What's the story for the authenticated user? (Ah, I see the release note...)
Made moot by change to use `url` pattern kwargs.
This will _break_ the debug page I think: instead of a list of routed URL patterns, we'll get a plain 404 error response. (Would like to do something at the resolver level, but we don't have the request... Can we limit it just to `DEBUG=False`? 🤔)
Maybe ```suggestion urlpatterns.append(re_path(r'^(?P<url>.*)$', wrap(self.catch_all_view))) ``` and we could use `url` in the `catch_all_view()`: ```python def catch_all_view(self, request, url): if (settings.APPEND_SLASH and self.append_slash and not url.endswith('/')): urlconf = getattr(request, 'urlconf', None) path = '%s/' % request.path ... ```
Can we please exclude any potential deprecation of the APPEND_SLASH in the admin from the scope of this PR.
```suggestion if settings.APPEND_SLASH and self.append_slash and not request.path_info.endswith('/'): ```
Revert unrelated change.
```suggestion path = '%s/' % request.path ``` :thinking:
> Should we mention the new behavior(Handling the TooBig exception) or mention the `pylibmc` version update? Removing support for older ``pylibmc`` versions, e.g. ``` * Support for ``pylibmc`` < 1.5.2 is removed.``` > about the `tests requirements`, Do you mean to change `pylibmc; sys.platform != 'win32'` to `pylibmc >= 1.5.2; sys.platform != 'win32'` in `tests/tequirements/py3`? Yes
We can revert this unrelated change.
I would revert this change.
Changing the names of variables which is not necessary for this patch makes it harder to review, can we revert them? e.g. `total_seconds_since -> since`, or ``` for index, (seconds_per_chunk, chunk_name) in enumerate(TIMESINCE_CHUNKS): ``` -> ``` for i, (seconds, name) in enumerate(TIMESINCE_CHUNKS): ```
You can merge `test_depth()`, `test_depth_out_of_range()`, and `test_depth_one()` into a single test `test_timesince_depth()` and use `self.subTest()`.
I see the idea, but for me if a function is called only once and only contains some simple lines, the function call overhead is not worth it. You can let this for now and wait for the Django fellows opinion.
This wrapper is used in several methods so I've increased `max_size` a bit.
This is an internal wrapper so I changed it to `_get_signature()`.
I initially thought it would be an issue for `boundmethod` instances but it looks like they hash to the same value even if they are bound to different instances ```python class Foo: def __init__(self): pass >>> Foo().__init__ == Foo().__init__ False >>> hash(Foo().__init__) == hash(Foo().__init__) True ``` In all cases I don't see a compelling reason for setting `maxsize=None` and allowing the cache to grow unbounded.
`Sqlite` -> `SQLite`, wrap at 79 chars.
Could we possibly skip the detection feature `if Database.sqlite_version_info >= (3, 29, 0)`? Since this is only present on macOS [could we branch off `platform.platform`](https://docs.python.org/3/library/platform.html?highlight=darwin#platform.platform)? I think this would partially address @claudep's concerns.
I think the point is that it's specifically this version that is bundled with macOS 10.15. (I'm on 10.14 and don't see it.)
Obviously this is unwanted changes.
@PluckyPrecious Can you confirm that `DECIMAL_SEPARATOR` is a comma? I found that it's probably a dot `'.'` :thinking:
Can you confirm that `DATE_FORMAT`, `DATETIME_FORMAT`, and `YEAR_MONTH_FORMAT` should contain the `г.` suffix for a year? I think it was copied from the `tg` format.
Languages are ordered by `code`, so this should be above `'tr'`.
Please move it above `'tr'`.
I've changed this to 47 to get 60 chars in total because we always add `'merge'`.
👍 Nice consolidation here
Do we need `\n`? ```suggestion self.fail('Form is valid') ```
`FormNotValid failed. ` seems unnecessary for me.
Yes, exactly. However, if the value is truthy but not `True`, I think the current message could be confusing. So perhaps some alternate failure message should be used when the method doesn't return a `bool`. Same idea should be applied to `assertFormNotValid`.
I think we should build an `ErrorDict` of expected errors and use `assertEqual()` to compare it with `form.error`. This way we will avoid building a custom message. See also ticket-24782 that should be fixed in advance.
Ahh, yes sorry wrong ticket. It should be ticket-28507.
Also, I don't think we should collect this in `to_report`. We can fail immediately with `self.fail('Form is valid')`.
I think it would be nice if these methods verified the value is identical to either `True` or `False` and not some other truthy/falsey value. This would align with recommendation in the [coding style guildelines](https://docs.djangoproject.com/en/3.0/internals/contributing/writing-code/coding-style/): > Use assertIs(…, True/False) for testing boolean values, rather than assertTrue() and assertFalse(), so you can check the actual boolean value, not the truthiness of the expression. As well as stdlib [unittest](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertTrue): > Note that this is equivalent to bool(expr) is True and not to expr is True (use assertIs(expr, True) for the latter).
Let's go with "ellipsis": it's primary meaning is _the omision_, for which folks _could_ use any symbol. It's secondary meaning is the three dots `…` that we actually use.
Okay, super, thanks for the clarification @pope1ni. I shall take another look tomorrow and hopefully that's job done! Good work, as ever. 😉
Try to avoid `Check that` and `Check`.
Should we call it "ellipsis"? It's basically an option to customize a separator and do not use ellipsis :thinking:
`Final exception` doesn't appear in a template. I added check for `During handling of the above exception`.
```suggestion 'DEFAULT_AUTO_FIELD', ```
Should we use `@cached_property`? This might be accessed frequently and the setting shouldn't change during runtime.
Please keep the alphabetical order.
```suggestion def _check_default_auto_field(cls): if ( cls._meta.pk.auto_created and not settings.is_overridden('DEFAULT_AUTO_FIELD') and not cls._meta.app_config._is_default_auto_field_overridden() ): return [ checks.Error( 'Auto-created primary key used without defining a primary key type.', hint=( 'Configure the DEFAULT_AUTO_FIELD setting or the %s.default_auto_field ' 'attribute to point to a subclass of AutoField, e.g. ' "'django.db.models.BigAutoField'." ) % cls._meta.app_config.__class__.__name__, obj=cls, id='fields.E101', ), ] return [] ```
```suggestion def _is_default_auto_field_overridden(self): ```
```suggestion return settings.DEFAULT_AUTO_FIELD ```
I think with the corrected naming the docstring doesn't add much. ```suggestion ```
I wouldn't call `AutoField` a "legacy", we should also include `SmallAutoField`.
You can use `SimpleTestCase` here I believe.
`self.assertFalse()` -> `self.assertIs(..., False)` `self.assertTrue()` -> `self.assertIs(..., True)`
I'm wondering if this should be within the `DATABASES` setting
Wrap at 79 chars.
I feel like this setting is out of context here. Should `AppConfig` only provide information in the context of an app? If I want to find out what kind of primary key a given app is asking for, I could look for `AppConfig.model_default_pk`, but if we're overriding if with a project setting it can cause some confusion.
```suggestion pk_setting = getattr(self.app_config, 'default_auto_field', settings.DEFAULT_AUTO_FIELD) pk_class = import_string(pk_setting) if not issubclass(pk_class, AutoField): raise ValueError("Configured default auto field '%s' is not a subclass of AutoField." % pk_class) auto = pk_class(verbose_name='ID', primary_key=True, auto_created=True) ```
I think we should catch `ImportError` and return appropriate message, e.g. ```python try: pk_class = import_string(pk_setting) except ImportError: msg = 'The module %r could not be imported.' if hasattr(self.app_config, 'default_auto_field' ): msg += 'Check your %s.default_auto_field attribute.' % self.app_config else: msg += 'Check your DEFAULT_AUTO_FIELD setting.' raise ImproperlyConfigured(msg % pk_setting) ``` We could also add a cached hook, `get_default_auto_field()`.
I believe this should included in the `_check_default_pk()` with a different check, e.g. `fields.E102`.
Can we add this attribute in the alphabetical order? (in all contrib apps)
> Is SmallAutoField ever the right choice for a primary key field? Why not, it can be the right choice for any small dictionary tables if you really want to save space. I would even say that it's justified more often then `BigAutoField` :wink:
We can use the constant here and the prefix also contains enough unique characters, so we can simplify: ```suggestion @override_settings(SECRET_KEY=base.SECRET_KEY_INSECURE_PREFIX + 'x' * 34) ```
```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " ```
Things seem to be hung up on "Django-generated". I propose the following wording instead which seems clearer to me. I also note that "sufficiently" sneaked in there, but I'm not sure it really adds anything. Also note that the line wrapping should be maintained. ```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " "%(min_unique_chars)s unique characters, or it is prefixed with " "'django-insecure-' indicating that it was generated automatically by " "Django. Please generate a long and random SECRET_KEY, otherwise many of " "Django's security-critical features will be vulnerable to attack." % { ``` (Note this suggestion may not apply cleanly in GitHub as I needed to include unchanged lines around the removed and added lines.)
```suggestion "%(min_unique_chars)s unique characters, or it's prefixed with %(prefix)s " "indicating that it was generated automatically by Django. Please " "generate a long and random SECRET_KEY, otherwise many of Django's " "security-critical features will be vulnerable to attack." % { ```
```suggestion 'min_unique_chars': SECRET_KEY_MIN_UNIQUE_CHARACTERS, 'prefix': SECRET_KEY_INSECURE_PREFIX, ```
`it's django-generated` --> `it's a Django-generated`
This would need updating in `checks.txt`
```suggestion from django.core.checks.security.base import SECRET_KEY_INSECURE_PREFIX ```
We should use key that fails only on a prefix check.
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
📖 I think we could add a docstring to this explaining why `__init__` was overridden. This and `CaseInsensitiveMapping.__init__` looks pretty similar
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
```suggestion del self.headers[header] ```
Oh, you're right! Code blindness. Sorry for the noise. Doh.
We can move this hook to the new static method.
I think we should add `tried` to the [`ResolverMatch` docs](https://docs.djangoproject.com/en/3.1/ref/urlresolvers/#django.urls.ResolverMatch).
I am not exactly sure about that change of mine. It is probably okay that `sanitize_address` returns a long address, but I'll have to double check if actually serializing a message like that rewraps it again.
There should never be a reason to encode ascii to something else. While technically valid it makes mails bigger (especially if at one point we decide to call sanitize address for all addresses)
I think the last time this code changed, we did this because it was the way it was done before, but I also support not encoding already correct ascii. Chances are no one will complain that this changed.
I wonder why we quote a collation name in all backends when altering a field, but we do this only on PostgreSQL in table creation :thinking:
We can simplify this with changing a template: ```python sql = self.sql_alter_column_collate if new_field.db_collation else self.sql_alter_column_no_collate return sql % { 'column': self.quote_name(new_field.column), 'type': new_type, 'collation': self.quote_name(new_collation), }, [], } ```
I think it should be quoted in all cases.
This collation doesn't work for me: ``` django.db.utils.ProgrammingError: collation "en_US" for encoding "UTF8" does not exist ``` I've changed to the `en-x-icu`.
IMO we don't need to test the default behavior.
This change is unrelated, I will move it to a separate PR.
`get_table_collation()` is missing for Oracle, I added it to the main query.
We should add release notes for these feature flags.
```suggestion row = cursor.execute(""" SELECT sql FROM sqlite_master WHERE type = 'table' AND name = %s """, [table_name]).fetchone() if not row: return {} sql = row[0] ```
Import `DatabaseError` from `django.db`.
Retrieving metadata from SQLite is always such a pleasure :)
```suggestion self.assertIsNone(table_description[1].collation) ```
This requires a database query, hence we should take into account only chosen databases and the `required_db_features` option (see e.g. `JSONField._check_supported()` and related tests).
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
```suggestion self.assertIsNone(table_description[1].collation) ```
We should add a trailing space in `collate_sql()`: ```suggestion sql += self.collate_sql(collation) ``` and ```python def collate_sql(self, collation): return ' COLLATE ' + collation ```
We should add database features for these, e.g. `supports_collation_on_charfield` and `supports_collation_on_textfield`; and use `skipUnlessDBFeature`.
I would change it to the `DatabaseFeature.supports_collation_on_charfield`.
I think we should add a system check for using `db_collation` on backends that don't support them, e.g. ``` * **fields.E123**: ``<database>`` does not support collations on ``CharField/TextField``\s. ```
Okay then, no worries. As context managers are a regular, routine Python idiom, even outside tests, I find them quite readable (even with the indentation) and I find it makes the clenaup extremely explicit. Both forms work, though.
Thanks both, I changed to a context manager.
`tempfile.TemporaryDirectory()` can be used as a context manager: ```suggestion with tempfile.TemporaryDirectory() as temp_dir: ``` The other tests were cleaned up in #13211.
Tests are missing for some validators, e.g. `DecimalValidator` and codes `invalid`, `max_digits`, `max_whole_digits`, and `max_decimal_places`.
I think we can chop import and use e.g. `validators.MaxLengthValidator` like in other tests.
To test `NotImplemented` we can compare with `mock.ANY`, see ticket-30651.
There is no need to test it for `hash()`.
so maybe `hash((self.message, self.code, make_hashable(self.params)))` :thinking:
We should take keys into account (like in `__eq__()`), so maybe: ```suggestion if hasattr(self, 'error_dict'): return hash(tuple(sorted(make_hashable(self.error_dict)))) return hash(tuple(sorted(self))) ```
True, but I think we should take keys into account instead of adding `error_dict`/`error_list`.
`mask_hashable()` returns a tuple or primitive so we don't need to wrap it into another tuple.
Chop unnecessary blank lines.
Use `hash()` instead of `__hash__()`, e.g. ```suggestion self.assertNotEqual(hash(exception_str), hash(exception_list)) ```
You don't need to use `make_hashable()` for primitives: ```suggestion return hash((self.message, self.code, self.params)) ```
I think we can simplify this: ```suggestion def __eq__(self, other): if not isinstance(other, ValidationError): return NotImplemented if hasattr(self, 'message'): return ( hasattr(other, 'message') and self.message == other.message and self.code == other.code and self.params == other.params ) return ( hasattr(self, 'error_list') == hasattr(other, 'error_list') and hasattr(self, 'error_dict') == hasattr(other, 'error_dict') and sorted(self.messages) == sorted(other.messages) ) ```
We also have to provide `__hash__()` because without it `ValidationError` instances are not hashable anymore.
I noticed that we missed keys comparison, e.g. `exception_a` and `exception_b` are equal: ```python exception_a = ValidationError({'field1': 'field error', 'field2': 'err'}) exception_b = ValidationError({'field2': 'err', 'field1': 'field error'}) ``` we should fix this, maybe: ```suggestion if hasattr(self, 'error_dict'): return hasattr(other, 'error_dict') and self.error_dict == other.error_dict return sorted(list(self)) == sorted(list(other)) ``` a test is also needed.
```suggestion new_record = '%s took %.3fs' % (record, record_time) ```
I would use `sys.stderr.write(msg + os.linesep)` for each result instead of `print()` with joined results.
I would personally structure this a bit differently by combining `time_keeper` and `time_it`: ```python class TimeKeeper: def __init__(...): self.records = [] @contextlib.contextmanager def timed(self, name): t1 = time.time() yield self.records.append(...) def __iter__(self): yield from records ``` Then you can do: ```python keeper = TimeKeeper() with keeper.timed("test"): ... for line in keeper: print(line) ``` or something akin to that, which feels more natural.
`run_keeper` → `time_keeper` for consistency? It feels like a hangover from when the class was called `time_keeper` before it changed to `TimeKeeper`. Are we also not still using single quotes? ```suggestion time_keeper = TimeKeeper() if options['timing'] else NullTimeKeeper() ```
```suggestion with time_keeper.timed('Total run'): failures = test_runner.run_tests(test_labels) time_keeper.results() ```
```suggestion with self.time_keeper.timed('Total database setup'): ```
```suggestion self.records = collections.defaultdict(list) ```
Should we name this `print_results` or move the `sys.stderr.write()` call outside? (I don't know if there would be a use for returning the generated text for something other than printing it out.)
Prefer "database" to "DB"? ```suggestion help='Output timings such as database creation, cloning, and teardown;' ' and total test run time.', ```
```suggestion time_keeper = TimeKeeper() if options.timing else NullTimeKeeper() with time_keeper.timed('Total run'): ```
```suggestion time_keeper.results() ```
That came from my suggestion. Originally it was `DB creation, DB cloning, DB teardown and total test run time` and, aside from `DB` → `database`, it seemed unnecessary to repeat `database` multiple times. Semicolons can be used in complex lists where there are commas used within the list items themselves. I perceived there to be two list items here: - database creation, cloning, and teardown - total test run time Your suggested wording now no longer makes it clear that "cloning" and "teardown" are database-related.
We need a trailing space to separate times from results, e.g. ``` test_order_index (schema.tests.SchemaTests) ... 0.000sok
Why not `TimeKeeper`? We instantiate this later: `self.time_keeper = time_keeper(self.timing)`, which could equally be `self.time_keeper = TimeKeeper(self.timing)`
`time_keeper` can't be `None`.
It seems that the `timing` parameter is doing too much work. We're storing it in the runner, plus passing it down to the time keeper class, for it only to be used here. Q: why is it the time keeper's job to choose whether output is displayed by the runner? (A: it's not) I think two classes would be better than the conditional. `TimeKeeper` and `NullTimeKeeper`, then in the runner we don't store `timing` but just do: ``` self.time_keeper = TimeKeeper() if timing else NullTimeKeeper() ``` `NullTimeKeeper` should implement no-ops for `timed()`, `append()` and `results()` and just a single `yield` for the context manager.
Can we drop the `-t`, I'm not convinced it's needed and the short help just puts `-t` which is opaque (if you misspell the option).
This should match the updated version in `runtests.py`.
Ah. It is because we are pre-populating `self.records` before the `yield` in the context manager. Changing to `defaultdict` means that the key only gets added after when the context manager is exiting and we do `self.records[name].append(end_time)`. This means that nested uses of `time_keeper.timed()` - as we do in the database setup -- end up being out of order.
```suggestion with self.time_keeper.timed('Total database teardown'): ```
Can we add the alias to this string, otherwise the output is a but meh...: ``` Database cloning took 2.384s Database cloning took 2.398s ```
`time.perf_counter()` should be used for best resolution
```suggestion with time_it("Database cloning", timing): ```
Yes this would be a good idea
I think there is, just so folks have a little less to learn between the two.
I think this should be instantiated by the runner, rather than a global instance. Otherwise multiple runs in the same process share state (imagine a script that calls `call_command('test')` in a loop).
I'm not sure why we have here a semicolon :thinking:, please use also hanging indentation: ```suggestion help=( 'Output timings such as database creation, cloning, teardown, ' ' total test run time.', ), ```
Add trailing comma.
It looks that you missed some of Carlton's edits, e.g. https://github.com/django/django/pull/13224#discussion_r468468374.
Adding `time_keeper` as the 3rd argument can cause issues for people that rely on the current signature and do not use keyword args.
Can combine these two `if` statements with `and`. ```suggestion if hasattr(settings, 'SITE_ID') and not isinstance(settings.SITE_ID, int): ```
```suggestion 'SITE_ID must be an integer', ```
Add trailing comma and use single quotes.
I would use `sites.E101` to separate them from checks related with `CurrentSiteManager`.
There is no need to `append()` because we have a single error: ```suggestion return [ ```
We should allow also `None`.
`check_site_id_type` -> `check_site_id`
It looks like this test is failing when run alongside other test apps with invalid models. I think you can change this assertion to check for the presence of at least the expected error: ```suggestion errors = checks.run_checks() expected = checks.Error(msg='SITE_ID must be an integer', obj='sites.E101') self.assertIn(expected, errors) ```
We could reuse `_field_should_be_altered()`: ```suggestion if not self._field_should_be_altered(old_field, new_field): ```
We can chop this docstring.
I would rather create a custom model with field that has `db_column`, e.g. ```python project_state = self.apply_operations('test_rfwdbc', ProjectState(), operations=[ migrations.CreateModel('Pony', fields=[ ('id', models.AutoField(primary_key=True)), ('field', models.IntegerField(db_column='db_field')), ]), ]) operation = migrations.RenameField('Pony', 'field', 'renamed_field') new_state = project_state.clone() operation.state_forwards('test_rfwdbc', new_state) ```
I don't see much value in this check.
I think we can simplify this test: ```suggestion self.assertIn('renamed_field', new_state.models['test_rfwdbc', 'pony'].fields) self.assertNotIn('field', new_state.models['test_rfwdbc', 'pony'].fields) self.assertColumnExists('test_rfwdbc_pony', 'db_field') with connection.schema_editor() as editor: with self.assertNumQueries(0): operation.database_forwards('test_rfwdbc', editor, project_state, new_state) self.assertColumnExists('test_rfwdbc_pony', 'db_field') with connection.schema_editor() as editor: with self.assertNumQueries(0): operation.database_backwards('test_rfwdbc', editor, new_state, project_state) self.assertColumnExists('test_rfwdbc_pony', 'db_field') ```
We're just checking the number of queries, so a single test with two columns sounds fine.
I think we should create a hook similar to the `_field_should_be_indexed()`, that will allow 3rd-party backends to adjust this behavior, e.g. ```python class BaseDatabaseSchemaEditor: ... def _field_should_be_altered(self, old_field, new_field): # Don't alter when changing only a field name. return ( old_field.column != new_field.column or old_field.deconstruct()[1:] != new_field.deconstruct()[1:] ) ```
Do we need to check this? We would also like to omit altering if `name` is the same.
We already compare columns in: ```python old_field.column != new_field.column or ``` so we can simply ignore `db_column` in kwargs, e.g. ```python def _field_should_be_altered(self, old_field, new_field): _, old_path, old_args, old_kwargs = old_field.deconstruct() _, new_path, new_args, new_kwargs = new_field.deconstruct() # Ignore db_column to not alter when changing only a db_column but it's # the same as a field name. old_kwargs.pop('db_column', None) new_kwargs.pop('db_column', None) # Don't alter when changing only a field name. return ( old_field.column != new_field.column or (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs) ) ```
We should keep both assertions: ```suggestion self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='ar').exists(), False) self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='bar').exists(), True) ```
It works with my proposition so we should have both assertions.
I don't like this solution because it creates even more caveats on Oracle. I will try to figure out sth. 2 hours later ... :hourglass_flowing_sand: I found quite small (and clean IMO) workaround that works in "all" cases: ```diff diff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py index edc5441799..5458fe91d0 100644 --- a/django/db/models/fields/json.py +++ b/django/db/models/fields/json.py @@ -163,7 +163,13 @@ class DataContains(PostgresOperatorLookup): lhs, '.%s' % json.dumps(key), json.dumps({'value': value}), ) for key, value in rhs.items() ]), params - return sql % (lhs, '', json.dumps({'value': rhs})), params + if isinstance(rhs, list): + if not rhs: + return "DBMS_LOB.SUBSTR(%s) LIKE '[%%%%]'" % lhs, params + return sql % (lhs, '', json.dumps({'value': rhs})), params + # Add JSON_EXISTS condition for JSON_ARRAYs. + sql = "%s = %%s OR JSON_EXISTS(%s, '$?(@==%s)')" + return sql % (lhs, lhs, json.dumps(rhs)), (rhs, *params) class ContainedBy(PostgresOperatorLookup): ```
This should be a feature flag as CockroachDB (which tries to emulate PostgreSQL in a lot of ways) has the same restriction.
Does it change anything? :thinking: The previous solution works fine for a dictionary on the RHS.
This workaround is not necessary with my proposition ```suggestion ('ar', []), ```
This line failed tests for me running sqlite as database but with psycopg2 installed. Only postgres adapter has `is_postgresql_13` defined.
```suggestion cache.clear() # Avoid the failed login delay in the next test. ```
```suggestion 'After a failed login, you need to wait for %s second before trying a new login.', 'After a failed login, you need to wait for %s seconds before trying a new login.', ```
I don't use login rate limiting myself at the moment, but I can see that people might want to use more sophisticated schemes (e.g. exponential delays). So I think it would be good to allow people to opt-out of this feature.
So I forgot to mention that checking `REMOTE_ADDR` is not going to be enough. Most serious deployments will have connections proxied so we would need to check for other headers such as `X-Forwarded-For`, etc. The challenge is that this cannot be blanket-enabled as we cannot assume that user's have configured their server correctly and we don't want those headers to be set by the client rather than the proxy. [`django-axes`](https://pypi.org/project/django-axes/) makes use of [`django-ipware`](https://pypi.org/project/django-ipware) for handling identification of client addresses. We'd probably want have a way of providing a setting pointing to a function that allows users to customise how this cache key is built? Because I doubt that we're going to want to add a (soft) dependency on another external package.
```suggestion timeout=60, ``` "60" on its own looks a bit weird. Also, it surely doesn't need to be as long as 60 seconds if `DELAY_AFTER_FAILED_LOGIN` is so much smaller? What if `DELAY_AFTER_FAILED_LOGIN > 60`? Maybe this should be: ```suggestion timeout=self.DELAY_AFTER_FAILED_LOGIN + 10, ```
```suggestion cache.clear() # Avoid the failed login delay in the next test. ```
We (and probably others) have existing solutions for this issue, and so would prefer to turn this off, both to avoid conflicts with existing policies and to avoid the slight cache overhead. So I suggest skipping the checks if `DELAY_AFTER_FAILED_LOGIN` is set to 0.
A form validation error seems sensible to me
Remove the space before the not for flake8
Add 1 empty line before the method declaration, and 1 empty line after it. Make sure the empty lines don't contain any whitespaces. This is for the flake8 failure as well
Remove spaces around the equal sign. It should be ```default=False``` to match PEP8.
Add a space before ```option.no_buffer``` to fix the flake8 failure
It would be clearer to the end-user if the help was "Shows output from passing tests."
It wouldn't hurt to evaluate the queryset to make sure it doesn't break somewhere down the line.
The default needs to be sha1 for existing projects. New projects can have the setting in the project template with `sha256`.
Does it? This is a specialized setting for people who need to run two versions in parallel. Those people should be able to read the release notes and prepare an upgrade plan. For everyone else (+new projects) `sha256` would be just fine as default.
`get_email_field_name()` is a class method so we can use: ```python self.assertEqual(AbstractBaseUser.get_email_field_name(), 'email') ```
Add trailing dot.
Please revert this unrelated change.
This assertion is not necessary.
I think we should copy `fields_cache`: ```suggestion state['_state'].fields_cache = state['_state'].fields_cache.copy() ``` because a copy of model instance can use the same values and we don't need to fetch it again.
This line is not necessary, because we don't call `save()`.
We can chop this docstring.
Do we need to use `Empty`? We will not hit `__reduce__()` with: ```python def __copy__(self): obj = type(self)() obj.__dict__ = self.__dict__.copy() obj._state = copy.copy(obj._state) obj._state.fields_cache = {} ```
Thanks, the current approach LGTM. Please uncheck "Patch needs improvement" flag on the ticket after local testing.
```suggestion class ModelFieldsCacheTest(TestCase): def test_fields_cache_reset_on_copy(self): department1 = Department.objects.create(id=1, name='department1') department2 = Department.objects.create(id=2, name='department2') worker1 = Worker.objects.create(name='worker', department=department1) worker2 = copy.copy(worker1) self.assertEqual(worker2.department, department1) # Changing related fields doesn't mutate the base object. worker2.department = department2 self.assertEqual(worker2.department, department2) self.assertEqual(worker1.department, department1) ```
Chop blank line.
Good idea, I will implement it :+1:
We try to avoid altering expressions during the compilation phase as it can lead to hard to diagnose issues what about ```suggestion self.collation = collation def as_sql(self, compiler, connection, **extra_context): extra_context.setdefault('collation', connection.ops.quote_name(self.collation) ```
It is subject to SQL injection, using a suitably crafted `collation`, e.g. ```python Author.objects.filter( alias=Collate('name', 'et-x-icu" OR 1=1 OR \'x\' = "name') ) ```
I added warning to docs.
This assertion is unreachable.
This assertion is unreachable.
Yes, I've created PR #13289 to fix them.
Might want to move this line just after `app_config_class = None` and keep the blank line, which helps a bit the readability of this way-too-long function.
You can simplify this with `assertLogs()`: ```suggestion url = reverse('test_with_sidebar:auth_user_changelist') with self.assertRaisesMessage(AssertionError, 'no logs'): with self.assertLogs('django.template', 'DEBUG'): self.client.get(url) ```
This change and `LoggingCaptureMixin` are unnecessary if you will use `assertLogs()`.
```suggestion "model, are m2m fields, or are non-concrete fields: %s" ```
Use list and remove unnecessary whitespace ```suggestion fields = [('name', 'position')] ```
Add a trailing period.
Please use single quotes (everywhere), you mixed single with double quotes.
```suggestion '<tr class="row-form-errors"><td colspan="3">' '<ul class="errorlist nonfield"><li>A non-field error</li></ul></td></tr>', ```
```suggestion '<thead><tr><th class="original"></th>' '<th class="column-name required">Name</th>' '<th class="column-position required hidden">Position</th>' '<th>Delete?</th></tr></thead>', ```
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">1</div></div>', ```
```suggestion self.add_error(None, ValidationError('A non-field error')) ```
```suggestion # Count all visible fields. ```
Chop blank line.
I don't think this is needed.
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">0</div></div>', ```
```suggestion model = SomeChildModel fields = ['name', 'position', 'parent'] widgets = {'position': forms.HiddenInput} ```
This can be single-lined.
I moved this unrelated typo fix to a separate commit.
I simplified this test with `@mock_inputs()`.
It may not be possible to internally import all of from `django.test` because we can create circular imports.
... but we can of course unify imports in docs and tests.
`compare_xml()` is not really a public API, I removed it.
I would stick with the one line if/else statements. The style guide says, "Don’t limit lines of code to 79 characters if it means the code looks significantly uglier or is harder to read."
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
please omit the blank line
No reason to use `dict.update()` anymore.
We would fallback to an empty `bytes` string as well ```suggestion boundary = opts.get('boundary', b'') ```
```suggestion # python-memcached ≥ 1.45 returns None for a nonexistent key in # incr()/decr(), python-memcached < 1.45 raises ValueError. ```
Currently, pymemcache has `get_multi`. So also works ```python def get_multi(self, keys, gets=False, *args, **kwargs): # pymemcache.client.hash.HashClient may return {'key': False} result = super().get_multi(keys, gets, *args, **kwargs) return {k: v for k, v in result.items() if v} ```
Maybe pinterest/pymemcache#58 related alias. `BaseMemcachedCache.get_many` calls pylibmc or python-memcache client's [`get_multi`](https://github.com/django/django/blob/3.1/django/core/cache/backends/memcached.py#L93). So override pymemcache client's `get_many` and alias it to `get_multi`. CC: Original author @jezdez
```suggestion # Normalize an exception raised by the underlying client library to # ValueError in the event of a nonexistent key when calling incr(). ```
```suggestion # Normalize an exception raised by the underlying client library to # ValueError in the event of a nonexistent key when calling decr(). ```
```suggestion # Exception type raised by the underlying client library for a # nonexistent key. ```
```suggestion with self.subTest(location), self.settings(CACHES=settings): ```
Maybe `client_servers` without a docstring.
```suggestion backend = self.base_params['BACKEND'] ```
```suggestion output.append(server[5:] server.startswith('unix:') else server) ```
Do we need to call `bool()`? `touch()` returns `True` or `False` according to `pylibmc` docs.
Revert unrelated changes.
If `formfield.queryset` is already filtered both the outer query and the subquery will have this filter applied which is unnecessary ```suggestion Exists(formfield.queryset.model._base_manager.filter(complex_filter)), ```
+1 for the ordered set... It would fit right in the original iteration without the extra method. If you do insist on keeping the extra method, consider prefixing it with a '_' to denote it is only used in this class. When I approach large codebases I like it when I can just see the intent of code and not have to switch from reading to a Silver Searcher search to guess from where it might be called.
I did. I see what's going wrong, a set has no defined order. So the order of the select options is not guaranteed. But if I'm not mistaken, neither dicts have no defined order either. Maybe there's something in itertools you can use. Otherwise collections.OrderdDict.fromkeys will guarantee the order is kept.
Do we not also need to change this as `.count()` will include the duplicate values? I noticed that previous patches attached to ticket-11707 took this into account. If this is changed there should also be a test for this.
Good catch :+1: Thanks
Do you have a traceback or the name(s) of test that fails with the set(). I ran the sqlite suite with the set() without problems.
Why the obscure `dict.fromkeys` with a list comprehension that could be just `list(queryset)`? IMHO the clearest code that wouldn't require a new method for clarification would be... ```python for obj in set(queryset): ... ``` If you feel the need to clarify why the `set` is used, maybe be more verbose in the unittest and/or commit message and squash the commits into one neat commit.
`BaseDatabaseCreation` shouldn't contain branches for specific backends.
It's rather rare that folks have the Oracle database engine installed locally, so it crashes because `expdp` and `impdp` are not available.
You should try to reuse `connection._connect_string()`.
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
The rest of the patch is using f-strings. Hopefully we can make a final decision on that in #13214 soon. `original_settings_dict` feels a bit clunky. Also note that unpacking a dictionary works like a shallow copy, so modifying the value of the `'TEST'` sub-ditctionary will affect the original. Perhaps this would be simpler: ```suggestion original = self.connection.settings_dict user = original['USER'] password = original['PASSWORD'] return { **original, 'USER': f'{user}_{suffix}', 'PASSWORD': f'{password}_{suffix}', 'TEST': { **original['TEST'], 'USER': f'{user}_{suffix}', 'PASSWORD': f'{password}_{suffix}', }, } ```
Then we could do this: ```suggestion parameters = self._get_test_db_params(suffix) ```
```suggestion orig_settings_dict['TEST']['PASSWORD'] = orig_settings_dict['PASSWORD'] ``` Not sure how the tests passed here... Unless username and password are the same...
This test fails: `(1235, "This version of MySQL doesn't yet support 'FORMAT=JSON with EXPLAIN ANALYZE'")`.
We need to add `analyze: True`, currently it fails: `django.db.utils.DataError: EXPLAIN option WAL requires ANALYZE`.
```suggestion assertEqual(len(threads_and_connections), 4) assertEqual(len(set(threads_and_connections)), 1) ```
```suggestion i = BigAutoField(primary_key=True) ```
```suggestion *_, kwargs = obj._meta.get_field('storage_callable').deconstruct() ```
```suggestion kwargs['storage'] = getattr(self, '_storage_callable', self.storage) ```
This is probably worth it's own test-case. (For ref: there are similar tests on ln70)
Really a micro-optmiization, but these can be constructed as tuples and then the `tuple()` cast after the ifs can be moved up to just the oracle branch ```suggestion func = ("JSON_UNQUOTE(JSON_EXTRACT(%s, '$'))",) * len(rhs_params) elif connection.vendor in {'sqlite', 'mysql'}: func = ("JSON_EXTRACT(%s, '$')",) * len(rhs_params) ```
This is really similar to `process_rhs` in `KeyTransformExact` though, can we reuse that somehow? Also, this is a rather edge case, but this means one of the elements of the rhs can't be `None` on SQLite (unless we add `OR JSON_TYPE` in the lhs.
This list of registrations was roughly in order of the definitions above, I think we should preserve that
I think we should still catch `TypeError` because `isinstance(key, str)` will not work for subclasses of `SafeExceptionReporterFilter` that use bytes pattern in `hidden_settings`. Maybe: ```diff diff --git a/django/views/debug.py b/django/views/debug.py index 68dba4b500..53e6b2d4dc 100644 --- a/django/views/debug.py +++ b/django/views/debug.py @@ -91,18 +91,18 @@ class SafeExceptionReporterFilter: value is a dictionary, recursively cleanse the keys in that dictionary. """ try: - if self.hidden_settings.search(key): - cleansed = self.cleansed_substitute - elif isinstance(value, dict): - cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()} - elif isinstance(value, list): - cleansed = [self.cleanse_setting('', v) for v in value] - elif isinstance(value, tuple): - cleansed = tuple([self.cleanse_setting('', v) for v in value]) - else: - cleansed = value + is_sensitive = self.hidden_settings.search(key) except TypeError: - # If the key isn't regex-able, just return as-is. + is_sensitive = False + if is_sensitive: + cleansed = self.cleansed_substitute + elif isinstance(value, dict): + cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()} + elif isinstance(value, list): + cleansed = [self.cleanse_setting('', v) for v in value] + elif isinstance(value, tuple): + cleansed = tuple([self.cleanse_setting('', v) for v in value]) + else: cleansed = value if callable(cleansed): ```
I think an example with `tuple` would be more realistic, e.g. `{('localhost', 8000): {....}`.
Can you wrap at 79 chars? as suggested in https://github.com/django/django/pull/13350#discussion_r481046575
```suggestion path('upload_stopped/', views.file_upload_stopped), ```
```suggestion request.FILES # Trigger file parsing. ```
`file` -> `temp_file`
Temporary file can be empty here, so we don't need these two lines.
Is there a reason to use `isfile()` instead of `exists()`.
Wrap docstrings at 79 chars. I would chop an example.
New tests show that this change is not necessary because temporary files are closed in `self._close_files()` when `StopUpload()` is raised. I reverted this change and renamed `upload_stopped()` to `upload_interrupted()`.
IMO this state should be controlled by the `MultiPartParser` not by a handler, e.g. ```diff diff --git a/django/http/multipartparser.py b/django/http/multipartparser.py index b3472f7be2..7fd7f0b49c 100644 --- a/django/http/multipartparser.py +++ b/django/http/multipartparser.py @@ -150,6 +150,7 @@ class MultiPartParser: num_post_keys = 0 # To limit the amount of data read from the request. read_size = None + uploaded_file = True try: for item_type, meta_data, field_stream in Parser(stream, self._boundary): @@ -159,6 +160,7 @@ class MultiPartParser: # we hit the next boundary/part of the multipart content. self.handle_file_complete(old_field_name, counters) old_field_name = None + uploaded_file = True try: disposition = meta_data['content-disposition'][1] @@ -206,6 +208,7 @@ class MultiPartParser: self._post.appendlist(field_name, force_str(data, encoding, errors='replace')) elif item_type == FILE: + uploaded_file = False # This is a file, use the handler... file_name = disposition.get('filename') if file_name: @@ -275,10 +278,15 @@ class MultiPartParser: # If this is neither a FIELD or a FILE, just exhaust the stream. exhaust(stream) except StopUpload as e: + for handler in handlers: + handler.upload_stopped() self._close_files() if not e.connection_reset: exhaust(self._input_data) else: + if not uploaded_file: + for handler in handlers: + handler.upload_stopped() # Make sure that the request data is all fed exhaust(self._input_data) ```
Please keep this list in alphabetical order, i.e. place this after `SECURE_CONTENT_TYPE_NOSNIFF`
This is already done in the super method, so undo: ```suggestion self.get_response = get_response ```
I think it's slightly more maintainable to use `self.cross_origin_opener_policy` as the variable name
@felixxm I was thinking about only specifying `css` OR `js` – the default values are empty datastructures which are falsy as well. There's no point in iterating through `_js_lists` or `_css_lists` to find whether an empty datastructure already exists in there. But it's probably a pointless microoptimization.
Including falsy is a user's mistake and we don't remove them from the source lists, so I think we shouldn't change this.
This isn't quite right. Now the lists in `combined` are assigned to those in `self` by reference. That means that the lists in `self` will also be modified. We can also avoid the unnecessary tuple construction. ```suggestion combined._css_lists = self._css_lists[:] combined._js_lists = self._js_lists[:] ``` I'm not sure how this extra copying will affect performance.
I think you could skip this check if `item` is falsy. I haven't done any measurements but I'd suggest changing this to: `if item and item not in self._css_lists`
> My only concern is that this might break some applications that touch the raw underlying connections. It does feel like a blunt hammer. Yes this is a bit backwards incompatible for apps using raw SQL using Djanogo's connection to select from a jsonb column. I'm not sure it's worth the effort though to try wrap specific queries though, that would require a new field -> queryset interface.
> for apps using raw SQL No need to use raw SQL. I was lazy and used `JSONField` (doesn't require a `base_field`) instead of `ArrayField` as `output_field` in the following query which resulted in a TypeError (list instead of str/bytes/bytearray passed to `json.loads()`). ```python class Project(Model): project_id = CharField(unique=True, max_length=36) class Lexicon(Model): lemma = CharField(max_length=256, db_index=True) # lexicon entries can be global or specific to a set of projects projects = ManyToManyField(Project, through="LexiconProjectThrough") class LexiconProjectThrough(Model): lexicon = ForeignKey(AdjectiveLexicon, on_delete=CASCADE) project = ForeignKey(Project, on_delete=CASCADE) class Meta: unique_together = (("lexicon", "project"),) Lexicon.objects.annotate( project_specific=Exists( LexiconProjectThrough.objects.filter(lexicon=OuterRef("pk")) ) ).annotate( project_ids=Case( When(project_specific=True, then=ArrayAgg("projects__project_id")), default=[], output_field=JSONField(), ) ).first() ``` The solution was to remove `output_field=JSONField()` (or replace it with `output_field=ArrayField(base_field=CharField(max_length=36))`). Back in 2017 (Django 1.11) the code failed without the output_field (`TypeError: int() argument must be a string, a bytes-like object or a number, not 'list'`; project_id was a PositiveIntegerField back then). The code also works when using a custom `JSONField` that brings back the `self.decoder is None` check: ```python class MyJSONField(JSONField): def from_db_value(self, value, expression, connection): if connection.features.has_native_json_field and self.decoder is None: return value return super().from_db_value(value, expression, connection) ``` <details><summary>stack trace</summary> ``` /usr/local/lib/python3.8/site-packages/django/db/models/query.py in first(self) 676 def first(self): 677 """Return the first object of a query or None if no match is found.""" --> 678 for obj in (self if self.ordered else self.order_by('pk'))[:1]: 679 return obj 680 /usr/local/lib/python3.8/site-packages/django/db/models/query.py in __iter__(self) 285 - Responsible for turning the rows into model objects. 286 """ --> 287 self._fetch_all() 288 return iter(self._result_cache) 289 /usr/local/lib/python3.8/site-packages/django/db/models/query.py in _fetch_all(self) [27/2653] 1301 def _fetch_all(self): 1302 if self._result_cache is None: -> 1303 self._result_cache = list(self._iterable_class(self)) 1304 if self._prefetch_related_lookups and not self._prefetch_done: 1305 self._prefetch_related_objects() /usr/local/lib/python3.8/site-packages/django/db/models/query.py in __iter__(self) 68 ])) for field, related_objs in queryset._known_related_objects.items() 69 ] ---> 70 for row in compiler.results_iter(results): 71 obj = model_cls.from_db(db, init_list, row[model_fields_start:model_fields_end]) 72 for rel_populator in related_populators: /usr/local/lib/python3.8/site-packages/django/db/models/sql/compiler.py in apply_converters(self, rows, converters) 1098 value = row[pos] 1099 for converter in convs: -> 1100 value = converter(value, expression, connection) 1101 row[pos] = value 1102 yield row /usr/local/lib/python3.8/site-packages/django/db/models/fields/json.py in from_db_value(self, value, expression, connection) 72 return value 73 try: ---> 74 return json.loads(value, cls=self.decoder) 75 except json.JSONDecodeError: 76 return value /usr/local/lib/python3.8/json/__init__.py in loads(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw) 339 else: 340 if not isinstance(s, (bytes, bytearray)): --> 341 raise TypeError(f'the JSON object must be str, bytes or bytearray, ' 342 f'not {s.__class__.__name__}') 343 s = s.decode(detect_encoding(s), 'surrogatepass') TypeError: the JSON object must be str, bytes or bytearray, not list ``` </details> ---- That said, at the moment I don't think that's worth an issue, but I wanted to let you know in case you think otherwise. :)
```suggestion # to json.dumps() to json.loads() when using a custom decoder in # JSONField.from_db_value(). ```
In the first case I think you were just lucky that the JSONField effectively was "pass through" for your return data. In the second case - I don't really think it's concern since `decoder` was introduced in Django 3.1, and users who subclass and duplicate logic become responsible for their duplicated logic staying in sync.
this can be super().clean() only as python 3 don't need this explicitness
The transform function is not only to re-project a raster. It can also be used to change its driver (by providing the same srs but a different driver name than the original). Admitedly, for that purpose the `warp` function might be more appropriate, but people might be using transform as well as "filetype change function" convenience. So before going into "clone mode", we might have to check for the equal drivers as well? I.e. `if diver is not None and driver == self.driver.name` or something along those lines.
The name provided in the "transform" call could be passed to the clone function to create the clone in the expected location.
Why this solution doesn't use `capi.copy_ds()`? :thinking:
Can we use instead `assertEqual()` and `assertIsNot()`? ```suggestion self.assertEqual(clone, source) self.assertIsNot(clone, source) ```
Is there anything wrong with `return type(self)(capi.copy_ds(self.ptr))`? this should be the most efficient way.
Great catch :+1:
Remove it please.
It's not required for the fix, this should be moved to a separate PR and discussed separately.
But it's already covered by the first assertions. Moreover `assertEqual()` uses `assertTupleEqual()` internally.
See also ticket-12826.
```suggestion self.assertEqual(value, (72, 75)) self.assertEqual(value, pickle.loads(pickle.dumps(value))) ```
```suggestion return NamedValuesListIterable.create_namedtuple_class(*names)(*values) ```
There is no need to mix these tests with `.extra()` we can use existing columns, e.g. ```python values = Number.objects.values_list('num', 'other_num', named=True).get() ```
I would move `create_namedtuple_class` outside of `NamedValuesListIterable` or even better to `django.db.models.utils`, e.g. ```python def unpickle_row(names, values): return create_namedtuple_class(*names)(*values) @functools.lru_cache() def create_namedtuple_class(*names): # Cache type() with @lru_cache() since it's too slow to be called for every # QuerySet evaluation. def namedtuple_reduce(self): return unpickle_row, (names, tuple(self)) return type('Row', (namedtuple('Row', names),), { '__reduce__': namedtuple_reduce, }) ```
We can then test all the different combinations and use `self.subTest(...)` to reduce duplication as follows: ```suggestion class CheckCacheLocationTest(SimpleTestCase): @staticmethod def get_settings(name, cache_path, other_path): return { 'CACHES': { 'default': { 'BACKEND': 'django.core.cache.backends.filebased.FileBasedCache', 'LOCATION': cache_path, }, }, name: [other_path] if name == 'STATICFILES_DIRS' else other_path, } def assertWarningWithHint(self, hint): self.assertEqual(check_cache_location_not_exposed(None), [Warning( 'Your configuration might expose your cache or lead to corruption of your data.', hint=hint, id='cache.W002', )]) def test_cache_path_matches_other_path(self): root = pathlib.Path.cwd() for name in ('MEDIA_ROOT', 'STATIC_ROOT', 'STATICFILES_DIRS'): settings = self.get_settings(name, root, root) with self.subTest(setting=name), override_settings(**settings): self.assertWarningWithHint(f"Your 'default' cache path matches your {name}.") def test_cache_path_inside_other_path(self): root = pathlib.Path.cwd() for name in ('MEDIA_ROOT', 'STATIC_ROOT', 'STATICFILES_DIRS'): settings = self.get_settings(name, root / 'cache', root) with self.subTest(setting=name), override_settings(**settings): self.assertWarningWithHint(f"Your 'default' cache path is inside your {name}.") def test_cache_path_contains_other_path(self): root = pathlib.Path.cwd() for name in ('MEDIA_ROOT', 'STATIC_ROOT', 'STATICFILES_DIRS'): settings = self.get_settings(name, root, root / 'other') with self.subTest(setting=name), override_settings(**settings): self.assertWarningWithHint(f"Your 'default' cache path contains your {name}.") def test_cache_path_does_not_conflict_with_other_path(self): root = pathlib.Path.cwd() for name in ('MEDIA_ROOT', 'STATIC_ROOT', 'STATICFILES_DIRS'): settings = self.get_settings(name, root / 'cache', root / 'other') with self.subTest(setting=name), override_settings(**settings): self.assertEqual(check_cache_location_not_exposed(None), []) ```
By using an extra `continue` we reduce the indentation. I also propose that we change the hint message when depending on whether the cache path matches, is inside, or contains one of the other paths: ```suggestion if not setting: continue if name == 'STATICFILES_DIRS': paths = {pathlib.Path(dir).resolve() for dir in setting} else: paths = {pathlib.Path(setting).resolve()} for alias in settings.CACHES: cache = caches[alias] if not isinstance(cache, FileBasedCache): continue cache_path = pathlib.Path(cache._dir).resolve() if any(path == cache_path for path in paths): hint = f"Your '{alias}' cache path matches your {name}." elif any(path in cache_path.parents for path in paths): hint = f"Your '{alias}' cache path is inside your {name}." elif any(cache_path in path.parents for path in paths): hint = f"Your '{alias}' cache path contains your {name}." else: continue errors.append(Warning( 'Your configuration might expose your cache or lead to corruption of your data.', hint=hint, id='cache.W002', )) ```
```suggestion import pathlib ```
hey @David-Wobrock thanks for the patch, just pointing out the spelling is "overridden". Would be good to update throughout.
It may be unclear why `self.assertEqual(response.context['data'], expected)` fails when the `status_code` isn't 200. I would suggest moving this line below the `self.assertContains` assertion. The same feedback applies to the other change in this file and also to the last change in `tests/admin_views/tests.py`. Apart from that this looks excellent.
We can reuse existing objects.
Yes, please use `self. addCleanup()`.
I would rather try to create a second non-blocking lock: ```suggestion file_path = Path(__file__).parent / 'test.png' f1 = open(file_path) f2 = open(file_path) self.assertIs(locks.lock(f1, locks.LOCK_EX), True) self.assertIs(locks.lock(f2, locks.LOCK_EX | LOCK_NB), False) ```
`BlockingIOError` is not raised on Windows so we should distinct assertions: ```python if os.name == 'nt': self.assertIs(locks.lock(f2, locks.LOCK_EX | locks.LOCK_NB), False) else: with self.assertRaises(BlockingIOError): locks.lock(f2, locks.LOCK_EX | locks.LOCK_NB) ```
You need to specify a type of lock, e.g. `locks.LOCK_NB | locks.LOCK_EX`. Currently it returns `False` because we passed an invalid argument.
These files should be explicitly closed using a `with`. Right now, they result in errors in the console. Same in `test_file_shared_lock`: ``` Exception ignored in: <_io.FileIO name='/home/jon/devel/django/tests/files/test.png' mode='rb' closefd=True> Traceback (most recent call last): File "/usr/lib64/python3.9/unittest/case.py", line 550, in _callTestMethod method() ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/jon/devel/django/tests/files/test.png' mode='r' encoding='UTF-8'> Exception ignored in: <_io.FileIO name='/home/jon/devel/django/tests/files/test.png' mode='rb' closefd=True> Traceback (most recent call last): File "/usr/lib64/python3.9/unittest/case.py", line 550, in _callTestMethod method() ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/jon/devel/django/tests/files/test.png' mode='r' encoding='UTF-8'> Exception ignored in: <_io.FileIO name='/home/jon/devel/django/tests/files/test.png' mode='rb' closefd=True> Traceback (most recent call last): . File "/usr/lib64/python3.9/unittest/case.py", line 550, in _callTestMethod ......... method() ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/jon/devel/django/tests/files/test.png' mode='r' encoding='UTF-8'> Exception ignored in: <_io.FileIO name='/home/jon/devel/django/tests/files/test.png' mode='rb' closefd=True> Traceback (most recent call last): File "/usr/lib64/python3.9/unittest/case.py", line 550, in _callTestMethod method() ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/jon/devel/django/tests/files/test.png' mode='r' encoding='UTF-8'> ................................. ---------------------------------------------------------------------- Ran 43 tests in 0.046s ```
You don't need to mock, it will return `False` for a bad file descriptor.
Use `assertIs(..., True/False)`.
```suggestion file_path = Path(__file__).parent / 'test.png' ```
```suggestion self.assertIs(locks.lock(f, locks.LOCK_EX), True) ```
`'rb'` flags are unnecessary.
We should respect also description for `None` (test is required).
I would add `('availability', BooleanFieldListFilter)` to the `BookAdminWithTupleBooleanFilter` instead of creating a separate class.
We don't reuse `availability_choices` anywhere so there is no need for a separate variable.
This change is not required, please revert it.
Please revert this unrelated change.
I've noticed that `None` from `flatchoices` should update `Unknown` not `All`. I fixed this.
This change is not required, please revert it.
Please revert this unrelated change.
IMO we could simplify this with using `dict`, e.g. ```python def choices(self, changelist): choices = { None: _('All'), True: _('Yes'), False: _('No'), **{lookup: title for lookup, title in self.field.flatchoices}, } for lookup, title in choices.items(): lookup_val = str(int(lookup)) if lookup is not None else lookup yield { 'selected': self.lookup_val == lookup_val and not self.lookup_val2, 'query_string': changelist.get_query_string({self.lookup_kwarg: lookup_val}, [self.lookup_kwarg2]), 'display': title, } ... ```
```suggestion WHEN %s THEN ```
Can we pass it in params? ```suggestion """, [self.index_name, table_name]) ```
I would call it `index_default_access_method`. `index_name` can be misleading.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
```suggestion self.assertEqual(response.headers['x-foo'], 'foo') ```
```suggestion self.assertEqual(response.headers['x-foo'], 'foo') ```
Do we need to call `render()`? It looks unnecessary.
Do we need to call `render()`? It looks unnecessary.
Maybe test whether `r.headers['x-foo']` is set or something? (`CaseInsensitiveMapping` itself is probably thoroughly tested but it may be useful to verify the case insensitivity here too)
This test works without the patch, I will move it to a separate commit.
This is unlikely to be enough as JSON can have an array or string as it's top-level data type.
```suggestion if expr.contains_aggregate and isinstance(expr, Ref) and expr.refs in kwargs: ```
Use hanging indentation: ```suggestion raise exceptions.FieldError( "Cannot compute %s('%s'): '%s' is an aggregate" % (annotation.name, name, name) ) ```
Not a native speaker but wonder if _collides_ instead of _overrides_ would be more appropriate.
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
It's fine 👍
```suggestion # Even the third inline should have the correct verbose_name ```
Does it also work if you leave away the wrapping DIV? It isn't obvious to me that the issue from the ticket (`'<a/><b/>'` should be contained by `'<a/><b/><c/>'`) is being addressed by this change.
I think you should add an explanation what this does or at least add a reference to the ticket to help future readers understand what this branch achieves.
Yes, that may be a good reason. Let's wait and see.
Using `property` is slightly backward incompatible since `self.backend` cannot be assigned anymore. We could use `cached_property` to avoid the implicit `sys.modules` lookup on every access and allow instance level assignments.
Do you need a `model_admin`? The ticket only mentions a model instance (`model` is a class not an instance). I'm not sure how a model admin class can be used in templates :thinking:
I don't see much value in renaming this method. This wouldn't make it a public API as explicit docs are also required. Also, there is a separate ticket-25671 and #13918 that propose to change related methods. I think we can revert this change for now.
PEP 8 hedges about line breaks and binary operators but suggests ultimately that breaking before the operator is better. As long as we're touching this I would suggest breaking before the operators.
In Django we break after the operator, that's why `W504` is ignored. It's checked by `flake8`.
I don't think it's an improvement, it's less readable IMO.
```suggestion request.method in ('GET', 'HEAD') ```
Because of Python's support for [short-circuiting](https://docs.python.org/3/library/stdtypes.html#boolean-operations-and-or-not) boolean operators, the tests are failing here as sometimes `[]` is being returned. The fix is easy: ```suggestion return bool( ```
Use hanging indentation (the same in the second test).
Add trailing comma.
I'm no English specialist, but shouldn't we remove the `s` in the first form, because reading `Please submit at most 1 forms.` sounds weird with the final `s`.
Chop blank line.
The singular form should be `Please submit at least %d form.`.
The singular form should be `Please submit at most %d form.`.
We can use a different count variable not only `'count'`, so it's probably better to use `self.countervar` instead.
No, `arg_options[opt.dest]` should be set to `True`, passing `flag=False` means that we don't want to include this option. That's how it works for arguments without groups.
As far as I'm aware we should pass a constant option only if `arg_options[opt.dest]` is `True`
~~I think we should pass `True` in all cases, because we're selecting a flag not declaring a value.~~
@hramezani I checked this again and it looks that I was wrong, we always pass value directly to the command, even if an invalid value is passed. Sorry for misleading. I've reverted this change.
So I understand that this is to address options that have no arguments. As implemented, this will handle those that have `action` set to `'store_true'` or `'store_false'`, but we should also consider those set to `'store_const'` and possibly others? The bonus is that `_StoreFalseAction` and `_StoreTrueAction` are subclasses of `_StoreConstAction` which simplifies this somewhat.
It's not about `options` but about argument that we pass to `parser.parse_args()`, you cannot pass `--flag1` when user call `call_command('test', flag1=False)`. Currently truthy values as treated as "flag selected" and we should keep this behavior for mutually exclusive groups, so: - `call_command('mutually_exclusive_required_with_boolean', flag_true=True)` -> `--flag_true` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_true='x')` -> `--flag_true` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_true=78)` -> `--flag_true` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_true=0)` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_true=False)` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_true=[])` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_false=True)` -> `--flag_false` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_false='x')` -> `--flag_false` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_false=78)` -> `--flag_false` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_false=0)` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_false=False)` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', flag_false=[])` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', const=True)` -> `--const` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', const='x')` -> `--const` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', const=78)` -> `--const` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', const=41)` -> `--const` :green_circle: - `call_command('mutually_exclusive_required_with_boolean', const=0)` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', const=False)` -> `''` :red_circle: - `call_command('mutually_exclusive_required_with_boolean', const=[])` -> `''` :red_circle:
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
```suggestion return 'Create collation {self.name}' ```
I think it's too late for this check, `locale` shouldn't be an optional argument.
We should also remove `self.collation_exists(schema_editor, self.name)` checks.
```suggestion return 'Remove collation {self.name}' ```
Collations are not the same as extensions, they are not determine by names. IMO we shouldn't use `IF (NOT) EXISTS` syntax but fail loudly instead. It can create a tricky issues when we will omit creating collations just because the collation with the same name already exists.
IMO it's more readable with dict of args, e.g. ```suggestion args = {'locale': schema_editor.quote_name(self.locale)} # Before PostgreSQL 10, the provider parameter doesn't exist, # so only set it if it's not the default `libc`. if self.provider != 'libc': args['provider'] = schema_editor.quote_name(self.provider) # Before PostgreSQL 12, the deterministic parameter doesn't exist, # so only set it if it's False. if self.deterministic is False: args['deterministic'] = 'false' schema_editor.execute('CREATE COLLATION %(name)s (%(args)s)' % { 'name': schema_editor.quote_name(self.name), 'args': ', '.join(f'{option}={value}' for option, value in args.items()), }) ```
I think we should add also `RemoveCollation()` to fully support managing collations via migrations.
```suggestion raise NotSupportedError('Non-deterministic collations require PostgreSQL 12+.') ``` Also, this exception isn't tested.
That's all fair. I'm happy with just adding the check for 10+. I just like to ask all the questions to ensure that we think of everything. :wink:
```suggestion return f'Create collation {self.name}' ```
```suggestion return f'Remove collation {self.name}' ```
Good catch :+1:
```suggestion # the latter includes all of the provided `args`. ```
```suggestion fake_client = Path(__file__).with_name('fake_client.py') ```
FWIW, mysql "masks" the password on the command line by replacing it with `X` for every character -- at least on system where it is possible. Since a cmd line argument usually leaks on every system I'd consider cmd line arguments highly insecure (no matter what). But even if the replacing of the password works properly on every system the error python raises would still contain it. An environment variable is usually somewhat secure (ie other users are generally not able to view them). A file would even fix those remaining issues but can be hard to implement -- one should just use a (non-swapping) ram-fs backed tempfile, otherwise you would persist the password on disk where it might be recoverable. But I'd argue that the last issue is not really such an issue because the password has to be on the disk already (settings file ;)) or somehow passed into it (and even if it comes as env variable into the settings file it usually is coming from yet another file on this PC). All in all I do not think that dbshell is used that much on production systems (or at least should not be), but making sure that we have no obvious leaks like in exceptions is worth it.
Nitpick: pluralisation here feels off. I think it should be: ```suggestion # Ensure the exception that results from a client crash doesn't expose # the password. ```
I wonder if you have considered catching the `CalledProcessError`, modifying the message, and re-throwing it (or throwing a different `CalledProcessError` instance)? It has the advantage of avoiding the `MYSQL_PWD` env var that MySQL advises against (and even [calls "insecure"](https://dev.mysql.com/doc/refman/8.0/en/environment-variables.html)), and means we don't need to make changes to the signatures of these DB backends. I must admit, I'm not sure if it would be much better, as it runs the risk of the same issue occurring for other errors that may be raised here. Modifying the error as it's raised could be considered a little distasteful, too, I suppose.
This will crash with `TypeError: 'Q' object is not iterable` if `limit_choices_to` is a `Q` object due to the use of `sorted` hence the previously suggested `if` construct. Looking at `make_hashable` it looks like it has a bug as it should be using `sorted` when dealing with `dict` otherwise two dict with different insert order won't generate the same hash. In other words `hash(make_hashable({'foo': 'bar', 'bar': 'foo'})) != hash(make_hashable({'bar': 'foo', 'foo': 'bar'}))` when dict are equals which breaks the expected `__eq__` and `__hash__` property. I think the right way forward is to adjust `make_hashable` and use it directly here without the `tuple(sorted(...))` wrapping.
Minor you could use `bulk_create`
We should return `NotImplemented` if objects are not comparable: ```python if not isinstance(other, self.__class__): return NotImplemented ... ```
Thanks for the report, I've prepare a fix #13529.
This condition is problematic on databases that use random rather than serial pk values (failure observed on CockroachDB).
I don't think this is the best way to address this issue. We will always have to keep this list of fields updated. Instead we could change `_alter_field` field to do nothing when the constraint hasn't changed. We could just compare the old and new field. This is the `if` that drops the constraint. https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L590 and the one that adds it back https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L810
There is an open ticket to support database-level cascading deletion, see ticket-21961. We should mention it here: ```suggestion # Database-level options are not supported, see #21961. 'on_delete', ```
I think we missed some attributes e.g. `related_query_name`, `limit_choices_to`, or `validators`.
Perhaps a better, shorter name would be: ```suggestion non_database_fields = [ ```
This should work on SQLite as well https://github.com/django/django/blob/292b3be698ef58aff9c215d62a444f66ead578c3/django/db/backends/sqlite3/schema.py#L101-L103
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
Yes, it's also already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f.
I guess `name` would be another one.
Chop the ticket number `(#25253)`.
```suggestion new_field = ForeignKey( Author, blank=True, editable=False, error_messages={'invalid': 'new error message'}, help_text='new help text', limit_choices_to={'foo': 'bar'}, related_name='new_related_name', related_query_name='new_related_query_name', on_delete=PROTECT, validators=[lambda x: x], verbose_name='new verbose name', db_column=old_field.column ) new_field.set_attributes_from_name('renamed_author') ``` Is what I'm referring to. The direct `set_attributes_from_name` call simulates what would happen a model is initialized with an attribute name like it happens normally. It can likely be removed entirely if you pass `name='renamed_author'` when calling `ForeignKey`.
looks like we explicitly discard `name` so that's why it doesn't need to be present in `non_database_fields`.
Chop the ticket number `(#25253)`.
This is not only about constraints but also about noop `ALTER FIELD` operations. Field alteration can cause many DDL changes. > We could just compare the old and new field. That's exactly what we're doing here, we compare fields but without attributes that don't impact schema changes.
@apollo13 you're completely right. Look I missed the inclusion of `'%'` in `safe` somehow.
Interesting. This is definitely the thing to do since `build_absolute_uri` already returns an _uri_ but I assume the removal of the double escaping might generate a new key. Not a big deal but maybe something worthy of a release note.
I think we should use a separate message because the current can be misleading, e.g.: ```suggestion if self.query.combinator and (args or kwargs): raise NotSupportedError( 'Calling QuerySet.get(...) with filters after %s() is not ' 'supported.' % self.query.combinator ) ```
These tests should be moved to a separate commit.
This can be single-lined.
OK, it was just a shot in the dark :dart:
I would chop blank lines in this test.
Maybe: ```suggestion self.assertSequenceEqual(x.lists(), [('a', [3])]) ``` I think we can use the same in below tests.
I think these are too internal, I would rather check that `MultiValueDict` is pickleable: ```python pickle.loads(pickle.dumps(...)) ```
This can be single-lined.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
Chop `Ensure that`.
`test_date_kind()` and `test_time_kind()` in `test_trunc_func_with_timezone()` doesn't have any value because both don't support timezones and are already covered by `test_trunc_func()`. I removed them.
`error_msg` -> `msg`
I think we should move: https://github.com/django/django/blob/3d4ffd1ff0eb9343ee41de77caf6ae427b6e873c/django/db/backends/sqlite3/base.py#L433-L444 to a separate hook and call it only if `tzname is not None`. With that we could avoid unnecessary workarounds such as added in `typecast_time()`.
I'm not sure about these changes, `test_touch` fails quite often even with longer delays.
`Book` model doesn't have the `first_book` attribute, moreover this test is not related with fix. I think we can chop it.
`Value` wrapping and `output_field` is unnecessary on the main branch ```suggestion annotated_field=2, ).filter(order__gte=6) qs2 = ReservedName.objects.annotate( annotated_field=1, ``` or ```suggestion annotated_field=Value(2), ).filter(order__gte=6) qs2 = ReservedName.objects.annotate( annotated_field=Value(1), ``` both work
It should be enough to add a list of missing fields, e.g. ```python _('ManagementForm data is missing or has been tampered with. Missing fields: %s') % ', '.join(form.errors), ```
We didn't change anything in building frames so it's enough to check that frames are not empty.
What do you think about moving the logic from the loop to a separate hook (as suggested by Chris)?, this will create a separation between iteration through exceptions and their tracebacks e.g. ```python def get_traceback_frames(self): ... frames = [] # No exceptions were supplied to ExceptionReporter if not exceptions: return frames # In case there's just one exception, take the traceback from self.tb exc_value = exceptions.pop() tb = self.tb if not exceptions else exc_value.__traceback__ frames.extend(self.get_inner_traceback_frames(exc_value, tb)) while exceptions: exc_value = exceptions.pop() exc_frames = self.get_inner_traceback_frames(exc_value, exc_value.__traceback__) frames.extend(exc_frames) return frames def get_inner_traceback_frames(self, exc_value, tb): frames = [] exc_cause = self.explicit_or_implicit_cause(exc_value), exc_cause_explicit = getattr(exc_value, '__cause__', True) while tb is not None: # Support for __traceback_hide__ which is used by a few libraries ... frames.append({ 'exc_cause': exc_cause, 'exc_cause_explicit': exc_cause_explicit, 'tb': tb, 'type': 'django' if module_name.startswith('django.') else 'user', 'filename': filename, 'function': function, 'lineno': lineno + 1, 'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame), 'id': id(tb), 'pre_context': pre_context, 'context_line': context_line, 'post_context': post_context, 'pre_context_lineno': pre_context_lineno + 1, }) tb = tb.tb_next return frames ``` Probably, this could be simplified even more.
I didn't suggest using a single loop, but two nested loops, first by exceptions and the second by traceback frames for each exception. Using a single loop is not readable and causes tests failures.
We can mock only `flush()`, e.g. ```python out = StringIO() with mock.patch.object(out, 'flush') as mocked_flush: management.call_command('outputwrapper', stdout=out) self.assertIs(mocked_flush.called, True) ```
We can chop these lines.
`assertTrue()` -> `assertIs(..., True)`
Hi again. Please revert these unrelated blank line changes. The idea is to keep diffs small when contributing patches, which helps reviewers and anyone else using the commit history in the future. You should only have needed blank line changes around the new test method you contributed.
I suggest all caps for HTTPS.
`update_fields` can be any iterable, `iter({}) -> dict_keyiterator` ```suggestion obj.save(using=self.db, update_fields=defaults) ```
> And yes it feels wasteful, but what are the options? I guess `Options` could have a private `cached_property(_concrete_field_names -> frozenset)`. It seems niche enough to be kept private but worth it given this set is computed on every `Model.save(update_fields)` call and on every `QuerySet.update_or_create` call after this PR.
You'd need to either include both `f.name` and `f.attname` or use `self.model._meta.get_field(name)` for each `defaults` which I think supports both form e.g. ```python get_field = self.model._meta.get_field update_defaults = True for default in defaults: try: field = get_field(default) except FieldError: break if not field.concrete: break else: update_defaults = False ```
Perhaps the following to avoid constructing a new set unnecessarily: ```suggestion if fnames.issuperset(defaults): ```
I think this should include non-concrete local field as well since `select_for_update` will lock at tables involved in MTI and `Model.save` handles it just fine.
To avoid duplication, this could call the method in its new location with `AbstractUser.normalize_email`.
Copy the style of other warnings in the code base ```suggestion warnings.warn( 'BaseUserManager.normalize_email() is deprecated in favor of ' 'AbstractUser.normalize_email() and will be removed in Django 4.1.', RemovedInDjango41Warning, stacklevel=2, ) ```
Right - you want to compare the `__func__` attributes of the bound methods, which point to their underlying functions: ``` In [4]: UserManager.normalize_email.__func__ is BaseUserManager.normalize_email.__func__ Out[4]: True ```
I would add something above like `When the active locale is English (en):`
I moved this test to the `tests/template_tests/filter_tests/test_floatformat.py`.
I'd rather talk about the `active thousand separator` (maybe linking to topics/i18n/formatting/?) instead of mentioning the `USE_L10N` setting. Same below in the docs.
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
Something like `id=1` here would also work just as well. Not sure if you rejected that for some reason.
I'm going to pull the `strict=True` out here. Refs ticket-31912
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
Chop blank line.
```suggestion self.assertContains( response, '<h1>Oh no, an error occurred!</h1>', status_code=500, html=True, ) ```
```suggestion description=gettext_lazy('Delete selected %(verbose_name_plural)s'), ```
It's a little confusing to not signpost the mismatch between the attribute names. Especially the wording "the attributes" sounds like they should be the same. Perhaps ```suggestion This is equivalent to setting some attributes (with the original, longer names) on the function directly:: ```
Here is the explanation I wrote some time ago :) https://python.astrotech.io/advanced/function/parameter-syntax.html
Was just thinking through what this means for ordering of arguments. `function` is a defaulted argument that may be passed positionally *or* by keyword. So `action(permissions=..., function=...)` worked. I think what we'd want ideally is `def action(function=None, /, permissions=None, description=None):`, making `function` positional only with a default, but that's only available on Python 3.8+. Anyway, just a curiousity really, I think the signature is fine as-is and unlikely to cause problems since the other arguments are named-only.
```suggestion Conveniently add attributes to a display function:: ```
> Actually, I think we'd want def action(function=None, /, *, permissions=None, description=None): to enforce that function is positional-only and description and permissions are keyword-only. Ah yes, my bad! Gosh these separators are a bit tricky :)
```suggestion Conveniently add attributes to an action function:: ```
Black won't mind. 😀
Line break for future black compat? 😇 ```suggestion @action_method( permissions=['delete'], description=gettext_lazy("Delete selected %(verbose_name_plural)s"), ) ```
`DEFAULT-CHARACTER-SET` is not a supported option. Please remove it. ```suggestion charset = settings_dict['OPTIONS'].get('charset') ``` This ticket is about passing `charset` to the underlying tool not about adding a new setting.
We should add `charset` to `OPTIONS`: ```suggestion 'OPTIONS': { 'charset': 'utf8', }, ```
This is what we want to test. Please restore `'--default-character-set=utf8'` in this line.
Please remove `DEFAULT-CHARACTER-SET` from all tests.
I don't see much value in `See method().` docstrings when it's only `sync_to_async()` call. Please remove it from `aadd`, `aget`, `aset`, `atouch`, `adelete`, `ahas_key`, `adecr`, `aclear`, and `aclose`.
I don't think there is a need to copy docstrings from sync variants, maybe only: ```python """See get_many().""" ```
```suggestion if val is not self._missing_key: ``` Can you rebase and check other methods? they should be synchronized with sync variants.
```suggestion await self.aadd(key, default, timeout=timeout, version=version) # Fetch the value again to avoid a race condition if another caller # added a value between the first get() and the add() above. return await self.aget(key, default, version=version) ```
```suggestion return await self.aget(key, version=version) is not self._missing_key ``` Please check all new methods.
So we should probably use the enum here. Something like: ```suggestion self.assertEqual(FirstNames.JOHN.value, f.clean(FirstNames.JOHN)) ```
I think the current form is fine. I would leave it.
While we're here... `token that is invalidated`
It will be more readable with f-string, IMO: ```suggestion return f'{user.pk}{user.password}{login_timestamp}{timestamp}{email}' ```
`func` is called even if no transaction is in progress, so we should move this to the first line. Fixed.
I would raise a `TypeError`, e.g.: ```suggestion if not callable(func): raise TypeError("on_commit()'s callback must be a callable.") ```
I think we should update assertions, instead of passing `repr`.
You can also use `.bulk_create()`.
This is nice. Worth the change.
I have a feeling something else if off here. The outer query's joining strategy should not have to special case inner queries as they are self contained expressions. My guess is that something is getting mixed up wrt to aliases because the same model is being involved in the outer and inner queries.
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
Why we're adding a constraint manually and not with `AddConstraintNotValid()`? Also, please use hanging indentation.
redundant, remove ```suggestion ```
This should likely be `'%s_validate_%s'`
Might be worth adjusting `migration_name_fragment` here as well to include a `not_valid` suffix.
`constraint_name` should also be quoted.
IMO we shouldn't inherit from `IndexOperation` it's misleading and we do this only to have the `model_name_lower` property.
I would chop _" on all existing rows"_.
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
Chop blank line.
It's too descriptive, IMO: ```suggestion Add a table constraint without enforcing validation, using PostgreSQL's NOT VALID syntax. ```
```suggestion """Validate a table NOT VALID constraint.""" ```
Chop blank line.
Maybe: ```'Create not valid constraint %s on model %s'```
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
You can use `super()`: ```suggestion return super().migration_name_fragment + '_not_valid' ```
We should add check for other constraints types and raise `NotSupportedError`.
You don't need to catch and reraise the exception: ```python with self.assertRaisesMessage(ProtectedError, msg) as cm: a.protect.delete() self.assertEqual(cm.exception.protected_objects, [a]) ```
This looks unnecessary, because we compare with a one-item list :thinking: (the same in L791).
I think you can to exclude conditional unique constraints here ```suggestion if not cls._meta.get_field(cls.USERNAME_FIELD).unique and not any( isinstance(constraint, models.UniqueConstraint) and constraint.fields == (cls.USERNAME_FIELD,) for constraint in cls._meta.total_unique_constraints ): ``` Kind of wish there was a way to avoid checking both the field and `cls._meta.total_unique_constraints`.
This is redundant because `total_unique_constraints` returns only `UniqueConstraint`s.
`self.assertFalse()` -> `self.assertIs(..., False)`
Don't include tickets numbers in test methods, e.g. ```suggestion def test_aggregation_random_ordering(self): ```
This assertion is not related with the patch. Please remove it.
Ah of course... 👀
Note that there are decorators that are using the same approach, e.g. `csrf_exempt()` :wink:
`` ```suggestion return resolve(path, urlconf) ```
IMO supporting a typical usage is not enough in this case, because `no_append_slash` should be used to avoid enumerations, so it's security-related, like `csrf_exempt`. It must be bulletproof, without any side effects.
Note that there are similar decorators that add attributes to functions in the works [here](https://github.com/django/django/pull/13483/files#diff-3fd16120fca44bdc94983057b9c28e7e815ed56a44f74fee21c2ddfac5cee2acR115-R139) and [here](https://github.com/django/django/pull/13532/files#diff-fd2291d1e25086ffa9e332f7bb4d16800501b7944a3659b1e5eb0a34e6ac924cR1-R60) that are not using this approach.
Yes, but I have to ask why? I get that there is a side effect, but how much of a problem is this? I can potentially see the problem if you do the following: ```python def view(request): ... wrapped_view = no_append_slash(wrapped_view) # Now both ``view`` and ``wrapped_view`` have ``should_append_slash`` set which # means using ``view`` might not do what you expect. ``` But typically you're going to do the following: ```python @no_append_slash def view(request): ... ``` Which would be no different to assigning the attribute directly after the function is created if not using a wrapper function: ```python def view(request): ... view.should_append_slash = False ``` I was concerned that there may be an issue if you wanted to do something like the following, but it turns out that `functools.wraps()` also copies attributes other than `__name__` and `__doc__` so this works fine: ```python @csrf_exempt @no_append_slash def view(request): ... ``` But it also effectively translates to having to call three functions, the outer two which have no benefit other than to have copies of all of the attributes of the functions within them. This has some call overhead and, if there are many decorated functions, excess memory use to store all these additional function objects and extra attributes as they bubble up.
You can delegate it to `self.default` https://github.com/django/django/blob/197b55c53469cf8344d1ba35175236780cb83bd1/django/db/models/expressions.py#L751-L752 ```suggestion if not self.cases: return self.default.get_group_by_cols(alias) ```
What if `default` is not a constant but a field reference? e.g. `F('integer')`
I've noticed that we missed a `prefix` here. Fixed.
I'm sorry but it's still the same :shrug: . You can manipulate with tests to create an unreachable state where you will get an expected message but that's not the correct solution. Please check an [attached project ](https://code.djangoproject.com/raw-attachment/ticket/25370/ticket_25370.tar.gz) and try to run: ``` $> python manage.py makemigrations ``` it raises: ``` ValueError: Error during <django.db.models.fields.IntegerField> serializing: Cannot serialize function: lambda ```
No it's not, without this patch it raises, e.g. ``` ValueError: Cannot serialize function: lambda ``` with this patch: ``` ValueError: Error during <django.db.models.fields.IntegerField> serializing: Cannot serialize function: lambda ``` It's not more descriptive, IMO. You can have hundreds of `IntegerField`s in dozens of apps. I would expect: ``` ValueError: Error during 'test_app.models.MyModel.field_1.default' serializing: Cannot serialize function: lambda ``` I don't see much value in this change if it's not feasible to get `<app label>.<model name>.<field name>.<parameter>` or at least `<app label>.<model name>.<field name>`. Maybe we should fix this in `FunctionTypeSerializer`, it should be doable to get at least `test_app.models.MyModel` from `__qualname__` and `__module__` :detective:
I don't see a reason for modifying a source exception, you can use: ```python raise ValueError(...) from e ``` Also `blew up` is not a appropriate wording and a new exception is not more informative because it refers to the field class `... the field <django.db.models.fields.CharField>` instead of `<app_label>.<model_name>.<field_name>`, maybe: ```python raise ValueError('Error during %s serializing: %s' % (field, e)) from e ``` I don't have a quick answer how to get a field path.
Thanks for updates :+1: > ... but I had trouble getting the field name, any ideas on that one? Unfortunately not, moreover I'm afraid that we will not be able to get `<app label>.<model name>.<field name>` or even `<app label>.<model name>` in a reliable way. We serialize `field` from `django.db.models` not a model attribute, that's why it's complicated or even not feasible. Each approach doesn't work in some cases, e.g. constructing messages in the `FunctionTypeSerializer` will not work for `lambda`s defined in the module: ``` Error during serializing test_one.models.<lambda>: ... ``` or imported from other modules: ``` ValueError: Error during serializing test_one.utils.<lambda>: ... ``` I think we should close this as wontfix :disappointed:
```suggestion "%s() prohibited to prevent data loss due to unsaved " "related object '%s'." % (operation_name, field.name) ```
Can we pass `operation_name` and keep the previous message? ```suggestion def _prepare_related_fields_for_save(self, operation_name): ```
OK, let's keep it.
Maybe: `EmployeeRange = namedtuple('EmployeeRange', 'minimum maximum')`
We want to get rid of `repr` in `assertQuerysetEqual()`, can we change to the `self.assertSequenceEqual()`, e.g. ```python @classmethod def setUpTestData(cls): ... cls.c5 = Company.objects.create(name='99300 Ltd', num_employees=99, num_chairs=300, ceo=ceo) def test_range_lookup_namedtuple(self): EmployeeRange = namedtuple('EmployeeRange', 'minimum maximum') qs = Company.objects.filter( num_employees__range=EmployeeRange(minimum=51, maximum=100), ) self.assertSequenceEqual(qs, [self.c5]) ```
We can use `_make` to detect a `namedtuple` but I would still use encapsulation ``` return type(value)(*values) ```
This will always return the same as `self.db_type()` which is not intended. I added `__mro__[1:]` to fix this.
I _think_ this will fail on some backends though due the conditional logic off `related_fields_match_type`.
That seems a bit brittle wrt to `PositiveBigIntegerField` subclassing or subclasses. What about using `__init_subclass__` to determine it from the MRO at class creation ```python class PositiveIntegerRelDbTypeMixin: def __init_subclass__(cls, **kwargs): super().__init_subclass__(**kwargs) if getattr(cls, 'integer_field_class', None) is None: integer_field_class = next(( parent for parent in cls.__mro__ if issubclass(parent, IntegerField) ), None) ``` and then ```suggestion return self.integer_field_class().db_type(connection=connection) ```
Can't believe we missed that one 🤦
I think that this will make it hard to override for third-party backends that run the test suite (e.g. see the recent commits of @timgraham for Cockroach DB).
This docstring spends a lot of time explainining the problem. I think it can be edited down to something a little more terse to make the class more maintainable. Perhaps: > Represents a failed test or SubTest for use in parallel testing. Needed as not all attributes of a `TestCase` may be pickleable, so this class extracts only those needed to report the error in the main process.
Please use at most one underscore, double underscores trigger name mangling which makes subclasses easier to use.
What does DTO stand for? I think it'd be better to use a spelled out name for this class
```suggestion "Year, 2 digits; e.g. '99', with leading zeros." ``` We should also update `date` [docs](https://docs.djangoproject.com/en/3.1/ref/templates/builtins/#date) for the `y` format add a small `versionchanged` annotations below the table with formats.
What do you think about? ```suggestion return '%02d' % (self.data.year % 100) ```
I'm not sure we want to allow the hyphen, I thought this patch was partly there to avoid those in locale names.
Could you try to use subTests? You can grep other tests to see how it is used by Django.
I added `continue` to skip processing invalid locales.
We don't need to test multiple cases because we want to ignore only locales with hyphens.
You don't need to check each part separately.
This change is not tested and I'm not sure if it's excepted. I would focus on improving an error message.
Maybe: ```suggestion "file %s. Make sure the 'locale' directory exist in an " "app or LOCALE_PATHS setting is set." ```
This is a WIP note to self by me. (TO DELETE 😀)
This looks like a bad-merge. The code has been changed since the first patch so we'll need to adjust.
~Never mind, looks it's the other way around. Works on 3.6, fails on 3.8.~ had an old Python 2.7 interpreter lying on my path 🤦
Not sure of the motivation behind these changes but this could be reduced to the following? ```suggestion attrs['declared_fields'] = { key: attrs.pop(key) for key, value in attrs.items() if isinstance(value, Field) } ```
Alternative using reduce: ```python import operator from functools import reduce def all_valid(formsets): return reduce(operator.and_, (f.is_valid() for f in formsets), True) ```
```suggestion # List comprehension ensures is_valid() is called for all formsets. ```
For what reason? Doesn't `all()` work fine on generators? (Typically we still use list comprehensions for `str.join()` as it converts to a list internally anyway.)
We could use `Mod()`, e.g. ```python self.assertIs( User.objects.annotate(odd_serial=Mod('serial', 2)).filter(odd_serial=1).exists(), False, ) ```
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
Remove the unused import.
```suggestion self.assertEqual(value, b'text/plain') ```
```python follow = extra.pop('follow', None) if follow is not None: s['follow'] = follow s['headers'].extend((key.lower().encode(), value.encode()) for key, value in extra.items()) ```
Or maybe it would be better to extract `follow` from `extra` like this: ```python def generic( self, method, path, data='', content_type='application/octet-stream', secure=False, follow=False, **extra, ): ... if follow: s['follow'] = follow s['headers'] += [(key.lower().encode(), value.encode()) for key, value in extra.items() if key] ``` or like this: ```python def generic( self, method, path, data='', content_type='application/octet-stream', secure=False, follow=False, **extra, ): ... s['headers'] += [(key.lower().encode(), value.encode()) for key, value in extra.items() if key] ... return self.request(follow=follow, **s) ```
```suggestion attrgetter('pk'), ```
Book PKs are assumed to be in order, which may not be true on CockroachDB. ```suggestion sorted([self.b1.pk, self.b4.pk, self.b5.pk, self.b6.pk]), ```
Do we need to use custom function? We could test the same using `JSONBAgg('char_field', distinct=True/False)`, e.g. ```python def test_jsonb_agg_distinct_false(self): values = AggregateTestModel.objects.aggregate( jsonbagg=JSONBAgg('char_field', distinct=False), ) self.assertEqual(sorted(values['jsonbagg']), ['Bar', 'Foo', 'Foo']) def test_jsonb_agg_distinct_true(self): values = AggregateTestModel.objects.aggregate( jsonbagg=JSONBAgg('char_field', distinct=True), ) self.assertEqual(sorted(values['jsonbagg']), ['Bar', 'Foo']) ```
I don't understand why this is here? Also why not `value.total_seconds()`? Or am I missing something? ```python >>> from datetime import timedelta >>> delta = timedelta(microseconds=90000000123) >>> delta datetime.timedelta(days=1, seconds=3600, microseconds=123) >>> delta.microseconds 123 >>> delta.total_seconds() 90000.000123 ```
```suggestion # JSON ```
This should be set only for values.
This doesn't cover `TextField`.
but OK let's have it.
IMO we don't need an extra check and `test_no_caches` test.
Wrap at 79 chars.
I think it should be a `deploy` check.
I've changed it to a deploy check because it's not really an issue in a local environment.
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
You can use `Path.is_absolute()`.
Why `LocalBasedCache`? I think we can chop it.
Chop all blank lines in `check_file_based_cache_is_absolute()`.
```suggestion id='caches.W003', ```
It's always better to assert with an excepted value, not only check if a test doesn't crash, so I switched to `django-admin help shell`.
```suggestion def test_stdin_read_inline_function_call(self, select): ```
I would chop this docstring.
```suggestion script_with_inline_function = ( 'import django\n' 'def f():\n' ' print(django.__version__)\n' 'f()' ) ```
I think we can chop it.
I think we should use `globals()` ```suggestion exec(options['command'], globals()) ``` some commands will crash with an empty globals, e.g. ``` >>> python -m django shell -c <<EOF " def f(): with open(__file__, 'r'): pass f()" EOF ... File "/django/django/core/management/commands/shell.py", line 88, in handle exec(options['command'], {}) File "<string>", line 5, in <module> File "<string>", line 3, in f NameError: name '__file__' is not defined ```
Please don't use a ticket numbers in tests, maybe: `script_with_inline_function`.
We have two more options that are not supported on Oracle, co maybe we should add a set with supported options and handle all of cases in a single feature, e.g. ```python supported_geojson_options = {'bbox', 'crs', 'precision'} ```
> That seems good. My only concern is that it's unclear if the flags that apply to a single database are truly generalizable. For example, there's also: Yes, but we have at least a few less vendor checks, and it seems better than three feature flags `supports_geojson_(crs/bbox/precision)`. > I feel like we'll have to continue some vendor checks. Unfortunately, yes.
Minor but I think a warning will be raised here as this is passing a naive datetime will timezone support is enabled.
Timezone support is disable by default and we use naive datetimes in many tests. I think we can leave it.
I guess these could be merged by doing a ```python self.assertEqual( qstr.count("LIMIT 1"), 3 if connection.features.supports_limiting_in_compound else 1 ) ```
I think using `connections[DEFAULT_DB_ALIAS]` is acceptable here as we even do it at a higher level (e.g. feature detection in `django.db.models`) but if we truly wanted to perform the check against a database the following minimal changes would allow you to use the proper database alias ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index c596ccfe5d..e356a5f981 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -1116,10 +1116,10 @@ def copy(self): def external_aliases(self): return self.query.external_aliases - def as_sql(self, compiler, connection, template=None, **extra_context): + def as_sql(self, compiler, connection, query=None, template=None, **extra_context): connection.ops.check_expression_support(self) template_params = {**self.extra, **extra_context} - subquery_sql, sql_params = self.query.as_sql(compiler, connection) + subquery_sql, sql_params = (query or self.query).as_sql(compiler, connection) template_params['subquery'] = subquery_sql[1:-1] template = template or template_params.get('template', self.template) @@ -1142,7 +1142,6 @@ class Exists(Subquery): def __init__(self, queryset, negated=False, **kwargs): self.negated = negated super().__init__(queryset, **kwargs) - self.query = self.query.exists() def __invert__(self): clone = self.copy() @@ -1150,7 +1149,9 @@ def __invert__(self): return clone def as_sql(self, compiler, connection, template=None, **extra_context): - sql, params = super().as_sql(compiler, connection, template, **extra_context) + sql, params = super().as_sql( + compiler, connection, template, query=self.query.exists(connection.alias), **extra_context + ) if self.negated: sql = 'NOT {}'.format(sql) return sql, params diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index a7dadf5a40..0d29aa28f3 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -525,7 +525,7 @@ def get_count(self, using): def has_filters(self): return self.where - def exists(self): + def exists(self, using): q = self.clone() if not q.distinct: if q.group_by is True: @@ -541,7 +541,7 @@ def exists(self): return q def has_results(self, using): - q = self.exists() + q = self.exists(using) compiler = q.get_compiler(using=using) return compiler.has_results() ```
I wonder if we want a database feature here for which backends support limiting within a combined query could be useful.
These assertions are redundant with tests where `qs1.difference(qs2).exists()` is `True`.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
I think we can move `supports_get_with_default` to test classes, revert changes in `BaseMemcachedCache` and `MemcachedCache`, and change `_sentinel` to a class property: ```python class BaseCache: _missing_key = object() ``` What do you think? this should simplify removing `MemcachedCache` when deprecation ends.
I would call it `_missing_key`, that's clearer, IMO.
I we're aiming for the lowest storage size we use `ensure_ascii=False` as well ```suggestion kwargs.setdefault('separators', (',', ':')) kwargs.setdefault('ensure_ascii', False) ```
This test is not related with the patch, I will move it to a separate commit.
These lookups are registered only for the `ArrayField`s, so this check is not necessary.
I wonder if [inspect.isclass](https://docs.python.org/3/library/inspect.html#inspect.isclass) wouldn't be clearer here? 🤔
This too. I meant for both of the checks to be via `check()`.
I see. I think then branch on the `message` and keep the raised error the same. (It makes no sense that we have `ImproperlyConfigured` for one case and `TypeError` for another.)
Chop blank line.
```suggestion errors = [] ```
```suggestion (self.pattern, view.__qualname__, view.__qualname__), ```
This error is raised when instantiating so we don't need to include a `route` in the message.
```suggestion (route, view.__name__, view.__name__) ) ```
I would revert this change. We want to add a system check so this seems redundant.
There is no need to split this into multiple assertions: ```suggestion self.assertEqual(check_url_config(None), [ Error( 'URL route ...', id='urls.E009', ), ]) ```
Feels like `--ignore-conflicts` would be a better fit if we want to move forward with this option.
Maybe we should keep this and rephrase to "To use one of the built-in backends, use 'django.db.backends.XXX', where...
> I think the test for using a related field without a transform already exists - isn't that what `test_joined_annotation` does? Ahh, yes :+1:
We can remove an aggregation (which is not important for this test) and chop `@skipUnlessDBFeature`.
yeah I think it would be worthwhile to at least test a single JOIN scenario.
yeah you're right, the previous test was affected by the silent truncation of transforms from field references as reported by users. I think the original intent was to do `count=Count('value')` and not `Count('value__d__0')` though so I'd switch it to do the latter.
Thanks, I've checked only `annotations` and `aggregation` tests.
> Can you tell me how do I open my issue for django I am new to django and github I have some questions about django this may be help https://code.djangoproject.com
I have mixed feelings because in other places we check the `resolve_expression` attribute, which we cannot use here 🤔. Neither solution is perfect 😐
```suggestion return super().get_group_by_cols() ```
I'm not sure about using `Expression` here (see similar doubts in #13165) :thinking: I would rather use `WhereNode`, e.g. ```suggestion if not isinstance(self.expression, WhereNode): ``` \cc @charettes
yeah I think that the crux of the issue is that `Q` and what it resolves to are not expression here but that would be an invasive change to backport. Feels kind of strange to wrap a non-`Expression` in an abstraction called `ExpressionWrapper`.
I don't have a strong opinion here as that's probably the only type of non-`Expression` wrapper supported in `ExpressionWrapper` but the previous `if isinstance(self.expression, Expression)` felt more correct.
Above `tests` entries could drop the `[]` wrapping if you use `QuerySet.get` here ```suggestion self.assertEqual( queryset.values_list(lookup, flat=True).get(), expected ) ```
We can reuse existing `'a': 'b'`.
These lookups are duplicated in the list.
From what I understand, the point of being able to turn off durability checking (via `ensure_durability`) is that durable atomic blocks _will_ be able to be run within a `TestCase`. So I think it's correct that it should ignore, rather than error.
Typo in the test name.
Ok great. +1 to prefixing the attribute with an underscore.
One day, black will do this for us
I think we should raise an error if someone is trying to use `durable` in the `TestCase` class, instead of ignoring it, e.g. ```python if self.durable and not self.ensure_durability: raise .... ```
This flag is ignored when `ensure_durability` is `False`, so we should inform users that is not allowed, e.g. ```diff (django-test) git:pr/13708 felixx@felixx-A555:~/repo/django/tests> git diff diff --git a/django/db/transaction.py b/django/db/transaction.py index c6ba346a99..8a84b97237 100644 --- a/django/db/transaction.py +++ b/django/db/transaction.py @@ -172,6 +172,11 @@ class Atomic(ContextDecorator): self.using = using self.savepoint = savepoint self.durable = durable + if self.durable and not self.ensure_durability: + raise ValueError( + 'A durable atomic block is not allowed. If you are running ' + 'tests, you must use TransactionTestCase, not TestCase.' + ) def __enter__(self): connection = get_connection(self.using) ``` We can be descriptive here.
```suggestion """ ```
Right :+1: OK let's leave it as it is.
~~I've switched `except` to `finally`~~. Reverted.
Unfortunately this doesn't work on Oracle where bind variables are not supported in DDL statements: ``` django.db.utils.DatabaseError: DPI-1059: bind variables are not supported in DDL statements ``` We should use a solution similar to that used in the functional indexes.
Maybe: ```suggestion supports_expression_defaults = True ```
Feels like this should be handled at the database backend level.
The fact you have to special case `DefaultNow` makes it look like a code smell to me, this logic should be completely abstracted by whatever is allowed to be passed to `db_default`.
This is off, if the backend doesn't `supports_functions_in_defaults` the expression will be wrapped in `Value`.
Only literal values of functions with literal values arguments should be allowed here. No _resolving_ phase should be necessary if an expression is provided, the only requirement should be an `as_sql` function that gets passed a `compiler` and a `connection` through `compiler.compile`. The way it's currently defined is too lax because it allows field references and event JOINs
This bi-directionnaly couples the model layer with the schema editor and should be avoided, only `connection` should be necessary. `model` is also already available through `self.model` assuming the field is bound otherwise it should not make a huge difference since no field references should be resolvable.
I think we should adjust `Now` instead, the fact it has an `output_field = DateTimeField` but returns an incompatible datatype is the crux of the issue here.
This should not be necessary as not reference to non-litteral values should be allowed in here.
Do we need a new flag? IMO it's unnecessary. It should be feasible to detect this automatically in the system check, e.g. with `_get_expr_references(expression)`.
Please move these tests to the `invalid_models_tests/test_ordinary_fields.py`. Also, we could move a new system check with tests to a separate commit, it would be easier to review.
I guess we could defer `check_field_default_support` to a system check instead? It could also be performed in `db_default_sql` for good measure.
What I mean is that it should not be allowed to pass expressions of the form `Lower('foo')` (reference to a field) but your patch currently allows that and has inherent complexity because it does (e.g. `resolve_expressions`). Only expressions that resolve to SQL literals or functions with all of the arguments resolving to SQL literals (on backends that support it) should be allowed here. Feels like we need a backend hook similar to `supports_expression` (e.g. `supports_field_default_expression`) that could be called by a check and called again on compilation attempts.
Can `schema_editor.quote_name` be used here instead? ```suggestion schema_editor.quote_name(value) if isinstance(value, str) else value ```
Do we want to allow setting both `default` and `db_default`? Might make sense if one only wants to use `db_default` during a deploy to prevent downtime.
minor improvement ```suggestion now = datetime.now() a = DBArticle.objects.create() ```
```suggestion now = datetime.utcnow() a = DBArticle.objects.create() ```
```suggestion default_sql = '%s' ```
```suggestion new_field.get_internal_type() in ('CharField', 'TextField')): ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
Don't sqlite have the same issue as illustrated by `test_field_database_defaults_sqlite`? Once solution might be to use `STRFTIME('%Y-%m-%d %H:%M:%f', 'NOW')` on sqlite but it appears like it only supports 3 digits when the expected precision is 6.
It would work but it would be a kind of implementation detail abuse since `value` is not an SQL identifier but an expression. This whole method should likely live on `connection.ops` instead.
I like how simple of a change that is :)
`Error` makes more sense to me.
Assuming we don't wrap `db_default` in `Value` in `Field.__init__` could this be simplified to ```suggestion def db_default_sql(self, field): """Return the sql and params for the field's database default.""" db_default = field.db_default if not hasattr(db_default, 'resolve_expression'): return '%s', db_default query = Query(model=field.model) compiler = query.get_compiler(connection=self.connection) sql, params = compiler.compile(field.db_default) return '(%s)' % sql, params ``` Looks like subclasses overrides should be pretty straightforward as well.
Maybe it should go in `django.contrib.mysql`...
Make sure you use `format_lazy()` to prevent issues with translated strings: ```suggestion self.verbose_name_plural = format_lazy('{}s', self.verbose_name) ``` This is also consistent with the following: https://github.com/django/django/blob/c70cd2a926ffab47f6613e83e0c8828eb6c2c064/django/db/models/options.py#L188-L191
I think `self.connection.alias` should be used in `transaction.atomic`, exceptions also need to bubble through `transaction.atomic` ```python @cached_property def supports_json_field(self): with self.connection.cursor() as cursor: try: with transaction.atomic(self.connection.alias): cursor.execute('SELECT JSON(\'{"a": "b"}\')') except OperationalError: return False return True
I'm not sure where exactly in runtests.py (if you have trouble with it, I'll look it at, hopefully it's feasible) but no, not there. The logic should run regardless of what test runner is used. The idea is that `runtests.py` is used for running Django's tests suite. That's all we care about. The test runner that's used doesn't matter. Jenkins, for example, uses `TEST_RUNNER = 'xmlrunner.extra.djangotestrunner.XMLTestRunner'`. We still need the logic to run in that case.
This seems like an odd place to put this... between the logging of test database creation and the actual creation. Actually, it might be possible to call `connection.creation.mark_expected_failures_and_skips()` in `runtests.py`. That would be cleaner and eliminate the need for the environment variable.
It might work to reuse the code but currently there's the drawback that a "skip reason" isn't set.
This should only be called when the Django test suite is running. Perhaps with an environment variable which `runtests.py` could set, unless we can come up with a more elegant solution.
A docstring could be nice: "mark_expected_failures_and_skips() isn't called unless RUNNING_DJANGOS_TEST_SUITE is 'true'."
Oops, this should be `set()`. None of the subclasses implementations call `super()` which perhaps isn't necessary but I want the CockroachDB backend to call `super()` to get any skips/expected failures from the PostgreSQL backend (which the CockroachDB inherits),
It's here because `mark_expected_failures_and_skips()` is on `DatabaseCreation` (`creation.py`). `test_base.py` is for `DatabaseWrapper` (`base.py`).
This must be an inner skip, please revert (ticket-31888).
We cannot move these skips, because that will cause running queries before a test database is created, see 493b26bbfc9cc0ad223ece131741cba2312ced0f (ticket-31888).
Wrap at 79 chars.
Assuming this works, don't forget that we'll need some solution (like the environment variable used before) to only run `mark_expected_failures_and_skips()` when running Django's test suite.
I'm not sure if it's the best place for these tests :thinking:, maybe `backends/base/test_base.py`.
```suggestion # Widget.get_context() returns 'Geometry' instead of 'Unknown'. ```
```suggestion # Widget.get_context() returns expected name for geom_type. ```
```suggestion 'geom_type': 'Geometry' if geom_type == 'Unknown' else geom_type, ```
It seems odd to keep `'point'` here, even though it probably doesn't make much difference. ```suggestion context = widget.get_context('polygon', None, None) ```
```suggestion # The Widget.get_context() attrs argument overrides self.attrs. ```
Using `.name` would be better than `str()`: ```suggestion geom_type = gdal.OGRGeomType(self.attrs['geom_type']).name ```
```suggestion geom_type = gdal.OGRGeomType(self.attrs['geom_type']) ```
Likewise, it seems odd to keep `'point'` here: ```suggestion context = widget.get_context('geometry', None, None) ```
This patch fixes the issue for me, however new tests work even without it, so I don't think we need them. Unfortunately, it's more complicated then raising and error in the `setUpTestData()`.
This looks unrelated.
OK I figure out why it doesn't fail. `ErrorClassTest` must be the first one, because there is a single instance of `DebugSQLTextTestResult` so `debug_sql_stream` already exists if we run any test before it. Edits is progress ...
```suggestion RelatedPrepopulated, RelatedWithUUIDPKModel, Report, Reservation, ```
```suggestion City, Collector, Color, Color2, ComplexSortedPerson, CoverLetter, ```
This doesn't look like it is tested.
This doesn't look like it is tested.
It would be better to loop over key-value pairs here instead of using `initial[k]` numerous times below.
This regex looks wrong. If you're not extracting components of the regex, then why use it when you could just check that the string starts with `prefix_name`? But given that you are then using `args_list` which is `k` split up it suggests that you do actually want a proper regex with capturing groups. (Also note that when substituting a string into a regex, `re.escape()` should be used.)
You can reuse `CountryInlineAdmin` and `StateAdmin` instead of defining extra classes: ```suggestion ``` Add `get_formset_params()` to `StateAdmin`.
I think we'd call this `get_formset_kwargs()` normally.
Do you have a better example of why this would be useful? This can already be achieved in a _safer_ way doing ```suggestion query = "SELECT * FROM raw_query_author WHERE first_name like %s" qset = Author.objects.raw(query, ('J%',)) ```
`admin.admin` is not so smart, let's add a convenient import in `admin.__init__`
```suggestion RemovedInDjango50Warning, stacklevel=2, ```
Good catch :+1:
```suggestion with ignore_warnings(category=RemovedInDjango50Warning): ```
I'd move depracated classes to a separate line: ```suggestion 'GISModelAdmin', 'OpenLayersWidget', # RemovedInDjango50Warning. 'GeoModelAdmin', 'OSMGeoAdmin', ```
We could add a note about `OSMGeoAdmin`, e.g. ```suggestion 'django.contrib.gis.admin.GeoModelAdmin and OSMGeoAdmin are ' 'deprecated in favor of django.contrib.gis.admin.GISModelAdmin.', ```
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
I'd move the entire `geoadmin` folder to the `geoadmin_depracated`.
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
I think we should use `setdefault()` ```suggestion kwargs.setdefault('disabled', False) ``` There is no need to enforce `disabled` if someone specify if explicitly.
Only option would be to not test it I think… 🤔
```suggestion # Most clients (e.g. pymemcache or pylibmc) raise when the value is ```
```suggestion 'MemcachedCache is deprecated in favor of PyMemcacheCache and ' 'PyLibMCCache.' ```
That seems unfortunate. Not sure I have any good suggestions though.
Yeah. I think it was coincidentally alphabetical and more likely the order that they were implemented in.
Why we change the logic here? This patch shouldn't change anything in the `UserPassesTestMixin` implementation.
Can this fail with KeyError? It looks like that was transformed to InvalidCacheBackendError in the old code.
```suggestion pizzeria, = Pizzeria.objects.bulk_create([ ```
Should we use `next_concrete_model.from_db` here? https://github.com/django/django/blob/991dce4fc5b656e04af08a595181bd576f2bd857/django/db/models/base.py#L507-L518
I would change this to a `NotSupportedError`, e.g. ```python raise NotSupportedError( 'Bulk create a multi-table inherited model is not supported ' 'on this database backend.' ) ```
I think we should use `local_concrete_fields` :thinking: Also, the current solutions doesn't work with recursive parents, e.g. ```python Pizzeria.objects.bulk_create([ Pizzeria(name='Vegan Pizza House', rank=33), ]) ``` crashes when we add the `Ranked` model: ```python class Place(models.Model): name = models.CharField(max_length=100) class Meta: abstract = True class Ranked(models.Model): rank = models.IntegerField(null=True) class Restaurant(Ranked, Place): pass class Pizzeria(Restaurant): pass ```` ```
Oh, I thought it was referring to two separate issues. Alright then, I'll make a new PR and we can proceed from there
I think you want to allow an extra parameter when it's a class based view In other words ``` # Class based views always take two arguements, (self, request). ``` Is not not true ```suggestion if signature.parameters.get('self'): num_parameters += 1 args = [None] * num_parameters ```
This call should be done once at the module level, see e.g. `django/core/handlers/asgi.py`
maybe I'm being a stickler, but I'd make extra assertions on the log record's level and message
why not use `a_signal` in this test? The signal objects seem to be identical.
imo these test cases should reworked to use a `try/finally` pattern to ensure the receivers are always disconnected: ```python a_signal.connect(fails) try: # the test finally: a_signal.disconnect(fails) ``` Alternatively maybe they could construct the signal instances internally to the test methods.
I would move it to the `test_send_robust_fail()`.
Yes, we should check if it's on `ERROR` level: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ... self.assertEqual(cm.records[0].getMessage(), ...) ``` and assert a message (`cm.records[0].getMessage()`) and an exception info (`cm.records[0].exc_info`).
> As per your request @felixxm i have added checks on `ERROR` level also. `ERROR` is still missing.
`ERROR` in `assertLogs()` is still missing: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ```
Whilst we can't show the signal name, I suggest using `Signal.send_robust()` in the message, to provide a little more context: ```suggestion 'Error calling %s in Signal.send_robust() (%s)', ```
```suggestion self.assertDoesNotOptimize( ```
This optimization can't be allowed. What if `RunPython` pointed at a function that referenced specific fields? e.g. ```python def forwards(apps, schema_editor): apps.get_model('app.MyModel').objects.filter(field_a__lte=42).update(field_a=14) operations = [ migrations.CreateModel( 'MyModel', [ ('field_a', models.IntegerField()), ('field_b', models.IntegerField()), ], ), migrations.RunPython(forwards), migrations.RenameField('MyModel', 'field_a', 'field_c'), ] ``` `RunPython` are opaque operations that must be optimization barriers as they can refer to model definitions at any time. They require either to be marked as `elidable` if they can be removed or adjusted by users on migration squashing.
Randomly ordering ascii letters is unlikely to break this test, since the input will always end up being a string of ascii letters. The reason for using the random string is so that zlib won't compress it and shorten the length of the message. An alternative would be to hard code a random string of ascii letters that was 406 long. But if the message size changed, say as a result of the cookie storage limit changing, then the test would break.
Happily - I will get onto it today.
I see what you mean - with tests being run so often it's only a matter of time. To resolve it we can call `random.seed(seed + i)` in the for loop before the string is created. And set `seed = 42`(or some other int) outside the loop. This way we'll have a set of known good random strings that aren't the same. Since if they are the same the zlib compression will detect the duplication and compress them efficiently, since the messages are stored in a single cookie which is processed all at once. BTW I tested with the initial `seed =42` and it passes the messages tests.
New PR #13800 with tests
You've done well to limit the latin-1 charset to this class. :1st_place_medal:
I'm not sure about what best practices say about importing at top of file or here in the test method. A fellow will tell.
`The app label '%s' is not a valid Python identifier.`
So this can be done because we're not trying to _stream_ the zipped output anywhere, only write to a file. I came up with this which seemed to work well: ```python import pathlib, zipfile class SingleZipWriter(zipfile.ZipFile): def write(self, data): path = pathlib.Path(self.filename) name = path.stem if path.suffix == '.zip' else path.name return zipfile.ZipFile.writestr(self, name, data) ```
It just seems overkill when you are checking the string ends with a particular value.
Ah I see, okay then.
Right, I see. With the following: ```python f = SingleZipWriter('test.txt.zip', 'w') f.write('abc') f.write('123') f.close() ``` I get: ``` /usr/lib/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'test.txt' return self._open_to_write(zinfo, force_zip64=force_zip64) ``` Thanks for taking the time to look.
But as I said, I think that is a bad idea as it will have the wrong extension on it. The two acceptable choices to deal with this are: 1. Fail loudly as the user expected a compressed file. 2. Strip the extension and continue with an uncompressed file, but show a warning.
Alphabetized, here and in docs.
```suggestion filename='dumpdata.json.gz', ``` in all new tests.
```suggestion RuntimeWarning, ```
I know but it's not worth complexity, we can use ```python stream = open_method(output, 'wt', **kwargs) if output else None ``` in `dumpdata` and ```python with open_method(filename, 'rt') as f: ``` in tests.
Do we need a separate variable? I would include it directly in the `compression_formats`: ```python compression_formats['lzma'] = (lzma.open, {'format': lzma.FORMAT_ALONE}, mode) ```
True, thanks :+1:
`t` is unnecessary, IMO.
I don't see a reason to include `mode` in this method, we always return the passed value.
> My main worry here is: Is this correct and does it make sense to implement for such a complex hasher (notably we already have others where we argue it is simply not possible in a sensible way). > > Since scrypt can raise errors like this: > > > ValueError: Invalid parameter combination for n, r, p, maxmem. > > I am wondering if `must_update` couldn't also trigger this condition. Or can we always calculate `extra_iterations` and `extra_block` and be sure that the combinations are valid? You're right parameters may no be valid, e.g. ``` self.work_factor = 2 **14 decoded['work_factor'] = 2 ** 11 ``` both are a power of 2, however `extra_iterations = 14336` is not and raises `ValueError: n must be a power of 2`.
Thanks! I see that you included `maxmem` in a string returned by `encode`. Is there any reason it should be there? `maxmem` should not affect a hash
Should also update based on `block_size` and `parallelism`
Should also include `block_size` and `parallelism`
I would not allow customization of `n`, `r` and `p` here (other hashers do not allow that either).
I'm not sure, I don't think there is a need to do this per release. :thinking: `work_factor` must be a power of two and the OpenSSL limits memory usage to 32 MiB, so we would have to increase `maxmem` as well: :teacher: ``` (2 ** 15) * (2 * 8) * 64 = 33554432 = 32 MiB ```
Good point, updated :+1:
We confirmed that `parallelism` should be taken into account.
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
We can remove the `maxmem` argument and use `self.maxmem`. Updated.
I think it's worth, re-added.
Does it make sense to add the hasher here? It will not get used anyways *scratches head*
@kerkeslager `hashlib.scrypt` is a low-level function that takes multiple arguments. `maxmem` is one of them, it has a default value that does not suit all cases. Therefore, Django should allow changing the value. @ryowright has already made the necessary change. Note, `maxmem` does not affect generated hashes, its value should not be included in a string saved to a database and should not be compared in `must_update`.
I wouldn't sort this at the bottom of the file below all the insecure hashers.
This won't work anymore without `ScryptPasswordHasher` in `PASSWORD_HASHERS`.
Throught your patch, please use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Is there a good reason to order the data like this? I'd personally expect the hash to be at the end, so it could include a `$` .
We decided to leave similar asserts in other hashers. Users should not call `encode()` directly.
Subtests can be used here (with pairs `(key, expected)`).
Yes, but these assertions can fail only for users with an incorrect hash in the database. IMO `assert`s can stay here, if you think otherwise we can discuss changing them in all hashers in ticket-32508.
Subtests can also be used here.
You can use something like this (wrapping lines at 79 chars): ``` self.assertEqual( encoded, 'scrypt$16384$seasalt$Qj3+9PPyRjSJIebHnG81TMjsqtaIGxNQG/aEB/NYaf' 'TJ7tibgfYz71m0ldQESkXFRkdVCBhhY8mx7rQwite/Pw==$8$1' ) ```
Do we have any plan on how & when to upgrade those as time passes by? (ie like we have for pbkdf2)
Is it possible for these asserts (and below) to fail without a bug in Django? If so, proper exceptions should be raised a la: https://code.djangoproject.com/ticket/32508
Why we want to catch all exceptions? I would catch only `(signing.BadSignature, json.JSONDecodeError)`.
Fair, I didn't really think about which exceptions could all happen :)
I might have mixed up 4.0and 4.1 to be honest.
(And round-tripping of the messages is already tested in other tests)
All tests pass without this change, it looks unnecessary.
`primary_key_column_name` and `column_name` should also be quoted. `backends` tests will crash with, e.g.: ```diff diff --git a/tests/backends/models.py b/tests/backends/models.py index 9a786c4bbd..2d0ce2d2e6 100644 --- a/tests/backends/models.py +++ b/tests/backends/models.py @@ -72,7 +72,7 @@ class ReporterProxy(Reporter): class Article(models.Model): headline = models.CharField(max_length=100) pub_date = models.DateField() - reporter = models.ForeignKey(Reporter, models.CASCADE) + reporter = models.ForeignKey(Reporter, models.CASCADE, db_column='where') reporter_proxy = models.ForeignKey( ReporterProxy, models.SET_NULL, ``` or ```diff diff --git a/tests/backends/models.py b/tests/backends/models.py index 9a786c4bbd..87eb6c63c6 100644 --- a/tests/backends/models.py +++ b/tests/backends/models.py @@ -70,6 +70,7 @@ class ReporterProxy(Reporter): class Article(models.Model): + id = models.AutoField(primary_key=True, db_column='select') headline = models.CharField(max_length=100) pub_date = models.DateField() reporter = models.ForeignKey(Reporter, models.CASCADE) ```
This can be single-lined.
That's not the correct solution, with e.g.: ```python DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'OPTIONS': { 'service': 'django_ticket', } }, } ``` the connection parameters will be set to: ```python {'database': 'postgres', 'service': 'django_ticket'} ``` The default `postgres` db shouldn't be used in this case.
```suggestion service = options.get('service') ```
I've pushed small edits to remove the `quoted` kwarg.
True, but it's highlighted in most editors so I think it's better to avoid it.
I don't think we need to run the entire `test_load()`.
I think it's better to use `module_file` and don't override builtins.
Because these are names that are only used internally by Django.
> I've noticed that these "internal" names leak into migrations. Making this change will cause migrations to be generated when users upgrade. Are you sure? I didn't notice this in a sample project.
For example: ```python class OtherModel(models.Model): pass class OtherModelM2M(models.Model): m2m = models.ManyToManyField(OtherModel, related_name='+') ``` `makemigrations` didn't detect any changes with this PR.
@pope1ni Sure, but that's a separate issue not related with this patch.
> Perhaps when creating migrations we should ensure the value of `related_name` is forced to `'+'` if it ends with `'+'`? We could edit the following in `RelatedField.deconstruct()` to undo the changes made in `ManyToManyField.contribute_to_class()`: https://github.com/django/django/blob/74fd233b1433da8c68de636172ee1c9c6d1c08c9/django/db/models/fields/related.py#L324-L325 Or handle it specially in `ManyToManyField.deconstruct()`.
I would put any refactoring of "files" handling in a separate commit to make it easier to see whether this enhancement affects that handling.
I don't mind, but I'm not 100% sure why this method has the `_` prefix where others don't. 🤔 (This may have been covered in the discussion.)
Small nitpick, but can we please rename this variable? "expected" to me in this context means that the server would expect this value. I'd like a variable naming here that indicates it is coming from the client. The referer code below uses `referer` or `request_*`. I guess `origin` as well as `request_origin` would be fine (not sure how to call `expected_scheme` & `expected_netloc` though). Open to naming ideas :)
What about changing the signature to `_origin_verified(expected_origin, request_origin)` -- this way we'd decouple it from the request and would allow for easy testing. Granted the naming of the params might need a little bit of thinking but you get the idea :)
In comparision to the `Refer(r)er` check we loose the possibility to override the "initial" override of `get_host`. Would this be something to worry about -- not sure, just thinking out loud…
I had suggested doing this before computing `good_origin`: https://github.com/django/django/pull/13829#discussion_r579863426 That way you can avoid the two method calls and string construction in favor of a set membership check.
If I read correctly `origin_verified` isn't used anywhere else so we can simplify this to: ```suggestion # Reject the request if the origin header doesn't match an allowed # value. if 'HTTP_ORIGIN' in request.META and not self._origin_verified(request): return self._reject(request, REASON_BAD_ORIGIN % request.META['HTTP_ORIGIN']) if request.is_secure(): ```
Right, my bad.
By the way, something else that just occurred to me. It seems like this `for` loop could be simplified or eliminated if `self.allowed_origin_subdomains` were to instead cache a dict mapping scheme to hosts. For example, something like: ```python return any( is_same_domain(request_netloc, host) for host in self.allowed_origin_subdomains.get(request_scheme, ()) ) ```
But now it will never fall back to the referer check if the Origin header exists (no matter if the origin header validated fine or not)…
Yeah the settings dependent part could be moved into the `__init__` of the middleware I guess.
👍 Here's a random example if you needed one: ``` >>> urlparse('http://[') ValueError: Invalid IPv6 URL ```
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
Regarding the referrer checking, given the length and complexity of the containing function, I was thinking it would be good to have that in a separate function, too. But I didn't want to suggest changes outside the scope of your change. I think either signature you proposed would be an improvement. (Another option, in between, would be to pass `good_origin` and `request.META`.) Perhaps the decision can be guided by what the signatures would be for other portions of the logic if they were similarly broken out (for parallel structure).
Nope, I guess it is as good as it gets. One option would be to rename `allowed_origins` to `allowed_origins_exact` but not sure if this is worth it.
You could avoid an extra list creation by doing: ```python allowed_origins = [good_origin, *self.allowed_origins_exact] ``` Or you could avoid any list creations and skip extra request processing in some cases (fast path) by doing: ```python request_origin = request.META['HTTP_ORIGIN'] if request_origin in self.allowed_origins_exact: return True good_origin = '%s://%s' % ( 'https' if request.is_secure() else 'http', request.get_host(), ) if request_origin == good_origin: return True ``` Also, if you do that, you could make `self.allowed_origins_exact` return a set rather than a list since it's being used for a membership test.
```suggestion is_same_domain(request_netloc, host) for host in self.allowed_origin_subdomains.get(request_scheme, ()) ```
Is this accurate? From the looks of it, subdomains are only allowed if a '*' is in there.
Arg true, doing to many things at the same time. Yes the `elif` is vastly better than the extra variable before. :+1:
Feel free to ignore this, but I noticed this can be tightened up as: ```python for parsed in (urlparse(origin) for origin in settings.CSRF_TRUSTED_ORIGINS if '*' if origin): ```
This just occurred to me, but would it make sense to structure things so the `CSRF_TRUSTED_ORIGINS` processing can be done just once instead of with each request? (There is similar parsing / processing [below](https://github.com/django/django/pull/13829/files#diff-eaa105f5b436e20dd838c27c7a753ef4cf888edcc8f868c084600f6cb7343166R314-R317) in the referer checking.)
Should these properties be marked private to allow tweaking their return value over time? Their use is mainly for optimization purposes.
@felixxm I suggested the exact opposite during previous review - I prefer to template it to allow the tests to be moved around in future without any diff noise
[limit try clauses](https://adamj.eu/tech/2019/10/02/limit-your-try-clauses-in-python/): ```suggestion try: view = _get_failure_view() except ImportError: msg = ( "The CSRF failure view '%s' could not be imported." % settings.CSRF_FAILURE_VIEW ) errors.append(Error(msg, id='security.E025')) else: try: inspect.signature(view).bind(None, reason=None) except TypeError: msg = ( "The CSRF failure view '%s' does not take the correct number of arguments." % settings.CSRF_FAILURE_VIEW ) errors.append(Error(msg, id='security.E024')) ```
why not an f-string as per my suggestion? We're on Python 3.6 only now.
```suggestion @override_settings( CSRF_FAILURE_VIEW=f'{__name__}.failure_view_with_invalid_signature', ) ```
I'm not convinced about this change is a bit backward incompatible, e.g. ```python >>> from django.views.debug import ExceptionReporter >>> ExceptionReporter.html_template_path Traceback (most recent call last): File "<stdin>", line 1, in <module> AttributeError: type object 'ExceptionReporter' has no attribute 'html_template_path' ``` Can we use a `@classproperty` (with `@lru_cache(maxsize=1)`) to keep the current behavior? :thinking:
This will target Django 4.0, where after #13915, Python 3.8 will be the lowest supported version, so we can use `functools.cached_property` I think.
Please use `cached_property` from `django.utils.functional`.
Not sure this needs the `_` 🤷
ticket-30949 is currently not accepted due to some performance issues, so we should use `cached_property` from `django.utils.functional`. We can swap all uses of `cached_property` when implementing ticket-30949.
I wanted to keep them isolated, without calling `cache_clear()` in both one of them will always be no-op.
I don't see much value in adding `_check_fixture_files_in_dir()`. I would move this to the `_find_fixture_files_in_dir()` or leave it in the main loop.
IMO we should revert this change `fixture_file` is an absolute path, so it can contain directories with dots in names, this can cause issues in `parse_name()`.
This format can be more clear: ```python try: import bz2 except ImportError: has_bz2 = False else: has_bz2 = True ```
```suggestion def save_obj(self, obj): ```
I don't see any point in changing the current form.
May be an easier change for django reviewers if you keep this block in the same format as the one you replaced
`product()` handles iterables so we don't need to call `list()`: ```suggestion cmp_fmts = self.compression_formats if cmp_fmt is None else [cmp_fmt] ```
As far as I'm aware we don't need to iterate twice over the same list: ```suggestion return { '%s.%s' % ( fixture_name, '.'.join([ext for ext in combo if ext]), ) for combo in product(databases, ser_fmts, cmp_fmts) } ```
We don't need to add the `_` prefix to the new methods. They are considered a private API even without it.
I think we should be consistent and use double-quotes.
We should move using named groups in regular expressions to a separate commit, and add a new rule and an actual fix in the second one.
I'm not sure if it's a correct solution, before db19619545dd99a1d2502c72974d79eca33acff7 we returned `json.dumps(None)` i.e. `'null'`. IMO it's expected. ```suggestion if data is None: return data ```
Bad rebase? `PASSWORD_RESET_TIMEOUT_DAYS` was removed in 4.0. ```suggestion ```
While I realize we cannot change that now, do we remember why we added `django.http.cookies` here? The salt alone should make sure that we do not clash with other signatures.
Interesting thought. But if a key is compromised one would switch from one key in the list to still one key (the new one) because you wouldn't want to keep the compromised key active. So in the case of a compromise I'd always expect the list to stay constant in length because the offending key would be replace with a new one (independent of other keys probably). Either way for the majority of cases (ie under normal operation) I'd expect just one key in there (or always two if one rotates a key every $x weeks)
Is this really necessary? Which information do we leak by using a normal any? To the best of my knowledge you'd leak which `SECRET_KEY` you used, which imo shouldn't be a problem? I also think it is maybe not the best idea to try against all secret keys if the first one (the common one) already matches, this creates extra work that should not be needed imo. In that sense I'd loop and break out early if you get a valid sig.
Fair warning, I don't know nearly enough about things of this nature to be actually valuable, except possibly to ask questions which might be dumb or might be previously unconsidered. So please take it with a grain of salt... If an adversary is making use of the fact a secret key has been compromised, which scenario gives them less information when the key is subsequently discovered and rotated and they want to stop trying to make use of it (to fly under the radar as much as possible); one constant time compare, or multiple? Layman's gut feeling says you'd want the time comparison to be actually roughly constant, which would probably require always doing either 1 or 2 (I think, it's murky in my brain now) always, regardless of number of keys in the corpus? (ie: if there's only one key, always compare as if there are 2...) And does that kind of scenario _actually_ matter? IDK.
nit: since the error message says "the elements" shouldn't this check all elements? ```suggestion if not all(val): ``` alternatively, we can leave the if-statement as-is and instead change the error to something like "the first key in the list must not be empty"
Same as below, I think I'd prefer a loop that breaks early.
What about: ```py for secret in self.secrets: if constant_time_compare(self._make_token_with_timestamp(user, ts, secret), token): break else: return False ``` EDIT: f'uped the indendation. First time I think I am using for … else
But if someone set `SECRET_KEY` to `None` and `SECRET_KEYS` to a valid list shouldn't that be allowed? I'd actually go backwards here and not use `is_overridden`. This way you'd error out if both has a usable value…
We do not have to overdo it, but `if not all(val)` seems easier and brings over the intent better than `if not val[0]`
This would set `SECRET_KEYS` to `[None]` if `SECRET_KEY` was `None` which again gives me the impression that using `is_overriden` is the wrong approach here.
We are doing a lot of work here when usually only the first key should be needed. I understand that usually the list will for short; but still… what about: ``` for key in self.keys: valid = constant_time_compare(sig, self.signature(value, key)) if valid: return value ```
If the user is able to make the server sign arbitrary data of their choosing, using the same salt and key will yield the same signature. However, if we slightly modify the key, they can't. This makes chosen plaintext attacks less vulnerable.
This makes it sound like the second to nth key are the only one used for validation, when in fact all keys are used for validation.
I'm leaning towards @felixxm idea of having a single point of truth and not needing to keep them in sync. Keeping something in sync is always hard and error prone. But if there's only one way to get to `settings.SECRET_KEY` we can encapsulate all logic in there.
This was not fully clear when I wrote the original patch either. 🙂 I added constant_time_any just for good measure. I discussed it with @MarkusH at DjangoCon EU in Copenhagen and (IIRC) we figured that it would be a good idea to keep the constant time check just to be extra careful. That said, yes, it could leak which secret key that was used but... I cannot see why that would be a problem. I do not have a strong opinion either way.
Do we need setters/getters and extra code in `is_overridden()`? Maybe it enough to set `SECRET_KEYS` in `Settings.__init__()`, e.g. ```python class Settings: def __init__(self, settings_module): ... if self.is_overridden('SECRET_KEY'): if self.is_overridden('SECRET_KEYS'): raise ImproperlyConfigured( 'SECRET_KEY and SECRET_KEYS are mutually exclusive.' ) setattr(self, 'SECRET_KEYS', [self.SECRET_KEY]) ``` I would add `SECRET_KEYS` to the `tuple_settings`.
Can we use the same signature as unittest's [assertNoLogs()](https://docs.python.org/3.10/library/unittest.html?highlight=assertnologs#unittest.TestCase.assertNoLogs)? ```suggestion def assertNoLogs(self, logger, level=None): ```
Do we need to check this message? `AssertionError` means that no logs were logged (with at least the given level), so I would change this to: ```suggestion pass ``` and add `else`: ```python try: with self.assertLogs(logger_name, level) as cm: yield except AssetionError: pass else: self.fail(f'Unexpected logs found: {cm.output!r}') ```
```suggestion """ Assert no messages are logged on the logger, with at least the given level. """ ```
This is unnecessary if we remove checking the error message.
I've proposed `self.fail(f'Unexpected logs found: {cm.output!r}')` to use the same message as in Python. With the current version `AssertNoLogsTest` tests will fail on Python 3.10+. We can adjust a message or skip new tests on Python 3.10+.
I don't think the `ast.literal_eval` approach is the best. I only included the code as an example on the ticket. It would be better to never force the result into a string in the first place.
why not define this tuple at import time? `import pytz` seems to already have made the classes accessible.
I guess we could introduce `django.utils.zoneinfo` like we did with `simplejson` back in the time. We could start deprecating the module when we drop support for Python 3.8.
right then I guess this import sequence is not too bad, it's already something we do in tests in a few other places when dealing with optional libraries.
Diff will be smaller without this unnecessary change.
Please use hanging indentation (everywhere).
no need to define here if it's defined by the below `if`
Not 100% sure. I will follow-up with @pganssle about this. Testing you can't get ambiguous results regardless of using `value` or `return_value`, and adjustments of fold: ``` >>> import datetime >>> from django.utils import timezone >>> import zoneinfo >>> d = datetime.datetime(2015, 3, 29, 2, 30) >>> d.fold 0 >>> PARIS_ZI = zoneinfo.ZoneInfo('Europe/Paris') >>> timezone._datetime_ambiguous_or_imaginary(d, PARIS_ZI) True >>> a = d.replace(tzinfo=PARIS_ZI) >>> timezone._datetime_ambiguous_or_imaginary(a, PARIS_ZI) True >>> a2 = a.replace(fold=1) >>> timezone._datetime_ambiguous_or_imaginary(a2, PARIS_ZI) True ```
```suggestion return '1' if self.timezone.dst(self.data) else '0' ```
```suggestion if ( not self.timezone or _datetime_ambiguous_or_imaginary(self.data, self.timezone) ): ```
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
Chop blank line.
```suggestion if ( not self.timezone or _datetime_ambiguous_or_imaginary(self.data, self.timezone) ): ```
My micro-optimizations from 2011 are so cute :-) https://github.com/django/django/commit/9b1cb755a28f020e27d4268c214b25315d4de42e#diff-698cf55de9163a8fc8381fc3f0320d8336203c45e03306f497c67495bffce40bR224 Then at some point I was the Python 3 guy but I wasn't aware of that subtlety with the datetime module! Thanks for cleaning that up.
Pulled this into #13916
Is `tz` necessary here ? elsewhere `self.timezone` is passed without it.
I'd be OK with calling the function `_datetime_ambiguous_or_imaginary`. It's verbose, but anything shorter will be confusing, given what Paul said.
Yes, this is covered in `tests/timezones/tests.py` `LegacyFormsTests.test_form_with_ambiguous_time()`
Perhaps just merging as a separate commit is fine.
I feel the test could be slightly improved to better underline the problem that was reported and to prevent future regression. Something like: ```suggestion encoded_url = '/test-setlang/%C3%A4/?foo=bar&baz=alpha%26omega' # (%C3%A4 decodes to ä, %26 to &) ```
The code I proposed sets the same content in the variable with the same length. It's not a major change, just a small improvement. IMO
couldn't we use the following code here? ``` import string RANDOM_STRING_CHARS = string.ascii_letters + string.digits ```
Hi @youguanxinqing — but `total_forms` is basically just `extra` + the initial forms, so if we have those two we _shouldn't_ need to set it manually (is my hunch). Maybe there's an edge case but I'd like to see that, and have it covered by a test if so. I'll have a play with it now, but if you can show how it's wrong, that would be great! (Thanks! 👍)
`extra` filed is assigned by user. for example: ```python class ChoiceInline(admin.StackedInline): model = Choice extra = 3 ``` ref: https://docs.djangoproject.com/en/3.1/intro/tutorial07/#writing-your-first-django-app-part-7 I'am sorry that I think `EXTRA_FORM_COUNT = TOTAL_FORM_COUNT - max(INITIAL_FORM_COUNT, MIN_NUM_FORM_COUNT)` is incorrect.
Sorry for my mistabke, you are right.
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
Ditto about `no_color=True`
Thanks :+1: IMO, we can also remove this assignment and simplify the code: ```python ... if self.localize: value = formats.sanitize_separators(value) try: return Decimal(str(value)) except DecimalException: raise ValidationError(self.error_messages['invalid'], code='invalid') ```
Just came here to suggest the exact same thing!
No... But looking at the implementation in `Logger._log()`: ```python if exc_info: if isinstance(exc_info, BaseException): exc_info = (type(exc_info), exc_info, exc_info.__traceback__) elif not isinstance(exc_info, tuple): exc_info = sys.exc_info() ``` If you pass an exception instance, it will decompose it into the `(type, value, traceback)` tuple. [^1] Instead of calling `sys.exc_info()`, perhaps we should hand that off to the logger and pass `exc_info=True` everywhere. Or, perhaps we should instead pass `exc_info=exc` everywhere because `response_for_exception()` is called within the exception block, but could possibly (if unlikely) be called in a different context where `sys.exc_info()` would give the wrong exception. [^1]: Out of interest, there is currently a lot of change going into 3.11 that ditches this 3-tuple mess for exceptions under the hood as it is pointless. Obviously the API will have to keep supporting this for a long time, perhaps forever.
> There's a difference between this and other cases -- this calls `Logger.error()` directly, while others go through `log_response().` Yes, I did notice this. The main difference is that the message is logged before the response is created. That prevents use of `log_response()` by passing `response`, although you can pass `logger` and `level` independently to that function instead. > However, if it is, we might as well call `security_logger.exception()` instead. True. Calling `.exception(…)` is the same as calling `.error(…, exc_info=True)`. > I'm not sure that, in general, taking threads and async in consideration, calling sys.exc_info() out of an except: block is valid (although it is done here in all the other cases). But I guess this is the main thing: If we already have an instance of the exception, why not pass that rather than look it up again with `sys.exc_info()` and run the risk that, somehow, however unlikely, we end up with the wrong exception.
Is there any reason to use `exc` instead of `sys.exc_info()`?, as in other cases :thinking:
There's a difference between this and other cases -- this calls `Logger.error()` directly, while others go through `log_response()`. I'm not sure that, in general, taking threads and async in consideration, calling `sys.exc_info()` out of an `except:` block is valid (although it is done here in all the other cases). However, if it is, we might as well call `security_logger.exception()` instead.
I could be missing something, but would it be better as the following to avoid masking exceptions? ```suggestion except ModuleNotFoundError: pass else: readline.set_completer(rlcompleter.Completer(imported_objects).complete) ``` I'm thinking of this [PEP-8 programming recommendation](https://www.python.org/dev/peps/pep-0008/#programming-recommendations): > Additionally, for all try/except clauses, limit the try clause to the absolute minimum amount of code necessary. Again, this avoids masking bugs:
Hey @inglesp — can you crib for me why we need this block? 🤔 Thanks.
You appear to have dropped support for macOS.
> these operating conditions are only ever theoretical. They're not. I use them all the time together with [`shell`]'s [`--pythonpath`] option. (And I do this on a Mac, hence my interest in making sure we get this PR right.) [`--pythonpath`]: https://docs.djangoproject.com/en/3.1/ref/django-admin/#cmdoption-pythonpath [`shell`]: https://docs.djangoproject.com/en/3.1/ref/django-admin/#shell
It's OK, I see — `imported_objects` is used as the interpreter environment, and we `exec` `.pythonrc` into it. — I think I was looking at the wrong diff. 😜
This one is fair-enough, yes.
I'm sceptical about this. Generating options is slow. I'm not convinced that avoiding the attribute lookup is the way to go with it though. A 4% speed-up is OK but the cost is to obfuscate the code. We used to do this with JavaScript. Browsers were bad at navigating the scope hierarchy, so you'd create local copies of variables at the start of a function. It worked, a good speedup. But it was horrible. In the end they made browsers better, and I don't see it done these days (certainly not as a first-option). Ultimately it was the browser's issue. Same here. If this is an issue, it's Python's issue (IMO) — let them speed up attribute access. (If we're that worried about speed, there's a question about why we're using Python in the first place... but that gets us off-topic). `SelectDateWidget` is close to a worst-case example. I'm not convinced it's typical. Is it really the case that choices generation is the holdup in common scenarios…? **And** if you are hitting issues here, the way forward (again IMO) is to cache choices generation, rather than bend the code the wrong way. I see us removing old micro-optimizations as unnecessary; not at all sure about adding more...
Thanks @timgraham! #13996.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
Although, having said that. If you made the suggested change below there would be no longer be a need to update this function.
The docstring should probably be updated so that it more accurately describes the new and improved function :)
```suggestion @method_decorator(never_cache) ``` This [ticket](https://code.djangoproject.com/ticket/32468#ticket) gives a thorough explanation as to why this is needed.
I think this logic would mark `Children.parent_ptr.auto_created = True` when it should be `False` ```python class Parent(models.Model): pass class Children(Parent): parent_ptr = models.OneToOne(Parent, parent_link=True) ```
I think we should ignore inherited PKs and check them only in parents, see #13925.
Maybe: ```suggestion setting = getattr(settings, 'FILE_UPLOAD_TEMP_DIR', None) if setting and not Path(setting).is_dir(): return [Error( f"The FILE_UPLOAD_TEMP_DIR setting refers to the nonexistent " f"directory '{setting}'.", id='files.E001', )] ```
There is no need to define `Error` in the module. I would move it to the check.
We should use `pathlib.Path.cwd()` instead, also there is no need to define a constant.
We can use a `subTest()`: ```suggestion def test_file_upload_temp_dir(self): tests = [ None, '', Path.cwd(), str(Path.cwd()), ] for setting in tests: with self.subTest(setting): with self.settings(FILE_UPLOAD_TEMP_DIR=setting): self.assertEqual(check_setting_file_upload_temp_dir(None), []) def test_file_upload_temp_dir_nonexisten(self): for setting in ['nonexistent', Path('nonexistent')]: with self.subTest(setting): with self.settings(FILE_UPLOAD_TEMP_DIR=setting): self.assertEqual(check_setting_file_upload_temp_dir(None), [ Error( "The FILE_UPLOAD_TEMP_DIR setting refers to the " "nonexistent directory 'nonexistent'.", id='files.E001', ), ]) ```
This should be `W024` (since there is already an `E023`). Also it feels like this should be an error not a warning. If the check fails we will get an error (in behaviour) somewhere down the line. It would also be consistent with other checks similar to this.
Please drop this property pattern and instead use plain function calls like in the above csrf failure view tests - we've been removing that pattern for checks tests
Slightly simpler: ```suggestion passed_check = ( isinstance(settings.ALLOWED_HOSTS, (list, tuple)) and all(isinstance(element, str) for element in settings.ALLOWED_HOSTS) ) ``` `else False` reminds me of: https://adamj.eu/tech/2020/01/17/simplify-your-ifs-that-return-booleans/
(Following the pattern of other checks.)
```suggestion 'ALLOWED_HOSTS must be a list or tuple of strings.', ```
FWIW I actually got bitten by this updating a project. See ticket-33362
No, that would make it impossible to override the `invalid_choice` message. IMO we should revert changes to the `invalid_choice` message (L1191-L1192) and only pass a `value` to the `ValidationError`: ```python raise ValidationError( self.error_messages['invalid_choice'], code='invalid_choice', params={"value": value}, ) ```
I would only pass a `value`, without changing the default `invalid_choice` message, see a similar change for built-in validators 83fbaa92311dd96e330496a0e443ea71b9c183e2.
Since we used the `::%(db_type)s` for PostgreSQL solely for readability purposes and this now requires two parentheses wrapping `((expr)::type)` I think we should consider removing that `as_postgresql` override entirely as `CAST(expr AS type)` seems more readable to me at this point.
No tests fail if I remove this change. I presume it was to avoid calling `tuple()` unnecessarily? For that matter, we can just change to the following as we're always unpacking into key-value pairs: ```suggestion yield elem ``` I don't think we need any guarantees that this will return a `tuple`. Loosely it only needs return an iterable of two elements with the first being a string.
What I meant was that you could stick the following in the top of `_destruct_iterable_mapping_values()` to make it more DRY: ```python if isinstance(data, Mapping): yield from data.items() return ``` I don't see why you think we'd need an extra for-loop...
Then this can just be: ```python for header, value in self._unpack_values(data): ```
There are only two uses of `_destruct_iterable_mapping_values()` and we use this same pattern exactly. I think that you could push the `isinstance(..., Mapping)` check into that function.
As a separate commit, I think that it is also probably worth moving that global function to be a `@staticmethod` on the `CaseInsensitiveMapping` class. It is closely associated with this class and would avoid the need to import it separately in `django.http.response`.
We currently prefer single quotes. The wrapping parentheses are not required.
For future reference, [here is the line](https://github.com/python/cpython/blob/aaa83cdfab6817446285e631232f64b394ac6791/Objects/unicodeobject.c#L10022) of interest. And here are the docs for [`PySequence_Fast()`](https://docs.python.org/3/c-api/sequence.html#c.PySequence_Fast) which states: > The `PySequence_Fast*` functions are thus named because they assume `o` is a `PyTupleObject` or a `PyListObject` and access the data fields of `o` directly. > > As a CPython implementation detail, if `o` is already a sequence or list, it will be returned.
~~You don't need to create a list, actually. You can just pass the generator expression through (no surrounding parentheses are needed). So `...join(key.encode(...`.~~ Never mind, I learned that this is slower (what @pope1ni was probably saying in the first place).
This has come up in the past when we were looking at removing unnecessary list comprehensions in favour of generators. IIRC, `str.join()` converts input to a list if it isn't already.
When using `str.join()` it is preferable to pass a `list` as it is slightly faster.
@heckad then you'll get a crash on the first attempt at creating a connection. The point of this patch is not to support all possible misconfiguration of `DATABASES` but to make sure an adequate exception is surfaced instead of a `RuntimeError`.
Because older versions.
Same? ```suggestion cls = super().__new__(metacls, classname, bases, classdict, boundary, **kwds) ```
```suggestion sql_alter_column_no_default_null = sql_alter_column_no_default ``` And then override it in `mysql.schema.SchemaEditor.sql_alter_column_no_default_null = "ALTER COLUMN %(column)s SET DEFAULT NULL"`
Remove unnecessary new line ```suggestion sql_alter_column_no_default_null = sql_alter_column_no_default ```
Ah I think you could use `assertTrue` without issues as both `1` and `True` are truthy. ```suggestion self.assertTrue(field.null_ok) ```
`UniqueConstraint` not `Index`.
Yes a separate PR with unification sounds good.
We could keep the same format as in indexes: ```suggestion return '<%s: %sname=%r%s%s%s%s%s>' % ( self.__class__.__name__, '' if not self.fields else "fields='%s' " % ', '.join(self.fields), self.name, '' if not self.expressions else " expressions='%s'" % ', '.join([ str(expression) for expression in self.expressions ]), ```
This is also a separate issue, but it's not testable without functional constraints so we can leave it here.
All changes to MySQL introspection (except this line) can be treated as a simplification of the current implementation, so I moved it them a separate PR #14000.
We cannot change the signature that much, it's backward incompatible. IMO it's acceptable to make `fields` and `name` arguments optional: ```python def __init__( self, *expressions, fields=(), name=None, ... ): if not name: raise ValueError('A unique constraint must be named.') ``` ```
I would move this out of the `Statement`: ```python if columns: columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses) else: columns = Expressions(model._meta.db_table, expressions, compiler, self.quote_value) ```
Maybe: ```suggestion '' if not self.fields else 'fields=%r ' % self.fields, ```
I think this test would make a little more sense if we used a `CharField` for the primary key of `Foo`. It's not super important though.
I think the logic is a bit easier to follow if we don't have any nested boolean expressions: ```suggestion if ( not connection.features.supports_expression_indexes and 'supports_expression_indexes' not in cls._meta.required_db_features and any(constraint.contains_expressions for constraint in cls._meta.constraints) ): ```
```suggestion raise TypeError('Cannot call delete() after .distinct()') ```
Since no queries are perform you can subclass `SimpleTestCase`. You also can drop the ticket reference as we've moved to only include them for cryptic errors that require a lot of context since nowadays most of these a tests are one `git blame` away from a link to their ticket. ```suggestion class DeleteDistinct(SimpleTestCase): ```
I don't see much value in added prefixes: `(cached property)`, `(property)`, and putting them in the `name` column can be misleading. We don't include prefixes for `classmethods`, `staticmethods` etc. If it's important for someone they can always add such information to the docstring.
Please alphabetize. ```suggestion if inspect.isfunction(func) or isinstance(func, (cached_property, property)): ```
Would it make sense to exclude check constrains from this query and get rid of the `elif` blocks? ```suggestion c.table_schema = kc.table_schema AND c.constraint_name = kc.constraint_name AND c.constraint_type != 'CHECK' AND ```
```suggestion def check_allowed_hosts(cls, expected): ```
```suggestion assertIs(self.set_up_called, True) ```
```suggestion # LiveServerTestCase's change to ALLOWED_HOSTS should be reverted. ```
```suggestion cls.set_up_called = True ```
However, I think it's worth to keep it for backends without built-in converters.
We can reuse `MyWrapper`.
This is already covered by `tests.queries.test_db_returning.ReturningValuesTests.test_bulk_insert`, that's why `ReturningValuesTests` tests crash on SQLite 3.35+ (see #14227).
```suggestion 'The SERIALIZE test database setting is ' 'deprecated as it can be inferred from the ' 'TransactionTestCase.databases that enable the ' 'serialized_rollback feature.', ```
Yes, you could do that, too. It's a little confusing because `_get_databases()` functions more like "update" (the provided argument) when a dict is provided. The return value isn't really used in that case.
FYI, I could be wrong, but it looks like this `update()` line could wind up overwriting the special `update()` precedence logic you include in the other branch. A possible fix for this would be to change `_get_databases()` to accept a required dict of databases and initialize the dict outside the first call. That way the update will only be happening in one place, and to the same dict. A second option would be to have these recursive calls build a list of pairs, and combine them to a dict only at the very end, in an outer call.
> PS - you might ask: why not fix ticket 29062 first? The reason is that fixing ticket 29062 properly would involve properly closing connections. Thus, any correct fix of ticket 29062 would be a superset of this PR, which would make it an even bigger change. Yes that was my first question :smile: Thanks for details :+1: . I'm afraid that it can be still confusing for a future me. I will try to move something to a separate commit e.g. `_make_connections_override()` which should reduce the number of changes and make it easier to bisect and fix potential regression.
Do we need this methods? Maybe I'm missing sth but thread's database connections should already by overridden, and we don't pass `connections_override` to the `_create_server()` anywhere in Django :thinking:
That won't work, `_combine` must return a _new_ object. I suggest we adapt the code to catch `TypeError` on `deepcopy` and use the old code path on failure.
I don't think we want to special case `Subquery`, feels like we'll want to duck type on `conditional` ```suggestion if not isinstance(other, Q) and not getattr(other, 'conditional', False) is True: ```
I think it would be batter to hide a sidebar, e.g. ```python # Hide sidebar. toggle_button = self.selenium.find_element_by_css_selector('#toggle-nav-sidebar') toggle_button.click() ```
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
After checking changes in tests I think using `repr()` for `expressions`, `fields`, `include`, and `opclasses` makes a representation more readable (it's easy to miss a comma and don't notice the list of values), e.g. ```python ' expressions=%s' % repr(self.expressions) ' fields=%s' % repr(self.fields) ' opclasses=%s' % repr(self.opclasses) ' include=%s' % repr(self.include) ```
Type of `condition` and `deferrable` is checked in `__init__()` so `str()` is not necessary.
We should use `__qualname__` in all classes.
`expressions` should be before the `name` like in other classes.
```suggestion # These views can be called when CsrfViewMiddleware.process_view() not run, ```
```suggestion The message from the exception which triggered the 403 (if one was supplied). ```
```suggestion "behavior and silence this warning or default=Value([]) to retain " ```
I think we can move it to the module level. ```python # RemovedInDjango50Warning NOT_PROVIDED = object() class DeprecatedConvertValueMixin: def __init__(self, *expressions, default=NOT_PROVIDED, **extra): ... ```
```suggestion "behavior and silence this warning or default=Value([]) to retain " ```
This can be single-lined: ```suggestion warnings.warn(self._deprecation_message, category=RemovedInDjango50Warning) ```
I don't think we need underscore prefixes: - `_DeprecatedConvertValueMixin` -> `DeprecatedConvertValueMixin` - `_deprecation_value` -> `deprecation_value` - `_deprecation_message` -> `deprecation_msg`
"In Django 5.0" :+1:
`'[]'` is a string so there is no need to wrap with `Value()`.
We ca re-use class variables: ```suggestion with self.assertWarnsMessage(RemovedInDjango50Warning, ArrayAgg.deprecation_msg): queryset.aggregate(aggregation=ArrayAgg('boolean_field')) ```
```suggestion "From Django 5.0, StringAgg() will return None instead of an " "empty string if there are no rows. Pass default=None to opt into " "the new behavior and silence this warning or default='' to keep the " "previous behavior." ```
```suggestion "From Django 5.0, JSONBAgg() will return None instead of an empty " "list if there are no rows. Pass default=None to opt into the new " "behavior and silence this warning or default=Value('[]') to keep the " "previous behavior." ```
Use consistent quotes. Also, maybe `previous` instead of `existing` :thinking: ```suggestion 'From Django 5.0, ArrayAgg() will return None instead of an empty ' 'list if there are no rows. Pass default=None to opt into the new ' 'behavior and silence this warning or default=Value([]) to keep the' 'previous behavior.' ```
"From Django 5.0" isn't clear to me. Does it mean, "Starting with Django 5.0"? If so, some other ways to say this could be "Starting in Django 5.0," "In Django 5.0 and up," "From Django 5.0 onward," or perhaps simply, "In Django 5.0" if the behavior won't carry forward.
Can we move this to a separate file, e.g. `tests/test_client/urls_overridden_urlconf.py`: ```python def empty_response(request): return HttpResponse() urlpatterns = [ path('', empty_response, name='overridden_urlconf_view'), ] ```
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
This is not a correct message for `@cache_control`, I'm going to move this check to decorators.
IMO there is enough to use `attname`, loop shouldn't be necessary. All tests work for me with (instead of L96-L102): ```python to_field_name = getattr(source_field.remote_field, 'field_name', remote_model._meta.pk.attname) to_field_name = remote_model._meta.get_field(to_field_name).attname ```
@codingjoe `setUpClassData` gives us a staff user: ```python cls.user = User.objects.create_user( username='user', password='secret', email='user@example.com', is_staff=True, ) ```
@felixxm the `if to_field.primary_key` check is needed for the FK as PK case. Two questions: 1. Can we tidy this block? 2. Do we need the same kind of thing again inside the `while` loop? 🤔
Super — let me give that a run. Thanks @felixxm
This being the change in question.
We can reuse `self.user`: ```suggestion request.user = self.user ```
```suggestion 'field_name': 'related_questions', ```
In general, I think _it shouldn't be as hard as this_ (at least not exposed 😀)
For consistency: ```suggestion to_field_name = remote_model._meta.get_field(to_field_name).attname ```
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
True, `exc` -> `cm`.
```suggestion return ','.join(data_list) if data_list else None ```
```suggestion form = PartiallyRequiredForm({'f_0': 'Hello', 'f_1': ''}) ```
Chop blank line.
```suggestion widget=MultiWidget(widgets=[TextInput(), TextInput()]), ```
Wrap at 79 chars.
```suggestion form = PartiallyRequiredForm({'f_0': '', 'f_1': ''}) ```
This will crash on Oracle: ```python @skipUnlessDBFeature('supports_subqueries_in_group_by') ```
I would wrap `asvar` and `view_name` in quotes and use `%`-formatting, e.g.: ```python def __repr__(self): return "<%s view_name='%s' args=%s kwargs=%s as='%s'>" % ( self.__class__.__name__, self.view_name, repr(self.args), repr(self.kwargs), self.asvar, ) ```
`asvar` can be `None`, so I added `repr()`.
`asvar` -> `as`
`Q()` is not a real "expression" and it deserves special treatment, see ticket-29125. IMO it makes sense to do this change only for all expressions (as for `django.db.models.fields.*`), but not all of them are importable from `django.db.models` so it's more complicated.
```suggestion processed_adjustable_paths = {} ```
```suggestion yield from adjustable_path_results.values() ```
Ah, I missed that because I looked in the man page, not at `--help` output, and forgot it defaults to the current user's username. And, yes, we'd rather get a chance of connecting to a known, valid database rather than a failure to connect because the user's database doesn't exist (which is highly likely).
Is this necessary? I'm sure that `psql` defaults to `postgres` if `dbname` is unspecified. ```suggestion ```
This is redundant with `test_no_errors_with_test_settings` because `CollectionTestCase` uses existing directories.
Using `CollectionTestCase` gives us existing directories in "static" settings.
We shouldn't mix a new check with existing tests. I would move it to a separate method.
```suggestion return errors ```
I don't see much value in this hint, also `Git` is not the only VCS. Please remove it.
This is a separate cleanup, so please move it do a separate commit.
Do we need to check that it's a string here? If it's not a list, a tuple, it seems unlikely it'll be some other iterable for which the further checks would be useful. As such - most likely an exception will be raised when it's iterated over and the error message above won't even be displayed. (I'm imaging some people might use a Path instance). This will then become a hard-to-diagnose problem for beginners, who will have a confusing exception rather than a useful error message from django. I wonder if for their sake it's worth always returning here.
I think it's enough to test `None` and `''`.
A few observations: - There is no need for the temporary variable. - We cannot just check if falsy as the value could be `0` or `False`. - Compare to a sentinel object to ensure that `None` isn't passed. (I think we can re-use `NOT_PROVIDED` here.) - Add a period to the end of the exception message. ```suggestion if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED: raise TypeError( f'{cls.__name__}() got both positional and keyword ' f"arguments for field '{field.name}'." ) ```
I don't think it's worth to add multiple fields. `IntegerField(null=True)` should be enough.
```suggestion f'{cls.__qualname__}() got both positional and keyword ' ```
Sure, so two extra fields - one to handle `0` and `None`, the other to handle `False`.
Good shout. (Perhaps other similar exceptions could be updated in another PR.)
> @felixxm What you mean is to fix this bug after proceeding with inserting `nullable` property first? Yes.
Also, I don't think it's a complete solution as annotations on the LHS still don't work properly, see failing test: ```python def test_exclude_nullable_fields_annotation(self): from django.db.models.functions import Abs number = Number.objects.create(num=1, other_num=1) Number.objects.create(num=2, other_num=2, another_num=2) self.assertSequenceEqual( Number.objects.annotate(x=Abs('another_num')).exclude(other_num=F('x')), [number], ) self.assertSequenceEqual( Number.objects.annotate(x=Abs('another_num')).exclude(num=F('x')), [number], ) ```
> my changs affect when LHS is annotation field and RHS is not field. I know, but this is also an issue with nullable annotation so we should fix it in this PR. If it is a different branch in `build_filter()` then we have another reason to add some hook.
We can try to refactor [existing code](https://github.com/django/django/blob/a9cf954e6174450057ea1065aa2ccbbd12f59b65/django/db/models/sql/query.py#L1351-L1375) and add some internal hook instead of having similar (identical?) logic in two places.
> @felixxm in my view, below test code is our expected result. No, it's not. `1 != NULL` so why it's expected that `number` is excluded? see 512da9d5855 and ticket-23797 for more details.
FYI I ran into the same issue of `AttributeError: 'generator' object has no attribute 'target'".` with this test checking if this PR fixed the issue when using exclude with an `alias` (flagged up in duplicate [ticket-32896](https://code.djangoproject.com/ticket/32896)): ```python # ExcludeTests def test_exclude_aliased_nullable_fields(self): number = Number.objects.create(num=1, other_num=1) Number.objects.create(num=2, other_num=2, another_num=2) qs = Number.objects.alias(aliased_num=F('num')) self.assertSequenceEqual( qs.exclude(another_num=F('aliased_num')), [number], ) self.assertSequenceEqual( qs.exclude(aliased_num=F('another_num')), [number], ) ```
I really don't like that we increase indentation here, it make code less readable, and it's complicated even without this :disappointed: We could reduce the number of changes significantly with: ```python if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) clause.add(condition, AND) # When col is nullable, add IS NOT NULL. col = self._gen_cols(reffed_expression) if col: lookup_type = condition.lookup_name target = col.target if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None and self.is_nullable(target): lookup_class = target.get_lookup('isnull') col = self._get_col(target, target, alias) clause.add(lookup_class(col, False), AND) return clause, () ``` and reverting related adjustments.
You could just do this: ```suggestion JOIN pg_namespace nsp ON nsp.oid = c.relnamespace AND nsp.nspname = current_schema() ```
Which avoids an extra query: ```suggestion ```
```suggestion """, [self.index_default_access_method, table_name]) ```
What's this call for here? 🤔
We should probably keep this class. I think I'd call it `SitemapIndexItem`, and give it a docstring. 🤔 I guess deprecating the `__str__()` usage will keep everyone on the same page. (Without something like this, we're still passing a list of pair or dicts or ... — given that we have the class already, we may as well keep it.)
I think it's just right as a dataclass 👍
This needs an entry in `deprecation.txt`
There's no test for the `and not callable(self.lastmod)` branch.
Tripe `"""` for a docstring. Missing period at the end.
I might handle the `if not hasattr(self, 'lastmod')` as a guard first, to get it out of the way: ```suggestion def get_latest_lastmod(self): if not hasattr(self, 'lastmod'): return None if callable(self.lastmod): try: return max([self.lastmod(item) for item in self.items()]) except TypeError: return None else: return self.lastmod ```
Separate to this PR: Even given ticket-23403, we could perhaps look at deprecating use of `date` here. 🤔
OK, good. Thanks. I think it's fine as it is. 👍
```suggestion path( 'generic-lastmod/index.xml', views.index, {'sitemaps': generic_sitemaps_lastmod}, name='django.contrib.sitemaps.views.index', ), ```
```suggestion path( 'lastmod/get-latest-lastmod-none-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_none_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/get-latest-lastmod-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/latest-lastmod-timezone-sitemap.xml', views.index, {'sitemaps': latest_lastmod_timezone_sitemaps}, name='django.contrib.sitemaps.views.index', ), ```
Please use single quotes.
I think we can get rid of `replace_metacharacters()` and just do the `re.sub()` here.
We can avoid the backslashes in `[…]`, even for `^` as long as it isn't first to avoid turning it into an inverse character set (`[^…]`): ```suggestion pattern = re.sub(r"(\\[bBAZ]|[?^$])", "", pattern) ```
Yes. However, note that isn't sufficient to replace all occurrences of e.g. `r'\Z'`, for example `r'a\\\Z'`.
In the pattern I provided, the `'Z'` is a plain `'Z'` (because the backslash preceding it is escaped), but your substitution line is removing it.
```suggestion # List of datatypes to that cannot be extracted with JSON_EXTRACT() on # SQLite. Use JSON_TYPE() instead. ```
Given the change in the for loop below; `class_count` is only used in one place, so it might also be simpler to get rid of it altogether. This Seems (slightly) more readable to my mind - might be a matter of opinion though 🤔 ```suggestion bins = [OrderedSet() for i in range(len(classes) + 1)] ```
This can be single-lined: ```suggestion return (matched_tags or not tags) and not test_tags.intersection(exclude_tags) ```
I would chop `does_`: ```suggestion if test_match_tags(test, tags, exclude_tags) ```
I would put this test method right before `test_contains()` to match the order of the methods in the class.
Before checking the return value's contents, you should check that its type is `OrderedSet`.
> Well, I considered checking that, but I discarded it because that's actually just testing the native python implementation No, it would be useful because it's checking what `OrderedSet. __reversed__()` returns. It's just that the answer is in terms of a Python dict.
> I also considered testing OrderedSets with miscellaneous data types (like user-defined class instances) rather than just integers. You don't need to check with other data types, or modify other tests. Using integers is fine.
Before this line, you can add `s = reversed(s)`, and then check `s` in the following lines instead of `reversed(s)`.
Sorry, the return value should be an iterator, not an `OrderedSet`. It might be good to check that.
`Cannot change a query once a slice has been taken.` Repeated many times, is it possible to extract a variable.
```suggestion mw_1 = middleware(GetResponse()) ```
This is redundant with `test_none_name()`.
We should probably check for empty strings as well.
We can move `get_migration_name_timestamp()` call to `if`.
Use single-quotes in the new code.
`left_out` is not necessary anymore: ```suggestion name = fragments[0] for fragment in fragments[1:]: new_name = f'{name}_{fragment}' if len(new_name) > 52: name = f'{name}_and_more' break name = new_name ```
This test doesn't have any assertions :thinking:
f-strings shouldn't contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I've moved the initial migrations changes to a separate PR, see #14116.
> What about `_16_more`(16 is the number of operations)? I don't see much value in this format, you still need to open the file to find out more.
```suggestion return "<%s vendor='%s' alias='%s'>" % ( ```
I think it's not worth to include the entire SQL, it should be enough to show a model.
This can cause credential leaks on crash :fire: , e.g. in Sentry. I would leave only `alias` and `vendor`.
Typically repr outputs include quoting around strings. One of the original ideas behind repr was that you should be able to execute the result and get a valid Python object back. ```suggestion return f'{self.__class__.__qualname__}(name=“{self.name}”)' ```
A better way to do this is with `{self.name!r}`.
To be more consistent with other `__repr__()` methods I would use: ```suggestion return '<%s name=%r>' % (self.__class__.__qualname__, self.name) ```
> @felixxm thanks for the extra context, I misread `self._meta_ordering` as `self._meta.ordering`. I did the same at the beginning.
This can be single-lined.
You can reuse `Article`, e.g. ```suggestion Article.objects.filter(headline='Article 1').update(author=self.author_1) Article.objects.filter(headline='Article 2').update(author=self.author_1) Article.objects.filter(headline='Article 3').update(author=self.author_1) Article.objects.filter(headline='Article 4').update(author=self.author_2) articles = Article.objects.values('author').annotate(count=Count('author')) self.assertCountEqual(articles, [ {'author': self.author_1.pk, 'count': 3}, {'author': self.author_2.pk, 'count': 1}, ]) ```
I guess we could use `bulk_update` but not a big deal.
I don't think this is completely correct. Models with a `Meta.ordering` can still make use of explicit `order_by` and when it's the case it should be honored.
I don't think it's worth doing fudges like that without a definite use case. For reference I checked `dataclases` and it leaves generated functions with their standard `__qualname__`: ``` In [1]: from dataclasses import dataclass In [2]: @dataclass ...: class X: ...: y: int ...: In [3]: X.__init__ Out[3]: <function __main__.__create_fn__.<locals>.__init__(self, y: int) -> None> ```
I looked into why the tests are failing. It's because some internals of the URL resolver and admindocs rely on the `__name__` set here. But they could also, more accurately, use the `view_class` atttribute. Therefore I've made PR #14138 to change that. If we go that route then I think we shouldn't even set `__name__` / `__qualname__`. Leaving them as their defaults is sensible and doesn't lie (`__name__ = 'view'` , `__qualname__ = '...View.as_view.<locals>.view'`). One can differentiate class-based views with the `view_class` attribute.
FWIW - These lines were committed in 2010, before python 3.2, when the `__wrapped__` attribute was added. Originally these lines would have worked without introducing any bugs, (but they still would have been semantically incorrect, since `view` isn't being wrapped).
If we use `import inspect`, we can make this a bit simpler: ```suggestion # Remove "self" from the generated view function signature. signature = inspect.signature(view) parameters = tuple(signature.parameters.values())[1:] view.__signature__ = signature.replace(parameters=parameters) ```
@pope1ni Sorry it took a while to get back to you - it's been a hectic 24 hours. But yes, the above seems good to me.
```suggestion # the dispatch method. Note that __name__ and __qualname__ are # intentionally left unchanged, as view_class should be used to robustly ``` A slight change of word order here makes this read more naturally.
This should go up before `import logging`.
@abbasidaniyal We can remove this test now as we're already checking that `__wrapped__` is not set in the test above as that was the source of the problem.
Excellent. Happy with that. So, as I have above, without any `__qualname__`-mangling, should do the trick.
Single quotes please, and you also don't need `.keys()` to check key containment on mappings: ```suggestion self.assertNotIn('self', signature.parameters) ```
The method name is misleading as it is not the signature of `View.as_view()`, but that of the view function it generates. With a good method name we also don't need the docstring as it is clear enough: ```suggestion def test_self_not_in_signature_of_view_generated_by_as_view(self): ``` Quite long, but explicit. 😂
To my mind the real issue here is that we shouldn't be using `update_wrapper` at all (here or above in line 76). `view` is not in any way wrapped by `cls.dispatch` or `cls`. We just happen to want to achieve something similar to what we would want to achieve if we were wrapping a function. By using `update_wrapper` we're setting the `__wrapped__` attribute, so when we call `inspect.signature` it thinks that this function is the decorator, and that the function we're actually interested in is `cls.dispatch`. That's the reason why it returns the signature from `dispatch`. We should just do the thing we want to do directly. Something along the lines of: ``` for attr in functools.WRAPPER_ASSIGNMENTS: # I'm not sure which of these we actually want try: value = getattr(cls, attr) except AttributeError: pass else: setattr(view, attr, value) view.__dict__.update(cls.dispatch.__dict__) ```
This is consistent with how we handle `negated`: ```suggestion kwargs['_connector'] = self.connector ```
Wrap at 79 chars.
We can raise a single error.
We can raise a single error.
The current message sounds good to me.
A new class is not necessary, you can use `MIMEText`.
I moved this class to a separate file.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
We should support `--shuffle` with `--bisect` and `--pair`, i.e. handle it in `get_subprocess_args()`.
```suggestion help=( 'Shuffle the order of test cases to help check that tests are ' 'properly isolated.' ), ) ```
I don't see a reason we can't use Python's `hash()` builtin, which is even faster and cached on strings I also don't think we need a class here - a single function to do the shuffling would do.
I feel like you're just testing argparse here, and this test can be removed. We don't test parsing any other arguments, since we can assume argparse works as advertised.
ditto ```suggestion ```
I don't see any need for this attribute.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
no need for a class-level attribute here, push this down into the function
I guess there is a fair amount of wasted effort for the majority(?) of projects that aren't using admindocs, so perhaps we could have a ticket for it to investigate the possibility of moving the admindocs specific-stuff out.
Interesting, yes -- `_is_callback()` is only used by the admindocs.
Single quotes throughout please 🙂 (As an aside, are we about ready to push forward with black? The DEP is accepted and nearly two years old. It feels like it is time - even though I in my heart I'll always be in the single quote camp! 💔)
Just a few more `"` → `'` here.
*↑* Oh, I'm sorry! 😂
I added also `self.assertHTMLEqual()` assertion.
`SELF_CLOSING_TAGS` contains deprecated tags. I think we should do the same here: ```suggestion # Depracate tags. 'truespeed', } ```
I would add a link to the list: ```suggestion # https://html.spec.whatwg.org/#attributes-3 BOOLEAN_ATTRIBUTES = { ```
Personally, I don't like an idea of comparing string representation, it seems error-prone. We should at least check a class: ```python def __eq__(self, element): if not isinstance(other, self.__class__): return NotImplemented ... ```
Chop blank line.
You shouldn't modify `DiscoverRunner.__init__()`. All of the logic can go in `DiscoverRunner.log()`. In addition to not being necessary, a problem with setting `self.level` is that there will now no longer be one source of truth. For example, a caller that sets `DiscoverRunner.verbosity` after instantiating the runner will get incorrect results when calling `DiscoverRunner.log()`.
There's no need to define your own constants. You can just use `logging.INFO`, etc.
+1, keep self.verbosity because third-party packages will assume ```self.verbosity``` is part of DiscoverRunner. This is a breaking change that's out of the scope of the PR.
The default level should be `logging.INFO` rather than `DEBUG`. However, I would implement this by making the default `None` (`level=None`) and interpreting `None` as `logging.INFO` in the body of the method.
> We define constants like You don't need to define your own constants. You can use e.g. `logging.INFO`, etc. if you need to. I would not modify `DiscoverRunner.__init__()`. Changes can be restricted to the new `DiscoverRunner.log()` using the current `self.verbosity` attribute.
You won't need to pass `INFO` if the default is `INFO`.
Yeah, that works, too.
This test data seems wrong to me. For example, you have verbosity `1` leading to level `DEBUG`, which means that logging at a level of `DEBUG` should result in output per the logic below (since `logging_level >= level` appends `output = True`). That isn't right though, since verbosity `1` shouldn't show `DEBUG`. The test would be a lot easier to understand and update if it was simply a hard-coded, sorted list of tuples, e.g. ```python cases = [ (0, None, False), (0, logging.DEBUG, False), (0, logging.INFO, False), (0, logging.WARNING, False), ... ] ``` Including `level=None` will serve to check the default case. Also, you don't need to check `level=logging.NOTSET` since that's not a level that anyone would ever pass when logging a message. That level is more for when reading what level is set on a configured logger. Having the correct test should help with getting your logic correct in the `log()` method above.
You can just include this in your actual call below, i.e. `runner.log('logging message', level)`.
I think you can simplify the above method implementation quite a bit by using more tailored logic. For example, you can start the method with: ```python if self.verbosity == 0: return ``` and then you're left with just two cases: verbosity `2` or more (log everything), and verbosity `None` and `1` (log `INFO` or higher). This should let you do away with the need for a separate `logging_level` variable. Once your test below is fixed, it should help you understand what's needed here.
Yeah, in tests it's often okay to duplicate things. (By the way, can you just test equality of strings instead of contains? That would be more precise, and you would just have a single assert line with two different expected values.)
No problem, happy to help. Thanks for keeping at it.
No empty line at the beginning.
This can be moved to the very beginning.
You can just say `expected`. (It's clear from the next line.)
You can simplify the rest of the method by doing: ```python if self.verbosity == 1 and level is not None and level < logging.INFO: return print(msg) ``` (This is what I meant when I said the `logging_level` variable could be eliminated.)
It looks like you need to pass `level` `DEBUG` here and below.
Again, it looks like you need to pass the level.
Since this might not be obvious from the method implementation, it's probably worth spelling out with another sentence in the docstring: "A verbosity of 1 logs INFO (the default level) or above, and verbosity 2 or higher logs all levels" (can go on a separate line).
I think something like, "Log the message at the given logging level." would be a bit better. (PEP 8 says no "s" at the end of "Log," by the way.)
You can remove the empty line above and the two empty lines below.
It simplifies getting the default behavior for callers defining functions that pass through a logging level because they can just pass `None` for the default, instead of having to hard-code the default in a second location or invoke the function in a different way (without passing the argument).
~~`verbosity` is already validated `django.core.management.base.BaseCommand`,~~ I don't think we need any validation for `level`.
It might be helpful to explain: "Invalid - urlparse() raises ValueError", or following the other examples: ``` >>> urlparse('https://[') ValueError: Invalid IPv6 URL ```
@adamchainz It says to remove self but can it get called for a static method or a class method? In the case of classmethod it will remove the cls. In the case of staticmethod it may remove argument.
This is redundant with an existing assertion, IMO we can drop it.
```python if step_size is not None: self.validators.append(validators.StepValueValidator(step_size)) ``` Use `django.core.validators.MinValueValidator` as a blueprint and create a `StepValueValidator`. Put the validation code from `to_python` in there.
then this has to be adopted as well
This of course is debatable, but how about this message: `'Ensure this value is a multiple of step size %(limit_value)s.'`
set default `step_size=None` instead of `"any"` and only render that attribute if it's `not None`.
```python math.isclose(math.remainder(value, step), 0, abs_tol=1e-9) ```
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
I think we should make `Value` inherit from `SQLiteNumericMixin`.
OK, thanks. Don't worry someone will prepare a patch.
There is no need to create a random suffix. We should also test all described scenarios, e.g. ```suggestion test_connection = copy.copy(connections[DEFAULT_DB_ALIAS]) test_connection.settings_dict = copy.deepcopy( connections[DEFAULT_DB_ALIAS].settings_dict, ) tests = [ ('test.sqlite3', 'test_1.sqlite3'), ('test', 'test_1'), ] for test_db_name, expected_clone_name in tests: with self.subTest(test_db_name=test_db_name): test_connection.settings_dict['NAME'] = test_db_name test_connection.settings_dict['TEST']['NAME'] = test_db_name creation_class = test_connection.creation_class(test_connection) clone_settings_dict = creation_class.get_test_db_clone_settings('1') self.assertEqual(clone_settings_dict['NAME'], expected_clone_name) ```
I would remove extra lookups and based `iso_year` on the `self.lhs`, e.g.: ```python def year_lookup_bounds(self, connection, year): from django.db.models.functions import ExtractIsoYear iso_year = isinstance(self.lhs, ExtractIsoYear) output_field = self.lhs.lhs.output_field if isinstance(output_field, DateTimeField): bounds = connection.ops.year_lookup_bounds_for_datetime_field( year, iso_year=iso_year, ) else: bounds = connection.ops.year_lookup_bounds_for_date_field( year, iso_year=iso_year, ) return bounds ```
We could add a small release notes about this change in the [Database backend API](https://docs.djangoproject.com/en/dev/releases/4.0/#database-backend-api) section, e.g.: ``` * ``DatabaseOperations.year_lookup_bounds_for_date_field()`` and ``year_lookup_bounds_for_datetime_field()`` now take the optional ``iso_year`` argument in order to support bounds for ISO-8601 week-numbering years. ```
There is no need to use `assertQuerysetEqual`, I would compare list of instances, e.g.: ```python obj_1_iso_2015 = self.create_model(week_1_day_2014_2015, end_datetime) obj_2_iso_2015 = self.create_model(week_53_day_2015, end_datetime) ... self.assertSequenceEqual(qs, [obj_1_iso_2015, obj_2_iso_2015]) ```
Sorry, these parameters are already checked in `save()` so there is no need to change these assertions.
I moved this test to the `tests/invalid_models_tests/test_models.py`.
I think we can revert changes to `from_model` assertions, it's rather an internal message useful when you write `check()` tests.
`HTTPS` is not necessary, so I removed this line.
We should fix this side-effect, probably by providing a custom `Round._resolve_output_field()` method, .e.g. ```python class Round(FixDecimalInputMixin, Transform): ... def _resolve_output_field(self): source = self.get_source_expressions()[0] return source.output_field ```
`Backend` supports negative precision, `SQLite` does not: ```suggestion raise ValueError('SQLite does not support negative precision.') ```
I think we should raise `ValueError` on SQLite when a negative precision is passed, e.g.: ```python def as_sqlite(self, compiler, connection, **extra_context): expression2 = self.get_source_expressions()[1] if isinstance(expression2, Value) and expression2.value < 0: raise ValueError('SQLite does not support negative precisions.') return super().as_sql(compiler, connection, **extra_context) ``` especially that it is simply treated as 0. I would also remove admonition about _"negative values for precision argument"_.
```suggestion n1 = models.DecimalField(decimal_places=2, max_digits=6) ```
`null=True, blank=True` are not necessary for this patch. Please revert them: ```suggestion ('n1', models.DecimalField(decimal_places=2, max_digits=6)), ```
Only if we use another variable, from the guide: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style > As a guide, f-strings should use only plain variable and property access, with prior local variable assignment for more complex cases I think it's fine as-is
I'm not sure if it deserves for a separate hook :thinking:
> That's the problem with using the correct (matching) tag in the test. It will still pass even without a syntax error. Are you sure? Maybe I'm missing sth, but `test_tag_fail_to_load` fails (as expected) without the fix :thinking: : ``` FAIL: test_tag_fail_to_load (test_runner.test_discover_runner.DiscoverRunnerTests) ---------------------------------------------------------------------- .... AssertionError: 0 != 2 ```
> By using a matching tag (`syntax_error`), the test will still pass with `NameError`. It would be better to (1) use a non-matching tag, and ... I wanted a regression test for the scenario described in the ticket. > ... (2) perhaps test that it's really a `SyntaxError`. Thanks. I've changed to a `SyntaxError`.
The walrus operator is not valid at the top level: ```python >>> a := 1 File "<stdin>", line 1 a := 1 ^ SyntaxError: invalid syntax ``` I've switched to sth more obvious.
UnqiueConstraint is suggested instead of unique_togather in newer versions [2.2+]
beside the flake8 error dont need to inherit from object
Yes I was thinking about this. Personally, I don't think catching small accuracy errors is that important here so let's use `-1` for all DBs :+1:
You also have to pass `'number'` as the last argument to `npgettext_lazy`, and in each line below.
```suggestion return Database.sqlite_version_info >= (3, 35) ```
`fetchall()` returns a list not a tuple on SQLite. ```suggestion statement into a table, return the list of returned data. ```
```suggestion # SQLite < 3.35 doesn't support an INSERT...RETURNING statement. ```
Perhaps only override for older Pythons? ```suggestion if not PY310: def __repr__(self): return '%s.%s' % (self.__class__.__qualname__, self._name_) ```
This is not covered by tests, also raising an exceptions in user-defined functions is not really helpful for users: ```python django.db.utils.OperationalError: user-defined function raised exception ``` I think we should return `None` instead.
I moved this check to the `DurationExpression`.
True, sorry for an undoable request. Folks can always use `sqlite3.enable_callback_tracebacks(True)` to see this message :shrug: .
I would add a separate hook for this (in a separate commit), e.g. ```python def _sqlite_prepare_dtdelta_param(conn, param): if conn in ['+', '-']: if isinstance(param, int): return datetime.timedelta(0, 0, param) else: return backend_utils.typecast_timestamp(param) if conn in ['*', '/'] and not isinstance(param, (int, float)): raise TypeError return param @none_guard def _sqlite_format_dtdelta(conn, lhs, rhs): """ LHS and RHS can be either: - An integer number of microseconds - A string representing a datetime - A scalar factor (e.g. float) """ conn = conn.strip() try: real_lhs = _sqlite_prepare_dtdelta_param(conn, lhs) real_rhs = _sqlite_prepare_dtdelta_param(conn, rhs) if conn == '+': # typecast_timestamp returns a date or a datetime without timezone. # It will be formatted as "%Y-%m-%d" or "%Y-%m-%d %H:%M:%S[.%f]" out = str(real_lhs + real_rhs) elif conn == '-': out = str(real_lhs - real_rhs) elif conn == '*': out = int(real_lhs * real_rhs) else: out = int(real_lhs / real_rhs) except (ValueError, TypeError): return None else: return out ```
`first()` is not crucial for this regression, so I've changed this to the `order_by()`.
I would prefer the solution from #9339 where we list all missing files not only all labels.
Do we need `app_labels`? IMO it should be fine to check all apps like in `check_consistent_history()`.
Please add a period: ```suggestion """Display server name and port after server bind.""" ```
We could just use f-strings here: ```suggestion errno.EACCES: f"You don't have permission to access port {self.port}.", errno.EADDRINUSE: f"Port {self.port} is already in use.", errno.EADDRNOTAVAIL: f"IP address {self.addr!r} can't be assigned to.", ``` (I know this means generating three strings when we'll only show one, but it isn't really going to add any significant overhead.)
If we don't go with the above, this should at least use a dict literal: ```suggestion error_text = ERRORS[e.errno] % {'addr': self.addr, 'port': self.port} ```
`server_name` is unused.
I think we should rather take into account `one_to_one` fields in [L2101](https://github.com/django/django/pull/14255/files#diff-1c8b882c73bfda668d5451d4578c97191b0ebc0f088d0c0ba2296ab89b428c44R2101) :thinking:
Move this test below the `test_check_constraint_pointing_to_reverse_fk`.
Please revert unrelated "blank" changes.
This is unused, please remove it.
Maybe `__qualname__` is better? Besides that, left you a small suggestion how your exception message may be improved. ```suggestion raise AttributeError( f"{cls.__qualname__} already has an attribute '{name}' which would be " f"overridden." ) ```
In this case, the error message is **not** as good I think, as that we get from the System Check, which is pretty explicit... `The field 'fk_id' clashes with the field 'fk' from model 'invalid_models_tests.model'.` (`E006`)
This leads to somewhat odd behavior. I assume, this is to allow overriding fields from abstract parents. However, maybe a warning is better suited here, since there might be a reason, why 3rd party overrides an existing attribute. I think it's a good idea to warn people, but I wouldn't go as far as to actively prevent people from doing so.
You are shadowing the original exception here, which could be useful for debugging. I am also not use your exception adds a lot more helpful context. Capturing `Exception` or `BaseException` is usually a red flag, as the underlying error could be anything. I would suggest removing the whole exception handling part. After that, it stands to reason, if you need to new two line method. If not, we should at least include the original exception. ```suggestion try: cls.add_to_class('id', pk_field) except Exception as e: raise FieldError(f"Adding the automatically gennerated primary key field to {cls.__qualname__} failed.") from e ```
This seems a little Herculean to maintain the existing check. (`E004`) If we are to push forwards with this, maybe we should remove that one? 🤔 (I appreciate it but, is re-adding the old add_to_class() method not a sign that it's done? 🤷‍♀️)
I would do what the other tests do and pass `test_labels` as a positional argument. Also, to be clearer what `foo` and `bar` are doing, it might be better to call them something like `notfound1` and `notfound2`. I'm assuming it's finding two failed test instances for labels not found. Alternatively, you could find real tests by passing something starting with `'test_runner_apps...'`.
Since `verbosity=1` is the default, you can leave this out. (It's good to be testing the default behavior.)
Yes, but as `REQUIRED_PYTHON` is 3.8, if `CURRENT_PYTHON` were 3.7, this would trigger. You'd be told to install `django<2` when higher versions are supported by Python 3.7.
Excellent, looks like we are aligned in our assessment! Thanks for the additional insights on this.
```suggestion if not (self.is_vsi_based and self.name.startswith(VSI_MEM_FILESYSTEM_BASE_PATH)): ``` This change should be covered by tests.
I was thinking about the same, but without any static list we cannot perform a proper validation. A wildcard approach is fine IMO, we can add a small warning in the docs, e.g. ``` .. warning: Rasters with names starting with `/vsi*/` will be treated as rasters from the GDAL virtual filesystems. Django doesn't perform any extra validation. ```
True, my bad, sorry https://github.com/django/django/pull/14296
`assertCountEqual`? This sometimes fails on CockroachDB.
So the question is whether it's safe to do this. (From security or regressions POV.)
Possibly, but it makes the commit here less clear. Please do revert. (We could assess whether there's a readability improvement as a separate change, but it's probably not worth it for me.)
Why move this line? There's no behaviour change no? I think revert this please.
This can be simplified to-- ```python if col in self.query.extra_select or self.query.combinator: ``` by changing the order of the two cases.
Since what you're appending here is the same as what's being appended in the second `else` clause below, it looks like you could adjust your conditional to handle both of these cases, so there would be two cases in all instead of three.
This test is too specific, IMO. It's should be enough to check that `SECRET_KEY` is lazy validated.
Please change to inner imports.
`asc` is misleading, because it's basically a default ordering. Renamed to the `default_order`.
Is there any way to prevent this? I'm actually running into a PostgreSQL syntax error because of it. I have these two custom functions: ```python from django.db.models.expressions import Func class Any(Func): function = "ANY" class Array(Func): function = "ARRAY" ``` And I'm trying to run a query similar to this: ```python Foo.objects.filter( pk=Any( Array( Foo.objects.filter(...).values("pk")[:1000] ) ) ).delete() ``` Before this change, it produced SQL like this: ```sql WHERE V0."id" = ANY(ARRAY(...)); ``` After this change I get this which isn't valid: ```sql WHERE V0."id" = (ANY(ARRAY(...))); ``` ``` ERROR: syntax error at or near "ANY" LINE 1: ... V0."id" FROM "foo" V0 WHERE V0."id" = (ANY(ARRAY(... ^ ``` Basically, `ANY` doesn't like being wrapped.
spelling / typo: parentheses
me too :+1:
`test_run_as_non_django_module` already exists, please use a different name.
I think a little clearer if less repetitive: ```suggestion args.append('-m') if (modspec.name == "__main__" or modspec.name.endswith(".__main__")) and modspec.parent: args.append(modspec.parent) else: args.append(modspec.name) args += sys.argv[1:] ```
Trailing comma: ```suggestion migrations.RunPython.noop, ```
Trailing comma: ```suggestion migrations.RunPython.noop, ```
```suggestion 'INSERT INTO test_runsql_pony (pink, weight) VALUES (1, 1)\n', ```
I guess, as we're relying on there being whitespace, we should make this explicit: ```suggestion 'INSERT INTO test_runsql_pony (pink, weight) VALUES (1, 1);\n', ```
I think this is good, but wonder if we can also change to the following in `django.db.backends.postgresql.client.DatabaseClient.settings_to_cmd_args_env()`: ```python return args, (env or None) ``` This seems to fit with the expectation that `None` is returned when nothing is being added to the environment.
I think the variable names have nothing to do with this regression. Also it's much easier to fix a regression introduced in commit with a small diff, that's why we prefer small diffs for patches that will be backported. P.S. Note that we're not all "guys" so please use gender neutral greetings, https://heyguys.cc/
I'd just stick with `env` over `extra_env` which will keep the diff to a minimum: ```suggestion args, env = self.settings_to_cmd_args_env(self.connection.settings_dict, parameters) env = {**os.environ, **env} if env else None ```
```suggestion **kwargs, ```
It's not really related with `black`. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
```suggestion **kwargs, ```
```suggestion **kwargs, ) ```
```suggestion **kwargs, ) ```
I meant all changed lines not only this particular place :wink:
@pope1ni Thanks for the suggestion, but IMO it's less readable and it's more complex (as far as I'm aware) :thinking: : <details> ```pycon >>> import dis >>> def test_1(): ... possible_lang_codes = [] ... lang_code = 'zh-hans-mo' ... lang_code_split = lang_code.split('-') ... for i in range(len(lang_code_split) - 1, 0, -1): ... possible_lang_codes.append('-'.join(lang_code_split[:i])) ... >>> def test_2(): ... possible_lang_codes = [] ... lang_code = 'zh-hans-mo' ... i = None ... try: ... while i := lang_code.rindex('-', 0, i): ... possible_lang_codes.append(lang_code[:i]) ... except ValueError: ... pass ... >>> dis.dis(test_1) 2 0 BUILD_LIST 0 2 STORE_FAST 0 (possible_lang_codes) 3 4 LOAD_CONST 1 ('zh-hans-mo') 6 STORE_FAST 1 (lang_code) 4 8 LOAD_FAST 1 (lang_code) 10 LOAD_METHOD 0 (split) 12 LOAD_CONST 2 ('-') 14 CALL_METHOD 1 16 STORE_FAST 2 (lang_code_split) 5 18 LOAD_GLOBAL 1 (range) 20 LOAD_GLOBAL 2 (len) 22 LOAD_FAST 2 (lang_code_split) 24 CALL_FUNCTION 1 26 LOAD_CONST 3 (1) 28 BINARY_SUBTRACT 30 LOAD_CONST 4 (0) 32 LOAD_CONST 5 (-1) 34 CALL_FUNCTION 3 36 GET_ITER >> 38 FOR_ITER 28 (to 68) 40 STORE_FAST 3 (i) 6 42 LOAD_FAST 0 (possible_lang_codes) 44 LOAD_METHOD 3 (append) 46 LOAD_CONST 2 ('-') 48 LOAD_METHOD 4 (join) 50 LOAD_FAST 2 (lang_code_split) 52 LOAD_CONST 0 (None) 54 LOAD_FAST 3 (i) 56 BUILD_SLICE 2 58 BINARY_SUBSCR 60 CALL_METHOD 1 62 CALL_METHOD 1 64 POP_TOP 66 JUMP_ABSOLUTE 38 >> 68 LOAD_CONST 0 (None) 70 RETURN_VALUE >>> dis.dis(test_2) 2 0 BUILD_LIST 0 2 STORE_FAST 0 (possible_lang_codes) 3 4 LOAD_CONST 1 ('zh-hans-mo') 6 STORE_FAST 1 (lang_code) 4 8 LOAD_CONST 0 (None) 10 STORE_FAST 2 (i) 5 12 SETUP_FINALLY 42 (to 56) 6 >> 14 LOAD_FAST 1 (lang_code) 16 LOAD_METHOD 0 (rindex) 18 LOAD_CONST 2 ('-') 20 LOAD_CONST 3 (0) 22 LOAD_FAST 2 (i) 24 CALL_METHOD 3 26 DUP_TOP 28 STORE_FAST 2 (i) 30 POP_JUMP_IF_FALSE 52 7 32 LOAD_FAST 0 (possible_lang_codes) 34 LOAD_METHOD 1 (append) 36 LOAD_FAST 1 (lang_code) 38 LOAD_CONST 0 (None) 40 LOAD_FAST 2 (i) 42 BUILD_SLICE 2 44 BINARY_SUBSCR 46 CALL_METHOD 1 48 POP_TOP 50 JUMP_ABSOLUTE 14 >> 52 POP_BLOCK 54 JUMP_FORWARD 20 (to 76) 8 >> 56 DUP_TOP 58 LOAD_GLOBAL 2 (ValueError) 60 COMPARE_OP 10 (exception match) 62 POP_JUMP_IF_FALSE 74 64 POP_TOP 66 POP_TOP 68 POP_TOP 9 70 POP_EXCEPT 72 JUMP_FORWARD 2 (to 76) >> 74 END_FINALLY >> 76 LOAD_CONST 0 (None) 78 RETURN_VALUE ``` </details>
While longer, this avoids creating the extra list, string building and "complex" range calculations: ```suggestion i = None try: while i := lang_code.rindex('-', 0, i): possible_lang_codes.append(lang_code[:i]) except ValueError: pass ``` I know it also uses the walrus operator, but Django 4.0 is targeting Python 3.8+, so it is available to us. It seems much more readable to me. (If this isn't a performance critical path then `contextlib.suppress()` could be used to shave off two lines.)
Thanks both :+1: I pushed edits.
These are not related with the `fallback` feature so I moved them to a separate test.
I've changed to `CaptureQueriesContext()`.
That's a nice trick! Certainly better than my idea of using a regex ;-).
If we're only passing in an `int` to `b62_encode()` as is the case in the only use of the function, then: ```suggestion sign = '-' if s < 0 else '' ```
I would move all internal import to the module level, e.g. ```python with ignore_warnings(category=RemovedInDjango50Warning): from django.utils.baseconv import ( BaseConverter, base2, base16, base36, base56, base62, base64, ) class TestBaseConv(SimpleTestCase): ... ```
We don't need to support different bases or other negation signs so I would expect a simplified implementation.
Because we use `-Wall` on Jenkins, so it's already consumed. I don't think there is a reliable way to test this.
```suggestion return '-' + value if neg else int(value) ```
```suggestion return '-' + value if neg else value ```
Are we expecting `s` to be anything other than `str`? If it were `bytes` this would fail as it would convert to `"b'...'"`. ```suggestion ```
Indeed, but this is a new, private copy intended for use in `django.core.signing` only. It seems sensible to limit it to the minimum required functionality.
Not sure this is any better, probably slower due to the function call, but putting it out there for consideration. ```suggestion num, remainder = divmod(num, 62) res = BASE62_ALPHABET[remainder] + res ```
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
I think we'll want to use `Table` and `IndexName` https://github.com/django/django/blob/65a9d0013d202447dd76a9cb3c939aa5c9d23da3/django/db/backends/base/schema.py#L1033-L1042 Otherwise column renames and deletion in the same migration will break.
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
> Current PR (Allows user to specify suffix - consistent with posgresql backend): Users cannot specify `prefix` it is an option that Django uses internally. I think we should keep the current prefix `_id` for backward compatibility.
We shouldn't change the current logic and use `_id` instead of `suffix` from `kwargs`.
You want to do it the other way around; no adjustments should be required to the base schema adaptor. In order to achieve that you'll want to have the PostGIS `_create_index_sql` method *not* pass `fields` but `expressions` when necessary ```python def _create_index_sql(self, model, *, fields=None, **kwargs): if fields is None or len(fields) != 1 or not hasattr(fields[0], 'geodetic'): return super()._create_index_sql(model, fields=fields, **kwargs) field = fields[0] template = None if field.geom_type == 'RASTER': # For raster fields, wrap index creation SQL statement with ST_ConvexHull. # Indexes on raster columns are based on the convex hull of the raster. template = self.rast_index_wrapper % '%(expressions)s' elif field.dim > 2 and not field.geography: # Use "nd" ops which are fast on multidimensional cases template = "%%(expressions)s %s" % self.geom_index_ops_nd expressions = None if template is not None: fields = None expressions = [Func(Col(field.column), template=template)] using = ' USING %s' % self.geom_index_type return super()._create_index_sql(model, fields=fields, expressions=expressions, using=using) ```
We can pass `opclasses` to the `super()._create_index_sql()`.
I think we can change `rast_index_wrapper` instead.
I moved `child` and `parent` to a separate templates.
If you look at `__init__`, this is a simple class that is easy to reconstruct, so we don't need to use the `<…>` pattern. Also consider that `varname` could be `None` so shouldn't be manually quoted like this, get it's repr instead. I'd change this to the following: ```python return f'{self.__class__.__name__}(path={self.path!r}, varname={self.varname!r})' ```
Please remove type annotations. We don't currently use them in Django.
This doesn't work. The substitution must happen after the translation: ```suggestion _('Can %(action)s %(verbose_name)s') % {'action': action, 'verbose_name': opts.verbose_name_raw} ``` I think, in this case, you can use `gettext` instead of `gettext_lazy`.
These strings should not be translated like this as they are used to generate the value for `Permission.codename`. This means that the values could be stored in the wrong language breaking permissions in the admin site.
Can we add a note to the docstring? e.g. ```python """Year, 4 digits with leading zeros; e.g. '1999'.""" ``` and to the docs: https://github.com/django/django/blob/205c36b58fed5a1a0ff462593fc61b58189027d8/docs/ref/templates/builtins.txt#L1370 e.g. ``` ``Y`` Year, 4 digits with leading zeros. ``'0000'``, ...,``'1999'``, ...,``'9999'`` ```
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
I think this changes the logic (possibly in a way not detected by CI if tests are run in a UTC locale). Needs to handle the USE_TZ case to get the UTC time.
I think neither branch here is using a deprecated / semi-deprecated call, but this is a bit more readable, IMO. I think this can be further simplified, though, because I think `.timestamp ` might do the same thing in both the if and else blocks.
The abstract model will not be registered, thus not be included in your test. You might need to call the check manually to validate your change.
This bit wasn't broken before, right? So, there should be already tests covering this behavior.
This is unused now, besides that, it's looking good. However, I presume one of the follows has more ideas on how to improve the tests. They know the test suite better.
I would keep the tests as atomic as possible. That aside, if you want to test the behavior for `abstract=False`, I would recommend dropping the PK and test that the check fails, hence the code inside the if-statement is actually being executed.
This change is unnecessary and unrelated. We support both `password` and `passwd` options in `DATABASES['OPTIONS']`.
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
I wonder if it's worth pointing to the alternative here. 🤔
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
This looks unnecessary.
I think it's enough to check `apps.py`. Also, `assertEquals()` is a deprecated alias of `assertEqual()`.
Can we also assert that `startapp` created some files?, e.g. ```python def test_trailing_slash_in_target_app_directory_name(self): app_dir = os.path.join(self.test_dir, 'apps', 'app1') os.makedirs(app_dir) _, err = self.run_django_admin(['startapp', 'app', os.path.join('apps', 'app1', '')]) self.assertNoOutput(err) self.assertIs(os.path.exists(os.path.join(app_dir, 'apps.py')), True) ```
We could use `top_dir` instead of stripping `os.sep`, e.g ```python else: top_dir = os.path.abspath(os.path.expanduser(target)) if app_or_project == 'app': self.validate_name(os.path.basename(top_dir), 'directory') ... ```
Hey! This test passes as it is ensuring that one particular error doesn't occur but the assertion is suppressing another error: <img width="1792" alt="image" src="https://user-images.githubusercontent.com/10276811/117889344-082ce100-b2d1-11eb-9d95-6fc5ba25296b.png"> Refer to my PR (#14382) for a way to assert that no error is occurring.
_Ideally_, unless you are testing a failure condition, you don't want tests to result in an error. So the test case which ensures that an error is raised when the target directory does not exist will be the one in which that error should occur. In this case, the test should ensure that running `$ ... startapp app directory/` works successfully given that everything else is in place. Consider this hypothetical scenario during a refactor: - Code is moved around such that `if not os.path.exists(top_dir): raise Error` occurs before `self.validate_name` - `.rstrip(os.sep)` is deleted. The test case will still pass but the command will fail at that point.
```suggestion HAS_COLORAMA = True ```
Good question. It’s also possible for this to be a VoiceOver-only issue – right now it’s very hard for me to test with any other screen reader, so I haven’t tested it anywhere else (but wouldn’t be surprised if other assistive technologies had the same issue). Screen readers do have wildly different behaviors for accessible name computation, as well as role, and lots of parts of the ARIA spec, so yes nonetheless it needs dealing with. I also can’t see `type="radio"` or checkbox in your link, which is a bit puzzling to me.
This is one problem, but if it stopped there it would just be a minor source of confusion. The real issue is that for screen reader users the first label’s text will be the only thing announced as the label of the first choice. So people don’t know what the first option is meant to be.
Here is the relevant WebKit bug: https://bugs.webkit.org/show_bug.cgi?id=152663. Opened since 2016 unfortunately. I’ve added the details we researched, although the initial report was already pretty clear.
Thank you, looks great to me. Sorry it took so long to get to the bottom of this! It’s a good reminder for me to properly caveat my findings for future issues.
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
```suggestion with self.assertWarnsMessage(RemovedInDjango50Warning, msg): ```
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
I think the wording could be improved a little here: ```suggestion if not self.protocol and not protocol: warnings.warn( "The default protocol will be changed from 'http' to 'https' " "in Django 5.0. Explicitly pass 'protocol' to this method or " "to the constructor to silence this warning.", category=RemovedInDjango50Warning, ) ``` Don't forget to update the tests too.
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
`any()` is nice but it's over-engineering for me, we don't need to create a tuple and use `any()` to check two values. ```suggestion if self.protocol is None and protocol is None: ```
Thanks for being more explicit about this than I was! (https://github.com/django/django/pull/14396#discussion_r632488901)
It is fine to say "Fixed" as the fellows will handle making the actual change when removing the deprecation when it matures.
```suggestion 'If you want to keep a False value for this setting, explicitly set ' ```
True, thanks :+1:
Maybe :thinking: : ```python # RemovedInDjango50Warning. USE_TZ = True ````
I pushed Simon's suggestion and fixed `flake8`/`isort`.
Both approaches work but I wonder if we'd want to be a bit more liberal here and simply return `copy` if no `output_field` can be retrieved. ```suggestion field = getattr(copy.lhs, 'output_field', None) if field is None: return copy ``` It would also avoid having to specify an explicit `output_field` when using a `Func` and `RawSQL` when users usually know what they are doing.
Good catch :dart:
They'll still be dependent on `cwd` I think... 🤔
But should we worry about non-existent directories? we can use `template_tests/templates/first` and `template_tests/templates/second` in tests.
Why not `resolve()`? :thinking:
This test seems correct. I think the class (or this method) docstring should call out the exception case.
```suggestion def test_repr(self): admin_site = CustomAdminSite(name='other') self.assertEqual(repr(admin_site), "CustomAdminSite(name='other')") ```
Please move it below the `__init__()`, we also don't need to use `<...>` notation, so maybe: ```suggestion return f'{self.__class__.__name__}(name={self.name!r})' ```
Please remove `OtherAdminSite`, we can re-use `CustomAdminSite` instead.
Use `assertContains()/assertNotContains()` instead.
Please add trailing commas to all of these new assertions, e.g. ```suggestion )['sum_awards'], None, ```
```suggestion # Nested coalesce ```
Condense? ```suggestion if result is NotImplemented or result is not None: return result ```
I was just thinking that perhaps we should name this `empty_value` instead: ```suggestion empty_value = None ``` After all, this attribute is intended for use on subclasses of `Aggregate` only, so the naming is a bit redundant.
Equally, as this is in `get_aggregation()` we can probably have: ```suggestion empty_result = [ ```
Yup, sorry! 🤕 Nothing else to add then. This is ready.
I'm a bit confused, but how it will work for multiple aggregations :thinking: ? e.g. ```python Book.objects.none().aggregate(pages_count=Count('pages'), rating_sum=Sum('rating')) ```
This test doesn't contain expressions.
That's the thing. I don't (didn't) know what implications these boundmethods have. If they're not worth mentioning, I think it's fine. And yes, they're likely much smaller than `ProjectState.__dict__`.
It's risky to use a mutable default. I've changed this to `None`.
Seem like all of these could be merged in a single `alter_model_option` method and even possible merged with `alter_model_options`.
These don't make sense, the state logic should not know about `Operation` instances at all.
As an example. The method signature should be ```python def rename_model(self, app_label, old_model_name, new_model_name): ... ``` And be called from `RenameModel.state_forwards` as `state.rename_model(app_label, self.old_name_lower, self.new_name_lower)` instead of passing the `Operation` instance along.
That makes sense, I think we'll need to keep passing the case aware names in this case for `rename_model`.
Might be worth moving theses utils to `django.db.migrations.utils` instead since they are used outside of `.operations` now.
Since most of the logic related to field referencing will be used by `django.db.migration.state` I think it would make sense to fold/merge `django.db.migrations.operations.utils` into `django.db.migrations.utils`.
```suggestion state.rename_model(app_label, self.old_name_lower, self.new_name_lower) ```
Looks like `self.model_name_lower` could be passed here and we could avoid all the `.lower()` handling in `.rename_field`. ```suggestion state.rename_field(app_label, self.model_name_lower, self.old_name, self.new_name) ```
```suggestion model_state = self.models[app_label, model_name] ```
These are unnecessary ```suggestion ```
```suggestion self, (app_label, model_name), (old_name, found), ```
```suggestion self.reload_model(app_label, model_name, delay=delay) ```
```suggestion def rename_field(self, app_label, model_name, old_name, new_name): ```
```suggestion def alter_field(self, app_label, model_name, name, field, preserve_default): ```
```suggestion def remove_field(self, app_label, model_name, name): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
```suggestion model_state = self.models[app_label, model_name] model_state.options = {**model_state.options, **options} for key in alter_option_keys: if key not in options: model_state.options.pop(key, False) self.reload_model(app_label, model_name, delay=True) ```
```suggestion def alter_model_managers(self, app_label, model_name, managers): ```
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
```suggestion renamed_model = self.models[app_label, old_name].clone() ```
```suggestion self.remove_model(app_label, old_name) self.reload_model(app_label, new_name, delay=True) ```
```suggestion old_model_tuple = (app_label, old_name) ```
```suggestion self.models[app_label, new_name] = renamed_model ```
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
Chop blank line.
```suggestion # with mset(). ```
Do we need to call `bool()` again? it's already called in `RedisCacheClient.touch()`.
Do we need to call `bool()` again? it's already called in `RedisCacheClient.delete()`.
Do we need to call `bool()` again? it's already called in `RedisCacheClient.clear()`.
Chop blank lines.
I would use a dict instead. ```suggestion self._pools = {} ``` and in `_get_connection_pool()`: ```python def _get_connection_pool(self, write): index = self._get_connection_pool_index(write) if index not in self._pools: self._pools[index] = self._pool_class.from_url( self._servers[index], **self._client_kwargs, ) return self._pools[index] ```
Do we need to call `bool()` again? it's already called in `RedisCacheClient.add()`.
```suggestion # the server, e.g. sharding. ```
FWIW +1 to doing it as a separate clean up. IMO it'll be much clearer what change was where looking back that way.
```suggestion self._servers[index], **self._client_kwargs, ```
Chop blank line.
```suggestion # Write to the first server. Read from other servers if there are more, # otherwise read from the first server. ```
```suggestion # The redis backend does not support cull-related options like `MAX_ENTRIES`. ```
The nested import doesn't look needed. 🤔
I don't think that `BaseSerializer` is necessary. I only want to avoid defining the same class in different places so moving `PickleSerializer` (as described in https://github.com/django/django/pull/14437#discussion_r696343672) is enough.
Chop blank lines: ```suggestion pool_index = cache._cache._get_connection_pool_index(write=False) ```
I think that we should unpack `self._options` here and make them arguments of `RedisCacheClient.__init__()`. ```suggestion return self._class(self._servers, **self._options) ``` This is how we approach this for all of the memcached backends using client classes implemented in third-party packages.
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
So [`.flushall()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.flushall) will clear everything in all databases. (Apparently Redis has 16 logical databases that can be switched between.) We should change this to use [`.flushdb()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.flushdb) instead and only clear the current database. For consistency we can also ensure this returns a boolean. ```suggestion return bool(client.flushdb()) ``` (We should probably also expose a `db` parameter via `RedisCacheClient.__init__()` which can be passed through via `_client_kwargs`. It should have a default value of `0`.)
Let's make `write` a keyword-only argument. ```suggestion def get_client(self, key=None, *, write=False): ```
Do we need to allow customisation of the client class via a setting? That seems like bikeshedding. If someone wanted to write and provide a custom client they can subclass `RedisCache` themselves.
We should try to keep similar naming, like `BaseMemcachedCache._class`: ```suggestion self._class = self._options.get("CLIENT", RedisCacheClient) ```
I think this is a typo: ```suggestion def _cache(self): ``` There is only one cache client class instance returned, cf. `BaseMemcachedCache._cache`
I guess we can avoid keyword args here for consistency. ```suggestion self._caches.set(key, value, self.get_backend_timeout(timeout)) ```
And this would be... ```suggestion self._serializer = PickleSerializer(pickle_protocol) ```
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Yes, sorry, I meant `max()`.
This functionality looks to have been inherited or intentionally taken from `BaseMemcachedCache`, and the **memcached** cache docs say: `To take advantage of this feature, include all server addresses in LOCATION, either as a semicolon or comma delimited string, or as a list.` (they then fail to give an example of the multi-server string form, but never mind). As far as I can see from the docs and examples in this PR, that line, or one like it, is missing. Presuming this is intentionally riffing on the memcached implementation, I think a docs note is in order (or just remove the functionality entirely? :)) Apologies if this has already been brought up somewhere upthread. To say there has been conversation on this PR would be an understatement :)
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Don't use `.items()` if you don't need the values. ```suggestion # Set timeout for each key individually as .mset() doesn't support # setting the timeout for all keys at the same time. for key in data: if timeout is None: client.persist(key) else: client.expire(key, timeout) ```
Ensure we return booleans here for consistency? ```suggestion if timeout is None: return bool(client.persist(key)) else: return bool(client.expire(key, timeout)) ```
As discussed, we can simplify this a bit, also benefiting from the `min(0, ...)` in `get_backend_timeout()`: ```suggestion if timeout == 0: if ret := bool(client.set(key, value, nx=True)) client.delete(key) return ret else: return bool(client.set(key, value, ex=timeout, nx=True)) ```
As discussed, we can simply `.delete()` here when `timeout == 0`. We can do this if we fix `get_backend_timeout()` to prevent negative numbers as mentioned above. ```suggestion if timeout == 0: client.delete(key) else: client.set(key, value, ex=timeout) ```
Although you changed this, I think you missed the the bit in https://github.com/django/django/pull/14437#discussion_r658641917 that the `if` can now go outside of the `for` to avoid a pointless iteration when `timeout` is `None`. ```suggestion # Set timeout for each key individually as .mset() doesn't support # setting the timeout for all keys at the same time. if timeout is not None: for key in data: client.expire(key, timeout) ```
~~Do we want to use [`.setex()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.setex)?~~ ```suggestion client.setex(key, timeout, self._serializer.dumps(value)) ``` ~~This is just an observation that can be ignored. Maybe it is better to keep `.set()` as for `.add()` above where there is no combination of `.setex()` and `.setnx()`, requiring the use of `.set()` instead.~~ **Edit:** Definitely ignore this as I read the following [here](https://redis.io/commands/set): > Note: Since the SET command options can replace SETNX, SETEX, PSETEX, GETSET, it is possible that in future versions of Redis these commands will be deprecated and finally removed.
We don't need the extra variable here. ```suggestion client.mset({k: self._serializer.dumps(v) for k, v in data.items()}) ```
Please move `add()` above `get()` to keep the order consistent with the definition in `BaseCache` and other backends. (It's probably worth ordering the methods in `RedisCacheClient` in the same way.)
Shouldn't this be writable? ```suggestion client = self.get_client(None, write=True) ```
We could flatten this? ```suggestion return default if value is None else self._serializer.loads(value) ```
I understand. Although I'm wondering if this is something that can just be configured by passing something in `OPTIONS` that is passed to the client class such that you don't need two separate client classes? (Failing that, a separate backend, e.g. `RedisShardedCache`, might make more sense? I know we are implementing the client class here, but for all other backends we are using an existing client class from a third-party package - we are never exposing knowledge of the client class to the end user.) Either way, if that sharded implementation is coming later (whether in another commit or PR), let's not add this client class loading stuff now. It doesn't add any benefit to this initial implementation other than making it more complex to review.
Please move `clear()` below `set_many()` to keep the order consistent with the definition in BaseCache and other backends. (It's probably worth ordering the methods in `RedisCacheClient` in the same way.)
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
The current coding style prefers single quotes. Please fix throughout, but new code only. ```suggestion if 'PICKLE_VERSION' in options: ``` _(Eventually it will be double quotes when we can use `black`.)_
As this is a docstring, prefer triple double quotes. ```suggestion """Redis cache backend""" ``` _(We don't change existing cases to avoid churn, but it'll all eventually be solved when `black` is out of beta.)_
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
Yes. ISTM that it is worth trying to do it via options first and then we can always look to use a different client class if it becomes absolutely necessary. Let's start out with something simple. The other benefit is that we (well, you!) are writing the client class and not linking to a third-party package. As such we can adjust it to fit our needs exactly. (When I wrote the `PyMemcacheCache` backend I even contributed changes to `pymemcache` to address some issues with compatibility as that was preferable to creating another custom client.)
Ah, yes. Good observation. 🙂
As discussed, move into the top of `RedisCacheClient.__init__()`.
I would follow PEP 257 with triple double quotes as suggested by @pope1ni and the ending period. ```suggestion """Redis cache backend.""" ```
Trailing comma... ```suggestion exclude=redis_excluded_caches, ```
This pattern is common to all backends. Maybe it makes sense to merge them together? If there is reason to call `make_key()` without validation it could learn `validate=False()`. Either way, it's a separate PR.
That's a matter of perspective. I find consistency across the codebase is also something to consider, particularly where the implementation is following the exact same pattern. Otherwise, you create islands of custom behaviour that may diverge enough to become a problem later.
See #14802 and ticket-33060.
> This pattern is common to all backends. Note that the `filebased` backend doesn't follow this pattern. It puts the `make_key()` / `validate_key()` lines in a single place: https://github.com/django/django/blob/3445c50a3affc5ae7b1c2712a139d4a5105aeaf5/django/core/cache/backends/filebased.py#L130-L131
I wouldn't say it's a separate PR since this is new code being added for the first time, and one can evaluate what is being added on its own merits. The method I'm proposing would be specific to this class, so it wouldn't affect other backends.
I don't think there is any point in creating `BaseCacheSerializer` and we can rename `PickleCacheSerializer`: ```suggestion class PickleSerializer: ```
Maybe: ```suggestion self._pool_options = {'parser_class': parser_class, 'db': db} ```
This docstring isn't necessary as the method name is should be clear enough. ```suggestion ```
Single quotes please. Also, can we use `size` instead of `dims` for consistency with the other tests? ```suggestion size = images.get_image_dimensions('missing.png') self.assertEqual(size, (None, None)) ```
Please move the `close = True` out of the `try:` block and remove the unused local `e`. ```suggestion try: file = open(file_or_path, 'rb') except OSError: return (None, None) close = True ```
Good catch :dart: , I missed this :facepalm:. Please feel-free to send a patch
I think it would be helpful if this were instead named `invalid_token_re`. The reason is that I coincidentally happened to be reading `csrf.py` and was confused by these lines: https://github.com/django/django/blob/b746596f5f0e1fcac791b0f7c8bfc3d69dfef2ff/django/middleware/csrf.py#L111-L112 The reason this was confusing is that this isn't a regex that matches tokens. It matches invalid tokens. And then I saw this was changed in this PR only a few days ago.
Yeah it's quite inconsistent :disappointed:. I think we should change `columns` to `fields` in a separate PR.
I would revert this change and ignore the `db_tablespace` option when a database doesn't support it.
Might want to squeeze all lines to follow the _style_ of the test module.
This is a "database cache"-specific tests, so it's not required. I removed it.
I think it should be good enough for now if it brings Oracle back to what it was, I was also confused by these failures.
> Weird stuff! Oracle doesn't ignore unnecessary `ORDER BY` clauses in subqueries, i.e. it raises an error if a subquery doesn't use `DISTINCT`, `FOR UPDATE`, or is not sliced. I renamed `supports_ordered_subquery` to `ignores_unnecessary_order_by_in_subqueries`, it's more accurate, IMO.
You'll want to use provided `connection` here to make sure we support mixed `DATABASES` backends to a certain extent.
```suggestion # __spec__ may not exist, e.g. when running in a Conda env. ```
The minimum supported Python version for the next major Django release is 3.8 so this version check is not needed.
I think it's too detailed, maybe: ```suggestion "The included URLconf '{name}' does not appear to have " "any patterns in it. If you see the 'urlpatterns' variable " "with valid patterns in the file then the issue is probably " "caused by a circular import." ```
Kwargs notation is not necessary. Also parentheses are missing: ```suggestion return f'{self.__class__.__name__}({self.user!r})' ```
Please compare to the expected value, e.g. `PermWrapper(...)`.
It's a top-level class internal class so it doesn't matter.
> Wouldn't we have to change the tests, if by any chance we change the class name? Yes and it's expected, we will be aware which tests are affected by our change to the base class. IMO it's also more readable.
I would assert with an explicit representation (except `TEMPLATE_DIR` which depends on OS) e.g. ```python self.assertEqual(repr(engine), ( f"<Engine dirs=[{TEMPLATE_DIR!r}] app_dirs=True " f"context_processors=[] loaders=[" f"'django.template.loaders.filesystem.Loader' " f"'django.template.loaders.app_directories.Loader'] " ... )) ```
Please add all initialization parameters to the `__repr__()` and keep the order from `__init__()`. We should also use `repr()` for most attributes, e.g. ```python def __repr__(self): return ( f'<{self.__class__.__qualname__} dirs={self.dirs!r} ' f'app_dirs={self.app_dirs} ' f'context_processors={self.context_processors!r} ' f'debug={self.debug} loaders={self.loaders!r} ' ... ) ```
It's only `__repr__()`, I don't think it's worth to test all cases.
They can be empty for subclasses, I think we can leave it that way.
I think the `_db` is redundant here - it's quite clear it refers to the database since we're in database features.
This extra newline seems unrelated and should be removed.
This won't work on Oracle because you're trying to create the same table twice.
We shouldn't use the same chain on `replace()` in multiple places, use `quote_value()` instead.
We shouldn't use quotes in SQL statements. Values must be properly quoted before passing to the statements.
Please revert unrelated blank line changes.
`other_actions` can be an empty list so there is no need to check it: ```suggestion post_actions.extend(other_actions) ```
`return` is not necessary.
Please assert with the expected string e.g. ```python self.assertEqual(repr(cl), '<ChangeList: model=Child model_admin=ChildAdmin>') ```
I don't see much value in including `opts`, `lookup_opts`, or `root_queryset`. I would limit representation to the `model` and `model_admin`. We can always add sth in the future, if needed.
Extra spaces around `=` are not necessary: ```suggestion return ( f'<{self.__class__.__qualname__}: model={self.model.__qualname__} ' f'model_admin={self.model_admin.__class__.__qualname__}>' ) ```
We want to save file with the `symlink.txt` name so this assertion doesn't have much value IMO. I would check that the new file exists.
Would another option be to define a simple `_load_with_patterns()` context manager and use that in `load_tests_for_label()` around the affected lines? It looks like only `loadTestsFromName()` and `discover()` need to be protected, as some returns don't actually wind up loading.
Nit: `test_loader_patterns_not_mutated` (with an "s")
It looks like this test itself isn't isolated. 😄 A context manager like this could be useful for both tests: ```python @contextmanager def _temp_loader_patterns(self, patterns): original_patterns = DiscoverRunner.test_loader.testNamePatterns DiscoverRunner.test_loader.testNamePatterns = patterns try: yield finally: DiscoverRunner.test_loader.testNamePatterns = original_patterns ``` For this `patterns` argument, you will want to pass something _different_ from `['UnittestCase1']`, and the assertion that it's not mutated can go in the body of the test itself.
The `test_name_patterns` argument shouldn't normally end in `.py` (that's `pattern`). So you can just pass `['UnittestCase1']` via this argument.
Nit: I would call this "saved" or "original" patterns, because technically it might not be the default.
Looks like you forgot to change the operator: ```suggestion return Q(self) ^ Q(other) ```
Please can you duplicate this for `__rxor__()`.
Please add a period: ```suggestion raise TypeError('The XOR operator is not supported on this database backend.') ```
As far as I'm aware this should be moved to the `Q.__xor__`.
```suggestion # Convert `A XOR B` to `(A OR B) AND NOT (A AND B)`. lhs = self.__class__(self.children, OR) rhs = self.__class__(self.children, AND, negated=True) return self.__class__((lhs, rhs), AND, self.negated).as_sql(compiler, connection) ```
Is this correct? As far as I'm aware `OR` is not an effective connector with not negated `XOR` :thinking: ``` p XOR q = (p OR q) AND NOT (p AND q) NOT (p XOR q) = NOT ((p OR q) AND NOT (p AND q)) = NOT (p OR q) OR (p AND q) ``` so `OR` is an effective connector for negated `XOR`, maybe: ```python may_need_split = ( (in_negated and self.connector in {AND, XOR}) or (not in_negated and self.connector == OR) ) ``` Also, tests are missing.
I have some nitpicks to these tests but I can push them later after the final review.
This doesn't work with many conditions, e.g. `a ^ b ^ c` see `XorLookupsTests.test_filter_negated()`.
We have many old tests in `queries` with unnecessary docstrings.
I checked this carefully and when connector is `XOR` we always have to push the whole branch to `HAVING` clause.
I know that tests in `queries` are mixed up, however I would move it to the `Queries6Tests` class.
This docstring doesn't have much value, I'd remove it.
This is already tested and it works without the patch, so I removed it.
I wonder if this and below wouldn't be more readable as `32 * 'a' + 32 * 'b'` but no strong feelings
@kezabelle What do you think about adjusting a docstring? :point_up:
Maybe: ```suggestion """ Return the given value. The default implementation of this method handles exceptions raised during rendering, that is not necessary for text nodes. ```
I would call `render()`, if case someone subclasses `TextNode` :thinking: ```suggestion return self.render() ```
~~I changed this to an assertion for the only file that is affected by the second round of post-processing i.e. `cached/relative.css`.~~
Why the `CombinedExpression` and not `Expression`? IMO it's misleading, I know that `CombinedExpression` has the concept of right-hand and left-hand sides but for other purposes.
> both `CombinedExpression` and `Lookup` combine a left and a right expression. Not always, many lookups are complicated expressions or even function calls. The only common factor for me is that both have two arguments. Also `CombinedExpression` has a lot of unnecessary logic, e.g. `SQLiteNumericMixin`. We should probably compare `Lookup` subclassing `Expression` vs. `CombinedExpression` :thinking:
I wonder if this could be addressed by adding a `MultiColSource` method that returns `self`
Yes, we need it, sorry for the noise https://github.com/django/django/pull/14494#discussion_r657703518.
OK, we need it :+1:
We could optimize this a bit: ```python if not self.prepare_rhs or hasattr(self.rhs, 'resolve_expression'): return self.rhs if hasattr(self.lhs, 'output_field'): ... ```
I think we should keep this property or add `c.is_summary = summarize` to the `resolve_expression()`.
```suggestion c = self.copy() ```
Wonder if we should check for `output_field` instead? ```suggestion if expression.output_field.empty_strings_allowed: ```
I wonder if a crash similar to 170b006 can happen if the lhs is a `Subquery` annotation.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
Chop blank line.
This should be in a `finally` block.
I don't think there's a need to delete attributes now, since they're not used in `hasattr` checks. I guess deleting them helps reduce memory consumption a tiny bit though.
The one place this branch might happen is if someone has used `register.tag` to register a tag that doesn't return a `Node` instance. It makes pretty clear in the docs that you should return a `Node`, but it feels like that someone could very easily fall into the trap of not doing so. Since (up until now) such an error would still work (I think) the error would go undetected. As such, maybe a release note could be warranted? It would mean that if some tags suddenly break upon updating Django, then the release notes would provide an avenue for investigation. On the other hand, perhaps I am overestimating how likely this is. 🤷
According to the `Node.render` docstring it should "Return the node rendered as a string" so if we really wanted to optimise for speed, we could potentially forgo the `str` as well, but I think probably better safe than sorry here, so better to leave it in.
Well, actually it'd better to enforce return from `Node.render()` string or list of strings. Multiple copies of strings leads to square complexity/
I run both with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` without it: ``` ~/repo/django> ./tests/runtests.py backends/postgresql ``` works and ``` ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. Sorry for confusing.
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
```bash ~/repo/django> ./tests/runtests.py backends/postgresql Testing against Django installed in '/home/felixx/repo/django/django' with up to 8 processes backends Found 1 test(s). System check identified no issues (0 silenced). E ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ---------------------------------------------------------------------- Ran 1 test in 0.000s FAILED (errors=1) ~/repo/django> ./tests/runtests.py tests/backends/postgresql Testing against Django installed in '/repo/django/django' with up to 8 processes tests Found 23 test(s). Creating test database for alias 'default'... Cloning test database for alias 'default'... Cloning test database for alias 'default'... Cloning test database for alias 'default'... Creating test database for alias 'other'... Cloning test database for alias 'other'... Cloning test database for alias 'other'... Cloning test database for alias 'other'... System check identified no issues (0 silenced). EEE.................... ====================================================================== ERROR: backends.postgresql.test_introspection (unittest.loader._FailedTest) ---------------------------------------------------------------------- Traceback (most recent call last): File "/usr/lib/python3.8/unittest/case.py", line 60, in testPartExecutor yield File "/usr/lib/python3.8/unittest/case.py", line 676, in run self._callTestMethod(testMethod) File "/usr/lib/python3.8/unittest/case.py", line 633, in _callTestMethod method() File "/usr/lib/python3.8/unittest/loader.py", line 34, in testFailure raise self._exception ImportError: Failed to import test module: backends.postgresql.test_introspection Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 436, in _find_test_path module = self._get_module_from_name(name) File "/usr/lib/python3.8/unittest/loader.py", line 377, in _get_module_from_name __import__(name) File "/repo/django/tests/backends/postgresql/test_introspection.py", line 6, in <module> from ..models import Person File "/repo/django/tests/backends/models.py", line 8, in <module> class Square(models.Model): File "/repo/django/django/db/models/base.py", line 113, in __new__ raise RuntimeError( RuntimeError: Model class backends.models.Square doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS. ====================================================================== ERROR: backends.postgresql.test_operations (unittest.loader._FailedTest) ---------------------------------------------------------------------- Traceback (most recent call last): File "/usr/lib/python3.8/unittest/case.py", line 60, in testPartExecutor yield File "/usr/lib/python3.8/unittest/case.py", line 676, in run self._callTestMethod(testMethod) File "/usr/lib/python3.8/unittest/case.py", line 633, in _callTestMethod method() File "/usr/lib/python3.8/unittest/loader.py", line 34, in testFailure raise self._exception ImportError: Failed to import test module: backends.postgresql.test_operations Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 436, in _find_test_path module = self._get_module_from_name(name) File "/usr/lib/python3.8/unittest/loader.py", line 377, in _get_module_from_name __import__(name) File "/repo/django/tests/backends/postgresql/test_operations.py", line 7, in <module> from ..models import Person, Tag File "/repo/django/tests/backends/models.py", line 8, in <module> class Square(models.Model): File "/repo/django/django/db/models/base.py", line 113, in __new__ raise RuntimeError( RuntimeError: Model class backends.models.Square doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS. ... ```
I don't know what you're saying but it sounds rude in cockney rhyming slang... https://en.wiktionary.org/wiki/bristol#Noun
Okay fine by me, as long as the ticket exists :)
`test_target_field_may_be_pushed_down` works without the patch. I would move it to a separate commit to make it clear where the behavior has changed.
Would it be worth emphasising that this straying from pythonic expectation is an _undesirable_ behaviour? In case `ModelBase.__new__()` were to get rewritten in future, and whoever works on it ends up thinking they need to be supporting these testcases? Orr just writing the testcase as an expected failure would imply this.
```suggestion class ScalarParent(models.Model): foo = 1 class ScalarOverride(ScalarParent): foo = models.IntegerField() self.assertEqual(type(ScalarOverride.foo), DeferredAttribute) ```
I think it would be more correct for the error description to be first, and help text second, as in Django’s default rendering the error messages appear before the field while the help text appears after.
Unfortunately as far as I can tell this doesn’t work in VoiceOver, due to the `ul` still being present. None of the content within the `ul` is announced. The content is correctly announced with the `div` alone, removing the list markup. I also tried adding `role="presentation"` to the `ul` so screen readers bypass the list semantics, that worked as expected, but since the error list still is visually displayed as a list it’s pretty jarring to have to force it to not be announced as once.
Question: Isn’t this going to break if `error_class` is provided in the constructor? I would have expected: ```suggestion '<div id="{}_errorlist"><ul class="{}">{}</ul></div>', self.field.id_for_label, ``` A few lines up – If I read this right this would lead to having a space in the id, which is not allowed. ```python self.error_class = 'errorlist {}'.format(error_class) ``` Additionally `_errorlist` seems to be hard-coded as the ID suffix in the `aria-describedby`.
Yes, that sounds good to me.
This docstring needs updating, I think.
Hm, yes, I forgot this is an async queue so `put()` won't just sleep synchronously. I think catching QueueFull and sleeping would accomplish the same thing, though, and give you a queue with one sync "end" and one async "end",
It won't necessarily - the queue means it'll be unloaded as it's loaded - but I do wonder if giving the queue an explicit length and using normal `put()`, or some similar way of _limiting_ the amount of memory used, would be sensible.
Well the thing is that what StreamingResponse returns isn't guaranteed to be single bytes - if I remember right, it can be chunks of any size - so the queue size isn't going to directly dictate the number of bytes stored in memory. 5 would be a good first start, but I wonder if there's a way to cap the number of _bytes_ too here, along with the sentinel value idea.
Your solution honestly isn't _that_ much more complex, so I'm not saying we shouldn't do it, I was just curious how you ended up here! I think the resulting patch is pretty nice - I will need to take more time to properly review it but I like it on first glance.
It seems like you should be able to do this without creating a new task for each call to `get()` and instead awaiting `get()` directly. For example, you could add a sentinel value to the queue when the sync iterator has been exhausted and check whether the retrieved value is the sentinel to know whether any items are left.
I would use the same format as in `HttpResponse.__repr__()`: ```suggestion return '<%(cls)s status_code=%(status_code)d%(content_type)s>' % { 'cls': self.__class__.__qualname__, 'status_code': self.status_code, 'content_type': self._content_type_for_repr, } ```
There is not need for an extra variable (`expected_repr_response`), also, we should call `__repr__` directly: ```suggestion self.assertEqual(repr(r), '<StreamingHttpResponse status_code=200>') ```
This introduces a regression from 7ec2a21be15af5b2c7513482c3bcfdd1e12782ed. We need a selenium test to cover it but, if I create an `<input type="number" />` without the `step` specified at all, I can't enter a non-integer value, such as `0.5` without triggering the browser validation (_Enter a valid value_). This ties in with [MDN docs for `step`](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/number#step): > The default stepping value for number inputs is 1, allowing only integers to be entered…
```suggestion msg = "'Ensure this value is a multiple of step size 0.02.'" with self.assertRaisesMessage(ValidationError, msg): ```
This needs tests in `tests/validators/tests.py`.
Thanks @prestontimmons — that's really handy. I appreciate it was a long time ago now, but just wanted to see that no immediate red flag popped up for you. (The discussion on #6498 is a monster 😅)
We should omit `default_bounds` when the default value is used: ```suggestion if self.default_bounds and self.default_bounds != '[)': kwargs['default_bounds'] = self.default_bounds ```
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
I'd chop blank lines: ```suggestion self.range_kwargs = {} if default_bounds := kwargs.pop('default_bounds', None): self.range_kwargs = {'bounds': default_bounds} ```
Yes, we should raise a `ValueError` for incorrect values.
I'd move this at the beginning of `__init__()`. Also, chop blank lines.
Please revert unrelated changes.
Do we need this check? All tests pass without it.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
```suggestion self.default_bounds = kwargs.pop('default_bounds', CANONICAL_RANGE_BOUNDS) ```
```suggestion msg = f"Cannot use 'default_bounds' with {field_class_name}." with self.assertRaisesMessage(TypeError, msg): ```
It's an attribute so folks can try to change it dynamically. I would add `if self.default_bounds and ..`
Please revert unrelated changes.
`timestamps_closed_bounds` field is defined with closed bounds in `default_bounds` so the current name is good, IMO. This test is to ensure that `default_bounds` doesn't impact open bounds pass in `DateTimeTZRange`.
We could also do not pass `default_bounds` when not provided, e.g. ```python class BaseRangeField(forms.MultiValueField): ... def __init__(self, **kwargs): ... self.range_kwargs = {} if default_bounds := kwargs.pop('default_bounds', None): self.range_kwargs = {'default_bounds': default_bounds} super().__init__(**kwargs) def compress(self, values): ... try: range_value = self.range_type(lower, upper, **range_kwargs) except TypeError: ... ```
This version works fine, however it's a bit confusing that we concatenate escaped and unescaped string. I would use `middle` for both, e.g. ```python punctuation_count = len(middle_unescaped) - len(stripped) trail = middle[-punctuation_count:] + trail middle = middle[:-punctuation_count] ```
```suggestion raise TypeError('Signal receivers must be callable.') ```
Please revert unrelated changes.
Wrap at 79 chars.
```suggestion raise TypeError( ```
Please revert unrelated changes.
```suggestion if 'uidb64' not in kwargs or 'token' not in kwargs: ```
I think we should ignore models with an invalid app label. I don't see much value in raising a warning for them. ```suggestion cls._meta.app_config and not cls._meta.app_config._is_default_auto_field_overridden ```
`clean()` works without this patch. The issue is in rendering a bound field. We should check `errors` and `as_p()`.
We can leave an assertion for `value()`, but the two above assertions should also be added. It's not enough to check that `as_p()` is not `None`.
I don't see much value in this assertion we should check `as_p()` and `errors`, e.g. ```python self.assertEqual(form.errors['json_field'], ['This field is required.']) self.assertIn('null</textarea>', form.as_p()) ```
> Ok! I'll change the `self.assertIsNotNone(form.as_p())` to something that asserts the text. We don't need to assert the entire HTML, `self.assertIn('null</textarea>', form.as_p())` is enough. > Do you think we need to check the errors dict? The issue doesn't really have anything to do with validation from what I can gather, which is why I removed the required=True argument from the original PR, but I can re-add it if you want. Bound form is typically used due to invalid input, so IMO it makes sense to check `errors`.
> I guess the behaviour of the field informs what the widget/form render? Yes.
```suggestion rows_updated = 0 if not objs: ```
```suggestion return rows_updated ```
Yes please remove unnecessary blank lines.
Please remove this blank line as requested by Paolo.
Compared to this other query: ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
Ditto. ```suggestion # Check empty result with non-execution optimization. with self.assertNumQueries(0): ```
Ditto. ```suggestion # Check empty result when query must be executed. with self.assertNumQueries(1): ```
I'm not sure we need the extra helper functions. If the string cannot be parsed the exception will be raised and the test will fail - the assertions are unnecessary: ```suggestion if format == 'json': # Parse the result to check it is valid JSON. json.loads(result) elif format == 'xml': # Parse the result to check it is valid XML. xml.etree.ElementTree.fromstring(result) ```
Please move this to a separate commit as an extra test coverage.
Yup. Happy with this. Was originally mulling over `self.fail(…)`.
Then we can get rid of these. ```suggestion ```
I think we usually use `cached_property` for these.
I could be missing something here but is this even necessary? ```suggestion ```
We don't need to call `ArrayLenTransform()`: ```suggestion sibling_count=models.Max('sibling_ids__len') ```
```suggestion field__len=models.OuterRef('field__len'), ```
Maybe ```suggestion ).filter(same_sized_fields__len__gt=1), ```
Why not `first()`? :thinking: ```suggestion ).first().ids, ```
Maybe ```suggestion [len(self.objs) - 1] * len(self.objs), ```
```suggestion ).values_list("siblings_json", flat=True).first() ```
```suggestion self.assertSequenceEqual( ```
Why not `first()`? :thinking: ```suggestion ).first().sibling_ids, ```
If I can bring a little bit of nuance to my position. Yes, Python supports aware time. However, the majority opinion in Django contributions (AFAIK) is that using this feature is likely to result in worse design than not using it. Many users aren't experts able to delineate narrow sets of circumstances under which code manipulating aware times is more likely to be correct (e.g. "my code will never be used outside HK and HK will never introduce DST [alternative: I will write a unit test that fails if HK ever introduces DST]"). The recommendation would be to manage the time and the timezone in separate objects. There are other cases where Django diverges from Python's standard behavior. For example, I have found the transaction behavior mandated by PEP 249 less than helpful for most users and I have decided to default to autocommit in Django instead.
```suggestion if match := datetime_re.match(value): ```
```suggestion if match := date_re.match(value): ```
IMO we don't need to catch `TypeError` because it will only cause another `TypeError` in the `.match()` call, so I would prefer ``` return datetime.date.fromisoformat(value) TypeError: fromisoformat: argument must be str ``` instead of ``` match = date_re.match(value) TypeError: expected string or bytes-like object ```
Chop blank line.
```suggestion return datetime.datetime(**kw, tzinfo=tzinfo) ```
```suggestion if match := time_re.match(value): ```
I think it's more readable (and readability is crucial in the ORM) with the opposite of `alternate_output_field` e.g. `source_output_field`: ```python def get_col(self, alias, output_field=None): source_output_field = output_field is None if source_output_field: output_field = self if ( alias != self.model._meta.db_table or (not source_output_field and output_field != self) ): from django.db.models.expressions import Col return Col(alias, self, output_field) else: return self.cached_col ```
`sql_table_creation_suffix()` will raise an exception so there is no need to pass anything except `COLLATION`.
Handling the positive case first would look cleaner: ```python if field_name in self.models[model_key].fields: ``` Note also that I don't think you need to use `keys()`.
It looks like if you set a variable equal to `to_model[model_key]` before this line, you can use it here and twice below (since `self._relations[from_model]` is `to_model`). You might also consider doing (using the right variable name to assign to): ```python try: to_fields = to_model[model_key] except KeyError: continue ``` Or maybe the latter won't work since you're using `defaultdict`'s.
I think the lines below will be easier to understand if before this line, you define a variable equal to `self._relations[remote_model_key][model_key]`, or at least `self._relations[remote_model_key]`.
It looks like you can actually do `fields = self.models[model_key].fields` (similar to further down) since you're only using `model_state.fields` below.
The following pattern is getting used here a lot: ```python if 'all_relations' in self.__dict__: ... else: self.all_relations ``` It seems like it should be possible to make this pattern simpler and easier to understand. For example, it looks like the current pattern relies on `@cached_property` setting a key in `self.__dict__`, but it doesn't seem like that should be necessary as it relies on a couple implementation details. (A `cached_property` is more common for cases where the caller doesn't care about whether the value has been cached yet -- you just access the property like a normal property -- but here you do care.) What about making it so that the check can instead be `if self.all_relations is None` (and not using `cached_property`), and then call a method to set it if it is `None`? Another idea would be to make the if check an appropriately named method call that returns a boolean and sets it if necessary. Then no `else` clause would be needed each time this pattern is used.
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
I meant in cases where you have many lines after `if self._relations is not None:`, you can change it to be: ```python if self._relations is not None: self.some_method(...) ``` instead of ```python if self._relations is not None: # many lines ... ```
This would be cleaner if you did the following before handling the `self._relations is not None` case: ```python if self._relations is None: fields[name] = field return ``` Then you don't need to indent after.
Similarly, you could define `model_key` before the `self.models[app_label, model_name].fields[name] = field` line above, which would let you use it there as well.
I don't think you need `list()` here.
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
I think this would be simpler if you did: ```python if old_remote_field: if new_remote_field: ... else: # Include code from the `if old_remote_field` case below. ... elif new_remote_field: # Include code from the `elif new_remote_field` case below. ```
It might make the code easier to understand if each chunk of code following `if self._relations is not None:` is its own helper method with a descriptive name.
Use more significant variable names here and take advantage of `.pop` return value ```suggestion for model_relations in relations.values(): if old_name_key in model_relations: model_relations[new_name_key] = model_relations.pop(old_name_key) ```
This code should only be performed if `relations` are already built. ```suggestion if old_name_key in self.relations: ```
Is this really necessary? I don't see any harm in leaving an empty list and all tests work without these lines.
Is this really necessary? I don't see any harm in leaving an empty list and all tests work without these lines.
This should only be performed if the `relations` registry is already computed; `if 'relations' in self.__dict__`
This change needs to be performed even if `apps` is not cached as that's an independent registry. A few things seems wrong/unnecessary here. I don't think there's anything wrong in leaving ```suggestion removed_model_key = (app_label, model_name) self.relations.pop(removed_model_key, None) for model_key, model_relations in list(relations.items()): model_relations.pop(removed_model_key, None) if not model_relations: self.relations.pop(model_key) ```
Again there's a bit of unnecessary work here (alot of unnecessary `.lower()` calls that can be cached in local variables)
This is the same as the inner block of `populate_relation_from_model_state()`, maybe we should refactored out another hook, e.g. `resolve_model_field_relations()` and use it here and in `populate_relation_from_model_state`.
```suggestion old_name_key = app_label, old_name_lower new_name_key = app_label, new_name_lower ```
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
We've checked that `old_name_key` is in the `model_relations` there is no need to pass a default value to `pop()`: ```suggestion model_relations[new_name_key] = model_relations.pop(old_name_key) ```
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
Moreover this hook could be moved to a separate commit/PR.
You could use `setdefault((model_state.app_label, model_state.name_lower), {})` here.
This a the kind of `O(m*n)` operation we'd want to avoid doing as it will become increasingly slower as projects get larger. Having a reverse map that allows direct access to objects pointing to an object being removed is necessary IMO. In other words, you need to find a way to perform this operation in constant time.
Ditto about a need to perform this operation in constant time.
The map should get automatically populated from the provided models and not specified through initialization as that's an internal data structure.
I don't think we should automatically resolve fields and relations at initialization time as they won't be needed most of the time. I'd suggest using the same approach as the `apps` `cached_property` where methods are in charge of looking up `'relations' in self.__dict__` to determine if the cache needs updating or not.
Maybe `resolve_model_relations`? Also, we can pass `real_apps` to avoid casting to `set()` for each model. ```suggestion def resolve_model_relations(self, model_state, model_key, concretes, real_apps): ``` Alternatively, we could add `self._real_apps_set = set(self.real_apps)` in a separate PR because it does not changed after the initialization and we're casting it to `set` in multiple places, or even cast `real_apps` to `set` in `ProjectState.__init__()` (see #14760).
```suggestion self.relations[new_name_key] = self.relations.pop(old_name_key) ```
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
To avoid calling `_get_concrete_models_mapping_and_proxy_models()` in multiple places I changed signature of new helpers to `concretes=None`.
This change is unnecessary, reverted.
This change is unnecessary, reverted.
You can reuse `resolve_model_field_relations()`.
You can reuse `resolve_model_field_relations()`.
You can reuse `resolve_model_field_relations()`.
Revert unrelated changes to blank lines.
We can use `self.real_apps`, there is no need to pass `real_apps`.
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
Please remove unrelated blank lines.
These lines will be unnecessary with the new version of `resolve_model_field_relations()` (see #14781) because it uses `self.real_apps` and handles `concretes`.
Changes in hooks are included in #14781.
Changes in hooks are included in #14781.
We can take `model_state` from `self.models`, there is no need to pass `model_state`.
Use single quotes.
Do we need to call `set()` in all tests? it seems unnecessary.
Please use "real" names, not `foo`, `bar`, `foobar`, e.g. `Author`,`Song`.
```suggestion self.resolve_model_field_relations(model_key, name, field) ```
Oh, when I was reading before, I thought the function ended there. It could still help readability to do the `if self._relations is None:` case first, since there are less "nots" to look at.
It looks like `update_model_field_relation()` is only called when `self._relations` is not `None`. Can you use `self._relations` here, then, instead? That would eliminate the uncertainty when reading of what code path is executing when the `relations` property is called.
```suggestion # It's safe to modify the same collection that is iterated ```
```suggestion ) ```
```suggestion f'site={self.admin_site!r}>' ) ```
Blank line is missing: ```suggestion from .sites import CustomAdminSite ```
Can we do it like: ```suggestion return ( (self.connection.mysql_is_mariadb and self.connection.mysql_version >= (10, 6)) or (self.connection.mysql_version >= (8, 0, 1) ) ```
Could use `charset` over `character_set`? It's a well-known "word" and losing the underscore might make this less noisy visually, especially in the f-strings. Only a suggestion, feel free to ignore.
Question mark has been moved here but not in `ask_rename_model` or `ask_merge` - I think it should go back to before the `[y/N]` for consistency with those.
here in `ask_not_null_addition ` the text is `[...] without specifying a default; because the [...]` but in `ask_not_null_alteration` it is `[...] without providing a default because the [...]` without the semicolon. Both should probably be the same, and personally something _feels_ off about having a because preceded by a semicolon. (though I can't codify the rule as to _why_ in my head), YMMV.
```suggestion print('Please enter the default value as valid Python.') ```
We can use f-string: ```suggestion f"Accept the default '{default}' by pressing 'Enter' or " f"provide another value." ```
This sentence is too long, IMO. Maybe: ```python choice = self._choice_input( f"It is impossible to add a non-nullable field '{field_name}' " f"to {model_name} without specifying a default. This is " f"because the database needs something to populate existing " f"rows.\n" f"Please select a fix:", [ ... ```
I would revert this change, the previous version is clearer to me.
I would revert this change, the previous version is clearer to me.
Period: ```suggestion "Quit and manually define a default value in models.py.", ```
I would revert this change, the previous version is clearer to me.
Period ```suggestion "Quit and manually define a default value in models.py.", ```
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to change a nullable field '{field_name}' " f"on {model_name} to non-nullable without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n" f"Please select a fix:" [ ... ```
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
I would leave the first part of the sentence untouched. Also please use hanging indentation: ```suggestion print( 'The datetime and django.utils.timezone modules are available, so ' 'it is possible to provide e.g. timezone.now as a value.' ) ```
I don't think we need parentheses and `Note:`. Also, there is no need to use `!`. Maybe: ```suggestion 'Ignore for now. Existing rows that contain NULL values ' 'will have to be handled manually, for example with a ' 'RunPython or RunSQL operation.', ``` ```
Period ```suggestion 'Quit and manually define a default value in models.py.', ```
For new code, we're using single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I'm guessing that you're referring to `MigrationQuestioner.ask_merge`? I don't think `[y/N]` is necessary there, since it's only in the docstring and not asked as a question to the user interactively.
`nun` should be `non`.
Yup, that sounds good too. :)
Same concern with `later` here.
As many as we can :smile:
`later` is a bit misleading, since the expectation is that the dev will update models.py (immediately) after quitting so that they can continue to create their migrations.
```suggestion str(ErrorList(['Grace is not a Zombie'], error_class='nonform')) ```
This can be single-lined ```suggestion '<ul class="errorlist nonform"><li>Please submit at most 1 form.</li></ul>', ```
Please revert removing blank line.
Can we use `value` instead of `string`? sorry for bikeshedding.
We shouldn't silently change passed parameters. IMO it better to raise an exception like we do now: ``` $ export DJANGO_SETTINGS_MODULE=test_oracle $ ./runtests.py queries --parallel=2 Testing against Django installed in '/django/django' with up to 2 processes Found 416 test(s). Creating test database for alias 'default'... Creating test user... Cloning test database for alias 'default'... Traceback (most recent call last): File "./runtests.py", line 659, in <module> failures = django_tests( File "./runtests.py", line 385, in django_tests failures = test_runner.run_tests(test_labels) File "/django/django/test/runner.py", line 881, in run_tests old_config = self.setup_databases( File "/django/django/test/runner.py", line 787, in setup_databases return _setup_databases( File "/django/django/test/utils.py", line 217, in setup_databases connection.creation.clone_test_db( File "/django/django/db/backends/base/creation.py", line 239, in clone_test_db self._clone_test_db(suffix, verbosity, keepdb) File "/django/django/db/backends/base/creation.py", line 255, in _clone_test_db raise NotImplementedError( NotImplementedError: The database backend doesn't support cloning databases. Disable the option to run tests in parallel processes. ```
Not exactly, we only changed the `parallel` to `1` when it was not given. Please see an example call :point_up:
We have the same consistent defaults in `setup_databases()` and `teardown_databases()`. It's just unrelated and backward incompatible. We can discuss this separately, but personally I think it's not worth changing due to concerns about backward incompatibility.
I think it's enough to check `stderr`, e.g. ```python with self.assertRaises(SystemExit), captured_stderr() as stderr: self.get_parser().parse_args(['--parallel', 'unaccepted']) msg = "argument --parallel: 'unaccepted' is not an integer or the string 'auto" self.assertIn(msg, stderr.getvalue()) ```
We should update `help` (here and in `runtests.py`).
```suggestion help=( 'Nominates a database to show migrations for. Defaults to the ' '"default" database.' ), ```
Seems wrong to hard code this list when Django fully supports user-written commands.
```suggestion return f'{self.__class__.__qualname__}.{self._name_}' ```
```suggestion # A similar format was proposed for Python 3.10. ```
```suggestion return f'{self.__class__.__qualname__}.{self._name_}' ```
```suggestion # A similar format was proposed for Python 3.10. ```
This message shouldn't be used when constraint is defined with `expressions`.
> It just happens to pretty straightforward here as you can directly call `Constraint.validate` without the `exclude` on the constraint you are interested in validating. That's a suitable workaround, but I feel like it should not be necessary. FWIW before Django 4.1 where this feature was added I added manual validation already, since there constraints with conditions where just skipped.
We should pass `using` to `check()`.
We're looking for the same constraint, not a constraint with the same type :thinking: ```suggestion if constraint is self: ```
This looks incorrect to me, we should check that object exists only when a condition is fulfilled ```suggestion if (self.condition & Exists(queryset.filter(self.condition))).check(against, using=using): ```
The point is that I am not using `exclude` myself, and it is good that `status` is excluded from checks itself. But the constraint is for `name`, and `status` is only used in the condition there: ``` class Meta(…): constraints = [ UniqueConstraint(fields=("name",), condition=Q(status="draft"), name="uniq_name_draft"), ] ```
`FieldError` is untested. Do we need it? It looks unnecessary.
Wrap at 79 chars.
```suggestion with self.assertRaisesMessage(ValidationError, msg): ```
I would add quotes: ```suggestion violation_error_message = _("Constraint '{name}' is violated.") ```
Improved typography and changed to [%-formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting) to be consistent with other error messages.
It was definitely relevant, let's continue the discussion over there.
I think this model is causing the MySQL failures. Since `Product` cannot be created on MySQL due to not having the `supports_table_check_constraints` feature then `ChildProduct` cannot be created either since MTI requires a foreign key (hence the `Cannot add foreign key constraint` error). ```suggestion class ChildProduct(Product): class Meta: required_db_features = { 'supports_table_check_constraints', } ```
We should make use of `self.message`.
As far as I'm aware, for backward compatibility we should assigned errors from `UniqueConstraint`s with a single field to this field :thinking:
I wonder if `Model.validate_constraints` should handle and silence this at first as to not force all `BaseContraint` subclasses to implement this method.
```suggestion # A composite constraint containing NULL value cannot cause ```
Thanks for these tests, they look great!
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
```suggestion Call clean_fields(), clean(), validate_unique(), and validate_constraints() on the model. ```
It's still time to change them :smile:
We update `var` in the https://github.com/django/django/blob/f03ba0ad52e6f1deb42f022090f226573b22f630/django/template/base.py#L800 so I'd revert to the `var[0]`.
```suggestion if VARIABLE_ATTRIBUTE_SEPARATOR + '_' in var or first_char == '_': ```
Can we change this to `_has_changed()`? I think it might link up better with `Field.has_changed()` and `Form.has_changed()`.
I think that `ValidationError` is only raised out of `Field.to_python()`, not `Widget.value_from_datadict()`, so this can be simplified: ```suggestion widget = field.hidden_widget() value = self.form._widget_data_value(widget, self.html_initial_name) try: initial_value = field.to_python(value) ```
This doesn't take into account the weighting that can be present, and assumes that the first item is the preferred one, which is AFAIK only true if _none_ of the options have a q weight (in which case they all have a `q=1`)
I wonder if it makes sense to add a hook (with better name) that could be called here and in `DeletionMixin`: ```python class DeletionMixin: ... def _delete(self): if not getattr(self, 'object', None): self.object = self.get_object() success_url = self.get_success_url() self.object.delete() return HttpResponseRedirect(success_url) def delete(self, request, *args, **kwargs): return self._delete() class BaseDeleteView(DeletionMixin, FormMixin, BaseDetailView): ... def form_valid(self, form): return self._delete() ```
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
```suggestion self.assertSequenceEqual(Author.objects.all(), []) ```
```suggestion self.assertEqual( res.context_data['form'].errors['__all__'], ['You must confirm the delete.'], ) self.assertEqual( res.context_data['form'].errors['confirm'], ['This field is required.'], ) ```
Good, thanks. Maybe `Note setting ` -> `Set `
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
You can use `self.assertContains()`: ```suggestion self.assertContains(response, 'This is a test. val is the value.') ```
Personally if it were happening to me, I'd be **thrilled** if it could tell me what needs applying, and if it couldn't and instead directed me to another command to run I'd _assume_ (and be disappointed) that the information wasn't available at the time the exception occurred. If it is there, I think it's prudent to respect the user's needs and attempt to surface the information. That said, my gut feeling is that the exception output format maybe isn't "right" (for a given value thereof). I can't recall many (any?) places where Django raises with an arg which is multiple lines. Those cases where there's multiple _things_ to enumerate tend to just get comma separated. That does leave the door open to super long lists though, if for whatever reason the partially applied list was big... Maybe because it's related to running migrations, which _are_ line oriented, it's OK? [Edit to add: big thumbs up from me to the information, FWIW. Next step seems much clearer as a result]
I'd move it to the `setUp()`: ```python def setUp(self): self.runner = NoOpTestRunner(verbosity=0, interactive=False) ```
Since this is only being used in one test case class, I would put it right before that test case class. If it turns out to be useful for other tests, it could always be moved to a more central location and modified as needed, etc.
I would make the test of `build_suite()` and `run_tests()` separate test methods.
Maybe just do this in the `__init__()` method of your subclass, after calling `super()`? That will keep all your modifications together in one place. This will also let you remove the `hasattr` check in `get_test_runner_kwargs()`.
```suggestion 'The extra_tests argument is deprecated.', ```
```suggestion 'The extra_tests argument is deprecated.', ```
I would move the check to the first line of the function since it's right after receiving the argument.
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
You can use `with captured_stderr()` instead.
```suggestion # RemovedInDjango50Warning class NoOpTestRunner(DiscoverRunner): def setup_test_environment(self, **kwargs): return def setup_databases(self, **kwargs): return def run_checks(self, databases): return def teardown_databases(self, old_config, **kwargs): return def teardown_test_environment(self, **kwargs): return class DiscoverRunnerExtraTestsDeprecationTests(SimpleTestCase): msg = 'The extra_tests argument is deprecated.' def setUp(self): self.runner = NoOpTestRunner(verbosity=0, interactive=False) def test_extra_tests_build_suite(self): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.build_suite(extra_tests=[]) def test_extra_tests_run_tests(self): with captured_stderr(): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.run_tests( test_labels=['test_runner_apps.sample.tests_sample.EmptyTestCase'], extra_tests=[], ) ```
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
@kezabelle You could still make this change and it would be functionally identical to the current state of this PR. The only question is whether we need to restore the following before the `elif` in the code above: ```python elif data in self.children: return data ``` Note that we don't need to worry about the `self.connector == conn_type` bit that was fixed in b81c7562fc33f50166d5120138d6398dc42b13c3 because, by reordering the code like this, the inverse of that condition can only fall in the first block. As such, it is clear that this proposed simplification makes the code easier to understand and less prone to the regressions that have gone before.
If we invert this condition we can remove a level of indentation: ```python def add(self, data, conn_type): """ Combine this tree and the data represented by data using the connector conn_type. The combine is done by squashing the node other away if possible. This tree (self) will never be pushed to a child node of the combined tree, nor will the connector or negated properties change. Return a node which can be used in place of data regardless if the node other got squashed or not. """ if self.connector != conn_type: obj = self._new_instance(self.children, self.connector, self.negated) self.connector = conn_type self.children = [obj, data] return data elif ( isinstance(data, Node) and not data.negated and (data.connector == conn_type or len(data) == 1) ): # We can squash the other node's children directly into this node. # We are just doing (AB)(CD) == (ABCD) here, with the addition that # if the length of the other node is 1 the connector doesn't # matter. However, for the len(self) == 1 case we don't want to do # the squashing, as it would alter self.connector. self.children.extend(data.children) return self else: # We could use perhaps additional logic here to see if some # children could be used for pushdown here. self.children.append(data) return data ```
We might as well lose the unnecessary string formatting while we're at it: ```suggestion old = repr(list(reversed(get_format_modules()))) new = repr(list(reversed(get_format_modules()))) # second try ```
You can remove the unnecessary assignment here: ```python return _format_modules_cache[lang] ```
Yes, we can remove this test.
Can you group both of these under `if self.include`? Or return early after checking `not self.include`.
Functions calls are not allowed in f-strings as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ```suggestion raise PicklingError(f'Cannot pickle {self.__class__.__qualname__}.') ```
URL patterns may change over time, so we can restore the different match :thinking:
`tried` can be also an issue for function-based views because `URLResolver` is not pickleable, everything depends on the order in `urlpatterns`, see e.g. ```diff diff --git a/tests/urlpatterns/path_urls.py b/tests/urlpatterns/path_urls.py index 29b6185292..0efb713959 100644 --- a/tests/urlpatterns/path_urls.py +++ b/tests/urlpatterns/path_urls.py @@ -3,13 +3,13 @@ from django.urls import include, path, re_path from . import views urlpatterns = [ + path('included_urls/', include('urlpatterns.included_urls')), path('articles/2003/', views.empty_view, name='articles-2003'), path('articles/<int:year>/', views.empty_view, name='articles-year'), path('articles/<int:year>/<int:month>/', views.empty_view, name='articles-year-month'), path('articles/<int:year>/<int:month>/<int:day>/', views.empty_view, name='articles-year-month-day'), path('users/', views.empty_view, name='users'), path('users/<id>/', views.empty_view, name='user-with-id'), - path('included_urls/', include('urlpatterns.included_urls')), re_path(r'^regex/(?P<pk>[0-9]+)/$', views.empty_view, name='regex'), re_path(r'^regex_optional/(?P<arg1>\d+)/(?:(?P<arg2>\d+)/)?', views.empty_view, name='regex_optional'), re_path( ```
We can do the same for `reffed_expression`: ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index b3d92d786c..21bc0aea7a 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1286,11 +1286,9 @@ class Query(BaseExpression): if check_filterable: self.check_filterable(value) - clause = self.where_class() if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) - clause.add(condition, AND) - return clause, [] + return self.where_class([condition], connector=AND), [] opts = self.get_meta() alias = self.get_initial_alias() @@ -1333,7 +1331,7 @@ class Query(BaseExpression): condition = self.build_lookup(lookups, col, value) lookup_type = condition.lookup_name - clause.add(condition, AND) + clause = self.where_class([condition], connector=AND) require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None: ```
> I'll do this and another quick sweep/scan for any similarly distanced/return early ones. I think that's the last one.
This works without the patch and should be moved to a separate commit.
This works without the patch and should be moved to a separate commit. I'd also move it to a separate test method: ```python def test_defer_only_clear(self): self.assert_delayed(qs.only('name').defer('name')[0], 0) self.assert_delayed(qs.defer('name').only('name')[0], 0) ```
If you handle the positive case first, this can be the simpler `if new_existing:`. You could also use an assignment expression to simplify further (`if new_existing := existing.difference(field_names):`).
`proxy` is not important for this regression: ```suggestion class PersonChild(Person): pass ```
I'd simplified this test: ```suggestion def test_reverse_inherited_m2m_with_through_fields_list_hashable(self): reverse_m2m = Person._meta.get_field('events_invited') self.assertEqual(reverse_m2m.through_fields, ['event', 'invitee']) inherited_reverse_m2m = PersonChild._meta.get_field('events_invited') self.assertEqual(inherited_reverse_m2m.through_fields, ['event', 'invitee']) self.assertEqual(hash(reverse_m2m), hash(inherited_reverse_m2m)) ```
The ticket number is not necessary. ```suggestion ```
It's not strictly a regression test, but it will crash without this patch.
If we implement this on `Node`, we can simplify the following to assume that we always have `.copy()`: https://github.com/django/django/blob/fd999318ad78613227cdb7c5656345d9e216802b/django/db/models/query_utils.py#L48
In this case you may as well do `obj = self.__class__()` as you're not passing anything in. `Node._new_instance()` only exists to help smooth out the incompatibilities between `Q.__init__()` and `Node.__init__()` when needing to reconstruct objects internally. In fact, it would be nice to eliminate it if possible.
Again, this might as well be `obj = self.__class__(_connector=conn)`.
I'm leaning toward reintroducing `Node._new_instance()`, although probably call it `.create()` and make sure it is used everywhere which it hasn't been up to new. The reason for this is that sometimes using `.copy()` has unnecessary overhead of copying `__dict__` when we don't need to.
I guess this point became moot when I moved to `Node.copy()` and merged `Node._new_instance()` into it.
Perhaps this could be encapsulated with a `Query.clear_where()` method (could be called in `subqueries.py` too).
Will do, marking it as unread to remind me.
You can remove both ticket numbers.
Also, maybe just call this `post_error` as "to raise" is redundant.
I think you can remove this one-line method and inline the code instead.
The code will be cleaner if you make the default `None` here and elsewhere, and then check for `None` below, similar to how `method` is done. In particular, you won't need to hard-code the default in more than one spot.
Maybe: > An OSError raised while reading the POST data should not be handled by the middleware.
If you add `error_to_raise = None` as a class attribute, you can do `if self.error_to_raise is not None`, which is a little nicer.
> An UnreadablePostError raised while reading the POST data should be handled by the middleware.
Yes, `_is_relevant_relation` should return the same result :thinking:
It appears to me that, since this previously returned an iterator (`zip()`'s return value), you don't need to construct an intermediate list here and can simply `yield` the tuples directly.
I was curious about something when seeing this. Must `_is_relevant_relation()` always give the same result for `new_field` as for `old_field`, in order for the `zip()` to line up? If so, it seems like a simplification could be done in a subsequent PR.
Please use the same order as in `--help` output, i.e. `--version`, `--verbosity`, `--settings`, `--pythonpath`, `--traceback`, `--no-color`, and `--force-color`.
Chop blank line.
Wrap at 79 chars.
There is no need to check the entire output, we can check the list of expected options, e.g. ```suggestion expected_options = [ '-h', '--option_a OPTION_A', '--option_b OPTION_B', '--option_c OPTION_C', '--version', '--verbosity {0,1,2,3}', '--settings SETTINGS', '--pythonpath PYTHONPATH', '--traceback', '--no-color', '--force-color', ] for option in expected_options: self.assertOutput(out, f'[{option}]') ```
Chop blank line.
Please remove type annotations. We don't currently use them in Django.
Move this class below `ManageRunserverEmptyAllowedHosts`.
Chop unnecessary blank line.
```suggestion """runserver doesn't support --verbosity and --trackback options.""" ```
I would change this so each of the positional arguments is checked against `self.suppressed_base_arguments`. Then e.g. `--verbosity` doesn't have to be listed first when both `-v` and `--verbosity` are provided. Also, if this is done, then `name` doesn't need to be distinguished / given a name in the argument list.
I would move it to the `ManageRunserver` class.
```suggestion suppressed_arguments = set() ``` or `suppressed_base_arguments`.
What do you think about using `argparse.SUPPRESS` instead (as suggested in the previous patch)? e.g. ```suggestion parser.add_argument( '-v', '--verbosity', default=1, type=int, choices=[0, 1, 2, 3], help=argparse.SUPPRESS if 'verbosity' in self.suppressed_arguments else ( 'Verbosity level; 0=minimal output, 1=normal output, ' '2=verbose output, 3=very verbose output' ), ) ``` This way the list of options will not be misleading anymore and at the same time default values will be available for subcommands :thinking: This should increase backward compatibility.
I feel like this boiler-plate could be handled more nicely. For example, what about defining a function above that looks something like-- ```python def add_argument(parser, name, *args, help=None, **kwargs): if name in self.suppressed_base_arguments: help = argparse.SUPPRESS parser.add_argument(*args, help=help, **kwargs) ``` Then each `parser.add_argument(...)` would become `add_argument(parser, name, ...)`. I also think it would be better if the convention were for the string in `suppressed_base_arguments` to match the first option string passed to `parser.add_argument()` (e.g. `--force-color` instead of `force-color`). I think it would be easier to remember. Also, if that were done, the name wouldn't have to be passed a second time, or manipulated in any way inside the helper function above before checking for membership in `self.suppressed_base_arguments`.
How about: > Call the parser's add_argument() method, suppressing the help text according to BaseCommand.suppressed_base_arguments.
I think you still want the `-` logic I suggested in the optional argument case (when the first argument starts with `-`). If the first argument doesn't start with `-`, I believe you can restrict to looking at just the argument providing the single name.
I would preserve the original ordering (`-v` then `--verbosity`).
I'd use f-strings for lookups (in all cases): ```suggestion lookup_conditions.append((f'{self.field_path}__isnull', True)) ```
I think we can reuse `rels_to_update`.
`str()` call is unnecessary: ```suggestion yield self.connection.ops.tablespace_sql(tablespace, inline=True) ```
Maybe: ```suggestion column_db_type = db_params['type'] ```
I would put both of these before `TEST_DATA` because they are simpler.
Also, you can use `extend()` with a generator expression to eliminate the need for a `for` loop with indentation.
You shouldn't need the extra parentheses inside `extend()`, FYI.
The test data should be defined so it isn't necessary to call `strip()`.
You can use the single line style if it fits: `"""Extra translations are ignored."""`
What do you think about changing `_generate_altered_foo_together()` to a generator `_get_altered_foo_together_operations()`, e.g.: ```python def _get_altered_foo_together_operations(self, option_name): for app_label, model_name in sorted(self.kept_model_keys): ... if old_value != new_value: dependencies = [] for foo_togethers in new_value: for field_name in foo_togethers: field = new_model_state.get_field(field_name) if field.remote_field and field.remote_field.model: dependencies.extend(self._get_dependencies_for_foreign_key( app_label, model_name, field, self.to_state, )) yield ( old_value, new_value, app_label, model_name, dependencies, ) def _generate_removed_altered_foo_together(self, operation): for old_value, new_value, app_label, model_name, dependencies in _get_altered_foo_together_operations(operation.option_name): removal_value = new_value.intersection(old_value) if removal_value or old_value: self.add_operation( app_label, operation(name=model_name, **{option_name: removal_value}), dependencies=dependencies, ) def generate_removed_altered_unique_together(self): self._generate_removed_altered_foo_together(operations.AlterUniqueTogether) ... ``` Maybe it's too complicated :thinking:
Do we need to check `removal_value`? It should be enough to check that `new_value` is not en empty set, I cannot imagine a different scenario :thinking: ```suggestion if new_value: ```
I'd remove this docstring.
```suggestion self.assertNotIn('CSRF_COOKIE', request.META) self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
Maybe: ```suggestion # Tokens of length CSRF_TOKEN_LENGTH. ```
`Test passing` is unnecessary, IMO, maybe: ```suggestion # A token of length CSRF_SECRET_LENGTH. ```
`self.assertNotIn()` is preferred: ```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
I'd remove this docstring, the test method name is self-explanatory.
I'd remove this docstring.
```suggestion # See e.g. create_forward_many_to_many_manager(). ```
I wouldn't use ternary.
`GenericForeignKey` or `GenericRelation`? Shouldn't we move this logic to the `ReverseGenericManyToOneDescriptor`? :thinking:
```suggestion """ Upon first access, replace itself with an empty dictionary on the instance. """ ```
Maybe `related_managers_cache` for consistency with `fields_cache` :thinking:
It was really hard for me to see how `favorite_things` and `favourite_things` collide, so I renamed them.
You don't use `edit_only` here :thinking:
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Tests for `formset_factory()` and `formset_factory()` are missing.
This should be an issue only when `migration_name` is passed, so I would move it to the `if options['app_label'] and options['migration_name']` branch, e.g. ```diff diff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py index 9ad1854a2d..aa1a41e78c 100644 --- a/django/core/management/commands/migrate.py +++ b/django/core/management/commands/migrate.py @@ -140,18 +140,20 @@ class Command(BaseCommand): except KeyError: raise CommandError("Cannot find a migration matching '%s' from app '%s'." % ( migration_name, app_label)) - targets = [(app_label, migration.name)] + target = (app_label, migration.name) + if ( + target not in executor.loader.graph.nodes and + target in executor.loader.replacements + ): + incomplete_migration = executor.loader.replacements[target] + target = incomplete_migration.replaces[-1] + targets = [target] ```
This should be in the `finally`: ```python with self.temporary_migration_module(module='migrations.test_migrations'): try: ... finally: # Unmigrate everything. call_command('migrate', 'migrations', 'zero', verbosity=0) ```
this attribute should be `non_picklable_attrs` I think.
`frozenset` makes a lot of sense and doesn't get enough use IMHO, as long as we're careful to remember we need to use `|` rather than `+` on any subclasses that want to extend the data.
We're more consistent then Python when it comes to "pickl(e)able": - Python: `picklable` - 92, `pickleable` - 39 - Django: `picklable` - 45, `pickleable` - 1
> > this attribute should be `non_picklable_attrs` I think. > > ... or `pickleable` 😄 I need to confirm with Carlton. Yeah that's how I was going to recommend spelling it, because it _felt/looked_ right, but then I looked at the python pickle docs and they use `picklable` everywhere. TIL.
```suggestion 'related_name has no effect on ManyToManyField with ' 'a symmetrical relationship to "self".', ```
Also, this can be single-lined.
Please use single quotes here. ```suggestion m2m = models.ManyToManyField( 'self', related_name='children' ) ```
Remove blank line.
This doesn't need to be an f-string. I think I'd adjust the wording slightly, to avoid any _What's a symmetrical relationship?_ moments: ```suggestion 'related_name has no effect on ManyToManyField ' 'with a symmetrical relationship to "self".', ``` Other cases will need adjusting too.
Is there a reason (there might well be!) why end can be either an empty string (`''`) _or_ a number (I'm assuming)? I assume the empty string is a falsy sentinel at first glance, but I may be mis-reading. It _seems_ like an awkward condition to potentially require user-subclasses to support, but if it's a technical necessity, so be it.
Mistake? Looks like test coverage is missing… ```suggestion return '%s[:%%s]' % lhs, params + [self.end] ```
Could probably use an f-string here and in the following branches. ```suggestion return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
Perhaps it's an additional burden that can be deferred for another time, but IMHO it'd be _cool_ if the `__repr__` included either the subscript object or the final attributes it leads to (the latter would require it be `<SliceableF ...>` though, I guess). I only bring it up because you specifically asserted it though; it's by no means a requirement given there's already an _acceptable_ repr for it.
I think something like the following (untested) code would do? ```python def __repr__(self): start = self.start - 1 stop = None if self.length is None else start + self.length subscript = slice(start, stop) return f'{self.__class__.__qualname__}({self.name!r}, {subscript!r})' ```
If changing to `None` from `''` in `.slice_expression()` above, then: ```suggestion if self.end is None: return f'{lhs}[%s:]', params + [self.start] else: return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
Ah I thought everywhere `self.end` was used was already guarded by a falsy check, which `0` or `None` would also satisfy, my bad.
Yes, because we can then get slicing in PostgreSQL such as `[5:]` because the `end` value being `''` allows nothing to be substituted. Arguably it isn't nice to mix strings and integers. We could use `None` instead, but then we'd need to explicitly handle that case later.
We allow up to 119 characters, so this doesn't need to be wrapped. ```suggestion def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): ```
```suggestion msg = 'Slice stop must be greater than slice start.' ```
I don't think it's necessary. In all cases we test the same (default) implementation. A single assertion should be enough, e.g. ```python def test_invalid_fields_in_slicing_f_expressions(self): msg = 'This field does not support slicing.' with self.assertRaisesMessage(NotSupportedError, msg): Company.objects.update(num_chairs=F('num_chairs')[:4]) ```
```suggestion raise ValueError('Slice stop must be greater than slice start.') ```
Wrap at 79 chars.
:thinking: ```suggestion An object that contains a slice of the F expression. ```
`Company` doesn't have a default ordering so we need to use `assertCountEqual()` or add `.order_by(...)`.
This will not work for `OuterRef()` :disappointed: because we don't resolve it properly, so it generates: ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING(U0."name", 3, 1)) LIMIT 1 ) ``` instead of ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING("expressions_company"."name", 3, 1)) LIMIT 1 ) ``` see `test_slicing_of_outerref`.
`target` is only available for `Col`, so it crashes for expressions, see `test_slicing_of_f_expression_with_annotated_expression`.
IMO it's valuable, because it explains why we can always use `self.start` without an extra check.
Please add a trailing comma in all cases: ```suggestion ['Exa', 'Foo', 'Tes'], ```
This line can be pushed up a level and re-used.
I'd move this line to the top of `__init__()` so it isn't lost below all the conditional logic.
Perhaps extend this for a wider range of field types, e.g. `BooleanField`, `IntegerField`, `FloatField`, etc.
```suggestion with self.subTest(s=s), with self.assertRaisesMessage(ValueError, msg): F('name')[s] ```
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
```suggestion widget=self.get_deletion_widget(), ```
Please move fixing typo to a separate commit.
```suggestion '\n'.join([form.as_ul() for form in formset.forms]), ```
I'd chop this docstring.
Rather than `get_num_test_processes()`, I wonder if something like `get_max_test_processes()` might be a better name. This is because the number of test processes can wind up being smaller, e.g. if there are fewer `TestCase` classes. (You also assign to `max_parallel` elsewhere, so there is an awareness of this meaning / caveat.)
Is it too late to move the conversion of `auto` to an integer to a post-processing step (e.g. your `get_num_test_processes()` function)? I feel like the `parallel_type` function's job here should only be to check that the value equals `auto` if the value is a string, but not to apply the environment-dependent business logic to convert `auto` to a number. (I also see that `get_num_test_processes()` is already calling `multiprocessing.cpu_count()`, so there may be some duplication of logic with the way things are currently structured.)
Would it be better to move this log message to after where `parallel` is done being computed below? Otherwise, if `parallel` needs to be reset to `1` below, maybe that can be logged below so people know it was changed.
Okay, I could take a crack at some of that follow-up clean-up afterwards, if you want.
I just noticed that you don't ever seem to need `get_max_test_processes()`'s argument. Here you do pass `parallel`, but you're only ever passing the default argument value. So it looks like you don't actually need to accept a value.
You can add `auto_id=False` to reduce the output.
```suggestion widgets = [TextInput(), TextInput(), TextInput(), TextInput()] ```
Yeah, I think it's worth keeping in the same place.
Yup. It's completely irrelevant to the module it's in with this change.
> Is there any backwards compatibility issue with doing this? I.e. is the availability of this import part of Django's public API? Theoretically yes, we should add a reverse import for backward compatibility, or at least a small release notes.
Thank you. Needless to say, I would say I find your English actually to be quite excellent.🥇
I think it's okay to use the variable, IMO, especially since it's used twice further down.
Just to be clear, I meant `processes` variable. But if you want to go with the other suggestion, I won't object.
Django's code style says to use complete sentences, so capitalize and end with a period.
The variable name doesn't need to be / shouldn't be changed, IMO. (My suggestion in the ticket for a variable name was for the string argument, if that was going to be tested separately.)
```suggestion # We need to remove it for subclasses like ManyToOneRel where the ```
You're right, sorry.
I'd not use the ternary: ```suggestion if filtered_relation: pathinfos = field.get_path_info(filtered_relation) else: pathinfos = field.path_infos ```
Can we move this logic to the `get_path_info()`? :thinking: ```python def get_path_info(self, filtered_relation=None): if not filtered_relation: return self.path_infos return self._get_path_info(direct=True, filtered_relation=filtered_relation) ```
Since `separate_logs` seems like a higher-level mode that does multiple things, maybe you can make it so the mode doesn't need to be stored as an attribute. For example, the following line could write to a `self.output_stream` that defaults to `os.devnull`. When running in script mode, it could be set to `self.stdout`. It would also eliminate the need for an `if` statement.
Can we move it to a property and use it here and in `log()`? For example: ```python @property def log_output(self): return self.stderr if self.scriptable else self.stdout ```
Good idea :+1:
`\n` is redundant because `self.stdout` is an instance of `OutputWrapper`.
I noticed that all logs and prompts have `ERROR` style when using `--scriptable`, e.g.: ![image](https://user-images.githubusercontent.com/2865885/148344507-ada0d115-4a48-4001-81a2-b62c919c5e45.png) ![image](https://user-images.githubusercontent.com/2865885/148344684-e00db0d8-c25f-45fc-ba54-9dfef13eac7c.png) We could create a copy of `stderr` without the `ERROR` style and use it where appropriate :thinking: ```diff diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py index cdb200f22e..096702814c 100644 --- a/django/core/management/commands/makemigrations.py +++ b/django/core/management/commands/makemigrations.py @@ -6,7 +6,7 @@ from itertools import takewhile from django.apps import apps from django.conf import settings from django.core.management.base import ( - BaseCommand, CommandError, no_translations, + BaseCommand, CommandError, no_translations, OutputWrapper ) from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router from django.db.migrations import Migration @@ -62,9 +62,17 @@ class Command(BaseCommand): help='Output only created migration filepaths to stdout; divert logging and prompts to stderr.', ) + def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False): + super().__init__(stdout, stderr, no_color, force_color) + if no_color: + self.stderr_log = self.stderr + else: + # stderr without the ERROR style. + self.stderr_log = OutputWrapper(stderr or sys.stderr) + ```
I wonder if something like `serialize_result` might be a more descriptive name for this function.
```suggestion Convert the provided model object to a dictionary that is added to the results list. ```
The docstring on lines 14-18 is no longer, strictly speaking, always true. Maybe it could be updated to say something like: "Return (by default) a JsonResponse with search results of the form:". I feel like my suggestion here could be better phrased, but I'm not sure how at this moment.
Maybe: ```suggestion Return a JsonResponse with search results as defined in serialize_result(), by default: ```
I think that you could move the slicing inside `DebugLexer._tag_re_split()` and then `DebugLexer.tokenize()` will be even closer to `Lexer.tokenize()`: ```suggestion for bit, position in self._tag_re_split(): ``` Maybe with these changes it makes sense to rename `DebugLexer._tag_re_split()` to something like `.split()` and add the same method to `Lexer` with something like: ```python def split(): yield from ((bit, None) for bit in tag_re.split(self.template_string)) ``` Then you should be able to ditch `DebugLexer.tokenize()` entirely and inherit it.
> But I think it would be better if we didn't let the debug implementation slow the non-debug implementation more. Yeah. That did occur to me, but haven't had time to check the performance. It might still work out in concert with other ideas I've had… But those don't need to hold this up.
We don't need to call `len()`, `slice()` will work the same with `None`.
IMO, we can use `self.template_string` without an extra variable.
As you say, this exists to support the following: https://github.com/django/django/blob/8208381ba6a3d1613bb746617062ccf1a6a28591/django/db/models/query.py#L1626-L1629 But, as that is the only call that passes arguments, if we change that to: ```python queryset = self.queryset._chain() queryset._result_cache = [] queryset._prefetch_done = True obj_dict['queryset'] = queryset ``` Then we can ditch this entirely: ```suggestion ``` ...and drop the `**kwargs` argument from `QuerySet._chain()`.
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
Yeah I'd absolutely leave it as `isinstance` too if performance is the reason. It's a constant time cost, and as you say, is faster (pretty sure it's _more_ than 10% faster if the incoming `set` is large enough, YMMV) 👍
Is this the right name? If I'm using `settings.CSRF_USE_SESSIONS` then no cookie gets set.
I'm in two minds on this. On one hand, yes, @carltongibson is right. On the other hand, a lot of this code treats `CSRF_USE_SESSIONS` as an afterthought (which, historically, it is, but...). Maybe this way is more consistent with the rest, and changing the not-necessarily-correct references to cookies (e.g. `request.META['CSRF_COOKIE']`) into something more befitting the dual use should be the subject of a separate refactoring, if we want it. Perhaps when we remove the distinction between the cookie/token and the secret, we should rename this to `_set_secret()`. Perhaps a good name now is `_set_masked_secret()`. Not sure. Whatever choice is picked here, should also apply to `_add_new_csrf_cookie()` above.
```suggestion return md5(password.encode()).hexdigest() ```
Is there any reason you can't do the following? ```python md5 = hashlib.md5 ``` Also, it may be cleaner to do this in an `else` of the `try`.
[`hashlib.new()`](https://docs.python.org/3/library/hashlib.html#hashlib.new) also accepts `usedforsecurity` as of Python 3.9. So I think it would be cleaner to eliminate the `md5`-specific `if` statement, and use a `hashlib.new()` wrapper that passes `usedforsecurity` if available.
As you're reordering here anyway, I'd reformat this to: ```suggestion if ( lookup_name == 'exact' and lookup.rhs == '' and connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls ): ```
Also, we should re-raise an exception to the compiler when `empty_aggregate_value` is not implemented, e.g. ```python except EmptyResultSet: arg_sql, arg_params = getattr(arg, 'empty_aggregate_value', NotImplemented), () if arg_sql is NotImplemented: raise ```
This won't work when `empty_aggregate_value` is `NotImplemented`.
This is not a proper regression test because we don't have any `author` here.
```suggestion [sys.executable, __file__, 'runserver'], ```
```suggestion @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
```suggestion f'-X{key}' if value is True else f'-X{key}={value}' ```
```suggestion @mock.patch.dict('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
```suggestion @mock.patch.dict('sys._xoptions', {}) ```
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
We currently use single quotes and this can be condensed a little and use f-strings. We can also drop the `hasattr()` check as the [`sys.implementation` docs](https://docs.python.org/3/library/sys.html#sys.implementation) state that it _must_ exist. ```suggestion if sys.implementation.name == 'cpython': args.extend( f'-X{key}' if isinstance(value, bool) else f'-X{key}={value}' for key, value in sys._xoptions.items() ) ```
Why is this way preferable to ```suggestion def _check_token_present(self, response, csrf_secret=TEST_SECRET): ```
This variable too appears incorrectly named. If I'm not mistaken, we can get to a state where the unmasked version is always called "secret" and the masked one always "token". I think we had that property before, it's just that in some places where we were using a token, we are now changing to use a secret; function and variable names should be changed to match this.
This is now misnamed, IMO. `_get_secret()`, maybe.
Fine with me either way, just wanted to point it out so it is not lost. Maybe we can rename it shortly before merging? (IE when all other reviews are done -- but in the end a second PR is fine as well)
This looks odd to me. In my view, assertions should never be considered part of (even internal) API. To strengthen this point -- this test should fail if the test suite is run with `python -o2` (assuming `assertRaises` actually raises an AssertionError, rather than `assert`ing something, of course...).
Personally, I like this because you can pass `None` to get the default value. We can decide to change, but it should be a part of a separate PR.
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
outer parentheses can be removed
I think names like `float_nan` would be more consistent with our coding style.
This string should be in `default_error_messages` and be marked as translatable with the underscore: `_('...')`, although I think it's probably okay to reuse the `'invalid'` message... the message "nan value must be a decimal number." seems to read okay.
This should work: ```suggestion transaction.on_commit(self.enqueue_callback) ```
Can you `assert` before this line that `field_name` isn't in `relations_to_remote_model[model_key]`? Before the change, it looks like that would have always been true (though I'm not sure why). After the change, it looks like you might also be replacing a field.
```suggestion """PO files are unchanged unless there are new changes.""" ```
I think we can use pathlib for new code. ```suggestion msgs = Path(pofile).read_text(encoding='utf-8') ```
```suggestion """PO file is properly updated when new changes are detected.""" ```
```suggestion self.original_po_contents = Path(self.PO_FILE).read_text() ```
In the places where `validate_key()` was being called before `make_key()`, it seems like this is a behavior change (bug fix?) that should put into a separate commit, maybe even with a regression test. That way introducing the new method will be a pure refactor. An example would be a case where the `version` argument causes the allowed length to be exceeded.
Okay, then I think there should be a regression test for sure, to make sure code using the helper method is behaving the right way with regard to the order.
OPTIONAL I would be inclined to put this directly below `validate_key()` (above) so that when you have the file open the two related methods are next to each other. (TBH, I'd put both of them directly below `make_key()` for the same reason but, if we don't want to move `validate_key()`, I'd at least put the new method in that place.)
Oh, sorry about that. I didn't notice there was more one commit. If a bug is being fixed even by a refactor, I think a regression test is still useful, but I'll defer to others.
In cases like this where the return value isn't being used, I wouldn't include the return value.
Remove print statement: ```suggestion ```
```suggestion call_command('makemigrations', 'migrations', interactive=False) ```
The default value it not necessary, IMO: ```suggestion def __init__(self, defaults=None, specified_apps=None, dry_run=None, verbosity=1, log=None): self.verbosity = verbosity self.log = log ```
Passing `stdout` and `stderr` is not necessary. ```suggestion call_command('makemigrations', 'migrations', interactive=False) ```
I would use `log`: ```suggestion def log_lack_of_migration(self, field_name, model_name, reason): if self.log is not None and self.verbosity > 0: self.log(f"Field '{field_name}' on model '{model_name}' not migrated: {reason}") ```
Can we check `fk_field` instead to avoid unnecessary queries? e.g. ```python for field in self._meta.private_fields:) if field.is_relation and hasattr(field, 'fk_field') and field.is_cached(self): if getattr(self, field.fk_field, None) is None: raise ValueError( "%s() prohibited to prevent data loss due to unsaved " "related object '%s'." % (operation_name, field.name) ) ```
Personally, I think `new_key` would be a more commonly used choice.
Remove blank line (and below).
Undo unrelated change (and below).
Remove blank line (and below).
In both cases we're checking `fk.remote_field.model._meta.proxy` when `fk` is a `ForeignKey` so there is no need to check `fk.remote_field`.
We're checking `get_parent_list()` in a loop so I would cache it in the variable: ```python parent_list = parent_model._meta.get_parent_list() fks_to_parent = [ f for f in opts.fields if isinstance(f, ForeignKey) and ( f.remote_field.model == parent_model or f.remote_field.model in parent_list or ( f.remote_field.model._meta.proxy and f.remote_field.model._meta.proxy_for_model in parent_list ) ) ] ```
There is a minor behaviour change here. Previously calling `decr()` with `delta=0` would call `self._cache.decr()`, but now it'll call `self._cache.incr()` instead. In theory this shouldn't be a problem, but am highlighting it.
It should be enough to use `lru_cache` instead, e.g.: ```python @functools.lru_cache(maxsize=128) def import_string(dotted_path): ... ```
Another option is one Andrew suggested to me in django/asgiref#288 (which I need to get back to) which is small and elegant enough that it might be useful to Django-proper, possibly here in `import_string` and more generally where imports happen inside functions/methods (to avoid circular refs) in hot loops, and it looks like: ``` def cached_import(module_name, item_name): modules = sys.modules if module_name not in modules: importlib.import_module(module_name) return getattr(sys.modules[module_name], item_name) ``` A benefit of it would be not having another _separate_ cache (LRU) with a finite hit-rate, and it still avoids going through the import machinery for hits.
> @kezabelle Is there a reason to have a local `modules` variable and use it only in `not in` check? Err, only because I suck :) Notionally it was to avoid `LOAD_GLOBAL` followed by `LOAD_ATTR` twice (once for the key check, once for the getattr) to try and make it As Fast As Possible (in the context of the aforementioned PR) ... but that only has value if you then use it in both places 🤦 Guess I'll have to re-run my benchmarks again when fixing that PR. Good catch ;) FWIW, I'm not tied to it being a separate function (vs just inlining the `if x in sys.modules`) for the purposes of _this_, but as alluded to on that other thread, I can see there being hot paths in Django which _do_ hit the import machinery every time, which might be a good reason to introduce such a function. However, I've not actually bench'd any of those places, so I can't say for _certain_ that it's of any further conseqence. Mostly I just wanted to surface the peeking into `sys.modules` as an option, whatever the implementation ends up being.
> @kezabelle This method is very good, but there are currently many Django-related modules that reference import_string during operation. If you add a cache_import, you must modify and adjust the module code that references import_string to improve performance. You can add a new hook and use it in `import_string()`, e.g. ```python def cached_import(module_name, item_name): modules = sys.modules if module_name not in modules: import_module(module_name) return getattr(sys.modules[module_name], item_name) def import_string(dotted_path): """ Import a dotted module path and return the attribute/class designated by the last name in the path. Raise ImportError if the import failed. """ try: module_path, class_name = dotted_path.rsplit('.', 1) except ValueError as err: raise ImportError("%s doesn't look like a module path" % dotted_path) from err try: return cached_import(module_path, class_name) except AttributeError as err: raise ImportError('Module "%s" does not define a "%s" attribute/class' % ( module_path, class_name) ) from err ```
> #14830 This is the newly proposed optimized version of sys.modules, but why turn it off ... It's exactly the same as this PR. We don't need multiple PRs with the same proposition.
We can drop the backticks, improve indentation, etc. ```suggestion warnings.warn( 'django.forms.BaseForm._html_output() is deprecated. ' 'Please use .render() and .get_context() instead.', RemovedInDjango50Warning, ) ```
I noticed that, with this removal, `django.forms.utils.flatatt()` is only used in one other place. Perhaps, in a follow up commit, we can change `AdminReadonlyField.label_tag()` to also render using templates: https://github.com/django/django/blob/eeed488a3439c5c5c3f0b5991ee400851057e127/django/contrib/admin/helpers.py#L193-L198 This would allow removal of `django.forms.utils.flatatt()` plus a bunch of tests in `tests/forms_tests/tests/test_utils.py`.
Although this was changed to use `self._bound_items()`, it is still doing `self[name]` and `field` is unused. ```suggestion fields = [] hidden_fields = [] top_errors = self.non_field_errors().copy() for name, bf in self._bound_items(): bf_errors = self.error_class(bf.errors) if bf.is_hidden: if bf_errors: top_errors.extend( [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ) hidden_fields.append(bf) else: fields.append((bf, mark_safe(str(bf_errors)))) return { 'form': self, 'fields': fields, 'hidden_fields': hidden_fields, 'errors': top_errors, } ```
```suggestion """Render as <tr> elements excluding the surrounding <table> tag.""" ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Yes. Effectively we should propagate the renderer passed in from formset to form to widget and errors.
Yes, that sounds sensible. Make it a separate preliminary commit.
As `BaseFormSet` is inheriting from `Renderable` we can ditch this as the definition is the same: ```suggestion ``` You can also remove `.as_table()`, `.as_p()`, and `.as_ul()`.
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
I think that `BaseForm.get_context()` describes this perfectly well: ```suggestion ``` But if we must keep it, it should be collapsed onto one line: ```suggestion """Returns context for form rendering.""" ```
Trailing commas: ```suggestion MAX_NUM_FORM_COUNT: self.max_num, }, renderer=self.renderer, ```
```suggestion return '<div class="errorlist">%s</div>' % ''.join( f'<div class="error">{error}</div>' for error in self ) ```
```suggestion return '<div class="errorlist">%s</div>' % ''.join( f'<div class="error">{error}</div>' for error in self ) ```
Can we avoid duplicating this? Maybe define it at the module level as it is used in multiple test cases.
```suggestion errors_on_separate_row=True, ```
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
```suggestion raise NotImplementedError('Subclasses of RenderableMixin must provide a get_context() method.') ```
We can remove this blank line: ```suggestion ```
```suggestion template_name = 'forms_tests/form_snippet.html' ```
We could simplify this and also be explicit rather than assuming that the Django renderer is the default? ```suggestion import inspect from django.test.utils import override_settings TEST_SETTINGS = [ { 'FORM_RENDERER': 'django.forms.renderers.DjangoTemplates', 'TEMPLATES': {'BACKEND': 'django.template.backends.django.DjangoTemplates'}, }, { 'FORM_RENDERER': 'django.forms.renderers.Jinja2', 'TEMPLATES': {'BACKEND': 'django.template.backends.jinja2.Jinja2'}, }, ] def test_all_form_renderers(): def wrapper(func): def inner(*args, **kwargs): for settings in TEST_SETTINGS: with override_settings(**settings): func(*args, **kwargs) return inner def decorator(cls): for name, func in inspect.getmembers(cls, inspect.isfunction): if name.startswith('test_'): setattr(cls, name, wrapper(func)) return cls return decorator ``` (I've not tested this, but it should give you an idea.)
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
```suggestion """Render as <p> elements.""" ```
```suggestion BookFormSet = modelformset_factory(Author, fields='__all__', renderer=renderer) ```
```suggestion """Render as <tr> elements excluding the surrounding <table> tag.""" ```
I think these _could_ be: ``` __str__ = render __html__ = render ``` Avoiding +1 depth (and it's faster). Off the top of my head, the only reasons _not_ to would be: - `x.__str__` would report `<bound method X.render of ...>` instead of `<bound method X.__str__ of ...>` - you _could_ technically manually call `x.__str__(template_name='a')` but I mean, who's doing that? Discuss amongst yourselves whether to change it, I don't think it really matters much :)
```suggestion """Render as <p> elements.""" ```
We seem to be calling `str()` twice here. Maybe: ```suggestion errors_str = str(bf_errors) if not isinstance(errors_str, SafeString): warnings.warn( 'Returning a plain string from ErrorList is deprecated. ' 'Please customize via the template system instead.', RemovedInDjango50Warning, ) errors_str = mark_safe(errors_str) # RemovedInDjango50Warning: remove check and replace errors_str # with str(bf_errors) fields.append((bf, errors_str)) ```
```suggestion renderer=renderer, ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Can we move deprecation tests to a separate file? e.g. ` tests/forms_tests/tests/test_deprecation_forms.py`.
```suggestion # RemovedInDjango50Warning: when the deprecation ends, remove # mark_safe() call. ```
```suggestion return {'formset': self} ```
```suggestion A custom renderer passed to a formset_factory() is passed to all forms and ErrorList. ```
Imports should be wrapped at 79 chars. Please move `Choice` to the next line: ```python Bookmark, Box, Category, Chapter, ChapterXtra1, Child, ChildOfReferer, Choice, City, Collector, Color, Color2, ComplexSortedPerson, CoverLetter, ```
Do we need named db? ```suggestion 'NAME': ':memory:', ```
```suggestion try: with connections['default'].cursor() as cursor: cursor.execute('PRAGMA journal_mode;') value = cursor.fetchone()[0] self.assertEqual(value, 'off') finally: connections['default'].close() ```
I don't see much value in this docstring, please remove it.
inheritance from object is not needed here.
Maybe even in advance with the current form.
I would use: ```python return self.selenium.find_element( By.CSS_SELECTOR, selector, ).get_attribute('class').find(klass) != -1 ```
This should go to the 2nd commit :pick:
We need to use inline imports or move all Selenium imports to the `try ... except` block (another separate commit) because tests shouldn't crash without it.
Maybe: ```python self.assertEqual(len(self.selenium.find_elements( By.CSS_SELECTOR, '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]', )), 1) ``` or ```python selector = '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]' self.assertEqual(len(self.selenium.find_elements(By.CSS_SELECTOR, selector)), 1) ```
```suggestion 'Add another Inner4 stacked', ```
This should go to the 2nd commit :gem:
Just throwing it out there; for floatformat uses which don't include `g` or `u` they're paying the cost for exhaustive checking. We can minimise that cost if you're bothered about it. ``` last_chars = arg[-2:] last_char = arg[-1] if last_chars in {'ug', 'gu'}: force_grouping = True use_l10n = False arg = arg[:-2] or -1 elif last_char == 'g': force_grouping = True arg = arg[:-1] or -1 elif last_char == 'u': use_l10n = False arg = arg[:-1] or -1 ``` eg: Back of the napkin costs; if I wrap the original `if` branches into a function `endswiths` (which does nothing else), and the ones above into `charslice`: ``` # Unsuffixed, most common usage presumably. In [2]: %timeit endswiths('21525.3532') 450 ns ± 5.76 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [3]: %timeit charslice('21525.3532') 305 ns ± 7.34 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) # Both suffixes In [4]: %timeit endswiths('21525.3532gu') 322 ns ± 4.62 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [5]: %timeit charslice('21525.3532gu') 350 ns ± 10.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) # u suffix In [6]: %timeit endswiths('21525.3532u') 529 ns ± 8.17 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [7]: %timeit charslice('21525.3532u') 385 ns ± 6.24 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) # g suffix In [8]: %timeit endswiths('21525.3532g') 435 ns ± 6.33 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [9]: %timeit charslice('21525.3532g') 355 ns ± 3.67 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
@pauloxnet Ahh, sorry, just merged.
Do we need to swap arguments? IMO we want to keep the same order as in `SIMILARITY()` calls. ```suggestion class TrigramWordSimilarity(TrigramBase): function = 'WORD_SIMILARITY' ``` e.g. - `TrigramWordSimilarity('Cat sat on mat.', 'cat')` should be equal to `0.30769232` instead of `1` - `TrigramWordDistance('Cat sat on mat.', 'cat')` should be equal to `0.6923077` instead of `0`
I think we always want the input on the `>>` side of the operator to be able to utilise any indexes. So we get the following SQL: ```sql SELECT t, t <->> 'word' AS dist FROM test_trgm ORDER BY dist; ``` That should mean that we want `arg_joiner = ' <->> '`. <details> <summary>Index operator classes query where LHS is the indexed value</summary> <code> SELECT am.amname AS index_method, opf.opfname AS opfamily_name, amop.amopopr::regoperator AS opfamily_operator FROM pg_am am, pg_opfamily opf, pg_amop amop WHERE opf.opfmethod = am.oid AND amop.amopfamily = opf.oid AND opf.opfname IN ('gist_trgm_ops', 'gin_trgm_ops') ORDER BY index_method, opfamily_name, opfamily_operator; </code> </details> ``` index_method | opfamily_name | opfamily_operator --------------+---------------+------------------- gin | gin_trgm_ops | ~(text,text) gin | gin_trgm_ops | ~~(text,text) gin | gin_trgm_ops | ~*(text,text) gin | gin_trgm_ops | ~~*(text,text) gin | gin_trgm_ops | %(text,text) gin | gin_trgm_ops | %>(text,text) gin | gin_trgm_ops | %>>(text,text) gist | gist_trgm_ops | ~(text,text) gist | gist_trgm_ops | ~~(text,text) gist | gist_trgm_ops | ~*(text,text) gist | gist_trgm_ops | ~~*(text,text) gist | gist_trgm_ops | %(text,text) gist | gist_trgm_ops | %>(text,text) gist | gist_trgm_ops | <->(text,text) gist | gist_trgm_ops | <->>(text,text) gist | gist_trgm_ops | %>>(text,text) gist | gist_trgm_ops | <->>>(text,text) (17 rows) ```
I would use the same order as the previous two classes (`TrigramSimilarity` and `TrigramDistance`): ```suggestion class TrigramWordSimilarity(TrigramWordBase): function = 'WORD_SIMILARITY' class TrigramWordDistance(TrigramWordBase): function = '' arg_joiner = ' <<-> ' ```
@felixxm yes that's what I'm thinking.
As far I'm aware if we want to keep the same order as in PostgreSQL, it should be :thinking: ```python TrigramWordSimilarity(string, expression) ``` For example ```python TrigramWordSimilarity('cat', 'Cat sat on mat.') ```
> Paolo, Can you take a look? (\cc @pauloxnet) point_up Sorry, I totally missed the notification of this. I'll take a look
@hannseman @jamesturk Can I ask for your opinion? :point_up:
:thinking: ```suggestion arg_joiner = ' <<-> ' ``` Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
> .. i'll follow your decision :) Just asking, I'm not an expert :shrug:. We can wait for the second opinion from Paolo.
Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
~Is there a reason this is in the `CANDIDATE_TRAVERSAL_FILE_NAMES` rather than the `CANDIDATE_INVALID_FILE_NAMES`?~ On further reflection, I've realised why. It's because the values in `CANDIDATE_INVALID_FILE_NAMES` return `None` rather than sanitised/fixed names. My apologies for the noise.
IMO `, got...` is not necessary.
Ticket number and a note about antivirus are not necessary, maybe: ``` """HTML email doesn't contain forms.""" ```
We can use a new instance instead of changing `admin_email_handler`: ```suggestion handler = AdminEmailHandler(include_html=True) ```
I would add: ``` self.assertIn('<div id="traceback">', htmls[0]) ```
```suggestion htmls = [content for (content, _type) in msg.alternatives if _type == 'text/html'] ```
On the other hand this code is checked in `LimitChoicesToTests` and we don't have a warning anymore so both tests seem redundant. I removed them.
Do we need to define `async_generator` in `__aiter__`? ```python async def _async_generator(self): # Generators don't actually start running until the first time you call # next() on them, so we make the generator object in the async thread # and then repeatedly dispatch to it in a sync thread. sync_generator = self.__iter__() # So, you can't raise StopIteration up through sync_to_async as # too much of the Python async system was originally built on # generators. Instead, we capture it inside a custom sync function # and change it to an exception we *can* propagate. # We should probably move this logic inside asgiref at some point. def custom_next(gen): try: return next(gen) except StopIteration: raise StopAsyncIteration() while True: try: yield await sync_to_async(custom_next)(sync_generator) except StopAsyncIteration: return # Note: __aiter__ is a *synchronous* method that has to then return an # *asynchronous* iterator/generator. Thus, we nest an async generator # inside it. # Also note: This is a generic iterable converter for now, and is going to # suffer a performance penalty on large sets of items due to the cost of # crossing over the sync barrier each time. We should write custom ones # for each Iterable subclass, but we'll need some work in Compiler first. def __aiter__(self): return self._async_generator() ```
Is this necessary? It's already a part of `count()` :thinking:
What about async variants of remaining methods: - `values_list()`, - `values()`, - `dates()`, - `datetimes()`, - `none()`, - `all()`, - `filter()`, - `exclude()`, etc. :thinking:
What about `prefetch_related()`? It's a new method so we should raise `ValueError` when `aiterator()` is used after `prefetch_related()`, e.g. ```python async def aiterator(self, chunk_size=2000): if chunk_size is None: if self._prefetch_related_lookups: raise ValueError( "chunk_size must be provided when using QuerySet.iterator() after " "prefetch_related()." ) elif chunk_size <= 0: .... ```
We'll want to do something with regards to the newly added support for `iterator`'s `prefetch_related` here.
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
To anyone curious, it's likely a problem of when (or rather, where) `connection.features` gets evaluated. ```python await a_getattr(connection.features, "supports_json_field") ``` is executed in the following order: ```python foo = connection.features bar = a_getattr(foo, "supports_json_field") await bar ``` Evaluating `connection.features` does the following: 1. Since `connection` is a `ConnectionProxy` instance, it first finds a default connection 2. It takes that connection and returns a `DatabaseFeatures` instance bound to it That first step is tricky because it uses the `_connections` object as a cache. `_connections` is an instance of `asgiref.local.Local`, which is thread-local by design. So the same cache instance will contain different attributes depending on where (which thread) it's accessed from. Now, when `connection.features` is evaluated in the main thread, it returns a `DatabaseFeatures` instance bound to the connection object created in the main thread (and only safe to use within that main thread). The last puzzle piece is `sync_to_async`, which creates a one-off worker thread to complete a synchronous function call without blocking the event loop. The `getattr` call executed within `sync_to_async` runs in a new thread. This new thread attempts to use the features object passed from the main thread. Which, in turn, tries to use the connection object created in the main thread (to check if the connection is to a MariaDB server).
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
Diff reproducing on SQLite: ``` diff --git a/tests/async/tests.py b/tests/async/tests.py index 66eece4b97..0610b6f1b0 100644 --- a/tests/async/tests.py +++ b/tests/async/tests.py @@ -1,13 +1,15 @@ +import _thread import asyncio import os from unittest import mock -from asgiref.sync import async_to_sync +from asgiref.sync import async_to_sync, sync_to_async from django.core.cache import DEFAULT_CACHE_ALIAS, caches from django.core.exceptions import ImproperlyConfigured, SynchronousOnlyOperation +from django.db import connection from django.http import HttpResponse -from django.test import SimpleTestCase +from django.test import SimpleTestCase, TestCase from django.utils.asyncio import async_unsafe from django.views.generic.base import View @@ -25,13 +27,22 @@ class CacheTest(SimpleTestCase): self.assertIs(cache_1, cache_2) -class DatabaseConnectionTest(SimpleTestCase): +class DatabaseConnectionTest(TestCase): """A database connection cannot be used in an async context.""" async def test_get_async_connection(self): with self.assertRaises(SynchronousOnlyOperation): list(SimpleModel.objects.all()) + async def test_validate_thread_sharing(self): + def func(connection): + print(connection.features.supports_json_field) + + await sync_to_async(func)(connection) + + a_getattr = sync_to_async(getattr) + print(await a_getattr(connection.features, "supports_json_field")) + class AsyncUnsafeTest(SimpleTestCase): """ ``` The first version works, wrapping the whole feature check in `sync_to_async`. The second, wrapping `getattr` causes the error.
Hey @patrys — Nice. 👍 > The last puzzle piece is... I'd gotten to just before this, but was missing this, so 👯 — Thanks! We need to have a little think about how we structure calls to not run into this — especially if they're nested somewhere inside a context manager, as @felixxm hit for `CaptureQueriesContext` — but tomorrow... 🛏️ 🎁
IMO copying docstrings from sync versions is of little value. I'd chop them.
Using `connection` inside `sync_to_async` correctly finds a `default` connection in `_connections` (which is a `Local` instance). However, using `connection` outside of `sync_to_async` doesn't find a `default` connection in `_connections` and creates a new one. In both cases, `_connections` is the same object according to its `ID`. :exploding_head:
`yield from` is not allowed in async functions.
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
```suggestion "Using QuerySet.aiterator() after prefetch_related() is not supported." ```
`lLook` => `look`
Any idea what the "cost" of this is? ie: because all template output runs through `render_value_in_context` -> `localize` which then dispatches to any of `number_format` / `date_format` / `time_format` each of which _may_ call `settings.USE_L10N` depending on if the `context.use_l10n` value (and I confess I can't remember when/where the details of _that_), each of those values (decimals/ints/floats/datetime.*) is unavoidably going to be slower (if/when `use_l10n` is `None`), and I wonder by how much? And is it avoidable? (eg: `cached_property` or what-have-you)
Can we restore the previous "style"? ```suggestion return repr(self.value).replace('datetime.timezone.utc', 'utc'), set(imports) ```
IMO, this warning can be confusing for users using `Trunc*()` or `QuerySet.datetimes()`. Maybe a note: _"... to make_aware(), used by Trunc() database functions and QuerySet.datetimes(), is deprecated..."_ :thinking:
```suggestion with self.settings(USE_DEPRECATED_PYTZ=use_pytz): with override_database_connection_timezone(connection_tz): self.assertIsInstance(connection.timezone, expected_type) ```
`IS_DST_PASSED` is confusing, maybe `NOT_PROVIDED`.
Usually `__getattr__` is paired with `__dir__`, so that the lazy-loaded stuff is still exposed to `dir()`. My go-to implementation is: ```python def __dir__(): return sorted(list(globals()) + ["utc"]) ```
I find this a mildly counter-intuitive name, since this is the *answer* to the question "is DST passed?" (or, worse, it's a statement "`isdst` passed", which is the opposite of the actual meaning of this sentinel!), but it is named as the question. I'd probably call it something like `IS_DST_SENTINEL` or `DST_NOT_SPECIFIED`.
However the `zoneinfo.ZoneInfo("UTC")` vs `timezone.utc` thing shakes out, it might make sense to support `timezone.utc` anyway, which has a `repr` of `datetime.timezone.utc`? Or is the idea that you only want to capture the situation where someone has used `django.utils.timezone.utc` specifically, and you want to always give them `django.utils.timezone.utc` in the event of migrations between Django instances with different values for `settings.USE_DEPRECATED_PYTZ`? If that's the case, do you want special-case logic for handling the more generic case of time zones? Presumably the `repr` can be rewritten to use something like `django.backends.db.timezone_constructor` instead? (Though there may be a performance hit from this, which may or may not be acceptable).
```suggestion @unittest.skipUnless(pytz is not None, 'Test requires pytz') ```
Good shout, thanks! Forgot about `__dir__()` when I proposed this.
```suggestion # RemovedInDjango50Warning: when the deprecation ends, remove is_dst # argument. def datetimes(self, field_name, kind, order='ASC', tzinfo=None, is_dst=timezone.NOT_PASSED): ```
```suggestion # RemovedInDjango50Warning: when the deprecation ends, remove is_dst # argument. def __init__(self, expression, output_field=None, tzinfo=None, is_dst=timezone.NOT_PASSED, **extra): ```
I'd chop the above blank line.
```suggestion RemovedInDjango50Warning, ```
```suggestion 'The USE_DEPRECATED_PYTZ setting, and support for pytz timezones is ' 'deprecated in favor of the stdlib zoneinfo module. Please update your ' 'code to use zoneinfo and remove the USE_DEPRECATED_PYTZ setting.' ```
This could possibly be split into additional simple wrappers based on `parameter.kind` if it were `POSITIONAL_ONLY` or `KEYWORD_ONLY`? Then you could have simple conditions: ```python if has_multiple_parameters: def wrapper(*args, **kwargs): if any( isinstance(arg, Promise) for arg in itertools.chain(args, kwargs.values()) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) elif parameter.kind == parameter.POSITIONAL_ONLY: def wrapper(*args, **kwargs): if isinstance(args[0], Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) elif parameter.kind == parameter.KEYWORD_ONLY: def wrapper(*args, **kwargs): if isinstance(kwargs[first_parameter.name], Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) else: # parameter.POSITIONAL_OR_KEYWORD def wrapper(*args, **kwargs): if (args and isinstance(args[0], Promise)) or ( first_parameter.name in kwargs and isinstance(kwargs[first_parameter.name], Promise) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) return wraps(func)(wrapper) ``` Although maybe that is overkill if we just simplify the last case: ```python def wrapper(*args, **kwargs): arg = args[0] if args else kwargs[first_parameter.name] if isinstance(arg, Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) ``` (Note that we can assume it exists in `kwargs` if `args` was empty and drop the additional containment check.)
If we `from itertools import chain` we can save the overhead of attribute access here.
Yeah, so none of the tests failed if I forced either the multiple or single argument form of the function. That can't be right.
This section doesn't seem so efficient as we're iterating the parameters twice. It's also a bit difficult to understand. I played and came up with something like the following: ```python def decorator(func): lazy_func = lazy(func, *resultclasses) first_parameter = None has_multiple_parameters = False for parameter in inspect.signature(func).parameters.values(): if first_parameter or parameter.kind in (parameter.VAR_POSITIONAL, parameter.VAR_KEYWORD): has_multiple_parameters = True break else: first_parameter = parameter if has_multiple_parameters: def wrapper(*args, **kwargs): if any( isinstance(arg, Promise) for arg in itertools.chain(args, kwargs.values()) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) else: def wrapper(*args, **kwargs): if (args and isinstance(args[0], Promise)) or ( first_parameter.name in kwargs and isinstance(kwargs[first_parameter.name], Promise) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) return wraps(func)(wrapper) return decorator ``` A few things to note: - Only define the wrapper if we're actually going to use it. Before, both were being defined and then one was being selected. - It is only necessary to look as far as the second parameter. If there is more than one, we have multiple arguments. If the first is `*args` or `**kwargs` we have multiple arguments. - We can tell whether we're looking at the second parameter if we have set `first_parameter` which nicely avoids the need for `enumerate()`.
We could reuse `test_readonly_foreignkey_links()`, e.g. ```diff diff --git a/tests/admin_views/tests.py b/tests/admin_views/tests.py index a8524379f8..7e0a3a3415 100644 --- a/tests/admin_views/tests.py +++ b/tests/admin_views/tests.py @@ -5093,7 +5093,7 @@ class ReadonlyTest(AdminFieldExtractionMixin, TestCase): response = self.client.get(reverse('admin:admin_views_choice_change', args=(choice.pk,))) self.assertContains(response, '<div class="readonly">No opinion</div>', html=True) - def test_readonly_foreignkey_links(self): + def _test_readonly_foreignkey_links(self, admin_site): """ ForeignKey readonly fields render as links if the target model is registered in admin. @@ -5110,10 +5110,10 @@ class ReadonlyTest(AdminFieldExtractionMixin, TestCase): user=self.superuser, ) response = self.client.get( - reverse('admin:admin_views_readonlyrelatedfield_change', args=(obj.pk,)), + reverse(f'{admin_site}:admin_views_readonlyrelatedfield_change', args=(obj.pk,)), ) # Related ForeignKey object registered in admin. - user_url = reverse('admin:auth_user_change', args=(self.superuser.pk,)) + user_url = reverse(f'{admin_site}:auth_user_change', args=(self.superuser.pk,)) self.assertContains( response, '<div class="readonly"><a href="%s">super</a></div>' % user_url, @@ -5121,7 +5121,7 @@ class ReadonlyTest(AdminFieldExtractionMixin, TestCase): ) # Related ForeignKey with the string primary key registered in admin. language_url = reverse( - 'admin:admin_views_language_change', + f'{admin_site}:admin_views_language_change', args=(quote(language.pk),), ) self.assertContains( @@ -5132,6 +5132,12 @@ class ReadonlyTest(AdminFieldExtractionMixin, TestCase): # Related ForeignKey object not registered in admin. self.assertContains(response, '<div class="readonly">Chapter 1</div>', html=True) + def test_readonly_foreignkey_links_default_admin_site(self): + self._test_readonly_foreignkey_links('admin') + + def test_readonly_foreignkey_links_custom_admin_site(self): + self._test_readonly_foreignkey_links('namespaced_admin') + def test_readonly_manytomany_backwards_ref(self): """ Regression test for #16433 - backwards references for related **objects** ```
```suggestion current_app=self.model_admin.admin_site.name, ```
I'm not sure if we can decruft this a bit? ```python def cached_import(module_path, class_name): # Check whether module is loaded and fully initialized. if not ( module := sys.modules.get(module_path) and spec := getattr(module, '__spec__', None) and getattr(spec, '_initializing', False) is False ): module = import_module(module_path) return getattr(module, class_name) ``` You'll have to double check this - just knocked it up quickly.
An aside: I see the reference to `EggLoader`. Haven't Python "eggs" been pretty much obsolete for ages? Can we remove this or the bits that are related to "eggs"? (Something to create a separate ticket for, if so.)
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
We can also go faster by using a list comprehension instead of a generator - they're cheaper to create: ```suggestion obj.combined_queries = tuple([query.clone() for query in self.combined_queries]) ``` Simple benchmark: ``` In [2]: items = [1, 2, 3, 4] In [3]: %timeit tuple(x*2 for x in items) 508 ns ± 10 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [4]: %timeit tuple([x*2 for x in items]) 358 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
Yes. Good. We need something like: ``` if settings['FORM_RENDERER'] == 'django.forms.renderers.Jinja2': ``` before applying the `skipIf`. (It's not very pretty but...)
This won't work either. The tests run, but they're marked as skipped. @felixxm is adjusting.
This will skip Django templates tests also...
I think it's worth doing.
Yeah, it's fine.
This one should be reverted. You'll be doing extra accesses because it is now in a loop!
This can be single-lined ```suggestion compiler = connection.ops.compiler('SQLCompiler')(self.query, connection, db) ```
```suggestion # - MySQL < 8.0.13 doesn't accept default values and implicitly treats them ```
This is a much better test that visibly demonstrates things _should_ work again, nice. :) I don't know the stylistic preferences @felixxm _et al_ might have around using `assertEqual` vs. `assertJSONEqual` here, so I'll leave this as a note for highlighting.
OK, thanks. I'll squash it down then. 😄
This block looks ordered alphabetically (although that may be a fluke when compared to the blocks below): ```suggestion geos_makevalid = GeomOutput('GEOSMakeValid', argtypes=[GEOM_PTR]) geos_normalize = IntFromGeom('GEOSNormalize') ```
I'm surprised that this needs to be `NULL` instead of `None`.
I thought `empty_result_set_value` was meant to be a literal or whatever you'd pass to `Value` ```suggestion empty_result_set_value = value = getattr(arg, 'empty_result_set_value', NotImplemented) if empty_result_set_value is NotImplemented: raise arg_sql, arg_params = '%s', (empty_result_set_value,) ``` Or alternatively ```suggestion empty_result_set_value = getattr(arg, 'empty_result_set_value', NotImplemented), () if empty_result_set_value is NotImplemented: raise arg_sql, arg_params = compiler.compile(Value(empty_result_set_value)) ``` Which allows for better placeholder and `NULL` interoperability on Oracle which might have been the reason `Query.empty_result_set_value = 'NULL'` instead of `None` https://github.com/django/django/blob/06f5c22ea5907295f2360dc83e17b89aa84ae2fe/django/db/models/expressions.py#L754-L770
We should move it out of the "aggregate specific fields" section. Maybe: ```suggestion # Func() specific fields. empty_result_set_value = NotImplemented ```
Right, so let's move it above the `# aggregate specific fields`.
`new_field.unique` is in both sub-conditions so we can simplify this: ```python return ( not new_field.primary_key and new_field.unique and (not old_field.unique or old_field.primary_key) ) ``` Also, `_unique_should_be_added()` in `django.db.backends.oracle.schema.DatabaseSchemaEditor` is redundant and can be removed: https://github.com/django/django/blob/fb05ca420da1341c0d39cf1f0e2fb659be836c92/django/db/backends/oracle/schema.py#L177-L181
I think the `FieldError` is an artifact of your test iteration process, you should be able to remove the `try` statement now.
You can define the `output_field` as a class attribute instead to avoid this boilerplate. See how it's done for `JSONBAgg` just above for example.
Would it make sense to put this into a try/except so we ignore errors from close? Maybe also add a `self.connection = None` after the `close()` so we can be sure we are not able to reuse it.
Maybe better named as `health_check_enabled` or `_configured`
I was considering the case where close might fail and as a result does not set `self.connection` to `None` because it returns before that (probably via raise). But if `close_if_unusable_or_obsolete()` doesn't handle it any differently I guess we are fine -- we can add it later if needed.
Maybe: ```suggestion try: self.assertInHTML('<th>1</th>', f.render()) except RecursionError: self.fail('Cyclic reference in BoundField.render().') ```
Maybe: ```suggestion template_name_label = 'forms_tests/cyclic_context_boundfield_render.html' ```
All tests (new and old) pass when we change only these two lines. I don't think that other changes are required.
`fake_user_data` is not passed to the `create_superuser()`.
Yes, these two lines are necessary, and `test_fields_with_m2m_by_env` is a regression test for them.
Only `test_fields_with_m2m_by_env` fails on a fresh branch without any of your changes in `django/contrib/auth/management/commands/createsuperuser.py` and `tests/auth_tests/models/with_foreign_key.py`,
It is not about the controversy, this is an actual bug that should be fixed. Changing the current behavior for foreign keys/many-to-many fields requires a separate ticket, however without a discussion on the mailing list we will close it immediately as _"wontfix"_, so I'd start from the discussion.
This works without the patch. Extra test coverage is welcome, but should be keep in a separate commit/PR.
This works without the patch. Extra test coverage is welcome, but should be keep in a separate commit/PR.
> Thank you. Should I open a Trac ticket for this bug or it's not necessary? For me ticket-33151 is a ticket for this bug we don't need a new one. I've changed the summary to _"createsuperuser doesn't work in non-interactive mode if a ManyToManyField is in REQUIRED_FIELDS"_.
This proves that the patch is backward incompatible. Currently we always pass an `id` for foreign keys and a list of `id`s for many-to-many fields. We should keep this behavior.
I'd check `hash()`: ```suggestion def test_choice_value_hash(self): value_1 = ModelChoiceIteratorValue(self.c1.pk, self.c1) value_2 = ModelChoiceIteratorValue(self.c1.pk, self.c2) self.assertEqual(hash(value_1), hash(ModelChoiceIteratorValue(self.c1.pk, None))) self.assertNotEqual(hash(value_1), hash(value_2)) ```
`test_choice_value_hash` is sufficient. IMO we can remove this test.
`in_atomic_block` here is redundant: ```suggestion if ( self.durable and connection.atomic_blocks and not connection.atomic_blocks[-1]._from_testcase ): ```
We don't need these two lines, or the starting `try:` line.
Rather than have the `_test_marker` as an instance variable that ripples through all the methods, we could have it as a class-level variable that defaults to `False` and override it here on the instance. Also I think a better name would be `_from_testcase` or similar - the word "marker" doesn't really convey much meaning. ```suggestion atomic = transaction.atomic(using=db_name) atomic._from_testcase = True atomics[db_name] = atomic ```
`connection.atomic_blocks` makes `connection.in_atomic_block` and `connection.savepoint_ids` somewhat redundant.
```suggestion in_test_context = ( len(connection.atomic_blocks) > 0 and connection.atomic_blocks[-1]._test_marker ) ```
It looks that only `OneToOneField` is affected, so I'd move your test to the `ExcludeTests`, e.g. ```python def test_exclude_unsaved_object(self): jack = Staff.objects.create(name='jack') jack_staff = StaffUser.objects.create(staff=jack) unsaved_object = Staff(name='jane') self.assertIsNone(unsaved_object.pk) self.assertSequenceEqual(StaffUser.objects.exclude(staff=unsaved_object), [jack_staff]) ```
`book` should be `Book` ideally, I think? I wonder also if the `Found ...` sentence should first. Telling the user about callable defaults without having told them what was found seems stiff. Though if it's following the cadence of other prompts (I can't recall), then disregard; better to be consistent.
I don't think it's worth changing :shrug:
`lambda` works better on Firefox, let's leave it.
Can we use [number_of_windows_to_be()](https://www.selenium.dev/selenium/docs/api/py/webdriver_support/selenium.webdriver.support.expected_conditions.html#selenium.webdriver.support.expected_conditions.number_of_windows_to_be)? ```suggestion self.wait_until(ec.number_of_windows_to_be(2)) ``` Also, we can probably chop `self.assertEqual(len(self.selenium.window_handles), 2)` in the next line.
Extracting first host in case of a list: ```python host_match = host_validation_re.match(host.split(",")[0]) ```
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
Passing `group` to the `call_command()` is unnecessary because it's already passed via `DJANGO_SUPERUSER_GROUP`.
`call_command()` raises an exception so these lines are unreachable.
`call_command()` raises an exception so these lines are unreachable.
`call_command()` raises an exception so these lines are unreachable.
This looks unnecessary.
This looks unnecessary.
This is risky, I would use (in all new tests): ```suggestion Group.objects.all().delete() nonexistent_group_id = 1 ```
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
Do we need to move these two lines? All tests pass without this change.
We cannot mix different bugfixes and bugfixes with cleanups, because it really makes it difficult to trace a potential regression. I prepared PR #14972 which only fixes this specific issue. We can rebase your patch after #14972.
I noticed that moving these lines outside of `while` is also a separate fix, see #14976.
Manager will raise a different `IntegrityError`, e.g. _"The row in table 'auth_tests_customuserwithfk' with primary key '1' has an invalid foreign key: auth_tests_customuserwithfk.group_id contains a value '-1' that does not have a corresponding value in auth_group.id."._
> .... that is not `many_to_one` or `many_to_one`. A `BooleanField`. I think there are a few typos in the sentence above. It's hard for me to understand what you meant. It seems to be a separate issue that can be fixed and tested separately. As for the test it should be enough to pass `first_name` in the command line in a test similar to the `test_validate_password_against_required_fields`.
Can we move the whole `data` setup into `items`? 🤔 ```suggestion def items(self): o1 = TestModel() o1.lastmod = datetime(2013, 3, 13, 10, 0, 0) o2 = TestModel() o2.lastmod = datetime(2014, 3, 13, 10, 0, 0) return [o1, o2] def lastmod(self, obj): return obj.lastmod ``` (Getting rid of the dict lookup step.) (🤷‍♀️)
```suggestion if scheme and scheme not in self.schemes: ``` 🤔
```suggestion if not isinstance(perm_list, (list, tuple)): ValueError('perm_list must be a list or tuple.') ```
```suggestion raise ValueError('perm_list must be a list or tuple.') ```
Please assert an error message, e.g. ```suggestion msg = 'perm_list must be a list or tuple.' with self.assertRaisesMessage(ValueError, msg): ```
```suggestion msg = 'perm_list must be a list or tuple.' with self.assertRaisesMessage(ValueError, msg): ```
I would raise a `ValueError`: ```suggestion if not isinstance(perm_list, (list, tuple)): ValueError('perm_list must be a list or tuple.') ```
Also we can use `[1]` instead of `.group(1)`.
Yes - sorry - not sure how I dropped that: ```python if match := re.match(r'^(?:\d+_squashed_)?(\d+)', name): return int(match[1]) ```
> If a migration is squashed twice [1](#user-content-fn-squash-b8f940599d11ece48c2972b0da589b55), Yes, it's not currently supported, see ticket-24529.
This can be simplified significantly: ```suggestion if match := re.match(r'^(?:\d+_squashed_)(\d+)', name): return int(match[1]) ```
It doesn't work in all cases. For example, I have two migrations: 1. `0001_initial.py` 2. `0002_mymodel2.py` `manage.py squashmigrations test_app 0001 0002` generates: ``` 0001_initial_squashed_0002_mymodel2.py ``` which doesn't match this regexp and the next migration is generated with the wrong number: `0002_mymodel3.py`.
We don't need two groups: ```suggestion if squashed_match := re.search(r'_squashed_(\d+)', name): return int(squashed_match.group(1)) ```
Add a blank line. ```suggestion base_table_class = BaseTable ```
`MultiJoin` is an exception class. I don't think you need to customize it.
I just tested it, I believe its good now, thank you :)
I simplified code with `expression.conditional`.
@felixxm, I've just ran some test, when functional indexes return boolean values, they act the same way as boolean fields, i.e. in order to use the functional index you need to explicitly say `(some_expression) = 1/0` where `some_expression` is the functional index.
Spitballing; is there any benefit/drawback/(in?)consistency/other to using `getattr(expression, 'conditional', False)`? (I don't think it necessarily _matters_, because `Col.conditional` is literally the same check AFIAIK)
```suggestion try: from aiosmtpd.controller import Controller except ImportError: HAS_AIOSMTPD = False else: HAS_AIOSMTPD = True ```
I'm not sure about changing the signature. Can we restore the previous one? ```suggestion def urlize(text, trim_url_limit=None, nofollow=False, autoescape=False): return urlizer(text, trim_url_limit=None, nofollow=False, autoescape=False) ```
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
```suggestion trailing_punctuation_chars = '.,:;!' wrapping_punctuation = [('(', ')'), ('[', ']')] ```
Maybe this should be a class docstring :thinking:
Wonder if we should go further and simply change the expression if `col.alias == old_table` that seems in line what other implementation of `rename_table_references` does ```suggestion if col.alias == old_table col.alias = new_table ```
OK we can revert my suggestion, sorry. `RenameModel()` doesn't change `db_table` so `old_db_table` can be different from `new_db_table` only when `db_table` is not defined.
Do we need this mapping? We could redirect to a `HttpResponse` with the `status_code`, e.g. `HttpResponse(status_code=r.redirect_type)`.
There is no such settings as `DIRS`. This is unnecessary. ```suggestion ``` We also try to deffer accessing `__file__`, see ticket-32316.
`mutliple` -> `multiple`
`module_label` -> `module_name`
This can be single-lined. Also, please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion custom_libraries = conf.get('OPTIONS', {}).get('libraries', {}) ```
```suggestion id='templates.E003', ```
```suggestion '{} is used for multiple template tag modules: {}.', ```
```suggestion def check_for_template_tags_with_the_same_name(app_configs, **kwargs): ```
We should restore this check because in the current version `LiveServerTestCaseSetupTest` doesn't test anything, but I'm not sure how to do this :thinking:
I removed this extra call.
I wonder if we could use `addClassCleanup()` instead, it's called even if `setUpClass()` raises an exception (see faba5b702a9c5bb9452a543100928bcb5f66ebcf and 213850b4b9641bdcb714172999725ec9aa9c9e84).
IMO both cleanup should be added in `_start_server_thread()`, i.e.: ```python @classmethod def _start_server_thread(cls): cls._live_server_modified_settings = modify_settings( ALLOWED_HOSTS={'append': cls.allowed_host}, ) cls._live_server_modified_settings.enable() cls.addClassCleanup(cls._live_server_modified_settings.disable) ... cls.server_thread.start() cls.addClassCleanup(cls._terminate_thread) ... ```
Is there a reason not to be backward compatible and to use `OR` instead? :thinking: ```suggestion queryset = queryset.filter(models.Q(*term_queries), _connector=models.Q.OR)) ``` This will still fix the issue with multiple joins.
We could use `self.CaptureQueriesContext()` and assert that `JOIN` is only used once.
`now` is unnecessary.
Use [hanging indent](https://docs.djangoproject.com/en/3.2/internals/contributing/writing-code/coding-style/#python-style): ```suggestion request = self.request_factory.get( '/', {'name__in': ",".join(escape_comma(e.name) for e in employees)}, ) ``` (But less than 120 chars it can go on one line.)
Use hanging indent: ```suggestion request = self.request_factory.get( '/', {'name__in': "|".join(e.name for e in employees), 'divider': '|'} ) ```
No need to assign this to `self`, since it's not used outside this one method.
I would leave this example as it is, so that the other tests are not affected, and then create a third `Employee` at the beginning of the new test.
This is not a good return on (complexity) investment IMO 🙂
I'd use `join()` in both places: ```suggestion output += ''.join([ escape(c) if isinstance(c, str) else str(c) for c in self.children ]) ```
We don't call `escape()` on lazy or safe strings so we can use `from html import escape` directly.
`join()` is unnecessary ```suggestion msg = ( '<p>\n<foo>\n</p>' ' != ' '<p>\n&lt;foo&gt;\n</p>\n' ) ```
```suggestion call_command('inspectdb', 'inspectdb_foreignkeytofield', stdout=out) self.assertIn( "to_field_fk = models.ForeignKey('InspectdbPeoplemoredata', " "models.DO_NOTHING, to_field='people_unique_id')", out.getvalue(), ) ```
We can drop this model and reuse `PeopleMoreData`, e.g. ```python class ForeignKeyToField(models.Model): to_field_fk = models.ForeignKey(PeopleMoreData, models.CASCADE, to_field='people_unique') ```
Do we need an extra hook? Is there a reason not to use `get_primary_key_column()` as [suggested](https://code.djangoproject.com/attachment/ticket/33187/handle_fk_to_field.diff) in the ticket? :thinking: For example: ```python if is_relation: ref_db_column, ref_db_table = relations[column_name] if extra_params.pop('unique', False) or extra_params.get('primary_key'): rel_type = 'OneToOneField' else: rel_type = 'ForeignKey' ref_pk_column = connection.introspection.get_primary_key_column(cursor, ref_db_table) if ref_pk_column and ref_pk_column != ref_db_column: extra_params['to_field'] = ref_db_column rel_to = ( "self" if ref_db_table == table_name else table2model(ref_db_table) ) if rel_to in known_models: field_type = '%s(%s' % (rel_type, rel_to) else: field_type = "%s('%s'" % (rel_type, rel_to) else: ... ```
Maybe ```suggestion 'Migration f{squashed_name} already exits, use a different file name.' ``` We should move this check to the [`squashmigrations` command](https://github.com/django/django/blob/main/django/core/management/commands/squashmigrations.py).
IMO there is no need to check a file content: ```suggestion msg = '...' with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
There is no need to use `assertRaisesRegex()`: ```suggestion msg = 'Migration 0001_initial already exists. Use a different name.' with self.temporary_migration_module(module='migrations.test_migrations'): with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
I don't see much value in this docstring: ```suggestion ```
```suggestion if os.path.exists(writer.path): raise CommandError( f'Migration {new_migration.name} already exists. Use a different name.' ) ```
```suggestion import os ```
I think I would define the additional parameters as keyword parameter, as in `__call__ `. BTW, thanks for fixing this thread issue I created!
The `trim_url_` prefix for the new argument seems unnecessary here. Also, if we're expecting it to be passed as a keyword, let's enforce that. ```suggestion def trim_url(self, x, *, limit=None): ```
```suggestion trimmed = self.trim_url(middle, limit=trim_url_limit) ```
Ensure that the new arguments are keyword only: ```suggestion def handle_word( self, word, *, safe_input, trim_url_limit=None, nofollow=False, autoescape=False, ): ```
I updated variable names. > and I would also remove unnecessary blank lines I don't see any unnecessary blank lines :thinking:
I'm sorry, the short variables had misled me, in fact there aren't any. Thanks
I know this is just a test, but to increase future readability I would suggest using talking names and not single characters (e.g. `c`, `t`, `x`) to store variables, and I would also remove unnecessary blank lines
```suggestion """The cache instance is different for each thread.""" ```
`FetchFromCacheMiddleware` and `UpdateCacheMiddleware` don't use `default` cache by default. We should override `CACHE_MIDDLEWARE_ALIAS` to make sure they will use the same cache as before. We can do this in a separate commit. For example: ```diff diff --git a/tests/cache/tests.py b/tests/cache/tests.py index 29e527d4e6..13ff0a45aa 100644 --- a/tests/cache/tests.py +++ b/tests/cache/tests.py @@ -994,9 +994,9 @@ class BaseCacheTests: self.assertEqual(caches['custom_key'].get('answer2'), 42) self.assertEqual(caches['custom_key2'].get('answer2'), 42) + @override_settings(CACHE_MIDDLEWARE_ALIAS=DEFAULT_CACHE_ALIAS) def test_cache_write_unpicklable_object(self): fetch_middleware = FetchFromCacheMiddleware(empty_response) - fetch_middleware.cache = cache request = self.factory.get('/cache/test') request._cache_update_cache = True @@ -1011,7 +1011,6 @@ class BaseCacheTests: return response update_middleware = UpdateCacheMiddleware(get_response) - update_middleware.cache = cache response = update_middleware(request) get_cache_data = fetch_middleware.process_request(request) ```
I added `supports_select_for_update_with_limit` because this will crash on Oracle.
We don't need to re-instantiate a runner ```suggestion cases = [ (1, 'FailureTestCase'), (1, 'ErrorTestCase'), (0, 'ExpectedFailureTestCase'), (1, 'UnexpectedSuccessTestCase'), ] runner = DiscoverRunner(verbosity=0) for expected_failures, testcase in cases: with self.subTest(testcase=testcase): ```
`captured_stdout()` is unnecessary: ```suggestion suite = runner.build_suite([ f'test_runner_apps.failures.tests_failures.{testcase}', ]) with captured_stderr(): result = runner.run_suite(suite) ```
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
I prefer to have it here, because this way the warning appears on startup. If we do it in `post()`, then the warning will appear only in runtime - when handling request. Better to keep it here and assume that `DELETE` http method is an edge case for `DeleteView` :) P.S. It would be helpful to include actual view class name to the warning message, to make it obvious which view must be updated.
What if a view based on `DeleteView` overrides `delete` method to actually handle requests with HTTP `DELETE` method? For them this warning would be a false positive.
I would prefer `tag=None` because we will be able to pass `None` to get the default value.
Would `tag='label'` be simpler? Also perhaps the docstring could be updated with the new param, since it's not always `<label>` now.
Chop blank line.
Looks like you're missing a `relations` assignment here.
Did you consider? `for column_name, (referenced_column_name, referenced_table_name) in relations.items():` (and similar for sqlite3)
```suggestion # Use XeLaTeX for Unicode support. ```
Is this necessary for every special character? If so, that doesn't seem very nice…
LaTeX has always been tricky! 😄
`DatabaseFailureError` is not declared, it should be a subclass of `AssertionError`.
OK, we can at least simplify `slug2`, e.g.: ```python prepopulated_fields = { 'slug1': ['name', 'pubdate'], 'slug2': ['status'], } ```
We don't need two slugs for a regression test. I would leave only one, e.g. ```suggestion fields = ['name', 'pubdate', 'slug1'] prepopulated_fields = {'slug1': ['name', 'pubdate']} ```
Do we need to be so restrictive? There are many language tags in the [IANA](http://www.iana.org/assignments/language-subtag-registry/language-subtag-registry) registry that don't match this regex, e.g. `i-mingo`, `de-CH-1996`, `de-1996`, or `kl-tunumiit`.
Indeed, we do not need to be so specific. The downside I see when being permissive is a bit more computation by going more often in `get_supported_language_variant` and possible `get_supported_language_variant` lru cache exhaustion. But I don't see a nice alternative.
My pleasure :)
@sdil Thanks for checking :+1:
```suggestion 'name_local': 'Melayu', ```
Thanks for confirmation.
I found sources that claim that it's Sunday :thinking: : - https://www.timeanddate.com/calendar/?year=2021&country=69 - https://en.wikipedia.org/wiki/Names_of_the_days_of_the_week#Days_numbered_from_Sunday
@sdil Can you take a look? Thanks!
We don't need to check `sys.platform` because `os.chmod()` will be ignored on Windows.
I would rename it to `kwargs` ```suggestion kwargs = {} ```
Do we need to check a `current_mask`? This code is reachable only when `umask` is set. ```suggestion kwargs['umask'] = umask ```
```suggestion @unittest.skipIf(sys.platform == 'win32', 'Windows only partially supports umasks and chmod.') ```
Use `PY39` instead: ```suggestion if umask and PY39: ```
~~Should we check `posix` instead?~~ ```suggestion if sys.platform != 'win32': ```
I guess we could `.pop('to', None)` instead to avoid the dual lookup? ```suggestion if field.remote_field and field.remote_field.model: deconstruction[2].pop('to', None) ```
```suggestion self.assertFormsetError(response, 'formset', 0, 'field', 'invalid value') ```
```suggestion self.assertFormError(response, 'form', 'field', 'invalid value') ```
What do you think about using an [opener](https://docs.python.org/3/library/urllib.request.html#urllib.request.build_opener) instead? For example: ```python the_path = os.path.join(tempdir, filename) opener = build_opener() opener.addheaders = [('User-agent', 'Django/%s' % get_version())] try: with opener.open(url) as source, open(the_path, 'wb') as target: headers = source.info() target.write(source.read()) except OSError as e: ... ```
This can be moved outside of `try...except...`.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Do we need an inner import? `from . import urls` should work fine.
Reverted to `django.__version__`, sorry.
I would use `get_version()` instead.
```suggestion # Q objects. ```
Use single quotes and add trailing commas, ```suggestion get_object_or_404( Article, Q(title__startswith='Run') | Q(title__startswith='Walk'), authors__name__contains='Brave', ), article, ```
```suggestion get_list_or_404( Article, Q(title__startswith='Run') | Q(title__startswith='Walk'), authors__name='Patsy', ), [article], ```
Yes, `override_settings_tags()` should no longer be necessary. Please change it to the `override_settings()`.
I moved this test to the `tests/messages_tests/tests.py`.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
In the end the algorithm below that generates `change_map` has a single requirement with regards to alias; the initial alias must be shared. I think it would be great if we could reuse `bump_prefix`'s usage of `change_aliases` while making sure that this particular initial alias (`self.get_initial_alias()`) is not _bumped_.
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
```suggestion # If keys and values of change_map were to intersect, an alias might be # updated twice (e.g. T4 -> T5, T5 -> T6, so also T4 -> T6) depending # on their order in change_map. ```
Please revert this unrelated change.
Please revert this unrelated change.
This unfortunately won't work if the subquery refers to any outer references as these must be included in the group by clause.
I'd prefer both to support \d -- but no hard feelings.
The main difference is that `integer_validator` is not used internally. `int_list_validator` is used in (deprecated) `CommaSeparatedIntegerField` and it's recommended as a validator for `CharField` that can be used instead. Unfortunately, values are not cast to `int()`, so non-ASCII digits can cause issues. We can change both :thinking:
@apollo13 What do you think? We can change both or neither.
This is because `\w` already includes `\d`; I wonder if we should switch that to `[a-zA-Z0-9_-]` though since charsets would probably be ASCII, can be done in another commit though
Given that `integer_validator` stays at `\d` I wonder if this one shouldn't stay with `\d` as well. Semantically there doesn't seem much of a diff to me between a single integer and a list of integers that would explain the difference in the regex.
TIL that character classes also work inside `[]` :D
Do we want to capture bad values early in the regex or leave it until later when constructing a `datetime` object as we currently do? ```suggestion __D = r'(?P<day>0[1-9]|[12][0-9]|3[01])' __D2 = r'(?P<day> [1-9]|[12][0-9]|3[01])' ``` Is is valid for `__D2`, i.e. `ASCTIME_DATE`, to contain a zero-padded day? (Given it's looking for space-padded.)
Same here? ```suggestion __T = r'(?P<hour>[01][0-9]|2[0-3]):(?P<min>[0-5][0-9]):(?P<sec>[0-5][0-9])' ``` Maybe this is a bad idea because of leap seconds 🤷🏻‍♂️
OK, will revert :+1:
> This is because `\w` already includes `\d`; Yes, exactly. > I wonder if we should switch that to `[a-zA-Z0-9_-]` though since charsets would probably be ASCII, can be done in another commit though Yes, can be done as a separate cleanup.
I tried to use a generated condition the `WHERE` clause and it works fine, so IMO we can safely assume that it's an Oracle caveat :smile:
I decided to fix `quote_value()` anyway, in order not to mask the original exception: ``` ORA-00904: "SDO_EQUAL": invalid identifier ``` with ``` ORA-00907: missing right parenthesis ```
Can we check that the constraint actually exists? ```python with connection.cursor() as cursor: constraints = connection.introspection.get_constraints( cursor, Neighborhood._meta.db_table, ) self.assertIn(constraint_name, constraints) ```
I think that only applies to `SDO_FILTER` but I never recall seeing operators being used in constraints.
I would use kwargs ```suggestion check=models.Q(geom__within=poly), ```
```suggestion poly = Polygon(((0, 0), (0, 1), (1, 1), (1, 0), (0, 0))) ```
Good catch, I think it might be worth doing and testing for yes.
This could be a little more compact: ```suggestion contents = bytearray() with open(origin.name, 'rb', buffering=0) as fp: while data := fp.read(65536): contents += data return contents.decode(self.engine.file_charset) ```
This is worrying :thinking:
Please revert all unrelated changes from single to double quotes.
We should be able to iterate now though `state.items()` directly without making a copy because state is no longer being mutated in the body of the loop.
I learned a bit from this about memoryviews. Thank you! It might not be worth it, since it's premature optimization, but if you are in the mood, here are a few ideas: 1. Assign the copied bytes to a local variable list and only add them to the state if the list is non-empty. This saves a dictionary entry if no memoryviews exist, and it saves a hash lookup into the state for each memoryview (when appending to the list). 2. Pop entries from the state after creating the local variable list. This would allow iterating over state's items without copying them into a list.
What do you think about using the same conditions as in `ModelAdmin`? https://github.com/django/django/blob/97e9a84d2746f76a635455c13bd512ea408755ac/django/contrib/admin/options.py#L1035 For example: ```suggestion has_quotes = relative_name.startswith(('"', "'")) and relative_name[0] == relative_name[-1] ```
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
Yes... our hope this was just the one version proved wrong.
This was the _Right Fix™_ last time I looked into this issue. Typically I no longer see this locally... — I shall try to reproduce, but, provisionally, should be good.
There is no need to simplify paths for private APIs that we will never use in migrations. Please revert changes to the `TemporalSubtraction`, `DurationExpression`, `CombinedExpression`, `Expression`, `SQLiteNumericMixin`, `ResolvedOuterRef`, `ExpressionList`, `Col`, `Ref`, etc.
`ExpressionList` is a private API, you will not find it in docs. `Expression` is not private, but it's not usable on its own, you need to create a subclass.
We should have both versions covered by tests, so I moved test methods with `opclasses` to the new class `ExclusionConstraintOpclassesDepracationTests`.
This variable looks unnecessary.
```suggestion cursor.execute('DELETE FROM %s WHERE %s < %%s' % ( ```
```suggestion return f'SELECT {cache_key} FROM %s ORDER BY {cache_key} LIMIT 1 OFFSET %%s' ```
There is not need to wrap `CursorWrapper.execute`, we should be able to use `CaptureQueriesContext()`, e.g. ```python def test_has_key_query_columns_quoted(self): with CaptureQueriesContext(connection) as captured_queries: cache.has_key('key') self.assertEqual(len(captured_queries), 1) sql = captured_queries[0]['sql'] # Column names are quoted. self.assertIn(connection.ops.quote_name('expires'), sql) self.assertIn(connection.ops.quote_name('cache_key'), sql) ``` There is also no need to check a table name because it contains spaces, so it's already tested.
We don't need a separate test, I would move assertions to the `test_cull_count_queries` renamed to `test_cull_queries`. For example: ```diff diff --git a/tests/cache/tests.py b/tests/cache/tests.py index ddfe9ddfe6..9a67161225 100644 --- a/tests/cache/tests.py +++ b/tests/cache/tests.py @@ -1113,7 +1113,7 @@ class DBCacheTests(BaseCacheTests, TransactionTestCase): with self.assertNumQueries(1): cache.delete_many(['a', 'b', 'c']) - def test_cull_count_queries(self): + def test_cull_queries(self): old_max_entries = cache._max_entries # Force _cull to delete on first cached record. cache._max_entries = -1 @@ -1124,6 +1124,13 @@ class DBCacheTests(BaseCacheTests, TransactionTestCase): cache._max_entries = old_max_entries num_count_queries = sum('COUNT' in query['sql'] for query in captured_queries) self.assertEqual(num_count_queries, 1) + # Column names are quoted. + for query in captured_queries: + sql = query['sql'] + if 'expires' in sql: + self.assertIn(connection.ops.quote_name('expires'), sql) + if 'cache_key' in sql: + self.assertIn(connection.ops.quote_name('expires'), sql) def test_delete_cursor_rowcount(self): """ ```
Hah. Had the same thought before I got here. See the caveats mentioned above.
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
No, what I'm saying is that the optimisation you are referring to is currently limited in scope. - https://docs.python.org/dev/whatsnew/3.11.html#optimizations - https://bugs.python.org/issue28307 Currently it supports `%a`, `%r`, and `%s` only. (python/cpython#5012). Support for numeric format types, e.g. `%d`, is still unmerged. (python/cpython#26160) And even if that does get merged, there are a [bunch of caveats](https://bugs.python.org/msg393740).
> I think this isn't a great trade-off to make, the special branch for "is the length exactlyt the same" will cost more than it saves across a range of different input string types. Only a few will match it. Yeah, I wondered whether the exact length check might be detrimental. > Regardless this is a rarely used DB function, this is too much time spent optimizing it already :) 😄 Yup. Happy with your solution.
Sure, perhaps `ValueError` is better. I think PostgreSQL does the nice thing here - silently returning the value unchanged is ugly. Given this is our own implementation, having a third way - returning `NULL` - isn't great. We should align to one of the other two behaviours, and raising an error seems best.
I'm not sure this is really worth it. Perhaps we can just add `step = list.append` to each of the four aggregates below and make them inherit from `list` directly? It might be clearer keeping `step` and `finalize` together, but I'm easy either way.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
Close, but not quite! 😉 ```suggestion def _sqlite_log(base, x): if base is None or x is None: return None # Arguments reversed to match SQL standard. return log(x, base) ```
This is not fixed.
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
```suggestion # typecast_timestamp() returns a date or a datetime without timezone. ```
I'm not sure about raising these exceptions (here, in `_sqlite_datetime_trunc()` and in`_sqlite_datetime_trunc()`), user will get rather unhelpful `OperationalError`: ``` django.db.utils.OperationalError: user-defined function raised exception ``` and we don't do this on other backends.
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
Error is raised only on PostreSQL. On Oracle and MySQL we simply return the same date. Even if we want to raise an exception on SQLite, `NotImplementedError` is probably not the best choice. It's not sth that will or may be implemented in the feature. I'd use `ValueError` as we do in similar cases.
This is not changed.
Various things that can be improved here: - Use f-strings for a speed boost over %-formatting - could add up significantly - Avoid unnecessary `elif`s. - Raise `NotImplementedError` in the default case for unknown lookups. ```suggestion if lookup_type == 'hour': return f'{dt.hour:02d}:00:00' if lookup_type == 'minute': return f'{dt.hour:02d}:{dt.minute:02d}:00' if lookup_type == 'second': return f'{dt.hour:02d}:{dt.minute:02d}:{dt.second:02d}' raise NotImplementedError(f'Unsupported lookup type: {lookup_type}') ``` Alternatively it is possible to do the following, but it is likely to be significantly slower as I think it delegates to `.strftime()` under the hood: ```suggestion if lookup_type == 'hour': return f'{dt:%H}:00:00' if lookup_type == 'minute': return f'{dt:%H:%M}:00' if lookup_type == 'second': return f'{dt:%H:%M:%S}' raise NotImplementedError(f'Unsupported lookup type: {lookup_type}') ```
We can remove the `elif`s and `else here: ```suggestion if lookup_type == 'week_day': return (dt.isoweekday() % 7) + 1 if lookup_type == 'iso_week_day': return dt.isoweekday() if lookup_type == 'week': return dt.isocalendar()[1] if lookup_type == 'quarter': return ceil(dt.month / 3) if lookup_type == 'iso_year': return dt.isocalendar()[0] return getattr(dt, lookup_type) ``` We'll have to wait until we're Python 3.9+ only to use `.week` and `.year` on the result of `dt.isocalendar()`.
Change the following: ```python import hashlib ``` Into: ```python from hashlib import sha1, sha224, sha256, sha384, sha512 ``` Then: ```suggestion return sha1(text.encode()).hexdigest() ``` And for `_sqlite_sha224()`, etc.
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Various things that can be improved here: - Avoid unnecessary elifs. - Raise NotImplementedError in the default case for unknown operators. ```suggestion if operator == '+': # typecast_timestamp() returns a date or a datetime without timezone. # It will be formatted as "%Y-%m-%d" or "%Y-%m-%d %H:%M:%S[.%f]" return str(real_lhs + real_rhs) if operator == '-': return str(real_lhs - real_rhs) if operator == '*': return real_lhs * real_rhs if operator == '/': return real_lhs / real_rhs raise NotImplementedError(f"Unsupported operator: {operator}") ```
This could be simplified to match the implementation in `_sqlite_datetime_extract()`: ```suggestion month_in_quarter = ceil(dt.month / 3) ```
This could be simplified to match the implementation in `_sqlite_datetime_extract()`: ```suggestion month_in_quarter = ceil(dt.month / 3) ```
`assertFalse()` matches anything falsy. If you want to check for `False` only you need to use `assertIs(…, False)`.
But `any()` always returns a bool? https://docs.python.org/3/library/functions.html#any
why not `assertFalse` ? ```suggestion self.assertFalse(any( 'CREATE TABLE' in query['sql'] for query in ctx.captured_queries ) self.assertFalse(any( 'DROP TABLE' in query['sql'] for query in ctx.captured_queries )) ```
I moved this to a separate PR, see #15426.
I moved this an a similar check for forms to the separate PR, see #15425.
I moved this to a separate PR, see #15426.
I moved this to a separate PR, see #15426.
```suggestion # RemovedInDjango50Warning ```
I moved this to a separate PR, see #15426.
I fixed this in a separate PR, see #15428.
Thanks :+1: , IMO a separate ticket is not necessary, we can `Refs #33348 -- ...`.
Can we deprecate passing `None` in `errors` in a separate PR? and do this in advance. There is already a lot of changes in this patch, that should make it more readable and easier to review. I can try to refactor this out if you don't have time to keep working on this.
I'm not sure about these changes, they seem unnecessary. We can raise a deprecation warning when `None` is passed in `errors` even without them.
```suggestion raise TypeError("You must use field=None when using form_index=None") ```
I don't think it needs any more logic.
You can reuse `empty_view`: ```suggestion path('hello/', empty_view, 'name') ```
IMO hint is not necessary, we also don't allow for calling functions in f-strings: ```suggestion f'kwargs argument must be a dict, but got {kwargs.__class__.__name__}.' ```
`editor` is not required to create an instance of `DurationField` or to call `column_classes()` that's why I kept these out of the context manager.
```suggestion self.assertEqual( columns['duration'][0], connection.features.introspected_field_types['DurationField'], ) ```
Do we need to catch `AttributeError`? It looks unnecessary since d2a26c1a90e837777dabdf3d67ceec4d2a70fb86 :thinking:
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
Just checking - this doesn't account for accidentally passing in a _str_ by say, omitting the comma of a _tuple_. Is an error suitably raised earlier/later by it being a `tuple_settings`? (I may have asked this on the previous PR, I just cannot recall)
Maybe `map()`: ```suggestion fallback_keys=map(_cookie_signer_key, settings.SECRET_KEY_FALLBACKS), ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion return TimestampSigner(key, salt=salt, fallback_keys=fallback_keys).unsign_object( s, serializer=serializer, max_age=max_age, ) ```
Use `assertIs(…, True/False)` for testing boolean values, rather than `assertTrue()` and `assertFalse()` as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion self.assertIs(p1.check_token(user, tk), True) self.assertIs(p2.check_token(user, tk), True) ```
```suggestion def loads( s, key=None, salt='django.core.signing', serializer=JSONSerializer, max_age=None, fallback_keys=None, ): ```
```suggestion self.assertIs(p2.check_token(user, tk), True) ```
```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
```suggestion self.assertIs(p2.check_token(user, tk), False) ```
```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
Let's be consistent, if the previous test we have `newsecret`: ```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
This is unrelated, please revert.
```suggestion # SECRET_KEYS items may be str or bytes. return b'django.http.cookies' + force_bytes(key) ```
It's more readable without the ternary, IMO: ```suggestion if self._secret_fallbacks is None: return settings.SECRET_KEY_FALLBACKS return self._secret_fallbacks ```
I would use encapsulation to avoid list/tuple issues: ```suggestion for secret in [self.secret, *self.secret_fallbacks]: ```
Good catch :dart: I didn't notice this :eagle: Definitely `SECRET_KEY_FALLBACKS`.
> Just checking - this doesn't account for accidentally passing in a _str_ by say, omitting the comma of a _tuple_. Is an error suitably raised earlier/later by it being a `tuple_settings`? Yes exactly, `tuple_settings` protects from passing a string.
```suggestion # List of secret keys used to verify the validity of signatures. This allows # secret key rotation. ```
Missed this one.
A None check would be required here (and not just look for truthiness of self._secret_fallbacks). I.e. using `SECRET_KEY_FALLBACKS = ['a']` and setting `generator.secret_fallbacks = []` would make the getter `generator.secret_fallbacks` return `['a']` and not `[]`.
For all these tests, I'd move `tk1 = p1.make_token(user)` up before instantiating `p2`, so that `p1` drops out of scope. I suspect @felixxm would like you to remove (or at least reduce) the whitespace.
I would move it right before the `with self.assertRaisesMessage(ValidationError, msg):`
```suggestion self.assertEqual([book.rating_count for book in qs], [1]) ```
I would move it to a separate test method because it's full result, not empty.
Is calling `c_uint()` redundant as well? https://github.com/django/django/blob/b0d16d0129b7cc5978a8d55d2331a34cb369e6c7/django/contrib/gis/geos/polygon.py#L93
Good catch :+1:
Can we just define `holes_param = (GEOM…`? It seems to me that the temporary `holes` variable is unneeded now.
The second part about `replaces` is always true. I'm not sure if adding `and/or` will make it clearer :thinking:, maybe ``` Cannot use --prune because the following squashed migrations have their 'replaces' attributes and may not be recorded as applied: migrations.0001_squashed_0002 Re-run 'manage.py migrate' if they are not marked as applied, and remove 'replaces' attributes in their Migration classes. ```
```suggestion if squashed_migrations_with_deleted_replaced_migrations: msg = ( " Pruning cannot take place until the following squashed " "migrations are recorded as applied (re-run 'manage.py migrate') " "and have their replaces attribute removed:" ) self.stdout.write(msg, self.style.NOTICE) for migration_to_warn in squashed_migrations_with_deleted_replaced_migrations: app, name = migration_to_warn self.stdout.write(f' {app}.{name}') else: to_prune = sorted(migration for migration in to_prune if migration[0] == app_label) if to_prune: for migration in to_prune: app, name = migration if self.verbosity > 0: self.stdout.write(f' Pruning {app}.{name}', ending='') executor.recorder.delete(app, name) if self.verbosity > 0: self.stdout.write(self.style.SUCCESS(' OK')) elif self.verbosity > 0: self.stdout.write(' No migrations to prune.') ```
Quotes should be consistent in a single string: ```suggestion " Pruning cannot take place until the following squashed " "migrations are recorded as applied (re-run 'manage.py migrate') " "and have their replaces attribute removed:" ```
This should be display when `verbosity > 0`.
```suggestion squashed_migrations_with_deleted_replaced_migrations = [ migration_key for migration_key, migration_obj in executor.loader.replacements.items() if any(replaced in to_prune for replaced in migration_obj.replaces) ] ```
`Delete` sounds better to me, because we delete rows from the `django_migrations` table. Maybe: ```suggestion help='Deletes nonexistent migrations from the django_migrations table.', ```
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
IMO migrations should not be applied when `--prune` is used (as with `--plan`). For example: ```bash $ python manage.py migrate --prune ``` applies all migrations and raises `CommandError: Migrations can be pruned only when an app is specified.` at the end.
I would add `OK`: ```suggestion executor.recorder.delete(app, name) self.stdout.write(self.style.SUCCESS(' OK')) ```
I think it's preferred to wrap this at 79 chars: ``` f'{self.display_name} {min_db_version} or later is required ' f'(found {db_version}).' ```
I would add: `return self.features.minimum_database_version is None or ....` so that this method doesn't crash if a minimum version isn't specified.
Perhaps this is simpler: ``` from textwrap import wrap return tuple(wrap(str(self.pg_version), 2)) ```
`return self.get_database_version() >= self.features.minimum_database_version`
add docstring: Return a tuple of the database's version.
My intuition would be to make this raise `NotImplemented` instead.
```suggestion """ Return a tuple of the database's version. E.g. for pg_version 120004, return (12, 4). """ return divmod(self.pg_version, 10000) ```
This is always truthy: ```suggestion mocked_check_database_version_supported.assert_called_once() ```
Add release notes.
Add release notes.
`0` is unnecessary: ```suggestion return (10, 2) else: return (5, 7) ```
```suggestion minimum_database_version = (19,) ```
I would use this style to save some lines: ``` msg = '....' with self.assertRaisesMessage(NotSupportedError, msg): ```
"of the" (though maybe it's redundant with the docstring if we add one to the base class)... in that case, the "E.g." still seems helpful.
```suggestion minimum_database_version = (10,) ```
I find it problematic we’d make it possible to override the `aria-describedby` for two reasons: - If the `help_text` is used, then I don’t think it would be appropriate for its content to be missing from the input’s description as computed from `aria-describedby`. - Assuming we implement the other fix for #32819 by adding the field’s error(s) in `aria-describedby`, it would also be inappropriate for that to be missing because of a customization. In both cases I guess this would be ok if the customization included the ids for the help text and error message when needed, but that doesn’t seem very convenient. --- So we could make it possible to customize `aria-describedby`, but if we did in my opinion it should be in addition to Django automatically populating it for `help_text` and field errors: ```suggestion if self.field.help_text and id_for_label: helptext_id = '%s_helptext' % id_for_label if 'aria-describedby' in widget.attrs: attrs['aria-describedby'] = f"{helptext_id} {attrs['aria-describedby']}" else: attrs['aria-describedby'] = helptext_id ``` I’m not too sold on this either because then we’re having to assume the order of the different descriptions. It gets more problematic if we had errors in there too: ```python attrs['aria-describedby'] = f"{helptext_id} {errors_id} {attrs['aria-describedby']}" ```
This assertions are now redundant with `test_help_text_aria_describedby()` and can be removed.
We use `assertHTMLEqual()` so newlines don't matter, I would use single quotes: ```python self.assertHTMLEqual( p.as_table(), '<tr><th><label for="id_username">Username:</label></th><td>' '<input type="text" name="username" maxlength="10" required ' 'aria-describedby="id_username_helptext" id="id_username">' ... ) ```
Can we move it to a separate test method? We already have so many HTML assertions here.
Happy New Year :fireworks:
Do we need `kwargs`? ```suggestion def __init__(self, using, origin=None): ```
:thinking: ```suggestion collector = Collector(using=using, origin=self) ```
:thinking: ```suggestion collector = Collector(using=del_query.db, origin=self) ```
```suggestion def test_migrate_skips_schema_creation(self, mocked_has_table): ```
`targets` is an empty list when `MIGRATE` is `False`: ```suggestion executor.migrate([], plan=[]) ```
This is required only for indexes defined in `Meta.indexes`. Should we pass list of pure fields names in `remove_index()` instead? For example: ```python def remove_index(self, model, index): self._create_missing_fk_index( model, fields=[field_name for field_name, _ in index.fields_orders], expressions=index.expressions, ) super().remove_index(model, index) ```
`meta` is used only here so a temporary variable is unnecessary: ```suggestion first_field = model._meta.get_field(first_field_name) ```
I moved adding this hook to a separate PR, see #16048.
I moved extra tests to a separate PR, see #16049.
This formatting change is not related with a bug fix, please revert.
Do we need this? if so, it is not tested.
What about indexes and constraints based on `expressions`? For example: ```python Index(F('author'), F('title'), name='author_title_index') ```
If I understand correctly, when the first field is indexed in descending order (like `-fieldname`) and the DB supports it, we will return `None` for this function. 1/ MySQL doesn't drop the implicit FK index when another index has as first field the FK in descending order, is that correct? 2/ The naming of the function is not _entirely_ accurate with respect to the behaviour, since we'll return None even though one would expect to get the first field name.
`fields` is always specified by callers, no need to have a default value
If that is indeed a bug, maybe we should have a test that could catch it 🤔 A test where we should create the missing index even if an index with an expression exists (but with a first field name that doesn't match the dropped index)
`responsive.css` uses only 1024 and 767 so there is not need to check other sizes, it's also better to assert separately: ```suggestion title_field_div = self.selenium.find_element(By.CLASS_NAME, 'field-title') current_size = self.selenium.get_window_size() try: self.selenium.set_window_size(1024, 768) self.assertIs(title_field_div.is_displayed(), False) self.selenium.set_window_size(767, 575) self.assertIs(title_field_div.is_displayed(), False) finally: self.selenium.set_window_size(current_size['width'], current_size['height']) ```
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Why this variable is called `unnamed_...` since it also stores named group? :thinking:
Such an extensive docstring is not necessary, IMO.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
We don't need to mock `django.db.migrations.questioner.sys.stdout` anymore.
Management command use `OutputWrapper()`, so we need to do the same here.
you could probably use the same pattern here and deduplicate this message.
I moved this to the `test()` method to avoid code duplication.
I moved renaming `_assert_template_used()` to a separate commit.
What about ```python def can_reduce_through(self, operation, app_label): return not operation.references_model(self.name, app_label) def reduce(self, operation, app_label): return ( super().reduce(operation, app_label) or self.can_reduce_through(self, operation, app_label) ) ```
Couldn't this possibly cause issues if `operation` is not a `ModelOperation` and happens to have a matching `name_lower` (e.g. `FieldOperation`) Pretty sure we'll want something along the lines of ```python def can_reduce_through(self, operation, app_label): return ( super().can_reduce_through(operation, app_label) or ( isinstance(operation, AlterTogetherOptionOperation) and type(operation) is not type(self) ) )
This change is backward incompatible. On the other hand, `inlines` should be overwritten, not modified, by subclasses as explicitly stated in docs. So theoretically it won't affect anyone. I'm torn. If we want to move it forward we should do the same with `actions`.
No indentation is needed: ```suggestion "Optimizing from %d operations to %d operations." % ```
This file is not formatted with `black` because it contains a syntax error :disappointed: I'm not sure how to fix this :thinking:
I don't think there is much we can do, and `squashmigrations` has the same issue.
```suggestion # Optimize migration. ```
That's not true, `return` is to avoid setting new migrations.
Do you think else statement is required in the following example? ```py def greet(): condition = False if condition: return "Hi" else: return "Hello" ```
I would use f-strings for these messages.
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
```suggestion # Find migration. ```
```suggestion f"App '{app_label}' does not have migrations." ```
There is no need to resolve replaced/applied migrations so I would pass `None` instead of the default connection: ```suggestion loader = MigrationLoader(None) ```
```suggestion sys.exit(1) ```
We need to `run_formatters()` on new files, see d113b5a837f726d1c638d76c4e88445e6cd59fd5.
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
```suggestion # Validate app_label. ```
You added the return statement to the above if the condition which means no need else statement. You should remove it to make it easier to read.
I added a small hook for this.
`'utf-8'` is the default. We can remove it.
In most of cases names won't contain multibyte chars, so it should be worth avoiding multiple encoding and slicing, e.g.: ```python if len(table_name.encode()) == len(table_name): table_name = table_name[:other_length] else: # Shorten table name accounting for multibyte characters. while len(table_name.encode()) > other_length: table_name = table_name[:-1] ```
This is not friendly for 3rd-party backends. We should use `connection.ops.max_name_length()` and generate names that are too long.
We do this twice, so I'd move `joined_column_names` above the first `index_name` creation.
Do we have to keep cutting to `other_length`? ```suggestion joined_column_names, ```
We don't need this skip.
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
```suggestion Prefetch('house', queryset=House.objects.only('address')), )), ```
```suggestion house.rooms.first().house.address ```
This line can be done once at the start of the loop, rather than before the loop and then at the end of each iteration.
Yes, `nonlocal` is necessary.
`itertools` looks unnecessary :thinking: I would use `int` variables and alphabetized hooks, e.g. ```python branch_1_call_counter = 0 branch_2_call_counter = 0 leaf_1_call_counter = 0 leaf_2_call_counter = 0 leaf_3_call_counter = 0 def leaf_1(): nonlocal leaf_1_call_counter leaf_1_call_counter += 1 def leaf_2(): nonlocal leaf_2_call_counter leaf_2_call_counter += 1 def leaf_3(): nonlocal leaf_3_call_counter leaf_3_call_counter += 1 def branch_1(): nonlocal branch_1_call_counter branch_1_call_counter += 1 transaction.on_commit(branch_2) transaction.on_commit(leaf_3) def branch_2(): nonlocal branch_2_call_counter branch_2_call_counter += 1 transaction.on_commit(leaf_1) transaction.on_commit(leaf_2) ```
This `atomic()` is not needed. ```suggestion transaction.on_commit(branch_1) ```
I'd would directly compare `callbacks`: ```suggestion self.assertEqual(callbacks, [branch_1, branch_2, leaf_3, leaf_1, leaf_2]) ```
```suggestion A visualization of the callback tree tested. Each node is expected to be visited only once: └─branch_1 ├─branch_2 │ ├─leaf_1 │ └─leaf_2 └─leaf_3 ```
Why double-underscore? I would also rename `func` to `callback`: ```suggestion for _, callback in connections[using].run_on_commit[start_count:]: callbacks.append(callback) if execute: callback() ```
IMO we should add a new hook, e.g. `get_caller(resolver_match)` with the logic from `technical_404_response`: https://github.com/django/django/blob/c67e1cf44f17c36139e25b1eae92216cb8baad77/django/views/debug.py#L539-L556 and use it in both views. For example: ```python def get_caller(resolver_match): obj = resolver_match.func caller = '' if hasattr(obj, 'view_class'): caller = obj.view_class elif hasattr(obj, '__name__'): caller = obj.__name__ elif hasattr(obj, '__class__') and hasattr(obj.__class__, '__name__'): caller = obj.__class__.__name__ if hasattr(obj, '__module__'): module = obj.__module__ caller = '%s.%s' % (module, caller) return caller ```
```suggestion caller = f'{obj.__module__}.{caller}' ```
I added a short docstring but without `is provided by developers ...`, this is not a strong argument, a lot of things are provided by developers but we don't mark them as safe. I'd say that's how it is, the decision was made a lot time ago :shrug:
No harm. Not really. Just an observation that this is a change in behaviour.
I don't think it makes a difference here, but the other tests use `html=True` ```suggestion self.assertContains(response, "<td>view_tests.views.technical404</td>", status_code=404, html=True) ```
I don't see much value in check that bad representation doesn't exists. I moved the entire row to a single assertion.
Can we drop this change, using `silence_checks` with `override_settings` just on specific tests? (We're not removing the current approach no?) — It leads to a lot of noise on the PR. 🤔
```suggestion def remove_non_capturing_groups(pattern): ```
```suggestion 1. (?P<a>\w+)/b/(?:\w+)c(?:\w+) => (?P<a>\\w+)/b/c ```
```suggestion 3. ^a(?:\w+)/b(?:\w+) => ^a/b ```
`[None:start]` works the same as `[:start]`: ```suggestion final_pattern += pattern[prev_end:start] ```
```suggestion # Match the beginning of a named, unnamed, or non-capturing groups. ```
```suggestion 2. ^(?:\w+(?:\w+))a => ^a ```
Arh, nothing to do with this PR but the lack of a label for each `<select>` is a problem 🙈. This is worth opening a bug ticket if anyone is up for it.
```suggestion form.render(), '<div><label for="id_field">Field:</label>' '<input id="id_field" name="field" required type="checkbox"></div>', ```
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
I know that `self._check_fk_val()` is called in `remove()` and `set()` because they use other methods, however, I'd call explicitly to avoid unnecessary work.
Why this error is raised? This should return an empty list without raising an exception.
A temporary variable is not necessary: ```suggestion # Remove all non-printable characters. file_name = ''.join([char for char in file_name if char.isprintable()]) ``` Also, it should be faster to check with `string.printable`: ```python file_name = ''.join([x for x in file_name if x in string.printable]) ``` ``` $ python3 -m timeit 'import random; x = "".join([chr(random.randint(1, 10000)) for _ in range(10000)]); "".join([char for char in x if char.isprintable()])' 50 loops, best of 5: 7.03 msec per loop $ python3 -m timeit 'import random; import string; x = "".join([chr(random.randint(1, 10000)) for _ in range(10000)]); "".join([char for char in x if char in string.printable])' 50 loops, best of 5: 6.76 msec per loop ```
We shouldn't mix file names that are candidates for path traversal with sanitizing non-printable chars. I moved it to a separate test method.
`source_map.css` is missing.
You can move it to the top, because we have an alias.
```suggestion Group(name=str(i)) for i in range(10) ```
😁 ```suggestion while results := list(islice(iterator, chunk_size)): ```
Yes. We already do it in a few places.
I'd raise ``ImproperlyConfigured`` as in other cases: ```suggestion try: import selenium except ImportError as e: raise ImproperlyConfigured(f'Error loading selenium module: {e}') ```
```suggestion if field_name == '_order': field_name = self.options.get('order_with_respect_to', field_name) ```
~Is this only required for the specifics of the test cases, or is it required to satisfy the merging and sorting in `Media` itself? If the former, all well and good, if the latter, would that need to be part of the `Paths as objects` interface contract?~ Oh I guess it's the `and be hashable` part already. My bad, ignore!
The only thing I'd change here is override `SESSION_COOKIE_NAME` to another value to ensure it's used over an hardcoded `'sessionid'` value ```suggestion @override_settings(SESSION_COOKIE_NAME="djangosession") def test_cleanse_session_cookie_value(self): self.client.cookies.load({"djangosession": "should not be displayed"}) response = self.client.get("/raises500/") ``` Also removed the trivial docstring as we usually don't use them if the test is explicit enough (`test_cleanse_session_cookie_value` should already be enough)
Can we move this branch into the `is_sensitive` check above? ``` is_sensitive = ( self.hidden_settings.search(key) or key == settings.SESSION_COOKIE_NAME ) ```
This will completely obscure `HTTP_COOKIE` but I don't think it's a big deal since individual items are still retrievable from `request_COOKIES_items`.
`</textarea><script>alert(1);</script>` appears in multiple places on a debug page, e.g. ![image](https://user-images.githubusercontent.com/2865885/151308176-80843436-86ee-4abb-ab37-fb86e777b47e.png) ![image](https://user-images.githubusercontent.com/2865885/151308204-103f7498-4f84-4a57-81ee-627a7535bff9.png) ![image](https://user-images.githubusercontent.com/2865885/151308332-92977d52-98f3-4729-98a1-f95356b21122.png) so I'd remove `h3` tags from assertions to cover all places.
This docstring is unnecessary, please chop it.
This can be single-lined. ```suggestion '<option value="" selected="">---------</option>', ```
```suggestion '<option value="" selected="">---------</option>', ```
```suggestion '<option value="" selected="">---------</option>', ```
I see no reason to uppercase these variables :thinking:
Why `BORN` is uppercased? :thinking: ```suggestion # Add new Country from the born_country select. ```
This docstring is unnecessary, please chop it.
I'd move it below `test_field_references()`.
Actually, shouldn't this be ```suggestion coalesce.is_summary = summarize ``` Or even ```suggestion coalesce.is_summary = c.is_summary ``` Otherwise, annotations of aggregate functions using `default` will be marked `is_summary` even if they are not used for `.aggregate` and that could cause other problems [if a subquery pushdown must take place](https://github.com/django/django/blob/30a01441347d5a2146af2944b29778fa0834d4be/django/db/models/sql/query.py#L403-L411).
The current development version of Django support Python 3.8+, so this note and workaround are unnecessary.
There is no need to compare generated queries. Please remove it.
```suggestion class TaggedItemWithUUID(models.Model): ```
These notes are unnecessary.
```suggestion class Integration(models.Model): ```
I would assert that querysets return the expected tag. Also, temporary variables are unnecessary. For example: ```python tag = integration.tags.create() self.assertSequenceEqual(TTag.objects.filter(integration=integration), [tag]) self.assertSequenceEqual(TTag.objects.filter(integration__id=integration.id), [tag]) ```
I'm not sure if this is a good solution. For me, the main question is why `self.lhs.output_field` is set to `generic_relations.TIntegration.tags` and not `generic_relations.TIntegration` :thinking:
I've changed to a non-lambda version.
Are both of these going through the `__radd__` path? At a glance, I'd have _guessed_ that both are using `__add__` because the LHS is a `SimpleLazyObject` which now has that magic method? I could be wrong, it has been a _long_ time since I filed the ticket, so I may be misremembering.
This is covered by other tests. We can remove it.
Test and test class names should describe shortly what we want to test. Phrases `demo` or `example` are not appropriate.
I'd rewrite this to something along the lines of: ``` new_path, args, captured_kwargs = match kwargs = {**captured_kwargs, **self.default_kwargs) ```
Ah yeah, I think I missed the `not` in the if.
This and the below line can be simply written as `sub_match_extra_dict = {**self.default_kwargs, **sub_match.extra_kwargs}`.
Do we need to do this? This is untested. Also, as far as I'm aware `default_kwargs` should take precedence: ```suggestion sub_match_extra_dict = { **sub_match.extra_kwargs, **self.default_kwargs, } ```
Can you changing this to: ``` {"slug": "default-slug"}, # Ensure that kwargs override extra ``` so we know that reversing this works properly (this also requires you to change `match.kwargs` to `match.captured_kwargs` above I think)
Why? you can simply pass `sub_match.capture_kwargs` below
I think this can be rewritten ala: ``` for k,v in defaults.items(): … if kwargs..get(k,v) != v: break else: continue ```
Ahh I see, ok let's go with this approach for now. There's likely a good way to reconcile the multiple boolean expression handling we have for Oracle across the ORM but this simple change should go a long way.
I think we should adapt `select_format` in this case to handle `''` to encapsulate the Oracle logic in one location. It's not clear _why_ `select_format` is called here though as we're directly filtering against the expression and not selecting it? https://github.com/django/django/blob/25514b604a64686ba603bf10a8a63390dc38b79d/tests/expressions/tests.py#L1916-L1918
I'd _guess_ it's the `C:\Users` part being incorrectly escaped: ``` In [1]: print("C:\Users") print("C:\Users") ^ SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \UXXXXXXXX escape In [2]: print(r"C:\Users") C:\Users ```
```suggestion black_path = shutil.which("black") if black_path: subprocess.run([black_path, "--", *written_files], capture_output=True) ```
```suggestion subprocess.run(["black", "--", *written_files], capture_output=True) ``` so that filenames that look like command line options don't break the command.
We should also handle `--merge` which creates new files, see `handle_merge()`.
Yeah I thought that might be the case, but thought it worth pointing out due to the sheer destructiveness of this specific fix in `.5` FWIW it doesn't look _entirely_ without precedent to use the patch releases (though it is _rare_), insofar as `supports_aggregate_filter_clause` is pinned to a minimum of `3.30.1` where the actual functionality was added in `3.30.0` but had fixes in the `.1` release by my reading of the release notes.
If the functionality introduced in `3.35.0` is known to be buggy, we would introduce potential data corruption issues if we use `3.35.0` in that flag. Not nice for users :-/ I'm with @kezabelle here.
Ideally we can pin at `3.35` as you've done here, but perhaps we should pin at `3.35.5` because `3.35.1` included bugfixes for that new functionality, and more importantly `3.35.5` has the following fix: > Fix defects in the new ALTER TABLE DROP COLUMN feature that could corrupt the database file Though it unfortunately doesn't specify further, or linked to a ticket/discussion. ([Docs for the entire 3.35 release line, including patch releases](https://www.sqlite.org/releaselog/3_35_5.html))
```suggestion django_location = os.path.dirname(os.path.dirname(django.__file__)) if hasattr(django, "__file__") else "" ```
Not all implementations of Python have even the standard library in files. `os.__file__` may not exist.
We should run it only on Django's test suite: ```suggestion if os.environ.get("RUNNING_DJANGOS_TEST_SUITE") == "true": self.mark_expected_failures_and_skips() ``` Also I'm not sure if it's the right place :thinking: , see #15477.
Maybe we just need to not call `str(alias)` here? If `alias` already works as a key in `connections`, why do we need to change it? That will avoid having to put `str()` calls everywhere.
Ditto regarding `str(alias)`.
This code is unreachable, because `get_test_db_clone_settings()` raises an exception for other start methods. ```suggestion ```
```suggestion raise NotSupportedError( ```
I'm slightly confused that were taking `source_db` from disk here with the same `_worker_id` value as the `worker_db` target. Maybe I'm missing something, but I thought we're trying to make copies for different processes, so the source and target cannot share the same `_worker_id`? 😕
Everywhere else uses an f-string, not sure why this doesn't: ```suggestion f"file:{alias}_{_worker_id}.sqlite3", uri=True ```
Can we use `self.connection.Database` instead? ```suggestion source_db = self.connection.Database.connect(f"file:{alias}_{_worker_id}.sqlite3", uri=True) ```
OK, so `PostgresConfig.ready()` enforces calling `register_type_handlers` that we need for `hstore`. It should also be called when we create a new extension, I'm not sure why it's not called with `spawn` :thinking: .
I would move initialization of these variables to the `ParallelTestSuite.__init_()`.
I'd prefer to use supported methods, in case there are new once in the future: ```suggestion # The current implementation of the parallel test runner requires # multiprocessing to start subprocesses with fork() or spawn(). if multiprocessing.get_start_method() not in {"fork", "spawn"}: ```
Can you reproduce any failure without `modify_settings()`? This test doesn't need anything from `PostgresConfig.ready()` :game_die: :thinking:
We call `get_start_method()` multiple times (one of them in a loop below) in this function. Let's pull it out into a variable as we do elsewhere in this patch: ```python start_method = multiprocessing.get_start_method() ```
This is confusing: ```suggestion connection.settings_dict.update(initial_settings[str(alias)]) if serialized_contents and alias in serialized_contents.keys(): connection._test_serialized_contents = serialized_contents[str(alias)] ``` Can aliases be anything other than `str` type? If so, then perhaps something is wrong elsewhere. It seems to have been done all over this patch. And this is broken anyway because the second line should have been `... str(alias) in ...`. The `.keys()` call is unnecessary as `in` will work on the keys of a dict anyway. ```suggestion connection.settings_dict.update(initial_settings[str(alias)]) if value := serialized_contents.get(str(alias)): connection._test_serialized_contents = value ```
`will re-opened in to ...` should maybe be something like `will re-open in ...`
Ah, that makes a lot of sense. Thanks :)
This should be called on re-wrapped `obj`.
Might be less clunky putting the form in a local variable: ```suggestion if form_obj := context.get(form): continue if not form_obj.is_bound: self.fail( f"{msg_prefix}The form {form_obj!r} is not bound, it will never " f"have any errors." ) ``` `context[form]` is repeated an awful lot further down too. You'll probably want a better name than `form_obj` though... 🤔
Ah, I hadn't looked at #15179 in detail. Even better! 😁
ln1733 looks redundant. `kwargs["to"]` is reassigned on either branch here. 🤔
I'm talking about an example in the same docstring: https://github.com/django/django/blob/1d071ec1aa8fa414bb96b41f7be8a1bd01079815/django/core/signing.py#L20
Of course :facepalm: @2019342a Thanks :+1:
`value = __getattribute__(name)` should work fine. I forgot to change it after adding the `__getattribute__` variable.
Hmm might I also suggest this instead? ```python def __getattribute__(self, name): if name == '_wrapped': return super().__getattribute__(name) value = super().__getattribute__(name) # If attribute is a proxy method, raise an AttributeError to call # __getattr__() and use the wrapped object method. if not getattr(value, "_mask_wrapped", True): raise AttributeError return value __getattr__ = new_method_proxy(getattr) ``` Basically from what I understand, this bug happens on cases where the wrapped objects`getattr` returns a `False` value, not necessarily a value. For example if you returned [1] instead of an empty list, the test would pass. This misses the `AttributeError` bellow. In both cases `if not found or not getattr(value, "_mask_wrapped", True):` and `if not getattr(value, "_mask_wrapped", True):` will return `[]` and go into the condition. Both implementations basically safeguard `_wrapped` to be returned and not go into the loop
We can immediately return a supported language instead of building a temporary list.
```suggestion with translation.override('fr'): self.assertEqual(tpl.render(Context({"s": s})), "nom") ```
Trailing zeros are unnecessary. Also, it'd be more readable to keep MySQL and MariaDB in separate branches, e.g.: ```python if self.connection.mysql_is_mariadb: return self.connection.mysql_version >= (10, 8) return self.connection.mysql_version >= (8, 0, 1) ```
It'd be interesting to see some numbers for doing it this way[^1], as it may be 'good enough' to obviate #14849 entirely, which would be nice from a simplicity point of view. [^1]: and indeed I'll try and check the numbers against my own at some point.
Default is unnecessary: ```suggestion if content_type := self.headers.get("Content-Type"): ```
Hey, what about: ```suggestion kwargs.get("empty_label", _("None")) if db_field.blank else None ```
We don't really need param substitution here ```suggestion sql = "SELECT 1 FROM pragma_compile_options() WHERE compile_options = 'ENABLE_MATH_FUNCTIONS' LIMIT 1" if connection.execute(sql).fetchone() is None: ```
I changed to `sqlite_compileoption_used()`.
Minor but the trailing `.all()` is unnecessary here.
Moving `databases` to the `BaseConnectionHandler` is misleading. I'd revert it.
IMO it's fine.
We can use the `maxsplit` argument: ```python header_value, *_ = split(",", 1) return "https" if header_value.strip() == secure_value else "http" ```
Minor but this could have likely be simplified by using `reduce` to avoid the private `_connector` usage ```python condition = reduce( (Q(app_label=app_label, model__in=models) for app_label, models in needed_models) , operator.or_) ``` In all cases `Q(("app_label", app_label), ("model__in", models), _connector=Q.AND)` can be simplified to `Q(app_label=app_label, model__in=models)` since `_connector` defaults to `Q.AND`.
@charettes Thanks :+1: I removed unnecessary connector, see #15511. As far as I'm aware we now prefer non-kwargs constructions for internal usage, see 9662193aea2ee982bc8e553c62499aca5e606755 and #14699,
The raster tif file we are talking about is https://github.com/django/django/blob/main/tests/gis_tests/data/rasters/raster.tif. There are no `.aux.xml` file. However, when reading the file with GIMP, the nodata tag (`0xA481`) shows a value of 15. So I'm still suspecting something is wrong with GDAL > 3.4.1.
this is probably the same as https://github.com/OSGeo/gdal/issues/5431 , that is GDAL >= 3.4.1 will use the nodata value from the .aux.xml side car file when it is present. another way would be to make sure you don't have a .aux.xml file
Ha ha! Here we are. Thanks a lot Even for helping us spotting the issue.
This docstring is unnecessary. ```suggestion ```
It's not important for this test.
```suggestion self.assertEqual( ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [AuthorWithIndexedNameAndBirthday] ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [AuthorWithUniqueNameAndBirthday] ```
In this case I'd manually delete `TagUniqueRename` before restoring it `db_table`: ```python def test_unique_name_quoting(self): old_table_name = TagUniqueRename._meta.db_table try: with connection.schema_editor() as editor: editor.create_model(TagUniqueRename) editor.alter_db_table(TagUniqueRename, old_table_name, "unique-table") TagUniqueRename._meta.db_table = "unique-table" # This fails if the unique index name isn't quoted. editor.alter_unique_together(TagUniqueRename, [], (("title", "slug2"),)) finally: with connection.schema_editor() as editor: editor.delete_model(TagUniqueRename) TagUniqueRename._meta.db_table = old_table_name ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [AuthorWithIndexedName] ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [BookForeignObj] ```
Please move it outside of the context processor: ```suggestion self.isolated_local_models = [Author] ```
> Please leave feedback on my solution, why it was not good enough, if it's possible? It's unnecessarily complicated.
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [AuthorWithUniqueName] ```
Maybe: ```suggestion "datetime.datetime" "(2012, 1, 1, 1, 1, tzinfo=datetime.timezone.utc)", ```
```suggestion "import datetime\nfrom django.db import migrations, models\n", ```
```suggestion RemovedInDjango50Warning, stacklevel=2, ```
I'm not sure about using `globals()` :thinking: What do you think about moving `__dir__()` at the end of the file and using `dir()` instead of `globals()`: ```python # RemovedInDjango50Warning. _DIR = dir() def __dir__(): return sorted([*_DIR, "utc"]) ``` we would avoid adding `_DIR`, `__warningregistry__`, and `__dir__` to the `dir(timezone)`.
It's just a suggestion. Deprecation is tricky for module constants, IMO we should try to avoid side-effects.
```suggestion msg = ... with self.assertRaisesMessage(RemovedInDjango50Warning, msg): ```
Might want to replace "old" with "pre-Django 4.1" and "new" with "Django 4.1+".
Why we have here a `column` from the `old_field`? ```suggestion "column": self.quote_name(column), ```
We should **return** `NotImplemented` not raise a different exception, see 54ea290e5bbd19d87bd8dba807738eeeaf01a362 and ticket-30651.
This should return `NotImplemented` when a type of `other` doesn't match: ```suggestion if not isinstance(other, RegexObject): return NotImplemented return self.pattern == other.pattern and self.flags == other.flags ```
What about views with a custom `options()` implementation? :thinking:
I'd add a view name to the exception message, e.g.: ```suggestion f"{view.__qualname__} HTTP handlers must either be all sync or all async." ```
Can we use a `classproperty` on `View` instead? I'm not sure if we need `Enum` :thinking: e.g. ```python class View: ... @classproperty def view_is_async(cls): handlers = [ getattr(cls, method) for method in cls.http_method_names if (method != "options" and hasattr(cls, method)) ] if not handlers: return False is_async = asyncio.iscoroutinefunction(handlers[0]) if not all(asyncio.iscoroutinefunction(h) == is_async for h in handlers[1:]): raise ImproperlyConfigured( f"{cls.__qualname__} HTTP handlers must either be all sync or all async." ) return is_async ```
Maybe? ```suggestion def _field_non_database_attrs(self): ```
This could just be a tuple, no need for a property here. Subclasses may opt to use a property or `cached_property`, but that's no concern in the base class. Also a mutable list is problematic compared to a tuple as subclasses could mutate the base class value acccidentally.
> `how I would overwrite the non_db_attrs in the sqllite3 case` This doesn't need to be overwrite for SQLite when we move it to the field, because custom fields as `EnumField` from `django-mysql` will be able to remove `"choices"` on their own from `EnumField.non_db_attrs`, so we could add `"choices"` to the `Field.non_db_attrs` for all databases. > within the _field_should_be_altered function, I need to reference the non_db_attrs. There are both an old_field and a new_field in this function, would I pick one of these in order to be the non_db_attrs or would it be better to loop through them separately (unsure if that makes sense) We should do this separately because a field type can change.
Can we use "0" instead? ```suggestion f.clean(["0"]) ```
This is already tested in `ExistsSql.test_exists()`.
I moved this to a separate commit.
This won't work on all backends, we need to use `connection.ops.quote_name()` for identifiers.
```suggestion """The cached template loader is always enabled by default.""" ```
We can keep them together ```suggestion with self.subTest(DEBUG=debug), self.settings(DEBUG=debug): ```
Don't we need to check the length of `captured_queries` here? `self.assertEqual(len(captured_queries), 1)`
Ah I see what's happening. Since MyISAM doesn't support transactions (it basically ignores any `BEGIN` and `ROLLBACK` statement and is always auto-commit) then `TestCase` doesn't perform any form of transaction wrapping and thus the `select_for_update` call is not wrapped in an implicit `atomic` block like it normally is. I see a few options: 1. Leave things as they are 2. Require that this test `supports_transactions` 3. Adjust the compiler to not raise this error when `not connection.features.supports_transactions` Ideally we should raise an error when `select_for_update` is attempted to be used on a backend that doesn't support transactions (as it's a noop) but that would be backward incompatible.
`_AssertNumQueriesContext(CaptureQueriesContext)` so this can effectively be replaced by ```suggestion with self.assertNumQueries(1) as captured_queries: ```
> Ok, what do you think of a method on `SchemaTests` with just: Looks good, do we need to subclass `GinIndex` instead of `PostgresIndex`? We want to fix an issue in `PostgresIndex`, so using `GinIndex` can be a bit misleading.
Do we need this change? it looks unnecessary.
This and similar assertions added for `bloom`, `btree`, `hash`, `gist`, and `spgist` are not related with this patch, and they're unnecessary. Index types are already checked in ``` self.assertEqual(constraints[index_name]["type"], ...) ``` Please remove them.
Features deprecated in Django 4.2 will be removed in Django 5.1 ```suggestion warnings.warn(DEFAULT_FILE_STORAGE_DEPRECATED_MSG, RemovedInDjango51Warning) ```
This is an isolation issue that should be fixed. `StorageHandler` cannot share the same global setting, you can check how it's handled in `BaseConnectionHandler` via `configure_settings()`.
Do we need to ignore a warning here? `kwargs["value"]` should be a string path to the class, so is it not enough to assign it to the `STORAGES`? ```suggestion storages._storages[DEFAULT_STORAGE_ALIAS] = kwargs["value"] ``` Do we need to `del storages.backends`? The `storages_changed` callback should handle this for us :thinking:
I have the same doubts to the `static_storage_changed()` receiver.
It's more important to make a removal straightforward than keeping this DRY.
Changing `settings` to `django_settings` is really disruptive and unrelated, please revert it.
IMO default values should be set in `LazySettings`/`Settings` (`django/conf/__init__.py`) and we should immediately deprecate `DEFAULT_FILE_STORAGE` and `STATICFILES_STORAGE` settings (see e.g. 226ebb17290b604ef29e82fb5c1fbac3594ac163). Also, the existing code outside of `django/conf/__init__.py` cannot use deprecated settings.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
We should also check if this doesn't introduce a regression as 519016e5f25d7c0a040015724f9920581551cab0 (fixed in 4122d9d3f1983eea612f236e941d937bd8589a0d).
This is a separate issue and we should move it to a separate commit (together with `test_save_generic_foreign_key_after_parent`) e.g. > _"Refs #28147 -- Fixed loss of assigned parent when saving GenericForeignKey after parent."_ Maybe even a separate PR to make it easier for review.
We can use a f-string ```suggestion f"{operation_name}() prohibited to prevent data loss due to " f"unsaved related object '{field.name}'." ```
I removed it.
You can rebase from the `main` branch and remove `Developer` model, that is now unused (see also 1ed8ca43f61138b8f8d6f92106c27060753ed4e7)
Ahh true, sorry for the noise. No changes are required.
```suggestion # GenericForeignKeys are private. ```
As far as I'm aware it's unneeded, because a reverse relation `GenericRelation` returns multiple objects, so a single `tag` is not assigned to an `object`.
Should we remove the object from a cache? :thinking:
Please revert this, it's not worth changing existing code.
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
We can reuse an existing migration: ```suggestion MIGRATION_MODULES={"migrations": "migrations.test_migrations_manual_porting"} ```
We can reuse an existing migration: ```suggestion call_command("sqlmigrate", "migrations", "0002", stdout=out) ```
```suggestion migrations.RunSQL(sql="", reverse_sql=""), ```
`create table` is not a filename, why we use `fnmatch()` here? :thinking: I'd use `assertIn()`: ```suggestion self.assertIn( 'CREATE TABLE %s' % connection.ops.quote_name("migrations_author"), lines[3], ) ```
```suggestion ChoiceFormSet().template_name, "a/custom/formset/template.html" ```
I'd move it below the `__init__()`.
I'd move it below the `__init__()`.
```suggestion ChoiceFormSet().template_name, "a/custom/formset/template.html" ```
This is not a regression test, it works without the patch. Maybe: ```diff index 1ed0c60b62..ea8404a11e 100644 --- a/tests/postgres_tests/test_ranges.py +++ b/tests/postgres_tests/test_ranges.py @@ -1107,3 +1107,12 @@ class TestWidget(PostgreSQLSimpleTestCase): '<input type="text" name="datetimerange_0" value="2006-01-10 07:30:00">' '<input type="text" name="datetimerange_1" value="2006-02-12 09:50:00">', ) + + def test_range_widget_render_tuple_value(self): + f = pg_forms.ranges.DateRangeField() + value = (datetime.datetime(2006, 1, 10), datetime.datetime(2006, 2, 12)) + self.assertHTMLEqual( + f.widget.render("daterange", value), + '<input type="text" name="daterange_0" value="2006-01-10">' + '<input type="text" name="daterange_1" value="2006-02-12">', + ) ```
We should skip this test when `non_default` collation is not defined, e.g. ```python collation = connection.features.test_collations.get("non_default") if not collation: self.skipTest("Language collations are not supported.") ```
```suggestion # Reversal. ```
```suggestion # Reversal. ```
We should skip this test when `non_default` collation is not defined, e.g. ```python collation = connection.features.test_collations.get("non_default") if not collation: self.skipTest("Language collations are not supported.") ```
If we wanted to test it at the compiler level instead we could do something along the following ```suggestion def test_aggregation_filter_exists(self): queryset = ( Book.objects.values('publisher') .annotate(cnt=Count('isbn')) .filter(cnt__gt=1) ) query = queryset.query.exists(connection.alias) self.assertEqual( len(query.get_compiler(connection).pre_sql_setup()[2]), 1 ) ``` It heavily depends on implementation details of `django.db.models.sql` but avoids a query and reliance on backend specific output.
> Only a warning should be given for passing False in null_first and nulls_last (any idea on what the warning could be would be appreciated). For example `Passing False to nulls_first/nulls_last arguments is deprecated, use None instead.` > The improvements should not be done for the time being (should be done later). Yes, see e.g. 31174031f1ded30d96c77908b965755e0be94c94.
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
`instance` and `ct` are not used in this branch, we should move them to the second branch: ```python if ct_id in custom_queryset_dict: ... else: instance = instance_dict[ct_id] ct = self.get_content_type(id=ct_id, using=instance._state.db) ret_val.extend(ct.get_all_objects_for_this_type(pk__in=fkeys)) ```
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
```suggestion if ct_id in custom_queryset_dict: ```
Ahh, yes :+1:
These objects are used only in `test_generic_foreign_key`, so we can move creation to the test.
This looks unnecessary: ```suggestion ```
Why we evaluate the queryset? Couldn't we keep the `QuerySet` object? ```suggestion ret_val.extend(custom_queryset_dict[ct_id]) ```
Note in passing: (Already in play from #14843, but _interesting_, to me at least 😜) The `__aiter__` here calls `BaseIterable._async_generator()` ([ln50](https://github.com/django/django/pull/15637/files#diff-d58ef61559dc7af5fdf7b56fee13571a4d2948e784cd608f6afeacf3ac2fb195R50)) which has this nice step: ``` while True: chunk = await sync_to_async(next_slice)(sync_generator) ... ``` ... so we (synchronously) fetch chunks of row before yielding them out asynchronously.
> Hmm, imho set serialization and key item assignment (as for dicts) have slightly different mechanics. Not sure, which one works better here. Doesnt key assignment have the risk of falling back to the hash(value) (identity) evaluation for complex types in cpython, that dont implement __eq__ properly (equality)? Both `set` and `set` rely on the same `__hash__` logic you are referring to so if you are worried about Python/SQL incoherence about using `Counter` you should be equally worried about using `set`. The problem is the same as ticket-25544 though (see 86eccdc8b67728d84440a46e5bf62c78f2eddf6d) it's possible that `model.pk` is not hashable and we must account for it one way or another.
What do you think about using `Counter()`? ```python counter = Counter(obj.pk for obj in objs) if counter.get(None): raise ValueError("All bulk_update() objects must have a primary key set.") if any(count > 1 for count in counter.values()): raise ValueError("...") ``` ... or to fail-fast, e.g. ```python pks = set() for obj in objs: if obj.pk is None: raise ValueError("All bulk_update() objects must have a primary key set.") if obj.pk in pks: raise ValueError(...) pks.add(obj.pk) ```
I'm not sure if it's correct. What about static methods that have no args: ```python @staticmethod def item_description(): return "Overridden item description" ```
Can we use `unwrap()` instead? Also this doesn't handle wrapped callable objects e.g.: ```python class MyCallable: @custom_decorator def __call__(self): return 1 ``` Maybe we should unwrap in advance :thinking: ```python if callable(attr): try: code = unwrap(attr).__code__ except AttributeError: code = unwrap(attr.__call__).__code__ if not code.co_argcount: raise ImproperlyConfigured(...) ```
This can be outside of `try..`.
Maybe it would be better to catch `TypeError` instead of adding complicated checks :thinking: ```python try: if code.co_argcount == 2: # one argument is 'self' return attr(obj) else: return attr() except TypeError as e: raise ImproperlyConfigured(...) from e ```
I'd revert this reformatting to make diff smaller: ```suggestion if code.co_argcount == 2: # one argument is 'self' return attr(obj) else: return attr() ```
We can pass old/new names instead of entire indexes.
Checking list of fields is not enough. Indexes with any custom options (`condition`, `deferrable`, `include`, `expressions`, etc.) should not be taken into account.
NVM, just saw the nested `Q(price=...)` and `Q(name=...)`
I _think_ this branch might not be covered by tests as no `**kwargs` are used https://github.com/django/django/blob/9d04711261156c487c6085171398070ea3df8122/django/db/models/query_utils.py#L45-L47
```suggestion 'The "django/forms/default.html" template will be removed.' ```
```suggestion 'The "django/forms/default.html" template will be removed.' ```
Happy with that. As long as the all of the `.as_*()` methods are tested independently then we can switch to the `<div>` output for the default case and not worry.
```suggestion # RemovedInDjango50Warning: When the deprecation ends, replaca with # form_template_name = "django/forms/div.html" # formset_template_name = "django/forms/formsets/div.html" ```
```suggestion # RemovedInDjango50Warning: When the deprecation ends, revert to # FORM_RENDERER="django.forms.renderers.Jinja2", ```
```suggestion # RemovedInDjango50Warning settings.FORM_RENDERER = "django.forms.renderers.DjangoDivFormRenderer" ```
Unnecessary -> ```suggestion def __str__(self): ```
Minor but I think the `LOOKUP_SEP` should not be baked in `prefix_references` to allow caller to include it themselves. ```suggestion F(f"{prefix}{expr.name}") ```
I'd suggest moving the `item.prefix_references` part to the `if isinstance(item, Orderby)` instead as all expressions are already wrapped in an `OrderBy` and the latter always has a `prefix_references` method so this conditional is unnecessary ```python if isinstance(item, OrderBy): results.append((item.prefix_references(f"{name}{LOOKUP_SEP}"), False)) continue ```
We could add this hook in a separate commit/PR.
We can use here `self.style.WARNING`.
IMO, it's unnecessary.
_"f-strings should use only plain variable and property access"_ This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I would not recommend any alternatives: ```suggestion f"Cannot update applied migration {migration}." ```
We could use migration files and don't use `assertRegex()`: ```python previous_migration_file = os.path.join(migration_dir, "0005_fifth.py") files = [f for f in os.listdir(migration_dir) if f.startswith("0005_auto")] updated_migration_file = os.path.join(migration_dir, files[0]) self.assertIn( f"Updated migration {updated_migrations_file} requires manual porting.", out_value, ) ```
```suggestion self.assertIn(f"Deleted {migration_file}", out.getvalue()) ```
This branch is untested. Also, we don't see this with a message without hints: ```python if leaf_migration_nodes[0] in loader.applied_migrations: migration = leaf_migration_nodes[0] raise CommandError(f"Cannot update applied migration {migration}.") ```
IMO a single test with custom `too_many_forms` and `too_few_forms` is enough.
Can we raise `ValueError` for consistency with what `SchemaEditor` do? ```suggestion if len(matching_index_name) != 1: raise ValueError( f"Found wrong number (%s) of indexes for fields ..." ) ```
XORs are great but for many folks they are also not readable. I'd prefer two checks: ```suggestion if not old_name and not old_fields: raise ValueError( "RenameIndex requires one of old_name and old_fields arguments to be " "set." ) if old_name and old_fields: raise ValueError( "RenameIndex.old_name and old_fields are mutually exclusive." ) ```
Should we add `reduce()` for `RenameIndex` on the same model with `self.new_name_lower == operation.old_name_lower`? :thinking:
Also these error messages are untested.
This docstring is unnecessary.
This docstring is unnecessary.
f-strings should not contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Users would use field names not column names :thinking: we must take this into account, e.g. ```python columns = [from_model._meta.get_field(field).column for field in self.old_fields] ```
> It's compiled once on import no? We made all module-level regexes to save import time, starting with 2bb1027d6bcdad59624a9d08701e0d2e4a9c0ba7. Often modules are imported but the relevant code paths aren't used. Perhaps that's not so relevant with such short regexes - I benchmarked it as taking about 400ns to compile, which is not much. But good point from Mariusz, if there's no need that's even better.
`s` is always `bytes` in our case so we can drop the `else` branch: ```suggestion return re.match(b"^[ -~]{0,200}[!-~]$", s) ``` We could also pre-compile this regex and use `fullmatch()`: ```python boundary_re = _lazy_re_compile(b"[ -~]{0,200}[!-~]") def valid_boundary(s): return boundary_re.fullmatch(s) ``` It's used only in `MultiPartParser` so maybe a separate hook is not necessary :thinking: ```python if not boundary or not boundary_re.fullmatch(boundary): raise MultiPartParserError( "Invalid boundary in multipart: %s" % force_str(boundary) ) ```
```suggestion """ Parse a Content-type like header. Return the main content-type and a dictionary of options. """ ```
This branch in untested :thinking:
This branch in untested :thinking:
> It's compiled once on import no? Yes, but do we need to compile it at all? In most of cases it's not necessary because `boundary` is already parsed in `opts`.
We can remove `db` from this line and from the arguments for `RedisCacheClient.__init__()` as we're not doing anything special here and it'll be handled by `**options`. We need to keep `parser_class` as we're allowing it to be provided as a dotted string for lazy import.
rather than custom caching with a dict, this might be clearer with a module-level function using `@lru_cache(maxsize=2)`, with the current value of `USE_TZ` as the only argument. It would save some lines and clarify it's a cache.
```suggestion def get_new_connection(self, conn_params): Database = self.Database ``` Better to use self.Database because someone may extend this backend
I know the heuristics are not exactly the same but maybe use `rhs_is_direct_value`? ```suggestion if self.rhs_is_direct_value(): ```
Oh I meant the opposite sorry ```suggestion if not self.rhs_is_direct_value(): ```
Makes sense, lets keep things as they are then.
The default argument for `pop` should not be necessary. When looking at the definition of `db.models.indexes.Index.deconstruct`, the `name` is always defined
Is it worth having nested `try ... except`? :thinking: It should be fine to catch both: ```python try: signature = inspect.signature(current) signature.bind() except ( # arguments *were* required TypeError, # no signature found ValueError, ): current = ( context.template.engine.string_if_invalid ) # invalid method call else: raise ``` or use separate clauses: ```python try: signature = inspect.signature(current) except ValueError: # no signature found current = context.template.engine.string_if_invalid else: try: signature.bind() except TypeError: # arguments *were* required current = ( context.template.engine.string_if_invalid ) # invalid method call else: raise ```
I would move it to the `DeprecatedMigrationOperationTests`.
IMO we should refactored out `test_rename_field_index_together()`.
This shouldn't be necessary anymore. Please decorate the entire `AutodetectorIndexTogetherTests` class.
We should mark other schema's tests which use `index_together`: ```python # RemovedInDjango51Warning def test_index_together(self): ... # RemovedInDjango51Warning def test_index_together_with_fk(self): ... ```
> Maybe we can have a different PR (or even ticket) to split the tests and make the `index_together` tests redundant with `unique_together` and easily delete-able. Yes, please :bow: , we could move `index_together` tests to a separate class, e.g. `AutodetectorIndexTogetherTests`. A different PR with `Refs #27236 -- ...` would be fine.
The main question is what to do with these tests? We should analyze them one by one and prepare alternative versions only with `unique_together` (if necessary). I'm afraid that we cannot simply remove them when deprecation ends because we will end with many not covered scenarios. For example: ```python diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py index 547e0b32c5..4c19a34d7f 100644 --- a/tests/migrations/test_autodetector.py +++ b/tests/migrations/test_autodetector.py @@ -2441,10 +2441,10 @@ class AutodetectorTests(TestCase): self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterField"]) + # RemovedInDjango51Warning: When deprecation ends rename to + # test_empty_unique_together(). + @ignore_warnings(category=RemovedInDjango51Warning) def test_empty_foo_together(self): - """ - #23452 - Empty unique/index_together shouldn't generate a migration. - """ # Explicitly testing for not specified, since this is the case after # a CreateModel operation w/o any definition on the original model model_state_not_specified = ModelState( @@ -2457,7 +2457,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": None, + "index_together": None, # RemovedInDjango51Warning "unique_together": None, }, ) @@ -2468,7 +2468,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": set(), + "index_together": set(), # RemovedInDjango51Warning "unique_together": set(), }, ) ```
```suggestion "index_together": {("bio", "age")}, # RemovedInDjango51Warning. "indexes": [], ```
We should mark all tests and model states that use `index_together` in `tests/migrations/test_autodetector.py` for removal. We can also move them to a common class for easier remove when deprecation ends.
We should also rename this tests, it's called `test_index_together`.
This test making a ProjectState with all options. We shouldn't remove `index_together` but mark it for removal when deprecation ends: ```suggestion index_together = ["bio", "age"] # RemovedInDjango51Warning. ```
Also, we should mark the `index_together` argument of `set_up_test_model` for removal: ```diff diff --git a/tests/migrations/test_base.py b/tests/migrations/test_base.py index cf9dd029bb..3f1559b8d6 100644 --- a/tests/migrations/test_base.py +++ b/tests/migrations/test_base.py @@ -255,7 +255,7 @@ class OperationTestBase(MigrationTestBase): unique_together=False, options=False, db_table=None, - index_together=False, + index_together=False, # RemovedInDjango51Warning. constraints=None, indexes=None, ): @@ -263,6 +263,7 @@ class OperationTestBase(MigrationTestBase): # Make the "current" state. model_options = { "swappable": "TEST_SWAP_MODEL", + # RemovedInDjango51Warning. "index_together": [["weight", "pink"]] if index_together else [], "unique_together": [["pink", "weight"]] if unique_together else [], } ```
> See #15755 Merged, please rebase.
This tests should check that the index names is properly quoted, it doesn't check it anymore because we quote the entire `CREATE INDEX` statement. This should fail with: ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index f2ca8c8df9..842b0e977f 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -1348,7 +1348,7 @@ class BaseDatabaseSchemaEditor: nonlocal name if name is None: name = self._create_index_name(*args, **kwargs) - return self.quote_name(name) + return name return Statement( sql_create_index, ```
A note in `docs/internals/deprecation.txt` is missing.
This isn't triggered until the input queue is read at least once.
We're not currently handling this correctly I think. Follow up at https://code.djangoproject.com/ticket/33738
Thanks. I think that gives a pointer in the right direction. 👍
Focusing in only on the point around 'slightly faster' (because whilst I can't think of additional syntax to disallow, that's much of the point around extensibility you bring up ;)). IM(limited)E, for any '_sensible_' length string, `x in mystr` (at least where `x` is a constant) is well-optimised, and usually performs better than the equivalent regex, even needing 2 passes, and accounting for compiling the regex beforehand. For the lengths of strings we might _expect_ here, the difference is probably still measured in nanoseconds. If performance were the _only_ consideration (vs. the aforementioned extensibility) it'd be worth checking.
a regex check for `/\*|\*/` could be slightly faster, avoiding two passes over the string and being more extensible in the future in case we find other syntax that shouldn't be allowed
I already suggested such changes, but Mariusz requested adding a hook which reverted them.
Do we need to do this recursively? I think we may be more restrictive and raise an error when `message` contains `\*`, `*/` or `--`.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
This is lifted from Python 3.10 so we should attribute appropriately and also ensure that we remove it when no longer needed: ```suggestion if PY310: from contextlib import aclosing else: from contextlib import AbstractAsyncContextManager # Backport of contextlib.aclosing() from Python 3.10. # Copyright (C) 2020 Python Software Foundation (see LICENSE.python). class aclosing(AbstractAsyncContextManager): """ Async context manager for safely finalizing an asynchronously cleaned-up resource such as an async generator, calling its ``aclose()`` method. """ def __init__(self, thing): self.thing = thing async def __aenter__(self): return self.thing async def __aexit__(self, *exc_info): await self.thing.aclose() ```
Consider wraping an async generator with aclosing, as recommended in this article: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators It is `contextlib.aclosing` in Python 3.10, or you may take a custom defined class from the article
OK, let's leave it.
`type` check is unnecessary.
Maybe: ```suggestion def get_primary_key_columns(self, cursor, table_name): ```
Composite primary key are not supported so we shouldn't change this (see ticket-373).
This line should use `connection.features.introspected_field_types["IntegerField"]`. (INTEGER is introspected as `BigIntegerField` on CockroachDB.) PR: https://github.com/django/django/pull/15750
```suggestion Return a list of primary key columns for the given table. ```
```suggestion return columns[0] if columns else None ```
We shouldn't use both `get_composite_key()` and `get_primary_key_column()` because we introspect the same primary key twice. I'd all `get_composite_key()` and reuse it result.
Ahh, yes, sorry :facepalm: Good catch :dart:
We could list the columns names.
I would test exactly what you reported, e.g. ```python self.assertEqual( str(inspect.signature(Article.objects.bulk_create)), "(objs, batch_size=None, ignore_conflicts=False, update_conflicts=False, " "update_fields=None, unique_fields=None)", ) ```
> ... then this test case need to be updated every time the original function's signature, docstring, etc are updated. That's not true. Proposed assertion compares only a signature: > ```python > self.assertEqual( > str(inspect.signature(Article.objects.bulk_create)), > "(objs, batch_size=None, ignore_conflicts=False, update_conflicts=False, " > "update_fields=None, unique_fields=None)", > ) > ``` and I don't see a big issue in updating it. We don't change signatures so often. > Moreover, our goal is to ensure manager methods show the same signature and docstrings as the queryset methods and not a specific string. It's exactly the same in this case. I'd prefer to compare with the exact value not the result of another function.
A regression test is required.
Is this possible? The constraint names are unique so this would only be possible if someone first manually renames an existing constraint for `unique_together`. IMO we don't need to worry about it.
Maybe we could add a new hook for the unique constraint names (we have for example `_fk_constraint_name()`).
This is only possible if the database allows multiple constraints on the same fields so we can also check the `allows_multiple_constraints_on_same_fields` feature flag.
Do we need the `depend_on_deletion` flag? It seems we can always add the same field as a dependency because this is only the case only when we use `RemoveField`/`AddField` instead of `RenameField` :thinking: ```suggestion dependencies.append((app_label, model_name, field_name, False)) ```
`by` :thinking: ```suggestion f"Cannot update when ordering by an aggregate: " ```
```suggestion new_order_by.append(annotation) ```
Is this something that we can support? so is it a backend or database limitation? Database limitation, I suppose.
This works without the patch so we should move it to a separate commit and test method.
We should use `django_test_skips` instead: https://github.com/django/django/blob/759ff4862a815d55c59bd8147bb180e08431e9c4/django/db/backends/mysql/features.py#L92
```suggestion if annotation := query.annotations.get(col): ```
```suggestion # Inline annotations in order_by(), if possible. ```
Pretty sure we can't drop the `order_by` based on 779e615e362108862f1681f965ee9e4f1d0ae6d2 which explicitly deals with this `annotate` / `FieldError` issue.
One thing that makes me uneasy here is that this code would make the following preserve ordering? ``` Bar.objects.order_by(Count("m2m_foo")) ``` Should we inline ordering references in ordering instead of silently eliminating them? It feels like we should as `annotate(foo=bar).order_by('foo')` should be equivalent to `order_by(bar)`? I'm bringing this up because ordering in updates is important for some backends (see 779e615e362108862f1681f965ee9e4f1d0ae6d2). All that to say that I believe we should either raise an error that points at using `order_by` directly or automated the translation of annotation references instead of silently dropping the user specified ordering.
```suggestion # Inline annotations in order_by, if possible. ```
> ... so I made it a required parameter. Sorry, I think we're not understanding each other. 🤔 * The `on_bind` parameter is defined as `on_bind=None`, so it's optional. * Exactly when `on_bind=None` that `server_bind` is only declared conditionally with lead to a `... is referenced before assignment` problem. If looks like this: ``` >>> on_bind = None >>> if on_bind is not None: ... a = "I won't be defined" ... >>> a Traceback (most recent call last): File "<stdin>", line 1, in <module> NameError: name 'a' is not defined ```
No need for the parameters, they are not relevant to the test I think: ```suggestion msg = "The make_random_password method is deprecated." with self.assertWarnsMessage(RemovedInDjango51Warning, msg): UserManager().make_random_password() ```
This warning should be tested.
```suggestion @ignore_warnings(category=RemovedInDjango51Warning) ```
Unneeded and outdated :) ```suggestion ```
```suggestion category=RemovedInDjango51Warning, ```
I would keep these states in `AutodetectorTests`. You can use them in `AutodetectorIndexTogetherTests` as a class properties, e.g.: ```python self.get_changes( [AutodetectorTests.book, AutodetectorTests.author_with_book], [...], ) ```
@lundberg The test runner already [raises `ResourceWarning` as an error](https://github.com/django/django/blob/49b470b9187b6be60e573fed08c8f4a87f133750/tests/runtests.py#L50) -- so that should be enough... — it's implicit but sufficient (since some of these don't get raised until shutdown). Happy to look at a warnings filter context manager version, if that's what you've got in mind, but I'm not sure it's needed. 🤔
Is there a reason to move this check? I'd move it to the previous place.
IMO introspecting generated SQL is unnecessary, maybe: ```python def test_order_by_f_expression_to_constant_value(self): qs = Article.objects.annotate(constant=Value(42)).order_by( F("constant"), F("headline") ) self.assertSequenceEqual(qs, [self.a1, self.a2, self.a3, self.a4]) ```
This seems to be on the right path but I'm not sure `query.annotations` is correct as some might have been excluded through `.values`? Do we want to check `.select` and `.extra_select` as well? There must be a way to merge this logic with the one below that already cover all of these paths.
`field` is always an `OrderBy` instance so we can use `.expression`: ```suggestion if isinstance(field.expression, F): ```
```suggestion self.assertSequenceEqual(qs, []) ```
`asc()` is unnecessary: ```suggestion .order_by(F("test")) ```
We could directly check that `name` is in `annotations`: ```python if isinstance(field.expression, F) and not self.query.combinator: col = field.expression.name if col in self.query.annotations: field.set_source_expressions([Ref(col, self.query.annotations[col])]) yield field, True ```
Please revert. ```suggestion ```
Maybe: ```suggestion def test_order_by_f_expression_to_constant_value(self): ```
This line is never executed. Instead: ``` with self.assertRaisesMessage(ValueError, msg): Note.objects.bulk_update([], fields=["note"], batch_size=0) ```
Use a similar logging to what we do for robust signals? See `django.dispatch.dispatcher.Signal.send_robust` and ``` try: response = receiver(signal=self, sender=sender, **named) except Exception as err: logger.error( "Error calling %s in Signal.send_robust() (%s)", receiver.__qualname__, err, exc_info=err, ) ``` Something like ```suggestion logger.error("Error calling {func.__qualname__} on_commit() ({e}).", exc_info=True) ```
When calling `on_commit` there are basically two modes: - there is no transaction in progress, so we execute the function right away - we are in an atomic block, so we register the function to execute it later (`self.run_on_commit.append(`) The first case is handled by the PR, but not the second one. And I'd think that we would need to handle a robust execution in the second case too. Does that make it clearer? :)
These will need to be adapted.
I'm mostly mimicking existing behaviour. I can't find any logger with the `.base` module, but `django/db/backends/utils.py` has a plain `logger = logging.getLogger("django.db.backends")`. That's why I think we don't need the `base` :)
`()` are unnecessary ```suggestion raise ForcedError ```
```suggestion f"Error calling {func.__qualname__} on_commit_robust() ({e}).", ```
I'm not sure about the proposed API. Josh suggested adding a `robust` kwarg to the `on_commit()` function which is much more handy, IMO (\cc @jarshwah).
```suggestion logger = logging.getLogger("django.db.backends") ``` is probably sufficient 🤔
```suggestion def on_commit(self, func, is_robust=False): ``` Add default value for better backward compatibility.
Subjective opinion: keep the same layout as `do` => ```suggestion Thing.objects.create(num=num) transaction.on_commit_robust(lambda: self.notify(num)) ```
I'd revert the logic i.e. check `execute` first: ```suggestion if execute: if is_robust: try: callback() except Exception as e: logger.error( f"Error calling {callback.__qualname__} on_commit() " f"during transaction (%s).", e, exc_info=True, ) else: callback() ```
`on_commit` can be used directly by 3rd-party database backends, that's why we should add a default value to `is_robust.`
A temporary variable is unnecessary ```suggestion self.run_on_commit.append((set(self.savepoint_ids), func, False)) ```
```suggestion self.run_on_commit.append((set(self.savepoint_ids), func, True)) ```
Error should be passed in `args`: ```suggestion logger.error( f"Error calling {func.__qualname__} on_commit_robust() (%s).", e, exc_info=True, ) ```
We cannot change the order of kwargs: ```suggestion def on_commit(func, using=None, is_robust=False): ```
When we register the function to run robustly on commit in an atomic bloc, should we also try/catch it when it is actually run? Meaning that in `db.backends.base.base.BaseDatabaseWrapper.run_and_clear_commit_hooks` we should take into account this info
I moved this check to a separate helper.
Please revert this unrelated cleanup and add: ``` CharField._unregister_lookup(TrigramStrictWordSimilar) TextField._unregister_lookup(TrigramStrictWordSimilar) ``` ``` CharField.register_lookup(TrigramStrictWordSimilar) TextField.register_lookup(TrigramStrictWordSimilar) ``` directly.
The only thing that we change is a `function`/`arg_joiner` so I would add a separate classes: ```python class TrigramStrictWordDistance(TrigramWordBase): function = "" arg_joiner = " <<<-> " class TrigramStrictWordSimilarity(TrigramWordBase): function = "STRICT_WORD_SIMILARITY" ```
This docstring is unnecessary.
In this method we use the different `opts` above, so I'd change to the `opts = self.opts` instead of switching all `opts` to `self.opts` below.
This is probably fine... We loose the **this thread** check but...
It's likely fine. 🤔 Let me have a play in the debugger tomorrow.
```suggestion if instance_lookups := getattr(self, "instance_lookups", None): ```
This seems a bit odd to have `classorinstancemethod` specialize these two here.
Should this override an instance lookup? As far as I'm aware "instance" lookups should always have a precedence as lookups with bigger granularity :thinking: (\cc @charettes).
Use `try ... finally` and unregister this lookup to keep tests isolated.
Can we test this with nested context processors to see that unregistering also works? e.g. ```python with register_lookup( models.CharField, CustomStartsWith, lookup_name="start") ): with register_lookup(Company.place.field, StartsWith4Char, lookup_name="start"): self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3], ) self.assertCountEqual( Company.objects.filter(name__start="a"), [self.obj1, self.obj2, self.obj4], ) self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3, self.obj4], ) ```
I pushed extra tests to the https://github.com/django/django/pull/16023.
Ahh, yes. I missed that both are instance lookups :facepalm:
Use `self.assertCountEqual()` when ordering is not specified and we have more than one expected result.
We can reuse `Author` model. If we need two `CharField`s then we can add e.g. `alias` to the `Author`.
Since the existence of instance lookups will be rare I suggest we avoid an unncessary dict creation when `instance_lookups` is missing ```suggestion if not (instance_lookups := self.__dict__.get("instance_lookups"): return class_lookups return {**class_lookups, **instance_lookups} ```
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
`black` doesn't change these lines for me, please revert.
This is already covered by `ParseHeaderParameterTests.test_basic()`.
Both `parse_header()` and `_parse_header_params()` are now unused. Please remove them.
True, this message is unused since its introduction in d725cc9734272f867d41f7236235c28b3931a1b2. I think we can remove `_parse_header()` hook, see #15802.
Help message is not necessary in this case. Please remove this.
It seems like a lot of complexity can be stripped out of this: ```python if self.base_field.choices and "choices_form_class" not in kwargs: obj = self.base_field defaults = { "choices_form_class": forms.TypedMultipleChoiceField, "coerce": self.base_field.to_python, # XXX: Do we actually need this? } else: obj = super() defaults = { "form_class": SimpleArrayField, "base_field": self.base_field.formfield(), "max_length": self.size, } if self.choices: warnings.warn("Choices should be defined in base field.", RemovedInDjango51Warning) return obj.formfield(**{**defaults, **kwargs}) ``` Obviously the behaviour of this post-deprecation also needs to be decided: - Does it throw an exception? - Does it silently ignore choices on the `ArrayField`? (Might need to actively strip them out?) - If we promote a system check warning to error, does it matter which approach we choose? (Not everyone uses the checks though.)
Sorry - typo. Fixed.
Is this necessary? If we're passing this `self.base_field.to_python` value of `coerce` to `self.base_field.formfield()`, is that not the same as assigning `self.to_python` within `.formfield()`? 🤔 If so, then we don't need this line or the change to `defaults["coerce"] = kwargs.get("coerce", self.to_python)`
We can't do this without a deprecation warning first. And there really out to be a system check (initially a warning, later an error) so that this is caught early rather than surprisingly at runtime.
IMO we don't need `databases` here.
IMO, it's fine to leave them in both places.
This can be single-lined.
Also `django.core.checks.migrations` should be imported in `django/core/checks/__init__.py`.
This can be single-lined.
alternative, create a "MigrationMock" factory ```py def MigrationMock(): m = Mock() m.check.return_value = [] return m # usage m = MigrationMock() assert len(m.check()) == 0 assert m.check.called ``` https://docs.python.org/3/library/unittest.mock.html#unittest.mock.Mock.return_value
IMO this check is unnecessary: ```suggestion errors.extend(operation.check()) ```
I'd _guess_ is that this was automatically performed by `black` because you had a trailing comma within the list (i.e. `[my_operation,]` rather than `[my_operation]`) which [black will treat as a rule to make the expression multi-line](https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#trailing-commas) > A pre-existing trailing comma informs Black to always explode contents of the current bracket pair into one item per line.
This is exactly the same as for `models.Field`. What do you think about moving this logic to a mixin (`django.utils.deprecation`) and using it in both places :thinking: ? e.g. ```python class DeprecationForHistoricalMigration(Mixin): system_check_deprecated_details = None system_check_removed_details = None def check(self): if self.system_check_removed_details is not None: return [ checks.Error( self.system_check_removed_details.get( "msg", "%s has been removed except for support in historical " "migrations." % self.__class__.__name__, ), hint=self.system_check_removed_details.get("hint"), obj=self, id=self.system_check_removed_details.get("id", "migrations.EXXX"), ) ] elif self.system_check_deprecated_details is not None: return [ checks.Warning( self.system_check_deprecated_details.get( "msg", "%s has been deprecated." % self.__class__.__name__ ), hint=self.system_check_deprecated_details.get("hint"), obj=self, id=self.system_check_deprecated_details.get( "id", "migrations.WXXX" ), ) ] return [] ```
Previously, this test didn't crash when we change `BaseModelFormSet.edit_only` to `True`. I pushed small edits.
is it strictly required to cast params to a tuple? I thought it was understood that `params` may be a list or a tuple throughout the ORM code.
This is precisely this inconsistency in the expressions API about `params: list | tuple` that forces the usage of `tuple` here. Some `lhs.as_sql` return `params: list` and but the backend expects layer only expects `tuples` to be provided. Without this `tuple` some tests crash and I think we want to avoid this expression API inconsistency leak into the backends layer as it could be considered as low level as the compiler which only deals with `params` in tuples.
Thanks, I missed this use case!
Minor but the `'%%Y-%%m-01 00:00:00'` could likely by appended to params as well.
newb here, I'm trying to understand why you are catching both `DataError` and `OperationalError` I'm guessing this test is somehow run on all ~3~ 4 backends and they raise different exceptions? _same with your [other change in this file](https://github.com/django/django/pull/15820/files#diff-7704d1b7fbfb3516a17d0f19338242c16eff438b3e06125015b35d62a314f638R248):_ ```py with self.assertRaises((DataError, OperationalError, ValueError)): ```
> Not really no.. Now that i think of it this will also address issues where data or keys (delete_many) don't have the expected type.. e.g. keys been None or data been None.. Why? `data`/`keys` are not falsey when they contains `None` :thinking:
Ahh sorry, I misunderstood. Thanks :+1:
Is there a reason to do this with `safe_data` instead of passed `data`? (the same in `delete_many()`), e.g. ```python def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None): if not data: return [] ... ```
I checked locally. It should pass for other backends.
We should add `violation_error_message` only when it's set and when it's different from the default value, e.g. ```python if self.violation_error_message and self.violation_error_message != _("Constraint “%(name)s” is violated."): ... ``` We could also add the `default_violation_error_message` attribute to the class: ```python class BaseConstraint: default_violation_error_message = _("Constraint “%(name)s” is violated.") violation_error_message = None def __init__(self, name, violation_error_message=None): self.name = name if violation_error_message is not None: self.violation_error_message = violation_error_message else: self.violation_error_message = self.default_violation_error_message def deconstruct(self): path = "%s.%s" % (self.__class__.__module__, self.__class__.__name__) path = path.replace("django.db.models.constraints", "django.db.models") kwargs = {"name": self.name} if self.violation_error_message is not None and self.violation_error_message != self.default_violation_error_message: kwargs['violation_error_message'] = self.violation_error_message return (path, (), kwargs) ```
```suggestion "support them.", ``` _f-string without any placeholders_
Please remove type annotations. We don't currently use them in Django.
Unless there's a significant difference, a single RTL language seems fine... 🤔
We cannot import from `selenium` at the module level as it's an optional requirement.
I'd add `HAS_CX_ORACLE` flag to use it here: ```python try: import oracledb except ImportError: import cx_Oracle as oracledb HAS_CX_ORACLE = True else: HAS_CX_ORACLE = False ... @cached_property def data_types_reverse(self): # RemovedInDjango51Warning. if HAS_CX_ORACLE and self.connection.cx_oracle_version < (8,): ```
You cannot remove the `cx_Oracle` < 8 branch, it's deprecated but still supported.
> Also, do I need to add this warning in the files like `django/contrib/gis/db/backends/oracle/adapter.py`, `django/contrib/gis/db/backends/oracle/introspection.py` and `django/db/backends/oracle/introspection.py`? Or only add it in `django/db/backends/oracle/base.py`? Yes, we should have warnings in both backends `django.db.backends.oracle` and `django.contrib.gis.db.backends.oracle`. I'd prefer to have a single point (`base.py`) that will raise a warning ```python try: import oracledb except ImportError: import cx_Oracle as oracledb warnings.warn( "cx_Oracle is deprecated. Please use oracledb instead.", RemovedInDjango51Warning, ) ``` In other imports, switching between libraries should be sufficient.
Tests of deprecation warnings are missing.
```suggestion "Exits with a non-zero status if unapplied migrations exist and does " "not actually apply migrations." ```
`app_configs` is initialized as an empty dict, so this line should be unnecessary :thinking:
```suggestion "Spawning reimports modules, overwriting my_check.did_run to False, " "making this test useless.", ```
Maybe we could add `pbkdf2_sha1` in place of `sha1`.
Maybe we could add `pbkdf2_sha1` in place of `sha1`.
Not your fault (ie this issue already exists), but this code does *not* exhaust the stream; we'd need a while loop here till `read()` returns "" or add an exhaust method like werkzeug
Probably more important, this means that https://github.com/django/django/blob/cb791a2540c289390b68a3ea9c6a79476890bab2/django/http/request.py#L338 is not guaranteed to read the whole body data. I think we should copy more from werkzeug (they are failing if not everything is readable)
```suggestion rs_path = Path(__file__).parent / "data" / "rasters" / "raster.tif" ```
```suggestion self.rs = GDALRaster(rs_path) ```
```suggestion return self is other if self.pk is None else self.pk == other.pk ```
Model instances without primary keys are not hashable.
Comparing instances without primary keys and exactly the same instances is probably the rarest case. I don't think it's desirable to do this every time.
This current version is more readable.
Minor but you could avoid repeating `case_insensitive` multiple times ```suggestion ci_collation = "case_insensitive" def drop_collation(): with connection.cursor() as cursor: cursor.execute(f"DROP COLLATION IF EXISTS {ci_collation}") with connection.cursor() as cursor: cursor.execute( f"CREATE COLLATION IF NOT EXISTS {ci_collation} " "(provider = icu, locale = 'und-u-ks-level2', " "deterministic = false)" ) ```
This was already discussed and reverted, see 6e4c6281dbb7ee12bcdc22620894edb4e9cf623f.
Does it work now? I wouldn't hesitate to simplify fix for 24974.
We should add a real-life callback, not mocking that `callback()` is called.
Can we simply fix for ticket-24974? I don't see any tests failures with: ```diff diff --git a/django/forms/models.py b/django/forms/models.py index 5bd7ef256a..95bce27d9a 100644 --- a/django/forms/models.py +++ b/django/forms/models.py @@ -258,21 +258,12 @@ class ModelFormOptions: class ModelFormMetaclass(DeclarativeFieldsMetaclass): def __new__(mcs, name, bases, attrs): - base_formfield_callback = None - for b in bases: - if hasattr(b, "Meta") and hasattr(b.Meta, "formfield_callback"): - base_formfield_callback = b.Meta.formfield_callback - break - - formfield_callback = attrs.pop("formfield_callback", base_formfield_callback) - new_class = super().__new__(mcs, name, bases, attrs) if bases == (BaseModelForm,): return new_class opts = new_class._meta = ModelFormOptions(getattr(new_class, "Meta", None)) - formfield_callback = opts.formfield_callback or formfield_callback # We check if a string was passed to `fields` or `exclude`, # which is likely to be a mistake where the user typed ('foo') instead @@ -310,7 +301,7 @@ class ModelFormMetaclass(DeclarativeFieldsMetaclass): opts.fields, opts.exclude, opts.widgets, - formfield_callback, + opts.formfield_callback, opts.localized_fields, opts.labels, opts.help_texts, ```
`must_remain_connected()` is called only here maybe it's better to pass `in_negated` instead of `negated` and don't calculate it twice :thinking:
```suggestion "Heterogeneous disjunctive predicates against window functions are " ```
Wrap at 79 chars.
Moved in #15947.
Can move `test_conditional_annotation` to the `WindowFunctionTests`? As far as I'm aware it should work now.
I understand what you meant, however this message can be difficult for most of folks. Unfortunately, I don't have a better wording (at least for now).
Is this possible? `coverage` shows that it's untested.
Ahh, true. I've convinced myself that `alias` is unused if `EmptyResultSet` is raised :facepalm:
It's unused for empty results, so maybe we can move it below the `try...except` block: ```python try: sql, params = self.compile(col) except EmptyResultSet: empty_result_set_value = getattr( col, "empty_result_set_value", NotImplemented ) if empty_result_set_value is NotImplemented: # Select a predicate that's always False. sql, params = "0", () else: sql, params = self.compile(Value(empty_result_set_value)) else: sql, params = col.select_format(self, sql, params) if alias is None and with_col_aliases: alias = f"col{col_idx}" col_idx += 1 ret.append((col, (sql, params), alias)) ```
We don't need to check `condition_params` when SQL is blank.
Use `hasattr(self.lhs, "resolve_expression")` for checking that `self.lhs` is an expression.
We should have a more generic solution and deep-copy all non-picklable attributes, e.g. ```python for attr in self.non_picklable_attrs: if hasattr(self, attr): setattr(obj, attr, copy.deepcopy(getattr(self, attr), memo)) ```
I'd be good to identify what in `META` is non-pickleable and maybe remove only this value :thinking:
I'd rename it to `meta_non_picklable_items`.
This should be called first, i.e. ```suggestion def __getstate__(self): state = super().__getstate__() for attr in self.meta_non_picklable_items: if attr in state["META"]: del state["META"][attr] return state ```
`environ` is `WSGI` specific we should move it to the `WSGIRequest`: ```python class WSGIRequest(HttpRequest): non_picklable_attrs = HttpRequest.non_picklable_attrs | frozenset(["environ"]) meta_non_picklable_items = frozenset( ... ```
That's what I thought. Thanks for the clarification 👍 The patch is fine to me 🚀
😮 I see that we have a similar condition here `django.db.models.expressions.Exists.as_sql`: ``` features = compiler.connection.features if not features.supports_boolean_expr_in_select_clause: return "1=1", () return compiler.compile(Value(True)) ``` Would it make sense to somehow move them to the same piece of logic? We could either have `compile(Value(True))` determine if it should generate a `1=1`, but it have other side-effects I think 😕
We don't use `assert ` in tests. Please use `unittest` assertions: ```suggestion self.assertIs(self._extension_exists(), False) ```
Creating and isolating new connections in tests are tricky. > if we don't have yet good mocking structure for ORM-database operations Testing database operations is not difficult, but here we want to test a low-level operations related with preparing a database before using ORM.
This can cause as isolation issues :thinking: Give me few minutes to figure out if it's worth testing.
Testing `prepare_database()` is difficult (a lot of mocking is needed to get a proper isolation). IMO we can push this without tests.
Maybe ```suggestion ("ckb", gettext_noop("Central Kurdish (Sorani)")), ```
```suggestion "ckb": { ```
Is Sorani not a RTL language? ```suggestion "bidi": True, ``` We should also add it to the `LANGUAGES_BIDI` in the `global_settings.py`
As far as I'm aware, on some databases `UPDATE` makes exclusive table lock regardless the set of updated rows :thinking: I'm just trying to think about the potential side-effects. > If they do match rows then they shouldn't be any worse than the previous IN `potentially_long_list_of_ids` queries? Yes, that's true.
The only issue I can see here is that `UPDATE` is the rows/table locking statement, so we will lock a table even if not necessary :thinking:
Do we need this branch? :thinking: All built-in handlers use non-evaluated querysets returned by `related_objects()`, so tests work without it: ```python # update fields for (field, value), instances_list in self.field_updates.items(): updates = reduce(or_, instances_list) updates.update(**{field.name: value}) ```
You're right. Thanks for the clarification :+1:
```suggestion char_value=KeyTextTransform(1, KeyTransform("bar", "value")) ```
I _think_ this one will fail on Postgres at least since `->>` returns text natively. ```suggestion char_value=KeyTextTransform(1, KeyTransform("bar", "value")), ```
NVM, I forgot that `KeyTransform` aggregated instances of `KeyTransform` independently of their actual types https://github.com/django/django/blob/aed60aee38215e293d6ec2f3c96ec55bb9a62fc2/django/db/models/fields/json.py#L321-L323
Using `self._state.db` will prevent `db_for_write` fallback and crash if the object was retrieved from a read-only replica. https://github.com/django/django/blob/e9fd2b572410b1236da0d3d0933014138d89f44e/django/db/models/query.py#L877-L880 https://github.com/django/django/blob/e9fd2b572410b1236da0d3d0933014138d89f44e/django/db/models/query.py#L1764-L1769
I have to admit that this still feels a bit odd to me 🤔 Especially since the tests above are expecting the initial value to be None, and we are perhaps lacking a bit of explanation why this is the case here.
Ticket number is unnecessary.
```suggestion self.assertIs(formset.is_valid(), True) ```
Hey @David-Wobrock — I think I prefer this `try...except` approach. (We're catching a pretty niche error no?) What do you think? (Looks good otherwise.)
Pushed extra tests to the #16015.
`if it encounter` => `if it encounters`
`mentionned` => `mentioned`
Moved to the #16013.
```suggestion self.assertTrue(self.temp_dir.joinpath("path", "to", "test.file").exists()) ```
```suggestion self.assertTrue(self.temp_dir.joinpath(f.name).exists()) ```
```suggestion self.assertIs(self.temp_dir.joinpath(f_name).exists(), True) ```
```suggestion content = app_path.joinpath("apps.py").read_text() ```
```suggestion self.assertTrue(self.temp_dir.joinpath(name).exists()) ```
I don't think we need to have a strict policy on `/` vs. `.joinpath()`. I'd prefer `/` but when readability hurts we can also use `.joinpath()` :shrug:
```suggestion self.temp_dir.joinpath("storage_dir_1").mkdir() ```
I think this is fine, but if building paths with a larger number of components, it's probably better to use `.joinpath()` as it's more costly to call `.__truediv__()` many times than `.joinpath()` once. For example: ```suggestion else Path(conf.__file__).parent.joinpath("project_template", "manage.py-tpl") ```
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
The use of `os.sep` doesn't make sense as this is normalized away by `pathlib`: ```suggestion template_path = custom_templates_dir / "project_template" ```
I think use of [`.joinpath()`](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath.joinpath) to avoid the parenthesis soup would be better here: ```suggestion self.test_dir = Path(tmpdir.name).joinpath("test_project").resolve() ```
This one could do with assigning to a variable: ```suggestion path = base_path / f self.assertTrue(path.exists()) with path.open() as fh: ```
With `os.path.join()` the `""` adds a trailing slash, but that won't happen with `pathlib`. ```suggestion _, err = self.run_django_admin(["startapp", "app", Path("apps") / "app1"]) ```
```suggestion self.assertIs(app_dir.joinpath("apps.py").exists(), True) ```
```suggestion content = app_path.joinpath("apps.py").read_text() ```
You'd made something similar use an f-string elsewhere: ```suggestion PO_FILE = Path(f"locale/{LOCALE}/LC_MESSAGES/djangojs.po") ```
```suggestion *app.split("."), "migrations", "0001_initial.py" ```
Ditto about being pointless, keep `os.path.exists(...)`.
```suggestion copytree(source_code_dir / self.work_subdir, self.test_dir) ```
```suggestion target_dir.joinpath("__init__.py").touch() ```
```suggestion migration_dir.joinpath("0001_initial.py").unlink() migration_dir.joinpath("0002_second.py").unlink() ```
```suggestion self.assertTrue(migration_dir.joinpath("0002_a.py").exists()) ```
```suggestion migration_dir.joinpath("0001_initial.pyc-tpl").rename( ```
```suggestion self.assertTrue(self.temp_dir.joinpath(name).exists()) ```
```suggestion self.assertTrue(tmp_dir.joinpath("unused", "foo.txt").exists()) ```
```suggestion img = Path(__file__).parent.joinpath("test.png").read_bytes() ```
```suggestion image_data = Path(__file__).parent.joinpath("test.png").read_bytes() image_data2 = Path(__file__).parent.joinpath("test2.png").read_bytes() ```
```suggestion self.temp_app_path.joinpath("__init__.py").touch() ```
```suggestion self._clear_filename = temp_dir / "test" / "cleared.txt" self._clear_filename.parent.mkdir() ```
```suggestion cached_files = Path(settings.STATIC_ROOT).joinpath("cached").iterdir() ```
```suggestion self.assertTrue(tmpdir.joinpath("1").is_file()) self.assertTrue(tmpdir.joinpath("2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "2").is_file()) ```
You're welcome. Hmm, I see. From my perspective, firstly I think that the extra parentheses make it less readable if another call is then chained. Secondly, using `/` and `.joinpath()` both call `.make_child()` under the hood, but using `.joinpath()` can combine many parts whereas `/` can only handle one. The call overhead for building long paths is not insignificant. In general, using `/` is fine for most cases where it doesn't overly affect readability or performance.
```suggestion Path("locale").joinpath("_do_not_pick").mkdir() ```
The slashes are stripped off by `pathlib`: ```suggestion STATIC_ROOT=self.test_dir / "static", MEDIA_ROOT=self.test_dir / "media_root", ```
The slashes are stripped off by `pathlib`: ```suggestion STATIC_ROOT=self.test_dir / "static", MEDIA_ROOT=self.test_dir / "media_root", ```
```suggestion files = sorted(self.storage_dir.joinpath("dotted.path").iterdir()) self.assertFalse(self.storage_dir.joinpath("dotted_.path").exists()) ```
```suggestion files = sorted(self.storage_dir.joinpath("dotted.path").iterdir()) self.assertFalse(self.storage_dir.joinpath("dotted_.path").exists()) ```
It's questionable whether this one is worth the change. If we're not building/manipulating the path, then we may as well stick with the `os.path` functions.
Again, the `os.sep` bit here will be stripped off when passed to `Path()`: ```suggestion cwd_prefix = os.curdir ``` It's probably worth reviewing this whole section.
Ditto regarding this change being a bit pointless as we're not modifying the path object.
```suggestion context["widget"]["attrs"].setdefault("disabled", False) ```
@iurisilvio Do you have time to keep working on this? If not I can push edits according to the https://github.com/django/django/pull/15993#discussion_r954605502.
```suggestion # Use a sentinel rather than None, as which() returns None when not found. ```
```suggestion # from the templates can sneak into the path. ```
```suggestion # The not-provided sentinel is distinct from None, as which() returns None when not found ```
Nitpicky: but I find it more readable when the name starts with the verb when the function returns a boolean. ```suggestion def is_field_selected(field): ```
This should raise a `ValueError`.
Right, maybe _"lookup must contains key or index transforms."_ :thinking: .
```suggestion self.assertSequenceEqual(qs1, [self.objs[7]]) ```
```suggestion self.assertSequenceEqual(qs2, [self.objs[4]]) ```
```suggestion raise ValueError("lookup cannot be empty.") ```
I'd prefer not to use `mock` and check generated SQL instead. Also, `Category` doesn't have `natural_key()` so it works with `XML` serializer even when optimization is not use. Maybe: ```python def test_serialize_only_pk(self): with self.assertNumQueries(5) as ctx: serializers.serialize( self.serializer_name, Article.objects.all(), use_natural_foreign_keys=False, ) categories_sql = ctx[1]["sql"] self.assertNotIn(connection.ops.quote_name("meta_data_id"), categories_sql) meta_data_sql = ctx[2]["sql"] self.assertNotIn(connection.ops.quote_name("kind"), meta_data_sql) def test_serialize_no_only_pk_with_natural_keys(self): with self.assertNumQueries(5) as ctx: serializers.serialize( self.serializer_name, Article.objects.all(), use_natural_foreign_keys=True, ) categories_sql = ctx[1]["sql"] self.assertNotIn(connection.ops.quote_name("meta_data_id"), categories_sql) # CategoryMetaData with natural_key(). meta_data_sql = ctx[2]["sql"] self.assertIn(connection.ops.quote_name("kind"), meta_data_sql) ```
We should add the same to the `django.core.serializers.xml_serializer.Serializer.handle_m2m_field`.
Please revert unrelated blank line. ```suggestion ```
> in In.get_prep_lookup and Exact.get_prep_lookup , still there was no failed testcase for this branch. Should I push those changes too? Let's leave it for a separate clean-up.
> You test effectively fails against main but passes against this branch without any further changes. It also passes if we remove the changes in RelatedIn.get_prep_lookup that this thread is attached to. True, so it's a proper regression test for `In()` lookup, and at the same time using `set_values` is not necessary for this to work.
Why? IMO they are affected by exactly the same issue, e.g. ```python long_books_qs = ( Book.objects.filter( pages__gt=400, ) .annotate(book_annotate=Value(1)) .alias(book_alias=Value(1)) ) Book.objects.filter(pk__in=long_books_qs) ```
Should we do the same in `In` and `Exact` lookups? i.e. use `set_values()` instead of ```python self.rhs.clear_select_clause() self.rhs.add_fields(["pk"]) ```
~~I moved casting to strings to `constraints` because `column_sqls` are always strings.~~
@shangxiao Do you have time to keep working on this? If not, I can push final bits (release notes, docs warning for Oracle, and update the feature flag name).
`BOOLEAN` data type is generally not supported in SQL on Oracle, that's why you cannot compare `BOOLEANS` to anything. However it's possible when wrapped with `CASE ... WHEN`. The main issue is that check constraints handle `NULL` in a special way, i.e. ``` > SELECT CASE WHEN NULL > 30 THEN 1 ELSE 0 END FROM DUAL 0 ``` but check constraints with the same are not violated. Maybe: `supports_comparing_boolean_expr` :thinking:
This won't work in many cases on Oracle :disappointed:
The following should work ```python query.add_q(Q(Coalesce(self, True, output_field=BooleanField()))) ```
@shangxiao thanks for the investigation on Oracle. Another alternative worth considering is doing something along the lines of (assuming we added the `supports_coalesce_condition` feature flag) ```suggestion if connections[using].features.supports_coalesce_condition: check = Q(Coalesce(self, True, output_field=BooleanField())) else: check = self | Q(IsNull(self, True)) query.add_q(check) ``` I don't have Oracle setup to figure out if this works but it seemed like it should from reading a few resources online.
If `Q(IsNull(self, True))` doesn't work then surely `Exact(Case(When(Q(IsNull(self, True)), 1)), 1)` will.
```suggestion query.add_annotation(Value(1), "_check") ```
`ordering_params` are overwritten and are not used anywhere :thinking: As far as I'm aware, we should add them to `params` ```suggestion ordering_sql, ordering_params = self.compile(ordering) ordering_sqls.append(ordering_sql) params.extend(ordering_params) ```
```suggestion formset = ArticleFormSet(form_kwargs={"empty_permitted": False}) ```
This docstring is unnecessary ```suggestion ```
IMO checking how `empty_form` is rendered is not necessary. It's enough to check `empty_permitted`, e.g. ```suggestion self.assertIs(formset.empty_form.empty_permitted, True) ```
Would not it be better to check this at the very beginning and return `None` or `""` immediately? ```python def format( ... ): if not str_number: return str_number use_grouping = ( use_l10n or (use_l10n is None and settings.USE_L10N) ) and settings.USE_THOUSAND_SEPARATOR ... ```
add also assertion for `None`: ```suggestion self.assertEqual(nformat("", "."), "") self.assertIsNone(nformat(None, ".")) ```
I'm not sure if it's an acceptable solution. I'm afraid of introducing a performance regression :chart_with_upwards_trend: as it basically creates an empty dictionary and `related_managers_cache` variable for all newly created objects, regardless of having or not cached managers.
The main difference is that `NewSupplier` inherits a `ManyToManyField`.
I pushed extra tests to #16135.
```suggestion # Avoid circular imports. ```
We can use `{x for x in ...}` instead of `set(x for x in ...)`: ```suggestion f_references = {expr.name for expr in self.flatten() if isinstance(expr, F)} q_references = { child[0].split(LOOKUP_SEP)[0] for expr in self.flatten() if isinstance(expr, Q) for child in expr.children if isinstance(child, tuple) } ```
It also needs to account about usage of boolean expressions such as lookups (e.g. `Q(Exact('field', 134))`); not all rhs are tuples of the form `(lookup: str, value: Any)` as `Q.__init__(*args)` also ends up in `Q.children`. https://github.com/django/django/blob/a69b0e9cfe0af7cd2deaf55c069453c4c4598604/django/db/models/query_utils.py#L48-L50
> Nice so if constraints must use F that makes things easier. Right you can likely use a similar walk based on `hasattr(expr, "flatten")` with `isinstance(expr, F)` checks.
I thin we should rename this to `referenced_base_fields` or something along these lines to denote that only root/base field names are returned and not the ones included in JOINs. This is only usable by `Constraint` because it's not possible to reference outer model fields through them.
[`PermissionError`](https://docs.python.org/3/library/exceptions.html#PermissionError) only corresponds to `errno.EACCES`, `errno.EPERM` is there a reason to inspect the `errno`? :thinking:
In practice this may again fail with a `PermissionError`. This might happen if the mount maps users in suboptimal ways. So after copying the file you'd no longer have the rights to change it at all. To keep backwards compatibility we'd still might want to ignore the `EPERM` here.
```suggestion AggregateTestModel.objects.values_list(ArrayAgg("integer_field")), [([0],), ([1],), ([2],), ([0],)], ```
We don't need new objects for this tests, it's enough to use objects created in `TestGeneralAggregate.setUpTestData`. ```suggestion ```
What do you think about assigning `has_lookups` to the `transform_function` and be more explicit here? ```suggestion and not getattr(transform_function, "has_lookups", False) ``` and ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index 7e43ec254d..58ccb8f923 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1820,6 +1820,7 @@ class Query(BaseExpression): final_transformer = functools.partial( transform, name=name, previous=final_transformer ) + final_transformer.has_lookups = True # Then, add the path to the query's joins. Note that we can't trim # joins at this stage - we will need the information about join type # of the trimmed joins. ```
Revert unrelated change.
As far as I'm aware, assigning variables to functions is not sth unusual :thinking: > If you're happy to do this I can squash everything down - or if you wanted to do it Please do. Also, `has_transforms` is probably more accurate than `has_lookups`.
Arf, this is also not optimal either. `pre_save` can have side-effects, like `django.db.models.fields.files.FileField.pre_save` does 😕 We probably don't want to trigger those here. I mean, serendipitously it would work for the `FileField` because even if the returned value is still the same (so we don't add the `field.name` to `updated_fields`), we actually triggered the side-effect committing the file 😂 However, that seems pretty brittle 😅 I'm not sure what the cleanest/Djangoest approach would be here 🤔 We could add an attribute on the Field class, like `Field.has_pre_save: bool`, but that creates a precedent and users/libs must update their code accordingly. But at least, we would know _for sure_ which fields need to be added and which don't. Any other suggestion is very welcome!
`test_mti_update_non_local_concrete_fields` works without the patch, so we should move it to a separate commit.
:thinking: ```suggestion defaults=defaults, ```
Maybe :thinking: ```suggestion if not ( field.primary_key or field.__class__.pre_save is Field.pre_save ): ``` according to de Morgan's laws.
Negation is unnecessary here so I would simplify this a bit: ```suggestion self.assertEqual(Book.objects.annotate(has_pk=Q(pk__isnull=False)).count(), 6) ```
```suggestion self.assertEqual( ```
```suggestion self.assertEqual( ```
This should be a `WeakValueDictionary` as in django-auto-prefetch: https://github.com/tolomea/django-auto-prefetch/blob/0daee9c12f613542cd2d71c8c5d921a63a24869f/src/auto_prefetch/__init__.py#L102 I believe @tolomea made the change to handle the case where a queryset returns duplicate objects, and there was some kind of garbage-collection race condition bug (?) that occurred occasionally. Not sure if [this test](https://github.com/tolomea/django-auto-prefetch/blob/0daee9c12f613542cd2d71c8c5d921a63a24869f/tests/test_basic.py#L149-L171) covers the issue.
when changing to a `WeakValueDictionary`, this could be made into an empty immutable mapping with [`MappingProxyType`](https://adamj.eu/tech/2022/01/05/how-to-make-immutable-dict-in-python/) (maybe) or just a normal dict
I think the list of weakrefs is fine. But specific tests would definitely be good. The problem I had way back when was I used a WeakSet, since Django hashes model instances on PK when a queryset had duplicate entries only one would end up in the WeakSet, the others would fall out, but still have peers set. My fix was using WeakValueDict keyed off `id(peer)`, but I think list of weak refs also works.
+1 for an all-or-nothing policy.
The main question is about the expected behavior. Should we instead rollback all changes when an error appears? :thinking: (\cc @carltongibson @vzima) i.e. ```python with transaction.atomic(using=router.db_for_write(self.model)): for form in formset.forms: ... ```
Deprecated `assertEquals` should be `assertEqual`.
I think partial updates is tricky thing to get right. How do we indicate to the user which rows were successfully updated and which not? I think for a simple first-addition the top-level transaction is more appropriate
> +1 for an all-or-nothing policy. +1 from me too. @Shubh1815 Please update the patch.
Do we need to mock `log_change()`? Should not be reachable when raising a database error in `save_related()`.
> So, should I only mock `log_change()`, as it would execute the last database query in the transaction? Makes sense to me.
This change looks unrelated :thinking: Please revert.
This change looks unrelated :thinking: Please revert.
```suggestion self.assertContains(response, '<nav aria-label="Breadcrumbs">') ```
```suggestion self.assertNotContains(response, '<nav aria-label="Breadcrumbs">') ```
`%`-formatting is called anyway: https://github.com/django/django/blob/f71b0cf769d9ac582ee3d1a8c33d73dad3a770da/django/db/models/expressions.py#L965 Do you think an extra value can cause a performance regression? :thinking: I was thinking about readability.
Trailing zeros are stripped on PostgreSQL, so I changed to ```suggestion self.assertRegex(now_string, rf"^.*\.\d{{1,{precision}}}") ```
I moved arguments to the `extra_context` to avoid escaping `%`.
Missed whimsy: if Black didn't normalize it to 'rf', this could be a 'fr', or French string.
Could be a little more precise by using exactly 3 or 6, not between 3 and 6 ```suggestion self.assertRegex(now_string, r"^.*\.(\d{3}|\d{6})") ```
Should we also clarify a `help` for the `--check` argument? (as suggested in #15845 for the `migrate` command). For example: ```python help="Exit with a non-zero status if model changes are missing migrations and doesn't actually write new migrations.", ```
We don't need to catch `in`, `out`, or `err` here. Removed.
As far as I'm aware more changes are needed, e.g. ```diff diff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py index d98072c66e..f898f7f342 100644 --- a/django/core/management/commands/migrate.py +++ b/django/core/management/commands/migrate.py @@ -237,22 +237,24 @@ class Command(BaseCommand): self.stdout.write(" No migrations to prune.") plan = executor.migration_plan(targets) - exit_dry = plan and options["check_unapplied"] - + check_unapplied = options["check_unapplied"] + if check_unapplied and not plan: + return if options["plan"]: self.stdout.write("Planned operations:", self.style.MIGRATE_LABEL) if not plan: self.stdout.write(" No planned migration operations.") - for migration, backwards in plan: - self.stdout.write(str(migration), self.style.MIGRATE_HEADING) - for operation in migration.operations: - message, is_error = self.describe_operation(operation, backwards) - style = self.style.WARNING if is_error else None - self.stdout.write(" " + message, style) - if exit_dry: - sys.exit(1) + else: + for migration, backwards in plan: + self.stdout.write(str(migration), self.style.MIGRATE_HEADING) + for operation in migration.operations: + message, is_error = self.describe_operation(operation, backwards) + style = self.style.WARNING if is_error else None + self.stdout.write(" " + message, style) + if check_unapplied: + sys.exit(1) return - if exit_dry: + if check_unapplied and plan: sys.exit(1) if options["prune"]: return ```
This is not a regression test as it works without the patch. You need to first have a database that is up to date, e.g. ```python @override_settings( INSTALLED_APPS=[ "migrations.migrations_test_apps.migrated_app", ], ) def test_migrate_not_reflected_changes_with_check(self): out = io.StringIO() try: call_command("migrate", "migrated_app", verbosity=0) call_command("migrate", "migrated_app", stdout=out, no_color=True, check_unapplied=True) self.assertEqual(out.getvalue(), "") finally: call_command("migrate", "migrated_app", "zero", verbosity=0) ```
I don't thinks it's a proper patch, `--check` should return when all migrations are applied, not raise a `SystemExit`.
Can we also test a conditional annotation? e.g. ``` .annotate(is_x_positive=Case(When(x__gt=0, then =True), default=False)).filter(is_active=~F('is_x_positive')) ```
Right, the check would need to happen at `NegatedExpression.resolve_expression` time to be effective. Maybe better to not be to restrictive for now.
I do realize that I'm late to the party and I was the one who suggested the introduction of `NegatedExpression` in the first place but I now wonder if simply returning `Q(self, _negated=True)` could have served the same purpose here.
This behaves quite unexpected with database functions on some databases (SQLite or MySQL). For example: `~ExtractYear("start_datetime")` crashes on PostgreSQL but returns `False` on SQLite and MySQL :open_mouth: I'm not sure if we can and should do anything about it :thinking:
_Gut feeling_ says that this ought to be a _clone_, so as not to leak the _original_ (un-negated) mutable expression out. e.g something like: ``` return self.expression.copy() ``` Currently you've got a test for `self.assertEqual(~~c, c)` which I would _guess_ (reading the diff only) would also pass with `assertIs` where I presume it oughtn't.
Yes, but it's an unrelated change for a backport to a release branch... 😬
I can have a look after lunch @adamchainz — thanks for your work! 🏅
TBH I'm struggling to come up with a test any more sophisticated that the already existing `test_debug_mode_flag_overrides_settings`... ``` with self.settings(DEBUG=False): runner = DiscoverRunner(verbosity=0, interactive=False, debug_mode=True) self.assertTrue(runner.debug_mode) ``` The trouble is it's just a pass through param... 🤔
I reverted to kwargs for this PR (to be back ported) Your point makes sense, so if you want to follow-up on main that's great.
For `main` we could maybe pull this fragment into a decorator to be applied both here and in `options()`. 🤔 (In a separate PR.)
No need for subclassing here. Maybe we should define `django.db.models.sql.compiler.__all__ = ('SQLCompiler', ...)` here and simply change this one to ```suggestion from django.db.models.sql import compiler from django.db.models.sql.compiler import * ```
This is ugly but I can't think of another way of doing that.
No sure about which parts should remain in `Q.checks` instead. Current separation seems relatively good but I'd be curious about input from others.
```suggestion class SQLCheckCompiler(compiler.SQLCheckCompiler): ```
Django coding standards prevent non-trivial f string interpolation I'm afraid 🙂 … (although tests might be another story and Carlton may be ok with it)
Please chop the ticket number from the test method name.
Yes, f-strings should use only plain variable and property access as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
sss :snake: ```suggestion password_help_text = form.fields["password"].help_text ```
No, here the f-string contains only property access, so it's fine.
Just got a typo here 😁 ```suggestion # assert joined_url and pw_change_url are identical ```
On second thoughts creating a URL with to_field isn't required to test this issue – so the string interpolation can simply be removed: ```suggestion admin_user_change_url = reverse( "admin:%s_%s_change" % (user._meta.app_label, user._meta.model_name), args=(user.username,), ) ```
Lastly we should mention what the specific issue is about the link in the helptext 🙂 ```suggestion def test_bug_34066_link_to_password_reset_in_helptext(self): # The password reset link should always refer to the primary key even when accessed via a to_field ```
~I think you should leave the setting in the test as it's part of what behaviour changes you'd requested in the ticket right? 🤔~ ~ie make sure with setting "de" it still returns None…~ actually nvm asserting against the default is probably enough "coverage" 🤷‍♂️
Did Black add this? 🤔 (Usually better to leave out miscellaneous whitespace changes if not)
```suggestion "addr": addr, ```
So if we were going to be strict about var naming, then technically `ipv4_addr` _could_ be an ipv6 addr. Little things like this are usually better to clean up because you never know what may happen to this code in the future. Maybe let Felixx or Carlton have the final say but imho it would be cleaner to move the logic away from the dictionary literal: ```suggestion if self.addr == "0": addr = "0.0.0.0" elif self._raw_ipv6: addr = "[%s]" % self.addr else: addr = self.addr ```
```suggestion *, headers=None, ```
As I wrote below for `generic()`, good idea to make the new arg kwarg-only ```suggestion def __init__(self, *, json_encoder=DjangoJSONEncoder, *, headers=None, **defaults): ```
```suggestion cls.to_wsgi_name(header_name): value ```
Put this above `to_wsgi_names()` to keep the methods that act on multiple headers together.
again, only used in one place, inline it
Since this is a new arg, we can enforce kwarg-only on it: ```suggestion *, headers=None, ``` (in all places) I think this is a good idea to avoid overly long positional argument lists
I think we can avoid creating a temporary var here ```suggestion self.defaults.update(self._transform_headers(headers) ```
Not sure whether it's worth having a `to_asgi_name()` for completeness? 🤔
Now that I've been looking at the ASGI equivalent below, I feel that we should perhaps call this `to_wsgi_name()` instead... Also, for this helper method we're only using it in one place and I think we could push that loop in here and call it `to_wsgi_names()` instead (or provide that in addition).
And then this would become: ```python extra.update(HttpHeaders.to_asgi_names(headers)) ```
We can reuse the `Student` model.
I added a temporary storage.
This hook is unnecessary you can reuse `has_native_uuid_field`, e.g. ```python class DatabaseFeatures(BaseDatabaseFeatures): ... @cached_property def has_native_uuid_field(self): return self.connection.mysql_is_mariadb and self.connection.mysql_version >= (10, 7) ``` ```python class DatabaseWrapper(BaseDatabaseWrapper): ... @cached_property def data_types(self): return { ..., "UUIDField": "uuid" if self.features.has_native_uuid_field else "char(32)", } ```
This hook is unnecessary we can use the ternary.
The test name method is self-explanatory, I'd remove the docstring. ```suggestion ```
```suggestion _, err = self.run_django_admin(args) self.assertNoOutput(err) ```
```suggestion try: import hashlib scrypt = hashlib.scrypt except AttributeError: scrypt = None ```
```suggestion # scrypt requires OpenSSL 1.1+. ```
```suggestion if query_string := request.GET.urlencode(): redirect_url += f"?{query_string}" ```
Creating two objects should not be necessary. ```suggestion ```
I guess we could use `DEFAULT_DB_ALIAS` here as well ```suggestion r"COMMIT; alias=%s" % DEFAULT_DB_ALIAS, ```
I guess we could use `contextlib.suppress` as well as that's not what we're actually testing. No strong opinion though.
Ditto about the two objects creation ```suggestion ```
We usually prefer `assertIs` here as it will also catch issues with an invalid return type ```suggestion self.assertIs(is_open, False) ```
We should also assert that the connection in the parent/current process remains usable. ```suggestion self.assertIs(connection.is_usable(), True) ```
I think you can avoid most of the boiler plate here by using the pool as a context manager. ```suggestion with multiprocessing.Pool(1) as pool: is_open = pool.apply(connection_is_open) ```
This can be dropped since `connection` is already imported in the context of the module. ```suggestion ```
Thanks for the patch @Giebisch, I think we should adjust the `expected_outputs` instead to be properly formatted in order to ensure formatting is actually used. https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L90-L111 https://github.com/django/django/blob/78657a201308a0b53661e2b267914407a9fd7fa1/tests/test_runner/test_debug_sql.py#L124-L133 The adjustments made make the tests pass with and without the proposed changes.
password1 and password2 are required form fields, so I'm wondering whether the empty/None check here is superfluous? 🤔
