I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
This logging statement has a `[{}]` but no argument to fill it
Out of curiosity, could we do all the types in parallel instead of blocking and waiting for each type to complete before moving to the next type? (It's probably out of scope for this PR, but I'm wondering for a future enhancement)
it seems that the latch is useless? or maybe you wanted to enable the recovery half way through the "indexing operations"? Also, this suffers from the same racing condition - if the ops that are now in flight when the relocation comes in are not first in the onLockAcquiredActions list, we will have a deadlock.
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
It should be public as it will be used in `producer` APIs.
I believe it should be `success, rx, tx, rtt = parse_ping(ping_results_list[-1])`
I'm not entirely sure it is required to have the FIPS checks implement an interface, but if we go down this path ,I think that conceptually it would make more sense to have a `FIPScheck` interface that all the relevant checks ( settings, password hash etc. ) would then implement.
it's a shame java need this...
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
It seems this still needs to be executed for `minReceivedMetadataVersion >= 2`
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
good point.... we should be able to get rid of it.
Add the `@Overrride` annotation to this method.
nit: remove empty link
Add the `@Overrride` annotation to this method.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
nit: remove empty link
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
typo: The title of the last column should be `DELETE_SEGMENT_FINISHED`.
```{@link org.apache.kafka.common.KafkaFuture#get}``` => ```{@link org.apache.kafka.common.KafkaFuture#get()}```
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
nit: remove extra line
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
`containsAlias` will throw an exception if you call it on a `KeyStore` that hasn't been initialised. I think you could test the exception handling with the following: ``` KeyStore keyStore = KeyStore.getInstance("JKS"); assertThatThrownBy(() -> SslUtils.assertStoreContainsAlias(keyStore, "alias")) .isInstanceOf(IllegalStateException.class) .hasMessage("Could not determine if keystore contains alias 'alias'").hasCause(keyStoreEx); ```
As the alternative is to change the mock maker for the whole project, I'd prefer to load an actual `KeyStore`.
Unnecessary extra space.
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
This should be the only method with actual code. All other overloads should call this one.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
This should be the only method with actual code. All other overloads should call this one.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
Another reason for having these classes in common (i.e. KAFKA-5265) is that they can potentially be used by the Authorizer interface when we move it to Java.
Actually we could go crazy and add couchbase to the list.
The current implementation provides a view onto the keys of the underlying map so its contents may change if an indicator is (un)registered.
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
@guozhangwang **Forgive me if I misunderstood this method, really**. But if the list is composed of key-value pairs, wouldn't this for loop goes up to the the middle of the array? Plus, if `tags` is `"a","1","b","2"` the final map will be `"a" -> "1", "1" -> "b"`. Is this the right intend? Besides not reaching "b" -> "2", it will make the previous value a key in the next iteration. If not, I suppose we could rewrite it as ``` for (int i = 0; i < tags.length; ) { tagMap.put(tags[i], tags[i+1]); i += 2; } ``` Again, forgive me if I understood everything wrong.
Glad to help! :)
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I wonder if we should resolve things again here. I think we should make it as simple as possible here. Maybe have a Primary request (or use internal request) which has the shardid already built into it. All we need to do in the action is lookup the index shard, see that we have it and do our thing.
I'm not sure this does what you want? it blocks the thread handling the request. Maybe use latches here to signal events and control the disruption from the test? I think it will also be clearer to read.
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
The current implementation provides a view onto the keys of the underlying map so its contents may change if an indicator is (un)registered.
There is a built-in for this `Function.identity()`
nit: 'else' can be dropped
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
nit. I think there is `.` missing `since 3.0[.] Use`
base -> based progress -> progressed
and -> a
nit add `a {@link Named} config`
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
We should use try-with-resources here (for `DataInputStream`).
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: I would rather use the full name instead of using acronyms.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
nit: We could omit `res` and return directly in the two places below.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
nit: We could omit `res` and return directly in the two places below.
this file can go back to 140 chars as well...
Nit: `automattic` -> `automatic`
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
This isn't thread-safe
This isn't thread-safe
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
Why is `completed` count being tracked? It doesn't seem to be used anywhere.
Which future? Did you mean `Event`. I assume that `deadlineNs` is the deadline for scheduling/executing the `run` method. The `run` method can take longer than `deadlineNs`.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
We should use try-with-resources here (for `DataInputStream`).
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
This isn't thread-safe
This isn't thread-safe
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
this file can go back to 140 chars as well...
Nit: `automattic` -> `automatic`
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
We should use try-with-resources here (for `DataInputStream`).
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
This may indicate a bug in `SessionWindowedDeserializer`
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
There a two independent configs for the list-type and inner-type, hence it might be better to handle both independently: ``` if (listClass == null) { String listTypePropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_DESERIALIZER_TYPE_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_DESERIALIZER_TYPE_CLASS; listClass = (Class<List<Inner>>) configs.get(listTypePropertyName); if (listClass == null) { throw new ConfigException("Not able to determine the list class because it was neither passed via the constructor nor set in the config"); } } if (inner == null) { String innerDeserializerPropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_SERIALIZER_INNER_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_SERIALIZER_INNER_CLASS; Class<Deserializer<Inner>> innerDeserializerClass = (Class<Deserializer<Inner>>) configs.get(innerDeserializerPropertyName); inner = Utils.newInstance(innerDeserializerClass); inner.configure(configs, isKey); } ```
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
We should use try-with-resources here (for `DataInputStream`).
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Should we also check that ``` final long start = SessionKeySerde.extractStart(bytes.get()); final long end = SessionKeySerde.extractEnd(bytes.get()); return end >= from && start <= to; ``` Although the current impl of RocksDBWIndowStore naturally checked that for us, it does not guarantee all underlying store impls guarantee that.
This is a slightly different test. The window is much larger to ensure all the entries are in the same window and the last timestamp for (a, 0005) is such that it causes the resuling composite key to come after the one for (aa, 0004)
@guozhangwang @dguy we cannot guarantee that all the entries for one key will necessarily precede the entries for the next key. The following code still fails with this patch, and only returns `0001` and `0003`, since the key for `("a", "0005")` will come after the key for `("aa", "0004")` ``` final RocksDBWindowStoreSupplier<String, String> supplier = new RocksDBWindowStoreSupplier<>( "window", 0x7a00000000000000L, 2, true, Serdes.String(), Serdes.String(), 0x7a00000000000000L, true, Collections.<String, String>emptyMap(), false); windowStore = supplier.get(); windowStore.init(context, windowStore); windowStore.put("a", "0001", 0); windowStore.put("aa", "0002", 0); windowStore.put("a", "0003", 1); windowStore.put("aa", "0004", 1); windowStore.put("a", "0005", 0x7a00000000000000L - 1); final List expected = Utils.mkList("0001", "0003", "0005"); assertThat(toList(windowStore.fetch("a", 0, Long.MAX_VALUE)), equalTo(expected)); ```
Should we also check that ``` final long start = SessionKeySerde.extractStart(bytes.get()); final long end = SessionKeySerde.extractEnd(bytes.get()); return end >= from && start <= to; ``` Although the current impl of RocksDBWIndowStore naturally checked that for us, it does not guarantee all underlying store impls guarantee that.
This is a slightly different test. The window is much larger to ensure all the entries are in the same window and the last timestamp for (a, 0005) is such that it causes the resuling composite key to come after the one for (aa, 0004)
@guozhangwang @dguy we cannot guarantee that all the entries for one key will necessarily precede the entries for the next key. The following code still fails with this patch, and only returns `0001` and `0003`, since the key for `("a", "0005")` will come after the key for `("aa", "0004")` ``` final RocksDBWindowStoreSupplier<String, String> supplier = new RocksDBWindowStoreSupplier<>( "window", 0x7a00000000000000L, 2, true, Serdes.String(), Serdes.String(), 0x7a00000000000000L, true, Collections.<String, String>emptyMap(), false); windowStore = supplier.get(); windowStore.init(context, windowStore); windowStore.put("a", "0001", 0); windowStore.put("aa", "0002", 0); windowStore.put("a", "0003", 1); windowStore.put("aa", "0004", 1); windowStore.put("a", "0005", 0x7a00000000000000L - 1); final List expected = Utils.mkList("0001", "0003", "0005"); assertThat(toList(windowStore.fetch("a", 0, Long.MAX_VALUE)), equalTo(expected)); ```
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I don't think it's necessary to warn in this case. Maybe debug, but not warn. If callers are concerned, they can check the parameters before calling the method.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
We should use try-with-resources here (for `DataInputStream`).
this can be replaced by just `ActionListener.wrap(runnable)`
super minor, but indentation is off here
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
make these parmaters to this method? then it doesn't really need to know about index creation requests.
We should use try-with-resources here (for `DataInputStream`).
this can be replaced by just `ActionListener.wrap(runnable)`
super minor, but indentation is off here
In cases like this, it's probably a bit more idiomatic in Connect to use a tertiary operator so that there is a single `return`: ```suggestion return inner == null ? null : usedPluginDesc(inner); ```
I see. Thank you.
Not sure we need this. For instance we don't allow to remove sorts on a SearchRequestBuilder.
I think the unlock calls should always be in a finally block
hehe :) nice one
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
I think the unlock calls should always be in a finally block
hehe :) nice one
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
I think the unlock calls should always be in a finally block
hehe :) nice one
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
grr nevermind I didn't see the last line pfff...
or N times
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
This TODO should be removed
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
This TODO should be removed
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
```throws Exception ``` is useless.
`video_id` literal is not a video id.
`video_id` may be `None`.
```throws Exception ``` is useless.
`video_id` literal is not a video id.
`video_id` may be `None`.
```throws Exception ``` is useless.
`video_id` literal is not a video id.
Who cares about effectiveness when it's broken? With your comparator `'1080' < '720'` that is incorrect.
I've seen alternative solutions floating around that use a configurable source here. Basically, the configuration passed to configure() is consulted to find the "source cluster", rather than looking at the topic name. That approach lets you return an actual source here, which obviates the new canTrackSource() method etc.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
nit: It seems clearer to use `ConsumerPartitionAssignor.class` directly below.
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
This should be 2.7 please.
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
This should be 2.7 please.
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
This should be 2.7 please.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
nit: we could define this transition list in a variable to be reused.
This TODO should be removed
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
no need to use `this.` outside the constructor. Here and below
nit: We could omit `res` and return directly in the two places below.
Might be simpler to just update the Jira and do all at once? > Any thought about how the prefix text should look like? The suggestion you made via wrapping one `IllegalArgumentException` with the other, was good. Just you proposed "outer" error message could be used to be passed in as prefix.
> I felt the same, but I picked this approach to make less changes in the code, since I am beginner here. That's fair. However, we should not "optimize" for fewer changes but for better code. :) > But, I need to give a thought on kind of prefixes we should use to make it unique for various fail cases. `validateMillisecondDuration()` will just add the prefix. Each called can pass in whatever prefix is suitable for it.
why we don't we fail early in case hosts is empty? I see that the length check has been moved below
Sorry, my example included this initializer but it isn't needed. This is just for information: we can tidy up my mistake when we merge your changes.
I think `kafkaOffset` was incorrectly changed to `Long`. We'll always have a Kafka offset, so it should be `long`. Also, the current version breaks compatibility since the old signature constructor is no longer available.
nit: remove `which is`
Sorry, my example included this initializer but it isn't needed. This is just for information: we can tidy up my mistake when we merge your changes.
I think `kafkaOffset` was incorrectly changed to `Long`. We'll always have a Kafka offset, so it should be `long`. Also, the current version breaks compatibility since the old signature constructor is no longer available.
nit: remove `which is`
Might be simpler to just update the Jira and do all at once? > Any thought about how the prefix text should look like? The suggestion you made via wrapping one `IllegalArgumentException` with the other, was good. Just you proposed "outer" error message could be used to be passed in as prefix.
> I felt the same, but I picked this approach to make less changes in the code, since I am beginner here. That's fair. However, we should not "optimize" for fewer changes but for better code. :) > But, I need to give a thought on kind of prefixes we should use to make it unique for various fail cases. `validateMillisecondDuration()` will just add the prefix. Each called can pass in whatever prefix is suitable for it.
why we don't we fail early in case hosts is empty? I see that the length check has been moved below
Even if the number of sub aggregation is expected to be small, I'm not too happy with the use of `ListIterator.add` which is linear on array lists.
I think ``` java if (prevParentDoc == -1) { childDocId = childDocs.nextDoc(); } else { if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc); } } ``` could just be replaced with ``` java if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc + 1); } ``` ? (No more check that the previous parent doc is -1, and advance to `prevParentDoc+1` instead of `prevParentDoc`)
Where do you cleanup the childrenSensors object? Otherwise we will maintain a reference to the Sensor objects always.
What do you think of: ``` private void handleReadResponse(long from, int maxOperationCount, long maxRequiredSeqNo, ShardChangesAction.Response response) { maybeUpdateMapping(response.getIndexMetadataVersion(), () -> { synchronized (ShardFollowNodeTask.this) { globalCheckpoint = Math.max(globalCheckpoint, response.getGlobalCheckpoint()); final long newMinRequiredSeqNo; if (response.getOperations().length == 0) { newMinRequiredSeqNo = from; } else { assert response.getOperations()[0].seqNo() == from : "first operation is not what we asked for. From is [" + from + "], got " + response.getOperations()[0]; buffer.addAll(Arrays.asList(response.getOperations())); final long maxSeqNo = response.getOperations()[response.getOperations().length - 1].seqNo(); assert maxSeqNo== Arrays.stream(response.getOperations()).mapToLong(Translog.Operation::seqNo).max().getAsLong(); newMinRequiredSeqNo = maxSeqNo + 1; // update last requested seq no as we may have gotten more than we asked for and we don't want to ask it again. lastRequestedSeqno = Math.max(lastRequestedSeqno, maxSeqNo); assert lastRequestedSeqno <= globalCheckpoint: "lastRequestedSeqno [" + lastRequestedSeqno + "] is larger than the global checkpoint [" + globalCheckpoint + "]"; coordinateWrites(); } if (newMinRequiredSeqNo < maxRequiredSeqNo) { int newSize = (int) (maxRequiredSeqNo - newMinRequiredSeqNo) + 1; LOGGER.trace("{} received [{}] ops, still missing [{}/{}], continuing to read...", params.getFollowShardId(), response.getOperations().length, newMinRequiredSeqNo, maxRequiredSeqNo); sendShardChangesRequest(newMinRequiredSeqNo, newSize, maxRequiredSeqNo); } else { // read is completed, decrement numConcurrentReads--; if (response.getOperations().length == 0 && globalCheckpoint == lastRequestedSeqno) { // we got nothing and we have no reason to believe asking again well get us more, treat shard as idle and delay // future requests LOGGER.trace("{} received no ops and no known ops to fetch, scheduling to coordinate reads", params.getFollowShardId()); scheduler.accept(idleShardChangesRequestDelay, this::coordinateReads); } else { coordinateReads(); } } } }); } ``` PS - note the difference in handling of `lastRequestedSeqno` - I think the way you had it had a bug.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
> In that case we always make a copy of the underlying array in ArrayList, Not if you change the request and such to use lists. > while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. which may be frequent (i.e., every request), which is why I was considering making a change.
nit: remove the redundant line. Same as below.
`asList` -> `Collections.singletonList`
redundant type arguments `<ProducerRecord<byte[], byte[]`
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
nit: also add java doc for type `T, O` here
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
nit: also add java doc for type `T, O` here
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
nit: also add java doc for type `T, O` here
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
We should add a `null` check to allow closing a deserializer that was not properly setup
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
I had the same thought, but I guess the point is to properly validate things when they get set to the builder, so that non supported values will never be serialized. I assume that we do that already, otherwise we should.
So as far as I see is this is the crucial change in this PR? I was wondering if might have undesired effects that we allow more field value types to be serialized/deserialized than before by using `writeGenericValue`. What would happen for example when fieldValue is a GeoPoint. It would have caused the serialization to trip previously, now it will be okay (and I guess it might cause error later). I guess switching to `writeGenericValue` is a good tradeoff here but would like to hear your ideas about that.
Can this be a `byte`.
OMG `== false`! 
This is assuming that `totalTopics` is always a multiple of `MAX_BATCH_SIZE. Is that always true? Perhaps it is better not to make that assumption in any case.
@cmccabe Since `flush` blocks until all records are sent, wouldn't it be better to compute the delay time after flush completes? Ideally, an async flush would be better to avoid more delay than required, but that would need another thread. Alternative is not to flush at all, since only the records in the last incomplete batch would be delayed when `linger.ms > 0`.
nit: We could omit `res` and return directly in the two places below.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
and -> a
base -> based progress -> progressed
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Yeah, I think it's worth the bit of logic to fail more quickly.
Add the stream task id prefix here as well for both exception message and the warning log entry.
@cmccabe Since `flush` blocks until all records are sent, wouldn't it be better to compute the delay time after flush completes? Ideally, an async flush would be better to avoid more delay than required, but that would need another thread. Alternative is not to flush at all, since only the records in the last incomplete batch would be delayed when `linger.ms > 0`.
Just checking... Is the intent to roll back the "hack" to also catch UnknownProducerId and initiate a rebalance to recover? Note, if this was not the intent, then there are similar catch blocks below.
nit: extra line
It would be nice to have a unit test for this.
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
```suggestion * is {@code null}, no records are emitted. ``` Please also fix this on the original method
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
`limitedTo(long bytes)`? Clone is kinda non-specific.
good catch on delta > 0
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
can we just return here to make it clear that we are baling out? We then don't need the further `if(!initializable.isEmpty())` checks below
+1. All for user readable assertions. If the bytes format is standardized then it should be tested in SubscriptionInfoTest.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
It's a little confusing that this is named newValue, but is sometimes actually priorValue
This TODO should be removed
Not sure what EE is here.
nit: break line
For this specific API, I suspect it is ever commonly used in PAPI, so I'm fine with not supporting it right away, also as a way to encourage users to change code sooner than later, if there's anyone.
hehe :) nice one
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
Nit: we use a single space after a period.
what's a requested topic partition? Also, above we mention just `partition`
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I also wonder if we should only have `Task.java` and have different ctors and if you don't pass a parentID you are not a child task? and default parent id is 0 just like in linux etc.
no need to use `this.` outside the constructor. Here and below
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I also wonder if we should only have `Task.java` and have different ctors and if you don't pass a parentID you are not a child task? and default parent id is 0 just like in linux etc.
no need to use `this.` outside the constructor. Here and below
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
How about this transport configuration that we se to `NettyConnectionFactory`? @wilkinsona mentioned that on the original issue and we'd like some feedback on that.
As far as I can see you did not hence why I am asking here. The code I've referenced makes an explicit setup using `NettyConnectorFactory`. As far as I can see we'd lose that as soon as an url is set.
> That's not accurate. Sorry, poor choice of words. I meant that the auto-configuration doesn't do anything special when a broker url is set while it does something explicit (in code) when a host is set. We're very cautious to not introduce any inconsistency and the reason why I asked you here. Thanks for the follow-up and the feedback !
How about this transport configuration that we se to `NettyConnectionFactory`? @wilkinsona mentioned that on the original issue and we'd like some feedback on that.
As far as I can see you did not hence why I am asking here. The code I've referenced makes an explicit setup using `NettyConnectorFactory`. As far as I can see we'd lose that as soon as an url is set.
> That's not accurate. Sorry, poor choice of words. I meant that the auto-configuration doesn't do anything special when a broker url is set while it does something explicit (in code) when a host is set. We're very cautious to not introduce any inconsistency and the reason why I asked you here. Thanks for the follow-up and the feedback !
`before or after`
`of` -> `or`
nit. I think there is `.` missing `since 3.0[.] Use`
`before or after`
`of` -> `or`
nit. I think there is `.` missing `since 3.0[.] Use`
How about defining two helper methods, one for each cases? * `private void maybeRewrapAndThrow(ExecutionException exception)`; and * `private void maybeRewrapAndThrow(CompletionException exception)`
nit: Would it make sense to move `throw e` into `maybeRewrapAndThrow` to let `maybeRewrapAndThrow` throw in both cases? More generally, I wonder if we could handle all the case in `maybeRewrapAndThrow` and use it everywhere.
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
How about defining two helper methods, one for each cases? * `private void maybeRewrapAndThrow(ExecutionException exception)`; and * `private void maybeRewrapAndThrow(CompletionException exception)`
nit: Would it make sense to move `throw e` into `maybeRewrapAndThrow` to let `maybeRewrapAndThrow` throw in both cases? More generally, I wonder if we could handle all the case in `maybeRewrapAndThrow` and use it everywhere.
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
I think `update the index` could be made clearer since the `DataInput` interface doesn't mention an index. Same for other similar cases.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
It looks like this could fit in 140 columns.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
It might be simpler to add a private constructor that allows to specify all 4 parameters: ``` return new StoreQueryParams<>(storeName, queryableStoreType, partition, staleStores); ``` Similar in other methods
As above -- incorrect return type description
`storeName` -> `state store name` (we should use natural language if possible, and avoid variable names)
It might be simpler to add a private constructor that allows to specify all 4 parameters: ``` return new StoreQueryParams<>(storeName, queryableStoreType, partition, staleStores); ``` Similar in other methods
As above -- incorrect return type description
`storeName` -> `state store name` (we should use natural language if possible, and avoid variable names)
We don't need this for files, right? Just for directories (because of `file.deleteOnExit`)
We should update the Scala `TestUtils` to call this method.
this needs a message
Some of the internal awkwardness seems to be the result of not having a clear "list of classes" type. Not something we have to do here, but potential room for improvement.
ok, I was more worried about the handling to make sure that we don't support stored scripts, but indeed, the rest is just calling Script.parse so it is not a lot of code.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
Some of the internal awkwardness seems to be the result of not having a clear "list of classes" type. Not something we have to do here, but potential room for improvement.
ok, I was more worried about the handling to make sure that we don't support stored scripts, but indeed, the rest is just calling Script.parse so it is not a lot of code.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
Please fix identation.
we need a consolidation of all the score mode / type we have at some point, not here though
nit: extra line
`newMean` & `newVariance` (we don't do underscores in var names)
nit: 'else' can be dropped
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
`newMean` & `newVariance` (we don't do underscores in var names)
nit: 'else' can be dropped
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
No need to check null. We always have to forward oldAgg and newAgg, anyway.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
No need to check null. We always have to forward oldAgg and newAgg, anyway.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think we should call `deserializer.configure(...)` here
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
We should use try-with-resources here (for `DataInputStream`).
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Please get rid of this volatile. There is no longer a circular dependency here.
Minor typo of `local` instead of `locale` in the exception message.
I realize the example already here used this form, but I think it is clearer to use `== false` for inverted conditions.
I think we should fix our datastrucuture first and don't make Path trie super complicated and flexible. This should be fixed first before we make this change here.
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
`.toString()` unnecessary here are other similar logs.
This should also be synchronized
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
`before or after`
`out-of-order` `window closed`
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
It works fine with a runtime exception, you don't need to change the constructor: ``` IllegalArgumentException exc = expectThrows(IllegalArgumentException.class, () -> new NGramTokenizerFactory(indexProperties, null, name, settings).create()); ``` .. and then you can check the message of the exception.
I don't think that we should move this code into the InetAddresses.java source file. That code is from the Guava code base, and is licensed to the Guava authors (see the license header). By moving this code which is not from Guava here we will create a confusing situation with respect to the licensing of the code. Let's take this code to IpFieldMapper.java.
`null` check is redundant as `null instanceof StringDeserializer` will return false anyway.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I looked at it, and I think the scenario is a bit different in `public <T> T getConfiguredInstance(String key, Class<T> t)` as in here, where `Utils.newInstance(Class<T> c)` is called and the passed `Class<?>` is directly from the config, where in this case the config value is a `String` and we directly use that in `Utils.newInstance`.
It actually seems like using the non-deprecated `put` method would improve this test's readability, since the verification depends on specific timestamps having been used in the put.
is this really needed we already have sooo much logging everywhere
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
master is the future 7.0, so I would do the following: ```java if (INDEX_MAPPER_DYNAMIC_SETTING.exists(indexSettings.getSettings())) { if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0)) { // 7.x index throw new IllegalArgumentException("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " was removed after version 6.0.0"); } else { // 6.x index DEPRECATION_LOGGER.deprecated("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " is deprecated since indices may not have more than one type anymore."); } } ``` Then when backporting I'll just remove the 7.x branch and make sure that we only emit a deprecation warning on 6.x indices (you don't need to worry about it).
I don't think so, that's relying too much on an internal implementation detail (that there is a cache, that file scripts are compiled and put into the static cache, that the key is the prefix of the filename, etc.). The purpose behind the PR is to get the script service to ignore hidden files, and that is what needs to be tested. I haven't looked too closely, but I suspect that you're going to have to hook into the script service or maybe the resource watcher and possibly refactor a little bit to expose the pieces needed to in fact make this assertion. Let me know if that's enough to get you started, I'm happy to take a closer look if needed. :)
This test is not really testing what we want to be testing here. The reason that it's not is because the cache key for a file named `".hidden_file"` is not `"hidden_file"`, but rather it is `""`. A file named `".hidden_file"` never would have been processed by the compilation engine because it doesn't have an extension. So this will ultimately throw, but not for the right reason.
So in my updated PR I change this line to line up with CompletableFuture.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
I think the implicit assumption is that the parent "foo" doesn't exist (yet), right? If so, shouldn't we assert that it actually does not exist prior to continuing? Or do we feel `TestUtils.tempDirectory();` is sufficient? (I think it is, but still wanted to ask.)
nit: seems unnecessary? similar for `State.FAILED` below.
nit: curious why `storeType` is not enum but raw string. Typo in `in_memory` could make it `ROCKS_DB` type. e.g. `in_memry`. Maybe it's register in `in(ROCKS_DB, IN_MEMORY),` when defining and checked there
`.toString()` unnecessary here are other similar logs.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
nice fix! this has been bothering me.
Yeah, that's a good point. Scratch that idea.
I originally thought the semantics of unsubscribe() is blacklisting. For example: subscribe("PageView*") unsubscribe("PageViewTopicA") will subscribe to all page-view topics except page-view-A. Arguably this can be done solely in subscribe() with"^" in regex, but I feel this semantics is more natural for users.
You might consider using any `public static` utilities in `ConfigDef`/`AbstractConfig` to help with this here. I know at least `ConfigDef.parseType` could help here since it also does things like trim the string. Reusing that code will keep this closer to the normal behavior of `ConfigDef`s (and if we eventually move this functionality to be part of `ConfigDef` itself, will probably make it a simpler transition).
Do we actually have to mock `generation()` and `rawConfig()` for this test? Looking at `connector()`, it looks like it only relies on the snapshot.
`.toString()` unnecessary here are other similar logs.
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
nit: 'else' can be dropped
The task name is incorrect (copy-paste error). Please, consider introducing a proper task name: ```yaml - name: gather the time at the end of the operation ```
Just curious, could we possibly call this function for the same node more than once? It seems yes as you are checking `!keyChangingOperationsToOptimizableRepartitionNodes.containsKey(node)` here, but I cannot tell from the code...
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
We have dedup in this PR already (line 161-163). The `lastSeenSeqNo` is used for dedup and range check. I am fine to remove the primary sort and dedup mechanism.
I see. I missed it. I think it's surprising to put it in `readDocAsOp` and shortcut. I'd prefer to do it in `next` where do all our state updates and then everything together. it's rare anyway and doesn't require optimization imo. That said, it's all nits. If you prefer it otherwise I'm good. Thanks for clarifying.
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
We have dedup in this PR already (line 161-163). The `lastSeenSeqNo` is used for dedup and range check. I am fine to remove the primary sort and dedup mechanism.
I see. I missed it. I think it's surprising to put it in `readDocAsOp` and shortcut. I'd prefer to do it in `next` where do all our state updates and then everything together. it's rare anyway and doesn't require optimization imo. That said, it's all nits. If you prefer it otherwise I'm good. Thanks for clarifying.
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
space after <`
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
Also, maybe we should assert that `numExceptionReceivedInCallback.get() > 0` if we expect at least one to fail (in theory, if `numSentRecords == 100`, there would be no exceptionReceivedInCallback).
Maybe we can have a numRecords variable for the `100`.
Hmm, I'd just generate the randoms during set-up and add them to an array.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
This has been fixed by: https://github.com/apache/kafka/pull/8291 Please omit and rebase to get the latest changes.
Sounds interesting, cc @kkonstantine
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
This has been fixed by: https://github.com/apache/kafka/pull/8291 Please omit and rebase to get the latest changes.
Sounds interesting, cc @kkonstantine
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
This has been fixed by: https://github.com/apache/kafka/pull/8291 Please omit and rebase to get the latest changes.
Sounds interesting, cc @kkonstantine
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`expectedType.cast(e)` should remove the need for the unchecked suppression.
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`expectedType.cast(e)` should remove the need for the unchecked suppression.
always what? I can't even :)
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
always what? I can't even :)
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
@SinghAsDev @guozhangwang I wonder if we could support blacklist filtering through a second argument to subscribe. For example: ``` java void subscribe(Pattern whitelist, Pattern blacklist); ``` This might get around some of the complexity mentioned above.
Would it have to? I would see each call to subscribe as replacing the previous one. Perhaps if we wanted to support multiple regex subscriptions, we could do: ``` java void subscribe(List<Pattern> patterns); ``` And we could require users to use '^' for blacklisting. This would be consistent with the changes proposed in KAFKA-2388.
Yeah, that's a good point. Scratch that idea.
@SinghAsDev @guozhangwang I wonder if we could support blacklist filtering through a second argument to subscribe. For example: ``` java void subscribe(Pattern whitelist, Pattern blacklist); ``` This might get around some of the complexity mentioned above.
Would it have to? I would see each call to subscribe as replacing the previous one. Perhaps if we wanted to support multiple regex subscriptions, we could do: ``` java void subscribe(List<Pattern> patterns); ``` And we could require users to use '^' for blacklisting. This would be consistent with the changes proposed in KAFKA-2388.
Yeah, that's a good point. Scratch that idea.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
nit: We could omit `res` and return directly in the two places below.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
nit: We could omit `res` and return directly in the two places below.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
```suggestion serial_port=dict(type='int', required=True), ```
If we change the definition of the available memory here, we may have to change a few other places as well. e.g. `deallocate()`, `unallocatedMemory()`, etc.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
Right, sorry I misread that line.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
```suggestion serial_port=dict(type='int', required=True), ```
Update return type to `L` (if we introduce `L`)
We should use try-with-resources here (for `DataInputStream`).
Update return type to `L` (if we introduce `L`)
Update return type to `L` (if we introduce `L`)
We should use try-with-resources here (for `DataInputStream`).
Update return type to `L` (if we introduce `L`)
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I think we should call `deserializer.close()` here
This condition will never evaluate to `true` as we'll get an NPE when dereferencing a `null` instance of type `ExecutorHolder` in the line above.
can we use the ThreadPool#info API here, so we don't have to cast to `ThreadPoolExecutor`, and be able to get the max back through the info class.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
This changes behaviour as any exception from the `close()` call will no longer be caught and logged as a warning.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
the naming used above seems better here ```suggestion Throwable exception = null; ```
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
I think this `if/else` block here can be removed and just go with ``` java for (final ProcessorNode child : children) { forward(child, key, value); } ```
Yeah if it exists elsewhere let's just leave it as is for now.
Let's remove on both side: I think in J8 it is not really a big difference.
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
Let's remove on both side: I think in J8 it is not really a big difference.
This is redundant. getDelayAllocationExpirationIn also calls getAllocationDelayTimeoutSetting()==0 and returns 0 in that case.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
I should have used a better exception type initially. Because the class is indeed found. Probably `ClassCastException` would be more appropriate. Let's leave as is here, since the exception does not bubble up as cnfe anyways.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
Ideally, we'd always use brackets on control flow operators.
Could we collapse the code path for having a queryable store name or not into the same function? For example: ``` filter(.. /*nothing*/) calls filter(.. (String) null); filter(.. "storeName") calls filter(.. storeSupplier); // if storeName is not null, otherwise pass null as well filter(.. supplier) do the actual impl, which checks if supplier is null or not ```
no need to use `this.` outside the constructor. Here and below
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
why don't you use `finally` instead of `catch`? I guess that is legacy or copy/paste
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
hehe :) nice one
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onGet` as a name instead of primer
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
why do we return `this` here this is not a builder and I don't think we need to do this though!
+1 to moving this to its own file
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
why do we return `this` here this is not a builder and I don't think we need to do this though!
+1 to moving this to its own file
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
What is the value in separating the `set` and `done` methods? The one place where I can see that they are separated by some other code it looks like moving the `set` next to the `done` doesn't affect the tests at all.
if we keep ending up with this pattern, it might be clearer to create a `Listener` implementation that delegates to a list of listeners instead of chaining them manually this way
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
no need for the annotation if the test method name starts with "test" :)
It doesn't look like you are using any of the regular `getThenSet` features of the AtomicReference, can this just be a mutable variable? (Not really a big deal either way)
One extra line.
I wonder if you want a CyclicBarrier here.
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
We should use try-with-resources here (for `DataInputStream`).
I think its worth it? most of the time the response handle is SAME, so its not a big problem, but it allows to not overflow the same thread pool if it happens
I suppose that would make things super clear, but you're right, it would be a bug... so tossing a stacktrace vs. an illegalstateexception is almost the same thing . all good
since `getActionFromPolicy` can, theoretically, return `null`, would it be safer to switch these around to ``` newAction.equals(currentAction) == false ```
I think its worth it? most of the time the response handle is SAME, so its not a big problem, but it allows to not overflow the same thread pool if it happens
I suppose that would make things super clear, but you're right, it would be a bug... so tossing a stacktrace vs. an illegalstateexception is almost the same thing . all good
since `getActionFromPolicy` can, theoretically, return `null`, would it be safer to switch these around to ``` newAction.equals(currentAction) == false ```
Missing a `@since`. I wonder if that wouldn't be something of interest for the library (ping @jkschneider)
there is only one impl
any chance we can remove the interface and just name this class NioChannel
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
same as above for parameters
req: Is it possible to use a defined constant (e.g. `ACTIVE_TASK_SENTINEL_LAG`) here and also use it in `TaskManager`? I think it would be good to have this constant defined here and then use it in `TaskManager`.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
same as above for parameters
req: Is it possible to use a defined constant (e.g. `ACTIVE_TASK_SENTINEL_LAG`) here and also use it in `TaskManager`? I think it would be good to have this constant defined here and then use it in `TaskManager`.
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
I don't think this is the right approach. Even if the root cause is important, we still want to know that we experienced a disconnect. If I'm reading it right, the current patch does not show this. In general, we can't really make blanket statements like "the root cause is always the most useful thing" It depends on how the code is using the exceptions. Also, we shouldn't change what any of the exception output is without making a detailed examination of the before and after log output, and making sure that we like the "after" output better.
The typo is still there.
Shouldn't this be `timeoutMs - (time.milliseconds() - startTimeMs)`? Also, it's not too big of a deal, but the checks for `Long.MAX_VALUE` seem like overkill.
Minor: maybe it's better override the override the acks to always be trimmed string inside `postProcessParsedConfig`, and then here we just check that the value is `all` or not; this way we can keep `parseAcks` as private static inside `ProducerConfig`.
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
you can use `IOUtils.close(processor)` it deals with `null` values...
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
you can use `IOUtils.close(processor)` it deals with `null` values...
Not sure I have great ideas for improvement, but this feels like a brittle test case. I wonder if we are just trying to handle too many cases in this test.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
The source KTable is materialized for this case. That's why `groupBy().aggregate()` is only executed after the flush on the last value per key. However, with `TopologyTestDriver` we cannot mimic this behavior any longer. Hence, it would make sense to delete this test, as it's the same as `testAggBasic`
as above (similar below)
nit: how about just using letters alphabetically from "A" than using multiples of `XYZ` only? Relying on numbers of letters may be bug-prone (see below).
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I think we should call `deserializer.configure(...)` here
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we can drop the benchmark.
AclAuthorizer is not a public class, so it may be ok to make this class public in AclAuthorizer instead of duplicating it here.
Same as before, `new Integer[]{}' not required for `Arrays.asList`.
the naming used above seems better here ```suggestion Throwable exception = null; ```
This is logic that I think should go into ReplicatedOperation.
don't try to fix it, you just moved code around, but this catch block worries me :(
the naming used above seems better here ```suggestion Throwable exception = null; ```
This is logic that I think should go into ReplicatedOperation.
don't try to fix it, you just moved code around, but this catch block worries me :(
the naming used above seems better here ```suggestion Throwable exception = null; ```
This is logic that I think should go into ReplicatedOperation.
don't try to fix it, you just moved code around, but this catch block worries me :(
does it make sense to put the "fail a shard" logic under a method? to make sure we don't forget to put it in failedShards etc.
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
@guozhangwang Yep, sounds good to me.
Maybe just one more case missing. If we call subscribe with a new pattern, the assignment also shouldn't change.
This is an interesting discussion. I don't have the full context of these discussions, but I can see the argument for keeping things simple and letting users rely on the regular expression for achieving their goals. I am not sure if it's any simpler to provide two separate regular expressions than just one with the appropriate negation. The latter is easier to write a unit test for too.
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
The implication here is that wakeup won't work if you've fetched data and keep calling poll() when you have max records set small, right? This seems like it could be a problem for anything that takes a long time to process messages since the wakeup may be an indicator that the application needs to shutdown...
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
Ditto here, we should retain some version of this test and any others that are specifically intending to test the behavior of the old API (until the deprecation period has elapsed and we can remove it)
You can remove this `assertThat` and the loop below as you've already proven this is true in the test above. So no need to assert it again.
```suggestion assertEquals(0L, JoinWindows.of(ofMillis(DEPRECATED_OLD_24_HR_GRACE_PERIOD)).gracePeriodMs()); assertEquals(0L, JoinWindows.of(ofMillis(DEPRECATED_OLD_24_HR_GRACE_PERIOD + 1L)).gracePeriodMs()); ```
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
nit: usually we drop the `get` prefix on getters.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
nit: usually we drop the `get` prefix on getters.
as above (similar below)
Got it. Thanks
@mjsax @vvcephei I ran the new commit locally and I think I get the difference here: In the ToplogyTestDriver#pipeInput: ``` // Process the record ... task.process(); task.maybePunctuateStreamTime(); task.commit(); captureOutputRecords(); ``` I.e. each record would cause a commit immediately, and in this case, when processing the two records from the repartition topics, each of them will trigger the `pipeInput` once and hence commit once, i.e. the processing of the original one `pipeInput` would cause two `pipeInput` from the repartition topic, and hence commit twice, and flush twice. While in the old `KStreamTestDriver`, we do not commit from the repartition-topic piped record, hence only result in one flush.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
It will good to clear the requests and test when empty as well.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
s/Consumer/The verifying consumer
while the verifying consumer itself is not part of the transaction
rewrite test as above using `assertThrows()`.
same as above for parameters
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
This is logic that I think should go into ReplicatedOperation.
We prefer to use `assertThat()`: ```suggestion assertThat(throwable.getMessage(), is(...); ```
`PrintForEachAction<>` to remove warning. Also in the `print` method
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
Why do you remove this check? A `TimeWindow` should not allow this case.
The map is not used.
I think it might be nice to move this in `TcpHeader`
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
recommended; ditto below.
Both `GZipInputStream` and `SnappyInputStream` read the header in the constructor, so it would make sense to me to remain consistent in that respect.
What's the purpose of this warning? It doesn't seem needed.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
What's the purpose of this warning? It doesn't seem needed.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
nit: add final to parameters
nit: make the `mapper` final
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
recommended; ditto below.
Both `GZipInputStream` and `SnappyInputStream` read the header in the constructor, so it would make sense to me to remain consistent in that respect.
Maybe it could just be `StoreType`. We don't to qualify everything.
It's within a `session` package so I wouldn't mind too much.
Is the order of the options important? I think it should be alphabetically or by priority - wait is not the 1st one in either cases, I reckon.
`NEO4J` is not needed. `neo4j` entry will be inferred from `Neo4jHealthIndicator`, can be replaced by `nodes`? Additionally, all entries in the result shouldn't be added to the detail.
Maybe we could use a different value here.
we should do this `assertTrue` thing for the CooperativeStickyAssignor as well
I don't think this method is needed. The existing `toInstance(Function<T, R> factory)` method should do what we need when given a method reference to one of `Mustache.Compiler`'s configuration methods that return a new `Compiler` instance.
By the way, I wonder if we should just say it should be idempotent? Seems redundant to mention KafkaProducer.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
since `Period` doesn't support time I think we can change `10s` to `10m`
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
Ah, scratch that. I just realized it was the spring data support.
There is `.data` package. You should probably move that stuff over there.
It's within a `session` package so I wouldn't mind too much.
Do we still need `needsJoinPrepare` now? It seems to me that we need to call `onJoinPrepare` whenever `needRejoin` is true.
might want to rename `workerId` so it doesn't shadow the member field. something like `workerIdOpt` could work
ah, right. nah, that's fine. just when reviewing I had the thought that if we guaranteed non-`null`/non-empty in the constructor, this wouldn't be necessary. i realized that it was actually intentional, but easy to miss when reviewing here and not getting the same highlighting as an IDE
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
This statement is a bit misleading, how about "to the format indicated by the given magic value".
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
This statement is a bit misleading, how about "to the format indicated by the given magic value".
Maybe we can say "Kafka admin client has been closed" for consistency with the consumer. When grepping, it's easier to if things are consistent across clients.
nit: seems unnecessary? similar for `State.FAILED` below.
I don't think this will ever be true, i.e., in `start` we set the state to `RUNNING` and then we call `globalStreamThread.start()`. So the listener will be invoked with `RUNNING` while the instance is already in the `RUNNING` state. The `StreamThread`s aren't started until after `globalStreamThread.start()` returns.
Maybe we can say "Kafka admin client has been closed" for consistency with the consumer. When grepping, it's easier to if things are consistent across clients.
nit: seems unnecessary? similar for `State.FAILED` below.
I don't think this will ever be true, i.e., in `start` we set the state to `RUNNING` and then we call `globalStreamThread.start()`. So the listener will be invoked with `RUNNING` while the instance is already in the `RUNNING` state. The `StreamThread`s aren't started until after `globalStreamThread.start()` returns.
remove empty line
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
remove empty line
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
remove empty line
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
We don't really care about the stack trace here or below, just the message. We know the `StreamsException` is generated from this class and the message is enough to identify the problem. Further, these are done in a retry loop so can become quite verbose if failed multiple times
Below is what I get when I try it out. As you can see that log message is drowned in many other log messages that don't mention the index name. A lot of this is guice and we're working on fixing it, but I think the easiest is to make sure that the index name is mentioned in the exception for now? people won't see it otherwise. ``` [2016-11-03T00:08:29,112][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... a terminal screen worth of stack trace here ... Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] .... [2016-11-03T00:08:29,144][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,146][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal screen worth of output [2016-11-03T00:08:29,161][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,161][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.archiveBrokenIndexSettings(MetaDataIndexUpgradeService.java:171) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:81) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] [2016-11-03T00:08:29,229][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main] org.elasticsearch.bootstrap.StartupException: org.elasticsearch.common.inject.CreationException: Guice creation errors: 1) Error injecting constructor, java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] <--- THESE IS REPEATED 4 times at org.elasticsearch.gateway.GatewayMetaState.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayMetaState for parameter 4 at org.elasticsearch.gateway.GatewayService.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayService ... another terminal, this time full of guice information Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) at org.elasticsearch.common.settings.Setting$$Lambda$183/2092885124.apply(Unknown Source) at org.elasticsearch.common.settings.Setting.get(Setting.java:312) at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:525) ... 47 more And this ^^^ is the last message on the screen. ```
Also minor, but I think I'd prefer `node == null ? null : node.toString()` because it requires less negative-resolving in my brain, up to you though.
Why use a static block to initialise this? `Sets.newHashSet` can turn this into a 1 liner, and then you can wrap it in `unmodifiableSet`
Just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. Would you mind to not move configs that get deprecate and add the new config at the "right" place. Thanks a lot. :)
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
`doWork` is just one iteration. `ShutdownableThread` has the loop. I'm ok with the change, but we probably will need to copy over some of the shutdown logic.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
I am ok with what you propose Nik!
As above for this and next ctor
As above for this and the next ctor
```suggestion "part of a group or is participating in a rebalance right now. You should first call poll to complete " + ```
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
the naming used above seems better here ```suggestion Throwable exception = null; ```
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
the naming used above seems better here ```suggestion Throwable exception = null; ```
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
nit extra newline
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
as above (similar below)
nit: line too long
nit: move `}` to next line
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
I think we should call `deserializer.close()` here
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
We should use try-with-resources here (for `DataInputStream`).
> The JVM chooses the heap size ergonomically when the heap size is not specified. Do we have the ability to see what it would choose? If running on a small machine, for instance, we'd still want to disable Netty's pooled allocator if the JVM is going to automatically choose a 400mb heap
exception messages should start with lowercase (for consistency)
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
the naming used above seems better here ```suggestion Throwable exception = null; ```
add the exception? :)
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
This TODO should be removed
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
We should use try-with-resources here (for `DataInputStream`).
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think we should call `deserializer.close()` here
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
`WindowStore` is public API -- we need a KIP if we want to deprecate something. Thus, this is not a `MINOR` PR.
I think I recall cases that work perfectly without the leading "/". e.g. https://github.com/elastic/elasticsearch/issues/19314
if we make such change, can we do it in a separate PR please? ;)
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
Doh! the recommendation is forbidden API ..never mind.
Nits: `set` -> `batch` and `task` -> `tasks`
Nit: you can call `Thread.enumerate` directly. Also, it would be good to assert that `threadCount` is < than `threads.length`.
I just thought about this. I think `endOffset` should be actual endOffset, ie, `11` for this test -- we pass in the `offsetLimit` as 5 in `StateRestorer` below.
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
If we don't count token with 0-increment this should be equal to 2
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
If we don't count token with 0-increment this should be equal to 2
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
Sorry, my example included this initializer but it isn't needed. This is just for information: we can tidy up my mistake when we merge your changes.
This unfortunately doesn't guarantee that all transactions are always rolled back. _dirty is never set if you run read-only queries in the default autocommit mode, yet transaction is started by any query (the cursor.is_dirty() checks if transactions are managed before setting ._dirty). It seems making sure ._rollback is called after every request would be a god idea if the connection isn't going to be persisted. Even better approach is to make the _dirty flag behave somewhat sanely. But this is not this issue's problem.
```suggestion default: no ```
I'm curious why we have getValues if all of these classes already extend list? Nothing to do with this PR, just something I noticed: since we are looking at breaking changes in the future, maybe this could be cleaned up too (either extend list, or have getValues())
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
I'm curious why we have getValues if all of these classes already extend list? Nothing to do with this PR, just something I noticed: since we are looking at breaking changes in the future, maybe this could be cleaned up too (either extend list, or have getValues())
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
and -> a
base -> based progress -> progressed
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
and -> a
base -> based progress -> progressed
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
nit: {@link KafkaClientSupplier}
a constant could cause problems though if the constant gets misused (e.g. changing its boost etc.), method is ok sorry
We should update the Scala `TestUtils` to call this method.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
nit - an extra d? release**d**Delayed..
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
nit - an extra d? release**d**Delayed..
the naming used above seems better here ```suggestion Throwable exception = null; ```
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
I am good
the naming used above seems better here ```suggestion Throwable exception = null; ```
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
nit: add `final`
nit: add `final`
nit: add `final`
Yeah, Java's type system makes this stuff a pain. I think you can fix it with: ``` final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(new KStreamBranch<>((Predicate<K, V>[]) predicates.clone(), childNames), branchName); ``` which should be safe If you want to also get rid of the cast, you can do it by coercing each of the predicates to a Predicate<K,V> when you loop over them at the beginning: ``` Predicate<K, V>[] kvPredicates = new Predicate[predicates.length]; for (int i = 0; i < predicates.length; i++) { final Predicate<? super K, ? super V> predicate = predicates[i]; Objects.requireNonNull(predicate, "predicates can't be null"); kvPredicates[i] = predicate::test; } ```
I would execute the `IOUtils.close(resources);` in a finally block after we sent back the response or the other way around.
as above: avoid `/` Update to ``` log.warn("Unable to read '{}{}{}'. Using default inputValues list", "resources", File.seperator, fileName); ```
I am good
the naming used above seems better here ```suggestion Throwable exception = null; ```
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
I am good
the naming used above seems better here ```suggestion Throwable exception = null; ```
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
it makes it too easy to call delete when its not necessary.
Was this intentional? `VALUE_SERDE_CLASS_CONFIG` is deprecated.
an -> a
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
`KeyValueStore` -> `TimestampedKeyValueStore`
nit: remove extra line
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
`KeyValueStore` -> `TimestampedKeyValueStore`
nit: remove extra line
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
`KeyValueStore` -> `TimestampedKeyValueStore`
nit: remove extra line
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
We should use try-with-resources here (for `DataInputStream`).
This is logic that I think should go into ReplicatedOperation.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
We should use try-with-resources here (for `DataInputStream`).
This is logic that I think should go into ReplicatedOperation.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
New public classes should have a `@since 2.7.0` (assuming we're going to accept this PR).
Missing a `@since`. I wonder if that wouldn't be something of interest for the library (ping @jkschneider)
Nit: `casted` should read `cast`.
New public classes should have a `@since 2.7.0` (assuming we're going to accept this PR).
nit: an object -> an object has associated partition offsets that can be ...
It's not necessary to have `PENDING_VALUE`, `RUNNING_VALUE`, etc. since you can just call `PENDING.name()` to get the string `"PENDING"`
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
This line is failing checkstyle.
nit: missing `<p>` for new paragraph
```suggestion * is an empty {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
nit: missing `<p>` for new paragraph
```suggestion * is an empty {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
no need to use `this.` outside the constructor. Here and below
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
We should use try-with-resources here (for `DataInputStream`).
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
no need to use `this.` outside the constructor. Here and below
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
nit: can remove type arguments
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Also set the store name in this test.
I think it is fine: we only build one search context per request per shard.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Just dug into it and found we use `TestRuleAssertionsRequired` from the lucene-test-framework jar to do this check
Well, it shouldnt be. The suppressed exceptions are like 'children' of `cause`, they don't need to be shuffled around. The current code is basically attaching grandchildren as children, which will be confusing.
We should nuke all this logic after the `super` call, because now we init the exception with `ex` as root cause, so it will still keep all of its suppressed exceptions.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Considering that we may have multiple `WebServiceMessageSender`, I don't think we should expose this method here. You can provide a configured `WebServiceMessageSender`, this feels weird to me that all of them are reconfigured behind the scenes.
This should also go away.
This should be the last step
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
This is skipping a path in `for path in list_valid_collection_paths(search_paths):`, and not the filter.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
This is skipping a path in `for path in list_valid_collection_paths(search_paths):`, and not the filter.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
This is skipping a path in `for path in list_valid_collection_paths(search_paths):`, and not the filter.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
`border_mode` is not required. The output is of value : (batch size, num_input_channels, input row size * row ratio, input column size * column ratio) So fi the ratio is good, everything should be.
Style: space needed after comma.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
nit: fix alignment.
We should log an error that prints out what the two configs actually are
state.isRunning() is as below ``` public boolean isRunning() { return equals(RUNNING) || equals(STARTING) || equals(PARTITIONS_REVOKED) || equals(PARTITIONS_ASSIGNED); } ``` if its not too much work, we can rename to something like `state.isAlive()` , that captures what we want to check .. your call.
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
as above. `requireNotNull` not necessary any longer
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
as above. `requireNotNull` not necessary any longer
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
as above. `requireNotNull` not necessary any longer
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
as above. `requireNotNull` not necessary any longer
as above. `requireNotNull` not necessary any longer
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
I wonder if we should use the cluster state for this check. I'm worried about people passing in a dated cluster state here. Maybe a cleaner model is to make this method synchronised (to avoid async collision with the create code) and check the existence of the index instance in the #indices map member of this class.
Ideally we'd not wrap the exception if there are no retries, so I guess it just depends on how hard it is to make that work.
I think there's an edge case where `timeoutMs` is positive but small enough that the condition on line 77 is not met but the while loop on line 85 is not satisfied because the end time has already passed. In this edge case, we might not call the callable function (even once). One option is to change the while loop to be a do-while loop so that we always go through one loop. Another option is to compute the remaining time before line 77 and not update it before the while loop. Either would work, but one of the options may require fewer duplicated lines.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
nit: IOException never thrown
What about inlining `transformations` and having something like: ``` when(plugins.transformations()).thenReturn(Collections.singleton(transformationPluginDesc())); ```
`<byte[]>` this explicit type is unnecessary
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
Nit: line too long
I don't know that we care about closing the handler. It probably does not matter too much, but there should not be any resources hanging around if we properly consume all the requests.
nit: IOException never thrown
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
base -> based progress -> progressed
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
base -> based progress -> progressed
This line can be reverted now that the JUnit 4/5 split is gone.
There's really no reason to remove that.
Still not addressed -- we should mention both methods return this iterator.
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
Why did not remove this from being a `ParseField`? This seems to go against the prevailing pattern.
make class final
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
good point.... we should be able to get rid of it.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
last parameter can be set to from.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
good point.... we should be able to get rid of it.
Fixed this in my latest update of #4033.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
"do nothing" is probably the right thing here.
> A new method also means their code is then not binary compatible with older client versions. yep, the BC could be broken. What I really care is the source compatibility. It seems to me a public API should be source compatible to next major release :) This patch is good to go and we need more time (rather than vespene gas ... StarCraft is my favor game :) ) to reach consensus.
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
"do nothing" is probably the right thing here.
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
> A new method also means their code is then not binary compatible with older client versions. yep, the BC could be broken. What I really care is the source compatibility. It seems to me a public API should be source compatible to next major release :) This patch is good to go and we need more time (rather than vespene gas ... StarCraft is my favor game :) ) to reach consensus.
"do nothing" is probably the right thing here.
> I think cleanest the way to do it backwards compatibly is to introduce a new store hierarchy and deprecate the old one. I am afraid that might be the only way to do it -- deprecation hell -- users won't be happy -- thus we should think hard if it's worth to do or not...
Cool, I will create a JIRA ticket for now to keep track of it.
can we mark this as nullable (and doc when it's null)? also, can we move it next to the setter, and make the naming consistent with the rest of this class? (i.e., shardId)
"do nothing" is probably the right thing here.
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
> I think cleanest the way to do it backwards compatibly is to introduce a new store hierarchy and deprecate the old one. I am afraid that might be the only way to do it -- deprecation hell -- users won't be happy -- thus we should think hard if it's worth to do or not...
Cool, I will create a JIRA ticket for now to keep track of it.
can we mark this as nullable (and doc when it's null)? also, can we move it next to the setter, and make the naming consistent with the rest of this class? (i.e., shardId)
same typo - copy paste probably
could be a instance variable, as used in all tests
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
I don't think this is the right approach. Even if the root cause is important, we still want to know that we experienced a disconnect. If I'm reading it right, the current patch does not show this. In general, we can't really make blanket statements like "the root cause is always the most useful thing" It depends on how the code is using the exceptions. Also, we shouldn't change what any of the exception output is without making a detailed examination of the before and after log output, and making sure that we like the "after" output better.
We should log the the failure here if the close fails
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
I don't think this is the right approach. Even if the root cause is important, we still want to know that we experienced a disconnect. If I'm reading it right, the current patch does not show this. In general, we can't really make blanket statements like "the root cause is always the most useful thing" It depends on how the code is using the exceptions. Also, we shouldn't change what any of the exception output is without making a detailed examination of the before and after log output, and making sure that we like the "after" output better.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
nit. I think there is `.` missing `since 3.0[.] Use`
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Yeah, I think it's worth the bit of logic to fail more quickly.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
as above. `requireNotNull` not necessary any longer
Yeah, Java's type system makes this stuff a pain. I think you can fix it with: ``` final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(new KStreamBranch<>((Predicate<K, V>[]) predicates.clone(), childNames), branchName); ``` which should be safe If you want to also get rid of the cast, you can do it by coercing each of the predicates to a Predicate<K,V> when you loop over them at the beginning: ``` Predicate<K, V>[] kvPredicates = new Predicate[predicates.length]; for (int i = 0; i < predicates.length; i++) { final Predicate<? super K, ? super V> predicate = predicates[i]; Objects.requireNonNull(predicate, "predicates can't be null"); kvPredicates[i] = predicate::test; } ```
Well that's the problem, we don't know what's important for a custom rescorer. `SearchContext` is mutable which is why I think it's too sensitive but the same applies to `SearchSourceBuilder` so you're probably right. We can find ways to pass more information in the `RescoreContext` anyways so +1 to keep this simplification.
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
No, I still think that it should not be a method on the `Strings` class.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
same typo - copy paste probably
this one is not used - can we remove it until we cat over to the paths API
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Do we really need a generic here? It looks to me that it's useful for innerBlobStore() / blobContainer() methods used in tests but otherwise it's not really required.
Typo: > Similar[ly], you can ... with [a] custom ...
don't ignore it? Just call `parser.text()` without the if, should work.
can we use Pattern.qoute for the prefix? just being paranoid..
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
CCE is never a good idea to throw out - especially since it forces the caller to handle it. It should be handled inside convert directly.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
`long,long` is used for `WindowStore` while `Instance,Duration` (or `Instance,Instance` if we correct it) is use for `ReadOnlyWindowStore` that return the same iterator.
Still not addressed -- we should mention both methods return this iterator.
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
@rjernst Ping on that cosmetic thing. Not sure it is worth changing though. Up to you :)
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
I think we can drop the benchmark.
I'm not sure what reference.conf is but this does not seem like a useful description, in my opinion. Descriptions may be published to metric backends, which almost certainly won't have access to the mentioned reference.conf. Even accessing the Actuator endpoint does not mean that person has access to this reference.conf file.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
base -> based progress -> progressed
nit: may worth explain how `queryableStoreName` can be find from `materialized` below.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
nit add `a {@link Named} config`
Should add that the class is not thread-safe.
This is not a suggestion for change: while working on removing `KStreamBuilder` and `TopologyBuilder` I realized in some unit tests we may still need this class to access the internal topology builder. So probably we cannot remove it even after that, but we can discuss this later in the cleanup PR.
How about making ```SizeDelimitedSend``` be a static method in ```ByteBufferSend```? For example: ```java public static Send withSizeDelimited(ByteBuffer buffer) { ByteBuffer sizeBuffer = ByteBuffer.allocate(4); sizeBuffer.putInt(0, buffer.remaining()); return new ByteBufferSend(sizeBuffer, buffer); } ```
this line is still a bit long... You could try a static import for `singletonList`.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
this is creative :)
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
This is logic that I think should go into ReplicatedOperation.
`performPreSyncedFlush` might call this. Let's make this noop
same here, this might be called by a user-invoked force-merge
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
HttpClient is optional, might be better to use RestTemplate.
nit: parameter descriptions are no sentences, thus no `.` at the end (on many other places, too). If we say they are sentences, they it should start with upper case `[T]he TopicPartition`
We shouldn't use `<br>`; instead, use a `<pre>` section around the lines.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
Makes sense @ewencp, not sure how I missed that sentence when I read it originally.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
hopefully the `System.nanoTime` goes away once you merge master in.
`KeyValueStore` -> `TimestampedKeyValueStore`
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
maybe just `esVersion()`
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
maybe just `esVersion()`
Nit: we don't normally use exclamation marks in Kafka log messages.
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
It's intentional to avoid build warnings about importing deprecated classes.
Nit: we don't normally use exclamation marks in Kafka log messages.
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
It's intentional to avoid build warnings about importing deprecated classes.
params are not nullable any more - please make sure this doesn't revive it.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
got it thank you.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
and -> a
`limitedTo(long bytes)`? Clone is kinda non-specific.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
good catch on delta > 0
I think we should call `deserializer.configure(...)` here
I think we should call `deserializer.close()` here
We should use try-with-resources here (for `DataInputStream`).
We should use try-with-resources here (for `DataInputStream`).
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
I think we should call `deserializer.close()` here
super minor, but indentation is off here
We should use try-with-resources here (for `DataInputStream`).
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
super minor, but indentation is off here
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
super minor, but indentation is off here
We should use try-with-resources here (for `DataInputStream`).
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
last parameter can be set to from.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
You don't need this anymore, this method always run with a single registered type.
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
Maybe consider JUnit Parameters here, but fine as is. EDIT: Thinking some more about this, I'd leave it as is.
nit: can remove type arguments
Also set the store name in this test.
super minor, but indentation is off here
Maybe this was already covered somewhere, but is `GENERIC` the right threadpool for this? (I don't have a better suggestion, just asking)
This TODO should be removed
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
nit: o2[%s] was **equal** to o1[%s]
I think we can drop the benchmark.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
I think we can drop the benchmark.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
I think we can drop the benchmark.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
Nit: missing `@Override`
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I stand by what i said, but I'll leave it up to you. It isn't a deal breaker for me!
I think this should be four different tests. One for each of the methods you are testing. I probably said this before, but it is much nicer if you can just read the test names to understand what should/shouldn't be happening
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
nit: new line
cancel that :) I figured it out.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
nit: new line
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
nit: new line
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
could be a instance variable, as used in all tests
Second parameter should be `serverConfigs`
nit: add `final` (same below)
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
Actually I think it works: http://www.slf4j.org/faq.html#paramException.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
```suggestion left.join( right, (value1, value2) -> value1 + value2, joinWindows, streamJoined ); ```
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
I think it'd be nice to remove this second ctor so we're explicit every time.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
base -> based progress -> progressed
and -> a
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
base -> based progress -> progressed
and -> a
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
I think the intended method to call would be ``` Thread.currentThread().interrupt() ``` Same with line 258 below.
Ah, you are right. Sorry.
nit: "so we assume"...
this one is not used - can we remove it until we cat over to the paths API
same typo - copy paste probably
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
request "got" re-sent to the control
an -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
request "got" re-sent to the control
an -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
"If no selection operation is currently in progress then the next invocation of one of these methods will return immediately unless the selectNow() method is invoked in the meantime." I read that to mean that that `poll(Long.MAX_VALUE)` will not return immediately since a `selectNow` was invoked in the meantime . Might be worth a unit test to verify that it works as expected.
I'm wondering if we also need to delay the call to `client.wakeup()`? For example, consider the following sequence: 1. disableWakeups() 2. wakeup() 3. poll(0) 4. enableWakeup() 5. poll(Long.MAX_VALUE) The underlying wakeup on Selector would effect the `poll(0)`, but we would suppress the exception. Then there would be nothing to wake us up from the `poll(Long.MAX_VALUE)`.
As we catch the exception we should swallow is and don't expect it
I believe the goal is to use constant-time comparison to prevent timing attacks, hence the walk through the arrays.
nit: remove empty line
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
and -> a
base -> based progress -> progressed
and -> a
base -> based progress -> progressed
and -> a
nit: `punctuate each second` (might be c&p error and affect other places, too) -- maybe better to address in separate PR (the `void punctuate()` issue and this can be one PR IMHO).
nit: I don't think there's any reason to mention this. Unexpected errors fall under `KafkaException`, which is listed below.
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
imho having `hasUnassigned` and `hasUnassignedShards` methods is very confusing.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
you can do some streaming java8 magic here.
This sucks.. I want to see how big of a deal it is to keep things as they were. Indeed snapshotting a commit will keep it's translog around but I'm not sure anymore it's worth this kind of wrapping layers. Maybe we should invest in faster clean up on those snapshotted commits. I'll reach out to discuss.
same here as what i said below. You can use a `assertThat`
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
same as above for parameters
