I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
I don't think this method is needed. The existing `toInstance(Function<T, R> factory)` method should do what we need when given a method reference to one of `Mustache.Compiler`'s configuration methods that return a new `Compiler` instance.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I think you use it indirectly through `parser. isBooleanValueLenient`.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
This logging statement has a `[{}]` but no argument to fill it
Out of curiosity, could we do all the types in parallel instead of blocking and waiting for each type to complete before moving to the next type? (It's probably out of scope for this PR, but I'm wondering for a future enhancement)
it seems that the latch is useless? or maybe you wanted to enable the recovery half way through the "indexing operations"? Also, this suffers from the same racing condition - if the ops that are now in flight when the relocation comes in are not first in the onLockAcquiredActions list, we will have a deadlock.
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
yeah, this is tricky. I instead I think we can run a test that cancels from the running task and makes sure it is never run again? we can then decide whether to cancel immediately or after a few iterations
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
It should be public as it will be used in `producer` APIs.
nit: extra line
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
nit: It seems clearer to use `ConsumerPartitionAssignor.class` directly below.
This is for possible future extensibility if we want to add new fields: with raw types (map) we'd have to change the signature of the API.
nit: remove `which is`
If the subscription changes, the `onPartitionsRevoked` would be triggered and the owned-partitions in subscription would not include them. The original reasoning is just to make sure all partitions except the ones that are attempted for reassignment-hence-revocation-first are owned by someone. But like we discussed in the other PR, today we are not checking these conditions anyways, e.g.: 1. assignor assign one partition to multiple consumers. 2. assignor assign one partition to no one. They are both bad situations but Coordinator does not check for those today. We discussed about this and think it worth a more general solution as a separate JIRA.
Also add `@params topics`
I believe it should be `success, rx, tx, rtt = parse_ping(ping_results_list[-1])`
I'm not entirely sure it is required to have the FIPS checks implement an interface, but if we go down this path ,I think that conceptually it would make more sense to have a `FIPScheck` interface that all the relevant checks ( settings, password hash etc. ) would then implement.
it's a shame java need this...
nit: move parameter to it's own line (same below)
ok let's move on I don't know if I like it it seems not consistently used across the board.
why do we return `this` here this is not a builder and I don't think we need to do this though!
That is a good point. I think adding a boolean flag in addition to the `future` result indicating if it may be incomplete is better than exposing the node map. I.e. we could have two fields inside `ListConsumerGroupsResult`, a `boolean` and a `KafkaFuture<Collection<ConsumerGroupListing>>` (I think we do not need to have nested KafkaFutures so I did not have that inside `Collection`, but correct me if I overlook anything).
Nit: ```suggestion * executed exactly once. If {@code maxRetries} is set to {@code n}, the callable will be executed at ```
That's not what I mean. Shouldn't that condition above be `@ConditionalOnBean({ CacheFactoryBean.class, GemfireCache.class,...` rather than `@ConditionalOnBean({ CacheFactoryBean.class, Cache.class,...`
We shouldn't use `<br>`; instead, use a `<pre>` section around the lines.
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
If you prefer, in the indexing method we can do tryAcquire first out of lock and go under lock and try again, if failed.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Nit: missing `@Override`
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Add the `@Overrride` annotation to this method.
When you make `initializeSnapshotWithHeader` private, you may need to slightly change this implementation. E.g.: ```java return supplier.get().map(snapshot -> { RecordsSnapshotWriter<T> writer = new RecordsSnapshotWriter<>( snapshot, maxBatchSize, memoryPool, snapshotTime, lastContainedLogTimestamp, CompressionType.NONE, serde); writer.initializeSnapshotWithHeader(); return writer; }); ```
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Add the `@Overrride` annotation to this method.
When you make `initializeSnapshotWithHeader` private, you may need to slightly change this implementation. E.g.: ```java return supplier.get().map(snapshot -> { RecordsSnapshotWriter<T> writer = new RecordsSnapshotWriter<>( snapshot, maxBatchSize, memoryPool, snapshotTime, lastContainedLogTimestamp, CompressionType.NONE, serde); writer.initializeSnapshotWithHeader(); return writer; }); ```
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
It seems this still needs to be executed for `minReceivedMetadataVersion >= 2`
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onGet` as a name instead of primer
Add the `@Overrride` annotation to this method.
nit: remove empty link
Add the `@Overrride` annotation to this method.
as above (more often below -- please fit all)
Add the `@Overrride` annotation to this method.
This overload does not take `Materialized` parameter
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
nit: remove empty link
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
as above (more often below -- please fit all)
This overload does not take `Materialized` parameter
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
brackets in the URL
Don't add this, if the parameter is not required.
This isn't needed if you have set a default.
I believe you will need to quote this as YAML may interpret it as null.
Not needed if you have a default.
Well, I am mostly concerned with absent/present because that is a generic option used by other modules. Besides your examples use it as lowercase anyway. For the others, if the casing is important, leave as-is, but ensure you validate using strict casing as well, or users with casing-issues may get an ugly exception.
Would be good to have a registry example
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
brackets in the URL
Don't add this, if the parameter is not required.
This isn't needed if you have set a default.
I believe you will need to quote this as YAML may interpret it as null.
Not needed if you have a default.
Well, I am mostly concerned with absent/present because that is a generic option used by other modules. Besides your examples use it as lowercase anyway. For the others, if the casing is important, leave as-is, but ensure you validate using strict casing as well, or users with casing-issues may get an ugly exception.
Would be good to have a registry example
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
brackets in the URL
Don't add this, if the parameter is not required.
This isn't needed if you have set a default.
I believe you will need to quote this as YAML may interpret it as null.
Not needed if you have a default.
Well, I am mostly concerned with absent/present because that is a generic option used by other modules. Besides your examples use it as lowercase anyway. For the others, if the casing is important, leave as-is, but ensure you validate using strict casing as well, or users with casing-issues may get an ugly exception.
Would be good to have a registry example
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
brackets in the URL
Don't add this, if the parameter is not required.
This isn't needed if you have set a default.
I believe you will need to quote this as YAML may interpret it as null.
Not needed if you have a default.
Well, I am mostly concerned with absent/present because that is a generic option used by other modules. Besides your examples use it as lowercase anyway. For the others, if the casing is important, leave as-is, but ensure you validate using strict casing as well, or users with casing-issues may get an ugly exception.
Would be good to have a registry example
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
brackets in the URL
brackets in the URL
Don't add this, if the parameter is not required.
This isn't needed if you have set a default.
I believe you will need to quote this as YAML may interpret it as null.
Not needed if you have a default.
Well, I am mostly concerned with absent/present because that is a generic option used by other modules. Besides your examples use it as lowercase anyway. For the others, if the casing is important, leave as-is, but ensure you validate using strict casing as well, or users with casing-issues may get an ugly exception.
Would be good to have a registry example
typo: The title of the last column should be `DELETE_SEGMENT_FINISHED`.
```{@link org.apache.kafka.common.KafkaFuture#get}``` => ```{@link org.apache.kafka.common.KafkaFuture#get()}```
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
Makes sense @ewencp, not sure how I missed that sentence when I read it originally.
nit: remove extra line
`while` seems to be missing
request "got" re-sent to the control
Not sure if we need to do that it's just one entry per field though.
should we use a native trove collection here from String to long
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
nit: remove extra line
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
Makes sense @ewencp, not sure how I missed that sentence when I read it originally.
Not sure if we need to do that it's just one entry per field though.
`while` seems to be missing
request "got" re-sent to the control
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Nit: missing `@Override`
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
`containsAlias` will throw an exception if you call it on a `KeyStore` that hasn't been initialised. I think you could test the exception handling with the following: ``` KeyStore keyStore = KeyStore.getInstance("JKS"); assertThatThrownBy(() -> SslUtils.assertStoreContainsAlias(keyStore, "alias")) .isInstanceOf(IllegalStateException.class) .hasMessage("Could not determine if keystore contains alias 'alias'").hasCause(keyStoreEx); ```
As the alternative is to change the mock maker for the whole project, I'd prefer to load an actual `KeyStore`.
Unnecessary extra space.
We don't use this construct, please mock the template in the test as you've done for the rest.
This doesn't need to be a field
Yeah, it's relatively new but it's the clear path forward especially with JUnit 5 coming with built-in support for the same.
As some of these mocks are test specific, I wouldn't initialize them at class level but rather in the test that uses them.
nit: remove the redundant line. Same as below.
`asList` -> `Collections.singletonList`
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
If we want the burst to be more similar to original behavior, it seems like this should be `#samples`. With the current implementation, we can do 1 unit of work in the oldest window and then accept a burst right at the end of the last (not full yet) sample. Which means that the max burst size is almost at #samples * quota (if sample = 1 sec, quota is in units/second). Does this sound right to you? Also, I think we should take into account `config.timeWindowMs`, because it could be something other than 1 second.
I wonder if we can somehow come up with something that better normalizes across failed cloud instances? If a machine is pulled, but its replacement can come up within the allotted time, then it would be ideal to not trigger the recovery because we're waiting on the dead machine (based on its InetAddress).
Yeah, I guess I'm thinking of people deploying without static IPs (certainly not recommended). These most likely won't suffer the same problems that this solution helps though, so it may be a moot point altogether.
I think we should extend our cloud integration plugins to add some kind of a stable identifier as a node attribute (if not already doing so) and auto-configure this setting to it. /cc @dadoinet @tlrx
cancel that :) I figured it out.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
This should be the only method with actual code. All other overloads should call this one.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
Thanks for verifying @vvcephei!
Generics confuse me regularly, too... I was just comparing to `transform` -- seems our API is not consistent. I guess your argument makes sense.
IIRC, Java doesn't fully implement variance, but this is the basic concept (in scala) of what's going on with those `extends` return types: https://docs.scala-lang.org/tour/variances.html
"top-k records" -> "top-k values"
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
This should be the only method with actual code. All other overloads should call this one.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
Thanks for verifying @vvcephei!
Generics confuse me regularly, too... I was just comparing to `transform` -- seems our API is not consistent. I guess your argument makes sense.
IIRC, Java doesn't fully implement variance, but this is the basic concept (in scala) of what's going on with those `extends` return types: https://docs.scala-lang.org/tour/variances.html
"top-k records" -> "top-k values"
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Another reason for having these classes in common (i.e. KAFKA-5265) is that they can potentially be used by the Authorizer interface when we move it to Java.
Actually we could go crazy and add couchbase to the list.
The current implementation provides a view onto the keys of the underlying map so its contents may change if an indicator is (un)registered.
You might consider using `OptionalDouble`.
Maybe we could use a different value here.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
(very minor) nit: inconsistent naming of these in this class
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
The other constructor calls the parameter `sampledStat`. We should be consistent.
Nit: should we call this `rateUnit`? Same for the other constructor.
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
The other constructor calls the parameter `sampledStat`. We should be consistent.
Nit: should we call this `rateUnit`? Same for the other constructor.
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
The other constructor calls the parameter `sampledStat`. We should be consistent.
Nit: should we call this `rateUnit`? Same for the other constructor.
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
The other constructor calls the parameter `sampledStat`. We should be consistent.
Nit: should we call this `rateUnit`? Same for the other constructor.
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
The other constructor calls the parameter `sampledStat`. We should be consistent.
Nit: should we call this `rateUnit`? Same for the other constructor.
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
There is a built-in for this `Function.identity()`
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
I also think it's better to start with burst size credits. We would normally create the sensor on the first byte/request/etc. and before that, the <user,client> is idle which means they were "accumulating credits".
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
The other constructor calls the parameter `sampledStat`. We should be consistent.
Nit: should we call this `rateUnit`? Same for the other constructor.
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
@guozhangwang **Forgive me if I misunderstood this method, really**. But if the list is composed of key-value pairs, wouldn't this for loop goes up to the the middle of the array? Plus, if `tags` is `"a","1","b","2"` the final map will be `"a" -> "1", "1" -> "b"`. Is this the right intend? Besides not reaching "b" -> "2", it will make the previous value a key in the next iteration. If not, I suppose we could rewrite it as ``` for (int i = 0; i < tags.length; ) { tagMap.put(tags[i], tags[i+1]); i += 2; } ``` Again, forgive me if I understood everything wrong.
Glad to help! :)
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
This is going to be modified and accessed on potentially different threads, right? If so, we should add the `volatile` modifier here.
`removeSensor()` would remove its associated metrics as well, I think we do not need the second call below.
Hey, I'm sorry, but can you explain what's going on here? `Sensor` doesn't override `equals`, so I'm not seeing how this assertion works.
Oh, right, I forgot that the metrics registry returns the same copy of the sensor when all the name, description, and tags are the same... Thanks.
Why is the order of these methods different than in `ConnectorStatusListener`? Also, the `TaskStatusListener` methods always forward the method to the delegate _last_, whereas the methods of the `ConnectorStatusListener` use a mixture. Let's make them consistent.
Nit: the methods of the `ConnectorStatusListener` and `TaskStatusListener` classes are in very different orders. It would help readability to have them in the same order. IMO, the order of the `TaskStatusListener` methods is nice because it follows the lifecycle.
This is going to be modified and accessed on potentially different threads, right? If so, we should add the `volatile` modifier here.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
no need to use `this.` outside the constructor. Here and below
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
This TODO should be removed
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
the naming used above seems better here ```suggestion Throwable exception = null; ```
no need to use `this.` outside the constructor. Here and below
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
This TODO should be removed
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
this is creative :)
state.isRunning() is as below ``` public boolean isRunning() { return equals(RUNNING) || equals(STARTING) || equals(PARTITIONS_REVOKED) || equals(PARTITIONS_ASSIGNED); } ``` if its not too much work, we can rename to something like `state.isAlive()` , that captures what we want to check .. your call.
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
I wonder if we should resolve things again here. I think we should make it as simple as possible here. Maybe have a Primary request (or use internal request) which has the shardid already built into it. All we need to do in the action is lookup the index shard, see that we have it and do our thing.
I'm not sure this does what you want? it blocks the thread handling the request. Maybe use latches here to signal events and control the disruption from the test? I think it will also be clearer to read.
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
can we use org.elasticsearch.indices.recovery.RecoverySource.Actions#START_RECOVERY ? it's a better indication that the recovery is started.
The logging brackets are off here: `[{} to [{}]]`.
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
lets' introduce a dedicated exception for this. We can upgrade discovery.zen.NotMasterException to be in the cluster package and use that.
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
let's just skip the iterator and use IndexShardRoutingTable.shards() (put it in a variable and use it in do run as well)
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
The current implementation provides a view onto the keys of the underlying map so its contents may change if an indicator is (un)registered.
There is a built-in for this `Function.identity()`
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
@rajinisivaram @stanislavkozlovski LGTM with the possible exception of maybe adding support for retrieving/logging any ignored extensions? I'll defer to your preference on this.
Yes, we could add `ignoredExtensions` and include that in the log in the server.
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
nit: 'else' can be dropped
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
nit. I think there is `.` missing `since 3.0[.] Use`
Oh nevermind I see it will happen below.
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
This still doesn't seem correct. We're only invoking configuration if the plugin implements `Configurable` afaict. This does not work for `Converter`s implemented against the new API and assuming the "forward" configuration. We *must* always invoke the "old" `configure(Map, boolean)`, and only invoke the `Configurable` version as a backup. Possibly it would make sense to indicate on the `HeaderConverter` that the `Configurable` methods should be idempotent if we need to be able to implement both. Not sure if we can test this easily with unit tests, but I think we might want a plain old `Converter` (that does not implement `HeaderConverter`) in tests to validate compatibility... but it's possible we'd need either integration or system tests to properly validate.
I see that we need it from another package, I think it's ok.
maybe we can try to log the stacktrace in a try-finally block in hopes that we can get the full stacktrace? In the finally we can throw the Error
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
Nit: "doens't" -> "doesn't"
base -> based progress -> progressed
and -> a
nit add `a {@link Named} config`
Was this intentional? `VALUE_SERDE_CLASS_CONFIG` is deprecated.
as above (more often below -- please fit all)
nit: may worth explain how `queryableStoreName` can be find from `materialized` below.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
and -> a
This overload does not take `Materialized` parameter
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
We should use try-with-resources here (for `DataInputStream`).
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
We should use try-with-resources here (for `DataInputStream`).
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I think we should call `deserializer.close()` here
This TODO should be removed
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I think we should call `deserializer.close()` here
This TODO should be removed
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
Thanks for verifying @vvcephei!
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
nit: We could omit `res` and return directly in the two places below.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
an -> a
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
an -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
This TODO should be removed
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
nit: We could omit `res` and return directly in the two places below.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
an -> a
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
this file can go back to 140 chars as well...
Nit: `automattic` -> `automatic`
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I think this can all fit on one line more cleanly if you break after the equal sign.
can we detect this rather than catching this exception? I'd feel better about it if we could
This isn't thread-safe
This isn't thread-safe
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
this file can go back to 140 chars as well...
this seems like it could create a lot of garbage since we do this for every request. Can we maybe hold a version of this per clusterstate version and invaliate it once the clusterstate has changed...
Nit: `automattic` -> `automatic`
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
Why is `completed` count being tracked? It doesn't seem to be used anywhere.
Which future? Did you mean `Event`. I assume that `deadlineNs` is the deadline for scheduling/executing the `run` method. The `run` method can take longer than `deadlineNs`.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I think that these log parameters are backwards.
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think this can all fit on one line more cleanly if you break after the equal sign.
can we detect this rather than catching this exception? I'd feel better about it if we could
We should use try-with-resources here (for `DataInputStream`).
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think we should call `deserializer.close()` here
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
docCount is a a long so it's totally fine, sorry.
This isn't thread-safe
This isn't thread-safe
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
this file can go back to 140 chars as well...
this seems like it could create a lot of garbage since we do this for every request. Can we maybe hold a version of this per clusterstate version and invaliate it once the clusterstate has changed...
Nit: `automattic` -> `automatic`
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
this file can go back to 140 chars as well...
Nit: `automattic` -> `automatic`
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I think this can all fit on one line more cleanly if you break after the equal sign.
can we detect this rather than catching this exception? I'd feel better about it if we could
We should use try-with-resources here (for `DataInputStream`).
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think we should call `deserializer.close()` here
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
docCount is a a long so it's totally fine, sorry.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
This may indicate a bug in `SessionWindowedDeserializer`
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
There a two independent configs for the list-type and inner-type, hence it might be better to handle both independently: ``` if (listClass == null) { String listTypePropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_DESERIALIZER_TYPE_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_DESERIALIZER_TYPE_CLASS; listClass = (Class<List<Inner>>) configs.get(listTypePropertyName); if (listClass == null) { throw new ConfigException("Not able to determine the list class because it was neither passed via the constructor nor set in the config"); } } if (inner == null) { String innerDeserializerPropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_SERIALIZER_INNER_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_SERIALIZER_INNER_CLASS; Class<Deserializer<Inner>> innerDeserializerClass = (Class<Deserializer<Inner>>) configs.get(innerDeserializerPropertyName); inner = Utils.newInstance(innerDeserializerClass); inner.configure(configs, isKey); } ```
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
There a two independent configs for the list-type and inner-type, hence it might be better to handle both independently: ``` if (listClass == null) { String listTypePropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_DESERIALIZER_TYPE_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_DESERIALIZER_TYPE_CLASS; listClass = (Class<List<Inner>>) configs.get(listTypePropertyName); if (listClass == null) { throw new ConfigException("Not able to determine the list class because it was neither passed via the constructor nor set in the config"); } } if (inner == null) { String innerDeserializerPropertyName = isKey ? CommonClientConfigs.DEFAULT_LIST_KEY_SERIALIZER_INNER_CLASS : CommonClientConfigs.DEFAULT_LIST_VALUE_SERIALIZER_INNER_CLASS; Class<Deserializer<Inner>> innerDeserializerClass = (Class<Deserializer<Inner>>) configs.get(innerDeserializerPropertyName); inner = Utils.newInstance(innerDeserializerClass); inner.configure(configs, isKey); } ```
This is `ListDeserializer` hence, shouldn't we use `ConsumerConfig.LIST_KEY_DESERIALIZER_INNER_CLASS_CONFIG` ? The "SERDE" config should be used in Kafka Streams codebase only? (Same for value, and for both inner types in the next line).
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it ð
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
We should add a `null` check to allow closing a deserializer that was not properly setup
Use `KafkaException` instead of `RuntimeException`
Use `KafkaException` instead of `RuntimeException`
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Use `KafkaException` instead of `RuntimeException`
We should add a `null` check to allow closing a deserializer that was not properly setup
super nit: extra blank line
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
We should add a `null` check to allow closing a deserializer that was not properly setup
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
super nit: extra blank line
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Use `KafkaException` instead of `RuntimeException`
We should add a `null` check to allow closing a deserializer that was not properly setup
super nit: extra blank line
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
We should use try-with-resources here (for `DataInputStream`).
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
We should add a `null` check to allow closing a deserializer that was not properly setup
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
super nit: extra blank line
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
nit - an extra d? release**d**Delayed..
nit: mentioning the time unit seems redundant.
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
Should we also check that ``` final long start = SessionKeySerde.extractStart(bytes.get()); final long end = SessionKeySerde.extractEnd(bytes.get()); return end >= from && start <= to; ``` Although the current impl of RocksDBWIndowStore naturally checked that for us, it does not guarantee all underlying store impls guarantee that.
This is a slightly different test. The window is much larger to ensure all the entries are in the same window and the last timestamp for (a, 0005) is such that it causes the resuling composite key to come after the one for (aa, 0004)
@guozhangwang @dguy we cannot guarantee that all the entries for one key will necessarily precede the entries for the next key. The following code still fails with this patch, and only returns `0001` and `0003`, since the key for `("a", "0005")` will come after the key for `("aa", "0004")` ``` final RocksDBWindowStoreSupplier<String, String> supplier = new RocksDBWindowStoreSupplier<>( "window", 0x7a00000000000000L, 2, true, Serdes.String(), Serdes.String(), 0x7a00000000000000L, true, Collections.<String, String>emptyMap(), false); windowStore = supplier.get(); windowStore.init(context, windowStore); windowStore.put("a", "0001", 0); windowStore.put("aa", "0002", 0); windowStore.put("a", "0003", 1); windowStore.put("aa", "0004", 1); windowStore.put("a", "0005", 0x7a00000000000000L - 1); final List expected = Utils.mkList("0001", "0003", "0005"); assertThat(toList(windowStore.fetch("a", 0, Long.MAX_VALUE)), equalTo(expected)); ```
Note that `WindowStore.fetch()` should return `WindowStoreIterator` where the key is `Long` indicating timestamp and `value` is the value.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
`PrintForEachAction<>` to remove warning. Also in the `print` method
As i said above, we should `requireNonNull(mapper, ...)`
lets' introduce a dedicated exception for this. We can upgrade discovery.zen.NotMasterException to be in the cluster package and use that.
Should we also check that ``` final long start = SessionKeySerde.extractStart(bytes.get()); final long end = SessionKeySerde.extractEnd(bytes.get()); return end >= from && start <= to; ``` Although the current impl of RocksDBWIndowStore naturally checked that for us, it does not guarantee all underlying store impls guarantee that.
This is a slightly different test. The window is much larger to ensure all the entries are in the same window and the last timestamp for (a, 0005) is such that it causes the resuling composite key to come after the one for (aa, 0004)
@guozhangwang @dguy we cannot guarantee that all the entries for one key will necessarily precede the entries for the next key. The following code still fails with this patch, and only returns `0001` and `0003`, since the key for `("a", "0005")` will come after the key for `("aa", "0004")` ``` final RocksDBWindowStoreSupplier<String, String> supplier = new RocksDBWindowStoreSupplier<>( "window", 0x7a00000000000000L, 2, true, Serdes.String(), Serdes.String(), 0x7a00000000000000L, true, Collections.<String, String>emptyMap(), false); windowStore = supplier.get(); windowStore.init(context, windowStore); windowStore.put("a", "0001", 0); windowStore.put("aa", "0002", 0); windowStore.put("a", "0003", 1); windowStore.put("aa", "0004", 1); windowStore.put("a", "0005", 0x7a00000000000000L - 1); final List expected = Utils.mkList("0001", "0003", "0005"); assertThat(toList(windowStore.fetch("a", 0, Long.MAX_VALUE)), equalTo(expected)); ```
Note that `WindowStore.fetch()` should return `WindowStoreIterator` where the key is `Long` indicating timestamp and `value` is the value.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
`PrintForEachAction<>` to remove warning. Also in the `print` method
As i said above, we should `requireNonNull(mapper, ...)`
lets' introduce a dedicated exception for this. We can upgrade discovery.zen.NotMasterException to be in the cluster package and use that.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I don't think it's necessary to warn in this case. Maybe debug, but not warn. If callers are concerned, they can check the parameters before calling the method.
I don't think it's necessary to warn in this case. Maybe debug, but not warn. If callers are concerned, they can check the parameters before calling the method.
request "got" re-sent to the control
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
as above (more often below -- please fit all)
This overload does not take `Materialized` parameter
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
WDYT? ```suggestion log.warn("RetriableException caught on attempt {}, retrying automatically up to {} more times. " + "Reason: {}", attempt, maxAttempts - attempt, e.getMessage()); ```
Are we intentionally not logging the exception as the extra parameter? If the exception wraps a more useful exception, we won't see any information about the wrapped exception unless we can see the stack trace in the warning log message.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Yeah, I think it's worth the bit of logic to fail more quickly.
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
We should use try-with-resources here (for `DataInputStream`).
this can be replaced by just `ActionListener.wrap(runnable)`
super minor, but indentation is off here
hehe :) nice one
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
hehe :) nice one
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
make these parmaters to this method? then it doesn't really need to know about index creation requests.
I know Simon preferes if (Strings.isEmpty(field) == false) , shall we change it then? ;)
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
hehe :) nice one
This TODO should be removed
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
We should use try-with-resources here (for `DataInputStream`).
this can be replaced by just `ActionListener.wrap(runnable)`
super minor, but indentation is off here
hehe :) nice one
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
In cases like this, it's probably a bit more idiomatic in Connect to use a tertiary operator so that there is a single `return`: ```suggestion return inner == null ? null : usedPluginDesc(inner); ```
I see. Thank you.
Not sure we need this. For instance we don't allow to remove sorts on a SearchRequestBuilder.
It seems like these calls could be updated to use the `Record` itself instead of the key, value, and `InternalProcesorContext#recordContext`.
I realize that `pluginDesc` in this name is just the equivalent of `PluginDesc`, but generally we try to avoid abbreviations, which is probably more true in this case because the name seems even more mangled: ```suggestion PluginDesc<?> usedPluginDesc(String name) { ```
```suggestion public ClassLoader connectorLoader(Connector connector) { ```
It works fine with a runtime exception, you don't need to change the constructor: ``` IllegalArgumentException exc = expectThrows(IllegalArgumentException.class, () -> new NGramTokenizerFactory(indexProperties, null, name, settings).create()); ``` .. and then you can check the message of the exception.
nit: remove blank lines.
`now` is unnecessary.
nit: add `final` (we use `final` whenever possible)
I think the unlock calls should always be in a finally block
hehe :) nice one
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
Yeah, that works, too, and is more align with the current code.
can we detect this rather than catching this exception? I'd feel better about it if we could
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
format: ``` if (exception != null) throw exception; ```
Minor, but both places that use this could avoid assigning a value by always using the contents of `else` block if this were initialized to `0`. ``` Int cnt = termFreqMap.get(term); if (cnt == null) { cnt = new Int(); termFreqMap.put(term, cnt); } cnt.x += freq; ```
format: no need for curly braces
formatting: no need for curly braces here
I think the unlock calls should always be in a finally block
hehe :) nice one
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
Yeah, that works, too, and is more align with the current code.
can we detect this rather than catching this exception? I'd feel better about it if we could
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
format: ``` if (exception != null) throw exception; ```
Minor, but both places that use this could avoid assigning a value by always using the contents of `else` block if this were initialized to `0`. ``` Int cnt = termFreqMap.get(term); if (cnt == null) { cnt = new Int(); termFreqMap.put(term, cnt); } cnt.x += freq; ```
format: no need for curly braces
formatting: no need for curly braces here
I think the unlock calls should always be in a finally block
hehe :) nice one
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
Yeah, that works, too, and is more align with the current code.
can we detect this rather than catching this exception? I'd feel better about it if we could
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
format: ``` if (exception != null) throw exception; ```
Minor, but both places that use this could avoid assigning a value by always using the contents of `else` block if this were initialized to `0`. ``` Int cnt = termFreqMap.get(term); if (cnt == null) { cnt = new Int(); termFreqMap.put(term, cnt); } cnt.x += freq; ```
format: no need for curly braces
formatting: no need for curly braces here
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
grr nevermind I didn't see the last line pfff...
or N times
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
nit: could be useful to log the type of exception in the assertion message.
Maybe the `testConfiguration` methods should be called `checkConfiguration` to distinguish from the test cases. Similarly for `testInvalidConfiguration`.
I think I'd just do: ```java List<String> lines = asList(loginType.contextName() + " { ", jassConfigProp, "};") Files.write(jaasConfigFile.toPath, lines); ```
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
This TODO should be removed
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
This TODO should be removed
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
The one we are keen on is PLAIN. We will be using SASL with SSL, so PLAIN gives us the simplest secure authentication without having to distribute certificates for mutual client auth. Yes, a separate PR makes sense so that this one can be committed soon. I will raise another JIRA.
Can the mechanism be made a configuration option? I haven't looked through the code yet to see if the implementation relies on this mechanism, but it will be good if it was configurable.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
You might want change IntelliJ to use the `java.util.Objects.equals and hashCode (java 7+)` setting when generating `equals` and `hashCode` implementations -- it generates nicer, tighter code that plays better with our checkstyle.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
The one we are keen on is PLAIN. We will be using SASL with SSL, so PLAIN gives us the simplest secure authentication without having to distribute certificates for mutual client auth. Yes, a separate PR makes sense so that this one can be committed soon. I will raise another JIRA.
Can the mechanism be made a configuration option? I haven't looked through the code yet to see if the implementation relies on this mechanism, but it will be good if it was configurable.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
You might want change IntelliJ to use the `java.util.Objects.equals and hashCode (java 7+)` setting when generating `equals` and `hashCode` implementations -- it generates nicer, tighter code that plays better with our checkstyle.
```throws Exception ``` is useless.
`video_id` literal is not a video id.
`video_id` may be `None`.
Who cares about effectiveness when it's broken? With your comparator `'1080' < '720'` that is incorrect.
Doesn't work in python 2.6.
`height` must be int. Any optional metadata must not break extraction. Bother to read coding conventions.
... and then the call to instantiate AnsibleModule can look like this: ``` python self.module = AnsibleModule(argument_spec=merged_arg_spec, required_if=merged_required_if, **kwargs) ```
Not necessary now but to bear in mind for the future we're going to need to go through and change these to `except Exception as exc:`... that syntax will be compatible with python2.6+ (I saw that this module needs python-2.7) and python3 which will be the big push starting with ansible 2.2. (Tangential information -- for code that has to also be compatible with python < 2.6 we have a helper function: `module_utils.basic.get_exception` that can be used to get exception info.)
trivial but you can just do: ``` python path = expanduser("~/.azure/credentials") ``` so that you only allocate a string once instead of three times. (+= creates a new string)
Another py3 porting note for 2.2 and beyond: if you don't need to use `.iteritems()` (because the number of entries would be small) just use `.items()`. If you do need to use iteritems because the items take up a lot of memory, in 2.2 we'll be adding ansible.module_utils.six which has an iteritems function to replace the dict method.
```throws Exception ``` is useless.
`video_id` literal is not a video id.
`video_id` may be `None`.
Who cares about effectiveness when it's broken? With your comparator `'1080' < '720'` that is incorrect.
Doesn't work in python 2.6.
`height` must be int. Any optional metadata must not break extraction. Bother to read coding conventions.
... and then the call to instantiate AnsibleModule can look like this: ``` python self.module = AnsibleModule(argument_spec=merged_arg_spec, required_if=merged_required_if, **kwargs) ```
Not necessary now but to bear in mind for the future we're going to need to go through and change these to `except Exception as exc:`... that syntax will be compatible with python2.6+ (I saw that this module needs python-2.7) and python3 which will be the big push starting with ansible 2.2. (Tangential information -- for code that has to also be compatible with python < 2.6 we have a helper function: `module_utils.basic.get_exception` that can be used to get exception info.)
trivial but you can just do: ``` python path = expanduser("~/.azure/credentials") ``` so that you only allocate a string once instead of three times. (+= creates a new string)
Another py3 porting note for 2.2 and beyond: if you don't need to use `.iteritems()` (because the number of entries would be small) just use `.items()`. If you do need to use iteritems because the items take up a lot of memory, in 2.2 we'll be adding ansible.module_utils.six which has an iteritems function to replace the dict method.
```throws Exception ``` is useless.
`video_id` literal is not a video id.
Who cares about effectiveness when it's broken? With your comparator `'1080' < '720'` that is incorrect.
Doesn't work in python 2.6.
`height` must be int. Any optional metadata must not break extraction. Bother to read coding conventions.
... and then the call to instantiate AnsibleModule can look like this: ``` python self.module = AnsibleModule(argument_spec=merged_arg_spec, required_if=merged_required_if, **kwargs) ```
A better pattern for this is to make exec_module an abstract method (ie: one that the subclasses must implement). Then have the subclass call self.module.exit_json() directly. In python-2.6+ you can use the abc library: https://docs.python.org/2/library/abc.html or for something quick you can just do: ``` python def exec_module(self): raise NotImplementedError() ``` The subclasses then implement exec_module and do **not** call the base class's exec_module method.
Not necessary now but to bear in mind for the future we're going to need to go through and change these to `except Exception as exc:`... that syntax will be compatible with python2.6+ (I saw that this module needs python-2.7) and python3 which will be the big push starting with ansible 2.2. (Tangential information -- for code that has to also be compatible with python < 2.6 we have a helper function: `module_utils.basic.get_exception` that can be used to get exception info.)
trivial but you can just do: ``` python path = expanduser("~/.azure/credentials") ``` so that you only allocate a string once instead of three times. (+= creates a new string)
Another py3 porting note for 2.2 and beyond: if you don't need to use `.iteritems()` (because the number of entries would be small) just use `.items()`. If you do need to use iteritems because the items take up a lot of memory, in 2.2 we'll be adding ansible.module_utils.six which has an iteritems function to replace the dict method.
I've seen alternative solutions floating around that use a configurable source here. Basically, the configuration passed to configure() is consulted to find the "source cluster", rather than looking at the topic name. That approach lets you return an actual source here, which obviates the new canTrackSource() method etc.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
nit: It seems clearer to use `ConsumerPartitionAssignor.class` directly below.
If the subscription changes, the `onPartitionsRevoked` would be triggered and the owned-partitions in subscription would not include them. The original reasoning is just to make sure all partitions except the ones that are attempted for reassignment-hence-revocation-first are owned by someone. But like we discussed in the other PR, today we are not checking these conditions anyways, e.g.: 1. assignor assign one partition to multiple consumers. 2. assignor assign one partition to no one. They are both bad situations but Coordinator does not check for those today. We discussed about this and think it worth a more general solution as a separate JIRA.
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
nit: extra line
This is for possible future extensibility if we want to add new fields: with raw types (map) we'd have to change the signature of the API.
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
It should be public as it will be used in `producer` APIs.
request "got" re-sent to the control
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
nit: Since we are reusing this function for aggregations as well now, better rename to `createReparitionedSource`.
`counts` is not used
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
same - please name it something like `explainOrThrowRejectedCommand`
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
This should be 2.7 please.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Nit: ```suggestion * executed exactly once. If {@code maxRetries} is set to {@code n}, the callable will be executed at ```
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Also add `@params topics`
Wouldn't "application.port" be a better default? There's already "application.pid", "application.properties", "application.yml" etc.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
This should be 2.7 please.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Nit: ```suggestion * executed exactly once. If {@code maxRetries} is set to {@code n}, the callable will be executed at ```
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Also add `@params topics`
Wouldn't "application.port" be a better default? There's already "application.pid", "application.properties", "application.yml" etc.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
This should be 2.7 please.
Should we check the `key` is not null here? Since in later callers e.g. `final KeyQuery<Bytes, byte[]> rawKeyQuery = KeyQuery.withKey(keyBytes(typedKeyQuery.getKey()));` we do not check if `getKey()` is null or not, and `keyBytes` function could throw if it is.
Nit: ```suggestion * executed exactly once. If {@code maxRetries} is set to {@code n}, the callable will be executed at ```
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Also add `@params topics`
Wouldn't "application.port" be a better default? There's already "application.pid", "application.properties", "application.yml" etc.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
nit: we could define this transition list in a variable to be reused.
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
no need to use `this.` outside the constructor. Here and below
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
this is creative :)
state.isRunning() is as below ``` public boolean isRunning() { return equals(RUNNING) || equals(STARTING) || equals(PARTITIONS_REVOKED) || equals(PARTITIONS_ASSIGNED); } ``` if its not too much work, we can rename to something like `state.isAlive()` , that captures what we want to check .. your call.
This TODO should be removed
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
no need to use `this.` outside the constructor. Here and below
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
nit: in spite of the getter convention, I still prefer setters be prefixed with `set`
This TODO should be removed
Might be simpler to just update the Jira and do all at once? > Any thought about how the prefix text should look like? The suggestion you made via wrapping one `IllegalArgumentException` with the other, was good. Just you proposed "outer" error message could be used to be passed in as prefix.
> I felt the same, but I picked this approach to make less changes in the code, since I am beginner here. That's fair. However, we should not "optimize" for fewer changes but for better code. :) > But, I need to give a thought on kind of prefixes we should use to make it unique for various fail cases. `validateMillisecondDuration()` will just add the prefix. Each called can pass in whatever prefix is suitable for it.
why we don't we fail early in case hosts is empty? I see that the length check has been moved below
Hmm.. I'm wondering how did we succeed in this test case, since in the above code `send()` call is only captured with `TimeoutException`? Note that we only set the KafkaException in the callback while here we throw exception directly. And in fact, you changed the expected exception from StreamsException to KafkaException in line 128 above.
I don't think you need to divide at all - randomDouble is between 0 and 1, I believe.
I think we can remove the `to()` operator to verify if we don't fail with a NPE.
I think we'll run into an NPE in the failAndRemoveShard code: ``` private void failAndRemoveShard(ShardRouting shardRouting, IndexService indexService, boolean sendShardFailure, String message, @Nullable Throwable failure) { if (indexService.hasShard(shardRouting.getId())) { ```
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
yeah, this is tricky. I instead I think we can run a test that cancels from the running task and makes sure it is never run again? we can then decide whether to cancel immediately or after a few iterations
Sorry, my example included this initializer but it isn't needed. This is just for information: we can tidy up my mistake when we merge your changes.
I think `kafkaOffset` was incorrectly changed to `Long`. We'll always have a Kafka offset, so it should be `long`. Also, the current version breaks compatibility since the old signature constructor is no longer available.
nit: remove `which is`
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
Can we please not show an example of such a silly use of hamcrest matchers...this should just be assertTrue(true)...
As above for this and next ctor
If the subscription changes, the `onPartitionsRevoked` would be triggered and the owned-partitions in subscription would not include them. The original reasoning is just to make sure all partitions except the ones that are attempted for reassignment-hence-revocation-first are owned by someone. But like we discussed in the other PR, today we are not checking these conditions anyways, e.g.: 1. assignor assign one partition to multiple consumers. 2. assignor assign one partition to no one. They are both bad situations but Coordinator does not check for those today. We discussed about this and think it worth a more general solution as a separate JIRA.
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
It should be public as it will be used in `producer` APIs.
Why is `completed` count being tracked? It doesn't seem to be used anywhere.
Sorry, my example included this initializer but it isn't needed. This is just for information: we can tidy up my mistake when we merge your changes.
I think `kafkaOffset` was incorrectly changed to `Long`. We'll always have a Kafka offset, so it should be `long`. Also, the current version breaks compatibility since the old signature constructor is no longer available.
nit: remove `which is`
same here, s/subscriptions/newSubscriptions and `toOldSubscription`
Can we please not show an example of such a silly use of hamcrest matchers...this should just be assertTrue(true)...
As above for this and next ctor
If the subscription changes, the `onPartitionsRevoked` would be triggered and the owned-partitions in subscription would not include them. The original reasoning is just to make sure all partitions except the ones that are attempted for reassignment-hence-revocation-first are owned by someone. But like we discussed in the other PR, today we are not checking these conditions anyways, e.g.: 1. assignor assign one partition to multiple consumers. 2. assignor assign one partition to no one. They are both bad situations but Coordinator does not check for those today. We discussed about this and think it worth a more general solution as a separate JIRA.
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
It should be public as it will be used in `producer` APIs.
Why is `completed` count being tracked? It doesn't seem to be used anywhere.
Might be simpler to just update the Jira and do all at once? > Any thought about how the prefix text should look like? The suggestion you made via wrapping one `IllegalArgumentException` with the other, was good. Just you proposed "outer" error message could be used to be passed in as prefix.
> I felt the same, but I picked this approach to make less changes in the code, since I am beginner here. That's fair. However, we should not "optimize" for fewer changes but for better code. :) > But, I need to give a thought on kind of prefixes we should use to make it unique for various fail cases. `validateMillisecondDuration()` will just add the prefix. Each called can pass in whatever prefix is suitable for it.
why we don't we fail early in case hosts is empty? I see that the length check has been moved below
Hmm.. I'm wondering how did we succeed in this test case, since in the above code `send()` call is only captured with `TimeoutException`? Note that we only set the KafkaException in the callback while here we throw exception directly. And in fact, you changed the expected exception from StreamsException to KafkaException in line 128 above.
I don't think you need to divide at all - randomDouble is between 0 and 1, I believe.
I think we can remove the `to()` operator to verify if we don't fail with a NPE.
I think we'll run into an NPE in the failAndRemoveShard code: ``` private void failAndRemoveShard(ShardRouting shardRouting, IndexService indexService, boolean sendShardFailure, String message, @Nullable Throwable failure) { if (indexService.hasShard(shardRouting.getId())) { ```
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
yeah, this is tricky. I instead I think we can run a test that cancels from the running task and makes sure it is never run again? we can then decide whether to cancel immediately or after a few iterations
Even if the number of sub aggregation is expected to be small, I'm not too happy with the use of `ListIterator.add` which is linear on array lists.
I think ``` java if (prevParentDoc == -1) { childDocId = childDocs.nextDoc(); } else { if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc); } } ``` could just be replaced with ``` java if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc + 1); } ``` ? (No more check that the previous parent doc is -1, and advance to `prevParentDoc+1` instead of `prevParentDoc`)
Where do you cleanup the childrenSensors object? Otherwise we will maintain a reference to the Sensor objects always.
This class is public API, so we cannot remove `setTimestamp` but can only deprecate it. We also need to update the KIP to mention the deprecation and the newly added methods.
You can use joinFieldType.name() right? Instead of `joinField`
Perhaps we can lock the Sensor first and then lock the base metrics instance whenever we are removing a sensor. During addMetric, the sensor is locked first and then the Metrics object. If we follow the same pattern when doing removeSensor, we should not have any deadlocks right? What do you think? I'm still open to handling this in KAFKA-2419, but I want to be sure we have an acceptable solution.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
please add `{}` even if it is only one line
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
What do you think of: ``` private void handleReadResponse(long from, int maxOperationCount, long maxRequiredSeqNo, ShardChangesAction.Response response) { maybeUpdateMapping(response.getIndexMetadataVersion(), () -> { synchronized (ShardFollowNodeTask.this) { globalCheckpoint = Math.max(globalCheckpoint, response.getGlobalCheckpoint()); final long newMinRequiredSeqNo; if (response.getOperations().length == 0) { newMinRequiredSeqNo = from; } else { assert response.getOperations()[0].seqNo() == from : "first operation is not what we asked for. From is [" + from + "], got " + response.getOperations()[0]; buffer.addAll(Arrays.asList(response.getOperations())); final long maxSeqNo = response.getOperations()[response.getOperations().length - 1].seqNo(); assert maxSeqNo== Arrays.stream(response.getOperations()).mapToLong(Translog.Operation::seqNo).max().getAsLong(); newMinRequiredSeqNo = maxSeqNo + 1; // update last requested seq no as we may have gotten more than we asked for and we don't want to ask it again. lastRequestedSeqno = Math.max(lastRequestedSeqno, maxSeqNo); assert lastRequestedSeqno <= globalCheckpoint: "lastRequestedSeqno [" + lastRequestedSeqno + "] is larger than the global checkpoint [" + globalCheckpoint + "]"; coordinateWrites(); } if (newMinRequiredSeqNo < maxRequiredSeqNo) { int newSize = (int) (maxRequiredSeqNo - newMinRequiredSeqNo) + 1; LOGGER.trace("{} received [{}] ops, still missing [{}/{}], continuing to read...", params.getFollowShardId(), response.getOperations().length, newMinRequiredSeqNo, maxRequiredSeqNo); sendShardChangesRequest(newMinRequiredSeqNo, newSize, maxRequiredSeqNo); } else { // read is completed, decrement numConcurrentReads--; if (response.getOperations().length == 0 && globalCheckpoint == lastRequestedSeqno) { // we got nothing and we have no reason to believe asking again well get us more, treat shard as idle and delay // future requests LOGGER.trace("{} received no ops and no known ops to fetch, scheduling to coordinate reads", params.getFollowShardId()); scheduler.accept(idleShardChangesRequestDelay, this::coordinateReads); } else { coordinateReads(); } } } }); } ``` PS - note the difference in handling of `lastRequestedSeqno` - I think the way you had it had a bug.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
> In that case we always make a copy of the underlying array in ArrayList, Not if you change the request and such to use lists. > while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. which may be frequent (i.e., every request), which is why I was considering making a change.
I wonder if we should use an ArrayList with initial capacity. We can then change the request etc to use List<> instead of array
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
can we detect this rather than catching this exception? I'd feel better about it if we could
nit: remove the redundant line. Same as below.
`asList` -> `Collections.singletonList`
redundant type arguments `<ProducerRecord<byte[], byte[]`
yeah, this is tricky. I instead I think we can run a test that cancels from the running task and makes sure it is never run again? we can then decide whether to cancel immediately or after a few iterations
typo: byteArrray -> byteArray
NIT: noisy reformat :)
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
`< Callback >` this explicit type is not necessary.
`<byte[]>` this explicit type is unnecessary
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
The purpose of this change was to highlight that the data structure is required to be concurrent. Of course if a method that existed in `ConcurrentMap` and not in `Map` was used, that would be a hard requirement. `putIfAbsent` used to be such a method but that's not the case after 1.8. In any case, the use of the more accurate interface is valid even if we don't explicitly use methods that don't exist in the parent. That's because the need for this implementation to be thread safe is a requirement here.
Can `LogManager.getRootLogger().getLevel()` be `null`? With other loggers you return the effective level if that's the case.
What are your thoughts regarding returning the same `"No such logger"` value? It might be more informative to JMX users
I think you can initialize the capacity.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
Also add `@params topics`
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
The purpose of this change was to highlight that the data structure is required to be concurrent. Of course if a method that existed in `ConcurrentMap` and not in `Map` was used, that would be a hard requirement. `putIfAbsent` used to be such a method but that's not the case after 1.8. In any case, the use of the more accurate interface is valid even if we don't explicitly use methods that don't exist in the parent. That's because the need for this implementation to be thread safe is a requirement here.
Can `LogManager.getRootLogger().getLevel()` be `null`? With other loggers you return the effective level if that's the case.
What are your thoughts regarding returning the same `"No such logger"` value? It might be more informative to JMX users
I think you can initialize the capacity.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
Also add `@params topics`
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
The purpose of this change was to highlight that the data structure is required to be concurrent. Of course if a method that existed in `ConcurrentMap` and not in `Map` was used, that would be a hard requirement. `putIfAbsent` used to be such a method but that's not the case after 1.8. In any case, the use of the more accurate interface is valid even if we don't explicitly use methods that don't exist in the parent. That's because the need for this implementation to be thread safe is a requirement here.
Can `LogManager.getRootLogger().getLevel()` be `null`? With other loggers you return the effective level if that's the case.
What are your thoughts regarding returning the same `"No such logger"` value? It might be more informative to JMX users
I think you can initialize the capacity.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
Also add `@params topics`
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
The purpose of this change was to highlight that the data structure is required to be concurrent. Of course if a method that existed in `ConcurrentMap` and not in `Map` was used, that would be a hard requirement. `putIfAbsent` used to be such a method but that's not the case after 1.8. In any case, the use of the more accurate interface is valid even if we don't explicitly use methods that don't exist in the parent. That's because the need for this implementation to be thread safe is a requirement here.
Can `LogManager.getRootLogger().getLevel()` be `null`? With other loggers you return the effective level if that's the case.
What are your thoughts regarding returning the same `"No such logger"` value? It might be more informative to JMX users
I think you can initialize the capacity.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
Also add `@params topics`
@wicknicks would be useful to have some unit test for this class.
Is this the format required by the mbean stuff? It might be nice to return something more structured here.
how about `onGet` as a name instead of primer
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
The purpose of this change was to highlight that the data structure is required to be concurrent. Of course if a method that existed in `ConcurrentMap` and not in `Map` was used, that would be a hard requirement. `putIfAbsent` used to be such a method but that's not the case after 1.8. In any case, the use of the more accurate interface is valid even if we don't explicitly use methods that don't exist in the parent. That's because the need for this implementation to be thread safe is a requirement here.
Can `LogManager.getRootLogger().getLevel()` be `null`? With other loggers you return the effective level if that's the case.
What are your thoughts regarding returning the same `"No such logger"` value? It might be more informative to JMX users
I think you can initialize the capacity.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
Also add `@params topics`
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
nit: also add java doc for type `T, O` here
Works for me. Maybe just have an interface called Cancellable - it seems CancellableTask is taken.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
nit: also add java doc for type `T, O` here
Works for me. Maybe just have an interface called Cancellable - it seems CancellableTask is taken.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
nit: also add java doc for type `T, O` here
Works for me. Maybe just have an interface called Cancellable - it seems CancellableTask is taken.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
This logic is not exactly the most straightforward. What about something like this? ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { Versioned versioned; if (pluginImpl != null) { versioned = (Versioned) pluginImpl; } else { versioned = (Versioned) pluginKlass.newInstance(); } return versioned.version(); } return "undefined"; ``` or ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { if (pluginImpl == null) { pluginImpl = pluginKlass.newInstance(); } return ((Versioned) pluginImpl).version(); } return "undefined"; ```
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
This logic is not exactly the most straightforward. What about something like this? ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { Versioned versioned; if (pluginImpl != null) { versioned = (Versioned) pluginImpl; } else { versioned = (Versioned) pluginKlass.newInstance(); } return versioned.version(); } return "undefined"; ``` or ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { if (pluginImpl == null) { pluginImpl = pluginKlass.newInstance(); } return ((Versioned) pluginImpl).version(); } return "undefined"; ```
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
We should add a `null` check to allow closing a deserializer that was not properly setup
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I'd suggest try-catch each line separately since the underlying `RocksDBException` would not tell you which line actually went wrong, and this piece of info would be very useful for trouble shooting; ditto below.
I don't think it's important for now
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
The logic here is a bit over-complicated to me, can we simplify to sth like standard sort-merge here? We have e.g. `AbstractMergedSortedCacheStoreIterator` for a similar pattern.
new lines missing. Also we should assert this is never called. Also no need for `throws EngineException`
newline, no need for `throws EngineException`
I had the same thought, but I guess the point is to properly validate things when they get set to the builder, so that non supported values will never be serialized. I assume that we do that already, otherwise we should.
So as far as I see is this is the crucial change in this PR? I was wondering if might have undesired effects that we allow more field value types to be serialized/deserialized than before by using `writeGenericValue`. What would happen for example when fieldValue is a GeoPoint. It would have caused the serialization to trip previously, now it will be okay (and I guess it might cause error later). I guess switching to `writeGenericValue` is a good tradeoff here but would like to hear your ideas about that.
Can this be a `byte`.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
My understanding is that Jun is suggesting that we should set `checkHC` to true for the Java client if message format is 1.
I think `update the index` could be made clearer since the `DataInput` interface doesn't mention an index. Same for other similar cases.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
OMG `== false`! ð±
This is assuming that `totalTopics` is always a multiple of `MAX_BATCH_SIZE. Is that always true? Perhaps it is better not to make that assumption in any case.
@cmccabe Since `flush` blocks until all records are sent, wouldn't it be better to compute the delay time after flush completes? Ideally, an async flush would be better to avoid more delay than required, but that would need another thread. Alternative is not to flush at all, since only the records in the last incomplete batch would be delayed when `linger.ms > 0`.
ok...but client depends on the transport service anyway no? I think I don't get it
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
I don't think it's important for now
did you plan to add here the list of nodes or something? looks like there is a missing argument.
This seems like as super critical thing not to have a stronger assertion about. I think it is worth brainstorming a better test for a followup.
Are the sizes not configurable? The constants are too hidden here, it may be better to declare them as a static at the start of the class if not configurable.
nit: We could omit `res` and return directly in the two places below.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
I don't think it's important for now
did you plan to add here the list of nodes or something? looks like there is a missing argument.
This seems like as super critical thing not to have a stronger assertion about. I think it is worth brainstorming a better test for a followup.
Are the sizes not configurable? The constants are too hidden here, it may be better to declare them as a static at the start of the class if not configurable.
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
and -> a
base -> based progress -> progressed
This exception doesn't make sense, because the actual timeout exception will be a `LockObtainFailedException` that is thrown and not caught. The boolean is only returned if the `FileChannel` couldn't be locked
and -> a
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I see that we need it from another package, I think it's ok.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
nit: blank missing :P
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Yeah, I think it's worth the bit of logic to fail more quickly.
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
brackets in the URL
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
nit: "so we assume"...
I *think* `0xFF & b` would amount to the same thing and is a bit easier to read, at least it is for me.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Add the stream task id prefix here as well for both exception message and the warning log entry.
@cmccabe Since `flush` blocks until all records are sent, wouldn't it be better to compute the delay time after flush completes? Ideally, an async flush would be better to avoid more delay than required, but that would need another thread. Alternative is not to flush at all, since only the records in the last incomplete batch would be delayed when `linger.ms > 0`.
Just checking... Is the intent to roll back the "hack" to also catch UnknownProducerId and initiate a rebalance to recover? Note, if this was not the intent, then there are similar catch blocks below.
Thanks for clarifying this... Maybe we should update the Producer docs, since this is enormously subtle, but also important for handling correctly.
format: ``` if (exception != null) throw exception; ```
These methods can throw any number of other exceptions, which we would catch and wrap when called via `send`, but would **not** catch and wrap when called via `commit`...
```suggestion "\nThe broker is either slow or in bad state (like not having enough replicas) in responding to the request, " + ```
format: no need for curly braces
formatting: no need for curly braces here
req: I don't think we should call `maybeBeginTxn`, as we do that call during every send. If we are not in a transaction but calling `commit()`, that sounds like an illegal state to me, or we should just bypass the whole commit logic as it indicates we didn't do any send call in the past when EOS is turned on.
nit: extra line
It would be nice to have a unit test for this.
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
We should test that delete twice in a row fails with `IllegalStateException`
we need a consolidation of all the score mode / type we have at some point, not here though
Nit: extra blank line
Please fix identation.
maybe use `indexOf(...)` and then `indexInsert(...)` and `indexGet(...)` respectively to avoid determining what the slot is for a key several times? ```java final int slot = processedSeqNo.indexOf(bitArrayKey); if (processedSeqNo.indexExists(slot) == false) { processedSeqNo.indexInsert(slot, bitArrayKey, new FixedBitSet(bitArraysSize)); } return processedSeqNo.indexGet(slot); ```
ah, I didn't realize that. Maybe we should do this to make optimal use of the `slot`? ```java final int slot = processedSeqNo.indexOf(bitArrayKey); if (processedSeqNo.indexExists(slot) == false) { FixedBitSet bitSet = new FixedBitSet(bitArraysSize)); processedSeqNo.indexInsert(slot, bitArrayKey, bitSet); return bitSet; } else { return processedSeqNo.indexGet(slot); } ```
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
```suggestion * is {@code null}, no records are emitted. ``` Please also fix this on the original method
Nit: missing `@Override`
```suggestion * {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
nit: "so we assume"...
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
`limitedTo(long bytes)`? Clone is kinda non-specific.
good catch on delta > 0
Also not clear why "numSegments - 1" here.
no need for `throws EngineException`
new lines missing. Also we should assert this is never called. Also no need for `throws EngineException`
hmm... I really wonder if we are better off throwing in an exception here...
newline, no need for `throws EngineException`
newline also no need to write `throws EngineException`
newline, also no need to write `throws EngineException`
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
can we just return here to make it clear that we are baling out? We then don't need the further `if(!initializable.isEmpty())` checks below
+1. All for user readable assertions. If the bytes format is standardized then it should be tested in SubscriptionInfoTest.
We have exactly the same use case and are running into this exact same problem. We have multiple subscriptions (for split billing and authorizations) and having to set environment variables or perform 'az account set -s' commands is very prone to human error. The fact that hosts and related resources belong to specific azure subscriptions is mostly a detail that our operators aren't concerned with during their work.
nit (sorry): seems ungrammatical when the error message is appended. How about this? ``` "Expiring " + recordCount + " record(s) for " + topicPartition + ": " + expiryErrorMessage) ```
nit: would be nice to be consistent on the pattern we use here
Ah, you are right. Sorry.
Hmm.. This method is invoked from `unsubscribe`. It seems like we might want to use `onPartitionsRevoked` in that case because it can still be a graceful handoff.
How about `completeExpiration` or `expirationDone`? Also, do you think we should add safeguards to ensure that the batch can't be completed more than once? Maybe at least we can add an assertion that `expiryErrorMessage` is null in `RecordBatch.done`.
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
We should use try-with-resources here (for `DataInputStream`).
No need to check null. We always have to forward oldAgg and newAgg, anyway.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
nit: formatting -> only one parameter per line
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
I think we should call `deserializer.close()` here
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
We should use try-with-resources here (for `DataInputStream`).
No need to check null. We always have to forward oldAgg and newAgg, anyway.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
nit: formatting -> only one parameter per line
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and -> a
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and -> a
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
It's a little confusing that this is named newValue, but is sometimes actually priorValue
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
super nit: extra blank line
nit: break line
I'm +1 on supporting the timestamps, even if it's not commonly used now, users will often look to tests for example usage (at least I do). I'm also +1 on removing `childIndex` for the same reason, but I don't have too strong an opinion on that.
For this specific API, I suspect it is ever commonly used in PAPI, so I'm fine with not supporting it right away, also as a way to encourage users to change code sooner than later, if there's anyone.
Child-Index was deprecated recently -- should we remove it? Also, with KIP-251, we should capture output timestamps, too.
hehe :) nice one
nit: break line
For this specific API, I suspect it is ever commonly used in PAPI, so I'm fine with not supporting it right away, also as a way to encourage users to change code sooner than later, if there's anyone.
hehe :) nice one
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
if you put it like that, you can undo c08cd8b
this method seems to be only used at indexing time, so I don't think it should accept `nowInMillis` since index dates need to be concrete dates rather than math expressions
please make sure they are positive or don't use vint to serialize them
I'nm still missing the buffer size, the max requested seq no, leader global checkpoint , follower global checkpoint etc. I'm fine with a follow up for those, but that's what I meant.
do we have a todo to extend this to the new setup (in a follow up)? There's much more that should go here.
in this re-write, we have a lot more things we probably want to report in our status.
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
Nit: we use a single space after a period.
what's a requested topic partition? Also, above we mention just `partition`
Maybe we can say "Kafka admin client has been closed" for consistency with the consumer. When grepping, it's easier to if things are consistent across clients.
That assumes `list` can't contain null..if that is not the case ignore
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
`(seq# requested [{}], local checkpoint [{}]` is missing a closing `)`.
Typo: "temporary" -> "temporarily"
ok I wasn't sure, perfect
nit: `lastCommitMs + commitTimeMs < now` -> `now - lastCommitMs > commitTimeMs` IMHO, easier to read this way.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I also wonder if we should only have `Task.java` and have different ctors and if you don't pass a parentID you are not a child task? and default parent id is 0 just like in linux etc.
no need to use `this.` outside the constructor. Here and below
Update return type to `L` (if we introduce `L`)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
This TODO should be removed
I wonder if it is worth compressing the hitCount into byteSequence? That way you only have to store an array of ints? You'd have to cap `hitCount` at 255 but maybe that is ok? Or you could use an array of long and have tons of precision on your `hitCount`.
I'm fine with the answer being "no, you are crazy Nik" or "not right now".
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I also wonder if we should only have `Task.java` and have different ctors and if you don't pass a parentID you are not a child task? and default parent id is 0 just like in linux etc.
no need to use `this.` outside the constructor. Here and below
Update return type to `L` (if we introduce `L`)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
This TODO should be removed
I wonder if it is worth compressing the hitCount into byteSequence? That way you only have to store an array of ints? You'd have to cap `hitCount` at 255 but maybe that is ok? Or you could use an array of long and have tons of precision on your `hitCount`.
I'm fine with the answer being "no, you are crazy Nik" or "not right now".
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
super nit: ditto from above
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
This TODO should be removed
How about this transport configuration that we se to `NettyConnectionFactory`? @wilkinsona mentioned that on the original issue and we'd like some feedback on that.
As far as I can see you did not hence why I am asking here. The code I've referenced makes an explicit setup using `NettyConnectorFactory`. As far as I can see we'd lose that as soon as an url is set.
> That's not accurate. Sorry, poor choice of words. I meant that the auto-configuration doesn't do anything special when a broker url is set while it does something explicit (in code) when a host is set. We're very cautious to not introduce any inconsistency and the reason why I asked you here. Thanks for the follow-up and the feedback !
> What exactly is the concern with losing the explicit NettyConnectorFactory setup? That's most probably the source of the confusion. When a URL is set, no specific transport is set. When a host and port are set a `NettyConnectorFactory` transport is set. Looking a bit more `NettyConnectorFactory` seems the default implementation anyway so we'd use that as well. That wasn't clear hence why we asked explicitly.
Sorry, I thought the URL could be used to provide the username and password.
We should use try-with-resources here (for `DataInputStream`).
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
How about this transport configuration that we se to `NettyConnectionFactory`? @wilkinsona mentioned that on the original issue and we'd like some feedback on that.
As far as I can see you did not hence why I am asking here. The code I've referenced makes an explicit setup using `NettyConnectorFactory`. As far as I can see we'd lose that as soon as an url is set.
> That's not accurate. Sorry, poor choice of words. I meant that the auto-configuration doesn't do anything special when a broker url is set while it does something explicit (in code) when a host is set. We're very cautious to not introduce any inconsistency and the reason why I asked you here. Thanks for the follow-up and the feedback !
> What exactly is the concern with losing the explicit NettyConnectorFactory setup? That's most probably the source of the confusion. When a URL is set, no specific transport is set. When a host and port are set a `NettyConnectorFactory` transport is set. Looking a bit more `NettyConnectorFactory` seems the default implementation anyway so we'd use that as well. That wasn't clear hence why we asked explicitly.
Sorry, I thought the URL could be used to provide the username and password.
We should use try-with-resources here (for `DataInputStream`).
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
`before or after`
`of` -> `or`
nit. I think there is `.` missing `since 3.0[.] Use`
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
please add `{}` even if it is only one line
Hmm.. is this correct? If `forward(kv)` is called without childName or childIndex, it means sending to all children. So should this be `capture.childName == null || ...` ? Ditto above in line 414.
+1 then we shouldn't forget about it :)
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
I see that we need it from another package, I think it's ok.
`before or after`
`of` -> `or`
nit. I think there is `.` missing `since 3.0[.] Use`
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
please add `{}` even if it is only one line
Hmm.. is this correct? If `forward(kv)` is called without childName or childIndex, it means sending to all children. So should this be `capture.childName == null || ...` ? Ditto above in line 414.
+1 then we shouldn't forget about it :)
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
I see that we need it from another package, I think it's ok.
How about defining two helper methods, one for each cases? * `private void maybeRewrapAndThrow(ExecutionException exception)`; and * `private void maybeRewrapAndThrow(CompletionException exception)`
nit: Would it make sense to move `throw e` into `maybeRewrapAndThrow` to let `maybeRewrapAndThrow` throw in both cases? More generally, I wonder if we could handle all the case in `maybeRewrapAndThrow` and use it everywhere.
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
canceled -> cancelled
typo - failIfCancled -> failIfCanceled
could be named as `processingMode`
req: typo unknown Pid
Just my 2 cents: having a lot of factored-out code in tests usually hinders, rather than helps, maintainability. In the long run, the overall number of lines in the test file doesn't hurt anything, because you rarely sit down to read all the methods (typically, just while doing the review like this). After this PR is merged, you would almost always just be trying to read and understand a single method. Thus, it pays to optimize for single-method legibility. Having a test harness to go read, and other support methods to go read, just to understand this method is only going to get in the way. As it is right now, this method is 28 lines long, perfectly legible and clear. Trading clarity for de-duplication is a bad deal.
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
Same here - more randomization would be nice
How about defining two helper methods, one for each cases? * `private void maybeRewrapAndThrow(ExecutionException exception)`; and * `private void maybeRewrapAndThrow(CompletionException exception)`
nit: Would it make sense to move `throw e` into `maybeRewrapAndThrow` to let `maybeRewrapAndThrow` throw in both cases? More generally, I wonder if we could handle all the case in `maybeRewrapAndThrow` and use it everywhere.
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
canceled -> cancelled
typo - failIfCancled -> failIfCanceled
could be named as `processingMode`
req: typo unknown Pid
Just my 2 cents: having a lot of factored-out code in tests usually hinders, rather than helps, maintainability. In the long run, the overall number of lines in the test file doesn't hurt anything, because you rarely sit down to read all the methods (typically, just while doing the review like this). After this PR is merged, you would almost always just be trying to read and understand a single method. Thus, it pays to optimize for single-method legibility. Having a test harness to go read, and other support methods to go read, just to understand this method is only going to get in the way. As it is right now, this method is 28 lines long, perfectly legible and clear. Trading clarity for de-duplication is a bad deal.
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
Same here - more randomization would be nice
I think `update the index` could be made clearer since the `DataInput` interface doesn't mention an index. Same for other similar cases.
We should probably say `update the buffer position` instead of `update index`. Same for other similar cases.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
request "got" re-sent to the control
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
It looks like this could fit in 140 columns.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
These always read clearer to me as `<= 0`.
I think we can get rid of the ResolvedHostname abstraction - what am I missing? ``` diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java b/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java index 61bf1cc..3d3495e 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java @@ -242,40 +242,36 @@ public class UnicastZenPing extends AbstractComponent implements ZenPing { throw new IllegalArgumentException("resolve timeout must be non-negative but was [" + resolveTimeout + "]"); } // create tasks to submit to the executor service; we will wait up to resolveTimeout for these tasks to complete - final List<Callable<ResolvedHostname>> callables = + final List<Callable<TransportAddress[]>> callables = hosts.stream().map(hn -> lookup(hn, transportService, limitPortCounts)).collect(Collectors.toList()); - final List<Future<ResolvedHostname>> futures = + final List<Future<TransportAddress[]>> futures = executorService.invokeAll(callables, resolveTimeout.nanos(), TimeUnit.NANOSECONDS); final List<DiscoveryNode> discoveryNodes = new ArrayList<>(); // ExecutorService#invokeAll guarantees that the futures are returned in the iteration order of the tasks so we can associate the // hostname with the corresponding task by iterating together final Iterator<String> it = hosts.iterator(); - for (final Future<ResolvedHostname> future : futures) { + for (final Future<TransportAddress[]> future : futures) { final String hostname = it.next(); - if (!future.isCancelled()) { + if (future.isCancelled()) { + logger.warn("timed out after [{}] resolving host [{}]", resolveTimeout, hostname); + } else { + assert future.isDone(); // guaranteed by the invokeAll try { - final ResolvedHostname resolvedHostname = future.get(); - if (resolvedHostname.isSuccess()) { - logger.trace("resolved host [{}] to {}", hostname, resolvedHostname.addresses()); - for (final TransportAddress address : resolvedHostname.addresses()) { - discoveryNodes.add( - new DiscoveryNode( - idGenerator.get(), - address, - emptyMap(), - emptySet(), - Version.CURRENT.minimumCompatibilityVersion())); - } - } else { - final String message = "failed to resolve host [" + hostname + "]"; - logger.warn(message, resolvedHostname.failure()); + final TransportAddress[] addresses = future.get(); + logger.trace("resolved host [{}] to {}", hostname, addresses); + for (final TransportAddress address : addresses) { + discoveryNodes.add( + new DiscoveryNode( + idGenerator.get(), + address, + emptyMap(), + emptySet(), + Version.CURRENT.minimumCompatibilityVersion())); } } catch (final ExecutionException e) { final String message = "failed to resolve host [" + hostname + "]"; logger.warn(message, e); } - } else { - logger.warn("timed out after [{}] resolving host [{}]", resolveTimeout, hostname); } } return discoveryNodes; @@ -289,17 +285,11 @@ public class UnicastZenPing extends AbstractComponent implements ZenPing { * @param limitPortCounts the port count limit * @return a callable that can be used to submit to an executor service */ - private static Callable<ResolvedHostname> lookup( + private static Callable<TransportAddress[]> lookup( final String host, final TransportService transportService, final int limitPortCounts) { - return () -> { - try { - return ResolvedHostname.success(transportService.addressesFromString(host, limitPortCounts)); - } catch (final UnknownHostException e) { - return ResolvedHostname.failure(e); - } - }; + return () -> transportService.addressesFromString(host, limitPortCounts); } @Override ```
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
Nit: `automattic` -> `automatic`
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
It might be simpler to add a private constructor that allows to specify all 4 parameters: ``` return new StoreQueryParams<>(storeName, queryableStoreType, partition, staleStores); ``` Similar in other methods
As above -- incorrect return type description
`storeName` -> `state store name` (we should use natural language if possible, and avoid variable names)
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
no need to use `this.` outside the constructor. Here and below
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Actually let me put in this way: `restoredPartitions` could just be local to this function? It's only usage outside is in `clear` so it seems we can keep it local or just use `restored` directly and remove it from `clear`.
`to fetch list of stores` -- that describe some internal implementation detail. Better: `Get the store partition that will be queried.`
This method does not return a `String`. Maybe ``` @return StoreQueryParams a new {@code StoreQueryParams} instance configured with the specified partition ```
It might be simpler to add a private constructor that allows to specify all 4 parameters: ``` return new StoreQueryParams<>(storeName, queryableStoreType, partition, staleStores); ``` Similar in other methods
As above -- incorrect return type description
`storeName` -> `state store name` (we should use natural language if possible, and avoid variable names)
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
no need to use `this.` outside the constructor. Here and below
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Actually let me put in this way: `restoredPartitions` could just be local to this function? It's only usage outside is in `clear` so it seems we can keep it local or just use `restored` directly and remove it from `clear`.
`to fetch list of stores` -- that describe some internal implementation detail. Better: `Get the store partition that will be queried.`
This method does not return a `String`. Maybe ``` @return StoreQueryParams a new {@code StoreQueryParams} instance configured with the specified partition ```
We don't need this for files, right? Just for directories (because of `file.deleteOnExit`)
We should update the Scala `TestUtils` to call this method.
this needs a message
One more thing, let's call this `recordsOrFail` to make it clear that the operation is not necessarily safe.
No `else` needed since we used `return` for both other cases. For the exception, I think we can just throw `ClassCastException` since `IllegalStateException` doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more `Records` subtypes. For example: ```java "The record type is " + partition.records().getClass().getSimpleName() + ", which is not a subtype of " + Records.class.getSimpleName() + ". This method is only safe to call if the `FetchResponse` was deserialized from bytes."
Omit these lines please.
this method is unused but it maybe useful in the future.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
Actually, maybe `self.forward_layer`, `self.backward_layer` to be extra explicit.
`self.forward / self.reverse` is inconsistent, it should be `self.forward / self.backward`
Some of the internal awkwardness seems to be the result of not having a clear "list of classes" type. Not something we have to do here, but potential room for improvement.
ok, I was more worried about the handling to make sure that we don't support stored scripts, but indeed, the rest is just calling Script.parse so it is not a lot of code.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
shall we make the error message agnostic "on field []" and reuse the existing parse method? It will need to be moved to a common place I guess.
Shouldn't this be in the contract of `Utils.newInstance` to not return some other class that doesn't match? I think this is pulled from `AbstractConfig` which makes sense for consistency, but I don't get why `Utils.newInstance` would ever return a value with an invalid type.
I looked at it, and I think the scenario is a bit different in `public <T> T getConfiguredInstance(String key, Class<T> t)` as in here, where `Utils.newInstance(Class<T> c)` is called and the passed `Class<?>` is directly from the config, where in this case the config value is a `String` and we directly use that in `Utils.newInstance`.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
Some of the internal awkwardness seems to be the result of not having a clear "list of classes" type. Not something we have to do here, but potential room for improvement.
ok, I was more worried about the handling to make sure that we don't support stored scripts, but indeed, the rest is just calling Script.parse so it is not a lot of code.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
shall we make the error message agnostic "on field []" and reuse the existing parse method? It will need to be moved to a common place I guess.
Shouldn't this be in the contract of `Utils.newInstance` to not return some other class that doesn't match? I think this is pulled from `AbstractConfig` which makes sense for consistency, but I don't get why `Utils.newInstance` would ever return a value with an invalid type.
I looked at it, and I think the scenario is a bit different in `public <T> T getConfiguredInstance(String key, Class<T> t)` as in here, where `Utils.newInstance(Class<T> c)` is called and the passed `Class<?>` is directly from the config, where in this case the config value is a `String` and we directly use that in `Utils.newInstance`.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
Please fix identation.
we need a consolidation of all the score mode / type we have at some point, not here though
nit: extra line
It would be nice to have a unit test for this.
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
There is probably a generic pattern that you could factor out here. Basically you are providing a translation from `Map<K, V1>` to `Map<K, V2>` in both of these cases. So you could construct a generic `MapView` or something like that with a `Function<V1, V2>` and save some of the duplication.
Nit: extra blank line
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
`newMean` & `newVariance` (we don't do underscores in var names)
nit: 'else' can be dropped
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
Nit: you can call `Thread.enumerate` directly. Also, it would be good to assert that `threadCount` is < than `threads.length`.
nit: Maybe we can consolidate this logic into a function as well? E.g. "respondSentRequest" etc.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
if you put it like that, you can undo c08cd8b
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
Function calls are complex. For example: ``` from youtube_dl.jsinterp import JSInterpreter jsi = JSInterpreter(''' function a(x) { return x; } function b(x) { return x; } function c() { return [a, b][0](0); } ''') print(jsi.call_function('c')) ```
`newMean` & `newVariance` (we don't do underscores in var names)
nit: 'else' can be dropped
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
Nit: you can call `Thread.enumerate` directly. Also, it would be good to assert that `threadCount` is < than `threads.length`.
nit: Maybe we can consolidate this logic into a function as well? E.g. "respondSentRequest" etc.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
if you put it like that, you can undo c08cd8b
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
Function calls are complex. For example: ``` from youtube_dl.jsinterp import JSInterpreter jsi = JSInterpreter(''' function a(x) { return x; } function b(x) { return x; } function c() { return [a, b][0](0); } ''') print(jsi.call_function('c')) ```
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
No need to check null. We always have to forward oldAgg and newAgg, anyway.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
I also wonder if we should only have `Task.java` and have different ctors and if you don't pass a parentID you are not a child task? and default parent id is 0 just like in linux etc.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
No need to check null. We always have to forward oldAgg and newAgg, anyway.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
I also wonder if we should only have `Task.java` and have different ctors and if you don't pass a parentID you are not a child task? and default parent id is 0 just like in linux etc.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
That class is different because it doesn't actually `define` the config, it's just an undeclared "extra" config that gets passed around to be interpreted inside the serde. Actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
No need to check null. We always have to forward oldAgg and newAgg, anyway.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
I also wonder if we should only have `Task.java` and have different ctors and if you don't pass a parentID you are not a child task? and default parent id is 0 just like in linux etc.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I think we should call `deserializer.configure(...)` here
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
We should use try-with-resources here (for `DataInputStream`).
nit: line too long. `final` not required -- a static method cannot be overwritten anyway
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
Can we actually include UUID type? It always 16 bytes.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
Please get rid of this volatile. There is no longer a circular dependency here.
Minor typo of `local` instead of `locale` in the exception message.
DEFAUTL -> DEFAULT again
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
if you put it like that, you can undo c08cd8b
I realize the example already here used this form, but I think it is clearer to use `== false` for inverted conditions.
I think we should fix our datastrucuture first and don't make Path trie super complicated and flexible. This should be fixed first before we make this change here.
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
I think the answer to this question is that it is possible to expire while the batch is still being built because closing the batch can be arbitrarily delayed by inflight fetches.
I think it will be cleaner to have ShardInfo have a constructor that takes all parameters and set that on the finalResponse. This will make sure we will not forget anything in the future.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
nit: 'else' can be dropped
nit (sorry): seems ungrammatical when the error message is appended. How about this? ``` "Expiring " + recordCount + " record(s) for " + topicPartition + ": " + expiryErrorMessage) ```
How about `completeExpiration` or `expirationDone`? Also, do you think we should add safeguards to ensure that the batch can't be completed more than once? Maybe at least we can add an assertion that `expiryErrorMessage` is null in `RecordBatch.done`.
Ah, you are right. Sorry.
`.toString()` unnecessary here are other similar logs.
This should also be synchronized
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
If we could get rid of null check, `addChildrenProducerBatch` and `getChildrenProducerBatch` could be removed as well.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Nit: missing `@Override`
if you put it like that, you can undo c08cd8b
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
`before or after`
`out-of-order` `window closed`
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
Sounds interesting, cc @kkonstantine
nit. I think there is `.` missing `since 3.0[.] Use`
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
Nit: missing `@Override`
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
I see that we need it from another package, I think it's ok.
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
It works fine with a runtime exception, you don't need to change the constructor: ``` IllegalArgumentException exc = expectThrows(IllegalArgumentException.class, () -> new NGramTokenizerFactory(indexProperties, null, name, settings).create()); ``` .. and then you can check the message of the exception.
I don't think that we should move this code into the InetAddresses.java source file. That code is from the Guava code base, and is licensed to the Guava authors (see the license header). By moving this code which is not from Guava here we will create a confusing situation with respect to the licensing of the code. Let's take this code to IpFieldMapper.java.
This will silently ignore octets that are captured by the regular expression, but are in fact not valid octets.
It would be nice to have a unit test for this.
ok, fair enough
just please don't add one. There are too many classes already.
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
This function is used to resolve index constraint on field stats. I am not sure if we should implement index constraint on a geopoint field but if we don't then we should throw an exception here.
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
`null` check is redundant as `null instanceof StringDeserializer` will return false anyway.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I looked at it, and I think the scenario is a bit different in `public <T> T getConfiguredInstance(String key, Class<T> t)` as in here, where `Utils.newInstance(Class<T> c)` is called and the passed `Class<?>` is directly from the config, where in this case the config value is a `String` and we directly use that in `Utils.newInstance`.
Makes sense. There is still some cleanup to do.... `windowedDeserializer` is not use anymore in the test but only `windowedDeserializer1` -- also, setting up `props` has `put` and later `remove` that can both be removed... When cleaning up: consider what is *required* to set up the test, and what is not. Remove everything that is not required.
We should log an error that prints out what the two configs actually are
you don't use `windowedDeserializer ` or `inner` below -- can be removed IMHO
Not sure about this -- why not add two generics to the store, one for "wrapped" and one for "root" and keep this method that return the root type? I would also rename `inner()` -> `root()`
`wrappedStore()` should `return wrapped;` -- that's why I argue for renaming the variable.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
nit: empty line.
It actually seems like using the non-deprecated `put` method would improve this test's readability, since the verification depends on specific timestamps having been used in the put.
is this really needed we already have sooo much logging everywhere
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
can we change to use isRelocationTarget() instead? i.e., `isRelocationTarget() || primary == false`
Can we check that the hits information is correct in the response too? i.e. the hits are empty, the totalHits is correct and the maxScore is zero
good these variants go away...
nit: than -> then (or just leave it out)
I was talking about the delayed interrupt time. Ideally, the shorter it is, the faster the test terminates. So I thought we could use 1s instead of 2s.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
It's a bit better if you move this inside the `try` and remove the `return` from the catch.
master is the future 7.0, so I would do the following: ```java if (INDEX_MAPPER_DYNAMIC_SETTING.exists(indexSettings.getSettings())) { if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0)) { // 7.x index throw new IllegalArgumentException("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " was removed after version 6.0.0"); } else { // 6.x index DEPRECATION_LOGGER.deprecated("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " is deprecated since indices may not have more than one type anymore."); } } ``` Then when backporting I'll just remove the 7.x branch and make sure that we only emit a deprecation warning on 6.x indices (you don't need to worry about it).
I don't think so, that's relying too much on an internal implementation detail (that there is a cache, that file scripts are compiled and put into the static cache, that the key is the prefix of the filename, etc.). The purpose behind the PR is to get the script service to ignore hidden files, and that is what needs to be tested. I haven't looked too closely, but I suspect that you're going to have to hook into the script service or maybe the resource watcher and possibly refactor a little bit to expose the pieces needed to in fact make this assertion. Let me know if that's enough to get you started, I'm happy to take a closer look if needed. :)
This test is not really testing what we want to be testing here. The reason that it's not is because the cache key for a file named `".hidden_file"` is not `"hidden_file"`, but rather it is `""`. A file named `".hidden_file"` never would have been processed by the compilation engine because it doesn't have an extension. So this will ultimately throw, but not for the right reason.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
nit: break line
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
Nit: `A method for...` (as above)
Hmm.. is this correct? If `forward(kv)` is called without childName or childIndex, it means sending to all children. So should this be `capture.childName == null || ...` ? Ditto above in line 414.
So in my updated PR I change this line to line up with CompletableFuture.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
> A new method also means their code is then not binary compatible with older client versions. yep, the BC could be broken. What I really care is the source compatibility. It seems to me a public API should be source compatible to next major release :) This patch is good to go and we need more time (rather than vespene gas ... StarCraft is my favor game :) ) to reach consensus.
"do nothing" is probably the right thing here.
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
I think the implicit assumption is that the parent "foo" doesn't exist (yet), right? If so, shouldn't we assert that it actually does not exist prior to continuing? Or do we feel `TestUtils.tempDirectory();` is sufficient? (I think it is, but still wanted to ask.)
nit: seems unnecessary? similar for `State.FAILED` below.
nit: curious why `storeType` is not enum but raw string. Typo in `in_memory` could make it `ROCKS_DB` type. e.g. `in_memry`. Maybe it's register in `in(ROCKS_DB, IN_MEMORY),` when defining and checked there
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
We wouldn't have the confusing Double (it immediately makes me think, how/why can this be null). I expect we'd use -1 for the back compat case anyway? (e.g. just read a single double, and return { x, -1, -1 }).
Maybe we should add one case where `position > 0`.
I am not sure what you mean by `test multiple reads` here. I think we're testing two things here: 1. That the first read doesn't cause a side-effect to the channel that could prevent the second read from succeeding. 2. That we can read into a smaller buffer than what's in the file channel. "multiple reads" is a little unclear as it sounds like we are causing the underlying file channel to do multiple reads, which I don't think we are.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
Again, lines L#118 to L#123 can be replaced by: ``` assignment.keySet().retainAll(userAssignment); ``` same effect, as we want the intersection of `assignment` and `userAssignment`
`.toString()` unnecessary here are other similar logs.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
This should also be synchronized
If we could get rid of null check, `addChildrenProducerBatch` and `getChildrenProducerBatch` could be removed as well.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
Do we actually have to mock `generation()` and `rawConfig()` for this test? Looking at `connector()`, it looks like it only relies on the snapshot.
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Nit: missing `@Override`
nice fix! this has been bothering me.
Yeah, that's a good point. Scratch that idea.
I originally thought the semantics of unsubscribe() is blacklisting. For example: subscribe("PageView*") unsubscribe("PageViewTopicA") will subscribe to all page-view topics except page-view-A. Arguably this can be done solely in subscribe() with"^" in regex, but I feel this semantics is more natural for users.
@SinghAsDev @guozhangwang I wonder if we could support blacklist filtering through a second argument to subscribe. For example: ``` java void subscribe(Pattern whitelist, Pattern blacklist); ``` This might get around some of the complexity mentioned above.
This is an interesting discussion. I don't have the full context of these discussions, but I can see the argument for keeping things simple and letting users rely on the regular expression for achieving their goals. I am not sure if it's any simpler to provide two separate regular expressions than just one with the appropriate negation. The latter is easier to write a unit test for too.
Would it have to? I would see each call to subscribe as replacing the previous one. Perhaps if we wanted to support multiple regex subscriptions, we could do: ``` java void subscribe(List<Pattern> patterns); ``` And we could require users to use '^' for blacklisting. This would be consistent with the changes proposed in KAFKA-2388.
as above: we need to remove adminPrefix configs
Again, lines L#118 to L#123 can be replaced by: ``` assignment.keySet().retainAll(userAssignment); ``` same effect, as we want the intersection of `assignment` and `userAssignment`
and -> a
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
You might consider using any `public static` utilities in `ConfigDef`/`AbstractConfig` to help with this here. I know at least `ConfigDef.parseType` could help here since it also does things like trim the string. Reusing that code will keep this closer to the normal behavior of `ConfigDef`s (and if we eventually move this functionality to be part of `ConfigDef` itself, will probably make it a simpler transition).
Do we actually have to mock `generation()` and `rawConfig()` for this test? Looking at `connector()`, it looks like it only relies on the snapshot.
`.toString()` unnecessary here are other similar logs.
I don't think we need to mock `generation()` in this test.
you can just do the conversion to unmodifiable map one time in the constructor. it looks like at the moment this is only accessed in tests anyway.
might want to rename `workerId` so it doesn't shadow the member field. something like `workerIdOpt` could work
ah, right. nah, that's fine. just when reviewing I had the thought that if we guaranteed non-`null`/non-empty in the constructor, this wouldn't be necessary. i realized that it was actually intentional, but easy to miss when reviewing here and not getting the same highlighting as an IDE
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
always what? I can't even :)
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
nit: 'else' can be dropped
The task name is incorrect (copy-paste error). Please, consider introducing a proper task name: ```yaml - name: gather the time at the end of the operation ```
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
and -> a
I see that we need it from another package, I think it's ok.
Nit: `A method for getting...` sounds clumsy to me
This method is also deprecated. We should throw same exception as for `childIndex`.
Nit: `A method for...` (as above)
Just curious, could we possibly call this function for the same node more than once? It seems yes as you are checking `!keyChangingOperationsToOptimizableRepartitionNodes.containsKey(node)` here, but I cannot tell from the code...
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
Generally speaking we should not rely on the caller to pass in parameters that are guaranteed to no pass the check. What I suggested (below) is to have a slightly modified recursion pattern which do not rely that the first caller would never satisfy the predicate.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
I think it will be cleaner to have ShardInfo have a constructor that takes all parameters and set that on the finalResponse. This will make sure we will not forget anything in the future.
We should try to take the rest status from the exception. See ShardSearchFailure
oh so this is not new stuff? If it was already there this way leave it, please!
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
We have dedup in this PR already (line 161-163). The `lastSeenSeqNo` is used for dedup and range check. I am fine to remove the primary sort and dedup mechanism.
I see. I missed it. I think it's surprising to put it in `readDocAsOp` and shortcut. I'd prefer to do it in `next` where do all our state updates and then everything together. it's rare anyway and doesn't require optimization imo. That said, it's all nits. If you prefer it otherwise I'm good. Thanks for clarifying.
I also wonder if we want to pull the `tombstoneDV` in the ctor next to `List<LeafReaderContext> leaves` and a `List<NumericDocValues>` for seqIds... I think this would be nice and prevent getting stuff from the reader over and over again.
I wonder if we can pull all these in the constructor into an array that we can access by index of the leaf reader. this is how we do things in lucene for stuff we access frequently.
I think I need to reset the DV :)
@s1monw I tried but realized that `NumericDocValues#advanceExact` method requires increasing docID values but it's not the case here. Do you have any suggestion for this? ``` /** Advance the iterator to exactly {@code target} and return whether * {@code target} has a value. * {@code target} must be greater than or equal to the current * {@link #docID() doc ID} and must be a valid doc ID, ie. &ge; 0 and * &lt; {@code maxDoc}. * After this method returns, {@link #docID()} retuns {@code target}. */ public abstract boolean advanceExact(int target) throws IOException; ```
I will make it in a follow-up.
this is unnecessary.
please don't load stuff lazily. go and load it all in the ctor. they are in memory anyways.
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
We have dedup in this PR already (line 161-163). The `lastSeenSeqNo` is used for dedup and range check. I am fine to remove the primary sort and dedup mechanism.
I see. I missed it. I think it's surprising to put it in `readDocAsOp` and shortcut. I'd prefer to do it in `next` where do all our state updates and then everything together. it's rare anyway and doesn't require optimization imo. That said, it's all nits. If you prefer it otherwise I'm good. Thanks for clarifying.
I also wonder if we want to pull the `tombstoneDV` in the ctor next to `List<LeafReaderContext> leaves` and a `List<NumericDocValues>` for seqIds... I think this would be nice and prevent getting stuff from the reader over and over again.
I wonder if we can pull all these in the constructor into an array that we can access by index of the leaf reader. this is how we do things in lucene for stuff we access frequently.
I think I need to reset the DV :)
@s1monw I tried but realized that `NumericDocValues#advanceExact` method requires increasing docID values but it's not the case here. Do you have any suggestion for this? ``` /** Advance the iterator to exactly {@code target} and return whether * {@code target} has a value. * {@code target} must be greater than or equal to the current * {@link #docID() doc ID} and must be a valid doc ID, ie. &ge; 0 and * &lt; {@code maxDoc}. * After this method returns, {@link #docID()} retuns {@code target}. */ public abstract boolean advanceExact(int target) throws IOException; ```
I will make it in a follow-up.
this is unnecessary.
please don't load stuff lazily. go and load it all in the ctor. they are in memory anyways.
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
if you put it like that, you can undo c08cd8b
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
Not sure if we need to do that it's just one entry per field though.
should we use a native trove collection here from String to long
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
space after Ì<`
nit: I would rather use the full name instead of using acronyms.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
I think we should call `deserializer.close()` here
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
This seems like as super critical thing not to have a stronger assertion about. I think it is worth brainstorming a better test for a followup.
static is not needed.
can we be slightly more verbose on why this is use full? (different deserialization logic based on key in parent map)
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
This should be the last step
This should also go away.
Considering that we may have multiple `WebServiceMessageSender`, I don't think we should expose this method here. You can provide a configured `WebServiceMessageSender`, this feels weird to me that all of them are reconfigured behind the scenes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
This should be the last step
This should also go away.
Considering that we may have multiple `WebServiceMessageSender`, I don't think we should expose this method here. You can provide a configured `WebServiceMessageSender`, this feels weird to me that all of them are reconfigured behind the scenes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
Also, maybe we should assert that `numExceptionReceivedInCallback.get() > 0` if we expect at least one to fail (in theory, if `numSentRecords == 100`, there would be no exceptionReceivedInCallback).
Maybe we can have a numRecords variable for the `100`.
Hmm, I'd just generate the randoms during set-up and add them to an array.
We don't want to be converting from int to string in the benchmark code.
Cool. @lkokhreidze did you create a ticket already? (Just want to make sure we don't drop this on the floor.)
Similar to above: we should be able to test with via unit tests using `Topology#describe()`
I had a similar thought, that it looks like good fodder for unit testing, but I did like the safety blanket of verifying the actual partition counts. I guess I'm fine either way, with a preference for whatever is already in the PR ;)
> Mainly because I was more comfortable verifying that topics actually get created when using repartition operation. I guess that is fair. (I just try to keep test runtime short if we can -- let's keep the integration test.)
Do we need an integration test for this? Using `Topology#describe()`, I think we could verify this with a unit test.
Ok. Thanks for clarifying.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
This should be the last step
This should also go away.
Considering that we may have multiple `WebServiceMessageSender`, I don't think we should expose this method here. You can provide a configured `WebServiceMessageSender`, this feels weird to me that all of them are reconfigured behind the scenes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
as above. use `StreamsConfig#...`
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
no need to use `this.` outside the constructor. Here and below
This has been fixed by: https://github.com/apache/kafka/pull/8291 Please omit and rebase to get the latest changes.
Sounds interesting, cc @kkonstantine
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
base -> based progress -> progressed
Yeah it makes sense. Sorry for not getting back to you sooner
and -> a
request "got" re-sent to the control
and -> a
I see that we need it from another package, I think it's ok.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
This has been fixed by: https://github.com/apache/kafka/pull/8291 Please omit and rebase to get the latest changes.
Sounds interesting, cc @kkonstantine
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
base -> based progress -> progressed
Yeah it makes sense. Sorry for not getting back to you sooner
and -> a
request "got" re-sent to the control
and -> a
I see that we need it from another package, I think it's ok.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
This has been fixed by: https://github.com/apache/kafka/pull/8291 Please omit and rebase to get the latest changes.
Sounds interesting, cc @kkonstantine
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
base -> based progress -> progressed
Yeah it makes sense. Sorry for not getting back to you sooner
and -> a
request "got" re-sent to the control
and -> a
I see that we need it from another package, I think it's ok.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`expectedType.cast(e)` should remove the need for the unchecked suppression.
CCE is never a good idea to throw out - especially since it forces the caller to handle it. It should be handled inside convert directly.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
We should use try-with-resources here (for `DataInputStream`).
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
Shouldn't this check instead be: `if (!(obj instanceof SuggestionBuilder))` Because sub-classes of this class will call its equals to test the equality of its specific private fields.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`expectedType.cast(e)` should remove the need for the unchecked suppression.
CCE is never a good idea to throw out - especially since it forces the caller to handle it. It should be handled inside convert directly.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
We should use try-with-resources here (for `DataInputStream`).
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
Shouldn't this check instead be: `if (!(obj instanceof SuggestionBuilder))` Because sub-classes of this class will call its equals to test the equality of its specific private fields.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
always what? I can't even :)
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
always what? I can't even :)
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
@SinghAsDev @guozhangwang I wonder if we could support blacklist filtering through a second argument to subscribe. For example: ``` java void subscribe(Pattern whitelist, Pattern blacklist); ``` This might get around some of the complexity mentioned above.
Would it have to? I would see each call to subscribe as replacing the previous one. Perhaps if we wanted to support multiple regex subscriptions, we could do: ``` java void subscribe(List<Pattern> patterns); ``` And we could require users to use '^' for blacklisting. This would be consistent with the changes proposed in KAFKA-2388.
Yeah, that's a good point. Scratch that idea.
I originally thought the semantics of unsubscribe() is blacklisting. For example: subscribe("PageView*") unsubscribe("PageViewTopicA") will subscribe to all page-view topics except page-view-A. Arguably this can be done solely in subscribe() with"^" in regex, but I feel this semantics is more natural for users.
This is an interesting discussion. I don't have the full context of these discussions, but I can see the argument for keeping things simple and letting users rely on the regular expression for achieving their goals. I am not sure if it's any simpler to provide two separate regular expressions than just one with the appropriate negation. The latter is easier to write a unit test for too.
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
@guozhangwang Yep, sounds good to me.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
@SinghAsDev @guozhangwang I wonder if we could support blacklist filtering through a second argument to subscribe. For example: ``` java void subscribe(Pattern whitelist, Pattern blacklist); ``` This might get around some of the complexity mentioned above.
Would it have to? I would see each call to subscribe as replacing the previous one. Perhaps if we wanted to support multiple regex subscriptions, we could do: ``` java void subscribe(List<Pattern> patterns); ``` And we could require users to use '^' for blacklisting. This would be consistent with the changes proposed in KAFKA-2388.
Yeah, that's a good point. Scratch that idea.
I originally thought the semantics of unsubscribe() is blacklisting. For example: subscribe("PageView*") unsubscribe("PageViewTopicA") will subscribe to all page-view topics except page-view-A. Arguably this can be done solely in subscribe() with"^" in regex, but I feel this semantics is more natural for users.
This is an interesting discussion. I don't have the full context of these discussions, but I can see the argument for keeping things simple and letting users rely on the regular expression for achieving their goals. I am not sure if it's any simpler to provide two separate regular expressions than just one with the appropriate negation. The latter is easier to write a unit test for too.
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
@guozhangwang Yep, sounds good to me.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
nit: We could omit `res` and return directly in the two places below.
the naming used above seems better here ```suggestion Throwable exception = null; ```
This TODO should be removed
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
can we give that a better name that describes what the function does? something like `checkCommittedAndSendCommitIfSo()`.
same as above, function name says nothing about what it does.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
nit: We could omit `res` and return directly in the two places below.
the naming used above seems better here ```suggestion Throwable exception = null; ```
I think we don't need this line or the following two, since they duplicate docs found elsewhere.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
does this need to be public and also does this class need to be subclassable
This TODO should be removed
can we give that a better name that describes what the function does? something like `checkCommittedAndSendCommitIfSo()`.
same as above, function name says nothing about what it does.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
```suggestion serial_port=dict(type='int', required=True), ```
I think all the `serial_` prefixes are repetitive. I think this module should be renamed `cpm_serial_port` then you can just remove all the `serial_` prefixes. This would also remove confusion on whether this module is configuring serial or network ports.
I believe it should be type+device_name/service_uri/file_path.
Need to update example with respect to new list parameter.
I find a list of dict easier to handle rather than dict of dict.
```suggestion serial_port_info = list() ```
This module fails in check mode since it is not calling `module.exit_json()`. Since this module does not look at the state and compare it before making changes, I would suggest removing check mode support from the module currently.
I maybe wrong but we are getting user input for `yield_on_poll` but you are not using here.
If we change the definition of the available memory here, we may have to change a few other places as well. e.g. `deallocate()`, `unallocatedMemory()`, etc.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
Right, sorry I misread that line.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Let's check that `previouslyAllocated`'s capacity is `batchSize` else `buffer.limit(sizeBytes)` is going to throw with a less useful stacktrace.
For things like fielddata I think it's an important requirement
for some caches it would be nice to make sure to not compute twice the same value
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Or not. It looks like you are allowed to modify the segment's innards while you have this lock.
I was getting confused by invalidateAll - on second inspection you hold both locks when clearing the maps.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
```suggestion serial_port=dict(type='int', required=True), ```
I think all the `serial_` prefixes are repetitive. I think this module should be renamed `cpm_serial_port` then you can just remove all the `serial_` prefixes. This would also remove confusion on whether this module is configuring serial or network ports.
I believe it should be type+device_name/service_uri/file_path.
Need to update example with respect to new list parameter.
I find a list of dict easier to handle rather than dict of dict.
```suggestion serial_port_info = list() ```
This module fails in check mode since it is not calling `module.exit_json()`. Since this module does not look at the state and compare it before making changes, I would suggest removing check mode support from the module currently.
I maybe wrong but we are getting user input for `yield_on_poll` but you are not using here.
Update return type to `L` (if we introduce `L`)
We should use try-with-resources here (for `DataInputStream`).
Update return type to `L` (if we introduce `L`)
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I think the old indentation was a bit better than this.
docCount is a a long so it's totally fine, sorry.
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
hehe :) nice one
`counts` is not used
Update return type to `L` (if we introduce `L`)
We should use try-with-resources here (for `DataInputStream`).
Update return type to `L` (if we introduce `L`)
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I think the old indentation was a bit better than this.
docCount is a a long so it's totally fine, sorry.
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
hehe :) nice one
`counts` is not used
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I think we should call `deserializer.close()` here
It might be simpler to add a private constructor that allows to specify all 4 parameters: ``` return new StoreQueryParams<>(storeName, queryableStoreType, partition, staleStores); ``` Similar in other methods
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
As above -- incorrect return type description
No need to check null. We always have to forward oldAgg and newAgg, anyway.
`storeName` -> `state store name` (we should use natural language if possible, and avoid variable names)
docCount is a a long so it's totally fine, sorry.
hehe :) nice one
This condition will never evaluate to `true` as we'll get an NPE when dereferencing a `null` instance of type `ExecutorHolder` in the line above.
can we use the ThreadPool#info API here, so we don't have to cast to `ThreadPoolExecutor`, and be able to get the max back through the info class.
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
can we add that to ClusterStateCreationUtils? It might be useful for others as well
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
Hmm, this doesn't need to block merging this, but we should think carefully about doing delay this way. The rest of Connect avoids trying to rely on Java's `interrupt` behavior because it's not really a reliable way to *actually* interrupt threads, and in a system where there are pluggable components that are allowed to block indefinitely, relying on functionality that most Java developers don't understand well probably isn't going to work all that well. It may not have actually gotten to a KIP, but there was at least some discussion on a JIRA somewhere about making connect perform interrupts in addition to the basic task `stop()` calls it already does, but it doesn't currently do this. For anything that can end up with pretty long sleep periods, we should try to make sure there's a good way of interrupting it and moving on (e.g. so rebalances wouldn't get delayed because there's a connector that's encountering errors). At a minimum, since we don't do interrupts currently, I think we wouldn't interrupt this code currently. The other approach we use elsewhere is to `wait` on a monitor so we can set a flag and interrupt with `notify` and have it bail out immediately.
I guess something went wrong.. no biggy.
Setter methods again.
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
Well, it shouldnt be. The suppressed exceptions are like 'children' of `cause`, they don't need to be shuffled around. The current code is basically attaching grandchildren as children, which will be confusing.
We should nuke all this logic after the `super` call, because now we init the exception with `ex` as root cause, so it will still keep all of its suppressed exceptions.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
This changes behaviour as any exception from the `close()` call will no longer be caught and logged as a warning.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Well, it shouldnt be. The suppressed exceptions are like 'children' of `cause`, they don't need to be shuffled around. The current code is basically attaching grandchildren as children, which will be confusing.
We should nuke all this logic after the `super` call, because now we init the exception with `ex` as root cause, so it will still keep all of its suppressed exceptions.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
the naming used above seems better here ```suggestion Throwable exception = null; ```
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
This is logic that I think should go into ReplicatedOperation.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
I think this `if/else` block here can be removed and just go with ``` java for (final ProcessorNode child : children) { forward(child, key, value); } ```
Yeah if it exists elsewhere let's just leave it as is for now.
Let's remove on both side: I think in J8 it is not really a big difference.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
s/The tasks has/In case the task has/
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
Wearing my performance paranoid hat here: unlike the StreamsBuilder's `Materialized / Consumed / etc` constructs which is only used once, this is actually on the very critical path of the processing of each record, and on average the forward call itself can be triggered many times per record. So I'm a bit concerning about the new `To` object per call to the timestamp setters here. Could we do some benchmarking say with the simple benchmark code and watch the GC metrics to analyze its impact? If it shows non-neglectable overhead I'd suggest we re-consider its API to, for example, adding overloaded `forward(k, v, timestamp)` instead.
Let's remove on both side: I think in J8 it is not really a big difference.
I think this `if/else` block here can be removed and just go with ``` java for (final ProcessorNode child : children) { forward(child, key, value); } ```
Yeah if it exists elsewhere let's just leave it as is for now.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
s/The tasks has/In case the task has/
This is redundant. getDelayAllocationExpirationIn also calls getAllocationDelayTimeoutSetting()==0 and returns 0 in that case.
I was checking the code in the protobuf repository and it turns out that the optimised version of this code is pretty complex: https://github.com/google/protobuf/blob/master/java/core/src/main/java/com/google/protobuf/CodedInputStream.java#L2473 I think it makes sense to start with the simple implementation, but we should file a JIRA for considering the optimisations in their implementation.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
if you put it like that, you can undo c08cd8b
I *think* `0xFF & b` would amount to the same thing and is a bit easier to read, at least it is for me.
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
Can we actually include UUID type? It always 16 bytes.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
@acogoluegnes Using 5.1.x seems like the best option purely from Boot's perspective. Is 5.1 backwards compatible with 5.0 or is it likely to cause problems for Spring AMQP do you know? /cc @garyrussell @artembilan
I just tested master against 5.1.1 with no problems.
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
Can we actually include UUID type? It always 16 bytes.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
@acogoluegnes Using 5.1.x seems like the best option purely from Boot's perspective. Is 5.1 backwards compatible with 5.0 or is it likely to cause problems for Spring AMQP do you know? /cc @garyrussell @artembilan
I just tested master against 5.1.1 with no problems.
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
Can we actually include UUID type? It always 16 bytes.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
@acogoluegnes Using 5.1.x seems like the best option purely from Boot's perspective. Is 5.1 backwards compatible with 5.0 or is it likely to cause problems for Spring AMQP do you know? /cc @garyrussell @artembilan
I just tested master against 5.1.1 with no problems.
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
Can we actually include UUID type? It always 16 bytes.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
@acogoluegnes Using 5.1.x seems like the best option purely from Boot's perspective. Is 5.1 backwards compatible with 5.0 or is it likely to cause problems for Spring AMQP do you know? /cc @garyrussell @artembilan
I just tested master against 5.1.1 with no problems.
Let's call that `DataSize` and move that to `org.springframework.boot.unit`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
Can we actually include UUID type? It always 16 bytes.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
@acogoluegnes Using 5.1.x seems like the best option purely from Boot's perspective. Is 5.1 backwards compatible with 5.0 or is it likely to cause problems for Spring AMQP do you know? /cc @garyrussell @artembilan
I just tested master against 5.1.1 with no problems.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
I should have used a better exception type initially. Because the class is indeed found. Probably `ClassCastException` would be more appropriate. Let's leave as is here, since the exception does not bubble up as cnfe anyways.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
This method is called from within `newConverter`, `newHeaderConverter`, and `newConfigProvider`, so mentioning "converters" and getting the available converter implementation classes is actually wrong when used to find the config provider implementation class. One way to address that would be to pass in additional parameters to the method, but since we want to backport this to branches before `2.0` we have to make that work without method references. So one simple option is to rename the method to `converterClassFromConfig` and add a new method for `configProviderClassFromConfig` that does essentially the same thing but is tailored for config providers. Perhaps a better alternative is to dynamically determine the name and the `pluginNames(...)` based upon whether `klass` is a subtype of `Converter` or `ConfigProvider`. This keeps a single method, but is a bit more dynamic.
s/to list of/to the list of/
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
Ideally, we'd always use brackets on control flow operators.
Could we collapse the code path for having a queryable store name or not into the same function? For example: ``` filter(.. /*nothing*/) calls filter(.. (String) null); filter(.. "storeName") calls filter(.. storeSupplier); // if storeName is not null, otherwise pass null as well filter(.. supplier) do the actual impl, which checks if supplier is null or not ```
no need to use `this.` outside the constructor. Here and below
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
can we remove this one, so it won't be called by mistake? I think only the benchmark calls it, in which case, the benchmark can call the one with the concurrencyLevel parameter using the available processors
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
why don't you use `finally` instead of `catch`? I guess that is legacy or copy/paste
well maybe you don't like the success pattern though... but I think it should be closed even on Throwable
can we hide `shared.refcount` behind a method ie. decRef() / incRef() to be consistent with other stuff
This TODO should be removed
You should be able to collapse this to `IOUtils.close(this.current, uncomittedTranslogs)`
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
why don't you use `finally` instead of `catch`? I guess that is legacy or copy/paste
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
and -> a
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
Generics confuse me regularly, too... I was just comparing to `transform` -- seems our API is not consistent. I guess your argument makes sense.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
hehe :) nice one
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
Thanks for verifying @vvcephei!
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
hehe :) nice one
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
This TODO should be removed
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
Generics confuse me regularly, too... I was just comparing to `transform` -- seems our API is not consistent. I guess your argument makes sense.
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
IIRC, Java doesn't fully implement variance, but this is the basic concept (in scala) of what's going on with those `extends` return types: https://docs.scala-lang.org/tour/variances.html
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Thanks for verifying @vvcephei!
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
Generics confuse me regularly, too... I was just comparing to `transform` -- seems our API is not consistent. I guess your argument makes sense.
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
Why `? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>` and not just `Iterable<KeyValue<K1, V1>>` ? `transform` also has return type `KeyValue<K1, V1>` but not `? extends KeyValue<? extends K1, ? extends V1>`
Thanks for verifying @vvcephei!
IIRC, Java doesn't fully implement variance, but this is the basic concept (in scala) of what's going on with those `extends` return types: https://docs.scala-lang.org/tour/variances.html
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
IIRC, Java doesn't fully implement variance, but this is the basic concept (in scala) of what's going on with those `extends` return types: https://docs.scala-lang.org/tour/variances.html
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
Generics confuse me regularly, too... I was just comparing to `transform` -- seems our API is not consistent. I guess your argument makes sense.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
Thanks for verifying @vvcephei!
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
Generics confuse me regularly, too... I was just comparing to `transform` -- seems our API is not consistent. I guess your argument makes sense.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
hehe :) nice one
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Ok, I stand corrected. I did the experiment I was suggesting, and I got the desired results only with the API you have submitted: ```java <K1, V1> KStreamImpl<K1, V1> flatTransform(final TransformerSupplier<? super K, ? super V, ? extends Iterable<? extends KeyValue<? extends K1, ? extends V1>>> transformerSupplier, String... storeNames) { return null; } public static class KV<K, V> extends KeyValue<K, V> { public KV(final K key, final V value) { super(key, value); } } public static void main(String[] args) { final KStreamImpl<Integer, Long> stream = new KStreamImpl<>(null, null, null, false, null); // exact transformer final KStreamImpl<Integer, Long> stream2 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) {} @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(key, value)); } @Override public void close() {} }; } } ); // transformer that takes superclass k/v and returns exact results final KStreamImpl<Integer, Long> stream3 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes exact parameters and returns subclass results final KStreamImpl<Number, Number> stream4 = stream.flatTransform( new TransformerSupplier<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Integer, Long, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Integer key, final Long value) { return Arrays.asList(new KV<>(key, value), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); // transformer that takes superclass parameters and returns subclass results final KStreamImpl<Number, Number> stream5 = stream.flatTransform( new TransformerSupplier<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>> get() { return new Transformer<Number, Number, Iterable<KeyValue<Integer, Long>>>() { @Override public void init(final ProcessorContext context) { } @Override public Iterable<KeyValue<Integer, Long>> transform(final Number key, final Number value) { return Arrays.asList(new KV<>(key.intValue(), value.longValue()), new KeyValue<>(1, 3L)); } @Override public void close() { } }; } } ); } ``` If you take out any of the `? extends`, it won't compile.
Thanks for verifying @vvcephei!
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: blank missing :P
hehe :) nice one
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
This TODO should be removed
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onGet` as a name instead of primer
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
`KeyValueStore` -> `TimestampedKeyValueStore`
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
nit: remove empty link
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
ditto on `.` in character groups
ditto on `.` in character groups
This TODO should be removed
Not mandatory, but a good practice: a trailing comma here too ;-) ```suggestion ), ```
Why not do this in a single statement ? ```suggestion result = dict( changed=False, ansible_facts=dict( tcp_listen_violations=list(), udp_listen_violations=list(), tcp_listen=list(), udp_listen=list(), ), ) ```
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
why do we return `this` here this is not a builder and I don't think we need to do this though!
+1 to moving this to its own file
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Do we need the generic type here? The interface just defines `Object getKey()` but I guess it safes us some casting somewhere else. Just asking.
Can we actually include UUID type? It always 16 bytes.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
why do we return `this` here this is not a builder and I don't think we need to do this though!
+1 to moving this to its own file
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Do we need the generic type here? The interface just defines `Object getKey()` but I guess it safes us some casting somewhere else. Just asking.
Can we actually include UUID type? It always 16 bytes.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
This should be the last step
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
What is the value in separating the `set` and `done` methods? The one place where I can see that they are separated by some other code it looks like moving the `set` next to the `done` doesn't affect the tests at all.
if we keep ending up with this pattern, it might be clearer to create a `Listener` implementation that delegates to a list of listeners instead of chaining them manually this way
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
nit: remove `which is`
It should be public as it will be used in `producer` APIs.
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
I see that we need it from another package, I think it's ok.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
no need for the annotation if the test method name starts with "test" :)
It doesn't look like you are using any of the regular `getThenSet` features of the AtomicReference, can this just be a mutable variable? (Not really a big deal either way)
One extra line.
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
Will categorisation jobs use `AutoDetectResultProcessor`? If so it should be renamed.
I wonder if you want a CyclicBarrier here.
yeah, this is tricky. I instead I think we can run a test that cancels from the running task and makes sure it is never run again? we can then decide whether to cancel immediately or after a few iterations
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
Shouldn't this be a config exception? It is not really invalid partitions.
Cool. @lkokhreidze did you create a ticket already? (Just want to make sure we don't drop this on the floor.)
I wonder if you want a CyclicBarrier here.
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
Actually let me put in this way: `restoredPartitions` could just be local to this function? It's only usage outside is in `clear` so it seems we can keep it local or just use `restored` directly and remove it from `clear`.
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Could we make the following function signatures a bit more consistent: ``` allAssignedTaskIds, suspended, restoring, running, previousTasks, runningTaskIds, allInitializedTasks ``` E.g. `Collection<T> XXTasks()` and then extract taskId / etc from the callers if necessary.
Okay, could we have two signatures then? ``` Collection<T> XXTasks(); Collection<TaskId> XXTaskIds(); ```
This TODO should be removed
In the task constructor we already created a bunch of modules, like the metrics and the producer object. We need to make sure these modules still get cleared even when the task was not initialized.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
We should use try-with-resources here (for `DataInputStream`).
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
can we also add a line saying this variant allows for custom value deserialization based on the map using a KeyedReader? I got confused by why this is useful (until I saw how it is used).
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Actually let me put in this way: `restoredPartitions` could just be local to this function? It's only usage outside is in `clear` so it seems we can keep it local or just use `restored` directly and remove it from `clear`.
This TODO should be removed
I think its worth it? most of the time the response handle is SAME, so its not a big problem, but it allows to not overflow the same thread pool if it happens
I suppose that would make things super clear, but you're right, it would be a bug... so tossing a stacktrace vs. an illegalstateexception is almost the same thing ð. all good
since `getActionFromPolicy` can, theoretically, return `null`, would it be safer to switch these around to ``` newAction.equals(currentAction) == false ```
I think the `&` needs to be `&amp;`
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
Correct me if I am wrong but these filters have to be executed in a serial fashion one after another, right? So you can make this async if you need to on top of the blocking loop? I would like to see an example where this is used to understand the rational please :)
We typically use `Locale.ROOT` rather than `ENGLISH` for case conversion.
Oh, and _nit_ on the unnecessary brackets :)
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think its worth it? most of the time the response handle is SAME, so its not a big problem, but it allows to not overflow the same thread pool if it happens
I suppose that would make things super clear, but you're right, it would be a bug... so tossing a stacktrace vs. an illegalstateexception is almost the same thing ð. all good
since `getActionFromPolicy` can, theoretically, return `null`, would it be safer to switch these around to ``` newAction.equals(currentAction) == false ```
I think the `&` needs to be `&amp;`
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
Correct me if I am wrong but these filters have to be executed in a serial fashion one after another, right? So you can make this async if you need to on top of the blocking loop? I would like to see an example where this is used to understand the rational please :)
We typically use `Locale.ROOT` rather than `ENGLISH` for case conversion.
Oh, and _nit_ on the unnecessary brackets :)
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Missing a `@since`. I wonder if that wouldn't be something of interest for the library (ping @jkschneider)
there is only one impl
any chance we can remove the interface and just name this class NioChannel
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
Wouldn't "application.port" be a better default? There's already "application.pid", "application.properties", "application.yml" etc.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
same as above for parameters
req: Is it possible to use a defined constant (e.g. `ACTIVE_TASK_SENTINEL_LAG`) here and also use it in `TaskManager`? I think it would be good to have this constant defined here and then use it in `TaskManager`.
Oh, actually, here's the reason a constant sentinel is nice, but we didn't actually use it!
nit: line too long
as above `final` and one parameter per line
nit: add `final`
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
nit: add `final`
This should return `-1` as old `BadValueTransformer`
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
same as above for parameters
req: Is it possible to use a defined constant (e.g. `ACTIVE_TASK_SENTINEL_LAG`) here and also use it in `TaskManager`? I think it would be good to have this constant defined here and then use it in `TaskManager`.
Oh, actually, here's the reason a constant sentinel is nice, but we didn't actually use it!
nit: line too long
as above `final` and one parameter per line
nit: add `final`
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
nit: add `final`
This should return `-1` as old `BadValueTransformer`
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
I don't think this is the right approach. Even if the root cause is important, we still want to know that we experienced a disconnect. If I'm reading it right, the current patch does not show this. In general, we can't really make blanket statements like "the root cause is always the most useful thing" It depends on how the code is using the exceptions. Also, we shouldn't change what any of the exception output is without making a detailed examination of the before and after log output, and making sure that we like the "after" output better.
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
How about defining two helper methods, one for each cases? * `private void maybeRewrapAndThrow(ExecutionException exception)`; and * `private void maybeRewrapAndThrow(CompletionException exception)`
nit: Would it make sense to move `throw e` into `maybeRewrapAndThrow` to let `maybeRewrapAndThrow` throw in both cases? More generally, I wonder if we could handle all the case in `maybeRewrapAndThrow` and use it everywhere.
It will be worth mentioning that it includes the root cause since this is in `Utils`.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
The typo is still there.
Shouldn't this be `timeoutMs - (time.milliseconds() - startTimeMs)`? Also, it's not too big of a deal, but the checks for `Long.MAX_VALUE` seem like overkill.
Minor: maybe it's better override the override the acks to always be trimmed string inside `postProcessParsedConfig`, and then here we just check that the value is `all` or not; this way we can keep `parseAcks` as private static inside `ProducerConfig`.
Here we can further refactor a bit: ``` if (config.idempotenceEnabled()) { // read out the acks string value if (string value is null) // just log an info saying we are gonna override it to -1 else if (string value is not "all") // throw exception } ```
Maybe we can have a numRecords variable for the `100`.
Also, maybe we should assert that `numExceptionReceivedInCallback.get() > 0` if we expect at least one to fail (in theory, if `numSentRecords == 100`, there would be no exceptionReceivedInCallback).
Technically, this is `numDrainedRecords`.
nit: Maybe we can consolidate this logic into a function as well? E.g. "respondSentRequest" etc.
I think the old indentation was a bit better than this.
We can setup other scenarios to test the cancellation if we remove `updateLeaderGlobalCheckpoint`. For example, make the read limits reached, then cancel, then verify that we won't issue any read request.
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
you can use `IOUtils.close(processor)` it deals with `null` values...
why do we need this toString() here? We run it right away and don't log it anywhere.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
This is logic that I think should go into ReplicatedOperation.
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
nit extra newline
new lines missing. Also we should assert this is never called. Also no need for `throws EngineException`
newline, no need for `throws EngineException`
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
Is this punctuate function necessary? Since we do not `schedule` in the init functions I think this punctuation will never be triggered.
you can use `IOUtils.close(processor)` it deals with `null` values...
why do we need this toString() here? We run it right away and don't log it anywhere.
looks like we could extract: ``` setCurrentNode(child); child.process(key, value); ``` into a method and use in all three places
This is logic that I think should go into ReplicatedOperation.
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
nit extra newline
new lines missing. Also we should assert this is never called. Also no need for `throws EngineException`
newline, no need for `throws EngineException`
Not sure I have great ideas for improvement, but this feels like a brittle test case. I wonder if we are just trying to handle too many cases in this test.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I don't know that we care about closing the handler. It probably does not matter too much, but there should not be any resources hanging around if we properly consume all the requests.
s/payload is/payloads are
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
typo: byteArrray -> byteArray
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
`<byte[]>` this explicit type is unnecessary
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
The source KTable is materialized for this case. That's why `groupBy().aggregate()` is only executed after the flush on the last value per key. However, with `TopologyTestDriver` we cannot mimic this behavior any longer. Hence, it would make sense to delete this test, as it's the same as `testAggBasic`
as above (similar below)
nit: how about just using letters alphabetically from "A" than using multiples of `XYZ` only? Relying on numbers of letters may be bug-prone (see below).
@mjsax @vvcephei I ran the new commit locally and I think I get the difference here: In the ToplogyTestDriver#pipeInput: ``` // Process the record ... task.process(); task.maybePunctuateStreamTime(); task.commit(); captureOutputRecords(); ``` I.e. each record would cause a commit immediately, and in this case, when processing the two records from the repartition topics, each of them will trigger the `pipeInput` once and hence commit once, i.e. the processing of the original one `pipeInput` would cause two `pipeInput` from the repartition topic, and hence commit twice, and flush twice. While in the old `KStreamTestDriver`, we do not commit from the repartition-topic piped record, hence only result in one flush.
Ah. That makes sense. Thanks! Not sure if we want/need to change the behavior. Also, it would require a KIP imho, because people may have tests in place testing for the current behavior... Not sure if it's worth it.
I feel that generally speaking the `commit-on-every-pipeInput` of TopologyTestDriver is debatable, especially since we call `pipeInput` recursively from repartition topics, which means each of the new / old records via the repartition topic would be triggering once. Will merge this PR still as-is and we can discuss if we want to change this behavior later.
This seems different to the old expected result.
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
This won't work in case of live HLS WebVTT streams because you constantly get new subtitle segments at the same playlist URL. It's a shame X-TIMESTAMP-MAP support patch hasn't been merged to ffmpeg yet after 3 years, but in my use-case (vlive.tv) it's not required, so dumping HLS WebVTT via ffmpeg works quite good.
nit: preserve empty line after `checkAndClearProcessResult`
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I think we should call `deserializer.configure(...)` here
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
Can we actually include UUID type? It always 16 bytes.
nit: line too long. `final` not required -- a static method cannot be overwritten anyway
We should use try-with-resources here (for `DataInputStream`).
`function` -> `method` ? `{@code null}`
I think we can drop the benchmark.
AclAuthorizer is not a public class, so it may be ok to make this class public in AclAuthorizer instead of duplicating it here.
Same as before, `new Integer[]{}' not required for `Arrays.asList`.
I was going to ask why we're using the `test` prefix for a benchmark, but then I realized that many of the kafka benchmarks do that and I somehow didn't notice. :) Given that, it seems fine to leave it like this for now.
This can be initialized here and be `final`
This line is failing checkstyle. I think we need a space after the first semicolon.
Just wondering if this test is good. Seems like a "RoundRobinAssigner" might compute the exact same assignment. Some more "randomness" would be good IMHO. (Not a must though.)
initialize the `KStream` here and make it `final`
the ```length``` is neglected
You should also compare `expectedValues`.
the naming used above seems better here ```suggestion Throwable exception = null; ```
This is logic that I think should go into ReplicatedOperation.
don't try to fix it, you just moved code around, but this catch block worries me :(
Out of curiosity, why create a class for this instead of an anonymous class in `IndexService` capturing the local `shardId`? There are no other instantiations of this class other than the single one
nit: I would rather use the full name instead of using acronyms.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
unkown -> uknown
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
unkown -> uknown
the naming used above seems better here ```suggestion Throwable exception = null; ```
This is logic that I think should go into ReplicatedOperation.
don't try to fix it, you just moved code around, but this catch block worries me :(
Out of curiosity, why create a class for this instead of an anonymous class in `IndexService` capturing the local `shardId`? There are no other instantiations of this class other than the single one
nit: I would rather use the full name instead of using acronyms.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
unkown -> uknown
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
unkown -> uknown
the naming used above seems better here ```suggestion Throwable exception = null; ```
This is logic that I think should go into ReplicatedOperation.
don't try to fix it, you just moved code around, but this catch block worries me :(
Out of curiosity, why create a class for this instead of an anonymous class in `IndexService` capturing the local `shardId`? There are no other instantiations of this class other than the single one
nit: I would rather use the full name instead of using acronyms.
I don't think this `Callable` should return `ManagedTask`. `ManagedTask` is an internal data structure that should only be accessed from the state change thread.
unkown -> uknown
Could we skip some of the checks below by setting the initial value? ``` boolean needsReadToEnd = configState.offset() < assignment.offset(); ```
Could we get rid of the backoffOnFailure variable and just use: ``` java if (isLeader() && needsRejoin) ``` It might make the code a little easier to follow if that's really the only case where we want to backoff.
unkown -> uknown
does it make sense to put the "fail a shard" logic under a method? to make sure we don't forget to put it in failedShards etc.
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
This is logic that I think should go into ReplicatedOperation.
I think "allocated" should be "allocate" here.
It feels squicky to ignore the exception. Personally I'd `assert false : "Exceptions not expected here."` and `logger.error` about it.
Typo: "Dynamics" -> "Dynamic"
can we give that a better name that describes what the function does? something like `checkCommittedAndSendCommitIfSo()`.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
same as above, function name says nothing about what it does.
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
Maybe we can close the first group here and verify that the sensors/metrics are no longer registered? A similar check for the sink would be good.
nit: new line
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
It will good to clear the requests and test when empty as well.
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
It will be better to use `MockTime` rather than `SystemTime`. That will make it easier to test timeouts
nit: not a big deal here, but for unit tests I think given the very low overhead it is better to separate out each of the cases into their own test as it can help make it more quickly obvious if issues are with a specific case or if it affects multiple cases.
@guozhangwang Yep, sounds good to me.
Maybe just one more case missing. If we call subscribe with a new pattern, the assignment also shouldn't change.
This is an interesting discussion. I don't have the full context of these discussions, but I can see the argument for keeping things simple and letting users rely on the regular expression for achieving their goals. I am not sure if it's any simpler to provide two separate regular expressions than just one with the appropriate negation. The latter is easier to write a unit test for too.
Yeah, that's a good point. Scratch that idea.
@SinghAsDev @guozhangwang I wonder if we could support blacklist filtering through a second argument to subscribe. For example: ``` java void subscribe(Pattern whitelist, Pattern blacklist); ``` This might get around some of the complexity mentioned above.
I originally thought the semantics of unsubscribe() is blacklisting. For example: subscribe("PageView*") unsubscribe("PageViewTopicA") will subscribe to all page-view topics except page-view-A. Arguably this can be done solely in subscribe() with"^" in regex, but I feel this semantics is more natural for users.
Would it have to? I would see each call to subscribe as replacing the previous one. Perhaps if we wanted to support multiple regex subscriptions, we could do: ``` java void subscribe(List<Pattern> patterns); ``` And we could require users to use '^' for blacklisting. This would be consistent with the changes proposed in KAFKA-2388.
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
nit: new line
This should return `-1` as old `BadValueTransformer`
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
The implication here is that wakeup won't work if you've fetched data and keep calling poll() when you have max records set small, right? This seems like it could be a problem for anything that takes a long time to process messages since the wakeup may be an indicator that the application needs to shutdown...
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
nit: break line
I'm +1 on supporting the timestamps, even if it's not commonly used now, users will often look to tests for example usage (at least I do). I'm also +1 on removing `childIndex` for the same reason, but I don't have too strong an opinion on that.
For this specific API, I suspect it is ever commonly used in PAPI, so I'm fine with not supporting it right away, also as a way to encourage users to change code sooner than later, if there's anyone.
Child-Index was deprecated recently -- should we remove it? Also, with KIP-251, we should capture output timestamps, too.
I dont remember why I did that. Looks like `future.get` would be better.
I mean it's odd to submit an empty job to the executor in order to verify progress. Why not call `get` on the close future itself.
This type is not parameterized. It's generally better to list the parameters when you reference a parameterized type.
Ditto here, we should retain some version of this test and any others that are specifically intending to test the behavior of the old API (until the deprecation period has elapsed and we can remove it)
You can remove this `assertThat` and the loop below as you've already proven this is true in the test above. So no need to assert it again.
```suggestion assertEquals(0L, JoinWindows.of(ofMillis(DEPRECATED_OLD_24_HR_GRACE_PERIOD)).gracePeriodMs()); assertEquals(0L, JoinWindows.of(ofMillis(DEPRECATED_OLD_24_HR_GRACE_PERIOD + 1L)).gracePeriodMs()); ```
Same here: we should leave this test here until we remove the deprecated API. (and just suppress the warnings for only this test method)
Just a question: Why is this not `6L` ? (it should be `5L` after you applied the fix you want to do in a follow up PR).
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
nit: there is not "partition stream time" -- there is "stream time" and "partition time" :)
nit: method can be `private`
Please verify that no `sensor#record` is executed after `recorder.record(0L);`
This type is not parameterized. It's generally better to list the parameters when you reference a parameterized type.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
nit: usually we drop the `get` prefix on getters.
If we follow the same pattern as `ConsumerGroupOperationContext`, then this could be a static method which takes the response as a parameter.
Given usage, this could probably be a Set.
nit: can simplify a little bit ```java return allErrors.stream().anyMatch(this::shouldRefreshMetadata); ```
Maybe doesn't matter, but seems a little more intuitive to check that the error is not NONE.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
nit: usually we drop the `get` prefix on getters.
If we follow the same pattern as `ConsumerGroupOperationContext`, then this could be a static method which takes the response as a parameter.
Given usage, this could probably be a Set.
nit: can simplify a little bit ```java return allErrors.stream().anyMatch(this::shouldRefreshMetadata); ```
Maybe doesn't matter, but seems a little more intuitive to check that the error is not NONE.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
as above (similar below)
Got it. Thanks
@mjsax @vvcephei I ran the new commit locally and I think I get the difference here: In the ToplogyTestDriver#pipeInput: ``` // Process the record ... task.process(); task.maybePunctuateStreamTime(); task.commit(); captureOutputRecords(); ``` I.e. each record would cause a commit immediately, and in this case, when processing the two records from the repartition topics, each of them will trigger the `pipeInput` once and hence commit once, i.e. the processing of the original one `pipeInput` would cause two `pipeInput` from the repartition topic, and hence commit twice, and flush twice. While in the old `KStreamTestDriver`, we do not commit from the repartition-topic piped record, hence only result in one flush.
Ah. That makes sense. Thanks! Not sure if we want/need to change the behavior. Also, it would require a KIP imho, because people may have tests in place testing for the current behavior... Not sure if it's worth it.
I feel that generally speaking the `commit-on-every-pipeInput` of TopologyTestDriver is debatable, especially since we call `pipeInput` recursively from repartition topics, which means each of the new / old records via the repartition topic would be triggering once. Will merge this PR still as-is and we can discuss if we want to change this behavior later.
This seems different to the old expected result.
nit: how about just using letters alphabetically from "A" than using multiples of `XYZ` only? Relying on numbers of letters may be bug-prone (see below).
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
nit: preserve empty line after `checkAndClearProcessResult`
nit: As key and value is accessed, we might want to iterate throw the `.entrySet` instead of `keySet`
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
It will good to clear the requests and test when empty as well.
redundant type arguments `<ProducerRecord<byte[], byte[]`
nit: we could split this lone line by different key, value by new line to make it clear. ex: ``` String[] args = new String[] { "--topic", "Hello-Kafka", "--num-records", "5", .... }; ``` Same as below.
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
typo: byteArrray -> byteArray
`< Callback >` this explicit type is not necessary.
`<byte[]>` this explicit type is unnecessary
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
s/Consumer/The verifying consumer
while the verifying consumer itself is not part of the transaction
Is this line intentional? Unit tests normally don't need to print out to console.
debug line should be removed.
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
Can you use Junit's assert so that it also works if assertions are disabled? (I think we randomize this)
I wonder if it should not also decrement the CountDownLatch if an exception is caught in the SimpleChannelUpstreamHandler ? Something like ``` new SimpleChannelUpstreamHandler() { @Override public void messageReceived(..) { ... latch.countDown(); } @Override public void exceptionCaught(...) { latch.countDown(); } ``` Just to be sure that the client does not hang indefintily.
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
maybe rename those methods to assert\* as this is what they do... same with the next one
rewrite test as above using `assertThrows()`.
same as above for parameters
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
nit: `final` params
You should also compare `expectedValues`.
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
nit: add `final`
nit: add `final`
nit: add `final`
nit: add `final`
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
This is logic that I think should go into ReplicatedOperation.
We prefer to use `assertThat()`: ```suggestion assertThat(throwable.getMessage(), is(...); ```
`PrintForEachAction<>` to remove warning. Also in the `print` method
Maybe this was already covered somewhere, but is `GENERIC` the right threadpool for this? (I don't have a better suggestion, just asking)
same for tests below as well
sure, or just make it `[foobarbaz/0/mynode]` or something, `[foobarbaz//]` if there is only one or something
nit: can remove type arguments
nit: add `final`
nit: add `final`
This type is not parameterized. It's generally better to list the parameters when you reference a parameterized type.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Why do you remove this check? A `TimeWindow` should not allow this case.
The map is not used.
I think it might be nice to move this in `TcpHeader`
records to it, and reading all records from it, such that
nit: might be better to set end to another timestamp.
the method name changed to `windowedTable` and `windowSize` parameter is missing
`windowSize` should be `Duration`
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
method name changes
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
recommended; ditto below.
Both `GZipInputStream` and `SnappyInputStream` read the header in the constructor, so it would make sense to me to remain consistent in that respect.
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
What's the purpose of this warning? It doesn't seem needed.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
Seems like this is the same in `testReadFullyOrFailWithMultiReads`. Maybe we can extract it to a helper method.
Seems like `assertFalse` would be more appropriate here. There are a few cases like that. Also, it would be good to verify the buffer contents.
Is this name correct? It seems like the buffer is never filled in this test.
just name it `read`
This is really inefficient if `buffer` is a `DirectByteBuffer` and it's not small. The bulk `put` method performs better by doing a JNI array copy if it's larger than 6 elements. It's also less code.
maybe rename those methods to assert\* as this is what they do... same with the next one
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
What's the purpose of this warning? It doesn't seem needed.
A bit unclear why we need this. In my mind, `readFully` should be as close to `FileChannel.read` as possible with the exception that it attempts to fill the buffer while end of file is not reached.
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
Seems like this is the same in `testReadFullyOrFailWithMultiReads`. Maybe we can extract it to a helper method.
Seems like `assertFalse` would be more appropriate here. There are a few cases like that. Also, it would be good to verify the buffer contents.
Is this name correct? It seems like the buffer is never filled in this test.
just name it `read`
This is really inefficient if `buffer` is a `DirectByteBuffer` and it's not small. The bulk `put` method performs better by doing a JNI array copy if it's larger than 6 elements. It's also less code.
maybe rename those methods to assert\* as this is what they do... same with the next one
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
nit: add final to parameters
nit: make the `mapper` final
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
nit: use `"table-source"` ? It's naming a source node, not a processor node.
same as above for parameters
Yes, that's more or less what I was concerned about. We are trying to achieve a specific result here (and brand-new 'Header' instance each time), but it's only achieved via a side effect. On the other hand, I just took a closer look at the code, and I see that there's a better reason to keep using `ConsumerRecord`, namely that `updateProcessorContext` is used both for regular processing (with "real" records) and for punctuation here with this dummy record. It seems like a good idea to prevent those code paths from diverging, so I'm +1 with keeping this change as-is.
From my understanding, neither the `ConsumerRecord` nor the `ProcessroRecordContext` are the issue, but the shared `Header` object -- it's just a "side effect" that creating a new `ConsumerRecord` creates an new `Header` object internally.
This is fine, but note that the new consumer record here is just a roundabout way to create a ProcessorRecordContext. It'd probably be better to just directly instantiate the context we want.
nit: add `final`
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
recommended; ditto below.
Both `GZipInputStream` and `SnappyInputStream` read the header in the constructor, so it would make sense to me to remain consistent in that respect.
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
My bad, the parameter is just an `int` and not a buffer. Thanks to @hachikuji for correcting me.
This is a security risk because the right bit pattern can cause an infinite loop. We need to stop after a certain size. Same for `sizeOfVarlong`.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Maybe it could just be `StoreType`. We don't to qualify everything.
It's within a `session` package so I wouldn't mind too much.
Is the order of the options important? I think it should be alphabetically or by priority - wait is not the 1st one in either cases, I reckon.
`{@code Joined}` `[o]ptional para[meter]s`
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
two license headers? :)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
`NEO4J` is not needed. `neo4j` entry will be inferred from `Neo4jHealthIndicator`, can be replaced by `nodes`? Additionally, all entries in the result shouldn't be added to the detail.
Maybe we could use a different value here.
we should do this `assertTrue` thing for the CooperativeStickyAssignor as well
I'd suggest moving this static method after the non-static methods.
> Why do you think that? Does having a hard reference to an object guarantees all weak references to it are kept around? I was worried the GC might decide to remove a weak reference just because, in which case we will create another marker. Again - not saying this is wrong, but looking to learn.
I think it will be cleaner? not a biggy though
The test name is not self describing: what about `shouldAlllowToSpecifyRocksDBConfigSetterClassAsString`
nit: add `final` (same below)
This particular test doesn't make sense any more, since there is no "old" assignor type now that PartitionAssignor is removed
removed? It does not seem to be used.
I don't think this method is needed. The existing `toInstance(Function<T, R> factory)` method should do what we need when given a method reference to one of `Mustache.Compiler`'s configuration methods that return a new `Compiler` instance.
By the way, I wonder if we should just say it should be idempotent? Seems redundant to mention KafkaProducer.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
shall we make the error message agnostic "on field []" and reuse the existing parse method? It will need to be moved to a common place I guess.
ok, I was more worried about the handling to make sure that we don't support stored scripts, but indeed, the rest is just calling Script.parse so it is not a lot of code.
I don't think we can do this. Also, I would only mention it, when we start to deprecate an API.
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
nit: remove empty line
nit: missing `<p>` for new paragraph
an -> a
since `Period` doesn't support time I think we can change `10s` to `10m`
Actually we could go crazy and add couchbase to the list.
I think we need a bit more than that. Hibernate may throw that exception when it cannot access the database. Pointing the user to the potentially wrong fix would causing more harm IMO. There's no way to prove that our auto-configuration lead to this so pointing to the property may be misleading as well. We usually try to throw dedicated exception whenever we can.
Yes, we could add `ignoredExtensions` and include that in the log in the server.
@rajinisivaram @stanislavkozlovski LGTM with the possible exception of maybe adding support for retrieving/logging any ignored extensions? I'll defer to your preference on this.
We shouldn't use `<br>`; instead, use a `<pre>` section around the lines.
Can initialize to `new HashMap<>()` here as is done with `invalidExtensions` below.
Can remove if initialize above
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Ah, scratch that. I just realized it was the spring data support.
There is `.data` package. You should probably move that stuff over there.
It's within a `session` package so I wouldn't mind too much.
Maybe it could just be `StoreType`. We don't to qualify everything.
Is the order of the options important? I think it should be alphabetically or by priority - wait is not the 1st one in either cases, I reckon.
remove the super call
remove the super call
two license headers? :)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Do we still need `needsJoinPrepare` now? It seems to me that we need to call `onJoinPrepare` whenever `needRejoin` is true.
might want to rename `workerId` so it doesn't shadow the member field. something like `workerIdOpt` could work
ah, right. nah, that's fine. just when reviewing I had the thought that if we guaranteed non-`null`/non-empty in the constructor, this wouldn't be necessary. i realized that it was actually intentional, but easy to miss when reviewing here and not getting the same highlighting as an IDE
I know the naming thing has bit us in the past, is this same approach used elsewhere and/or how was it decided on? Specifically, metric name constraints really shouldn't be JMX specific if that is the case here, despite the fact that the metrics is so obviously JMX-inspired. I can easily find https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/metrics/KafkaMetricsGroup.scala#L46 but nothing else. Have we not had the same problems because metrics w/ topic names in them already have constraints on the naming? If I am remembering correctly, I think maybe both @gwenshap and @junrao were involved in some discussions, I think `-` vs `_` was a problem at some point? Maybe one of them could chime in here.
We did the dot to _ conversion for Yammer metric mostly because reporters like Graphite typically use dot to represent hierarchy and quite a few people are using the existing Graphite reporter that may be confused with dot. Since Kafka metric is new, we could just let individual reporter deal with this issue, instead of changing the metric name directly.
to me it seems like we can't possibly know what the constraints of all reporters would be and they don't provide an interface for validation, so it should be up to them to figure out how to substitute. but i've also asked some other folks to maybe chime in here who may have better context on how we've handled this elsewhere.
I don't think limiting the pool to 2 threads is really what you want, since you have 3 runnables that you are creating later on. Check out some of the other newXYZThreadPool functions. There is at least one that doesn't limit the number of threads.
This probably shouldn't be called "prepare", right? It is the main Callable here and we expect to stay in it for a while.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
This statement is a bit misleading, how about "to the format indicated by the given magic value".
nit: Indicate that this needs deep iterations on the entries.
nit: Indicate that this needs shallow iterations on the entries.
We need to think about how we can avoid this. The package structure appears to be working against us.
"of [a] windowed..."
"of [an] ever-updating ..."
"of [a] windowed..."
"of [an] ever-updating ..."
Just keep in mind that it's important to be careful not to simplify to the point of being incorrect (e.g. a successful response is not the same as a response containing metadata for a given topic).
I'd probably say "in case the number of partitions has been increased" instead of "in case a partition expansion has taken place".
This statement is a bit misleading, how about "to the format indicated by the given magic value".
nit: Indicate that this needs deep iterations on the entries.
nit: Indicate that this needs shallow iterations on the entries.
We need to think about how we can avoid this. The package structure appears to be working against us.
"of [a] windowed..."
"of [an] ever-updating ..."
"of [a] windowed..."
"of [an] ever-updating ..."
Maybe we can say "Kafka admin client has been closed" for consistency with the consumer. When grepping, it's easier to if things are consistent across clients.
nit: seems unnecessary? similar for `State.FAILED` below.
I don't think this will ever be true, i.e., in `start` we set the state to `RUNNING` and then we call `globalStreamThread.start()`. So the listener will be invoked with `RUNNING` while the instance is already in the `RUNNING` state. The `StreamThread`s aren't started until after `globalStreamThread.start()` returns.
Nit: I think the state transition should be done before the INFO log.
Yeah this is observed in another PR review, and should be fixed by now. cc @dguy
I think the intended method to call would be ``` Thread.currentThread().interrupt() ``` Same with line 258 below.
`delay_min_macos = delay_min | 1`
I'm not sure returning `true` is valid. We don't actually know if all the threads have shutdown. Though, i'm not entirely sure what to do about it. Perhaps we need to extract the shutdown Thread as a field and then we can check if it is still running. If it isn't running then we can return true, otherwise we should try and join on the thread with the provided timeout
This was originally to try and prevent a dead-lock, i.e, the `UncaughtExceptionHandler` is triggered by Thread-1. The user calls close (still on `Thread-1`). Thread-1 join will never return as we are executing on `Thread-1`, but we already know it isn't running. I think we still need this check
I like it!
Maybe we can say "Kafka admin client has been closed" for consistency with the consumer. When grepping, it's easier to if things are consistent across clients.
nit: seems unnecessary? similar for `State.FAILED` below.
I don't think this will ever be true, i.e., in `start` we set the state to `RUNNING` and then we call `globalStreamThread.start()`. So the listener will be invoked with `RUNNING` while the instance is already in the `RUNNING` state. The `StreamThread`s aren't started until after `globalStreamThread.start()` returns.
Nit: I think the state transition should be done before the INFO log.
Yeah this is observed in another PR review, and should be fixed by now. cc @dguy
I think the intended method to call would be ``` Thread.currentThread().interrupt() ``` Same with line 258 below.
`delay_min_macos = delay_min | 1`
I'm not sure returning `true` is valid. We don't actually know if all the threads have shutdown. Though, i'm not entirely sure what to do about it. Perhaps we need to extract the shutdown Thread as a field and then we can check if it is still running. If it isn't running then we can return true, otherwise we should try and join on the thread with the provided timeout
This was originally to try and prevent a dead-lock, i.e, the `UncaughtExceptionHandler` is triggered by Thread-1. The user calls close (still on `Thread-1`). Thread-1 join will never return as we are executing on `Thread-1`, but we already know it isn't running. I think we still need this check
I like it!
remove empty line
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
nit: add `final` (2x)
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
nit: remove empty line
this will never be called if one of the assertions fails
nit: java style
remove empty line
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
nit: add `final` (2x)
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
nit: remove empty line
this will never be called if one of the assertions fails
nit: java style
remove empty line
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
nit: add `final` (2x)
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
nit: remove empty line
this will never be called if one of the assertions fails
nit: java style
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Do we need the generic type here? The interface just defines `Object getKey()` but I guess it safes us some casting somewhere else. Just asking.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
Can we actually include UUID type? It always 16 bytes.
Wouldn't "application.port" be a better default? There's already "application.pid", "application.properties", "application.yml" etc.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
I think we should call `deserializer.configure(...)` here
I am wondering, if we should get the `List` type as generic (not sure). `public class ListDeseializer<L extends List<T>, T> implements Deserializer<L>`
It's better to avoid "double-brace initialization", which is actually declaring a new anonymous subclass of HashMap just to add some stuff to it in one statement. A little while back, I added this method for accomplishing the same thing more safely: `org.apache.kafka.common.utils.Utils#mkMap`, and the accompanying `org.apache.kafka.common.utils.Utils#mkEntry`.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Do we need the generic type here? The interface just defines `Object getKey()` but I guess it safes us some casting somewhere else. Just asking.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
Can we actually include UUID type? It always 16 bytes.
Wouldn't "application.port" be a better default? There's already "application.pid", "application.properties", "application.yml" etc.
We don't really care about the stack trace here or below, just the message. We know the `StreamsException` is generated from this class and the message is enough to identify the problem. Further, these are done in a retry loop so can become quite verbose if failed multiple times
Below is what I get when I try it out. As you can see that log message is drowned in many other log messages that don't mention the index name. A lot of this is guice and we're working on fixing it, but I think the easiest is to make sure that the index name is mentioned in the exception for now? people won't see it otherwise. ``` [2016-11-03T00:08:29,112][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... a terminal screen worth of stack trace here ... Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] .... [2016-11-03T00:08:29,144][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,146][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal screen worth of output [2016-11-03T00:08:29,161][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,161][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.archiveBrokenIndexSettings(MetaDataIndexUpgradeService.java:171) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:81) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] [2016-11-03T00:08:29,229][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main] org.elasticsearch.bootstrap.StartupException: org.elasticsearch.common.inject.CreationException: Guice creation errors: 1) Error injecting constructor, java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] <--- THESE IS REPEATED 4 times at org.elasticsearch.gateway.GatewayMetaState.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayMetaState for parameter 4 at org.elasticsearch.gateway.GatewayService.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayService ... another terminal, this time full of guice information Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) at org.elasticsearch.common.settings.Setting$$Lambda$183/2092885124.apply(Unknown Source) at org.elasticsearch.common.settings.Setting.get(Setting.java:312) at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:525) ... 47 more And this ^^^ is the last message on the screen. ```
Also minor, but I think I'd prefer `node == null ? null : node.toString()` because it requires less negative-resolving in my brain, up to you though.
nit: can remove type arguments
I don't think we should special-case this. Depending on underlying blobcontainer, a different exception might be thrown.
simpler as it decouples these two things. And no need for having this method return a boolean.
why change the semantics here to only call close when setting the tragedy the first time? Let's keep the existing semantics and make `setTragicException` return void
remove extra newline
put the message as the first arg on assertTrue so we know what it was when it fails.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Why use a static block to initialise this? `Sets.newHashSet` can turn this into a 1 liner, and then you can wrap it in `unmodifiableSet`
Just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. Would you mind to not move configs that get deprecate and add the new config at the "right" place. Thanks a lot. :)
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
The `<=` will need to be escaped.
Do we need this Constructor? It looks like it's only called from `parse()` which has the version so it could call the other constructor
Nit: " . " -> ". "
This is not completely compatible with the behavior of older Streams apps. See #10953 for a fix and more details.
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
`doWork` is just one iteration. `ShutdownableThread` has the loop. I'm ok with the change, but we probably will need to copy over some of the shutdown logic.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
I am ok with what you propose Nik!
This test should assert that the headers are correct.
We should pass in `record.topic()` instead of `""` into `deserialize`.
should we put `kafka` and `numThread` directly into `props` and reduce number of parameters here (would also simplify all the "passing through" code.
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
`start` is not used.
Is this line intentional? Unit tests normally don't need to print out to console.
The JIT can easily inline this method, so it doesn't actually do anything. The BlackHole implementation in JMH is a lot more complex: http://hg.openjdk.java.net/code-tools/jmh/file/cde312963a3d/jmh-core/src/main/java/org/openjdk/jmh/logic/BlackHole.java#l117
As above for this and next ctor
As above for this and the next ctor
```suggestion "part of a group or is participating in a rebalance right now. You should first call poll to complete " + ```
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
It should be 'false' by default
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
It should be public as it will be used in `producer` APIs.
nit: It seems clearer to use `ConsumerPartitionAssignor.class` directly below.
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
nit: single parameter per line
how about `onGet` as a name instead of primer
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
We do expect RemoteStorageManager to have strong consistency on the data. We only relax the requirements on metadata consistency. So, it would be useful to make this clear.
I think we should call `deserializer.configure(...)` here
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
the naming used above seems better here ```suggestion Throwable exception = null; ```
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
the naming used above seems better here ```suggestion Throwable exception = null; ```
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit extra newline
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
ok - same thing three times. Maybe extract it to a method `verifyTransactionInflight`
the naming used above seems better here ```suggestion Throwable exception = null; ```
no need to use `this.` outside the constructor. Here and below
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
hehe :) nice one
as above (similar below)
nit: line too long
nit: move `}` to next line
I suspect the test failures in this class are due to the fact the value here is a String `"(1<-null)"` for the expected value but what is returned from processing is a `Change` object so the test fails. For example the expected values are created like ```java new KeyValueTimestamp<>("B", "(1<-null)", 10) ``` but should be ```java new KeyValueTimestamp<>("B", new Change(1, null), 10) ``` I suspect the issue is the same in some other failures as well when removing `toString` from the `equals` method.
nit: move closing `}` to next line
nit: how about just using letters alphabetically from "A" than using multiples of `XYZ` only? Relying on numbers of letters may be bug-prone (see below).
Got it. Thanks
nit: preserve empty line after `checkAndClearProcessResult`
@mjsax @vvcephei I ran the new commit locally and I think I get the difference here: In the ToplogyTestDriver#pipeInput: ``` // Process the record ... task.process(); task.maybePunctuateStreamTime(); task.commit(); captureOutputRecords(); ``` I.e. each record would cause a commit immediately, and in this case, when processing the two records from the repartition topics, each of them will trigger the `pipeInput` once and hence commit once, i.e. the processing of the original one `pipeInput` would cause two `pipeInput` from the repartition topic, and hence commit twice, and flush twice. While in the old `KStreamTestDriver`, we do not commit from the repartition-topic piped record, hence only result in one flush.
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
It *looks* to me like this will hit a `NullPointerException`.
When you use it with an instance of `PreBuiltAnalyzers`.
It'd be super nice to explain that we only need this because of `PreBuiltAnalyzers`.
I think it'd be nice to remove this second ctor so we're explicit every time.
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
nit: We could omit `res` and return directly in the two places below.
the naming used above seems better here ```suggestion Throwable exception = null; ```
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
This TODO should be removed
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: in spite of the getter convention, I still prefer setters be prefixed with `set`
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
nit: We could omit `res` and return directly in the two places below.
the naming used above seems better here ```suggestion Throwable exception = null; ```
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
This TODO should be removed
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
nit: in spite of the getter convention, I still prefer setters be prefixed with `set`
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
at that point you want have a read budget, which I mentioned above.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
I think we should call `deserializer.close()` here
We should use try-with-resources here (for `DataInputStream`).
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
nit: merge both lines: `byte[] payload = new byte[primitiveSize == null ? dis.readInt() : primitiveSize];`
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
We should use try-with-resources here (for `DataInputStream`).
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
I think the old indentation was a bit better than this.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
> The JVM chooses the heap size ergonomically when the heap size is not specified. Do we have the ability to see what it would choose? If running on a small machine, for instance, we'd still want to disable Netty's pooled allocator if the JVM is going to automatically choose a 400mb heap
exception messages should start with lowercase (for consistency)
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
> 6 shard copies? That's rather useless in a system like ES We do have people using more then 3 shards so that lead to the idea of having the default scale with it. Thinking about it more I think the main usage for having so many copies is auto-expand-replicas-like usages, where you want to have shard copies available on all active nodes. In those case I think you mostly care about the data being on everything thatâs up and not be bound by durability guarantees. In that case I would be fine with waitForActiveShards default to 1 and allow people to set things differently on the index level if the want different default (when we do that change). > This setting is of limited use anyhow as it does not provide the guarantee that most users are after Correct - this setting is meant to be used to limit the scope of events that will be indexed into less than a given number of shards. It should be coupled with a check of the response of each write operation.
> just let the default be 1 instead My rational with going with half as default is that I think that adding replicas should change the behavior - if someone runs with 6 copies , it's probably not a good default to let of them (but one) go away before signalling alarm. I chose the word "half" in order to avoid a loaded word like "quorum" which implies stuff that aren't part of our model (i.e., quorum reads). I don't mind if we round up (i.e., `(size() + 1) / 2`) or down (i.e. `size()/2` ) as long as it's not `size()/2 + 1` .
I wonder if we should just let the default be 1 instead of confusing the user with some sort of QUORUM semantics that does not exist in our replication model.
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
Great. I now wonder if this whole block can move into the `JoinHelper`. If the code above returned its `mode` and called `becomeLeader()` then the `JoinHelper` should be able to work out the right things to do with the join.
The advantage of doing this via serialization instead of copy constructor would be that this is a deep copy then, this way we only copy the references.
We can restore those assertions about the state of the join helper here - i.e. no accumulated joins when leader or follower.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
the naming used above seems better here ```suggestion Throwable exception = null; ```
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Hmm.. In fact, there is not necessarily any relation between the partitions that are being consumed and those that are being written. Usually you would expect them not to overlap. I wonder if it actually makes more sense to track these offsets in a separate map.
This TODO should be removed
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
add the exception? :)
Should we check `newPair != null` before checking the key and value for nulls? A user might want to have their `mapper` return `null` in the case they want the value to be skipped.
This TODO should be removed
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
That class is different because it doesn't actually `define` the config, it's just an undeclared "extra" config that gets passed around to be interpreted inside the serde. Actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.
This may indicate a bug in `SessionWindowedDeserializer`
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
docCount is a a long so it's totally fine, sorry.
We should use try-with-resources here (for `DataInputStream`).
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think we should call `deserializer.close()` here
Update return type to `L` (if we introduce `L`)
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
same - please name it something like `explainOrThrowRejectedCommand`
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
hehe :) nice one
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
This may indicate a bug in `SessionWindowedDeserializer`
That class is different because it doesn't actually `define` the config, it's just an undeclared "extra" config that gets passed around to be interpreted inside the serde. Actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.
nit: remove `this` (not required)
docCount is a a long so it's totally fine, sorry.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
can we fix this into a boolean before we start? will be easier to reproduce / know what happened.
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
oh..ok... so make `Operation` implement `Callback`, it'll still clean things up
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
I'd like to use a sentinel here rather than null like `BenchmarkMetaData.Entry.INVALID_ENTRY` or so.. I try to prevent `null` invariants they tend to throw NPEs :)
`WindowStore` is public API -- we need a KIP if we want to deprecate something. Thus, this is not a `MINOR` PR.
I think I recall cases that work perfectly without the leading "/". e.g. https://github.com/elastic/elasticsearch/issues/19314
if we make such change, can we do it in a separate PR please? ;)
Do you know why we have all these ReadOnlyWindowStore methods also declared here in WindowStore? We don't need reverse variations of these I guess? ð¤
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
No, I still think that it should not be a method on the `Strings` class.
> Though I do prefer that it fails fast instead of lazily later. ++
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
Also set the store name in this test.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
```suggestion * This is a synchronous commit and will block until either the commit succeeds, an unrecoverable error is ```
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onGet` as a name instead of primer
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
how about `onGet` as a name instead of primer
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
```suggestion * This is a synchronous commit and will block until either the commit succeeds, an unrecoverable error is ```
Is this going to be used for non-testing code in the future? If it is only going to be for metrics purposes maybe we can allow it to be non thread-safe just to not blocking on other critical paths.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
and -> a
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
Doh! the recommendation is forbidden API ..never mind.
Nits: `set` -> `batch` and `task` -> `tasks`
same here - can we add a note about the batching? i.e., not batched
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
good point.... we should be able to get rid of it.
I wonder if the input parameter should just be typed as an `IdentityHashMap` then? Note that currently this will silently ignore duplicates in the input `tasks`.
Yes, I confused myself.
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
And so does my proposal, by typing `existing` more strongly than the compiler can do (because of erasure) but is clearly correct and eliminates the suspicious call inspection.
Nit: you can call `Thread.enumerate` directly. Also, it would be good to assert that `threadCount` is < than `threads.length`.
I just thought about this. I think `endOffset` should be actual endOffset, ie, `11` for this test -- we pass in the `offsetLimit` as 5 in `StateRestorer` below.
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
Seems to be the exact same test as above (both don't use grace). Seem the difference is if window size enlarged retention time setting or not, but it's not reflected in the names of the tests.
We could actually show the client state by: `"Some clients didn't reach state RUNNING without any stand-by tasks. Eventual status: [Client1: {}, Client2: {}]", client1IsOk, client2IsOk`
The implication here is that wakeup won't work if you've fetched data and keep calling poll() when you have max records set small, right? This seems like it could be a problem for anything that takes a long time to process messages since the wakeup may be an indicator that the application needs to shutdown...
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
nit: java style
this will never be called if one of the assertions fails
This type is not parameterized. It's generally better to list the parameters when you reference a parameterized type.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
```suggestion val = self.data[key] # See notes in VarsWithSources' docstring for caveats and limitations of the source tracking ```
It would be nice if this class was immutable, and this line shows why it isn't currently. This is how to make it immutable: ``` List<CompositeValuesSourceBuilder<?>> sources = new ArrayList<>(num); for (int i = 0; i < num; i++) { CompositeValuesSourceBuilder<?> builder = CompositeValuesSourceParserHelper.readFrom(in); sources.add(builder); } this.sources = Collections.unmodifableList(sources); ```
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
can we just change this to System.getProperty("tests.seed") != null? Then that method can be removed.
Why not just use System.getProperty("tests.seed") ? is this an intellij auto-complete thing? I see this anti-pattern quite often and i wonder why its done.
ReflectiveOperationException can be used instead of both of these
That's quite fragile IMO. There is no guarantee that `CouchbaseProperties` won't be processed differently in the future.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
If we don't count token with 0-increment this should be equal to 2
I haven't seen this struct being used.
Are you sure? I don't see this struct being used for read anywhere.
nit: we could require non-negative value for `numOfRepartitions`
`...build a graph to calculate partition number of repartition topic, and numOfRepartitions of underlying TopicsInfo is used for memoization.`
This is why I do not like `assertEquals`; this is backwards from expected and actual. Instead: `assertThat(t1.v1(), equalTo(2L))`.
Double-brace initialization is an anti-pattern. It would be preferable to use `mkProperties`.
Perhaps I misunderstood Anssi's original intent somehow, but the fact that your filter expression uses INNER joins seems like you're maintaining the status quo at the minimum. @charettes I've just pinged you on IRC but if you've got some thoughts on this I'd like to hear them.
Use: `StreamsException e = assertThrows(StreamsException.class, () -> stateManager.initialize);` and also add `assertThat(e.getMessage(), is("..."))`;
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
If we don't count token with 0-increment this should be equal to 2
I haven't seen this struct being used.
Are you sure? I don't see this struct being used for read anywhere.
nit: we could require non-negative value for `numOfRepartitions`
`...build a graph to calculate partition number of repartition topic, and numOfRepartitions of underlying TopicsInfo is used for memoization.`
This is why I do not like `assertEquals`; this is backwards from expected and actual. Instead: `assertThat(t1.v1(), equalTo(2L))`.
Double-brace initialization is an anti-pattern. It would be preferable to use `mkProperties`.
Perhaps I misunderstood Anssi's original intent somehow, but the fact that your filter expression uses INNER joins seems like you're maintaining the status quo at the minimum. @charettes I've just pinged you on IRC but if you've got some thoughts on this I'd like to hear them.
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I think this can all fit on one line more cleanly if you break after the equal sign.
those are hard to debug I can tell u :dancers:
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I think this can all fit on one line more cleanly if you break after the equal sign.
those are hard to debug I can tell u :dancers:
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I think this can all fit on one line more cleanly if you break after the equal sign.
those are hard to debug I can tell u :dancers:
+1 lets get rid of it! If we don't use it there is no need for the complexity!
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I think this can all fit on one line more cleanly if you break after the equal sign.
those are hard to debug I can tell u :dancers:
Sorry, my example included this initializer but it isn't needed. This is just for information: we can tidy up my mistake when we merge your changes.
This unfortunately doesn't guarantee that all transactions are always rolled back. _dirty is never set if you run read-only queries in the default autocommit mode, yet transaction is started by any query (the cursor.is_dirty() checks if transactions are managed before setting ._dirty). It seems making sure ._rollback is called after every request would be a god idea if the connection isn't going to be persisted. Even better approach is to make the _dirty flag behave somewhat sanely. But this is not this issue's problem.
```suggestion default: no ```
Does this really need to be generic? We certainly don't care about any of that on the consumption side.
nit: space before brackets
The name of the method seems to explain where it's expected to be called from. I wonder if that is necessary.
typo: optain -> obtain
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
I suspect it's now neater to turn this logic around - find the appropriate `Bucket` using `request.getParam("bucket")` and let the `Bucket` check the authorisation, look up the handler, and do the necessary.
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
I'm curious why we have getValues if all of these classes already extend list? Nothing to do with this PR, just something I noticed: since we are looking at breaking changes in the future, maybe this could be cleaned up too (either extend list, or have getValues())
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
Yes, I confused myself.
I wonder if the input parameter should just be typed as an `IdentityHashMap` then? Note that currently this will silently ignore duplicates in the input `tasks`.
can we name this `CompleteDiff` don't use simple please :)
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
I'm curious why we have getValues if all of these classes already extend list? Nothing to do with this PR, just something I noticed: since we are looking at breaking changes in the future, maybe this could be cleaned up too (either extend list, or have getValues())
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
Yes, I confused myself.
I wonder if the input parameter should just be typed as an `IdentityHashMap` then? Note that currently this will silently ignore duplicates in the input `tasks`.
can we name this `CompleteDiff` don't use simple please :)
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
static is not needed.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
This TODO should be removed
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
Do you need this `int` cast? I thought I removed that in my branch and it worked fine.
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
and -> a
base -> based progress -> progressed
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
request "got" re-sent to the control
as above (more often below -- please fit all)
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
and -> a
This overload does not take `Materialized` parameter
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
and -> a
base -> based progress -> progressed
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
request "got" re-sent to the control
as above (more often below -- please fit all)
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
and -> a
This overload does not take `Materialized` parameter
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
nit: {@link KafkaClientSupplier}
a constant could cause problems though if the constant gets misused (e.g. changing its boost etc.), method is ok sorry
We should update the Scala `TestUtils` to call this method.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think filter and query can never be null here? not sure whether we should validate this here.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
nit: also add java doc for type `T, O` here
s/y ou/you Also I think upfront is one word.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I see that we need it from another package, I think it's ok.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
base -> based progress -> progressed
nit: We could omit `res` and return directly in the two places below.
and -> a
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
and -> a
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
base -> based progress -> progressed
nit: We could omit `res` and return directly in the two places below.
and -> a
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
and -> a
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
nit - an extra d? release**d**Delayed..
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
method name changes
lower cased exception name
where is this method used? I can't find it
> Ok this doesn't work because the standard synonym token filter also sets the position length attribute Arrrrgh, you are right. Here's maybe another idea: why not always treat things as if they were a graph,since a single linear chain of tokens really is just a graph. And then, when the graph enumerates to just one path, it should naturally "become" what already happens today? I.e. don't break out any special treatment for "graph" vs "not graph".
I _think_ you could just pull the `PositionLengthAttribute` and if it has a value greater than 1 on any token, it is a graph.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
We can call the static function of KStreamImpl directly and get rid of the additional function in `InternalStreamsBuilder`.
nit - an extra d? release**d**Delayed..
the naming used above seems better here ```suggestion Throwable exception = null; ```
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
typo: CompleteableFuture -> CompletableFuture
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
I am good
the naming used above seems better here ```suggestion Throwable exception = null; ```
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
Listener can be null here.
unkown -> uknown
unkown -> uknown
nit: add `final`
nit: add `final`
nit: add `final`
super nit: extra blank line
nit: add `final`
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
unkown -> uknown
unkown -> uknown
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
The implication here is that wakeup won't work if you've fetched data and keep calling poll() when you have max records set small, right? This seems like it could be a problem for anything that takes a long time to process messages since the wakeup may be an indicator that the application needs to shutdown...
Yeah, Java's type system makes this stuff a pain. I think you can fix it with: ``` final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(new KStreamBranch<>((Predicate<K, V>[]) predicates.clone(), childNames), branchName); ``` which should be safe If you want to also get rid of the cast, you can do it by coercing each of the predicates to a Predicate<K,V> when you loop over them at the beginning: ``` Predicate<K, V>[] kvPredicates = new Predicate[predicates.length]; for (int i = 0; i < predicates.length; i++) { final Predicate<? super K, ? super V> predicate = predicates[i]; Objects.requireNonNull(predicate, "predicates can't be null"); kvPredicates[i] = predicate::test; } ```
I would execute the `IOUtils.close(resources);` in a finally block after we sent back the response or the other way around.
as above: avoid `/` Update to ``` log.warn("Unable to read '{}{}{}'. Using default inputValues list", "resources", File.seperator, fileName); ```
It feels to me that this is the wrong approach to the problem. Looking at the reported issue, setting `spring.datasource.schema-username` should not have any impact on an embedded database that we've created. Rather, we should detect such case and ignore the username and password.
Unfortunately, the fact the database is embedded is not exactly the same as us replacing the database with an embedded database. In theory, I'd very surprised if an embedded database would require different credentials for schema initialization so that approach would work but not really semantically correct IMO.
prop: change `stateStoreNames` -> `stateStoreName` here.
I wonder if we can just get a Map with the default size. I don't expect this code path to be very hot
Should we mention this in the KIP? It was not specified there - even though this is the same behavior as the old AlterConfigs, in the context of the KIP this non-transactional functionality isn't obvious I fear
nit: maybe we could add an example here like "e.g a configuration key was specified more than once"
This data construction seems better to be put in the `AlterConfigsResponse` constructor.
I am good
the naming used above seems better here ```suggestion Throwable exception = null; ```
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
Listener can be null here.
unkown -> uknown
unkown -> uknown
I am good
the naming used above seems better here ```suggestion Throwable exception = null; ```
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
Listener can be null here.
unkown -> uknown
unkown -> uknown
it makes it too easy to call delete when its not necessary.
Was this intentional? `VALUE_SERDE_CLASS_CONFIG` is deprecated.
an -> a
base -> based progress -> progressed
and -> a
and -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
an -> a
nit: remove extra line
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
`KeyValueStore` -> `TimestampedKeyValueStore`
nit: remove extra line
nit: remove empty link
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
as above (more often below -- please fit all)
This overload does not take `Materialized` parameter
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
`KeyValueStore` -> `TimestampedKeyValueStore`
nit: remove extra line
nit: remove empty link
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
as above (more often below -- please fit all)
This overload does not take `Materialized` parameter
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
must be param prefixes now
"of [an] ever-updating ..."
where is this method used? I can't find it
lower cased exception name
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
`KeyValueStore` -> `TimestampedKeyValueStore`
nit: remove extra line
nit: remove empty link
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
as above (more often below -- please fit all)
This overload does not take `Materialized` parameter
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
super nit: ditto from above
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
super nit: ditto from above
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
and also add it to thenApply while we're at it
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
super nit: ditto from above
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
We should use try-with-resources here (for `DataInputStream`).
This is logic that I think should go into ReplicatedOperation.
this logic belongs in transportWriteAction
This is not in this PR: I realized that in `KGroupedStreamsImpl#repartitionIfRequired`, in the return statement: ``` return KStreamImpl.createReparitionedSource(this, keySerde, valSerde, queryableStoreName); ``` We pass the `queryableStoreName` as the prefix of the repartition topic. That seems not correct to me? cc @enothereska since it seems from one of your previous commits,.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
nit: Since we are reusing this function for aggregations as well now, better rename to `createReparitionedSource`.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
We should use try-with-resources here (for `DataInputStream`).
This is logic that I think should go into ReplicatedOperation.
this logic belongs in transportWriteAction
This is not in this PR: I realized that in `KGroupedStreamsImpl#repartitionIfRequired`, in the return statement: ``` return KStreamImpl.createReparitionedSource(this, keySerde, valSerde, queryableStoreName); ``` We pass the `queryableStoreName` as the prefix of the repartition topic. That seems not correct to me? cc @enothereska since it seems from one of your previous commits,.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
nit: Since we are reusing this function for aggregations as well now, better rename to `createReparitionedSource`.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we name this `CompleteDiff` don't use simple please :)
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we name this `CompleteDiff` don't use simple please :)
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we name this `CompleteDiff` don't use simple please :)
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I think we should call `deserializer.configure(...)` here
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
can we name this `CompleteDiff` don't use simple please :)
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
New public classes should have a `@since 2.7.0` (assuming we're going to accept this PR).
Missing a `@since`. I wonder if that wouldn't be something of interest for the library (ping @jkschneider)
Nit: `casted` should read `cast`.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
Nitpick: I'd call this `deserialize`.
We should limit this suppression to the method for which we really need it instead of the whole class
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
New public classes should have a `@since 2.7.0` (assuming we're going to accept this PR).
nit: an object -> an object has associated partition offsets that can be ...
It's not necessary to have `PENDING_VALUE`, `RUNNING_VALUE`, etc. since you can just call `PENDING.name()` to get the string `"PENDING"`
I'd consider making this extend org.junit.rules.ExternalResource - it can then be used as a JUnit ClassRule or Rule. The benefits being that the JUnit framework takes care of startup and shutdown
That's a good idea. Note: Kafka does not use this JUnit functionality yet (i.e. no use of ExternalResource, ClassRule, Rule as far as I can tell). @ijuma: Would it ok for us to introduce this? There's no additional dependency etc., it's just using a new JUnit feature that was introduced in 4.7 (we're on 4.12).
I think we probably should clean these up so they are more useful for users, but won't block merging this on that. I was thinking something more along the lines of: ``` UUIDDeserializer deserializes UUIDs in standard 36-byte hexidecimal string representation. ``` then followed by the encoding details, i.e. the stuff a user wants to know. Many users won't even think about the fact that what's going into the deserializer (or out of the serializer) is actually a `byte[]`.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
two license headers? :)
Understood. I've bumped the version to 4.0.0.RELEASE in my modified version of your commit: https://github.com/wilkinsona/spring-boot/commit/f0089a40bc95c16dc9b386c63530f4c80f49f1eb. I'll merge this tomorrow (assuming the JFrog issues have been resolved by then)
Thanks, Artem. Dropping the `groovy-xml` dependency makes sense. I think we should stick with using the starter (as part of this change at least). I'll take care of that when I merge this in.
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
This line is failing checkstyle.
When it gets long like this can you indent it like ``` assertResult(() -> builder() .startObject() .startObject("foo") .startObject("bar") .endObject() .endObject() .endObject(), ``` I know we `assertThat` has the matcher second, but maybe we should put the closure second for this? I think it is nice when the closure is second because it makes the code formatting prettier.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
Same here - more randomization would be nice
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
`assertEquals` and `assertSame` for these? I like to avoid hamcrest if it doesn't buy anything beyond "normal" junit asserts.
Can you assert something about the message? As it stands someone could break something to throw a **different** `IllegalArgumentException` and we'd not notice.
nit: missing `<p>` for new paragraph
```suggestion * is an empty {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
```suggestion * is {@code null}, no records are emitted. ``` Please also fix this on the original method
nit: remove empty line
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
nit: `punctuate each second` (might be c&p error and affect other places, too) -- maybe better to address in separate PR (the `void punctuate()` issue and this can be one PR IMHO).
```suggestion * {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: missing `<p>` for new paragraph
```suggestion * is an empty {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
```suggestion * is {@code null}, no records are emitted. ``` Please also fix this on the original method
nit: remove empty line
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
nit: `punctuate each second` (might be c&p error and affect other places, too) -- maybe better to address in separate PR (the `void punctuate()` issue and this can be one PR IMHO).
```suggestion * {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
no need to use `this.` outside the constructor. Here and below
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
Typo: "`local checkpoint`" -> "`local checkpoints`".
Not sure if we need to do that it's just one entry per field though.
should we use a native trove collection here from String to long
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
We should use try-with-resources here (for `DataInputStream`).
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I looked at it, and I think the scenario is a bit different in `public <T> T getConfiguredInstance(String key, Class<T> t)` as in here, where `Utils.newInstance(Class<T> c)` is called and the passed `Class<?>` is directly from the config, where in this case the config value is a `String` and we directly use that in `Utils.newInstance`.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
no need to use `this.` outside the constructor. Here and below
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Add the `@Overrride` annotation to this method.
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
Typo: "`local checkpoint`" -> "`local checkpoints`".
Not sure if we need to do that it's just one entry per field though.
should we use a native trove collection here from String to long
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
nit: can remove type arguments
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Also set the store name in this test.
line too long
We should use `to()` and use a `TestOutputTopic` instead of the processor
Line too long (also some lines above and further below)
Just see the test from below with "many windows" -- I think we can merge them into one test
Just see the `timeWindowMixAggregatorsTest` below -- seems it's a super set of this test and hence, having the second one only seems to be sufficient.
There are two input streams in this test, and thus we should create a second `TestInputTopic` to pipe input via both.
This seems to be the same program as in the test above -- if yes, I think we should merge both tests into one.
I think it is fine: we only build one search context per request per shard.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Just dug into it and found we use `TestRuleAssertionsRequired` from the lucene-test-framework jar to do this check
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
No need for the `u` prefix, we're already importing `unicode_literals`.
Is it guaranteed that the contents of `errors` will only actually be compilation errors and not, e.g., warnings? Might be worth just using the return value of [call()](https://docs.oracle.com/javase/8/docs/api/javax/tools/JavaCompiler.CompilationTask.html#call--) to determine if compilation succeeded.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
Gotcha. Okay, two points: 1) It may be overkill, but you may want to consider separating the input (source, resource, etc.) files from the output (compiled class, JAR) files. It'd more closely mirror the build setup that's commonly used for Java projects and would probably make this code easier to modify in the future. 2) This bug initially surfaced with use of the `ServiceLoader` mechanism; it'd be great if we could have a test that verifies that the changes here fix how that works in isolated plugins.
Let's use `Map` on the left side instead of `HashMap`
Well, it shouldnt be. The suppressed exceptions are like 'children' of `cause`, they don't need to be shuffled around. The current code is basically attaching grandchildren as children, which will be confusing.
We should nuke all this logic after the `super` call, because now we init the exception with `ex` as root cause, so it will still keep all of its suppressed exceptions.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
I don't think this is the right approach. Even if the root cause is important, we still want to know that we experienced a disconnect. If I'm reading it right, the current patch does not show this. In general, we can't really make blanket statements like "the root cause is always the most useful thing" It depends on how the code is using the exceptions. Also, we shouldn't change what any of the exception output is without making a detailed examination of the before and after log output, and making sure that we like the "after" output better.
It will be worth mentioning that it includes the root cause since this is in `Utils`.
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
This TODO should be removed
Considering that we may have multiple `WebServiceMessageSender`, I don't think we should expose this method here. You can provide a configured `WebServiceMessageSender`, this feels weird to me that all of them are reconfigured behind the scenes.
This should also go away.
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
IMO that's one more argument to remove that feature.
I've removed the Supplier in my polish commit. I didn't found a single use of it and would argue that it is something you can determine when you build the template
In the meantime I've seen we're doing that with `RestTemplateBuilder` and I see you're using a separate collection. Retrospectively, it's not that bad at all.
I don't like this pattern. If you call the setter several times, you'll append this customizer and rely on the fact the last one called will set the expected value. I guess you've done this that way to avoid adding too much parameters to the builder? I think we need to find a different option for this.
Got it but I think the reason why a `Supplier` was added is wrong.
there are too many flavours to set a `WebServiceMessageSender`. Specifying a vararg of instance and a `Class` looks wrong to me. I've removed that in my fork.
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
yeah, prefer top-level there as well.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
and -> a
base -> based progress -> progressed
and -> a
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
yeah, prefer top-level there as well.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
base -> based progress -> progressed
and -> a
and -> a
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
yeah, prefer top-level there as well.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
and -> a
base -> based progress -> progressed
and -> a
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
This is skipping a path in `for path in list_valid_collection_paths(search_paths):`, and not the filter.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Can this use `b_output_path` from line 291? ```suggestion b_output_path, ```
I'm fine with the change in message, just noting that this test needs to be fixed up to check the new assertion https://github.com/ansible/ansible/blob/cf39d9de258cb9c47de9043e1a85e327e177dba7/test/integration/targets/ansible-galaxy-collection/tasks/install.yml#L43.
to_text and prefix the string with u.
probably want a to_text and u prefix.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
This is skipping a path in `for path in list_valid_collection_paths(search_paths):`, and not the filter.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Can this use `b_output_path` from line 291? ```suggestion b_output_path, ```
I'm fine with the change in message, just noting that this test needs to be fixed up to check the new assertion https://github.com/ansible/ansible/blob/cf39d9de258cb9c47de9043e1a85e327e177dba7/test/integration/targets/ansible-galaxy-collection/tasks/install.yml#L43.
to_text and prefix the string with u.
probably want a to_text and u prefix.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
This is skipping a path in `for path in list_valid_collection_paths(search_paths):`, and not the filter.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Can this use `b_output_path` from line 291? ```suggestion b_output_path, ```
I'm fine with the change in message, just noting that this test needs to be fixed up to check the new assertion https://github.com/ansible/ansible/blob/cf39d9de258cb9c47de9043e1a85e327e177dba7/test/integration/targets/ansible-galaxy-collection/tasks/install.yml#L43.
to_text and prefix the string with u.
probably want a to_text and u prefix.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
`border_mode` is not required. The output is of value : (batch size, num_input_channels, input row size * row ratio, input column size * column ratio) So fi the ratio is good, everything should be.
Style: space needed after comma.
`{}` won't work in python 2.6.
The way to do examples changed. Now your EXAMPLES section can simply be a list of tasks, or a play.
Probably best to use the YAML syntax for examples here. You no longer need to use `description:` and `code`. You can just add your tasks as in a normal playbook with `name:` and your module action.
Use `utils.xpath_text` instead, again with `fatal=False`.
No, default is ok. I've just emphasized it should not be fatal in order not to break extraction.
One more thing, avoid long strings if possible.
All the fields except `title` should be passed `fatal=False` in order not to break extraction if webpage layout for any of these field changes.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
I think that these log parameters are backwards.
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
I think this can all fit on one line more cleanly if you break after the equal sign.
nit: fix alignment.
We should log an error that prints out what the two configs actually are
state.isRunning() is as below ``` public boolean isRunning() { return equals(RUNNING) || equals(STARTING) || equals(PARTITIONS_REVOKED) || equals(PARTITIONS_ASSIGNED); } ``` if its not too much work, we can rename to something like `state.isAlive()` , that captures what we want to check .. your call.
this is creative :)
the naming used above seems better here ```suggestion Throwable exception = null; ```
ok, fair enough
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
just please don't add one. There are too many classes already.
shard can remain
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
as above. `requireNotNull` not necessary any longer
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Do we need to lock here? I think the lock has already been taken out from the callers of this method
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
I don't know what you mean by "consider qualifier in the build". There should be no attempt to test bwc of any qualified version, so I don't believe the build needs to know about it in our build Version, since that class is all about which versions we bwc test against.
I would make the class `final`, and these members `public final`
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
as above. `requireNotNull` not necessary any longer
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
Do we need to lock here? I think the lock has already been taken out from the callers of this method
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
I don't know what you mean by "consider qualifier in the build". There should be no attempt to test bwc of any qualified version, so I don't believe the build needs to know about it in our build Version, since that class is all about which versions we bwc test against.
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
I would make the class `final`, and these members `public final`
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
as above. `requireNotNull` not necessary any longer
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
Do we need to lock here? I think the lock has already been taken out from the callers of this method
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
I don't know what you mean by "consider qualifier in the build". There should be no attempt to test bwc of any qualified version, so I don't believe the build needs to know about it in our build Version, since that class is all about which versions we bwc test against.
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
I would make the class `final`, and these members `public final`
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
Is it correct to set parent node name as `this.name + "GROUP_BY"`? Seems the parent node name is not set in this way. Ditto below.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
as above. `requireNotNull` not necessary any longer
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
Do we need to lock here? I think the lock has already been taken out from the callers of this method
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
I don't know what you mean by "consider qualifier in the build". There should be no attempt to test bwc of any qualified version, so I don't believe the build needs to know about it in our build Version, since that class is all about which versions we bwc test against.
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
I would make the class `final`, and these members `public final`
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
as above. `requireNotNull` not necessary any longer
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
I wonder if we should use the cluster state for this check. I'm worried about people passing in a dated cluster state here. Maybe a cleaner model is to make this method synchronised (to avoid async collision with the create code) and check the existence of the index instance in the #indices map member of this class.
as above: avoid `/` Update to ``` log.warn("Unable to read '{}{}{}'. Using default inputValues list", "resources", File.seperator, fileName); ```
nit: maybe we could add an example here like "e.g a configuration key was specified more than once"
Should we mention this in the KIP? It was not specified there - even though this is the same behavior as the old AlterConfigs, in the context of the KIP this non-transactional functionality isn't obvious I fear
`windowSize` should be `Duration`
Question, do you think it would be helpful to copy the pattern we have elsewhere having a `*Safe` version of the functions? So something like: ``` java public Decision getDecisionSafe() { if (isDecisionTaken() == false) { throw new IllegalArgumentException("decision must have been taken in order to return decision"); } return decision; } ```
Additionally, I like calling these `getFinalDecision` in ClusterAllocationExplanation.java because it differentiated it from the node decisions, how do you feel about that? (It would also probably change `getExplanation()` to `getFinalExplanation()`)
method name changes
Ideally we'd not wrap the exception if there are no retries, so I guess it just depends on how hard it is to make that work.
I think there's an edge case where `timeoutMs` is positive but small enough that the condition on line 77 is not met but the while loop on line 85 is not satisfied because the end time has already passed. In this edge case, we might not call the callable function (even once). One option is to change the while loop to be a do-while loop so that we always go through one loop. Another option is to compute the remaining time before line 77 and not update it before the while loop. Either would work, but one of the options may require fewer duplicated lines.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
nit: remove empty line
nit: `punctuate each second` (might be c&p error and affect other places, too) -- maybe better to address in separate PR (the `void punctuate()` issue and this can be one PR IMHO).
This should be the last step
Is the `& 0x7f` needed here? The protobuf code doesn't seem to do that: ```java if ((value & ~0x7F) == 0) { buffer[position++] = (byte) value; totalBytesWritten++; return; } else { buffer[position++] = (byte) ((value & 0x7F) | 0x80); totalBytesWritten++; value >>>= 7; } ```
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
nit: IOException never thrown
What about inlining `transformations` and having something like: ``` when(plugins.transformations()).thenReturn(Collections.singleton(transformationPluginDesc())); ```
`<byte[]>` this explicit type is unnecessary
typo: byteArrray -> byteArray
a leftover here which can be removed
Not sure I have great ideas for improvement, but this feels like a brittle test case. I wonder if we are just trying to handle too many cases in this test.
I don't know that we care about closing the handler. It probably does not matter too much, but there should not be any resources hanging around if we properly consume all the requests.
Is this name correct? It seems like the buffer is never filled in this test.
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
Similar to below. Maybe `testManualAssignmentChangeWithAutoOffsetCommitEnabled` is a more descriptive name.
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
in generation, this should be a variable that's resolved and cached. We shouldn't do settings lookups with each op.
Not sure I have great ideas for improvement, but this feels like a brittle test case. I wonder if we are just trying to handle too many cases in this test.
lets' introduce a dedicated exception for this. We can upgrade discovery.zen.NotMasterException to be in the cluster package and use that.
The logging brackets are off here: `[{} to [{}]]`.
let's just skip the iterator and use IndexShardRoutingTable.shards() (put it in a variable and use it in do run as well)
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
Nit: line too long
I don't know that we care about closing the handler. It probably does not matter too much, but there should not be any resources hanging around if we properly consume all the requests.
nit: IOException never thrown
Not sure I have great ideas for improvement, but this feels like a brittle test case. I wonder if we are just trying to handle too many cases in this test.
Please use parentheses rather than backslashes for line continuations.
What about inlining `transformations` and having something like: ``` when(plugins.transformations()).thenReturn(Collections.singleton(transformationPluginDesc())); ```
typo: byteArrray -> byteArray
Why this restriction? If several files are saved in a quick sequence — for instance with a text editor's "save all" feature" — only the first change willl be taken into account.
`<byte[]>` this explicit type is unnecessary
remove "0" in {0}
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
base -> based progress -> progressed
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
and -> a
and -> a
```suggestion * This is a synchronous commit and will block until either the commit succeeds, an unrecoverable error is ```
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
base -> based progress -> progressed
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
and -> a
and -> a
```suggestion * This is a synchronous commit and will block until either the commit succeeds, an unrecoverable error is ```
This doc seems wrong for `retry.timeout`. Or is this really a retry limit? Either way, might want to mention the constraints (e.g., "Must be a positive number.") that are enforced by the config.
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
This line can be reverted now that the JUnit 4/5 split is gone.
There's really no reason to remove that.
Still not addressed -- we should mention both methods return this iterator.
`long,long` is used for `WindowStore` while `Instance,Duration` (or `Instance,Instance` if we correct it) is use for `ReadOnlyWindowStore` that return the same iterator.
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
We don't format method name that way. Please look at the rest of the codebase for inspiration.
Please remove the extra new lines.
Good idea to add this safety net.
Thanks. Not a blocker.
Nitpick: I'd call this `deserialize`.
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
Why did not remove this from being a `ParseField`? This seems to go against the prevailing pattern.
make class final
I wonder why we're mocking this simple class. Maybe we can fix the tests? :-)
I wonder if we should use something like `"_na_"` similar to the `INDEX_UUID_NA_VALUE`. That is more an explicit value.
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
We've avoided using `@Nested` thus far.
Thanks. Not a blocker.
I don't think this is needed. All inner `@Configuration` classes will be implicitly imported. If it's for ordering purposes then I think things will need to be restructured to ensure that they're processing in the right order. Something that is structured like org.springframework.boot.autoconfigure.thymeleaf.TemplateEngineConfigurations may be needed.
If these aren't expected to change at runtime, I'd suggest initializing the `HashMap` in the static block as a temporary variable , then wrapping it to create an unmodifiable map which is then used for the constant here: ```java Map<String, File> pluginJars = new HashMap<>(); try { pluginJars.put(..., ...); // More of the same } finally { PLUGIN_JARS = Collections.unmodifiableMap(pluginJars); } ```
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
We should use try-with-resources here (for `DataInputStream`).
as above. use `StreamsConfig#...`
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Fixed this in my latest update of #4033.
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
good point.... we should be able to get rid of it.
No need to check null. We always have to forward oldAgg and newAgg, anyway.
nit: formatting -> only one parameter per line
nit: Since we are reusing this function for aggregations as well now, better rename to `createReparitionedSource`.
I think the old indentation was a bit better than this.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
last parameter can be set to from.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
good point.... we should be able to get rid of it.
Fixed this in my latest update of #4033.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
as above. use `StreamsConfig#...`
We should use try-with-resources here (for `DataInputStream`).
This TODO should be removed
nit: Since we are reusing this function for aggregations as well now, better rename to `createReparitionedSource`.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
"do nothing" is probably the right thing here.
> A new method also means their code is then not binary compatible with older client versions. yep, the BC could be broken. What I really care is the source compatibility. It seems to me a public API should be source compatible to next major release :) This patch is good to go and we need more time (rather than vespene gas ... StarCraft is my favor game :) ) to reach consensus.
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
"do nothing" is probably the right thing here.
> A new method also means their code is then not binary compatible with older client versions. yep, the BC could be broken. What I really care is the source compatibility. It seems to me a public API should be source compatible to next major release :) This patch is good to go and we need more time (rather than vespene gas ... StarCraft is my favor game :) ) to reach consensus.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
This TODO should be removed
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
> A new method also means their code is then not binary compatible with older client versions. yep, the BC could be broken. What I really care is the source compatibility. It seems to me a public API should be source compatible to next major release :) This patch is good to go and we need more time (rather than vespene gas ... StarCraft is my favor game :) ) to reach consensus.
"do nothing" is probably the right thing here.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
> I think cleanest the way to do it backwards compatibly is to introduce a new store hierarchy and deprecate the old one. I am afraid that might be the only way to do it -- deprecation hell -- users won't be happy -- thus we should think hard if it's worth to do or not...
Cool, I will create a JIRA ticket for now to keep track of it.
can we mark this as nullable (and doc when it's null)? also, can we move it next to the setter, and make the naming consistent with the rest of this class? (i.e., shardId)
I'm not convinced we gain anything by adding another level of inheritance here. It removes one method that doesn't do much anyway. My preference would be to leave it as it was. If we are going to use inheritance then i think we should keep the hierarchy as shallow as possible.
I'm curious why we have getValues if all of these classes already extend list? Nothing to do with this PR, just something I noticed: since we are looking at breaking changes in the future, maybe this could be cleaned up too (either extend list, or have getValues())
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
can we name this `CompleteDiff` don't use simple please :)
"of [an] ever-updating ..."
"do nothing" is probably the right thing here.
Good question. AK 3.0 is a good opportunity to do such breaking changes so I would be in favour of doing it. Let's see what other think.
> But this wasn't described in the KIP and wouldn't be a source compatible change (existing code with a catch (InterruptedException) As it can cause compatible change, we should deprecate it and then add a new method (for example: get(T value)) to replace it. This can be discussed in another issue :)
> A new method also means their code is then not binary compatible with older client versions. yep, the BC could be broken. What I really care is the source compatibility. It seems to me a public API should be source compatible to next major release :) This patch is good to go and we need more time (rather than vespene gas ... StarCraft is my favor game :) ) to reach consensus.
the naming used above seems better here ```suggestion Throwable exception = null; ```
I like the type safety!
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
> I think cleanest the way to do it backwards compatibly is to introduce a new store hierarchy and deprecate the old one. I am afraid that might be the only way to do it -- deprecation hell -- users won't be happy -- thus we should think hard if it's worth to do or not...
Cool, I will create a JIRA ticket for now to keep track of it.
can we mark this as nullable (and doc when it's null)? also, can we move it next to the setter, and make the naming consistent with the rest of this class? (i.e., shardId)
I'm not convinced we gain anything by adding another level of inheritance here. It removes one method that doesn't do much anyway. My preference would be to leave it as it was. If we are going to use inheritance then i think we should keep the hierarchy as shallow as possible.
good point.... we should be able to get rid of it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
I'm curious why we have getValues if all of these classes already extend list? Nothing to do with this PR, just something I noticed: since we are looking at breaking changes in the future, maybe this could be cleaned up too (either extend list, or have getValues())
This is a nitpick, but perhaps we should not use `at the same time` in `close` or `configure` because it won't actually happen at the same time (it will most likely happen sequentially, but we don't have to specify that).
can we name this `CompleteDiff` don't use simple please :)
"of [an] ever-updating ..."
same typo - copy paste probably
could be a instance variable, as used in all tests
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
How about "runs an external command for the worker."
can we open an issue/track it somewhere that these should be evaluated
Earlier we discussed sending the task spec on the process' standard input. Did you decide not to do this? It seems like using a command-line option will be pretty awkward...
Will categorisation jobs use `AutoDetectResultProcessor`? If so it should be renamed.
+1, rather catch them early than with transport weirdness later on
Why do you need to prepare `KafkaStreams` for testing? Only classes that are mocked and that are either `final` or have static methods need to be prepared.
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
Well, it shouldnt be. The suppressed exceptions are like 'children' of `cause`, they don't need to be shuffled around. The current code is basically attaching grandchildren as children, which will be confusing.
We should nuke all this logic after the `super` call, because now we init the exception with `ex` as root cause, so it will still keep all of its suppressed exceptions.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
This is logic that I think should go into ReplicatedOperation.
This changes the empty options.. no good..
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
I don't think this is the right approach. Even if the root cause is important, we still want to know that we experienced a disconnect. If I'm reading it right, the current patch does not show this. In general, we can't really make blanket statements like "the root cause is always the most useful thing" It depends on how the code is using the exceptions. Also, we shouldn't change what any of the exception output is without making a detailed examination of the before and after log output, and making sure that we like the "after" output better.
We should log the the failure here if the close fails
It will be worth mentioning that it includes the root cause since this is in `Utils`.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
This is logic that I think should go into ReplicatedOperation.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
This changes the empty options.. no good..
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
I don't think this is the right approach. Even if the root cause is important, we still want to know that we experienced a disconnect. If I'm reading it right, the current patch does not show this. In general, we can't really make blanket statements like "the root cause is always the most useful thing" It depends on how the code is using the exceptions. Also, we shouldn't change what any of the exception output is without making a detailed examination of the before and after log output, and making sure that we like the "after" output better.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
I'd be tempted to rename this `getJobName()`
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
This TODO should be removed
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
nit. I think there is `.` missing `since 3.0[.] Use`
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
Maybe use log parameters instead? ``` java log.warn("Error executing interceptor onSend callback for topic: {}, partition: {}", record.topic(), record.partition(), t); ```
Oh, good to know that they've changed the behaviour since 1.6.0 to make this work (i.e. if the last parameter is unused and it's a Throwable, then it's interpreted as a Throwable instead of a parameter).
Actually I think it works: http://www.slf4j.org/faq.html#paramException.
This is a little annoying, but you do that the Throwable is also a parameter. As far as I can see, there is no overload that takes a Throwable _and_ parameters. I assume that's why Anna did it like this. However, I didn't test to see if slf4j does a runtime check on the arguments to look for a Throwable (it would surprise me if it did).
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Yeah, I think it's worth the bit of logic to fail more quickly.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
no need to use `this.` outside the constructor. Here and below
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
Nit: ```suggestion final long maxAttempts = maxRetries + 1; ```
WDYT? ```suggestion log.warn("RetriableException caught on attempt {}, retrying automatically up to {} more times. " + "Reason: {}", attempt, maxAttempts - attempt, e.getMessage()); ```
Are we intentionally not logging the exception as the extra parameter? If the exception wraps a more useful exception, we won't see any information about the wrapped exception unless we can see the stack trace in the warning log message.
This is a weird line break. It would be better to shorten the line by assigning the result of `mapper.apply` to a variable.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Yeah, I think it's worth the bit of logic to fail more quickly.
Nit: ```suggestion final long maxAttempts = maxRetries + 1; ```
WDYT? ```suggestion log.warn("RetriableException caught on attempt {}, retrying automatically up to {} more times. " + "Reason: {}", attempt, maxAttempts - attempt, e.getMessage()); ```
Are we intentionally not logging the exception as the extra parameter? If the exception wraps a more useful exception, we won't see any information about the wrapped exception unless we can see the stack trace in the warning log message.
Maybe "to specify callbacks for producer.send() or to call .get() on the returned Future:..."
For the cases where I've wanted to use a nose test generator, I've ended up just making the test class inherit from object. You lose the TestCase methods (various self.assert*) but usually test generators methods have pretty simple assertions so not too much of a issue. To me it is simpler than injecting the support into a TestCase subclass. (an example is https://github.com/alikins/ansible/blob/6e8a3d0c25fdeaa349351c6636b062376c30b0a6/test/units/plugins/lookup/test_ini.py)
as above. `requireNotNull` not necessary any longer
Yeah, Java's type system makes this stuff a pain. I think you can fix it with: ``` final ProcessorParameters<K, V> processorParameters = new ProcessorParameters<>(new KStreamBranch<>((Predicate<K, V>[]) predicates.clone(), childNames), branchName); ``` which should be safe If you want to also get rid of the cast, you can do it by coercing each of the predicates to a Predicate<K,V> when you loop over them at the beginning: ``` Predicate<K, V>[] kvPredicates = new Predicate[predicates.length]; for (int i = 0; i < predicates.length; i++) { final Predicate<? super K, ? super V> predicate = predicates[i]; Objects.requireNonNull(predicate, "predicates can't be null"); kvPredicates[i] = predicate::test; } ```
Well that's the problem, we don't know what's important for a custom rescorer. `SearchContext` is mutable which is why I think it's too sensitive but the same applies to `SearchSourceBuilder` so you're probably right. We can find ways to pass more information in the `RescoreContext` anyways so +1 to keep this simplification.
as above. `requireNotNull` not necessary any longer
Maybe you could put the validation removed from toCContent here. (point.size > 0)
This should be 2.7 please.
I think it's always a single node cluster, but I'm good to keep it like this.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
No, I still think that it should not be a method on the `Strings` class.
We should nuke all this logic after the `super` call, because now we init the exception with `ex` as root cause, so it will still keep all of its suppressed exceptions.
Well, it shouldnt be. The suppressed exceptions are like 'children' of `cause`, they don't need to be shuffled around. The current code is basically attaching grandchildren as children, which will be confusing.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
This is logic that I think should go into ReplicatedOperation.
This changes the empty options.. no good..
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Yeah, I think it's worth the bit of logic to fail more quickly.
WDYT? ```suggestion log.warn("RetriableException caught on attempt {}, retrying automatically up to {} more times. " + "Reason: {}", attempt, maxAttempts - attempt, e.getMessage()); ```
Are we intentionally not logging the exception as the extra parameter? If the exception wraps a more useful exception, we won't see any information about the wrapped exception unless we can see the stack trace in the warning log message.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
same typo - copy paste probably
this one is not used - can we remove it until we cat over to the paths API
For efficiency I guess, accumulating vs composing with a new operator for every write. If there are a lot of writes, this could end up with a lot of unecessary objects and an unnecessarily long pipeline.
Here is a further simplification https://github.com/rstoyanchev/spring-boot/commit/fc5a2cb89243e1cf109c22cb6dae7482e692cf60.
Oh I see the `write(Object)` method which handles Publisher values. Still isn't it all collected/aggregated before `response#writeAndFlushWith` is called? So it could be a `List<Object>` (either String or Publisher) which can then be handled through a combination of `Flux.fromIterable` and `concatWith`.
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
Has the author signed the CLA? We can't accept this if not.
@dheld-expedia are you the original author for this? Any chance you could consider submitting it as a PR for Boot so the CLA bot confirms that you've signed the CLA.
Earlier we discussed sending the task spec on the process' standard input. Did you decide not to do this? It seems like using a command-line option will be pretty awkward...
The first two of these fields are unused. I think that's right, and we should remove them and also `ec2Bucket`, by generating the key and token and then passing them into the bucket's constructor.
Do we really need a generic here? It looks to me that it's useful for innerBlobStore() / blobContainer() methods used in tests but otherwise it's not really required.
Typo: > Similar[ly], you can ... with [a] custom ...
don't ignore it? Just call `parser.text()` without the if, should work.
All those `to` can go away in benefit of a generic `public long to(Unit unit)` (more on that later).
This is a breaking change, right? Same for the other `create` method in this class.
This should be 2.7 please.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
can we use Pattern.qoute for the prefix? just being paranoid..
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
I don't know what you mean by "consider qualifier in the build". There should be no attempt to test bwc of any qualified version, so I don't believe the build needs to know about it in our build Version, since that class is all about which versions we bwc test against.
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
remove empty line
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I think you use it indirectly through `parser. isBooleanValueLenient`.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
CCE is never a good idea to throw out - especially since it forces the caller to handle it. It should be handled inside convert directly.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
nit: We could omit `res` and return directly in the two places below.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
`long,long` is used for `WindowStore` while `Instance,Duration` (or `Instance,Instance` if we correct it) is use for `ReadOnlyWindowStore` that return the same iterator.
Still not addressed -- we should mention both methods return this iterator.
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
we can randomly use a different cluster? or maybe downsize the global cluster to 1 node for this test? I also wonder if we should consider to run tests with one node as well? the minNode=2 was only convenience...
I think we can drop the benchmark.
I'm not sure what reference.conf is but this does not seem like a useful description, in my opinion. Descriptions may be published to metric backends, which almost certainly won't have access to the mentioned reference.conf. Even accessing the Actuator endpoint does not mean that person has access to this reference.conf file.
The shapeFieldMapper seems unused here.
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
@rjernst Ping on that cosmetic thing. Not sure it is worth changing though. Up to you :)
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
add a note that this be opened concurrently with another engine? It think that's not obvious.
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
I see! I think your change makes it clearer actually, looks good
yep. sorry I missed it.
java docs on obtainLock please.
I always wondered the same, I think we don't given that everything works without... that said we do have a lot of empty constructors with the `@Inject` annotation. Up to you... ;)
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
I think we can drop the benchmark.
I'm not sure what reference.conf is but this does not seem like a useful description, in my opinion. Descriptions may be published to metric backends, which almost certainly won't have access to the mentioned reference.conf. Even accessing the Actuator endpoint does not mean that person has access to this reference.conf file.
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
java docs on obtainLock please.
add a note that this be opened concurrently with another engine? It think that's not obvious.
we can randomly use a different cluster? or maybe downsize the global cluster to 1 node for this test? I also wonder if we should consider to run tests with one node as well? the minNode=2 was only convenience...
Earlier we discussed sending the task spec on the process' standard input. Did you decide not to do this? It seems like using a command-line option will be pretty awkward...
@rjernst Ping on that cosmetic thing. Not sure it is worth changing though. Up to you :)
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
base -> based progress -> progressed
and -> a
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
and -> a
Considering that we may have multiple `WebServiceMessageSender`, I don't think we should expose this method here. You can provide a configured `WebServiceMessageSender`, this feels weird to me that all of them are reconfigured behind the scenes.
This should also go away.
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
nit: may worth explain how `queryableStoreName` can be find from `materialized` below.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
nit add `a {@link Named} config`
an -> a
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
as above (more often below -- please fit all)
This overload does not take `Materialized` parameter
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Should add that the class is not thread-safe.
This is not a suggestion for change: while working on removing `KStreamBuilder` and `TopologyBuilder` I realized in some unit tests we may still need this class to access the internal topology builder. So probably we cannot remove it even after that, but we can discuss this later in the cleanup PR.
How about making ```SizeDelimitedSend``` be a static method in ```ByteBufferSend```? For example: ```java public static Send withSizeDelimited(ByteBuffer buffer) { ByteBuffer sizeBuffer = ByteBuffer.allocate(4); sizeBuffer.putInt(0, buffer.remaining()); return new ByteBufferSend(sizeBuffer, buffer); } ```
Nice solution to this problem.
`incompatible runtimes and unexpected results` -> `incompatible runtime code and unexpected results or errors.`
Maybe consider replacing `Stack` with `Deque` as `Stack` is synchronized and `ownedSensors` only adds in the constructor and removes values in `synchronized` block already.
nit: avoid `this` if not necessary
Could this be a `URI`? The same question applies to Atlas, Influx, New Relic and SignalFX but I missed those previously.
Let's go with `URI` for this one, and then make all the others use `URI` in a separate commit/PR.
Nitpick: I'd call this `deserialize`.
this line is still a bit long... You could try a static import for `singletonList`.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
this is creative :)
state.isRunning() is as below ``` public boolean isRunning() { return equals(RUNNING) || equals(STARTING) || equals(PARTITIONS_REVOKED) || equals(PARTITIONS_ASSIGNED); } ``` if its not too much work, we can rename to something like `state.isAlive()` , that captures what we want to check .. your call.
typo: CompleteableFuture -> CompletableFuture
no need to use `this.` outside the constructor. Here and below
typo: CompleteableFuture -> CompletableFuture
i.e. defaults on the query params will get rid of this weirdness (although at least it is isolated here)
This is not in this PR: I realized that in `KGroupedStreamsImpl#repartitionIfRequired`, in the return statement: ``` return KStreamImpl.createReparitionedSource(this, keySerde, valSerde, queryableStoreName); ``` We pass the `queryableStoreName` as the prefix of the repartition topic. That seems not correct to me? cc @enothereska since it seems from one of your previous commits,.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
nit: I would rather use the full name instead of using acronyms.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
This should be the last step
no need to use `this.` outside the constructor. Here and below
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
This should be the last step
This is logic that I think should go into ReplicatedOperation.
`performPreSyncedFlush` might call this. Let's make this noop
same here, this might be called by a user-invoked force-merge
nit extra newline
newline, also no need to write `throws EngineException`
newline also no need to write `throws EngineException`
hmm... I really wonder if we are better off throwing in an exception here...
no need for `throws EngineException`
new lines missing. Also we should assert this is never called. Also no need for `throws EngineException`
newline, no need for `throws EngineException`
Is there a way we can check this property on startup as well/instead? Maybe we could check it in SearchModule or MapperService? The concern I see here is that restarts can be a pain for users and here they will only get feedback on the setting when they try to use a span query and then they can't use the query until they get the admin to restart the cluster
For this to be useful to me in my work on KIP-183 I also need `addWaiter()` to be made `public` on `KafkaFuture`.
and also add it to thenApply while we're at it
For completeness I would add ``` The action may be invoked by the thread that calls {@code whenComplete} or it may be invoked by the thread that completes the future. ```
I don't think this method is needed. The existing `toInstance(Function<T, R> factory)` method should do what we need when given a method reference to one of `Mustache.Compiler`'s configuration methods that return a new `Compiler` instance.
and -> a
base -> based progress -> progressed
and -> a
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
Also set the store name in this test.
nit: add `final`
This should return `-1` as old `BadValueTransformer`
nit: add `final`
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
It will good to clear the requests and test when empty as well.
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
Also set the store name in this test.
nit: add `final`
This should return `-1` as old `BadValueTransformer`
nit: add `final`
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
It will good to clear the requests and test when empty as well.
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
Also set the store name in this test.
nit: add `final`
This should return `-1` as old `BadValueTransformer`
nit: add `final`
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
It will good to clear the requests and test when empty as well.
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
You need to insert a `fail("Should have thrown IllegalArgumentException")` to make sure that the test fails if no exception is thrown (same below for all the other tests with this pattern).
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
Also set the store name in this test.
nit: add `final`
This should return `-1` as old `BadValueTransformer`
nit: add `final`
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
It will good to clear the requests and test when empty as well.
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
HttpClient is optional, might be better to use RestTemplate.
nit: parameter descriptions are no sentences, thus no `.` at the end (on many other places, too). If we say they are sentences, they it should start with upper case `[T]he TopicPartition`
We shouldn't use `<br>`; instead, use a `<pre>` section around the lines.
We do expect RemoteStorageManager to have strong consistency on the data. We only relax the requirements on metadata consistency. So, it would be useful to make this clear.
Nit: remove unnecessary blank.
These should be `<pre>` rather than `<code>`. The latter is more for phrases, not blocks, and loses all indentation and line breaks within a block of code. Then you can get rid of the `<br>` tags.
Can we change the naming to use `ALL_CAPS`? For example, compare with the definition of `RemotePartitionDeleteState` in this PR.
Good point, but it could be clearer. This implementation can be used in production, but the `PropertyFileLoginModule` that also ships with this reference implementation should NOT be used in production.
half the shards? please update
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
Makes sense @ewencp, not sure how I missed that sentence when I read it originally.
request "got" re-sent to the control
and -> a
and -> a
This overload does not take `Materialized` parameter
base -> based progress -> progressed
as above (more often below -- please fit all)
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
hopefully the `System.nanoTime` goes away once you merge master in.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
something is wrong in this sentence :)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
`KeyValueStore` -> `TimestampedKeyValueStore`
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
as above (more often below -- please fit all)
request "got" re-sent to the control
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
This overload does not take `Materialized` parameter
an -> a
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
maybe just `esVersion()`
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
one assert per member is better then you see what's not null :0
why use `topicName` here? Should it not be `failed: key=X actual=A expected=B...` instead of `failed: key=X <topicName>=A expected=B...`
`consumerProps` and `producerProps` are of type `Map`, therefore the `.toString()` is probably not readable. So you'd need to convert these into a comma-separated list sth like `K1=V1,K2=V2,...Kn=Vn`.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
maybe `Objects.equal` could make it easier to read
That seems to be pretty harsh. If I have a huge shard and this shard has one small file that is corrupted, that will add "corrupted_" prefix to all files and then replicate all files from another shard (including files that were perfectly fine locally).
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
maybe just `esVersion()`
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
one assert per member is better then you see what's not null :0
why use `topicName` here? Should it not be `failed: key=X actual=A expected=B...` instead of `failed: key=X <topicName>=A expected=B...`
`consumerProps` and `producerProps` are of type `Map`, therefore the `.toString()` is probably not readable. So you'd need to convert these into a comma-separated list sth like `K1=V1,K2=V2,...Kn=Vn`.
should probably remove the `get` prefix and use `optionValue` since that is the convention followed in the Kafka codebase. Lots of other occurrences like this.
maybe `Objects.equal` could make it easier to read
That seems to be pretty harsh. If I have a huge shard and this shard has one small file that is corrupted, that will add "corrupted_" prefix to all files and then replicate all files from another shard (including files that were perfectly fine locally).
Nit: we don't normally use exclamation marks in Kafka log messages.
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
It's intentional to avoid build warnings about importing deprecated classes.
What is the reasoning for not throwing an exception if the condition is not met after the timeout? That would make the tests more concise.
recommended; ditto below.
We should wait for the new stream thread with a timeout, otherwise we risk that this test may become flaky.
nit: {@link KafkaClientSupplier}
request "got" re-sent to the control
Consider adding some small back-off time (say 100 millis) to avoid busy looping and possible log polluting.
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Nit: we don't normally use exclamation marks in Kafka log messages.
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
It's intentional to avoid build warnings about importing deprecated classes.
What is the reasoning for not throwing an exception if the condition is not met after the timeout? That would make the tests more concise.
recommended; ditto below.
We should wait for the new stream thread with a timeout, otherwise we risk that this test may become flaky.
nit: {@link KafkaClientSupplier}
request "got" re-sent to the control
Consider adding some small back-off time (say 100 millis) to avoid busy looping and possible log polluting.
Can we also assert that the state gets to `RUNNING` after the new thread has joined
params are not nullable any more - please make sure this doesn't revive it.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
got it thank you.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
look into `StreamInput#readMap`
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
the node where the shard should move to
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
must be param prefixes now
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
I _think_ you could just pull the `PositionLengthAttribute` and if it has a value greater than 1 on any token, it is a graph.
> Ok this doesn't work because the standard synonym token filter also sets the position length attribute Arrrrgh, you are right. Here's maybe another idea: why not always treat things as if they were a graph,since a single linear chain of tokens really is just a graph. And then, when the graph enumerates to just one path, it should naturally "become" what already happens today? I.e. don't break out any special treatment for "graph" vs "not graph".
This overload does not take `Materialized` parameter
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
and -> a
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
and -> a
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Considering that we may have multiple `WebServiceMessageSender`, I don't think we should expose this method here. You can provide a configured `WebServiceMessageSender`, this feels weird to me that all of them are reconfigured behind the scenes.
This should be the last step
`limitedTo(long bytes)`? Clone is kinda non-specific.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
good catch on delta > 0
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Does this really need to be generic? We certainly don't care about any of that on the consumption side.
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
I think we should call `deserializer.configure(...)` here
I think we should call `deserializer.close()` here
We should use try-with-resources here (for `DataInputStream`).
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
This may indicate a bug in `SessionWindowedDeserializer`
That class is different because it doesn't actually `define` the config, it's just an undeclared "extra" config that gets passed around to be interpreted inside the serde. Actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.
As mentioned on the KIP discussion, `BytesDeserializer` should not be included.
We should use try-with-resources here (for `DataInputStream`).
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
I think we should call `deserializer.close()` here
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
docCount is a a long so it's totally fine, sorry.
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
Yeah, less classes is much better
super minor, but indentation is off here
We should use try-with-resources here (for `DataInputStream`).
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
I think we should call `deserializer.close()` here
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
super minor, but indentation is off here
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
We should use try-with-resources here (for `DataInputStream`).
I think we should call `deserializer.close()` here
hehe :) nice one
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
All the methods above should go away please. There is really no need to start with something that complex/complete. The purpose of the enhancement is to have a data type to represent a "data size" for binding purposes.
Yeah, less classes is much better
super minor, but indentation is off here
We should use try-with-resources here (for `DataInputStream`).
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
I think we should call `deserializer.close()` here
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
Yeah, less classes is much better
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
last parameter can be set to from.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
That while loop is too complicated (any `while(true)` should be avoided whenever is possible). Can we put all of these conditions under a `hasReadBudget` and have the while be something like ``` while(hasReadBudget() && lastRequestedSeqNo < leaderGlobalCheckpoint) { numCurrentReads++; long from = lastRequestSeqNo + 1; lastRequestSetNo = Math.min(from + size, leaderGlobalCheckpoint) sendShardChangesRequest(from, size) } ```
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
I wonder if we should use an ArrayList with initial capacity. We can then change the request etc to use List<> instead of array
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
You don't need this anymore, this method always run with a single registered type.
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
Generate the type and write it out to the internal state.
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
this way we only test against non existing types, I think it would be worth to test against types that we have. Have a lok at what we do in IdsQueryBuilderTest#doCreateTestQueryBuilder for instance
These 3 tests are actually one test. It should be parametrized rather than copy-pasted.
It's a standard practice to use separate args for different params. Also, autogenerated param ids aren't very readable when they are complex so in such cases it's better to assign them meaningful names (they are displayed in the pytest report): ```suggestion @pytest.mark.parametrize( ('returned_items_count', 'patched_dc_stdout'), ( (3, (DOCKER_OUTPUT_MULTIPLE, '')), (2, (PODMAN_OUTPUT, '')), (0, ('', '')), ), ids=('docker JSONL', 'podman JSON sequence', 'empty output'), ) def test_docker_images(docker_images, mocker, returned_items_count, patched_dc_stdout): mocker.patch( 'ansible_test._internal.docker_util.docker_command', return_value=patched_dc_stdout) ret = docker_images('', 'quay.io/ansible/centos7-test-container') assert len(ret) == returned_items_count ```
+1. I passed an engine searcher directly.
Oh, I think I see why, it's for closing. I think it's still to pass in a search and close it on exception as you did now.
Maybe consider JUnit Parameters here, but fine as is. EDIT: Thinking some more about this, I'd leave it as is.
nit: can remove type arguments
Also set the store name in this test.
line too long
We should use `to()` and use a `TestOutputTopic` instead of the processor
Line too long (also some lines above and further below)
Just see the test from below with "many windows" -- I think we can merge them into one test
There are two input streams in this test, and thus we should create a second `TestInputTopic` to pipe input via both.
Just see the `timeWindowMixAggregatorsTest` below -- seems it's a super set of this test and hence, having the second one only seems to be sufficient.
This seems to be the same program as in the test above -- if yes, I think we should merge both tests into one.
super minor, but indentation is off here
Maybe this was already covered somewhere, but is `GENERIC` the right threadpool for this? (I don't have a better suggestion, just asking)
This TODO should be removed
Not sure what EE is here.
nit: I would rather use the full name instead of using acronyms.
hehe :) nice one
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
This TODO should be removed
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
the naming used above seems better here ```suggestion Throwable exception = null; ```
nit: We could omit `res` and return directly in the two places below.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
these ElasticsaerchExceptions are bogus remove them
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
I think it would be better to make this a static factory method and keep the constructor for the case where we receive `FetchResponseData`.
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
nit: o2[%s] was **equal** to o1[%s]
base -> based progress -> progressed
`o1 +=8;` <== format this file again :)
and -> a
I think that we can do without this flag, it could be a util method that returns a boolean depending on whether values are set or lookup details are.
and -> a
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I think you use it indirectly through `parser. isBooleanValueLenient`.
I think we can drop the benchmark.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
We should read the metadata inside the while loop since it could change.
I was going to ask why we're using the `test` prefix for a benchmark, but then I realized that many of the kafka benchmarks do that and I somehow didn't notice. :) Given that, it seems fine to leave it like this for now.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It will good to clear the requests and test when empty as well.
the ```length``` is neglected
AclAuthorizer is not a public class, so it may be ok to make this class public in AclAuthorizer instead of duplicating it here.
I think this can move to before the threads start - will be nastier
I think we can drop the benchmark.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
We should read the metadata inside the while loop since it could change.
I was going to ask why we're using the `test` prefix for a benchmark, but then I realized that many of the kafka benchmarks do that and I somehow didn't notice. :) Given that, it seems fine to leave it like this for now.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It will good to clear the requests and test when empty as well.
the ```length``` is neglected
AclAuthorizer is not a public class, so it may be ok to make this class public in AclAuthorizer instead of duplicating it here.
I think this can move to before the threads start - will be nastier
I think we can drop the benchmark.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
We should read the metadata inside the while loop since it could change.
I was going to ask why we're using the `test` prefix for a benchmark, but then I realized that many of the kafka benchmarks do that and I somehow didn't notice. :) Given that, it seems fine to leave it like this for now.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It will good to clear the requests and test when empty as well.
the ```length``` is neglected
AclAuthorizer is not a public class, so it may be ok to make this class public in AclAuthorizer instead of duplicating it here.
I think this can move to before the threads start - will be nastier
Nit: missing `@Override`
We don't use `@Nullable` in Spring Boot yet and I am not keen to introduce it at this point. This `print` method should go away in benefit of `toString`
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
This should also go away.
This should be the last step
I haven't looked in detail but I am wondering why you need to resort to reflection for a builder pattern that should "just" do what the regular template can do. Perhaps this feature should be removed in benefit from something more advanced? I don't like the idea to use reflection in production code.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
This overload does not take `Materialized` parameter
as above (more often below -- please fit all)
I stand by what i said, but I'll leave it up to you. It isn't a deal breaker for me!
I think this should be four different tests. One for each of the methods you are testing. I probably said this before, but it is much nicer if you can just read the test names to understand what should/shouldn't be happening
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
Might be nice to have quite a few of these tests that verify various values are invalid and valid, to act as regression tests.
Basically yes. I would extend the composite test with multiple occurrences of each case so that we also cover the scenario where we have -- for example -- n active running task, m active non-running tasks, k standby tasks etc. If this makes the test too clumsy, you could cover each of n active running task, m active non-running tasks, k standby tasks etc in its own test and make one composite test with one occurrence of each case. Choose what is better readable. My point is, that the current test does not cover multiple occurrences of the same case.
nit: insert empty line
`listStore.all()` will return a `KeyValueIterator`, which should be explicitly closed. I think we can re-use the iterator below this line, which is closed at the end.
This particular test doesn't make sense any more, since there is no "old" assignor type now that PartitionAssignor is removed
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
Also set the store name in this test.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
nit: new line
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
got it thank you.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
Yes. I meant to say `ElectionState` instead of `LeaderState`. `ElectionState` has a field called `votedIdOpt` for which `equals` checks for equality. This is not strictly required for having a "consistent" leader. I think for having a consistent leader for an epoch, only the `epoch` and `leaderIdOpt` need to match for all of the replicas.
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
nit: new line
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
got it thank you.
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
Yes. I meant to say `ElectionState` instead of `LeaderState`. `ElectionState` has a field called `votedIdOpt` for which `equals` checks for equality. This is not strictly required for having a "consistent" leader. I think for having a consistent leader for an epoch, only the `epoch` and `leaderIdOpt` need to match for all of the replicas.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
nit: new line
cancel that :) I figured it out.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
got it thank you.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
Yes. I meant to say `ElectionState` instead of `LeaderState`. `ElectionState` has a field called `votedIdOpt` for which `equals` checks for equality. This is not strictly required for having a "consistent" leader. I think for having a consistent leader for an epoch, only the `epoch` and `leaderIdOpt` need to match for all of the replicas.
cancel that :) I figured it out.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
nit: new line
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
got it thank you.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
Yes. I meant to say `ElectionState` instead of `LeaderState`. `ElectionState` has a field called `votedIdOpt` for which `equals` checks for equality. This is not strictly required for having a "consistent" leader. I think for having a consistent leader for an epoch, only the `epoch` and `leaderIdOpt` need to match for all of the replicas.
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
nit: new line
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
cancel that :) I figured it out.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
got it thank you.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
Hmm. I was looking at the implementation for `hasConsistentLeader`. It checks that all of the `LeaderState` match. Which means that all of the replicas need to vote for the same leader. This is not strictly required for having a consistent leader. Maybe this works in this test because the number of voters is 3 and one of the nodes was killed.
Yes. I meant to say `ElectionState` instead of `LeaderState`. `ElectionState` has a field called `votedIdOpt` for which `equals` checks for equality. This is not strictly required for having a "consistent" leader. I think for having a consistent leader for an epoch, only the `epoch` and `leaderIdOpt` need to match for all of the replicas.
Got it. I missed that `votedIdOpt` is set to `empty` by the leader and the followers.
could be a instance variable, as used in all tests
Second parameter should be `serverConfigs`
nit: add `final` (same below)
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
could be shorted using `com.google.common.io.Files.write`
Maybe we could use a different value here.
Ok, I'm convinced :) Thanks for clearing up my confusion.
I see. But even though the number gets incremented after each test method, the string `inputTopic` is already fixed when the class is constructed, so it won't automatically get incremented. I think you need to make this a method to achieve the effect you intended.
Not sure what the intent is here, to increment the number between each test, or between each instance of this integration test class within the JVM... It actually does the latter.
These three fields should be final as well.
by no means a blocker (especially given public interfaces relying on this same problem), but i would not be opposed to making internal APIs not rely on these booleans -- clear enums, with properly handled default cases (presumably throwing exceptions) would be better. we tend to let things like this leak into internal (and subsequently external) APIs, but I think it is probably always a mistake -- unclear from the caller standpoint and not extensible.
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
Actually I think it works: http://www.slf4j.org/faq.html#paramException.
Code convention nitpick: there should be a space before the colon.
and -> a
base -> based progress -> progressed
and -> a
```suggestion * is {@code null}, no records are emitted. ``` Please also fix this on the original method
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
```suggestion * {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
nit: I would rather use the full name instead of using acronyms.
Not sure what EE is here.
This TODO should be removed
It seems like we do it for a couple of cases. It doesn't seem worth it given that fetch is one of the hot paths. We could have static helper methods instead if helpful.
nit: We could omit `res` and return directly in the two places below.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
maybe `== false` just so we don't typo it in the future
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
```suggestion left.join( right, (value1, value2) -> value1 + value2, joinWindows, streamJoined ); ```
same as above for parameters
This should return `-1` as old `BadValueTransformer`
nit: add `final`
nit: add `final`
Are these methods the sam as in the class above? If so consider refactoring so we only have them once
Might be nice to rewrite this using `assertThrows` ? (Similar below.)
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
I think it'd be nice to remove this second ctor so we're explicit every time.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
Not 100% sure -- but we need tests for this cases. The `configure()` code is untested atm
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
`<byte[]>` this explicit type is unnecessary
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
base -> based progress -> progressed
and -> a
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
and -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
method name changes
nit: may worth explain how `queryableStoreName` can be find from `materialized` below.
request "got" re-sent to the control
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
This overload does not take `Materialized` parameter
base -> based progress -> progressed
and -> a
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
and -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
method name changes
nit: may worth explain how `queryableStoreName` can be find from `materialized` below.
request "got" re-sent to the control
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
This overload does not take `Materialized` parameter
I think the intended method to call would be ``` Thread.currentThread().interrupt() ``` Same with line 258 below.
Ah, you are right. Sorry.
nit: "so we assume"...
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
We are using the creation time of the batch to check for expiration. That will tend to expire some records which were added to the batch after creation earlier than the delivery timeout (by as much as linger.ms). Alternatively, we could use the time that the batch was closed, which will tend to expire records later than the delivery timeout (by as much as linger.ms), but maybe expiring late is bit safer than expiring early? This is equivalent to saying that the delivery timeout excludes linger time.
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
I think the answer to this question is that it is possible to expire while the batch is still being built because closing the batch can be arbitrarily delayed by inflight fetches.
request "got" re-sent to the control
How about `completeExpiration` or `expirationDone`? Also, do you think we should add safeguards to ensure that the batch can't be completed more than once? Maybe at least we can add an assertion that `expiryErrorMessage` is null in `RecordBatch.done`.
nit (sorry): seems ungrammatical when the error message is appended. How about this? ``` "Expiring " + recordCount + " record(s) for " + topicPartition + ": " + expiryErrorMessage) ```
this one is not used - can we remove it until we cat over to the paths API
same typo - copy paste probably
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
.jva -> .java
To be clear, I was referring to both `globalCheckpoint` and `docId`.
Earlier we discussed sending the task spec on the process' standard input. Did you decide not to do this? It seems like using a command-line option will be pretty awkward...
can we open an issue/track it somewhere that these should be evaluated
also, please make a note to make this configurable.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
request "got" re-sent to the control
an -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
`while` seems to be missing
as above (more often below -- please fit all)
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
This overload does not take `Materialized` parameter
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
Makes sense @ewencp, not sure how I missed that sentence when I read it originally.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
request "got" re-sent to the control
an -> a
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
`while` seems to be missing
as above (more often below -- please fit all)
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
This overload does not take `Materialized` parameter
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
Makes sense @ewencp, not sure how I missed that sentence when I read it originally.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
"If no selection operation is currently in progress then the next invocation of one of these methods will return immediately unless the selectNow() method is invoked in the meantime." I read that to mean that that `poll(Long.MAX_VALUE)` will not return immediately since a `selectNow` was invoked in the meantime . Might be worth a unit test to verify that it works as expected.
I'm wondering if we also need to delay the call to `client.wakeup()`? For example, consider the following sequence: 1. disableWakeups() 2. wakeup() 3. poll(0) 4. enableWakeup() 5. poll(Long.MAX_VALUE) The underlying wakeup on Selector would effect the `poll(0)`, but we would suppress the exception. Then there would be nothing to wake us up from the `poll(Long.MAX_VALUE)`.
As we catch the exception we should swallow is and don't expect it
It would be good to have some assertions.
Thanks. I should have linked to the relevant code earlier. It is the following: https://github.com/spring-projects/spring-boot/blob/16111f126e707fb5064bab6150df7a77f54850ee/spring-boot-project/spring-boot-tools/spring-boot-gradle-plugin/src/main/java/org/springframework/boot/gradle/tasks/bundling/BootJar.java#L113-L119 This will result in a `NOTICE.txt` and `LICENSE.txt` file beneath each project's `build` directory. An alternative could be to access the files in `buildSrc/src/main/resources` directly from the filesystem.
I think this'll break up-to-date checking for the jar. Creating a text resource from a string results in the creation of a temporary file with a random name. As that random name varies from build-to-build, the jar tasks will never be considered up-to-date as it'll look like its inputs have changed. We had this problem when adding the classpath index support to `BootJar`. The solution was to get the text resource's file and rename it before adding it to the copy spec rather than as part of the spec.
`ConsumerRecordFactory` is deprecated via KIP-470 (merge recently) -- please update the code to use `TestInputTopic` -- we cannot merge as-is, because the build would fail if we use deprecated classes.
If this test passes then this assertion isn't quite right as `TomcatContextCustomizerConfiguration` doesn't define a `TomcatContextCustomizer`. The assertions needs to be written such that if you remove `.withUserConfiguration(TomcatContextCustomizerConfiguration.class)` the test will fail.
remove try-catch and replace with: ``` final StreamsException s = assertThrows(StreamsException.class, () -> testDriver.pipeInput(consumerRecord)); ``` assert afterwards and don't re-throw.
rewrite test as above using `assertThrows()`.
I believe the goal is to use constant-time comparison to prevent timing attacks, hence the walk through the arrays.
nit: remove empty line
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
records to it, and reading all records from it, such that
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
base -> based progress -> progressed
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
and -> a
and -> a
```suggestion * {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
and -> a
base -> based progress -> progressed
and -> a
nit: `punctuate each second` (might be c&p error and affect other places, too) -- maybe better to address in separate PR (the `void punctuate()` issue and this can be one PR IMHO).
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
nit: remove empty link
```suggestion * {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
as above (more often below -- please fit all)
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
This overload does not take `Materialized` parameter
base -> based progress -> progressed
and -> a
nit: `punctuate each second` (might be c&p error and affect other places, too) -- maybe better to address in separate PR (the `void punctuate()` issue and this can be one PR IMHO).
and -> a
nit: remove empty link
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
```suggestion * {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
as above (more often below -- please fit all)
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
This overload does not take `Materialized` parameter
nit: I don't think there's any reason to mention this. Unexpected errors fall under `KafkaException`, which is listed below.
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
imho having `hasUnassigned` and `hasUnassignedShards` methods is very confusing.
can this executor? name is what we often give the tasks..
nit: 'else' can be dropped
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
this is much better!! ð
Might be worth adding a null check here for `groupMetadata`. Another simple validation is ensuring that if `generationId > 0`, then `memberId` should be non-empty.
We can give a clear message saying null is not supported. If it's an NPE somewhere down the stack then the user doesn't know if it's a bug or not.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
> If set it to `MAX_VALUE` or something and it goes wrong the stats will be extremely off and hard to recover. Well, it would only be when assertions are enabled. > Felt like an overkill. Okay.
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Do we need to shutdown the dead stream thread? `completeShutDown()` will be called anyways.
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
maybe we can try to log the stacktrace in a try-finally block in hopes that we can get the full stacktrace? In the finally we can throw the Error
If this checks out, then I think we actually don't need to track this variable.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
> If set it to `MAX_VALUE` or something and it goes wrong the stats will be extremely off and hard to recover. Well, it would only be when assertions are enabled. > Felt like an overkill. Okay.
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Do we need to shutdown the dead stream thread? `completeShutDown()` will be called anyways.
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
maybe we can try to log the stacktrace in a try-finally block in hopes that we can get the full stacktrace? In the finally we can throw the Error
If this checks out, then I think we actually don't need to track this variable.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
> If set it to `MAX_VALUE` or something and it goes wrong the stats will be extremely off and hard to recover. Well, it would only be when assertions are enabled. > Felt like an overkill. Okay.
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Do we need to shutdown the dead stream thread? `completeShutDown()` will be called anyways.
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
maybe we can try to log the stacktrace in a try-finally block in hopes that we can get the full stacktrace? In the finally we can throw the Error
If this checks out, then I think we actually don't need to track this variable.
Capitalize 't' Also, died _due_ to
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
I think it would be cleaner to extract this code to a separate method.
> If set it to `MAX_VALUE` or something and it goes wrong the stats will be extremely off and hard to recover. Well, it would only be when assertions are enabled. > Felt like an overkill. Okay.
seems dangerous to use the thread name to check ownership. might be safer to check reference equality on `Thread`
Should we use "NO_CURRENT_THREAD" to replace "null"? It seems to me "NO_CURRENT_THREAD" is more readable.
Do we need to shutdown the dead stream thread? `completeShutDown()` will be called anyways.
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
maybe we can try to log the stacktrace in a try-finally block in hopes that we can get the full stacktrace? In the finally we can throw the Error
If this checks out, then I think we actually don't need to track this variable.
you can do some streaming java8 magic here.
This sucks.. I want to see how big of a deal it is to keep things as they were. Indeed snapshotting a commit will keep it's translog around but I'm not sure anymore it's worth this kind of wrapping layers. Maybe we should invest in faster clean up on those snapshotted commits. I'll reach out to discuss.
same here as what i said below. You can use a `assertThat`
don't drink and code ð» (same line twice)
typo in the method name here too
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
Why do you remove this check? A `TimeWindow` should not allow this case.
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
nit: new line
two calls to createWorkerTask
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
same as above for parameters
it is preferable to have descriptive test names, i.e., `emptyIteratorAlwaysReturnsFalse` `emptyIteratorPeekNextKeyShouldThrowNoSuchElementException` etc
We actually don't need to name the store. This could be `.count()` plus updating the name for the repartitioning and changelog topic.
I understand your point -- however, naming must be deterministic and should not change from release to release (otherwise, upgrading hard harder and we need to mention it in the upgrade docs). Thus, if we use internal names in tests, we have some implicit testing that naming does not change. That's why I prefer to not name the operator, too, if not required.
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
Sorry for the forth and back -- for `assertThat` you original code was correct and expected argument is second one... (it different for `assertEquals` -- my bad(!)).
Nit: `assertThat` take expected result as first parameter IIRC (otherwise error message on failing test is "reversed")
nit: not a big deal here, but for unit tests I think given the very low overhead it is better to separate out each of the cases into their own test as it can help make it more quickly obvious if issues are with a specific case or if it affects multiple cases.
