Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
We cannot change the signature of a protected method since someone may be overriding it.
just beware that Long.compare is Java 1.7 only, you might want to use Longs.compare from Guava instead when merging to 1.x
`Count(..., distinct=True)` is already tested in `test_count()` and it is not related with this patch, so we can refactor tests but in a separate commit, e.g. - 1st commit: _"Moved test for distinct Count() to a separate test case."_: ```diff diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py index ea11c02edc..2f667a0fe1 100644 --- a/tests/aggregation/tests.py +++ b/tests/aggregation/tests.py @@ -388,9 +388,6 @@ class AggregateTestCase(TestCase): vals = Book.objects.aggregate(Count("rating")) self.assertEqual(vals, {"rating__count": 6}) - vals = Book.objects.aggregate(Count("rating", distinct=True)) - self.assertEqual(vals, {"rating__count": 4}) - def test_count_star(self): with self.assertNumQueries(1) as ctx: Book.objects.aggregate(n=Count("*")) @@ -403,6 +400,10 @@ class AggregateTestCase(TestCase): ) self.assertEqual(aggs['distinct_ratings'], 4) + def test_distinct_on_aggregate(self): + books = Book.objects.aggregate(Count('rating', distinct=True)) + self.assertEqual(books, {'rating__count': 4}) + def test_non_grouped_annotation_not_in_group_by(self): """ An annotation not included in values() before an aggregate should be ``` - 2nd commit, fix and extra test cases (with `self.subTest`), e.g. ```python def test_distinct_on_aggregate(self): for aggregate, expected_result in ( (Count, 4), (Sum, 16.5), (Avg, 4.125), ): with self.subTest(aggregate=aggregate): books = Book.objects.aggregate(ratings=aggregate('rating', distinct=True)) self.assertEqual(books['ratings'], expected_result) ``` Also, I think that `Book.rating` would be better for testing `distinct` argument.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
I would make the class `final`, and these members `public final`
Maybe change to `AtomicLong`? Took me awhile to get it :thought_balloon:
I would make the class `final`, and these members `public final`
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
Change "param required" to "parameters are required"
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
Can we fold this into `writeTo` and add a boolean to the signature (maybe `includeRequestHeaders`)? It seems like it just requires adding a if/else block
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
I think the unlock calls should always be in a finally block
Can we fold this into `writeTo` and add a boolean to the signature (maybe `includeRequestHeaders`)? It seems like it just requires adding a if/else block
This also seems like the kind of leniency that we'd want to remove in the future.
you can do some streaming java8 magic here.
you can do some streaming java8 magic here.
you can do some streaming java8 magic here.
you can do some streaming java8 magic here.
you can do some streaming java8 magic here.
you can do some streaming java8 magic here.
you can do some streaming java8 magic here.
you can do some streaming java8 magic here.
the @Test annotation is unnecessary
you can do some streaming java8 magic here.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
> I guess the behaviour of the field informs what the widget/form render? Yes.
> I guess the behaviour of the field informs what the widget/form render? Yes.
> I guess the behaviour of the field informs what the widget/form render? Yes.
Do we want to be exposing more java.util.regex stuff? We've been trying to be careful with that package. Is there a version of this that take Lucene's regexes? You can limit the time and space complexity of those....
change `duration` to `period`
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
Works for me. Maybe just have an interface called Cancellable - it seems CancellableTask is taken.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Works for me. Maybe just have an interface called Cancellable - it seems CancellableTask is taken.
Works for me. Maybe just have an interface called Cancellable - it seems CancellableTask is taken.
I think this should have a `continue;` after it for the sake of completeness, otherwise it's possible that it will be added to both the valid and invalid lists (it'll still fail the parsing, but to prevent future bugs)
Do we want to be exposing more java.util.regex stuff? We've been trying to be careful with that package. Is there a version of this that take Lucene's regexes? You can limit the time and space complexity of those....
Do we want to be exposing more java.util.regex stuff? We've been trying to be careful with that package. Is there a version of this that take Lucene's regexes? You can limit the time and space complexity of those....
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
Do we want to be exposing more java.util.regex stuff? We've been trying to be careful with that package. Is there a version of this that take Lucene's regexes? You can limit the time and space complexity of those....
Do we want to be exposing more java.util.regex stuff? We've been trying to be careful with that package. Is there a version of this that take Lucene's regexes? You can limit the time and space complexity of those....
nit: space between `if` and `(`
We don't need any of these `build*Properties()` methods; all the kafka specific properties are already handled by parts of `KafkaProperties`.
super nit: I tend to like validation to be first
super nit: I tend to like validation to be first
Yes, that is what I meant.
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
Same here... we don't really need `String[] addresses`
good catch on delta > 0
This sucks.. I want to see how big of a deal it is to keep things as they were. Indeed snapshotting a commit will keep it's translog around but I'm not sure anymore it's worth this kind of wrapping layers. Maybe we should invest in faster clean up on those snapshotted commits. I'll reach out to discuss.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
ok...but client depends on the transport service anyway no? I think I don't get it
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
`describe` and `get` methods are almost the same: a refactor is possible.
ok...but client depends on the transport service anyway no? I think I don't get it
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
It should not be removed because `module.params['executable'] or module.get_bin_path(...)` is used.
Would be removed if `get_bin_path` used.
It should not be removed because `module.params['executable'] or module.get_bin_path(...)` is used.
Add a `# Arguments` section to the docstring.
I think we have a problem here. The version that is supposed to be supplied as a parameter should only consist of major.minor version like `2.0` (so that all 2.x version go into the same repository) - this one is `2.0.0-beta1` though.
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
Don't you simply want an `else:` here? Or do you explicitly want to have the case that you call `self._has_migs(local)` twice in a row (without a sleep inbetween), and once it returns `False` and then `True`? Otherwise this `elif` makes no sense.
Don't you simply want an `else:` here? Or do you explicitly want to have the case that you call `self._has_migs(local)` twice in a row (without a sleep inbetween), and once it returns `False` and then `True`? Otherwise this `elif` makes no sense.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This should be done in reset()
I wonder if we should void this check if indexUUID or that.indexUUID is IndexMetaData#INDEX_UUID_NA_VALUE . We can still run into this value when reading existing state files.
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
Oh I see. I like it better the current way better then. I was confused by the fact that you could have both ALWAYS and PARTIAL in the same doc, maybe we could add an assertion that it never happers.
Please remove the unnecessary trailing comma and space.
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Some more candidates for `ESTestCase#randomValueOtherThan` here.
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
Or use [`Math.toIntExact`](https://docs.oracle.com/javase/8/docs/api/java/lang/Math.html#toIntExact-long-) on `writtenBytes - checksumPosition` and do away with the extra `if` and `else` (less lines of code)? ``` int index = Math.toIntExact(writtenBytes - checksumPosition); footerChecksum[index] = b; ```
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
I wasn't entirely sure either but good to know! :)
I wasn't entirely sure either but good to know! :)
Or use [`Math.toIntExact`](https://docs.oracle.com/javase/8/docs/api/java/lang/Math.html#toIntExact-long-) on `writtenBytes - checksumPosition` and do away with the extra `if` and `else` (less lines of code)? ``` int index = Math.toIntExact(writtenBytes - checksumPosition); footerChecksum[index] = b; ```
Sorry I had missed that
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
maybe just `esVersion()`
This should be done in reset()
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
I wonder if we should void this check if indexUUID or that.indexUUID is IndexMetaData#INDEX_UUID_NA_VALUE . We can still run into this value when reading existing state files.
can we just change this to System.getProperty("tests.seed") != null? Then that method can be removed.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
What about using a ConstructingObjectParser? You get the arguments and then can just return an ExpressionRoleMapping instead of the builder.
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
maybe just `esVersion()`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
This should only be done in close()
maybe just use `IOUtils` here they handle null values as well
maybe just use `IOUtils` here they handle null values as well
This should only be done in close()
maybe just use `IOUtils` here they handle null values as well
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
remove the super call
annoying :) I'd be nice if we could share it somehow
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
URL should never used IMO you should always use URI. Generally, if the URL describes both the location and name of a resource, the term to use is URI. URI also doesn't take care of encoding of the characters which might come in handy if there are spaces in the path etc. Yet unless you need to have a URL I'd always use URI (ie. if you need to have support for credentials which I'd discourage anyways here)
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
oh oh I hadn't read your reply when I replied ;)
Can we also clear the temp `charBytes` array, something on the lines of: ``` final byte[] charBytes = CharArrays.toUtf8Bytes(password); try { return builder.startObject() .field("password").utf8Value(charBytes, 0, charBytes.length) .endObject(); } finally { Arrays.fill(charBytes, '\u0000'); } ```
maybe just `esVersion()`
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
oh oh I hadn't read your reply when I replied ;)
Do we want to be exposing more java.util.regex stuff? We've been trying to be careful with that package. Is there a version of this that take Lucene's regexes? You can limit the time and space complexity of those....
Do we want to be exposing more java.util.regex stuff? We've been trying to be careful with that package. Is there a version of this that take Lucene's regexes? You can limit the time and space complexity of those....
+1 then we shouldn't forget about it :)
can we have a shorter name here maybe `forceReadFromFileChannel`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
randomInt cannot be within the loop, otherwise it changes at every iteration...
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
randomInt cannot be within the loop, otherwise it changes at every iteration...
yea I was looking at the stacktrace and wondering what is important in there, not sure.
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
I'm doing buffer now and they all emit buffered data in case of onError.
Small typo here: Guage -> Gauge.
This changes behaviour as any exception from the `close()` call will no longer be caught and logged as a warning.
Yeah, I guess I'm thinking of people deploying without static IPs (certainly not recommended). These most likely won't suffer the same problems that this solution helps though, so it may be a moot point altogether.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
make `Boolean` and only serialize when not null
You might want to use `type=ip_network` (then add from `ansible.module_utils.compat.ipaddress import ip_network`) for `ip_range`, in order to validate the value before using it. (value of `type` parameter can be a callback).
You should catch the error twice to produce an error message suitable for each query
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
It seems nothing is done when `check_mode` is enabled.
It seems nothing is done when `check_mode` is enabled.
Please import only what you need, rather than `*`
`force` parameter: use boolean type
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
last `%version` should be `%major_minor_version`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think we should leave this method for java api bw comp
I think we should leave this method for java api bw comp
`o1 +=8;` <== format this file again :)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I don't think that complexity is warranted. Just keep constructor injection please.
I don't think that complexity is warranted. Just keep constructor injection please.
I don't think that complexity is warranted. Just keep constructor injection please.
This has the same issue where multiple threads could wind up âfinishingâ this since done is not rechecked within the synchronized block.
@rjernst can you fix this ^^
why do we need two of these? can't we have just markShardCopyAsStaleIfNeeded? we can rename `markUnavailableShardsAsStale` to `markUnavailableShardsAsStaleIfNeeded`
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
oh yeah I missed that :/
oh yeah I missed that :/
oh yeah I missed that :/
oh yeah I missed that :/
Yes, pass the value as a json string.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
@thomwiggers `line.partition(':')[2]` yes, I have no problem with that.
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
@thomwiggers `line.partition(':')[2]` yes, I have no problem with that.
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
s/y ou/you Also I think upfront is one word.
s/y ou/you Also I think upfront is one word.
s/y ou/you Also I think upfront is one word.
s/y ou/you Also I think upfront is one word.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
My idea was to make the BulkRequestSource hold what it has to hold (the failed items), be able to retrieve them and act accordingly from processBulkIndexRequest, rather than have logic to deal with failures within the BulkRequestSource itself. Exposing different getters might help as well, that's another option. I tend to think that extracting the "processing" part would make things cleaner but I may be wrong.
s/y ou/you Also I think upfront is one word.
I'd rather chose a common unit here instead of converting to nanos. ``` java TimeUnit common = initialDelayUnit.compareTo(periodUnit) < 0 ? initialDelayUnit : periodUnit; final long initial = common.convert(initialDelay, initialDelayUnit); final long period = common.convert(period, periodUnit); ```
I'd rather chose a common unit here instead of converting to nanos. ``` java TimeUnit common = initialDelayUnit.compareTo(periodUnit) < 0 ? initialDelayUnit : periodUnit; final long initial = common.convert(initialDelay, initialDelayUnit); final long period = common.convert(period, periodUnit); ```
I'd rather chose a common unit here instead of converting to nanos. ``` java TimeUnit common = initialDelayUnit.compareTo(periodUnit) < 0 ? initialDelayUnit : periodUnit; final long initial = common.convert(initialDelay, initialDelayUnit); final long period = common.convert(period, periodUnit); ```
s/y ou/you Also I think upfront is one word.
I'd rather chose a common unit here instead of converting to nanos. ``` java TimeUnit common = initialDelayUnit.compareTo(periodUnit) < 0 ? initialDelayUnit : periodUnit; final long initial = common.convert(initialDelay, initialDelayUnit); final long period = common.convert(period, periodUnit); ```
also this class should be final.
also this class should be final.
oh nevermind - I see why ð
that's just a suggestion, I tend to do thsi this way: ```Java Runnable toRelease = () -> {}; //... semaphore.acquire(); toRelease = semaphore:release ``` that way you don't need to check any boolean logic and can just call the runnable
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
Nit: `numConnection` -> `numConnections`.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Ok, sounds fine.
nit: extra line
or just: "return ok;"? :)
or just: "return ok;"? :)
why not native boolean type instead of Boolean object? Also, we use the package names as prefix for modules settings, so I would go with `plugins.isolation` compared to `plugin.isolation`.
It seems nothing is done when `check_mode` is enabled.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
maybe `== false` just so we don't typo it in the future
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
Since these tests are so fast + simple, maybe we could just test both methods every time. I don't think this will be much extra code, as you could re-use the same `FakeRestRequest.Builder`.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
`of the it's last` -> `of its last`
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
Let's make this an `UncheckedIOException` too.
same note as in the json processor PR.
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
look into `StreamInput#readMap`
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
Let's make this an `UncheckedIOException` too.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
hopefully the `System.nanoTime` goes away once you merge master in.
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
this should be `isExists`
nit: extra newline
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
Error message could mention the erroneous value (`len(self.topic)`). DONE
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
we can remove the 1 + , now that 0 is not reserved for the global scope. This should be `portCounter.incrementAndGet() % 10;`
`of the it's last` -> `of its last`
`describe` and `get` methods are almost the same: a refactor is possible.
The more I think about this the more I think this should be a list type where you can specify some the options `success` and `failure`. You can use a combination of both (`success and failure`) or just an empty list (`none`) for the other options. We should also decide on a default, potentially `none` is the default if it isn't set.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
This is no-go imo. `Game` string is localized and this regex will work only on English YouTube page. Also don't capture groups you don't use.
`of the it's last` -> `of its last`
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
`of the it's last` -> `of its last`
Why use the funky `filter(None, ...)` to strip out extra spaces instead of just `.split()`? I.e., in what circumstance would this be insufficient: ``` current_label_list = list(set(current_label.split())) ``` Or, if you really truly need to only split on spaces (not tabs or newlines): ``` space_re = re.compile(' +') ... current_label_list = list(set(space_re.split(current_label))) ```
`of the it's last` -> `of its last`
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
here is a space missing before `EMPTY_FLAGS`
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
Users won't be able to use `--disable-rack-aware`.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
Add a trailing comma.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
weird to declare vars after the constructor
`six.raise_from(ValueError("Can not parse package name '%s', error: '%s'" % (name_string, to_native(e))), e)`
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
this still has the #73643 issue, we might want to store the 'raw' notification instead and reprocess handler matching so we always get the 'latest' version of that handler
In the case of exception print the exception e. Getting self-heal status can fail for various reasons, this error message is wrong. If the status option is wrong ansible takes care of printing it, since we have provided possible options.
Why don't you just encode suffix like `u'-\u00c5\u00d1\u015a\u00cc\u03b2\u0141\u00c8'.encode('utf-8')` and for the no_temp_unicode override just do `suffix = b'-ansible'`? No need for this check which is arguably more confusing.
(Not part of this, just asking hypothetically)
We should make TaskInfo final then.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
The style checker will complain that there's no exception class/tuple (eg, `(ExtractorError, RegexNotFoundError, KeyError, )`). Otherwise you could make all the calls non-fatal and (as appropriate) test for falsity or supply defaults.
`if n.__class__.__name__ == ...`
We can use a `subTest()`: ```suggestion def test_file_upload_temp_dir(self): tests = [ None, '', Path.cwd(), str(Path.cwd()), ] for setting in tests: with self.subTest(setting): with self.settings(FILE_UPLOAD_TEMP_DIR=setting): self.assertEqual(check_setting_file_upload_temp_dir(None), []) def test_file_upload_temp_dir_nonexisten(self): for setting in ['nonexistent', Path('nonexistent')]: with self.subTest(setting): with self.settings(FILE_UPLOAD_TEMP_DIR=setting): self.assertEqual(check_setting_file_upload_temp_dir(None), [ Error( "The FILE_UPLOAD_TEMP_DIR setting refers to the " "nonexistent directory 'nonexistent'.", id='files.E001', ), ]) ```
we can randomly use a different cluster? or maybe downsize the global cluster to 1 node for this test? I also wonder if we should consider to run tests with one node as well? the minNode=2 was only convenience...
`try` and `except` statement seems useless: nothing will raise `KafkaError`.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
I am concerned this will cause a ton of calls to `nanoTime`. We can prevent this by using `ThreadPool#relativeTimeInMillis()` (if we need nanosec resolution we can add it here too). This means we need to pass a `LongSupplier` to the stats somehow but I think it's worth it.
I am concerned this will cause a ton of calls to `nanoTime`. We can prevent this by using `ThreadPool#relativeTimeInMillis()` (if we need nanosec resolution we can add it here too). This means we need to pass a `LongSupplier` to the stats somehow but I think it's worth it.
I am concerned this will cause a ton of calls to `nanoTime`. We can prevent this by using `ThreadPool#relativeTimeInMillis()` (if we need nanosec resolution we can add it here too). This means we need to pass a `LongSupplier` to the stats somehow but I think it's worth it.
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
`describe` and `get` methods are almost the same: a refactor is possible.
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Ahh, just noticed one more thing. ec2_connect() is boto2 only. Going to need to add a thing to make an ec2 client with appropriate exception handling `region, ec2_url, aws_connect_kwargs = get_aws_connection_info(module, boto3=True)` `ec2_connection = boto3_conn(module, 'client', 'ec2', region, ec2_url, **aws_connect_kwargs)` then replace ec2_connect(module) with ec2_connection
Ahh, just noticed one more thing. ec2_connect() is boto2 only. Going to need to add a thing to make an ec2 client with appropriate exception handling `region, ec2_url, aws_connect_kwargs = get_aws_connection_info(module, boto3=True)` `ec2_connection = boto3_conn(module, 'client', 'ec2', region, ec2_url, **aws_connect_kwargs)` then replace ec2_connect(module) with ec2_connection
I like the fact that any `AbstractBigArray` can use differently typed pages! that's pretty cool though!
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
```suggestion 'After a failed login, you need to wait for %s second before trying a new login.', 'After a failed login, you need to wait for %s seconds before trying a new login.', ```
```suggestion 'After a failed login, you need to wait for %s second before trying a new login.', 'After a failed login, you need to wait for %s seconds before trying a new login.', ```
I think we should leave this method for java api bw comp
I think NamedWriteableAwareStreamInput was introduced just a bit later. Only my guess.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
this could be static
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
I think we prefer not to use underscores as part of method names, camel case is better
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
We don't need to delay the error ... just emit it and skip everything else. We confirmed this behavior in `observeOn`: https://github.com/ReactiveX/RxJava/issues/1680
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
The `try`/`except` statements seems useless (nothing can raise `KafkaError`) DONE
I think it's still nice to keep the debug logging as we had before.
also this class should be final.
hey can we rename this V1 to ChecksummedTranslogStream
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
nit: read lock -> just lock.
I think the unlock calls should always be in a finally block
+1 on adding UUID
should be removed, `PluginInfo#DEFAULT_VERSION` should be made public and used here instead
Missing a `@since`. I wonder if that wouldn't be something of interest for the library (ping @jkschneider)
those are hard to debug I can tell u :dancers:
We discussed this on another channel, and decided to only do the auto-bootstrapping when autoManageMinMaster mode is active. We also decided to have multiple nodes participate in / run the bootstrapping process.
We discussed this on another channel, and decided to only do the auto-bootstrapping when autoManageMinMaster mode is active. We also decided to have multiple nodes participate in / run the bootstrapping process.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
```suggestion call_command('makemigrations', 'migrations', interactive=False) ```
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
You should catch the error twice to produce an error message suitable for each query
I think you can initialize the capacity.
I think you can initialize the capacity.
I think you can initialize the capacity.
I think you still can add the named patterns, since the files are still on the class path? ``` java grok.loadFromStream(getClass().getResourceAsStream("/config/ingest/patterns/aws")); grok.loadFromStream(getClass().getResourceAsStream("/config/ingest/patterns/bacula")); // next file ```
I think you still can add the named patterns, since the files are still on the class path? ``` java grok.loadFromStream(getClass().getResourceAsStream("/config/ingest/patterns/aws")); grok.loadFromStream(getClass().getResourceAsStream("/config/ingest/patterns/bacula")); // next file ```
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Can we deprecate and remove this one too? I don't think we should have global settings like this.
Can we deprecate and remove this one too? I don't think we should have global settings like this.
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
oh oh I hadn't read your reply when I replied ;)
just please don't add one. There are too many classes already.
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
just please don't add one. There are too many classes already.
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
Use code markers around `put()`
Bit of redundancy: this sets `input` twice (here and in the next few lines).
Ok, sounds fine.
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
And how about activating ordinary sniffing instead , maybe with a very high resniff interval or something like that? I do see why replacing the hosts is not ideal, but I think that not doing it complicates things in our production code, which is even worse.
can this be in try-with logic.... you are not closing this input stream at all
``# The response and file buffers are closed.``
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
remove this additional line break? :)
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
I guess it could be renamed to isFalse() / isTrue() now
I like to give split a second parameter to control the maximum number of times it will split. So something like: `hostname.split(':', 1)` it may also be appropriate to use rsplit() instead of split() here (although the ipv6 address might be the only case where rsplit() vs split() would be valid and you're already taking care of that above.)
This should be the version we are going back to, so 6.5. In this PR, disable bwc tests in the root build.gradle file. Then re-enable in the backport, and do a followup to master to re-enable there as well. This minimizes the changes necessary to followup to master (instead of needing to remember and change all the places that have this version constant).
This should be the version we are going back to, so 6.5. In this PR, disable bwc tests in the root build.gradle file. Then re-enable in the backport, and do a followup to master to re-enable there as well. This minimizes the changes necessary to followup to master (instead of needing to remember and change all the places that have this version constant).
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
I think this can be done easier with an Iterator ```java final StringBuilder spaceDelimitedJvmOptionsBuilder = new StringBuilder(); Iterator<String> it = jvmOptions.iterator(); while (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(it.next()); if (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(" "); } } return spaceDelimitedJvmOptionsBuilder.toString(); ```
The reason should be more explicit about why this needed.
Okay, we might have to revisit some other queries we refactored then.
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
I see that we need it from another package, I think it's ok.
I think this can be done easier with an Iterator ```java final StringBuilder spaceDelimitedJvmOptionsBuilder = new StringBuilder(); Iterator<String> it = jvmOptions.iterator(); while (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(it.next()); if (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(" "); } } return spaceDelimitedJvmOptionsBuilder.toString(); ```
`app_configs` is initialized as an empty dict, so this line should be unnecessary :thinking:
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
Okay, we might have to revisit some other queries we refactored then.
`app_configs` is initialized as an empty dict, so this line should be unnecessary :thinking:
make it final
Sorry, i don't think i was very clear. I meant the hashing algorithm here is an HMAC (a keyed hash). For the anonymization use case we could use a non keyed Hash to the same effect. The key doesn't provide much value unless you are verifying the hash's integrity. To avoid swapping implementations based on a key's existence, a hard coded key can be used, which effectively (but not technically) changes from a keyed hash to non keyed hash.
> write past EOF :dancers: +1!
I think this can be done easier with an Iterator ```java final StringBuilder spaceDelimitedJvmOptionsBuilder = new StringBuilder(); Iterator<String> it = jvmOptions.iterator(); while (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(it.next()); if (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(" "); } } return spaceDelimitedJvmOptionsBuilder.toString(); ```
The reason should be more explicit about why this needed.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
maybe add which type of section it was, so that it's even safer to get rid of the double exception? That is the only useful bit I find in the original stacktrace that would otherwise get lost.
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
same here please add a nice constant that is human readable
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
here too I think we should just do `this.tokenFilters.add(new NameOrDefinition(tokenFilter));`
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I don't like this pattern. If you call the setter several times, you'll append this customizer and rely on the fact the last one called will set the expected value. I guess you've done this that way to avoid adding too much parameters to the builder? I think we need to find a different option for this.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
Ok, sounds fine.
oh..ok... so make `Operation` implement `Callback`, it'll still clean things up
If `MessageContext` is the same instance in both `handleRequest` and `afterCompletion`, we may be able to employ a `Map` rather than `ThreadLocal`. Not sure if there is any advantage to this.
:+1: (I added the same method here locally (differently implemented) )
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
Pick node with THE primary shard
comma-separated should not bee needed, just make flags a type=list in argspec, it will accept both actual lists and comma separated strings
s/payload is/payloads are
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
or N times
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
I wasn't entirely sure either but good to know! :)
This potentially overflows. I mean it's ok for our purposes (it overflows deterministically) but a sufficiently powerful linter would complain. Suggest `^` instead of `+`.
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
We can't use hardcoded ports.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
`@EnableWebSecurity` will have switched off Boot's web security configuration so I don't think the order matters. I think we need either `@EnableWebSecurity` or `@Order`.
please use `assumeFalse(Constants.WINDOWS);`
We can't use hardcoded ports.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
We didn't serialize or use the defaultType of ToXContentToBytes so far, neither in the QueryBuilders nor in any other elements of the SearchSourceBuilder. I think it is safe to ignore this, because the only thing it does is to determine which type of xContent the object is written to when `buildAsBytes()` is called without an argument. It doesn't really change anything about how the object behaves on the shard.
We didn't serialize or use the defaultType of ToXContentToBytes so far, neither in the QueryBuilders nor in any other elements of the SearchSourceBuilder. I think it is safe to ignore this, because the only thing it does is to determine which type of xContent the object is written to when `buildAsBytes()` is called without an argument. It doesn't really change anything about how the object behaves on the shard.
We didn't serialize or use the defaultType of ToXContentToBytes so far, neither in the QueryBuilders nor in any other elements of the SearchSourceBuilder. I think it is safe to ignore this, because the only thing it does is to determine which type of xContent the object is written to when `buildAsBytes()` is called without an argument. It doesn't really change anything about how the object behaves on the shard.
Small typo here: Guage -> Gauge.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
instead of this, can we use Files.newBufferedReader whenever we do this? Its not only more concise, it throws exceptions for malformed input or unmappable characters by default.
Same thing, let's output the type of `msg` here; the `FullHttpRequest` part can be read from the assertion line (at least my first step when an assertion trips is to find the line in the codebase, so we only need what can only be known at runtime).
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
it doesn't reset the ignored list..
We don't need any of these `build*Properties()` methods; all the kafka specific properties are already handled by parts of `KafkaProperties`.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
do we really need that `is not None` check? `check_token` should return `False` for None tokens.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Nit: " . " -> ". "
I think we should return active.get() == false and also - set it if we became idle...
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should only be done in close()
Fine with me, just a thought :)
Can you add a TODO/followup here to just make SortedDocValues "view" that exposes 'missing' as arbitrary value? I can work on it, just so its always fast...
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
Done. I would prefer using `action` as a parameter of `get` instead of being an attribute of `KafkaTopics`.
I think there's no reason that 'template' and 'arg_joiner' need to go into `data` -- they aren't meant to be interpolated into `template`, correct? Instead of the `data.get()` lines below, wouldn't this work: ``` python template = template or self.template arg_joiner = arg_joiner or self.arg_joiner ```
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
We can't use hardcoded ports.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
add a a `logger.isTraceEnabled()` check
super nit: I tend to like validation to be first
++ on debug message
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
Nit: drop the `,` here.
Not sure if we need to do that it's just one entry per field though.
But the Iterators it returns aren't.
Not sure if we need to do that it's just one entry per field though.
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
Nit: drop the `,` here.
But the Iterators it returns aren't.
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
can we just pass the action to the `AsyncShardFetch` class instead of subclassing this seems so close, maybe the two actions can share a common interface
nit: s/final ArrayList<ParentIDFieldMapper>/final List<ParentIDFieldMapper>
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
But the Iterators it returns aren't.
maybe just `esVersion()`
maybe just `esVersion()`
But the Iterators it returns aren't.
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
I think we still might want a test for this, for the case when the license expires upstream.
I think we still might want a test for this, for the case when the license expires upstream.
I think we still might want a test for this, for the case when the license expires upstream.
use AbstractRunnable? Then you don't need the try catch :)
This will close the `SocketChannel` before it can be used by `TimeoutAwareChannel`. It's eventually closed when the `TimeoutAwareChannel` is closed so this is change isn't needed. I'll address this while merging.
This will close the `SocketChannel` before it can be used by `TimeoutAwareChannel`. It's eventually closed when the `TimeoutAwareChannel` is closed so this is change isn't needed. I'll address this while merging.
You can remove the `hasResponseFromRequest` method - it is not needed anymore.
You can remove the `hasResponseFromRequest` method - it is not needed anymore.
A suggestion: '--config' repetition could be avoided using: ``` if self.config: config_param = ''.join(' --config %s=%r' % (key, value) for (key, value) in self.config.items()) else: config_param = '' ``` _DONE_
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
A suggestion: '--config' repetition could be avoided using: ``` if self.config: config_param = ''.join(' --config %s=%r' % (key, value) for (key, value) in self.config.items()) else: config_param = '' ``` _DONE_
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
You should catch the error twice to produce an error message suitable for each query
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
nit: should be "commit_ting_ writer with commit data"
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
+1 on pulling this out, I'm sure this can be used in other places, although in many of the tests I'm thinking about right now we have NamedWriteable things under test, but only the copy method would need to be slightly different.
Shouldn't this be `type: int`? ð¤
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I *really* don't like `BreakIterator` for this. It is a much wider interface than the highlighter needs. But it is what we have to work with. So we shall!
From the spec, it appears that action could potentially be a high cardinality tag: ![image](https://user-images.githubusercontent.com/1697736/40988408-96a7bae0-68b0-11e8-91e7-dd24f5108dcc.png)
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
I'm not sure it is ever good for this to be a global default. Haven't we learned that it causes nasty issues in places like event loops? It seems only appropriate for separate threads, like the IO or NewThread schedulers.
I think java 9 is going to choke on `_` here, if I recall correctly
I think java 9 is going to choke on `_` here, if I recall correctly
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
to make this simpler, I think we should add a method `addCustomFields` to the `AcknowledgedResponse` object instead and just call `response.addCustomFields(builder)` in `AcknowledgedRestListener`. As a follow-up we can then make AcknowledgedResponse implement `StatusToXContent`.
I think you can initialize the capacity.
Not sure you need to initialize the factory every time there.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think you can initialize the capacity.
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
I think the unlock calls should always be in a finally block
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
Great, that solves it then.
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
Great, that solves it then.
yeah, prefer top-level there as well.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
Great, that solves it then.
I think the unlock calls should always be in a finally block
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I think the unlock calls should always be in a finally block
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
I think the unlock calls should always be in a finally block
I think you can initialize the capacity.
I would be using a `Set` in this circumstances.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
Another `_` java 9 will be mad at
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
Nit: missing `@Override`
Can we deprecate and remove this one too? I don't think we should have global settings like this.
not sure `6.` is needed as you have `from __future__ import division`
not sure `6.` is needed as you have `from __future__ import division`
not sure `6.` is needed as you have `from __future__ import division`
not sure `6.` is needed as you have `from __future__ import division`
something is wrong in this sentence :)
`file reopened` -> `file is reopened`
`file reopened` -> `file is reopened`
Note that this is different than setting a single property as it adds the inputs to the list.
any chance we can remove the interface and just name this class NioChannel
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
good catch on delta > 0
`file reopened` -> `file is reopened`
+1 to explore that option. Although, I always doubted whether we should set the primary terms on the ReplicationOperation level, I didn't do it because it wasn't needed and reluctantly opted to keep things as simple as possible and left it at that assert we have now. With the move the primary term based failures we bring the terms into scope, which makes me more inclined to also set them. As said, I'm still on the fence about it myself so I will go along with not doing it, if you feel differently.
++. Thx On Wed, Jun 17, 2015 at 9:09 PM, Shay Banon notifications@github.com wrote: > > - return 0; > > - } > > - TimeValue delayTimeout = indexSettings.getAsTime(DELAYED_NODE_LEFT_TIMEOUT, settings.getAsTime(DELAYED_NODE_LEFT_TIMEOUT, DEFAULT_DELAYED_NODE_LEFT_TIMEOUT)); > > - return Math.max(0l, delayTimeout.millis()); > > - } > > + > > - /** > > - \* The delay in millis when delaying assigning the shard need to expire in. > > - */ > > - public long getDelayAllocationExpirationIn(Settings settings, Settings indexSettings) { > > - long delayTimeout = getAllocationDelayTimeoutSetting(settings, indexSettings); > > - if (delayTimeout == 0) { > > - return 0; > > - } > > - long delta = Math.max(0l, System.currentTimeMillis() - timestamp); > > - if (delta == 0) { > > I think I got what you mean, I will improve it to check on negative value and return 0, to accomdate cases where its fast enough where currentTime is the same as timestamp > > --- > > Reply to this email directly or view it on GitHub: > > https://github.com/elastic/elasticsearch/pull/11712/files#r32663140
`of the it's last` -> `of its last`
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
Error message could mention the erroneous value (`len(self.topic)`). DONE
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
I don't like this pattern. If you call the setter several times, you'll append this customizer and rely on the fact the last one called will set the expected value. I guess you've done this that way to avoid adding too much parameters to the builder? I think we need to find a different option for this.
I think we want to test index level blocks too here
s/y ou/you Also I think upfront is one word.
Space missing between `}` and `is`.
there are too many flavours to set a `WebServiceMessageSender`. Specifying a vararg of instance and a `Class` looks wrong to me. I've removed that in my fork.
I don't think that complexity is warranted. Just keep constructor injection please.
`doSaveState` is async so there is no need to try/catch this call. We ignore exceptions in `doSaveState`, this is ok IMO since saving the state here is just to ensure that we'll start from the last commit point.
`doSaveState` is async so there is no need to try/catch this call. We ignore exceptions in `doSaveState`, this is ok IMO since saving the state here is just to ensure that we'll start from the last commit point.
`doSaveState` is async so there is no need to try/catch this call. We ignore exceptions in `doSaveState`, this is ok IMO since saving the state here is just to ensure that we'll start from the last commit point.
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
Same as the double note above, just for long.
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
++ on this. The ReroutePhase owns retrying across the board.
extra space between 'for' and 'index'. Also, we typically log the index name first under []: `[{}] failed to ack index store deleted' . If I read things correctly, this also logged when something went wrong in innerNodeIndexDeleted so maybe change to "fail to ack index & store deletion"
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
or just: "return ok;"? :)
I'd use `assertRaisesMessage()` with `msg = 'backend does not support timezone-aware datetimes when USE_TZ is False.'`. There's a small chance that messages from third-party backends might not match the `connection.vendor` convention and I don't think it's a critical part of the assertion.
I'd use `assertRaisesMessage()` with `msg = 'backend does not support timezone-aware datetimes when USE_TZ is False.'`. There's a small chance that messages from third-party backends might not match the `connection.vendor` convention and I don't think it's a critical part of the assertion.
when do not want to do it (and throw an exception as said above)
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
this can be collapsed into `assertTrue(foundTerms.add(bucket.getKeyAsNumber()))`
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
QueryBuilders should always set the defaults since they can be constructed without ever passing through the parser (Java API)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
This should probably be private.
oh yeah I missed that :/
I think we should leave this method for java api bw comp
save -> safe
save -> safe
I think we should leave this method for java api bw comp
I think this results in double logging, we will log this here too, no? https://github.com/elastic/elasticsearch/pull/11545/files#diff-9a7b643d56430763f42de913657ca798R125
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Great, that solves it then.
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
I think it might makes sense to split this into `initalPosition` and `initialState`.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
it would be awesome to have some doc-strings on these settings
I see that we need it from another package, I think it's ok.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
If there's GEOS 3.1 (as on Ubuntu 10.04), however you'll need to raise a `NotImplementedError`.
I think it might be nice to move this in `TcpHeader`
I think it might be nice to move this in `TcpHeader`
I think it might be nice to move this in `TcpHeader`
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Yes, I confused myself.
at this point you don't need the restClient variable anymore
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
at this point you don't need the restClient variable anymore
But you are just fixing a typo so you can skip it.
`o1 +=8;` <== format this file again :)
`o1 +=8;` <== format this file again :)
`o1 +=8;` <== format this file again :)
nit: space after if
Sounds good, it's fine to only have support for imagenet1k for now (this is consistent with the other applications). We can add more checkpoints in the future.
yeah, I was thinking we could validate the input with a regexp first, but maybe it's easier/safer to reimplement the parsing logic
Just import `utils`
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
I think we should also name it `get` or `getOrDefault`
I'm doing buffer now and they all emit buffered data in case of onError.
I think we should also name it `get` or `getOrDefault`
could be shorted using `com.google.common.io.Files.write`
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
Actually, I think we can do this without a `TemporaryFolder`. We can just write a new file within the `globalTempDir()` that is already available, no need to create a new folder. Also, this should make it possible to merge this new class with the existing `LogginConfigurationTests`.
This should be done in reset()
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This should be done in reset()
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
makes sense to me as well now, sorry for the noise.
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
Lets please not do that. The thing is it would break: the codebase of the utility class itself would screw everything up. To me, the right answer is not to make these acc blocks easier: its to have less of them, by fixing the actual problems so the blocks are not needed :)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
nit: indenting should be only 4 extra spaces
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I would suggest to use the ungettext_lazy('%(number)d minute', ''%(number)d minutes', 'number') syntax, if possible.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Never mind, even such an API would be useless since the raw password is no longer available after its initially set. So there really is no way around that limitation of this validator.
Should we use `AnsibleUndefined` here instead? I know there is likely circular imports due to `AnsibleUndefined` existing in `lib/ansible/template/__init__.py`, but I've wanted to move it to `lib/ansible/template/undefined.py` to allow it to be imported more freely.
Never mind, even such an API would be useless since the raw password is no longer available after its initially set. So there really is no way around that limitation of this validator.
I think it is not clear here exactly when IndexMissingException is expected to be thrown or not. I would rather move the if on top and have different asserts path based on that. FOr the expected exception one you can then do: ``` try { //do something fail("shouldn't get here"); } catch (IndexMissingException e) { //assert on exception } ```
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
randomInt cannot be within the loop, otherwise it changes at every iteration...
We can call it suspend if you want. To me LongGC is easier to remember as it is what we talk about all them time.
We can call it suspend if you want. To me LongGC is easier to remember as it is what we talk about all them time.
We can call it suspend if you want. To me LongGC is easier to remember as it is what we talk about all them time.
We can call it suspend if you want. To me LongGC is easier to remember as it is what we talk about all them time.
We can call it suspend if you want. To me LongGC is easier to remember as it is what we talk about all them time.
`scheduler` does not appear in parameter list of this method...
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
This does not work for dictionaries: ``` $ python2.7 Python 2.7.5 (default, Aug 10 2014, 21:16:28) [GCC 4.7.1] on linux2 Type "help", "copyright", "credits" or "license" for more information. >>> a=dict() >>> b=dict() >>> cmp(a, b) 0 >>> (a > b) - (a < b) 0 ``` ``` $ python3.7 Python 3.7.1 (default, Jan 31 2019, 22:50:41) [GCC 4.7.1] on linux Type "help", "copyright", "credits" or "license" for more information. >>> a=dict() >>> b=dict() >>> (a > b) - (a < b) Traceback (most recent call last): File "<stdin>", line 1, in <module> TypeError: '>' not supported between instances of 'dict' and 'dict' ```
I'd put the method taking `Duration` above the deprecated one, not below.
I think you can initialize the capacity.
I don't think that complexity is warranted. Just keep constructor injection please.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
I think you are missing a `\n` here.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
I don't think that complexity is warranted. Just keep constructor injection please.
`scheduler` does not appear in parameter list of this method...
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
ok as a follow-up
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
This is not related to your changes (can be followup) but is an obvious bug (just discards `args` completely).
Nit: `reject` -> `rejected`
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
Same here about multi-line toString methods
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
just name it `readSize`
@adityasrini Rather than doing the two String.toLowerCase(Locale.ENGLISH) which requires 2 changes, you should replace the new HashMap() with a new TreeMap(String.CASE_INSENSITIVE_ORDER).
what I mean is just do it at the end of the method so waiting for refresh will be concurrent to the fsync (just a minor optimization - not really something worth complicating flow paths)
@adityasrini Rather than doing the two String.toLowerCase(Locale.ENGLISH) which requires 2 changes, you should replace the new HashMap() with a new TreeMap(String.CASE_INSENSITIVE_ORDER).
this should be `public static final Setting<TimeValue> INDICES_CACHE_REQUEST_CLEAN_INTERVAL = Setting.positiveTimeSetting("indices.requests.cache.clean_interval", TimeValue.timeValueSeconds(60), false, Setting.Scope.CLUSTER);`
this curly bracket should be on the previous line
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Does this really need to be generic? We certainly don't care about any of that on the consumption side.
offtopic: I'm wondering if we should drop `SubscriptionHelper.isCancelled()`
nit: ditto for `final` method args here
nit: ditto for `final` method args here
nit: ditto for `final` method args here
nit: ditto for `final` method args here
`delayTimeoutNanos` can be smaller than `(nanoTimeNow - unassignedTimeNanos)`. For example if `delayTimeoutNanos` is initially 1 minute, and later changed to 10 sec (after 30 seconds).
I think this can move to before the threads start - will be nastier
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
the start cluster does this.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
You're right. I prepared separate PR #7787.
would be nice to allow to configure it to a percentage of the heap size
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
let's add java docs here, it becomes non trivial :)
I don't think is necessary. `request` is passed as`params`. So, "verbose" is already in `params` if it was specified, you just need to be careful resolving defaults. You would also miss other parameters here such as human and pretty.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
I think we should remove this if, call deepCopy recursively in any case, so that the main else works in this case too. Again being paranoid, I know...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
should we release the releasable just in case the exception comes from the listener? this would allow us to only implement on failure.
should we release the releasable just in case the exception comes from the listener? this would allow us to only implement on failure.
We can use the SuppressForbidden annotation on top of the class to fix this.
I admit Django still has much code looking like that, but it should be safe to simply use `if options['empty']:` below without first pushing the result in `self`. Having the value on `self` might make sense when we want to use the value in other methods. Same for `options.get('help', False)`, as we are using the parser in both `call_command` and `run_from_argv`, we can be sure that `'help'` is in the options dictionary, so `options['help']` is fine.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
This should be clarified that it's not guaranteed to actually exclude processing of mentioned things since extractor may use own extraction routines.
I admit Django still has much code looking like that, but it should be safe to simply use `if options['empty']:` below without first pushing the result in `self`. Having the value on `self` might make sense when we want to use the value in other methods. Same for `options.get('help', False)`, as we are using the parser in both `call_command` and `run_from_argv`, we can be sure that `'help'` is in the options dictionary, so `options['help']` is fine.
I admit Django still has much code looking like that, but it should be safe to simply use `if options['empty']:` below without first pushing the result in `self`. Having the value on `self` might make sense when we want to use the value in other methods. Same for `options.get('help', False)`, as we are using the parser in both `call_command` and `run_from_argv`, we can be sure that `'help'` is in the options dictionary, so `options['help']` is fine.
should we call the field `socket_timeout` ? Will we want to add `connect_timeout` too in the future? I think timeout is very generic so we may want to be more specific.
should we call the field `socket_timeout` ? Will we want to add `connect_timeout` too in the future? I think timeout is very generic so we may want to be more specific.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
this could be static
`''.join(self.topic)` could be replaced with `self.topic[0]` (here size of `topic` is always 1). DONE
We prefer using `== false` instead of `!` as it the first is more obvious when scanning code.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
thanks for adding this
A test would be great.
`} catch(IllegalArgumentException e) {`
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
It'd be super nice to explain that we only need this because of `PreBuiltAnalyzers`.
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
@JakeWharton well, it depends on use case, I guess somebody who wants to use `await(time)` on `TestSubscriber` either wants it to be: - "max timeout to fail the test instead of looping infinitely", like @Timeout in JUnit. so in that case value will be someting like `1, MINUTE` while actually data will arrive much faster. - "precise value to check some concurrency algorithm with expected timeouts" so in that case "success" long (relatively) after actual timeout can be considered as a bug. I'd be ok with something like this: ``` java while (true) { if (valueCount >= expected) { return true; } if (System.nanoTime() - start > timeoutNano) { return false; } Thread.sleep(1); } ``` So that only flakiness of last `sleep()` will be amortized. Current implementation increments `timeout` after each `sleep(1)` and may collect some relatively big error, like you had 150 `sleep(1)` but actually spent `200ms` which is ~25% error and seems possible in real life.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
can we make that -1 a constant and use it in all the relevant places? it would be easier to remove it once we go to 4.0
this method can be private now
Same here about multi-line toString methods
Same here about multi-line toString methods
can we make that -1 a constant and use it in all the relevant places? it would be easier to remove it once we go to 4.0
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
can we make that -1 a constant and use it in all the relevant places? it would be easier to remove it once we go to 4.0
would be nice to allow to configure it to a percentage of the heap size
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
this method can be private now
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
I would use `sys.stderr.write(msg + os.linesep)` for each result instead of `print()` with joined results.
Can you add the `<String, Object>` (@nik9000 style) or `<?, ?>` (@jpountz style) to the map? Again, I don't know if you should have a default here.
I think it's always a single node cluster, but I'm good to keep it like this.
I think it's always a single node cluster, but I'm good to keep it like this.
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
I am glad we simplified things by just renaming id to tag, that's a good choice
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
I think it's always a single node cluster, but I'm good to keep it like this.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
or just: "return ok;"? :)
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
Since the account settings are supplied by user, I would feels better if we used URI to build this string. This way we will have at least some basic validation of the things that go into this URL.
Ok, sounds fine.
also this class should be final.
```suggestion - The repository name. ```
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
I think we should return `null` if the key is not an instance of `String` rather than converting it
I don't see much value in this docstring.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I don't see much value in this docstring.
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
or just: "return ok;"? :)
`of the it's last` -> `of its last`
`of the it's last` -> `of its last`
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
we throw the exception and thus take care of the interrupt. We don't need to set it...
we throw the exception and thus take care of the interrupt. We don't need to set it...
we throw the exception and thus take care of the interrupt. We don't need to set it...
we throw the exception and thus take care of the interrupt. We don't need to set it...
we throw the exception and thus take care of the interrupt. We don't need to set it...
we throw the exception and thus take care of the interrupt. We don't need to set it...
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Okay, I am going to commit #4613 for now and I will update it to use this with #4616 once this has been merged.
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
I'd deliver to current thread uncaught exception handler similarly how this method worked before This change can also end up violating Reactive Streams in some cases
we throw the exception and thus take care of the interrupt. We don't need to set it...
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
I wonder if using fromSeq and toSeqNo (instead of size) will result in this being less confusing.
maybe we implement `Iterable<V>`
I think I'd prefer to have a single `static` block, since it's not easily apparent which would be executed first
maybe we implement `Iterable<V>`
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
just please don't add one. There are too many classes already.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
should this check be in the same place where we make the actual transition? then it doesn't look a `LIFECYCLE_FORCED_PHASE` would have to be set as a signal back to this execution.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
should this check be in the same place where we make the actual transition? then it doesn't look a `LIFECYCLE_FORCED_PHASE` would have to be set as a signal back to this execution.
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
Isn't `js` the common extension? At least, that's what is in RFC 4329.
Isn't `js` the common extension? At least, that's what is in RFC 4329.
I would say that we should have `-v` as verbose as it stands now and just support `--version` for the version parameter and not have a short form for it (if thats possible). If not, I think this is a good solution. `-v` is fairly universal as a flag for verbose.
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
I am confused. Is that streams specific? Yet this property doesn't indicate that's the case.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Typo: "se" -> "so"
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Nit: " . " -> ". "
And we could then just leave an assert here.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
we are trying to move away from this syntax, use this instead: ``` _found_file: "{{ lookup('first_found', findme, paths=['/extra/path/'], skip=True) }}" ```
I am not sure what you mean by "non-null" here.
I am not sure what you mean by "non-null" here.
I have seen this comparison in several places. Maybe, it makes sense to move inside Snapshot and have something like `boolean hasName(String repository, String name)` method where it will take place? Not sure if `hasName` is a good name for this method though.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
nit - an extra d? release**d**Delayed..
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
do we need ordered things? does order help anywhere? If not I would just use HashMap
I don't think you need to divide at all - randomDouble is between 0 and 1, I believe.
I think the logging in this class is unneeded. if you debug it you can add it back
Doesn't actually throw `IOException`.
can we pass empty string and empty bytes ref to this so it's a valid ctor? we should fail if these args are null
I think the logging in this class is unneeded. if you debug it you can add it back
can we pass empty string and empty bytes ref to this so it's a valid ctor? we should fail if these args are null
This should be done in reset()
randomInt cannot be within the loop, otherwise it changes at every iteration...
+1 then we shouldn't forget about it :)
or just: "return ok;"? :)
or just: "return ok;"? :)
or just: "return ok;"? :)
This should be done in reset()
This should be done in reset()
or just: "return ok;"? :)
or just: "return ok;"? :)
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
randomInt cannot be within the loop, otherwise it changes at every iteration...
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
this class is also missing a hashCode impl.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
We should log the the failure here if the close fails
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
Great, that solves it then.
we should totally not have this method, one more reason to not implement the interface.
cool can you update the title of the PR then? :)
this feels weird to have this here (concerning whether we should delete data of closed indices , on master nodes - I feel this should be made higher up). It is a different change though... (and has nothing to do with your change).
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
same here, all retry logic should be removed
nice! I like this. super helpful for keeping track
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
cool can you update the title of the PR then? :)
maxDepth can be final
As it's a new major release, I think we can just break this without deprecation.
same here, all retry logic should be removed
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
I think we should try to do it in an atomic way? ``` java if (queryFetchResults.compareAndSet(shardIndex, null, result) == false) { throw new Exception(); } ```
oh I see what you meant now in the other PR :) if Tuples don't pollute the method arguments, I am ok with this, actually it simplifies synchronization issues between the two maps otherwise, I will update my PR to do the same.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
If module-level version_added is 2.5 this can be deleted
We should use a try-with-resources syntax with this.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I think this is expected to be a sorted list on the `job_id`.
I think this is expected to be a sorted list on the `job_id`.
I think this is expected to be a sorted list on the `job_id`.
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
Great seeing these replaced with ParseFields.
this method is not returning a boolean
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
you can omit `ElasticsearchException` here it's unchecked
should be ThreadedActionListener<>
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
you can omit `ElasticsearchException` here it's unchecked
Can we create the exponential back off here and provide a package protected getter for the `BackoffPolicy`? It avoids to jump to another method just to see what kind of policy is created
you can omit `ElasticsearchException` here it's unchecked
I'm not a fan of this. we effectively always wait. Can we just rely on the `assertNull(throwableRef.get())` at the end of the test? it may have some false positives but if we get something wrong, we'll know soon enough
why don't you use `finally` instead of `catch`? I guess that is legacy or copy/paste
You already asserted this 2 lines ago, this is a duplicate.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
how would you feel about naming this method (and it's counterpart) `activatePrimaryMode` ? I was confused a couple of times as initialize and primary terms already used in the IndexShard context (a primary relocation target is a primary shard and is already initializing long before the method is called) .
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
I think this block would be simpler as: ```java if (accessKey.length() == 0) { throw new IllegalArgumentException("Missing access key for s3 client [" + clientName + "]"); } if (secretKey.length() == 0) { throw new IllegalArgumentException("Missing secret key for s3 client [" + clientName + "]"); } final BasicAWSCredentials credentials = new BasicAWSCredentials(accessKey.toString(), secretKey.toString()); return new S3ClientSettings(...); ``` Instead of the nested if statements and double-negative-ish `if` statements
I like this much better!
not used (I was so much looking forward to more usages of this)
This is short and only used in one place, so I think I'd inline it.
same here re iterator.remove()
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
I like this much better!
same here with removing retry logic
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
If it is not required, you don't have to add `'required: False`.
If it is not required, you don't have to add `'required: False`.
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Why using StopWatch? this create many short live objects for not resean.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
We can use the SuppressForbidden annotation on top of the class to fix this.
`.*(?!</li>)` does not make any sense. `['|"]` incorrect.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
right, I forgot about the skip part. then we also end up trying to validate that there's only one version, otherwise skip won't quite work. if we really want to run this thing against a multi-versioned cluster, we should rather take the lower version and lose the validation. But for now this is ok as-is.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
I think this has to happen before you start the cluster, or else the cluster will start with full knowledge.
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
I think the whole point of this PR is to add this new parameter and make it required, so I don't think we should fall back? Otherwise the leniency that we are trying to fix is still here.
I don't think that a security exception should be re-thrown as an `IOException`.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
> the original query weight is greater than 1 and that the rescore weight is greater than 0 `query_weight >= 1` is not even necessary anymore now that you changed rescoring to multiply the score of all hits with the query weight
would you mind adding the same for allocation ids? :+1:
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
no worries, this one seems indeed a good candidate to be tested via unit test :)
no worries, this one seems indeed a good candidate to be tested via unit test :)
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
no worries, this one seems indeed a good candidate to be tested via unit test :)
I think I would still like it better as it avoids reverse-engineering a toString() impl.
This could be `Strings.hasLength(tokenizerName)`
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
would you mind adding the same for allocation ids? :+1:
would you mind adding the same for allocation ids? :+1:
I think I would still like it better as it avoids reverse-engineering a toString() impl.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
same - please name it something like `explainOrThrowRejectedCommand`
This test should assert that the headers are correct.
`start`/`stop` is flexible since it means `_count/list_valid_files_in_directory` will be agnostic to the validation/training story, and only needs the `split` argument. But it doesn't make a big difference.
Maybe change to `AtomicLong`? Took me awhile to get it :thought_balloon:
Nit: `initializing.size()-1` -> `initializing.size() - 1`
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
nit: hasFields ? score docs are always sorted ;)
does this need to be public and also does this class need to be subclassable
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
It'd be better to check for `profileNames.length == 0` rather than creating and immediately throwing away the list
It'd be better to check for `profileNames.length == 0` rather than creating and immediately throwing away the list
It'd be better to check for `profileNames.length == 0` rather than creating and immediately throwing away the list
hopefully the `System.nanoTime` goes away once you merge master in.
hopefully the `System.nanoTime` goes away once you merge master in.
grr nevermind I didn't see the last line pfff...
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
one assert per member is better then you see what's not null :0
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
~~Are you rounding down to the nearest second here? Do you not need an `L` to ensure the result of `System.currentTimeMillis()/1000` is an integer i.e. System.currentTimeMillis()/1000L~~ Sorry ignore that. You do seem to be mixing seconds and millis below in `long oneDayAgo = now - 86400;`
nit: ditto for `final` method args here
I think we can use the `relativeTimeSupplier` and merely report the time (elapsed) since the last fetch.
nit: ditto for `final` method args here
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
Ah yes, thanks!
Oops, sorry, brain fart. :)
Can we use `self.connection.Database` instead? ```suggestion source_db = self.connection.Database.connect(f"file:{alias}_{_worker_id}.sqlite3", uri=True) ```
What if the user specifies 0 here? Previously that meant unbounded.
and use the constant here
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
can we add bogus non relevant settings? Would be good to know they don't mess up with things.
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
It seems that all the implementations of `DisruptableMockTransport` simply have a getter for some constant value for the local node as their implementation. Maybe just move that getter up into `DisruptableMockTransport` and pass it as constructor parameter while we're changing this anyway? (just to save a bit of noise in the concrete tests :))
So, this could be simplified to `assertFalse` Or could be something like the following (which admittedly, is probably less simple) ``` import static org.hamcrest.CoreMatchers.everyItem; import static org.hamcrest.Matchers.greaterThanOrEqualTo; import static org.hamcrest.beans.HasPropertyWithValue.hasProperty; ... assertThat(response.records(), everyItem(hasProperty("recordScore", greaterThanOrEqualTo(50)))); ``` Man, that is frustrating that hamcrest does not support just passing a lambda as a type of matcher :(
remove this additional line break? :)
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
You are already in `ESRestTestCase` so you don't need the to reference the class.
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
Thinking about this more, I wonder if we should have this run-even-if-there-is-nothing-to-do complexity. I'll reach out to discuss.
Thinking about this more, I wonder if we should have this run-even-if-there-is-nothing-to-do complexity. I'll reach out to discuss.
Somehow we need to distinguish "background" tasks for the cluster from those started by rest actions.
I might have missed something here. I don't see that the UnsafeFunc0 adds much. After all every Func0 is potentially unsafe inasmuch as it can throw a RuntimeException for instance.
`} catch(IllegalArgumentException e) {`
I still feel like there ought to be a way to make these methods look less copy-and-paste-ish. They just set off my copy-and-paste blindness even though they aren't copied and pasted.
can we add some trace logging here? I can imagine it will save some WTF at some point.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
I might have missed something here. I don't see that the UnsafeFunc0 adds much. After all every Func0 is potentially unsafe inasmuch as it can throw a RuntimeException for instance.
I'd use `of` to be consistent with `Duration` and have a value with a unit rather than those dedicated methods. The surface area of this object has to remain small given where it is actually going to be used.
oh..ok... so make `Operation` implement `Callback`, it'll still clean things up
For readability, could we have ``` java List<SortBuilder<?>> sorts = mainRequest.getSearchRequest().source().sorts(); if (sorts == null || sorts.isEmpty()) { mainRequest.getSearchRequest().source().sort(fieldSort("_doc")); } ```
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
Is there any reason to use these static factories? The nested classes could just be public (or promoted to top-level) and referenced directly.
I think we should also check the taskId here
I think we should also check the taskId here
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Somehow we need to distinguish "background" tasks for the cluster from those started by rest actions.
oh..ok... so make `Operation` implement `Callback`, it'll still clean things up
Somehow we need to distinguish "background" tasks for the cluster from those started by rest actions.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
It should say greater than zero, 0 is not permitted.
It should say greater than zero, 0 is not permitted.
```suggestion - When used on earlier versions of HAProxy, it will be ignored. ```
I was able to fix this locally by changing to `if r == self.payload:`. No idea if there's some case this doesn't work for though. At scale ansible might not be the right tool. However I have no desire to deal with adding another tool just for updating a single record.
```suggestion - When used on earlier versions of HAProxy, it will be ignored. ```
```suggestion - When used on earlier versions of HAProxy, it will be ignored. ```
```suggestion - When used on earlier versions of HAProxy, it will be ignored. ```
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Maybe this one too, I'm not sure.
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
nit: space between `if` and `(`
I don't think we can make this `private` in case someone else is relying on it.
I don't think we can make this `private` in case someone else is relying on it.
remove this additional line break? :)
nit: space between `if` and `(`
Ah sorry missed that
Ah sorry missed that
thanks for adding this
~~Are you rounding down to the nearest second here? Do you not need an `L` to ensure the result of `System.currentTimeMillis()/1000` is an integer i.e. System.currentTimeMillis()/1000L~~ Sorry ignore that. You do seem to be mixing seconds and millis below in `long oneDayAgo = now - 86400;`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
I think we should have just one pool for all job types, and the maximum number of open jobs per node should also relate to _all_ job types. Since the number of threads in the pool is governed by the number of named pipes we create per job we shouldn't need to adjust the thread pool size. However, since people might now want more jobs this might be a good opportunity to implement #29809.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
see above about abstract runnable
we can now remove this localUUID crazyness.. yay!
see above about abstract runnable
see above about abstract runnable
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
can we use >= instead of == ? it's strictly speaking OK if we synchronize this method, but it always scares me to use equality when using shared variables - we might miss it.
can we get away with passing `null` instead of `TrustSelfSignedStrategy`? I'd prefer to have the certificates we trust only stored in the truststore
can we get away with passing `null` instead of `TrustSelfSignedStrategy`? I'd prefer to have the certificates we trust only stored in the truststore
can we get away with passing `null` instead of `TrustSelfSignedStrategy`? I'd prefer to have the certificates we trust only stored in the truststore
I'd not do this, just pass syntactically valid values to the Prototype ctor
I'd not do this, just pass syntactically valid values to the Prototype ctor
This does not compile; `FakeRestRequest` does not have a constructor with two arguments. This is a recent change and I think you just missed it when you rebased.
I think maybe just "return Math.log(doc.popularity) \* 100;", you don't need the "<idOrCode>" bit.
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
Can you please put these constants into something like `GeoUtils` so `DataTypes`? I went with a similar approach in #30418 for readability and maintenance.
Could you assert the entire text of the message as you had done previously? It helps to clarify what this bit of code is testing.
I think this should be a trace log with "[{}] trying to delete store (reason: [{}})" (note the index name as well) and log the info after successful deletion. We already log a debug message (or higher) in all callers of this method and it will not result in an info message saying "deleting" when we actually failed. ``` logger.trace("{} trying to deleting store (reason [{}]}", index, reason); nodeEnv.deleteIndexDirectorySafe(index, 0, indexSettings); logger.info("{} store deleted (reason [{}]}", index, reason); } catch (LockObtainFailedException ex) { logger.debug("{} failed to delete index store - at least one shards is still locked", ex, index); ```
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
canceled -> cancelled
asked f2f, we can probably delete logging at this point.
`Arrays.asStream(response.pingResponses)` would not materialize it
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
I would keep `if not ...` in the same line.
good that you added this assertion :)
good that you added this assertion :)
good that you added this assertion :)
good that you added this assertion :)
good that you added this assertion :)
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
Since the account settings are supplied by user, I would feels better if we used URI to build this string. This way we will have at least some basic validation of the things that go into this URL.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Fine by me. I would still add that note related to child-namespaces so people skimming the code understand the limitations and/or can contribute a more comprehensive fix for this.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
If it is not required, you don't have to add `'required: False`.
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
this should look like this instead: ``` result = super(ActionModule, self).run(tmp, task_vars) if result.get('skipped', False) or result.get('failed', False): return result ```
We're in the controller and this isn't something we're passing to an exception constructor. Therefore use to_text() here.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
If it is not required, you don't have to add `'required: False`.
should we use a long just to be on the paranoia side of things
should we use a long just to be on the paranoia side of things
The repeatedly printed stacktrace is not relevant if you want to fail the test. The uncaught handlers are thread-local and you only need to get past the catch around the onError handler. They are invoked together on the same thread.
`of the it's last` -> `of its last`
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
It feels wrong that hashCode is using writtenBy while equals isn't
I wonder if with this change you can remove `UpdateHelper.Operation` entirely and just use `DocWriteResult.Operation`. I'm not sure it'd be clear to use `CREATE` instead of `UPSERT` in all the places though.
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
`''.join(self.topic)` could be replaced with `self.topic[0]` (here size of `topic` is always 1). DONE
```suggestion self.temp_app_path.joinpath("__init__.py").touch() ```
```suggestion self.temp_app_path.joinpath("__init__.py").touch() ```
I usually just do ``` /** * Read from a stream. */ ``` The input and output are relatively obvious. Same for the IOException. The IllegalArgumentException isn't, but honestly it isn't a big deal I think. Also not a big deal, more a matter of my personal style preference which I don't want to force on anyone.
Since the account settings are supplied by user, I would feels better if we used URI to build this string. This way we will have at least some basic validation of the things that go into this URL.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just saw @s1monw replacing `Lists.newArrayList` with `new ArrayList<>()` a few days ago. Maybe that way is out preferred way now? +1 on removing the warning though.
I just saw @s1monw replacing `Lists.newArrayList` with `new ArrayList<>()` a few days ago. Maybe that way is out preferred way now? +1 on removing the warning though.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
We also need a simple rest test, testing integration like we have for the other processors
We also need a simple rest test, testing integration like we have for the other processors
We also need a simple rest test, testing integration like we have for the other processors
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
or just: "return ok;"? :)
good catch on delta > 0
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
Ah yes sorry, ~~prefix~~ suffix
If it is not required, you don't have to add `'required: False`.
Ah yes sorry, ~~prefix~~ suffix
If it is not required, you don't have to add `'required: False`.
IMO this is useless since it will throw an NPE anyway the check is obsolet
```suggestion via U(https://www.rabbitmq.com/ssl.html#automated-certificate-generation) and RabbitMQ ``` Also, there recently was a discussion in #ansible-docs about the word `via`; I think the result was to avoid it, since not everyone understands it.
Key descriptions do not start with "The", "A", etc.
We should log the the failure here if the close fails
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
`(parameterPosition == -1) ? 0 : parameterPosition` maybe more readable
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
> In that case we always make a copy of the underlying array in ArrayList, Not if you change the request and such to use lists. > while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. which may be frequent (i.e., every request), which is why I was considering making a change.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
> In that case we always make a copy of the underlying array in ArrayList, Not if you change the request and such to use lists. > while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. which may be frequent (i.e., every request), which is why I was considering making a change.
Why use a static block to initialise this? `Sets.newHashSet` can turn this into a 1 liner, and then you can wrap it in `unmodifiableSet`
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
this deserves a sep issue I guess but good catch
I think it's always a single node cluster, but I'm good to keep it like this.
I believe this will inject non-determinism ... notifications will be capable of interleaving and being out of order. I think we need to combine this with `ScheduledObserver` which maintains a queue and event loop for handling each notification sequentially on the given scheduler.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Key descriptions do not start with "The", "A", etc.
this can be collapsed into `assertTrue(foundTerms.add(bucket.getKeyAsNumber()))`
Key descriptions do not start with "The", "A", etc.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
It would be good to have some context as to where the filter appeared. I would at least word it a little differently: `"Missing [type] setting for anonymous char filter: " + charFilterName`
It would be awesome if buildah supported copying from a container.
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
(Similarly, mark any string that you are going to call decode on with as a b"string".)
(Similarly, mark any string that you are going to call decode on with as a b"string".)
or maybe "shard cannot remain on this node and is force-moved to another node"
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
nit: should be "commit_ting_ writer with commit data"
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
Yes, I think we should make `Job.Builder::setJobType` `public`. The user could change it if they used the low level REST client.
I still feel like there ought to be a way to make these methods look less copy-and-paste-ish. They just set off my copy-and-paste blindness even though they aren't copied and pasted.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
go for it, thanks @tlrx !
I am glad we simplified things by just renaming id to tag, that's a good choice
super nit: I tend to like validation to be first
What if the user specifies 0 here? Previously that meant unbounded.
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
Wrong key. Again breaks if no such key.
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
I think we should collapse the two above methods, they are always called in sequence.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
nit - an extra d? release**d**Delayed..
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
nit - an extra d? release**d**Delayed..
Ok, sounds fine.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
can this see `unregister task for id: [{}]`
It would make sense to keep `testOnBorrow` `true` because you don't want to get broken connections from the pool. For all other properties, it would make more sense to accept a `JedisPoolConfig` bean, if a bean is configured externally. `testOnCreate`/`testWhileIdle`/`testOnCreate` are very specific and not required to set by the majority of users. Pooling config can be sometimes very specific so it makes no sense to include the more advanced properties as it increases mostly complexity.
It would make sense to keep `testOnBorrow` `true` because you don't want to get broken connections from the pool. For all other properties, it would make more sense to accept a `JedisPoolConfig` bean, if a bean is configured externally. `testOnCreate`/`testWhileIdle`/`testOnCreate` are very specific and not required to set by the majority of users. Pooling config can be sometimes very specific so it makes no sense to include the more advanced properties as it increases mostly complexity.
Small typo here: Guage -> Gauge.
Small typo here: Guage -> Gauge.
this method can be private now
I meant `node` from the for loop.
this could be static
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
The theoretical idea here is to try to move away from overriding methods like crazy at the transport level. So if refactorings need to happen, we can (hopefully) just move the stubs to different locations, opposed to dealing with a billion different tightly couple to the `Transport` interface tests.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
can you add spaces? `new KeyManager[] { km }, new TrustManager[] { tm }`
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
Ah, okay. Thanks.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
also reflect the deprecations on the java api to the corresponding parse fields too? (slop etc.)
Maybe add "for example"
this assumes that the returned array will be of the same size as tops. This will be true in practice since they are both arrays of doubles, but I think the code would be more robust if it called `resize(bottoms, tops.size())` instead of `grow(bottoms, owningBucketOrdinal+1)`.
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
There's an extraneous blank line here.
can we add some trace logging here? I can imagine it will save some WTF at some point.
After thinking about this more, it's probably more reliable and easier to maintain if we just default to always using our version of `ismount()` rather that trying to evaluate the Python version. Ideally we could probe somehow and fallback to this version rather than doing a version comparison, but it's really hard to probe for a bugfix. ```suggestion ```
I would leave this like how it was before without this extra internal class. It's not actually used in any new places outside of Painless from what I can tell (maybe I missed something), so these things are literally just part of the PainlessScript still.
I would leave this like how it was before without this extra internal class. It's not actually used in any new places outside of Painless from what I can tell (maybe I missed something), so these things are literally just part of the PainlessScript still.
I would leave this like how it was before without this extra internal class. It's not actually used in any new places outside of Painless from what I can tell (maybe I missed something), so these things are literally just part of the PainlessScript still.
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I usually prefer the way without the else but I don't object to either one.
Such changes in our own source is a good indication there will be generics issues for the users of the library.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
General thought for these various `Double.NaN`'s .. should we be returning `null` instead (and subsequently returning a `Double` instead of `double`)? E.g. because some fields may actually have `NaN`'s as real values, and lacking a field isn't quite the same as not-a-number? Not sure, probably needs several more opinions :)
General thought for these various `Double.NaN`'s .. should we be returning `null` instead (and subsequently returning a `Double` instead of `double`)? E.g. because some fields may actually have `NaN`'s as real values, and lacking a field isn't quite the same as not-a-number? Not sure, probably needs several more opinions :)
can you please add the `clusterStateVersion` to the assert message
(we just load all files in the `ES_HOME/config/ingest/grok` directory)
for style can we maybe invert the if statements here ie `if (!masterCopy.isEmpty)` and `if (!success)`? I like to have only one return statement at the end of the method
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
Can we call these `from` and `to` and the non Diff fields `toVersion` `fromUuid` and `toUuid` ? sorry to be a pain but I think it will be clearer.
just beware that Long.compare is Java 1.7 only, you might want to use Longs.compare from Guava instead when merging to 1.x
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
maybe fold this if-else into the next one.
maybe fold this if-else into the next one.
maybe fold this if-else into the next one.
can you just leave the constant in this class? There isn't a need to put it in realm imo
I think checking for newline is better than relying on pretty printing having space between key/object...
canceled -> cancelled
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
canceled -> cancelled
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
canceled -> cancelled
canceled -> cancelled
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I think we should also check the taskId here
I think we should also check the taskId here
I like this much better!
This isn't needed client-side.
I think `InternalDateHistogram.NAME` would be a bit better. Now that type isn't used for serialization I'd like to remove it entirely one day.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
I think `InternalDateHistogram.NAME` would be a bit better. Now that type isn't used for serialization I'd like to remove it entirely one day.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
This isn't needed client-side.
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
should we check here that the totalShardWeight is not negative. I was just thinking if somebody uses the number of docs per shard and we overflow? I really wonder if we should put some upperbound into the setting to ensure folk don't go crazy? They should use some log scale rather than actual numbers? maybe we use `1<<16` as the upper limit for now? and move totalShardWeight to a long and use doubles elsewhere? I really just wanna protect us form going negative :)
nit: missing a space after the first comma
same here re enumSet.toString
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
look into `StreamInput#readMap`
This could become a `Map<String, String>` and remain as `SHUTDOWN_MESSAGE`
This is great! No more @Inject!
Can you indent this one extra time? When the body of the block below it and a part of the `if` statement line up I have trouble separating them properly when reading quickly.
Can you indent this one extra time? When the body of the block below it and a part of the `if` statement line up I have trouble separating them properly when reading quickly.
I'm not a big fan of this field. It feels like it could just get pushed down to be an `AtomicBoolean` inside `upgradeTemplates`, or if we need it to be a field, I think it works better if its meaning is reversed e.g. `detectedUpgradeErrors` As it stands we reset it to `true` even if we know something failed, which just feels wrong.
Typo, "Trasnlog" -> "Translog"
I'm not a big fan of this field. It feels like it could just get pushed down to be an `AtomicBoolean` inside `upgradeTemplates`, or if we need it to be a field, I think it works better if its meaning is reversed e.g. `detectedUpgradeErrors` As it stands we reset it to `true` even if we know something failed, which just feels wrong.
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
Is this negative check necessary? long has 2^63 -1 capacity and let's assume that we will accumulate 10^9 every second we would still need 106 752 days to overflow (roughly 292 years).
Typo, "Trasnlog" -> "Translog"
I'm not a big fan of this field. It feels like it could just get pushed down to be an `AtomicBoolean` inside `upgradeTemplates`, or if we need it to be a field, I think it works better if its meaning is reversed e.g. `detectedUpgradeErrors` As it stands we reset it to `true` even if we know something failed, which just feels wrong.
I guess it is "these" marked consumers now.
I don't think you need to this, the internal cluster will call the node settings automatically.
I guess it is "these" marked consumers now.
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
Typo, "Trasnlog" -> "Translog"
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
these ElasticsaerchExceptions are bogus remove them
Typo, "Trasnlog" -> "Translog"
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
let's add an assertion that this method is only called from the snapshot thread.
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
use AbstractRunnable? Then you don't need the try catch :)
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
I'd switch the order of these so it matches the declaration order.
How about throwing a dedicated exception for this so that we can have a `FailureAnalyzer` that goes with it. Maybe going a tad too far ... If we don't, I think the error message should state why they couldn't be excluded (because these are not auto-configurations or something).
How about throwing a dedicated exception for this so that we can have a `FailureAnalyzer` that goes with it. Maybe going a tad too far ... If we don't, I think the error message should state why they couldn't be excluded (because these are not auto-configurations or something).
would you mind adding the same for allocation ids? :+1:
How about throwing a dedicated exception for this so that we can have a `FailureAnalyzer` that goes with it. Maybe going a tad too far ... If we don't, I think the error message should state why they couldn't be excluded (because these are not auto-configurations or something).
instead of flags_on/off just flags .. a canonical list
remove empty string, default to null and return info if null (other modules use list/query, but not a fan of those either)
Do note that this only looks at the primary credential cache. This means that if you use a collection credential cache such as DIR, KEYRING or KCM (default in most distributions these days), you might not see a ticket that exists in a non-primary credential cache. Maybe consider using `klist -A`, or try a `kswitch -p <principal>`? The latter is easier to parse, but might break stuff if people are still using the old krb5 APIs (rather than GSSAPI) and were using the primary credential that you just made secondary.
Nit: you could use `Collections.emptyList()` instead of `new ArrayList<>()`
This sentence ``` "To validate an individual application's models rather than all applications' models, call ``self.check(app_configs)`` from ``handle()``, where ``app_configs`` is the list of application's configuration provided by the app registry." ``` is still valid. I will restore it.
Nit: " . " -> ". "
Dot at the end.
Nit: " . " -> ". "
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Cases from lines 361 and 363 work with the previous implementation.
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
typo? oracle corp isn't the jvm version..
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
ok...but client depends on the transport service anyway no? I think I don't get it
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
can we have a shorter name here maybe `forceReadFromFileChannel`
Another `_` java 9 will be mad at
can we have a shorter name here maybe `forceReadFromFileChannel`
fyi I think you can IOUtils.closeWhileHandlingException(files) since its Iterable...
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
just name it `read`
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
can we have a shorter name here maybe `forceReadFromFileChannel`
not sure if we should make such a big deal out of it
not sure if we should make such a big deal out of it
not sure if we should make such a big deal out of it
just name it `read`
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
you can omit `ElasticsearchException` here it's unchecked
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
Yeah, I see now. We'll clean it up later.
Another `_` java 9 will be mad at
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
we decided to live on the edge and have fun. The concern was around non ascii codes breaking tooling but CI seems happy. Let's see how far we get.
Missing a space here after `id`
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Nit: missing `@Override`
I don't think that complexity is warranted. Just keep constructor injection please.
I see that we need it from another package, I think it's ok.
would be nice to allow to configure it to a percentage of the heap size
I see that we need it from another package, I think it's ok.
Looking at this I was wondering if the latch was needed with the introduction of the barrier, it can probably be removed.
Nit: missing `@Override`
That's java 1.8 construct
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
I think when this is rewritten, I would prefer to have an `.isConcreteIndex()` method on `AliasOrIndex` to avoid the double negatives in comparisons, I had to stare at this for a while to validate it is working correctly.
@nik9000 Note that because of 5bbb1312b1b752a87d8ab1721042fad3f2133a7e this code in a slightly different place in 2.x (for the backport).
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
or maybe give the return value a variable and name it accordingly
here I'd do the same as above an pass in an some kind of BytesReference factory that can produce new BytesReferences and return a `CompositeBytesReference` instead the `int` to signal how much has been read. We can figure out how to do SSL and stuff afterwards this is too hard to do in one step
yes my reasoning is that a compile error makes you think about validation rather then forgetting because there's a default empty impl that does no validation. I tend to prefer an empty validate in all queries that don't need to validate, although that's verbose. Plus that is what we do with ActionRequest as well.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
or maybe give the return value a variable and name it accordingly
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
or maybe give the return value a variable and name it accordingly
or maybe give the return value a variable and name it accordingly
I think when this is rewritten, I would prefer to have an `.isConcreteIndex()` method on `AliasOrIndex` to avoid the double negatives in comparisons, I had to stare at this for a while to validate it is working correctly.
or maybe give the return value a variable and name it accordingly
@nik9000 Note that because of 5bbb1312b1b752a87d8ab1721042fad3f2133a7e this code in a slightly different place in 2.x (for the backport).
Randomized runner should not need these @Test annotations.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
is there a way to filter out the index metadata here? We just want the global metadata.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I think I'd prefer to check `listedNodes()` instead of `filteredNodes()`, which wouldn't be empty if the transport client used the right cluster name (`foobar`). Otherwise it feels like we are testing two things at the same time (filtering out the nodes and updating the version)...
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
same here: no need for the [].
Oh, got confused , which is the point :) getDelayCalculationTimestampInNanos -> getUnassignedTimeInNanos
I think it might be nice to move this in `TcpHeader`
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I'd rather just `new ConcurrentLinkedQueue<>()`.
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
nxapi will fail here when given a CustomNetworkConfig directly. In order to avoid this, call `.items_text()` before `load_config()` like so: ``` candidate = candidate.items_text() load_config(module, candidate) result['changed'] = True result['commands'] = candidate ```
isn't enough to have another waitForEvents to make sure that the previous event was successfully published? I really think we shouldn't have this time based solution. 10s makes me shudder :)
can we just pre-compute the hashCode in the ctor instead? I can already see this going bad with concurrency and we might be just lucky we didn't hit that yet? Either we do in the ctor and make it final or we need a volatile read here
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
There's no need to specify `this` : `if (isString() && other.isString())`
I think this should be a ParseException instead of an IllegalArgumentException. This would be in line with what we do elsewhere in the codebase (such as in the mapper parsers where any left over parameters after parsing is done are throw in a MapperParsingException).
You can use joinFieldType.name() right? Instead of `joinField`
You can use joinFieldType.name() right? Instead of `joinField`
Answering my own question: you build the array to simulate the task being on all of the simulated nodes. I don't know that that is required here but doesn't hurt anything.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
would be great if this logic could be unit tested.
Answering my own question: you build the array to simulate the task being on all of the simulated nodes. I don't know that that is required here but doesn't hurt anything.
You can use joinFieldType.name() right? Instead of `joinField`
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
I just merged this ... but I'm always hesitant when changing something as core as `Subscriber`. Are we ready to support this new method forever. Is it the right signature for all the use cases? I think it's right, but I've regretted public API decisions before :-) /cc @zsxwing @abersnaze for more eyes and thought on this.
I just merged this ... but I'm always hesitant when changing something as core as `Subscriber`. Are we ready to support this new method forever. Is it the right signature for all the use cases? I think it's right, but I've regretted public API decisions before :-) /cc @zsxwing @abersnaze for more eyes and thought on this.
I just merged this ... but I'm always hesitant when changing something as core as `Subscriber`. Are we ready to support this new method forever. Is it the right signature for all the use cases? I think it's right, but I've regretted public API decisions before :-) /cc @zsxwing @abersnaze for more eyes and thought on this.
I just merged this ... but I'm always hesitant when changing something as core as `Subscriber`. Are we ready to support this new method forever. Is it the right signature for all the use cases? I think it's right, but I've regretted public API decisions before :-) /cc @zsxwing @abersnaze for more eyes and thought on this.
`# Using the __icontains lookup with ArrayField is inefficient.`
I just merged this ... but I'm always hesitant when changing something as core as `Subscriber`. Are we ready to support this new method forever. Is it the right signature for all the use cases? I think it's right, but I've regretted public API decisions before :-) /cc @zsxwing @abersnaze for more eyes and thought on this.
`Arrays.asStream(response.pingResponses)` would not materialize it
we need to find a way to keep the headers and context of the original benchmark requests here, when executing the "internal" ones. That might involve recreating the `SearchRequest` via copy constructor passing in the original benchmark request where the headers and context would get copied from.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
I think it is fine: we only build one search context per request per shard.
we could pass a glob with regex:xxx to newDirectoryStream if we want
we could pass a glob with regex:xxx to newDirectoryStream if we want
how will you be able to detect duplicates? hmm... maybe I'm missing something here... the way I saw it, each plugin will effectively define a static its contexts (probably static constants of `SearchContext.Plugin`) and then pass it to executable/compile on demand
this looks a bit odd of a toString() implementation as it's very much targeted towards that one logging call site. Maybe change it to be more generic.
same for functions below
Such changes in our own source is a good indication there will be generics issues for the users of the library.
I don't think it's important for now
I don't think it's important for now
+1 for tests, I am slightly worried that we will forget about this location parameter in some places in the future, was wondering if there's way to enforce it, so that we print out the location whenever possible.
can we have a shorter name here maybe `forceReadFromFileChannel`
I'd return a dedicated return type not a tuple.. tuples are ugly on these interfaces introduce a new class!
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
s/same id is/same id but it is/
same here `if (shard.state() != RELOCATING) {`
same as above, no need for try catch
same as above, no need for try catch
and here too ;)
and here too ;)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
and here too ;)
This should be done in reset()
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
This should be done in reset()
same as above, no need for try catch
So as far as I see is this is the crucial change in this PR? I was wondering if might have undesired effects that we allow more field value types to be serialized/deserialized than before by using `writeGenericValue`. What would happen for example when fieldValue is a GeoPoint. It would have caused the serialization to trip previously, now it will be okay (and I guess it might cause error later). I guess switching to `writeGenericValue` is a good tradeoff here but would like to hear your ideas about that.
So as far as I see is this is the crucial change in this PR? I was wondering if might have undesired effects that we allow more field value types to be serialized/deserialized than before by using `writeGenericValue`. What would happen for example when fieldValue is a GeoPoint. It would have caused the serialization to trip previously, now it will be okay (and I guess it might cause error later). I guess switching to `writeGenericValue` is a good tradeoff here but would like to hear your ideas about that.
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
`file reopened` -> `file is reopened`
`file reopened` -> `file is reopened`
maybe also here `"foo"` -> `{@code foo}`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Maybe rewrite this using `assertNotEquals`? It makes it symmetric with the previous line so that it's clearer, and it gives better failure messages from JUnit when the assertion fails.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Do not need the enumerate here. i is not used.
can we do `if (closed == false)` or use an AtomicBoolean and use `if (closed.compareAndSet(false, true)) {`
these ElasticsaerchExceptions are bogus remove them
shard can remain
same as above, no need for try catch
I would be using a `Set` in this circumstances.
and here too ;)
you can use `IOUtils.close(processor)` it deals with `null` values...
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
To keep things simple, I would not support null values for now.
Maybe call RxJavaPlugins.onError() or however that api is called in 1.x? I believe people won't like stacktrace popping up in their logs without ability to swallow it
mhm, I see, ok
We need to cast indeed, but I want to give the compiler opportunities to find errors, which is never possible when one starts definiting methods whose generic parameter is only used in the return value. By the way I'm thinking that we could make casts more safe by making category a class instead of a string, and this class would be the base class of the object that the namedwriteables can deserialize
Maybe call RxJavaPlugins.onError() or however that api is called in 1.x? I believe people won't like stacktrace popping up in their logs without ability to swallow it
Are there any calls to this version of findTemplateBuilder with matchType `string`? Or `findTemplate` below? very confusing how we have so many public variants of this method...
Oh, never mind, I misread. Sorry for that. ð
Why all these extra levels of indirection? I think this addSupplier, and the other one added here could just be implemented inside `keystore` that takes a FileSupplier, and the File variant calls that method instead of this indirection.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
already have this in basic.py, no need to create your own, it also includes sanitation and no_log
At minimum this should be typed (we should have separate script classes for each underlying doc values type), but I would much rather this be built into the script itself, so instead of setting the value, an iterate type call is made, similar to the doc values api.
same note as in the json processor PR.
At minimum this should be typed (we should have separate script classes for each underlying doc values type), but I would much rather this be built into the script itself, so instead of setting the value, an iterate type call is made, similar to the doc values api.
maybe just `esVersion()`
At minimum this should be typed (we should have separate script classes for each underlying doc values type), but I would much rather this be built into the script itself, so instead of setting the value, an iterate type call is made, similar to the doc values api.
same note as in the json processor PR.
If we assume that all surrogate pairs need encoding, I think we can make this simpler? ``` int startIndex = i; for (i++;i< s.length() && doesNotNeedEncoding.get(s.charAt(i)) == false; i++) { assert Character.isSurrogate(s.charAt(i)) == false || doesNotNeedEncoding.get(s.charAt(i)) == false; } final byte[] bytes = s.substring(startIndex, i).getBytes(UTF_8); ```
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I am not sure whether the log message is too specific, i.e. the subclass must not necessarily be a service.
I see that we need it from another package, I think it's ok.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Maybe just clear a range of bits with `FixedBitSet#(int, int)` instead of clearing bit by bit? The implementation looks to be more efficient and would just require care around the offset wrapping.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
If we assume that all surrogate pairs need encoding, I think we can make this simpler? ``` int startIndex = i; for (i++;i< s.length() && doesNotNeedEncoding.get(s.charAt(i)) == false; i++) { assert Character.isSurrogate(s.charAt(i)) == false || doesNotNeedEncoding.get(s.charAt(i)) == false; } final byte[] bytes = s.substring(startIndex, i).getBytes(UTF_8); ```
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
Let's use `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
You would have to remove the type if you donât want int32. We deal with unsigned ints that are 64 bits in length in win_regedit and have to rely on the manual parsing.
I don't think we want to subclass `base.Deserializer`. Instead, we can just do `self.object_list = object_list` and use that instead of `self.stream` below.
I don't think we want to subclass `base.Deserializer`. Instead, we can just do `self.object_list = object_list` and use that instead of `self.stream` below.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
`split` can be reserved for internal methods, as it isn't very user-friendly. For user-facing APIs, we can go with your original proposal: ```python generator = image.ImageDataGenerator(validation_split=0.5) train_iterator = generator.flow_from_directory(image_dir, subset='training') val_iterator = generator.flow_from_directory(image_dir, subset='validation') # This should also be possible train_iterator = generator.flow(x, y, subset='training') val_iterator = generator.flow(x, y, subset='validation') ```
remove empty line
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
I think it is more idiomatic to statically import the `instanceOf`.
I think it is more idiomatic to statically import the `instanceOf`.
This looks like it was accidentally left behind after doing some debugging.
In the two methods above, I think you should get a local copy of the immutable map so that it cannot get null between the null check and the call to isEmpty/get
I think maybe just "return Math.log(doc.popularity) \* 100;", you don't need the "<idOrCode>" bit.
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
Ok, sounds fine.
Ah! I see the static reference now. I think this method is fairly confusing then? Like, it _looks_ like it is just about the version that you are calling it on but it does stuff with the _current_ build.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Change "param required" to "parameters are required"
This looks like it was accidentally left behind after doing some debugging.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
this could lead to NPE if from the java api no set call is performed
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
Change "param required" to "parameters are required"
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
We also need a simple rest test, testing integration like we have for the other processors
I don't think that complexity is warranted. Just keep constructor injection please.
Change "param required" to "parameters are required"
I guess, are any of the other assertions necessary given that we are checking that source has not changed at all in this case (and no metadata was added).
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
``` java assertThat(provider.fetchCount, is(1)); ```
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
I see that we need it from another package, I think it's ok.
I think it was better when this was passed into the constructor of the exception. The thrower knows the type so thereâs no need to make the analysis figure it out.
It'd be nice if the map were `unmodifiable`.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
can we just change this to System.getProperty("tests.seed") != null? Then that method can be removed.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
You can make the whole PR a lot simpler by using: `for fname in sorted(files)[start : stop]` Remember: this feature should only total a few lines of change. The only "logic" required by this PR is the computation of `start` and `stop` above given the `validation_split` passed by the user (if any).
`split` can be reserved for internal methods, as it isn't very user-friendly. For user-facing APIs, we can go with your original proposal: ```python generator = image.ImageDataGenerator(validation_split=0.5) train_iterator = generator.flow_from_directory(image_dir, subset='training') val_iterator = generator.flow_from_directory(image_dir, subset='validation') # This should also be possible train_iterator = generator.flow(x, y, subset='training') val_iterator = generator.flow(x, y, subset='validation') ```
There's no need for that. If the pool is not available, then no pool should be configured as before.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Ah sorry missed that
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
thanks for adding this
remove empty line
We also need a simple rest test, testing integration like we have for the other processors
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
There are other methods in InstallPluginCommandTests that could potentially be useful if we wanted to share them.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
s/same id is/same id but it is/
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Nit: `active.size()-1` -> `active.size() - 1`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
style wise, I think `getV3Key` reads easier
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
Nit: `who's the a better` -> `which is the better`
Nit: `who's the a better` -> `which is the better`
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I think we want to test index level blocks too here
oh cool the read is in the ctor! nice!
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Sorry, right, I was confused by the child and _child looking similar.
This eagerly shuts down the chain and does not wait for the delayed values.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Randomized runner should not need these @Test annotations.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Randomized runner should not need these @Test annotations.
randomInt cannot be within the loop, otherwise it changes at every iteration...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I am ok with what you propose Nik!
we can use assertThat(translog.currentId(), isGreaterThan(currentTranslogId) and get nice messages automatically.
Add period and I usually put the space on the previous line.
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
So it's starts with and (ends with or ends with).
Key descriptions do not start with "The", "A", etc.
I think that we need to be able to deal with higher node ordinals somehow. To be discussed, as it's not immediately clear how to do so.
Key descriptions do not start with "The", "A", etc.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
Key descriptions do not start with "The", "A", etc.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
just name it `readSize`
You should be able to collapse this to `IOUtils.close(this.current, uncomittedTranslogs)`
This is why I said moving to compute instead of computeIfPresent so that we could assert that we do have a mapping for nodeId in that map at that point. To be clear I think that what you did is correct, I'd just like to add assertions to it to make sure the invariant is respected.
This is why I said moving to compute instead of computeIfPresent so that we could assert that we do have a mapping for nodeId in that map at that point. To be clear I think that what you did is correct, I'd just like to add assertions to it to make sure the invariant is respected.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
oh yeah I missed that :/
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I think java 9 is going to choke on `_` here, if I recall correctly
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
do we need ordered things? does order help anywhere? If not I would just use HashMap
Can we switch to using the method that returns `Index[]` and use the index uuid rather than the index name as key in the map? That will help with the upcoming cross cluster search feature ;)
Good for me, I didn't have a strong feeling about it.
Can we switch to using the method that returns `Index[]` and use the index uuid rather than the index name as key in the map? That will help with the upcoming cross cluster search feature ;)
Good for me, I didn't have a strong feeling about it.
Good for me, I didn't have a strong feeling about it.
Good for me, I didn't have a strong feeling about it.
same as above, could be an array
> Just checking - this doesn't account for accidentally passing in a _str_ by say, omitting the comma of a _tuple_. Is an error suitably raised earlier/later by it being a `tuple_settings`? Yes exactly, `tuple_settings` protects from passing a string.
> Just checking - this doesn't account for accidentally passing in a _str_ by say, omitting the comma of a _tuple_. Is an error suitably raised earlier/later by it being a `tuple_settings`? Yes exactly, `tuple_settings` protects from passing a string.
yea, in that case, let's not add the addition message, and solve it on the logging side m
yea, in that case, let's not add the addition message, and solve it on the logging side m
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
ok let me have a look then ;)
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
to avoid extra memory taken by toArray() (it does copy array to new array object), we could create primitive array like: ```java String[] argsWithoutDebugFlags = new String[args.length]; ``` and then copy values in proper index by maintaining running index e.g. ```java int index = 0; for (String arg : args) { ... argsWithoutDebugFlags[index++] = arg; ... } ... return argsWithoutDebugFlags; ```
to avoid extra memory taken by toArray() (it does copy array to new array object), we could create primitive array like: ```java String[] argsWithoutDebugFlags = new String[args.length]; ``` and then copy values in proper index by maintaining running index e.g. ```java int index = 0; for (String arg : args) { ... argsWithoutDebugFlags[index++] = arg; ... } ... return argsWithoutDebugFlags; ```
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Configuration properties must be JavaBean properties (the type must match) and we don't support `Optional` here.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
nit: read lock -> just lock.
The message doesn't really make sense because it's missing the "discovery state" part, right now it says it timed out waiting for initial timeout :)
The message doesn't really make sense because it's missing the "discovery state" part, right now it says it timed out waiting for initial timeout :)
The message doesn't really make sense because it's missing the "discovery state" part, right now it says it timed out waiting for initial timeout :)
oh boy :)
I wonder if `PARSER.declareString((b, v) -> b.sortMode(SortMode.fromString(b), SORTMODE_FIELD);` is better? I kind of prefer it because then you don't need to think about `ValueType`.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
I wonder if `PARSER.declareString((b, v) -> b.sortMode(SortMode.fromString(b), SORTMODE_FIELD);` is better? I kind of prefer it because then you don't need to think about `ValueType`.
not sure if we should make such a big deal out of it
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
Although the code is clear, the level of indirection here makes it hard for the reader to figure out that this (and similar other) test does. As a suggestion, what about combining test_object/test_object_IgnoreMalformed, then the code from `sourceWithObject` can be inlined in the test case. Also I would make the assertion on field1 and field2 explicit, even if that means a few more lines of code. In this case I would trade repetition for readability.
nit: npe is possible here, though state overall won't be ok, but npe is still seems possibe
seems like we use field or fieldName throughout the different processors. Can we settle on the same name for all processors? I think field is enough.
Randomized runner should not need these @Test annotations.
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
I see you've fixed this one in the latest commit. Thanks.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
can we use "script_factor" I think it's nicer than the came case
can we use "script_factor" I think it's nicer than the came case
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
I see you've fixed this one in the latest commit. Thanks.
nit: npe is possible here, though state overall won't be ok, but npe is still seems possibe
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
Randomized runner should not need these @Test annotations.
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
Nit: `getNumConnection` -> `getNumConnections`.
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
nit: extra line
typo - failIfCancled -> failIfCanceled
Traditional how? That it's in 1.x? I don't see why that should stop us from removing it. Doing something like this is wrong: ``` java timer(1, SECONDS, Schedulers.test()) ``` yet it's how you'd use every other static method in this class.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
left over reference to a countdown latch
This isn't thread-safe
typo - failIfCancled -> failIfCanceled
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
Oh, and _nit_ on the unnecessary brackets :)
this should happen after we update `isSecurityEnabledByTrialVersion`
I don't think we should save the state at the end of the job. In fact the indexer should never save any state, this should be done outside of the task. I have a branch that does that but it's not ready yet. In the mean time I think it's fine to just ignore the exceptions thrown by `doSaveState` and just call `onFailure` with the real one (the one thrown by the search/bulk).
I don't think we should save the state at the end of the job. In fact the indexer should never save any state, this should be done outside of the task. I have a branch that does that but it's not ready yet. In the mean time I think it's fine to just ignore the exceptions thrown by `doSaveState` and just call `onFailure` with the real one (the one thrown by the search/bulk).
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I would add an `assert this.context != null` here just to make sure
the start cluster does this.
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
Current web player does not use any API on this host.
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
Can we do this instead (throw an exception)? And just tell the user to use a cidr mask? Supporting "fuzzy" queries on ip addresses seems crazy, and I don't think we should continue this.
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
This should be done in reset()
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
can you just call spliStringToSet with true? why do we need another variant when the method this calls is public
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
can you just call spliStringToSet with true? why do we need another variant when the method this calls is public
can you just call spliStringToSet with true? why do we need another variant when the method this calls is public
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
can you just call spliStringToSet with true? why do we need another variant when the method this calls is public
can you just call spliStringToSet with true? why do we need another variant when the method this calls is public
this check is obsolet - we can just remove it
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
do we do this in other places? I mean using read/WriteByte for enum ordinals? I think there's many many places where we have VInt instead
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
this check is obsolet - we can just remove it
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
just name it `read`
It should now be possible to make up the `RoleArn` and `SecretAccessKey` using the seeded RNG rather than by concatenating strings like this. They can reasonably be different each call.
would you mind adding the same for allocation ids? :+1:
It should now be possible to make up the `RoleArn` and `SecretAccessKey` using the seeded RNG rather than by concatenating strings like this. They can reasonably be different each call.
`file reopened` -> `file is reopened`
should be removed, `PluginInfo#DEFAULT_VERSION` should be made public and used here instead
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
Another `_` java 9 will be mad at
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
Another `_` java 9 will be mad at
should be removed, `PluginInfo#DEFAULT_VERSION` should be made public and used here instead
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
I usually use a ternary for these sorts of random values. I don't usually like ternaries but for things like this I figure it is still pretty readable.
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
Ok, sounds fine.
also this class should be final.
I think the indentation was better before, indicating these lines are a continuation of the try with resources.
I think the indentation was better before, indicating these lines are a continuation of the try with resources.
I think the indentation was better before, indicating these lines are a continuation of the try with resources.
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
Ok, sounds fine.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
why change the semantics here to only call close when setting the tragedy the first time? Let's keep the existing semantics and make `setTragicException` return void
why change the semantics here to only call close when setting the tragedy the first time? Let's keep the existing semantics and make `setTragicException` return void
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This should be done in reset()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
or just: "return ok;"? :)
if we add a null check to the String constructor we can remote this check here given that the parser already looks for the existence of the field too.
I think @bizybot is correct - we probably need some of the failure cases in `ApiKeyService.authenticateWithApiKeyIfPresent` to have a `terminate` status instead of `continue`. If I'm passing an API Key over TLS, then it would be very strange (and hard to debug) if the authentication use the API Key right up until it expired and then suddenly switched to PKI auth.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
ok I am fine with that, not a huge deal
nit: read lock -> just lock.
Although this is some kind of hidden feature, there might be people relying on us following links here... I'd open a separate issue if we want to remove it to give people the chance to speak up if they need it.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
(we just load all files in the `ES_HOME/config/ingest/grok` directory)
This goes away in favour of the version in #18042 I guess.
nit: missing a space after the first comma
We cannot change the signature of a protected method since someone may be overriding it.
seems like we use field or fieldName throughout the different processors. Can we settle on the same name for all processors? I think field is enough.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
can we please unpack the tuple right away instead of using v1 v2? just easier to read
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
aws_ip_ranges -> aws_service_ip_ranges
nit: s/read blob's/read the blob's
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
nit: s/read blob's/read the blob's
nit: s/read blob's/read the blob's
cool stuff - I wonder if we should only add fields to the multimap that are explicitly added like via `add(IndexableField field, String key)` for the most of the field this is not needed at all though.
I think this needs to be wrapped in try/catch so that this doesn't cause a missed invalid line like: ``` 2147483648-:-XX:+TurnOnCatLasers ```
please wrap {}
The SLF4J logging system shouldnât know anything thatâs Log4j2- or Logback-specific. If thereâs a need for the two logging systems to use different bridge handlers then this class should be reworked and the handler logic pushed down into the two system-specific sub-classes.
The SLF4J logging system shouldnât know anything thatâs Log4j2- or Logback-specific. If thereâs a need for the two logging systems to use different bridge handlers then this class should be reworked and the handler logic pushed down into the two system-specific sub-classes.
Ah, okay. Thanks.
nit: s/read blob's/read the blob's
I think @bizybot is correct - we probably need some of the failure cases in `ApiKeyService.authenticateWithApiKeyIfPresent` to have a `terminate` status instead of `continue`. If I'm passing an API Key over TLS, then it would be very strange (and hard to debug) if the authentication use the API Key right up until it expired and then suddenly switched to PKI auth.
nit: s/read blob's/read the blob's
"This class is intended for a single thread use." - can we change this to a more aggressive "This class is NOT thread-safe"? I want to make sure there is no confusion in the future for any other devs using this class
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
You already asserted this 2 lines ago, this is a duplicate.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
Please remove this docstring, it doesn't have any value IMO.
I wonder if this should be a `LinkedHashSet` or similar? Assuming that the ordering is preserved elsewhere, losing it here by switching to a `HashSet` could, in theory, have an effect on the beans that are defined as it'll change the order in which they're processed during refresh.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
This isn't the right fix, it's not a response parameter (it controls the request that the node client sends). Rather, this parameter needs to be consumed (and parsed as a boolean).
```suggestion playbooks to use M(dellemc_pmax_addvolume) module." ```
this file can go back to 140 chars as well...
This isn't the right fix, it's not a response parameter (it controls the request that the node client sends). Rather, this parameter needs to be consumed (and parsed as a boolean).
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
```suggestion playbooks to use M(dellemc_pmax_addvolume) module." ```
Another `_` java 9 will be mad at
If you like, something like this can be redone as `if protocol in ('tftp', 'ftp', 'sftp', 'scp'):`
Can we move these up at the top of the class with the other object variable declarations? I think it is more readable than having them 300 lines down into the class.
Ah sorry missed that
Ah sorry missed that
redundant `public` as mentioned by the gradle checkStyle task
redundant `public` as mentioned by the gradle checkStyle task
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
this getClass() test is not necessary, super.equals already takes care of it
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
It's usually better to use raw-strings for regexps: ```suggestion assert re.match(r'ansible [0-9.a-z]+ .*$', version_lines[0]), 'Incorrect ansible version line in "ansible --version" output' ``` (I'm pretty sure Python 3.6+ will emit warnings if you don't)
I realize the example already here used this form, but I think it is clearer to use `== false` for inverted conditions.
We should tell the use to use `position_increment_gap` in this error message.
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
> We should never rely on the ordinal for any enum anywhere We've been relying on ordinals for serialization for a while, asserting that the ordinals do not change in the tests.
I think this the right trade off here.
The assertions here need to stronger than this.
Randomized runner should not need these @Test annotations.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
For things like fielddata I think it's an important requirement
can we have a shorter name here maybe `forceReadFromFileChannel`
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
sorry, I missed the ping here. I think that 1 is ok too, but then we should in general change the terminology in `IndexShardOperationPermits` to move from the notion of blocking operations to running exclusive operations (similar to a read/write lock).
sorry, I missed the ping here. I think that 1 is ok too, but then we should in general change the terminology in `IndexShardOperationPermits` to move from the notion of blocking operations to running exclusive operations (similar to a read/write lock).
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
I think we want to test index level blocks too here
Since the time unit is ms, we should remove this conversion.
Doesn't actually throw `IOException`.
If it can be done as part of another PR I would like it better :)
If it can be done as part of another PR I would like it better :)
If it can be done as part of another PR I would like it better :)
Probably not the best choice of error type, `InternalError` indicates JVM error, combined with "Null check on a primitive" message might mislead the developer into thinking that something is wrong with bytecode/VM hehe
or just: "return ok;"? :)
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
ok let me have a look then ;)
I think `InternalDateHistogram.NAME` would be a bit better. Now that type isn't used for serialization I'd like to remove it entirely one day.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I think `InternalDateHistogram.NAME` would be a bit better. Now that type isn't used for serialization I'd like to remove it entirely one day.
I think the indentation was better before, indicating these lines are a continuation of the try with resources.
we can just call `terminate(threadPool)` here
we can just call `terminate(threadPool)` here
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
not true anymore
I would also like it better if the side effects of this getDynamicParentMapper were limited to just dynamic field creation, and path management stayed local (so that we keep both the add and remove together in the same method).
++ on debug message
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think they can stay here, until we start using them in other places.. but I'm good with moving if people want to
I think they can stay here, until we start using them in other places.. but I'm good with moving if people want to
I think they can stay here, until we start using them in other places.. but I'm good with moving if people want to
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
`like` -> `likely`
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
I think we have a problem here. The version that is supposed to be supplied as a parameter should only consist of major.minor version like `2.0` (so that all 2.x version go into the same repository) - this one is `2.0.0-beta1` though.
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
oh oh I hadn't read your reply when I replied ;)
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
isn't this the default? just omit in that case.
Great, that solves it then.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
We don't need any of these `build*Properties()` methods; all the kafka specific properties are already handled by parts of `KafkaProperties`.
@jasontedor Thanks. I think `:` is a reserved char on Windows and if used in logging.yml but no node name is configured then it might fail the creation of the log file. But I don't think there's something we can do.
Do we need this? the settings are already immutable
Ok, sounds fine.
or just: "return ok;"? :)
Didn't know about `dematerialize`, then I guess we stick to that convention. Providing a mapper sounds good. Then maybe we could deprecate the current `dematerialize` in Observable.
"should is allowed" doesn't seem to be grammatically correct
Is reversing the order here ( from 'unsub then sub' to 'sub then unsub') going to cause any problems? Thinking about cases where a system/org may be out or almost out of available subs.
This could become: `# IndexError error is used for historical reasons.`
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
I don't think we should be promoting using this feature of scripting. If someone wants this level of control over scores, they should implement their own Similarity; that is its purpose.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I wonder if we can add this (and similar ones) as invariant to the class (similar as was done for ReplicationTracker) we then call `assert invariant()` on each of these methods. For example, one invariant might state that if we are in TRANSLATED state, the executionResult is null.
Same here about multi-line toString methods
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
Should we just hardcode this instead of using `__name__`? Using `__name__` could make this dynamic, as it could be `__main__` or `ansible.utils.display`. We might benefit from just making it `ansible`
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
```suggestion if gql_auth: ```
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
```suggestion if gql_auth: ```
I think there is `LuceneTests.randomSortValue()` that generates random sort values. I wonder if we could use it here.
I think there is `LuceneTests.randomSortValue()` that generates random sort values. I wonder if we could use it here.
I think there is `LuceneTests.randomSortValue()` that generates random sort values. I wonder if we could use it here.
I think there is `LuceneTests.randomSortValue()` that generates random sort values. I wonder if we could use it here.
+1 - And the use of such expression for the JMX stuff always bugged me.
This test should assert that the headers are correct.
This test should assert that the headers are correct.
This test should assert that the headers are correct.
I am ok with what you propose Nik!
You don't like f-strings at all, do you? :-)
You don't like f-strings at all, do you? :-)
You don't like f-strings at all, do you? :-)
You don't like f-strings at all, do you? :-)
You don't like f-strings at all, do you? :-)
You don't like f-strings at all, do you? :-)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
you can use `ExceptionsHelper#rethrowAndSuppress` here
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
derives -> derived
you can use `ExceptionsHelper#rethrowAndSuppress` here
Nit: `active.size()-1` -> `active.size() - 1`
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
did you plan to add here the list of nodes or something? looks like there is a missing argument.
A lot of the instantiations (of the derived classes) in the tests and a few other places that ultimately pass through this constructor use an explicit `-1`.
you can use `ExceptionsHelper#rethrowAndSuppress` here
I think that we need to guard against overflow here!
we need to find a way to keep the headers and context of the original benchmark requests here, when executing the "internal" ones. That might involve recreating the `SearchRequest` via copy constructor passing in the original benchmark request where the headers and context would get copied from.
you can use `ExceptionsHelper#rethrowAndSuppress` here
A simple change to the message can make this assertion fit on one line: ``` diff diff --git a/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java b/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java index 5ccb541..ca172f8 100644 --- a/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java +++ b/core/src/test/java/org/elasticsearch/index/seqno/CheckpointsIT.java @@ -54,8 +54,7 @@ public class CheckpointsIT extends ESIntegTestCase { IndicesStatsResponse stats = client().admin().indices().prepareStats("test").clear().get(); for (ShardStats shardStats : stats.getShards()) { if (shardStats.getSeqNoStats() == null) { - assertFalse("didn't get seq no stats for a primary " + shardStats.getShardRouting(), - shardStats.getShardRouting().primary()); + assertFalse("no seq_no stats for primary " + shardStats.getShardRouting(), shardStats.getShardRouting().primary()); continue; } logger.debug("seq_no stats for {}: {}", shardStats.getShardRouting(), ```
So as far as I see is this is the crucial change in this PR? I was wondering if might have undesired effects that we allow more field value types to be serialized/deserialized than before by using `writeGenericValue`. What would happen for example when fieldValue is a GeoPoint. It would have caused the serialization to trip previously, now it will be okay (and I guess it might cause error later). I guess switching to `writeGenericValue` is a good tradeoff here but would like to hear your ideas about that.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
It might be cleaner and create less new-Function objects if you extract this compute block as a new method, say "newIndexFieldDataCache(fieldName)", then just do `fieldDataCaches.computeIfAbsent(fieldName, this::newIndexFieldDataCache)` here.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Ah yes, thanks!
I think we can get rid of the ResolvedHostname abstraction - what am I missing? ``` diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java b/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java index 61bf1cc..3d3495e 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java @@ -242,40 +242,36 @@ public class UnicastZenPing extends AbstractComponent implements ZenPing { throw new IllegalArgumentException("resolve timeout must be non-negative but was [" + resolveTimeout + "]"); } // create tasks to submit to the executor service; we will wait up to resolveTimeout for these tasks to complete - final List<Callable<ResolvedHostname>> callables = + final List<Callable<TransportAddress[]>> callables = hosts.stream().map(hn -> lookup(hn, transportService, limitPortCounts)).collect(Collectors.toList()); - final List<Future<ResolvedHostname>> futures = + final List<Future<TransportAddress[]>> futures = executorService.invokeAll(callables, resolveTimeout.nanos(), TimeUnit.NANOSECONDS); final List<DiscoveryNode> discoveryNodes = new ArrayList<>(); // ExecutorService#invokeAll guarantees that the futures are returned in the iteration order of the tasks so we can associate the // hostname with the corresponding task by iterating together final Iterator<String> it = hosts.iterator(); - for (final Future<ResolvedHostname> future : futures) { + for (final Future<TransportAddress[]> future : futures) { final String hostname = it.next(); - if (!future.isCancelled()) { + if (future.isCancelled()) { + logger.warn("timed out after [{}] resolving host [{}]", resolveTimeout, hostname); + } else { + assert future.isDone(); // guaranteed by the invokeAll try { - final ResolvedHostname resolvedHostname = future.get(); - if (resolvedHostname.isSuccess()) { - logger.trace("resolved host [{}] to {}", hostname, resolvedHostname.addresses()); - for (final TransportAddress address : resolvedHostname.addresses()) { - discoveryNodes.add( - new DiscoveryNode( - idGenerator.get(), - address, - emptyMap(), - emptySet(), - Version.CURRENT.minimumCompatibilityVersion())); - } - } else { - final String message = "failed to resolve host [" + hostname + "]"; - logger.warn(message, resolvedHostname.failure()); + final TransportAddress[] addresses = future.get(); + logger.trace("resolved host [{}] to {}", hostname, addresses); + for (final TransportAddress address : addresses) { + discoveryNodes.add( + new DiscoveryNode( + idGenerator.get(), + address, + emptyMap(), + emptySet(), + Version.CURRENT.minimumCompatibilityVersion())); } } catch (final ExecutionException e) { final String message = "failed to resolve host [" + hostname + "]"; logger.warn(message, e); } - } else { - logger.warn("timed out after [{}] resolving host [{}]", resolveTimeout, hostname); } } return discoveryNodes; @@ -289,17 +285,11 @@ public class UnicastZenPing extends AbstractComponent implements ZenPing { * @param limitPortCounts the port count limit * @return a callable that can be used to submit to an executor service */ - private static Callable<ResolvedHostname> lookup( + private static Callable<TransportAddress[]> lookup( final String host, final TransportService transportService, final int limitPortCounts) { - return () -> { - try { - return ResolvedHostname.success(transportService.addressesFromString(host, limitPortCounts)); - } catch (final UnknownHostException e) { - return ResolvedHostname.failure(e); - } - }; + return () -> transportService.addressesFromString(host, limitPortCounts); } @Override ```
I think we can get rid of the ResolvedHostname abstraction - what am I missing? ``` diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java b/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java index 61bf1cc..3d3495e 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/UnicastZenPing.java @@ -242,40 +242,36 @@ public class UnicastZenPing extends AbstractComponent implements ZenPing { throw new IllegalArgumentException("resolve timeout must be non-negative but was [" + resolveTimeout + "]"); } // create tasks to submit to the executor service; we will wait up to resolveTimeout for these tasks to complete - final List<Callable<ResolvedHostname>> callables = + final List<Callable<TransportAddress[]>> callables = hosts.stream().map(hn -> lookup(hn, transportService, limitPortCounts)).collect(Collectors.toList()); - final List<Future<ResolvedHostname>> futures = + final List<Future<TransportAddress[]>> futures = executorService.invokeAll(callables, resolveTimeout.nanos(), TimeUnit.NANOSECONDS); final List<DiscoveryNode> discoveryNodes = new ArrayList<>(); // ExecutorService#invokeAll guarantees that the futures are returned in the iteration order of the tasks so we can associate the // hostname with the corresponding task by iterating together final Iterator<String> it = hosts.iterator(); - for (final Future<ResolvedHostname> future : futures) { + for (final Future<TransportAddress[]> future : futures) { final String hostname = it.next(); - if (!future.isCancelled()) { + if (future.isCancelled()) { + logger.warn("timed out after [{}] resolving host [{}]", resolveTimeout, hostname); + } else { + assert future.isDone(); // guaranteed by the invokeAll try { - final ResolvedHostname resolvedHostname = future.get(); - if (resolvedHostname.isSuccess()) { - logger.trace("resolved host [{}] to {}", hostname, resolvedHostname.addresses()); - for (final TransportAddress address : resolvedHostname.addresses()) { - discoveryNodes.add( - new DiscoveryNode( - idGenerator.get(), - address, - emptyMap(), - emptySet(), - Version.CURRENT.minimumCompatibilityVersion())); - } - } else { - final String message = "failed to resolve host [" + hostname + "]"; - logger.warn(message, resolvedHostname.failure()); + final TransportAddress[] addresses = future.get(); + logger.trace("resolved host [{}] to {}", hostname, addresses); + for (final TransportAddress address : addresses) { + discoveryNodes.add( + new DiscoveryNode( + idGenerator.get(), + address, + emptyMap(), + emptySet(), + Version.CURRENT.minimumCompatibilityVersion())); } } catch (final ExecutionException e) { final String message = "failed to resolve host [" + hostname + "]"; logger.warn(message, e); } - } else { - logger.warn("timed out after [{}] resolving host [{}]", resolveTimeout, hostname); } } return discoveryNodes; @@ -289,17 +285,11 @@ public class UnicastZenPing extends AbstractComponent implements ZenPing { * @param limitPortCounts the port count limit * @return a callable that can be used to submit to an executor service */ - private static Callable<ResolvedHostname> lookup( + private static Callable<TransportAddress[]> lookup( final String host, final TransportService transportService, final int limitPortCounts) { - return () -> { - try { - return ResolvedHostname.success(transportService.addressesFromString(host, limitPortCounts)); - } catch (final UnknownHostException e) { - return ResolvedHostname.failure(e); - } - }; + return () -> transportService.addressesFromString(host, limitPortCounts); } @Override ```
The existing code doesn't filter out paths whose `mount` property is `null`, so I don't think we should start doing so as per this test case.
Nit: please add spaces around the `=` sign.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
It would be worth requiring that `jobId` and `jobType` are not `null`.
Yes, I think we should make `Job.Builder::setJobType` `public`. The user could change it if they used the low level REST client.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I don't think it's important for now
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
nit: "an started" -> "a started"
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Are there plans on adding more objects that can manage the disks? if it is only a VM then it may be better to have this be `vm_name` but happy to be convinced otherwise.
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
This is unnecessary.
is this really needed we already have sooo much logging everywhere
Why does this abstract class need to be public? It feels like a complicated implementation detail and I'm wary of adding it to the public API.
Hmm, good point.
Written while holding a lock and read without lock.
This changes behaviour as any exception from the `close()` call will no longer be caught and logged as a warning.
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
can you use try with resource here since we are on java 7 now ie: ``` Java try (CBORParser parser = CborXContent.cborFactory.createParser(content)) { parser.nextToken(); generator.copyCurrentStructure(parser); } ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
Since we have this guard here, should `innerClose` be changed to have ``` java assert !closed; ``` instead of ``` java if (closed) { return; } ```
Since we have this guard here, should `innerClose` be changed to have ``` java assert !closed; ``` instead of ``` java if (closed) { return; } ```
there is a bunch of duplication here so I guess we could at least put the `recycler != null` case in a a single method like ``` Java private <T> T registerNewPage(Recycler.V<T> v, int expectedSize) { cache = grow(cache, page + 1); assert cache[page] == null; cache[page] = v; assert v.v().length == expectedSize return v.v(); } ```
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
Ok, sounds fine.
should be cached thread pool, the default constructor does the right thing here
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
/me is wondering why this one didn't get an @Override annotation while other methods did, is it Intellij's fault? :)
I think this is a tricky place to put this - it doesn't really know what the retry semantics are (that we always retry a full batch). This is why we had the BatchOperationException. If we want to remove it from the "official exception list" (+1 on that), we can still make BatchOperationException dedicated non ElasticsearchException by always rethrowing it's cause.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
At minimum this should be typed (we should have separate script classes for each underlying doc values type), but I would much rather this be built into the script itself, so instead of setting the value, an iterate type call is made, similar to the doc values api.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
maybe just `esVersion()`
At minimum this should be typed (we should have separate script classes for each underlying doc values type), but I would much rather this be built into the script itself, so instead of setting the value, an iterate type call is made, similar to the doc values api.
@jasontedor Thanks. I think `:` is a reserved char on Windows and if used in logging.yml but no node name is configured then it might fail the creation of the log file. But I don't think there's something we can do.
oh, multi-bucket comparisons are ready already? :)
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
I think the message here should be different? Otherwise it is confusing to see the same message, with different endings (one being xcontent, and the other being a java stack trace).
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
There's really no reason to remove that.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
this feels weird to have this here (concerning whether we should delete data of closed indices , on master nodes - I feel this should be made higher up). It is a different change though... (and has nothing to do with your change).
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
I wonder if we should void this check if indexUUID or that.indexUUID is IndexMetaData#INDEX_UUID_NA_VALUE . We can still run into this value when reading existing state files.
This should be done in reset()
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This is logic that I think should go into ReplicatedOperation.
same 1+ randomInt
I think we should increment the term, and log that we've done so.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
`try` and `except` statement seems useless: nothing will raise `KafkaError`.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
can you just leave the constant in this class? There isn't a need to put it in realm imo
can you just leave the constant in this class? There isn't a need to put it in realm imo
can you just leave the constant in this class? There isn't a need to put it in realm imo
can you just leave the constant in this class? There isn't a need to put it in realm imo
or rather pass it to `spawnNativePluginControllers` and change it's signature to `spawnNativePluginControllers(Path pluginPath, Map<String,String> env)` I don't think we need to depend on `Environment`
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
or rather pass it to `spawnNativePluginControllers` and change it's signature to `spawnNativePluginControllers(Path pluginPath, Map<String,String> env)` I don't think we need to depend on `Environment`
lets call `stdinReferences.clear()` after we closed all of them. I also think you should use `IOUtils.close(stdinReferences)` instead, it will close all references even if one close call throws an exception.
lets call `stdinReferences.clear()` after we closed all of them. I also think you should use `IOUtils.close(stdinReferences)` instead, it will close all references even if one close call throws an exception.
can we make the environment variables passed on to this configurable ie. as ctor arguments? I also wonder if the variable should be prefixed with `ES_`
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
it makes it too easy to call delete when its not necessary.
must be param prefixes now
must be param prefixes now
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
can we do this once we check the write is indeed allowed? Also I think it will be clearer if we have this in a dedicated method (`markLastWrite` or something like that)
can we do this once we check the write is indeed allowed? Also I think it will be clearer if we have this in a dedicated method (`markLastWrite` or something like that)
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
It's a sample application so I don't think the performance argument applies here.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
oh boy :)
oh boy :)
And we could then just leave an assert here.
nit: s/final ArrayList<ParentIDFieldMapper>/final List<ParentIDFieldMapper>
oh boy :)
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Good point, I forgot about the pretty printing. `equalToIgnoringWhiteSpace` sounds good.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
The style checker will complain that there's no exception class/tuple (eg, `(ExtractorError, RegexNotFoundError, KeyError, )`). Otherwise you could make all the calls non-fatal and (as appropriate) test for falsity or supply defaults.
You should catch the error twice to produce an error message suitable for each query
You should catch the error twice to produce an error message suitable for each query
You should catch the error twice to produce an error message suitable for each query
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Please fix identation.
Looks like the '--' is not necessary since the variable is not used anymore later on.
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
A lot of the instantiations (of the derived classes) in the tests and a few other places that ultimately pass through this constructor use an explicit `-1`.
oh yeah I missed that :/
I don't think we need the unassignedDelayedShards anymore, right? now that findSmallestDelayedAllocationSetting only takes delayed shards into account.
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
remove this additional line break? :)
remove extra newline
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
Nit: missing `@Override`
can we detect this rather than catching this exception? I'd feel better about it if we could
The `run()` and `call()` methods complicate the signature for me. I deleted the methods and stopped implementing `Action0` and `Runnable` and it still works for me, and is more clear now. I'd prefer not to mix those in with this class as it confuses what is being run where. The `tryDrainAsync` method already allows for async scheduling.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Actually, I think we can do this without a `TemporaryFolder`. We can just write a new file within the `globalTempDir()` that is already available, no need to create a new folder. Also, this should make it possible to merge this new class with the existing `LogginConfigurationTests`.
Actually, I think we can do this without a `TemporaryFolder`. We can just write a new file within the `globalTempDir()` that is already available, no need to create a new folder. Also, this should make it possible to merge this new class with the existing `LogginConfigurationTests`.
That'd be cool! I was hoping something like ``` java Files.write(loggingConf, Arrays.asList( "logger.test: INFO, console", "appender.console.type: console"), StandardCharsets.UTF_8); ``` would be possible. Either way is cool with me.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
That'd be cool! I was hoping something like ``` java Files.write(loggingConf, Arrays.asList( "logger.test: INFO, console", "appender.console.type: console"), StandardCharsets.UTF_8); ``` would be possible. Either way is cool with me.
just name it `readSize`
just name it `read`
I think I'd prefer two tests to test these two paths.
just name it `read`
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
just name it `read`
can't this just be `if (IndexMetaData.isOnSharedFilesystem(indexSettings) == false || closed)`
I think java 9 is going to choke on `_` here, if I recall correctly
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
`o1 +=8;` <== format this file again :)
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
this license change looks wrong
just name it `readSize`
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
last `%version` should be `%major_minor_version`
So I'm thinking of using this in the reindex API which'd make it used inside of Elasticsearch. Taking a ThreadPool is fairly normal for the internals of Elasticsearch. I suppose if you wanted to keep API backwards compatibility then you could make it optional and the whole thing to fail if one isn't provided but a backoff needs it.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
That does not look correct to me.
That does not look correct to me.
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
Not a big deal, I'm fine without it
Not a big deal, I'm fine without it
This has the same issue where multiple threads could wind up âfinishingâ this since done is not rechecked within the synchronized block.
This has the same issue where multiple threads could wind up âfinishingâ this since done is not rechecked within the synchronized block.
Format replacement strings with nothing inside of them, {}, are only available in python-2.7 or better. So you'll need to make sure that all your formats have numbers inside of them. For example, this line would then be: `record_ids = client.get('/domain/zone/{0}/record'.format(domain))`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
super nit: I tend to like validation to be first
Instead of using `IndexWriter` here, you could use `DirectoryReader.listCommits` (there should be at most `IndexCommit` returned) and then call `IndexCommit.getUserData()` instead. Seems safer since `DirectoryReader` cannot do any writing on the index, doesn't acquire the write lock, etc.
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Is this an oversight? `DEFAULT_KEEPALIVE_SETTING.get(settings)`
There is no benefit to wrap these get, post, put, delete methods inside this class. We can just use the api client accessible from this class, and be able to catch the exceptions raised from the ovh python package. This is not possible the way it is now, because all api exceptions are normalized to a less useful OvhApiError
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
alright - didn't see it immeditately
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
where is this method called? Looking into why we have so many different concreteIndices methods here :)
Is there anyway of outputting the name(s) of the fields we couldn't load doc values for here? Probably useful for debugging
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
I'd use an approach from other tests that iterates over the key/values and checks the key is there but not the value.
Same here for `compareAndSet`
Nit: missing `@Override`
Yeah. It can and should wait.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
maybe try with 30 seconds first? 60 is a lot, 30 is a lot already as well....
@sdodsley sounds good, thank you for the clarification
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
at this point you don't need the restClient variable anymore
I think the message here should be different? Otherwise it is confusing to see the same message, with different endings (one being xcontent, and the other being a java stack trace).
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
with the recent changes, I think that you only need the filter above when testing with failures. here and in the other test.
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
I think the unlock calls should always be in a finally block
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
I see, so we wither use the PercolatorQueryRegistry straight-away, real-time, or we go to lucene and do additional things that make the whole thing near real-time. Clear, thanks!
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
It'd be nice to be sure it contained that `not_found` wasn't found.
The score of this query depends on the number of shards, the default similarity, ... To make sure that we have consistent scoring you can use a `function_score` query like the following: ```` QueryBuilder query = functionScoreQuery( termQuery("name", "one"), ScoreFunctionBuilders.fieldValueFactorFunction("my_static_doc_score") ).boostMode(CombineFunction.REPLACE); ```` ... and add the `my_static_doc_score` at indexing time.
I'd switch the order of these so it matches the declaration order.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
or just: "return ok;"? :)
we should escape expectedWarningHeaders, or alternatively unescape when we read.
nit: `an` -> `a`
I think this test can be moved somewhere else and use the single node base class? this doesn't really have a disruption in it and will be slow...
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
boost will be gone once you rebase, same for queryName
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
nit: extra line
maybe just `esVersion()`
Super tiny nit: could we wrap the `SUPPORTED_DATE_METRICS` with brackets (`[...]`)? Makes it easier for the user to see the difference in message and dynamic values. Ditto to below with `unsupportedMetrics`
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
derives -> derived
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
would use currenTimeInMillis here as well, also, shouldn't the order be reversed? (currentTime - startOf)
NIT: noisy reformat :)
We can setup other scenarios to test the cancellation if we remove `updateLeaderGlobalCheckpoint`. For example, make the read limits reached, then cancel, then verify that we won't issue any read request.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This should only be done in close()
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Typo "uncomitted" -> "uncommitted"
Nit: `active.size()-1` -> `active.size() - 1`
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
add some message to the assertions here so it makes more sense than `expected true/false` in case it fails. Can you add an `ElasticsearchAssertions.assertFileExists` (for both `File` and `Path`) and `ElasticsearchAssertions.assertDirectoryExists` as shortcuts, I guess we can reuse that a lot
did you plan to add here the list of nodes or something? looks like there is a missing argument.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think it might makes sense to split this into `initalPosition` and `initialState`.
remove this additional line break? :)
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
I recently used the Script.parse methof in the same way when refactoring the ScriptSortParser, Nik encouraged be to add a static 'parse' method to the Script class that does the wrapping of the potential IOException. This can most likely also be used here.
Might be nice to add a check for existence of these parameters for completeness.
This should be done in reset()
This should be done in reset()
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
This should be done in reset()
This should be done in reset()
`file reopened` -> `file is reopened`
maybe `Objects.equal` could make it easier to read
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
I suggest using an `Action0` here.
I suggest using an `Action0` here.
oh, multi-bucket comparisons are ready already? :)
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
maybe `Objects.equal` could make it easier to read
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
maybe `Objects.equal` could make it easier to read
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
It might be cleaner and create less new-Function objects if you extract this compute block as a new method, say "newIndexFieldDataCache(fieldName)", then just do `fieldDataCaches.computeIfAbsent(fieldName, this::newIndexFieldDataCache)` here.
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I think it might be nice to move this in `TcpHeader`
Right. I figure we should have a test for it or explicitly make the min for that parameter `1`. We have other ways to turn off dynamic scripts if we want so maybe it'd be better not to have two ways to do it.
I think it might be nice to move this in `TcpHeader`
We can single-lined this docstring.
We can single-lined this docstring.
nit: "so we assume"...
We can single-lined this docstring.
can we pass a reason to this method and mention it here? I always to scroll to find out whether this is a "true" index or just one that was created when importing/creating one.
ok...but client depends on the transport service anyway no? I think I don't get it
canceled -> cancelled
can we pass a reason to this method and mention it here? I always to scroll to find out whether this is a "true" index or just one that was created when importing/creating one.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
This does not compile; `FakeRestRequest` does not have a constructor with two arguments. This is a recent change and I think you just missed it when you rebased.
It's super minor, but I think we usually don't include punctuation at the end of exception messages (the `.`)
maybe add which type of section it was, so that it's even safer to get rid of the double exception? That is the only useful bit I find in the original stacktrace that would otherwise get lost.
I think the message here should be different? Otherwise it is confusing to see the same message, with different endings (one being xcontent, and the other being a java stack trace).
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I'm not sure if it's worth the complexity of this code here just to provide a better message as to why an index service got removed. If you think it's useful, maybe factor the logic of determining the `AllocatedIndices.IndexRemovalReason` based on currentState and newState into a helper method so it can be reused by removeIndices
I don't think we should add new settings like this which are unsecured. This and `account` above should be secure settings.
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
hmm can't we use `State.values()` and if this is only used for `fromId` I think we can just do this: ``` Java switch(id) { case RUNNING.id: return RUNNING; //... } ```
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
I'm not sure if it's worth the complexity of this code here just to provide a better message as to why an index service got removed. If you think it's useful, maybe factor the logic of determining the `AllocatedIndices.IndexRemovalReason` based on currentState and newState into a helper method so it can be reused by removeIndices
It wouldn't validate the following: - http://.com - http://. - http://.. - http://../ - http://.www.foo.bar/ - http://.www.foo.bar./ It would indeed validate the following URL (but they are actually valid): - http://example - http://example. All the others are about leading and trailing hyphens, if we really want to filter them out despite the increased complexity then I suggest we break the pattern into multiple variable for readability: https://gist.github.com/386830e46e8d2aca9dcb Regarding formal grammar, it's spread out among a bunch of RFCs, I doubt it's worth the effort.
This lock is unnecessary since the onNext call is not supposed to be invoked concurrently.
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
cool can you update the title of the PR then? :)
Same here for `compareAndSet`
I'm not sure if it's worth the complexity of this code here just to provide a better message as to why an index service got removed. If you think it's useful, maybe factor the logic of determining the `AllocatedIndices.IndexRemovalReason` based on currentState and newState into a helper method so it can be reused by removeIndices
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
It wouldn't validate the following: - http://.com - http://. - http://.. - http://../ - http://.www.foo.bar/ - http://.www.foo.bar./ It would indeed validate the following URL (but they are actually valid): - http://example - http://example. All the others are about leading and trailing hyphens, if we really want to filter them out despite the increased complexity then I suggest we break the pattern into multiple variable for readability: https://gist.github.com/386830e46e8d2aca9dcb Regarding formal grammar, it's spread out among a bunch of RFCs, I doubt it's worth the effort.
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
removeIndex might be good enough here.
I don't think we should go so deep into validation, we opt out from numbers but at the same time we allow the whole unicode range. Unicode numbers like `๑` would happily validate therefore it's an uphill battle. I'd opt for a vastly simplified regex to validate FQDN: `'(?:[a-z0-9\u00a1-\uffff-]+\.?)+'`. Sure it'll let some invalid segments go through (e.g. leading/trailing hyphens) but at least it doesn't pretend of being exhaustive. Proper validation requires a parser anyway.
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
typo: direct**or** -> direct
s/y ou/you Also I think upfront is one word.
something is wrong in this sentence :)
"new" -> "now"
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I think this needs to be ``` settings.put(INITIAL_MASTER_NODE_COUNT_SETTING.getKey(), numSharedDedicatedMasterNodes + (numSharedDedicatedMasterNodes > 0 ? 0 : numSharedDataNodes)); ``` because of the condition further below where we make the shared data nodes data-only nodes when there are dedicated master nodes.
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I think this needs to be ``` settings.put(INITIAL_MASTER_NODE_COUNT_SETTING.getKey(), numSharedDedicatedMasterNodes + (numSharedDedicatedMasterNodes > 0 ? 0 : numSharedDataNodes)); ``` because of the condition further below where we make the shared data nodes data-only nodes when there are dedicated master nodes.
Doesn't actually throw `IOException`.
Doesn't actually throw `IOException`.
seems like we use field or fieldName throughout the different processors. Can we settle on the same name for all processors? I think field is enough.
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
BackpressureUtils didn't exist at that point, so I am considering how to consolidate this type of logic as we keep repeating this type of non-trivial code and it is easy to get wrong. I'm okay with merging ... we really should spend some time figuring out the core patterns so we can encode the state machine, similar to what BackpressureUtils and AbstractOnSubscribe have started formalizing.
I'd not do this, just pass syntactically valid values to the Prototype ctor
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Randomized runner should not need these @Test annotations.
grr nevermind I didn't see the last line pfff...
or N times
Randomized runner should not need these @Test annotations.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
Good point. I'll take care of that once I've merged this PR.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Ah sorry missed that
Ah sorry missed that
Ah sorry missed that
here I'd do the same as above an pass in an some kind of BytesReference factory that can produce new BytesReferences and return a `CompositeBytesReference` instead the `int` to signal how much has been read. We can figure out how to do SSL and stuff afterwards this is too hard to do in one step
Ah sorry missed that
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
Small typo here: Guage -> Gauge.
interesting, what is the reason for this funny upper bound? :)
Does it need to be Writeable? It looks like we only serialize it using JSON.
```suggestion - The repository name. ```
opt for `user` over `username` unless there's a good reason to differ
```suggestion - The repository name. ```
+1 - And the use of such expression for the JMX stuff always bugged me.
SubnetIds expects a list `[result['subnets'][0]]`
actuallt are we sure it's good to just ignore it if field is null? I would rather leave as it was (it throws NPE) and throw IAE ourselves, not much difference though
actuallt are we sure it's good to just ignore it if field is null? I would rather leave as it was (it throws NPE) and throw IAE ourselves, not much difference though
We handle this by temporarily disabling bwc tests. I just pushed the disabling to your branch. Tomorrow I will test the bwc behavior locally before pushing.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
You could actually test this by setting `System.err` to something that records, but it would be a bit much.
We usually use the `ExpectedException` `@Rule` for this to make sure the exception is thrown exactly where it is supposed to. There are plenty of tests that use that stuff in our codebase.
I think we should have just one pool for all job types, and the maximum number of open jobs per node should also relate to _all_ job types. Since the number of threads in the pool is governed by the number of named pipes we create per job we shouldn't need to adjust the thread pool size. However, since people might now want more jobs this might be a good opportunity to implement #29809.
I think you should inline this into `planIndexingAsNonPrimary` then we don't need all the asserts
I think it's good to reuse this threadpool, but it implies that the analytics process is a "job" from the point of view of deciding how many jobs can run on each node. We definitely need to hook these processes into a unified allocation framework. Also, maybe rename the threadpool to `JOB_PROCESS_THREAD_POOL_NAME` or similar.
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
hopefully the `System.nanoTime` goes away once you merge master in.
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
hopefully the `System.nanoTime` goes away once you merge master in.
I meant `node` from the for loop.
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
I think the unlock calls should always be in a finally block
Elasticsearch guarantees that two nodes that have the same major version can talk to each other, so I'm wondering if HDRHistogram has a similar warranty so that upgrading HDRHistogram in a minor Elasticsearch release would not break Elasticsearch's wire protocol.
I'd probably just pass the map rather than close over it.
This `{` block `}` fits the pattern we use elsewhere, but feels unnecessary in this context.
No, I still think that it should not be a method on the `Strings` class.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
update version to beta 1
Great, that solves it then.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
I think the unlock calls should always be in a finally block
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
also this class should be final.
hey can we rename this V1 to ChecksummedTranslogStream
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Key descriptions do not start with "The", "A", etc.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
If this error prevents you from working further on RxJava then do the changes.
This eagerly shuts down the chain and does not wait for the delayed values.
I think you can use `RestClient.SyncResponseListener` here instead
If no obvious solution comes up, let's open an issue to track this for the future.
I see that we need it from another package, I think it's ok.
s/payload is/payloads are
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
I always think of `Iterator` as sitting between two entries rather than on the last entry it returned. But I see your way of thinking and am fine with keeping `current`.
Space missing between `}` and `is`.
Ah ok, right. I understand now. Yes, so we should have to consistent indeed but we need to deprecate them.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
This can be replaced by ` ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser::getTokenLocation);` from `XContentParserUtils`
I think it's still nice to keep the debug logging as we had before.
Missing a space here after `id`
> the original query weight is greater than 1 and that the rescore weight is greater than 0 `query_weight >= 1` is not even necessary anymore now that you changed rescoring to multiply the score of all hits with the query weight
I'd switch the order of these so it matches the declaration order.
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
make this an atomicreference to throwable so we can see what it was in the failure message? (use assertNull)
Do we actually use this anywhere? It seems to only be assigned into.
Do we actually use this anywhere? It seems to only be assigned into.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
This can just be `System.out.print(msg)` now I think. Thanks for removing the formatting from these print apis! I think that was the real problem, its trappy for a `printf()` to be named anything other than `*printf()`. And in this case the caller can just always `String.format` themselves.
I think after closing #19917 we can remove this todo
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
removed? It does not seem to be used.
Like, just for checking that assertions are enabled.
I think it is more idiomatic to statically import the `instanceOf`.
We could get rid of this `== false` by inverting this statement.
please fail if vals.length > 3
We could get rid of this `== false` by inverting this statement.
We could get rid of this `== false` by inverting this statement.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
We could get rid of this `== false` by inverting this statement.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
Can we remove the "ingest_" prefix here? To me this structure should be similar to what we have for: ``` GET /_nodes/stats/indices?filter_path=nodes.**.indices.suggest { "nodes" : { "1S6tILi0QtKdOBVBMXml4Q" : { "indices" : { "suggest" : { "total" : 0, "time" : "0s", "time_in_millis" : 0, "current" : 0 } } } } } ```
we should totally not have this method, one more reason to not implement the interface.
we should totally not have this method, one more reason to not implement the interface.
Can we remove the "ingest_" prefix here? To me this structure should be similar to what we have for: ``` GET /_nodes/stats/indices?filter_path=nodes.**.indices.suggest { "nodes" : { "1S6tILi0QtKdOBVBMXml4Q" : { "indices" : { "suggest" : { "total" : 0, "time" : "0s", "time_in_millis" : 0, "current" : 0 } } } } } ```
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
No need to squash, we can do it on merge.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
Also this isn't available yet, but this might be a good place to make use of the `StepListener` from #37327
nit - an extra d? release**d**Delayed..
It wouldn't validate the following: - http://.com - http://. - http://.. - http://../ - http://.www.foo.bar/ - http://.www.foo.bar./ It would indeed validate the following URL (but they are actually valid): - http://example - http://example. All the others are about leading and trailing hyphens, if we really want to filter them out despite the increased complexity then I suggest we break the pattern into multiple variable for readability: https://gist.github.com/386830e46e8d2aca9dcb Regarding formal grammar, it's spread out among a bunch of RFCs, I doubt it's worth the effort.
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
lets skip the guard - not perf critical and gets called more often then
last parameter can be set to from.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
You can use end instead of `out.position()` here.
You can use end instead of `out.position()` here.
You can use end instead of `out.position()` here.
You can use end instead of `out.position()` here.
You can use end instead of `out.position()` here.
You can use end instead of `out.position()` here.
I think that I found complex solution for all binary operators in `MySQL` that return an unsigned 64-bit integer. We can simple convert return value to `SIGNED` integer. I don't know why, but it doesn't work for right shift operator. ```diff --- a/django/db/backends/mysql/operations.py +++ b/django/db/backends/mysql/operations.py @@ -202,8 +202,14 @@ class DatabaseOperations(BaseDatabaseOperations): + lhs, rhs = sub_expressions if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) + # MySQL's binary operators return an unsigned 64-bit integer. + elif connector in ['<<', '|', '&']: + return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) + elif connector == '>>': + return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs} return super(DatabaseOperations, self).combine_expression(connector, sub_expressions) ```
```suggestion ({b'str'.encode(DEFAULT_ENCODING): b'str'.encode(DEFAULT_ENCODING)}, {u'str': u'str'}), ```
You might want to use `type=ip_network` (then add from `ansible.module_utils.compat.ipaddress import ip_network`) for `ip_range`, in order to validate the value before using it. (value of `type` parameter can be a callback).
please don't use two letter variables names for acronyms.
please don't use two letter variables names for acronyms.
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
maybe just `esVersion()`
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
same here - I think it's better to log the info message if the deletion was successful.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
maybe just `esVersion()`
maybe just `esVersion()`
maybe just `esVersion()`
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
maybe just `esVersion()`
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
(Not part of this, just asking hypothetically)
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
this is a personal preference, I like to avoid overriding the setup and teardown methods of estestcase and use separate one
this is a personal preference, I like to avoid overriding the setup and teardown methods of estestcase and use separate one
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
paramlist needs to be instantiated before this line. Then after the loop len(terms) should be compared to the length of results. Also [line 172](https://github.com/ansible/ansible/pull/35569/files#diff-55e80dc4588cb031afcf2736c1338c47R172) should be removed or the 'return None' replaced with a continue
`of the it's last` -> `of its last`
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
paramlist needs to be instantiated before this line. Then after the loop len(terms) should be compared to the length of results. Also [line 172](https://github.com/ansible/ansible/pull/35569/files#diff-55e80dc4588cb031afcf2736c1338c47R172) should be removed or the 'return None' replaced with a continue
This doesn't allow the caller to cancel downtime by scope. _get_downtime returns an empty dictionary when id is not specified. It'd be great if this was changed to require id or scope instead of just id.
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
you can do some streaming java8 magic here.
`. Delete it if there` -> `so we delete it if they exist`
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
`file reopened` -> `file is reopened`
`of the it's last` -> `of its last`
Key descriptions do not start with "The", "A", etc.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
You should be able to use the "default" constant you defined here so the test will still pass if it's changed in the future.
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
remove this additional line break? :)
remove this additional line break? :)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
nit: should be "commit_ting_ writer with commit data"
++ on removing this catch. Not true any more
When I see this, I am now happy that wait is a forbidden API. :-)
I think we might miss some responses in case of onFailure() because it will be using responses created [here](https://github.com/s1monw/elasticsearch/blob/issues/5766/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java#L94)
The assert message should be `https` not `http`!
Nitpicking: The current migration output uses both `('app_label', 'migration_name')` and `app_label.migration_name` scattered all over the place. I'll open a ticket to use the dot-notation across the board which I find easier to read / write. In the mean time I'd use that format here already.
I think it would be more portable to update the regular expression below rather than using `grep`
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I'd probably keep the old signature of this method and do the set construction above.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Sorry I wasn't explicit, I meant create a GH issue and link here.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
I doubt this util from spring-kafka is acceptable in Spring Boot code. See other similar auto-configuration classes which use something like this: `PropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull();` The `IntegrationAutoConfiguration` is good one to look into.
This should only be done in close()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
same here: I'd like to keep the version using `generateParser` since its the same as in master.
The name of the method seems to explain where it's expected to be called from. I wonder if that is necessary.
I am glad we simplified things by just renaming id to tag, that's a good choice
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
single line here is okay (lines up to 119 chars are fine when it improves readability)
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
The name of the method seems to explain where it's expected to be called from. I wonder if that is necessary.
Another here, warning for cost for logging :)
Is this really needed ? Why not keeping the original `build(QueryShardContext context)` ? Custom QueryBuilder have the same signature for the build function and the `QueryShardContext` does not expose too many things like the `SearchContext` so it should not be a problem to expose this in a plugin.
Since the account settings are supplied by user, I would feels better if we used URI to build this string. This way we will have at least some basic validation of the things that go into this URL.
nit: extra line
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
I Am concerned that we will miss the actual message because its wrapped, my vote is the detailed message one
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
lets' introduce a dedicated exception for this. We can upgrade discovery.zen.NotMasterException to be in the cluster package and use that.
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
This can be `UnaryOperator` instead of `Function`.
The current comparison is completely legal, same as Java 7's Objects.equals(). Why did you swap the variables? Implementation of equals should be symmetric: a.equals(b) == b.equals(a).
I wonder if we want to rename this one to avoid confusion.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
can we use Pattern.qoute for the prefix? just being paranoid..
I think we should also check the taskId here
can we use a limit variable that looks like `int limit = indexMetaData.numberOfReplicas() + 1; // one for the primary` and then bound the loop with `<` instead of `<=` it took me a while :)
I still feel like there ought to be a way to make these methods look less copy-and-paste-ish. They just set off my copy-and-paste blindness even though they aren't copied and pasted.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
I realize the example already here used this form, but I think it is clearer to use `== false` for inverted conditions.
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Remove and create again is not needed I think
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
I'm not sure I see a good use case for it. In any case, this check could be relaxed (or moved to the outer `get_response`, outside the middleware chain) later as a separate change (maybe after the old middleware system is gone, which would reduce the complexity of the change).
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
If I change the name of the property source to be something else than this, the test fails. The `PropertySource` implementation and its name are irrelevant for this, it could be anything.
Builin -> Builtin (forgot a 't')
I have the same thoughts as above for commit time.
Should really ask for `toString()`s on these handlers too, although this adds noise.
Okay, I guess that's a good enough reason.
Builin -> Builtin (forgot a 't')
I have the same thoughts as above for commit time.
super nit: I tend to like validation to be first
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
space between `if` and `(`
maybe, to be more precise, it would be good to check the partition that included the new primary.
Good for me, I didn't have a strong feeling about it.
nit: space after IOException
minor typo - "indexes shards lock" -> "shard locks"
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
`Description` -> `Descriptor`
`Description` -> `Descriptor`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think that I found complex solution for all binary operators in `MySQL` that return an unsigned 64-bit integer. We can simple convert return value to `SIGNED` integer. I don't know why, but it doesn't work for right shift operator. ```diff --- a/django/db/backends/mysql/operations.py +++ b/django/db/backends/mysql/operations.py @@ -202,8 +202,14 @@ class DatabaseOperations(BaseDatabaseOperations): + lhs, rhs = sub_expressions if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) + # MySQL's binary operators return an unsigned 64-bit integer. + elif connector in ['<<', '|', '&']: + return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) + elif connector == '>>': + return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs} return super(DatabaseOperations, self).combine_expression(connector, sub_expressions) ```
`BeanUtils.instantiateClass` will create the instance and throw a `BeanInstantiationException` on error.
I think that I found complex solution for all binary operators in `MySQL` that return an unsigned 64-bit integer. We can simple convert return value to `SIGNED` integer. I don't know why, but it doesn't work for right shift operator. ```diff --- a/django/db/backends/mysql/operations.py +++ b/django/db/backends/mysql/operations.py @@ -202,8 +202,14 @@ class DatabaseOperations(BaseDatabaseOperations): + lhs, rhs = sub_expressions if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) + # MySQL's binary operators return an unsigned 64-bit integer. + elif connector in ['<<', '|', '&']: + return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) + elif connector == '>>': + return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs} return super(DatabaseOperations, self).combine_expression(connector, sub_expressions) ```
I think that I found complex solution for all binary operators in `MySQL` that return an unsigned 64-bit integer. We can simple convert return value to `SIGNED` integer. I don't know why, but it doesn't work for right shift operator. ```diff --- a/django/db/backends/mysql/operations.py +++ b/django/db/backends/mysql/operations.py @@ -202,8 +202,14 @@ class DatabaseOperations(BaseDatabaseOperations): + lhs, rhs = sub_expressions if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) + # MySQL's binary operators return an unsigned 64-bit integer. + elif connector in ['<<', '|', '&']: + return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) + elif connector == '>>': + return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs} return super(DatabaseOperations, self).combine_expression(connector, sub_expressions) ```
I think the unlock calls should always be in a finally block
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Ok, sounds fine.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Ok, sounds fine.
`of the it's last` -> `of its last`
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Ok, sounds fine.
Great, that solves it then.
In the two methods above, I think you should get a local copy of the immutable map so that it cannot get null between the null check and the call to isEmpty/get
hmm can't we use `State.values()` and if this is only used for `fromId` I think we can just do this: ``` Java switch(id) { case RUNNING.id: return RUNNING; //... } ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Like, just for checking that assertions are enabled.
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
this check is obsolet - we can just remove it
this check is obsolet - we can just remove it
this check is obsolet - we can just remove it
this check is obsolet - we can just remove it
I would be using a `Set` in this circumstances.
Apparently @s1monw prefered the reverse. I'm fine with leaving as is.
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
In the two methods above, I think you should get a local copy of the immutable map so that it cannot get null between the null check and the call to isEmpty/get
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
this method is dangerous as it wrong usage leads to re-resolving all the time. Maybe just remove it and do the `resolveSnapshotId` in TransportDeleteSnapshotAction
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
nit: shard routing already has [] in it's toString
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
In the two methods above, I think you should get a local copy of the immutable map so that it cannot get null between the null check and the call to isEmpty/get
Ok, sounds fine.
oh right sorry I had missed it's a single value for these processors. sounds good.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
The linger time for a socket is very different to the time it'll wait for a connection before being closed. When the socket is closed, the linger time causes the socket to block waiting for acknowledgement of the close from its peer.
can we add some trace logging here? I can imagine it will save some WTF at some point.
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
can we add some trace logging here? I can imagine it will save some WTF at some point.
You're right. I prepared separate PR #7787.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Consider making this an `||` and having it lazily fail on use (or moving the on-use exception to the constructor and fail fast) due to a misconfiguration.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
it would be awesome to have some doc-strings on these settings
good catch on delta > 0
this needs to be fixed before merging (as it should go to 5.2.1).
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
oh cool the read is in the ctor! nice!
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
I don't think that complexity is warranted. Just keep constructor injection please.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Else right after a return makes me sad. I'm not sure I have a good reason to think that way, but I do.
Please import only what you need, rather than `*`
Typo here, "Trasnlog" -> "Translog"
Maybe this one too, I'm not sure.
I see that we need it from another package, I think it's ok.
Maybe this one too, I'm not sure.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
+1 to throwing the exception.
+1 to throwing the exception.
Not sure about this parameter name (`trackingRemoteClusters`).
This one is `false` but the one above is `true`. I'd prefer both to be `true`.
Same as above, reference equality shortcut would probably fit here as well.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
> Is there a different way we can handle this altogether? That's what I'm going to be thinking about.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
Not sure about this parameter name (`trackingRemoteClusters`).
Again missing units :(
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I'm doing buffer now and they all emit buffered data in case of onError.
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Do not need the enumerate here. i is not used.
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
this case got lost
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
For backporting to 6.3, I think this needs to be changed to 7.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
I am ok with what you propose Nik!
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
always do these things with nano time. Also the logic here is the reverse - we want to keep up to 10K items, UNLESS they are too recent. Which makes me think that the default _minimum_ expiration time can be 48 hours.
Again missing units :(
I wonder if using fromSeq and toSeqNo (instead of size) will result in this being less confusing.
Can we fold all these assertions into a single one? I think this should cover enough. ``` assertThat(shardChangesRequests, contains(new long[][]{ {0L, 8L}, {9L, 8L}, {18L, 8L}, {27L, 8L}, {36L, 8L}, {45L, 8L}, {54L, 8L}, {63L, 8L} })); ``` Moreover, the leader should not return more than the requesting batch size. Here, we request 8 operations, but it returns 9 operations.
this test is about timeouts, right? feels unnatural to throw a normal exception here. You can also rename to the test to say "handle exceptions" and check all exception are handled correctly (timeout or thrown) - imho a deidcate non-timed out error is better (i.e., it tests it returns immediately and not after a short timeout).
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
can we check here if the listener is done? (just checking if I got it right this time :))
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
I think this the right trade off here.
For things like fielddata I think it's an important requirement
I think we should return active.get() == false and also - set it if we became idle...
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
Change "param required" to "parameters are required"
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
For things like fielddata I think it's an important requirement
s/y ou/you Also I think upfront is one word.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I don't think it's messy, just wanted to make sure.
I find this API name non-obvious, asked 4 team members "what such method could do in their opinion" and only one had assumption that it may hold stacktrace, others assumed that it's some instrumentation api for RxJava scheduler workers. My options at the moment are: - `Schedulers.collectStacktraces()` - `Schedulers.trackStacktraces()` - `Schedulers.keepStacktraces()`
I think @bizybot is correct - we probably need some of the failure cases in `ApiKeyService.authenticateWithApiKeyIfPresent` to have a `terminate` status instead of `continue`. If I'm passing an API Key over TLS, then it would be very strange (and hard to debug) if the authentication use the API Key right up until it expired and then suddenly switched to PKI auth.
What do you think of: ``` private void handleReadResponse(long from, int maxOperationCount, long maxRequiredSeqNo, ShardChangesAction.Response response) { maybeUpdateMapping(response.getIndexMetadataVersion(), () -> { synchronized (ShardFollowNodeTask.this) { globalCheckpoint = Math.max(globalCheckpoint, response.getGlobalCheckpoint()); final long newMinRequiredSeqNo; if (response.getOperations().length == 0) { newMinRequiredSeqNo = from; } else { assert response.getOperations()[0].seqNo() == from : "first operation is not what we asked for. From is [" + from + "], got " + response.getOperations()[0]; buffer.addAll(Arrays.asList(response.getOperations())); final long maxSeqNo = response.getOperations()[response.getOperations().length - 1].seqNo(); assert maxSeqNo== Arrays.stream(response.getOperations()).mapToLong(Translog.Operation::seqNo).max().getAsLong(); newMinRequiredSeqNo = maxSeqNo + 1; // update last requested seq no as we may have gotten more than we asked for and we don't want to ask it again. lastRequestedSeqno = Math.max(lastRequestedSeqno, maxSeqNo); assert lastRequestedSeqno <= globalCheckpoint: "lastRequestedSeqno [" + lastRequestedSeqno + "] is larger than the global checkpoint [" + globalCheckpoint + "]"; coordinateWrites(); } if (newMinRequiredSeqNo < maxRequiredSeqNo) { int newSize = (int) (maxRequiredSeqNo - newMinRequiredSeqNo) + 1; LOGGER.trace("{} received [{}] ops, still missing [{}/{}], continuing to read...", params.getFollowShardId(), response.getOperations().length, newMinRequiredSeqNo, maxRequiredSeqNo); sendShardChangesRequest(newMinRequiredSeqNo, newSize, maxRequiredSeqNo); } else { // read is completed, decrement numConcurrentReads--; if (response.getOperations().length == 0 && globalCheckpoint == lastRequestedSeqno) { // we got nothing and we have no reason to believe asking again well get us more, treat shard as idle and delay // future requests LOGGER.trace("{} received no ops and no known ops to fetch, scheduling to coordinate reads", params.getFollowShardId()); scheduler.accept(idleShardChangesRequestDelay, this::coordinateReads); } else { coordinateReads(); } } } }); } ``` PS - note the difference in handling of `lastRequestedSeqno` - I think the way you had it had a bug.
I am ok with what you propose Nik!
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Consider making this an `||` and having it lazily fail on use (or moving the on-use exception to the constructor and fail fast) due to a misconfiguration.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
this file can go back to 140 chars as well...
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
afaics, all accesses to listeners are under lock, but I may miss something.
hopefully the `System.nanoTime` goes away once you merge master in.
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
I think it might be nice to move this in `TcpHeader`
`file reopened` -> `file is reopened`
Please add `@Experimental`
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
good catch! that means we are not properly testing this case either given that we didn't catch it.
`file reopened` -> `file is reopened`
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
This could become a `Map<String, String>` and remain as `SHUTDOWN_MESSAGE`
I've noticed this field isn't in 6.x so please remove from the backport
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
I think this can all fit on one line more cleanly if you break after the equal sign.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
can we detect this rather than catching this exception? I'd feel better about it if we could
I think this can all fit on one line more cleanly if you break after the equal sign.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
Nit: it isn't a jsonBuilder - it is whatever kind of xcontent was passed in. Nit: maybe only set prettyPrint if the original had it set? I don't know if you can tell though. Neither are a big deal.
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
isn't enough to have another waitForEvents to make sure that the previous event was successfully published? I really think we shouldn't have this time based solution. 10s makes me shudder :)
isn't enough to have another waitForEvents to make sure that the previous event was successfully published? I really think we shouldn't have this time based solution. 10s makes me shudder :)
++ on debug message
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
don't prettyprint please we don't test this here
Here again I think we should use `builder.timeField` to handle this
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
update version to beta 1
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
This will close the `ServerSocketChannel` before it can be used by the `ServerThread`. The channel is eventually closed when the thread is closed so this change is unnecessary. I'll address this when merging.
Why use a static block to initialise this? `Sets.newHashSet` can turn this into a 1 liner, and then you can wrap it in `unmodifiableSet`
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
fillResponse can throw an already closed exception. We should make sure we deal with exceptions here correctly
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
We also need a simple rest test, testing integration like we have for the other processors
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
fillResponse can throw an already closed exception. We should make sure we deal with exceptions here correctly
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
We also need a simple rest test, testing integration like we have for the other processors
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think `InternalDateHistogram.NAME` would be a bit better. Now that type isn't used for serialization I'd like to remove it entirely one day.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
This isn't needed client-side.
new ArrayList<String>() => new ArrayList<>()
nit: extra line
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
new ArrayList<String>() => new ArrayList<>()
new ArrayList<String>() => new ArrayList<>()
These look like leftovers.
I see what your are saying but I donât think we can rely on this. The nanoTime() is not guaranteed to actually have nano precision (just resolution). it is only guaranteed to never go backâ¦ > On 29 Jun 2015, at 10:39, Masaru Hasegawa notifications@github.com wrote: > > In core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStateTest.java: > > > @@ -154,7 +154,7 @@ public void run() { > > if (randomBoolean()) { > > timer.stop(); > > assertThat(timer.stopTime(), greaterThanOrEqualTo(timer.startTime())); > > - assertThat(timer.time(), equalTo(timer.stopTime() - timer.startTime())); > > - assertThat(timer.time(), lessThanOrEqualTo(timer.stopTime() - timer.startTime())); > > I think lessThanOrEqualTo is correct. (because it's rounded down to nearest decimal value) > > If we use nano seconds, when start time is 1ns and stop time is 1000000ns (1ms), time() would be 99999ns but it's 0ms because of TimeValue.nsecToMSec. > But if we use milliseconds, above becomes 1ms - 0ms = 1ms. In this case, time() < stop() - start(). > When start time is 1ns (0ms) and stop time is 1999999ns (1ms), it's 1999998ns but time() will be 1ms and stop() - start() = 1ms. > > That's said, I like time() > 0 since it makes it simpler. > > â > Reply to this email directly or view it on GitHub.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
that awfully sounds like two voices for debug.... your turn, @jasontedor.
I'd not do this, just pass syntactically valid values to the Prototype ctor
I think it would be better to do something like `return "[" + new BytesRef(ranges, 0, BYTES) + " TO " + new BytesRef(ranges, BYTES, BYTES) + "]";`
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
e.g. I think this should either be a warning or an error.
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
this could be static
isn't enough to have another waitForEvents to make sure that the previous event was successfully published? I really think we shouldn't have this time based solution. 10s makes me shudder :)
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
The method name implies yellow though. I bet there are places where we don't _need_ green.
The method name implies yellow though. I bet there are places where we don't _need_ green.
s/HashMap<String, Object> fields/Map<String, Object> fields
s/HashMap<String, Object> fields/Map<String, Object> fields
s/HashMap<String, Object> fields/Map<String, Object> fields
I think we can remove this
can `aliases` be final as well
same here - just pass a new instance
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
Should really ask for `toString()`s on these handlers too, although this adds noise.
Should really ask for `toString()`s on these handlers too, although this adds noise.
oh yeah I missed that :/
oh yeah I missed that :/
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
we should start thinking about testing the parsing phase for things that we never output from doXContent.... :)
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
It'd be more helpful to me if these notes were on the method if we're going to mix them together like this. Another option would be to have two interfaces implemented by one class. I'm not sure that helps at all.
It'd be more helpful to me if these notes were on the method if we're going to mix them together like this. Another option would be to have two interfaces implemented by one class. I'm not sure that helps at all.
why is this public? it's only used internally, right
when do not want to do it (and throw an exception as said above)
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
when do not want to do it (and throw an exception as said above)
when do not want to do it (and throw an exception as said above)
same here- I think this should be a hard exception.
`scheduler` has no effect here...
I think it's in the right place here.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
hopefully the `System.nanoTime` goes away once you merge master in.
I find this API very awkward since it's available on every type but should only be used on `Single<Notification<T>>`. I don't have a better suggestion though. Except defining it yourself and using a Kotlin extension function.
Please change it to `only one thread should call`, remove `be allowed to`.
I am confused. Is that streams specific? Yet this property doesn't indicate that's the case.
Not sure if we need to do that it's just one entry per field though.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
Not sure if we need to do that it's just one entry per field though.
thanks a lot! should we have a test that leverages this extension point for score functions? I thought we had one already but not sure anymore
thanks a lot! should we have a test that leverages this extension point for score functions? I thought we had one already but not sure anymore
thanks a lot! should we have a test that leverages this extension point for score functions? I thought we had one already but not sure anymore
This should be the last step
Not sure if we need to do that it's just one entry per field though.
Not sure if we need to do that it's just one entry per field though.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
Personally I'd make this an interface that has a static method that returns an implementation that makes the `HeapBufferedAsyncResponseConsumer`. I'm not super comfortable with the no-arg ctor for `HeapBufferedAsyncResponseConsumer` because it sort of pushes you not to think about the buffer's maximum size.
nit: please use lowercase start for variable names
master is now Django 1.8 so we start the deprecation now and remove it in two release which will be Django 2.0
master is now Django 1.8 so we start the deprecation now and remove it in two release which will be Django 2.0
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
thanks for digging in. i only dug into the aws one and have not looked at the root case of the gce problems. If it involves weakhashmaps, maybe its something easy we can fix for them as well to avoid pain.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
Is this wrap+indent intentional? took me a second to figure out what was going on
Is this wrap+indent intentional? took me a second to figure out what was going on
If no obvious solution comes up, let's open an issue to track this for the future.
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
`limitedTo(long bytes)`? Clone is kinda non-specific.
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
You could also (if you don't want to use the `useOrSuppress` above, just collect the exceptions into a list and use `ExceptionsHelper.maybeThrowRuntimeAndSuppress(listOfExceptions);` without the `if` statement
This is no longer used, could be removed
good catch on delta > 0
For all of these find calls, you can use `in` operator instead: if '(On branch %s' % branchName) not in s:
Feel free to ignore me here but `get_*_coverage_files()` is common between python and powershell, you could just have the 1 function and have ``` def _get_coverage_files(language): coverage_dir = ResultType.COVERAGE.path coverage_files = [os.path.join(coverage_dir, f) for f in os.listdir(coverage_dir) if '=coverage.' in f and ('=%s' % language) in f] return coverage_files def get_python_coverage_files(): return _get_coverage_files('python') def get_powershell_coverage_files(): return _get_coverage_files('powershell') ```
For all of these find calls, you can use `in` operator instead: if '(On branch %s' % branchName) not in s:
For all of these find calls, you can use `in` operator instead: if '(On branch %s' % branchName) not in s:
I'd rename this method to `writeRandomBlob()` since this is generating random data and writes it to the container
Is there a reason to change the signature of this method? This is unrelated to this PR so I'd like this to be reverted.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
I don't think that's what I had in mind. What we need to do here is check if "NONE" is active and change the description accordingly.
we can remove the bound (AllocationCommand) and make this a top-level class `FromXContent` (dual to `ToXContent`). There are also other places that could implement this new interface (e.g. ContextMapping, MetaData.Custom, ...).
Hi @Qathos! Thank you for the review and @mirmali will remove those in v2. I asked him to push v2 today so that we can get all green. Thank you for your support!
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
can this see `unregister task for id: [{}]`
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
IMHO it's an antipattern when you catch everything wholesale. You mask future bugs this way.
This isn't thread-safe
thanks for adding this
for the line wrap can you split it right before `List<String`? I find this easier to read
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Missing a `@since`. I wonder if that wouldn't be something of interest for the library (ping @jkschneider)
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
From the top of my head no, but I will keep it in my mind to change those when I see them.
Yes I think so.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
I think you can initialize the capacity.
I think we should collapse the two above methods, they are always called in sequence.
How about you install a custom hook to the current thread from the `onError` handler that will rethrow the original exception: ```java import java.io.IOException; import java.lang.Thread.UncaughtExceptionHandler; import org.junit.*; import io.reactivex.Observable; import io.reactivex.plugins.RxJavaPlugins; public class HookThrowing { @Before public void before() { RxJavaPlugins.setErrorHandler(ex -> { UncaughtExceptionHandler h = Thread.currentThread().getUncaughtExceptionHandler(); Thread.currentThread().setUncaughtExceptionHandler((t, e) -> { Thread.currentThread().setUncaughtExceptionHandler(h); HookThrowing.sneakyThrow(ex); }); throw new RuntimeException("Fail up"); }); } @SuppressWarnings("unchecked") static <E extends Throwable> void sneakyThrow(Throwable ex) throws E { throw (E)ex; } @After public void after() { RxJavaPlugins.reset(); } @Test public void test() { Observable.error(new IOException()) .subscribe(); } } ```
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
nit: "so we assume"...
I think `InternalDateHistogram.NAME` would be a bit better. Now that type isn't used for serialization I'd like to remove it entirely one day.
I like this simplification!
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Randomized runner should not need these @Test annotations.
This application doesn't do anything if you run it with an existing broker.
I think you can use `RestClient.SyncResponseListener` here instead
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think it's in the right place here.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
did you plan to add here the list of nodes or something? looks like there is a missing argument.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
Nit: `initializing.size()-1` -> `initializing.size() - 1`
Nit: `active.size()-1` -> `active.size() - 1`
did you plan to add here the list of nodes or something? looks like there is a missing argument.
Nit: `active.size()-1` -> `active.size() - 1`
can't we just call this feature `trim`? `trim` personally makes more sense to me.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
`describe` and `get` methods are almost the same: a refactor is possible.
remove this additional line break? :)
`describe` and `get` methods are almost the same: a refactor is possible.
`''.join(self.topic)` could be replaced with `self.topic[0]` (here size of `topic` is always 1). DONE
can you just leave the constant in this class? There isn't a need to put it in realm imo
can you just leave the constant in this class? There isn't a need to put it in realm imo
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
I think we should leave this method for java api bw comp
This will fail if `(int)((end - start)/bucketSpan)` is greater than 10000. A check should be added elsewhere to ensure that the window is small enough that this won't happen.
I think we should leave this method for java api bw comp
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
It's super minor, but I think we usually don't include punctuation at the end of exception messages (the `.`)
Please fix identation.
Please fix identation.
Please fix identation.
You can make the whole PR a lot simpler by using: `for fname in sorted(files)[start : stop]` Remember: this feature should only total a few lines of change. The only "logic" required by this PR is the computation of `start` and `stop` above given the `validation_split` passed by the user (if any).
I don't think you need @Before here, the parent method already has it.
Perhaps open a separate pr for the change to this method? This adds additional validation outside concrete index to data stream lookup.
should we use a long just to be on the paranoia side of things
s/write target file {0}/put_file to {0}/
I don't think you need to this, the internal cluster will call the node settings automatically.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
please log the exception here as well we really wanna see what was going wrong
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
minor nit: "int he" -> "in the"
This duplication isn't to my taste - I think I'd try and pull the notion of "doc" out into a class of its own and have this kind of thing be methods there.
thank you for renaming this.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
I think it'd be useful to see the filenames in the exception message.
I think its worth it? most of the time the response handle is SAME, so its not a big problem, but it allows to not overflow the same thread pool if it happens
maybe it's nicer to just capture the `DiscoveryNode` object here and use `equals` on that (internally it will use the ephemeral id for comparison anyhow).
newline, no need for `throws EngineException`
++ on error
I think we should do this in a `AccessController.doPrivileged` block since we need a special permission to modify threadgroup. It's good to respect that since we use this in reindex etc. as well
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
we decided to live on the edge and have fun. The concern was around non ascii codes breaking tooling but CI seems happy. Let's see how far we get.
Fine by me.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
Remove if/else by `in.readOptionalWriteable(Snapshot::new)`
please wrap {}
I think that we can save the instanceof checks, builder.value(Object) does it already
Oh nevermind, `CodecUtil.checkHeader` is already doing the real check. You really do not trust anyone ;)
Answering my own question: you build the array to simulate the task being on all of the simulated nodes. I don't know that that is required here but doesn't hurt anything.
Oh nevermind, `CodecUtil.checkHeader` is already doing the real check. You really do not trust anyone ;)
Answering my own question: you build the array to simulate the task being on all of the simulated nodes. I don't know that that is required here but doesn't hurt anything.
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
This is great! No more @Inject!
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
This should be done in reset()
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
I am not sure why you changed this.
nit: space after IOException
I have the same thoughts as above for commit time.
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
++ on debug message
++ on debug message
Missing a space here after `id`
should be ThreadedActionListener<>
You can use a for-each syntax here: `for (ObjectCursor<byte[]> cursor : bytesList)`
errors should go to stderr, you can just use sys.exit('message") to do both in one statement
The `isInternal` data member hasn't been removed - is it correct to remove it here? (If it is for some reason then it should also be removed from `hashCode()`.)
I think you are missing a `\n` here.
Not related to this PR but I think that we should check if what we are trying to remove is not part of the BLACKLIST. Someone could potentially provide a plugin which contains his own `bin/elasticsearch` script, which looks scary to me.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think you are missing a `\n` here.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
The linger time for a socket is very different to the time it'll wait for a connection before being closed. When the socket is closed, the linger time causes the socket to block waiting for acknowledgement of the close from its peer.
The linger time for a socket is very different to the time it'll wait for a connection before being closed. When the socket is closed, the linger time causes the socket to block waiting for acknowledgement of the close from its peer.
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
I wonder if we should extend `ChannelReference` to implement `Closeable` and have the `.close()` method decrement the ref and throw an error if it's not now at 0 (which it should be since it's being closed in this case). That way we error immediately if the translog is closed but something incremented the channel ref. What do you think of this? Dunno if you think it might make ChannelReference too complex.
I wonder if we should extend `ChannelReference` to implement `Closeable` and have the `.close()` method decrement the ref and throw an error if it's not now at 0 (which it should be since it's being closed in this case). That way we error immediately if the translog is closed but something incremented the channel ref. What do you think of this? Dunno if you think it might make ChannelReference too complex.
Please revert to `== false`. This is used throughout the Elasticsearch codebase as a more visually abrupt form of negation to not be easily overlooked.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
I think s/lang/defaultLang/
don't drink and code ð» (same line twice)
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
Hope this doesn't bite us for really slow (read: Windows) CI servers...
Hope this doesn't bite us for really slow (read: Windows) CI servers...
You are right, I messed up :) I was pretty sure we had dedicated apis for search templates, but I confused the REST layer with the Java api. Leave it as-is, sorry for the confusion!
Oh, that error handling!
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
I wonder if using fromSeq and toSeqNo (instead of size) will result in this being less confusing.
Nah, if it hasn't hit yet we'll handle it if it does in the future, don't worry about it.
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
I think that we need to guard against overflow here!
I think that we need to guard against overflow here!
I think that we need to guard against overflow here!
I think I've seen this somewhere else today ;-)
Also minor, but I think I'd prefer `node == null ? null : node.toString()` because it requires less negative-resolving in my brain, up to you though.
Also minor, but I think I'd prefer `node == null ? null : node.toString()` because it requires less negative-resolving in my brain, up to you though.
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
Why not add ``` java if (highlightFields.contains(fieldName)) { continue; } ``` around line 94? That'll prevent two regexes that find the same field from highlighting it twice.
I think this is fine for now. While I do think expert users will want to tweak exactly which metric they use for evaluation, I guess it's ok to not make this plug-able right from the start.
I think this is fine for now. While I do think expert users will want to tweak exactly which metric they use for evaluation, I guess it's ok to not make this plug-able right from the start.
I think this is fine for now. While I do think expert users will want to tweak exactly which metric they use for evaluation, I guess it's ok to not make this plug-able right from the start.
same here - just pass a new instance
I think this is fine for now. While I do think expert users will want to tweak exactly which metric they use for evaluation, I guess it's ok to not make this plug-able right from the start.
or just: "return ok;"? :)
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
maybe a custom junit rule would be good here? I see that scheme a lot in tests to reset the plugin system once the test is done
also this class should be final.
This eagerly shuts down the chain and does not wait for the delayed values.
nested `if`s could be collapsed with `&&`
Er, well, it doesn't work like that. Ignore.
maybe a custom junit rule would be good here? I see that scheme a lot in tests to reset the plugin system once the test is done
maybe a custom junit rule would be good here? I see that scheme a lot in tests to reset the plugin system once the test is done
Either I'm missing something or ``` ObservableCache<Integer> source = (ObservableCache<Integer>)new ObservableCache<Integer>(Observable.range(0, 1000), 16); ``` can just be ``` ObservableCache<Integer> source = new ObservableCache<Integer>(Observable.range(0, 1000), 16); ```
Er, well, it doesn't work like that. Ignore.
I mean random number of replicas with random combination of non-active states
Ahh okay, makes sense, good point.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
look into `StreamInput#readMap`
I think it's always a single node cluster, but I'm good to keep it like this.
I'd separate catching the error and subscribing to the Single outside the try-catch.
This is unnecessary.
I'd separate catching the error and subscribing to the Single outside the try-catch.
nit: missing a space after the first comma
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
maybe just `esVersion()`
This should only be done in close()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
maybe just `esVersion()`
This should only be done in close()
maybe just `esVersion()`
maybe just `esVersion()`
maybe just `esVersion()`
maybe just `esVersion()`
This should only be done in close()
removed? It does not seem to be used.
maybe just `esVersion()`
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
maybe just `esVersion()`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
nit: extra line
Yes, `arrayContaining()` is for ordered checks, `arrayContainingInAnyOrder()` not. But I see that it has been closed. Have a good day!
I would be using a `Set` in this circumstances.
this means the mutable ShardRouting will have their hashes re-calculated every time . Can you double check the impact this have on a huge routing nodes and the balancer (your favorite code :)).
Yes, `arrayContaining()` is for ordered checks, `arrayContainingInAnyOrder()` not. But I see that it has been closed. Have a good day!
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
+1 much better than the while loops in the rest action
+1 much better than the while loops in the rest action
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
we shouldn't need this here in parse phase
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
Rename the method to something about captures I think now that the utility is gone.
nit: missing a space after the first comma
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
also this class should be final.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
`state == State.STARTED`? Otherwise no need to define the local variable `state` above
same here - just pass a new instance
same here - just pass a new instance
same here - just pass a new instance
here you may be able to use copyCurrentStructure
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
here you may be able to use copyCurrentStructure
We also need a simple rest test, testing integration like we have for the other processors
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
here you may be able to use copyCurrentStructure
here you may be able to use copyCurrentStructure
I think we lost some spaces before 123 here and in a few other places below.
I don't think you need @Before here, the parent method already has it.
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
This should be the last step
Space missing between `}` and `is`.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
thanks for adding this
canceled -> cancelled
It seems there is four spaces missing (unrelated to your changes).
Can you add the `<String, Object>` (@nik9000 style) or `<?, ?>` (@jpountz style) to the map? Again, I don't know if you should have a default here.
Do you really need to write it character by character. Seems to be quite inefficient when you could write in chunks. Also use `to_bytes(c, errors='surrogate_or_strict')` instead of `.encode()`
Do you really need to write it character by character. Seems to be quite inefficient when you could write in chunks. Also use `to_bytes(c, errors='surrogate_or_strict')` instead of `.encode()`
Group names are supposed to be named similar to variables, i.e. alphanumeric and underscore. So at least the prefix should adhere to that. Besides that, look at this PR: https://github.com/ansible/ansible/pull/52748
Do you really need to write it character by character. Seems to be quite inefficient when you could write in chunks. Also use `to_bytes(c, errors='surrogate_or_strict')` instead of `.encode()`
```suggestion rc, vg_extent_size, err = module.run_command(pvdiplay_cmd_device_options + ["-o", "vg_extent_size"]) ```
Ah, this is `golang`'s `omitempty`: https://github.com/moby/moby/blob/8e610b2b55bfd1bfa9436ab110d311f5e8a74dcb/api/types/container/config.go#L28
Group names are supposed to be named similar to variables, i.e. alphanumeric and underscore. So at least the prefix should adhere to that. Besides that, look at this PR: https://github.com/ansible/ansible/pull/52748
Nit: `active.size()-1` -> `active.size() - 1`
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
I am ok with what you propose Nik!
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
this method can be private now
Hmmm, I do see what you mean. Personally I would still prefer the register method in the registry but I think this is a personal preference thing rather than a substantial concern so I'm happy to yield on it :smile:
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
we should totally not have this method, one more reason to not implement the interface.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
we should escape expectedWarningHeaders, or alternatively unescape when we read.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
ok let me have a look then ;)
Please add a string message about the context registry being null
no utils for this :( `out.writeLongArray()` maybe :)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
"joined the cluster back" -> "rejoined the cluster"
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
maybe just `esVersion()`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
can we move all purging to the purge method, which will always be called by the builder? The down side will be not having logging, but if people want that they can put the cluster service in trace logging and see the changes.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Oh I see. I like it better the current way better then. I was confused by the fact that you could have both ALWAYS and PARTIAL in the same doc, maybe we could add an assertion that it never happers.
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
also this class should be final.
I think the unlock calls should always be in a finally block
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
@charettes Ideas welcome. Can you take a look? I really don't like the idea of using `psycopg2` in expressions.
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
should be superfluous unless you want to add a different command for check_mode support (since `supports_check_mode` is false)
I think it will be cleaner? not a biggy though
I think filter and query can never be null here? not sure whether we should validate this here.
Ah sorry missed that
I think it will be cleaner? not a biggy though
I would also test the direct retrieval of a file (not relevant to this change but we miss that one now and it will be good to have)
we should start thinking about testing the parsing phase for things that we never output from doXContent.... :)
I don't think you need to this, the internal cluster will call the node settings automatically.
I think it will be cleaner? not a biggy though
Now I wonder if you should make readFrom/writeTo final and make an abstract method that is just responsible for reading the response. That pattern was used by the query builders until they switched to constructor based reading and it seems fairly a appropriate. I don't think it should block the PR though. It isn't really important I think.
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
would be nice to allow to configure it to a percentage of the heap size
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
I don't think this indenting is intended.
I could be wrong (not that familiar with the code in that area) but I think that in-memory data structures for mappings are not created by the `createIndex` method. These are merged later (see e.g. MetaDataCreateIndexService:325). We could check here as well that all is good on the mapping level.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
... so that this doesn't need the `{credentials}` parameter in the URL ...
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
I'd prefer using `IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> prez.setRelevalntRatingThreshold(-1))` here like we do in many other tests and get rid of the @Rule
same here and in the rest of this method
No need to talk to a mocked observer, TestObserver.assertEmpty() already verifies these.
I'd prefer using `IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> prez.setRelevalntRatingThreshold(-1))` here like we do in many other tests and get rid of the @Rule
I suspect it's now neater to turn this logic around - find the appropriate `Bucket` using `request.getParam("bucket")` and let the `Bucket` check the authorisation, look up the handler, and do the necessary.
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
It's a standard practice to use separate args for different params. Also, autogenerated param ids aren't very readable when they are complex so in such cases it's better to assign them meaningful names (they are displayed in the pytest report): ```suggestion @pytest.mark.parametrize( ('returned_items_count', 'patched_dc_stdout'), ( (3, (DOCKER_OUTPUT_MULTIPLE, '')), (2, (PODMAN_OUTPUT, '')), (0, ('', '')), ), ids=('docker JSONL', 'podman JSON sequence', 'empty output'), ) def test_docker_images(docker_images, mocker, returned_items_count, patched_dc_stdout): mocker.patch( 'ansible_test._internal.docker_util.docker_command', return_value=patched_dc_stdout) ret = docker_images('', 'quay.io/ansible/centos7-test-container') assert len(ret) == returned_items_count ```
I would prefer two tests to test these two paths.
exiting -> exists
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I think this should be `Strings.collectionToCommaDelimitedString` and then you can use our Strings.java instead of JOpt's version
I think this should be `Strings.collectionToCommaDelimitedString` and then you can use our Strings.java instead of JOpt's version
I wonder if we should have a static `EnumSet<State> PAUSE_ELIGABLE = ...` this makes it simpler IMO
I don't think the test name needs the issue number. The rest of the name explains what the test is checking.
I wonder if we should have a static `EnumSet<State> PAUSE_ELIGABLE = ...` this makes it simpler IMO
I wonder if we should have a static `EnumSet<State> PAUSE_ELIGABLE = ...` this makes it simpler IMO
Drop the string constant. :)
ok...but client depends on the transport service anyway no? I think I don't get it
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I'd like to use a sentinel here rather than null like `BenchmarkMetaData.Entry.INVALID_ENTRY` or so.. I try to prevent `null` invariants they tend to throw NPEs :)
I wonder if we should have a static `EnumSet<State> PAUSE_ELIGABLE = ...` this makes it simpler IMO
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I'd like to use a sentinel here rather than null like `BenchmarkMetaData.Entry.INVALID_ENTRY` or so.. I try to prevent `null` invariants they tend to throw NPEs :)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
There's definitely some formatting differences here. Anyway, make sure you set your IDE to format only the lines that were modified as that prevents unnecessary changes like the above.
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
you can use `ExceptionsHelper#rethrowAndSuppress` here
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
We will need stronger assertions here too.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
Isn't it missing a whitespace ? Are you sure environ is defined here ? I don't see it. Perhaps this would work too, if you do want OVIRT_URL= to override kwargs['url']: kwargs['url'] = environ.get('OVIRT_URL', kwargs['url']) Example: $ A= python -c 'import os; print os.environ.get("A", "X")' (we get an empty string) If you do not want OVIRT_URL= to override kwargs['url'], then you can use or: kwargs['url'] = os.environ.get('OVIRT_URL') or kwargs['url'] Example: $ A= python -c 'import os; print os.environ.get("A") or "X"' X (we get the value that's at the right of or) Hope this helps
or just: "return ok;"? :)
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I don't think we should change that there. If the boostrap hosts aren't set, it should return `null` as before. Adding a logic of a "default" host while the property has no default value is wrong.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
I don't think we should change that there. If the boostrap hosts aren't set, it should return `null` as before. Adding a logic of a "default" host while the property has no default value is wrong.
I am not sure why you changed this.
I am not sure why you changed this.
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
Typo here, "pathf" instead of "path"
I'd switch the order of these so it matches the declaration order.
I don't think we need this branch anymore.
I don't think we need this branch anymore.
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
good point.... we should be able to get rid of it.
`(byte_counter / rate_limit) - elapsed` sometimes takes negative values (tested on python2). Negative delay to `sleep` results in `IOError` and failed download. There should be at least a check for that.
I am ok with what you propose Nik!
I think it's enough to check `stderr`, e.g. ```python with self.assertRaises(SystemExit), captured_stderr() as stderr: self.get_parser().parse_args(['--parallel', 'unaccepted']) msg = "argument --parallel: 'unaccepted' is not an integer or the string 'auto" self.assertIn(msg, stderr.getvalue()) ```
grr nevermind I didn't see the last line pfff...
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
I wonder if we should extend `ChannelReference` to implement `Closeable` and have the `.close()` method decrement the ref and throw an error if it's not now at 0 (which it should be since it's being closed in this case). That way we error immediately if the translog is closed but something incremented the channel ref. What do you think of this? Dunno if you think it might make ChannelReference too complex.
I wonder if we should extend `ChannelReference` to implement `Closeable` and have the `.close()` method decrement the ref and throw an error if it's not now at 0 (which it should be since it's being closed in this case). That way we error immediately if the translog is closed but something incremented the channel ref. What do you think of this? Dunno if you think it might make ChannelReference too complex.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
I realize the example already here used this form, but I think it is clearer to use `== false` for inverted conditions.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
Should this be ``` java + final boolean enable = settings.getAsBoolean(SETTING_CLUSTER_INDICES_CLOSE_ENABLE, true); ``` ? Settings can't really be cleared right now but if they could be this would stick the value to whatever it was set at before clearing. Maybe it doesn't matter but I'm certainly more used to seeing the default value here.
Should this be ``` java + final boolean enable = settings.getAsBoolean(SETTING_CLUSTER_INDICES_CLOSE_ENABLE, true); ``` ? Settings can't really be cleared right now but if they could be this would stick the value to whatever it was set at before clearing. Maybe it doesn't matter but I'm certainly more used to seeing the default value here.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
those are hard to debug I can tell u :dancers:
those are hard to debug I can tell u :dancers:
That'd be cool! I was hoping something like ``` java Files.write(loggingConf, Arrays.asList( "logger.test: INFO, console", "appender.console.type: console"), StandardCharsets.UTF_8); ``` would be possible. Either way is cool with me.
We also need a simple rest test, testing integration like we have for the other processors
Nit: please add spaces around the `=` sign.
we decided to live on the edge and have fun. The concern was around non ascii codes breaking tooling but CI seems happy. Let's see how far we get.
Nice idea, that would also show the possible benefits of using the logging infrastructure.
It feels squicky to ignore the exception. Personally I'd `assert false : "Exceptions not expected here."` and `logger.error` about it.
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
Yes, but we can address this in another release.
Yes, but we can address this in another release.
Yes, but we can address this in another release.
Yes, but we can address this in another release.
Yes, but we can address this in another release.
can we add bogus non relevant settings? Would be good to know they don't mess up with things.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
this could be static
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
Yes I think so.
please include newlines between methods
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
this is not good... you rely on the base class implementation (that only these two parameters for it's state). You have to proxy all method implementation to the delegate
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
both are valid tests, i don't see why you need to eliminate the existing one
or just: "return ok;"? :)
Same here for `compareAndSet`
A bit odd. I'd rather have two separate tests (and the one using the deprecated form should be marked as deprecated so that we can clean things up once we remove the deprecated feature that it tests.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
Ok, sounds fine.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Same deal, I'd just convert it to nanos.
or just: "return ok;"? :)
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
or just: "return ok;"? :)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
```suggestion display.vvv(u"No connection ot reset: %s" % to_text(stderr)) ``` ```suggestion display.vvv(u"No connection to reset: %s" % to_text(stderr)) ```
Sure, warnings are an option. But if it does work as non-root, I wouldn't add the warning.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
> That's not accurate. Sorry, poor choice of words. I meant that the auto-configuration doesn't do anything special when a broker url is set while it does something explicit (in code) when a host is set. We're very cautious to not introduce any inconsistency and the reason why I asked you here. Thanks for the follow-up and the feedback !
This can just be `System.out.print(msg)` now I think. Thanks for removing the formatting from these print apis! I think that was the real problem, its trappy for a `printf()` to be named anything other than `*printf()`. And in this case the caller can just always `String.format` themselves.
Please could you assert that the content of the message is correct? (`expectThrows` returns the exception thrown, so you just need to assign it to a variable and check its message.)
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
I think you should pass in the request here instead of empty params
Please could you assert that the content of the message is correct? (`expectThrows` returns the exception thrown, so you just need to assign it to a variable and check its message.)
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
we should escape expectedWarningHeaders, or alternatively unescape when we read.
At minimum this should be typed (we should have separate script classes for each underlying doc values type), but I would much rather this be built into the script itself, so instead of setting the value, an iterate type call is made, similar to the doc values api.
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
I like this simplification!
Nit: `active.size()-1` -> `active.size() - 1`
Nit: `active.size()-1` -> `active.size() - 1`
I wonder how long this would work ;)
I don't think you need to divide at all - randomDouble is between 0 and 1, I believe.
I think we can check also randomly on a shard that relocates _to_ the local node
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
beware it might not do what you think: https://stackoverflow.com/questions/8819738/why-does-double-nan-double-nan-return-false
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
`upgrade API` -> `the upgrade API`
I think we can check also randomly on a shard that relocates _to_ the local node
is this a pattern or just a separator? wondering about naming
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
in this case is it worth peaking at the file again and check if the first byte is valid even for version 0? maybe we should do that check first and then move to V1 and fail hard if we see a CorruptIndexExp
There is a race here. If `run()` gets here and `onNext` is fired, throttling will be disposed and the `onNext` value gets emitted. Here then the cached value gets emitted as well and now there are two tasks delayed for the subsequent interactions.
same note as in the json processor PR.
We can setup other scenarios to test the cancellation if we remove `updateLeaderGlobalCheckpoint`. For example, make the read limits reached, then cancel, then verify that we won't issue any read request.
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
I'm not super comfortable making this. I think maybe instead we should add the match skipping at the `FieldParser` level. Maybe some kind of subclass that skips or something. Not sure.
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
I think we should maybe make it even simpler and add this signature: `````` Java public synchronized void verifyIndexMetadata(final NodeServicesProvider nodeServicesProvider, IndexMetaData metaData, IndexMetaData metaDataUpdate) throws IOException {``` and just call `IndexService#updateMetadata()` if it's not the same? ``````
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
thanks @nik9000 ! @elastic/es-clients is this ok? I guess all the client runners will have to be changed accordingly.
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
Since these are for tests we probably want to set play_context.prompt and check the output. Then unset play_context.prompt and check the output.
I've noticed this field isn't in 6.x so please remove from the backport
I've noticed this field isn't in 6.x so please remove from the backport
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
The first two of these fields are unused. I think that's right, and we should remove them and also `ec2Bucket`, by generating the key and token and then passing them into the bucket's constructor.
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
I mean in the code but just noticed there was one already
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
You can save a line and go `Object value = valueTypes[level].get();` directly
I think this should be a ParseException instead of an IllegalArgumentException. This would be in line with what we do elsewhere in the codebase (such as in the mapper parsers where any left over parameters after parsing is done are throw in a MapperParsingException).
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
This is great! No more @Inject!
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
Randomized runner should not need these @Test annotations.
Randomized runner should not need these @Test annotations.
Randomized runner should not need these @Test annotations.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This is great! No more @Inject!
This is great! No more @Inject!
ok, i see it. Its just a little non-obvious due to the way searchers are bubbled up. maybe we can add an assert in the future.
Randomized runner should not need these @Test annotations.
Randomized runner should not need these @Test annotations.
does this work? it works for percentiles, but with percentiles rank it's reversed
This is great! No more @Inject!
lets just use IOException that's much better for this purpose and it's checked
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
(we just load all files in the `ES_HOME/config/ingest/grok` directory)
lets just use IOException that's much better for this purpose and it's checked
lets just use IOException that's much better for this purpose and it's checked
1s should be enough.
Randomized runner should not need these @Test annotations.
oh right sorry I keep missing that.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I wonder if we should void this check if indexUUID or that.indexUUID is IndexMetaData#INDEX_UUID_NA_VALUE . We can still run into this value when reading existing state files.
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I wonder if we should void this check if indexUUID or that.indexUUID is IndexMetaData#INDEX_UUID_NA_VALUE . We can still run into this value when reading existing state files.
Such a loop in a test is not acceptable. You could send a message and wait a bit. There are similar samples in the JMS area you can reuse.
lets just use IOException that's much better for this purpose and it's checked
I think it would be good to be consistent and always throw
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
I know we already checked it but I think it's important to make sure all data deletion goes through the same place where we do (and will extend) all the required safety checks. We might even want to restrict access to the delete methods in NodeEnv via forbidden API.
should we move the `configureSocketChannel` call into the try block as well here? seems cleaner
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
can we add the [] around values? we should make this consistent with other logs `merge segment [%s] done: took [%s], [%.1f MB], [%d] docs`
Ah sorry missed that
isn't this still subject to the race condition discussed in implementation on the base backend? something else could `set` the key in between the `get` and `set`.
In the previous version, we didn't delay the onCompleted event.
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
We will need stronger assertions here too.
Only for consistency. Not sure it's a good enough reason.
already have this in basic.py, no need to create your own, it also includes sanitation and no_log
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
I am not sure why you changed this.
I am not sure why you changed this.
I am not sure why you changed this.
I am not sure why you changed this.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Nit: `active.size()-1` -> `active.size() - 1`
yea, I would at least debug log it..., it shouldn't happen
yea, I would at least debug log it..., it shouldn't happen
yea, I would at least debug log it..., it shouldn't happen
Can we move these up at the top of the class with the other object variable declarations? I think it is more readable than having them 300 lines down into the class.
Exactly, or in that particular case, from their child since constant-score queries can only have one child.
Exactly, or in that particular case, from their child since constant-score queries can only have one child.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
This could return an immutable list
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
`engine failure` -> shard failure
I think we'll run into an NPE in the failAndRemoveShard code: ``` private void failAndRemoveShard(ShardRouting shardRouting, IndexService indexService, boolean sendShardFailure, String message, @Nullable Throwable failure) { if (indexService.hasShard(shardRouting.getId())) { ```
Should we actually control this? I know, I wrote that code as well at the begining but the more I think about it, the more I think it's not that useful to block... May be only log.warn with "[{}] signer might not be supported"...
I think we'll run into an NPE in the failAndRemoveShard code: ``` private void failAndRemoveShard(ShardRouting shardRouting, IndexService indexService, boolean sendShardFailure, String message, @Nullable Throwable failure) { if (indexService.hasShard(shardRouting.getId())) { ```
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
I think we should leave this method for java api bw comp
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
StreamInputReader already does this.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
I don't think that complexity is warranted. Just keep constructor injection please.
s/y ou/you Also I think upfront is one word.
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
maybe just return null if all is ok? then we just need to do a null check at line 158.
we may want to rename match_formats as well here, can do in another PR though.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
don't drink and code ð» (same line twice)
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
don't drink and code ð» (same line twice)
you should assign a new list instance (or clear the `abortBenchmarkNodeStatuses` list) to make sure we are not reading an instance that already has some status in the list.
I think that we can do better than this. If I'm reading this correctly, this means that we wait until an entire batch is complete before submitting another batch of requests. Thus, a slow request can hold the next batch and thus the response. I think instead we should try to maintain as many requests in the queue as possible, up to the concurrent request limit.
I think here we can go with an ordinary `BytesReference` and use it's efficient iterator `BytesRefIterator iterator()` the returned `BytesRef` is just a pointer into the underlying `byte[]` that you can wrap in with `ByteBuffer#wrap` and do your accounting what is left for writing in this method. so there is no need to use a `NetworkBytesReference`
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
doesn't matter that much, I thought -1 didn't make sense :)
doesn't matter that much, I thought -1 didn't make sense :)
In some previous discussion for other builders we tried to set default values for non primitive types that have a default, setting to null effectively means use the default, same as specifying `field: null` in the json query. Maybe we can keep this here (and in the following setters that have default values)
In some previous discussion for other builders we tried to set default values for non primitive types that have a default, setting to null effectively means use the default, same as specifying `field: null` in the json query. Maybe we can keep this here (and in the following setters that have default values)
In some previous discussion for other builders we tried to set default values for non primitive types that have a default, setting to null effectively means use the default, same as specifying `field: null` in the json query. Maybe we can keep this here (and in the following setters that have default values)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I see, bummer, I guess we can't do much about it ;)
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
we could pass a glob with regex:xxx to newDirectoryStream if we want
I'd switch the order of these so it matches the declaration order.
there are too many flavours to set a `WebServiceMessageSender`. Specifying a vararg of instance and a `Class` looks wrong to me. I've removed that in my fork.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
we could pass a glob with regex:xxx to newDirectoryStream if we want
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
In some previous discussion for other builders we tried to set default values for non primitive types that have a default, setting to null effectively means use the default, same as specifying `field: null` in the json query. Maybe we can keep this here (and in the following setters that have default values)
+1 - And the use of such expression for the JMX stuff always bugged me.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
It seems that all the implementations of `DisruptableMockTransport` simply have a getter for some constant value for the local node as their implementation. Maybe just move that getter up into `DisruptableMockTransport` and pass it as constructor parameter while we're changing this anyway? (just to save a bit of noise in the concrete tests :))
we could pass a glob with regex:xxx to newDirectoryStream if we want
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
+1 - And the use of such expression for the JMX stuff always bugged me.
And here... Wrap calls to self.client.X in try/except block. On APIError call self.client.fail() with an error message and exception details.
I think after closing #19917 we can remove this todo
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
Got it but I think the reason why a `Supplier` was added is wrong.
(we just load all files in the `ES_HOME/config/ingest/grok` directory)
This does not necessarily need to be within a static initialization block.
How is the `path` value handled? I don't think this will support relaxed binding, e.g. if someone sets `spring.integration.graphControllerPath` or `SPRING_INTEGRATION_GRAPH_CONTROLLER_PATH` the configuration will be ignored.
And here... Wrap calls to self.client.X in try/except block. On APIError call self.client.fail() with an error message and exception details.
This does not necessarily need to be within a static initialization block.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Okay, we might have to revisit some other queries we refactored then.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
Sorry, i don't think i was very clear. I meant the hashing algorithm here is an HMAC (a keyed hash). For the anonymization use case we could use a non keyed Hash to the same effect. The key doesn't provide much value unless you are verifying the hash's integrity. To avoid swapping implementations based on a key's existence, a hard coded key can be used, which effectively (but not technically) changes from a keyed hash to non keyed hash.
Sorry, i don't think i was very clear. I meant the hashing algorithm here is an HMAC (a keyed hash). For the anonymization use case we could use a non keyed Hash to the same effect. The key doesn't provide much value unless you are verifying the hash's integrity. To avoid swapping implementations based on a key's existence, a hard coded key can be used, which effectively (but not technically) changes from a keyed hash to non keyed hash.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
we should start thinking about testing the parsing phase for things that we never output from doXContent.... :)
I think this will be clearer if we say - "// precreate incoming indices and popluate them with the relevant types"
+1 on adding UUID
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
minor note: we consider shards inactive until the first indexing operation has happen, so I think this part is OK regardless of the change.
and also assert that `startOfThrottle != 0`
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
Is this negative check necessary? long has 2^63 -1 capacity and let's assume that we will accumulate 10^9 every second we would still need 106 752 days to overflow (roughly 292 years).
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
Any chance you could group this so `unit.isMillisBased` is called once? I think it might be a bit easier to read if you juggle the "arms" of the `if` statement.
Any chance you could group this so `unit.isMillisBased` is called once? I think it might be a bit easier to read if you juggle the "arms" of the `if` statement.
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
For the record, I'm asking because I expect the setter to be called once while these create methods can be called _many_ times
maybe `Objects.equal` could make it easier to read
can we pass a reason to this method and mention it here? I always to scroll to find out whether this is a "true" index or just one that was created when importing/creating one.
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
not sure, I'm not too familiar with the weird formatting language.
Small typo here: Guage -> Gauge.
you should assign a new list instance (or clear the `abortBenchmarkNodeStatuses` list) to make sure we are not reading an instance that already has some status in the list.
I like `hasSize` better for this because it gives a nicer error message on failure.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
Er, well, it doesn't work like that. Ignore.
`engine failure` -> shard failure
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
For what it's worth, I would give a +1 for any solution that does not split up value and unit into two separate parameters (as Java does by default), as they are clearly logically coupled. I would give another +1 for making whatever solution is settled for consistent across the code base. Beyond that, I don't really feel strong about one solution or another.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
args are not used.. we should either remove those from the method sig (which will be consistent with the `println` methods) or pass `String.format(text, args)` to `doPrint`
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
This is logic that I think should go into ReplicatedOperation.
oh cool the read is in the ctor! nice!
you can omit `ElasticsearchException` here it's unchecked
Doesn't actually throw `IOException`.
This is short and only used in one place, so I think I'd inline it.
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
Thanks for taking the time to run the benchmarks!
you can omit `ElasticsearchException` here it's unchecked
Never mind. I just found `SafeSubscriber` will do it.
I think it would be easier to read if we use the string representation to create these: http://docs.oracle.com/javase/7/docs/api/java/nio/file/attribute/PosixFilePermissions.html#fromString(java.lang.String)
Never mind. I just found `SafeSubscriber` will do it.
`of the it's last` -> `of its last`
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
Done. I would prefer using `action` as a parameter of `get` instead of being an attribute of `KafkaTopics`.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
The first condition seems to be redundant, but it might be ok to leave it in for clarity.
remove this additional line break? :)
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I think it would be valid to fallback to a generated salt if none is set (for other use cases), but it doesn't necessarily need to be part of this PR.
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
you can do some streaming java8 magic here.
Randomized runner should not need these @Test annotations.
Randomized runner should not need these @Test annotations.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Randomized runner should not need these @Test annotations.
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
make `Boolean` and only serialize when not null
This should be done in reset()
I think I'd just let deleted and updated come out in the toString rather than worry about that. I think it was a mistake that I did it. I don't think it is worth the complexity of the map. It is just a couple of fields that we can ignore.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
I suspect it's now neater to turn this logic around - find the appropriate `Bucket` using `request.getParam("bucket")` and let the `Bucket` check the authorisation, look up the handler, and do the necessary.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
Small typo here: Guage -> Gauge.
I suspect it's now neater to turn this logic around - find the appropriate `Bucket` using `request.getParam("bucket")` and let the `Bucket` check the authorisation, look up the handler, and do the necessary.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
I suspect it's now neater to turn this logic around - find the appropriate `Bucket` using `request.getParam("bucket")` and let the `Bucket` check the authorisation, look up the handler, and do the necessary.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
nit: extra line
this could be static
Do we also need to protect agains renaming to `IndexWriter.WRITE_LOCK_NAME`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
This should accept XContentFilterBuilder, and then use toXContent to transform it to bytes.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
+1 then we shouldn't forget about it :)
randomInt cannot be within the loop, otherwise it changes at every iteration...
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
You can use `assertAcked` here and just wrap the above line... one line saved ;)
This should be done in reset()
++ on removing this catch. Not true any more
This should be done in reset()
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
Please fix identation.
this getClass() test is not necessary, super.equals already takes care of it
hmm no idea really need to think about that one? should this be a //nocommit
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
Changing to `List<List<FlywayMigration>>` breaks backwards compatibility without any benefit. I think we should either keep the old format, or change to a Map<String, List<FlywayMigration>> where the string somehow indicates which DataSource the migrations were run against. The JDBC URL of the DB would be ideal, but I'm not sure we can get that.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
Here again I think we should use `builder.timeField` to handle this
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
good catch! that means we are not properly testing this case either given that we didn't catch it.
I think you should just do `instanceof Number` and else call `.toString()`
wouldn't it be cleaner to just work with sets here? (instead of converting to arrays)
> Are you concerned with how metrics are enabled in the driver? Or should I be enabling metrics automatically in the Actuator? If we provide first-class support for metrics here, the user shouldn't have to write code to enable it ideally. Looking at other metrics we have, they are usually enabled by default, sometimes with a flag that indicates if metrics for that particular `CqlSession` is enabled or not. Concretely we should then have a `enabled` property somewhere in the `spring.cassandra` namespace that user can set in `application.properties` the usual way. I don't have an opinion as whether the flag should be enabled by default or not but listing the metrics seem a bit tedious and inconsistent for an "out-of-the-box" scenario. Paging @shakuzen to get some more feedback on this.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
`Description` -> `Descriptor`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
space between `try` and `(`
We don't know if it's going to fail or not. I might have that custom table in my database init script. There is no way to know. What @vpavic suggested initially is that a user would have to explicitly disable the initializer flag to prevent the exception. Doesn't feel right to me. It will fail down the road if you configure a custom table name and you have no script to create said custom table name.
this can be: ``` Java public static final Setting<List<URIPattern>> ALLOWED_URLS_SETTING = Setting.listSetting("repositories.url.allowed_urls",Collections.emptyList(), URIPattern::new, false, Setting.Scope.CLUSTER); ```
I don't think this is correct? Do tests pass? This should fail on unmapped fields.
I'd find this easier to read as `assertThat(environment.getActiveProfiles()).containsExactly("profile1", "profile2");` rather than calling the method, but that might just be me and I have no idea what the rest of the team might prefer.
oh right sorry I keep missing that.
oh right sorry I keep missing that.
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
This should only be done in close()
This should only be done in close()
This should be done in reset()
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
`metric1` first? you have `metric2` twice.
same here - just pass a new instance
`metric1` first? you have `metric2` twice.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
same here: I'd like to keep the version using `generateParser` since its the same as in master.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
Small typo here: Guage -> Gauge.
why did this become public? Did you remove the support package in the test directory structure
Nit: `initializing.size()-1` -> `initializing.size() - 1`
Nit: `initializing.size()-1` -> `initializing.size() - 1`
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
Nit: `active.size()-1` -> `active.size() - 1`
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
don't drink and code ð» (same line twice)
Nit: `active.size()-1` -> `active.size() - 1`
Nit: `initializing.size()-1` -> `initializing.size() - 1`
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
Since we now use a logger with an index prefix , this will result in double index name logging `[index][index][0]`
Since we now use a logger with an index prefix , this will result in double index name logging `[index][index][0]`
I think we should use `writeAtomic` everywhere just to reduce the complexity.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
s/y ou/you Also I think upfront is one word.
nit: extra line
I think we should use `writeAtomic` everywhere just to reduce the complexity.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
Rather than using a boolean, I think @philwebb's suggestion of taking the event class that should be listened for would be a more flexible approach. Depending on the type of the event, the environment can then be used it it's available. If the environment's not available or it doesn't contain the property to configure the pid file location, the default location could be used.
after is now minimum_age
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
I prefer when the `readFrom`/`writeTo` are symmetrical. Specifically, since we can't use `readOptionalStreamable` in `readFrom` due to `ShardId` only having a private constructor, I think that we should have a symmetrical `if` here in the `writeTo` rather than using `writeOptionalStreamable`. The symmetry makes it easier to check that the `readTo/writeFrom` are in sync.
let's add an assertion that this method is only called from the snapshot thread.
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
100kb also seems arbitrary, I know it was here before maybe @costin knows
100kb also seems arbitrary, I know it was here before maybe @costin knows
100kb also seems arbitrary, I know it was here before maybe @costin knows
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
++ on debug message
we don't want it to be retried... that was the cause of the failure
use `unittest.skipIf` decorator on the class
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
100kb also seems arbitrary, I know it was here before maybe @costin knows
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Randomized runner should not need these @Test annotations.
It should say greater than zero, 0 is not permitted.
Ok, sounds fine.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
I see that we need it from another package, I think it's ok.
Maybe add "for example"
also this class should be final.
nit: space before brackets
Ok, sounds fine.
I don't think that complexity is warranted. Just keep constructor injection please.
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
we have a new awaitNoMaster util method
I'm doing buffer now and they all emit buffered data in case of onError.
Key descriptions do not start with "The", "A", etc.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think it would be better to do something like `return "[" + new BytesRef(ranges, 0, BYTES) + " TO " + new BytesRef(ranges, BYTES, BYTES) + "]";`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
same question as above
same question as above
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
I think it would be better to do something like `return "[" + new BytesRef(ranges, 0, BYTES) + " TO " + new BytesRef(ranges, BYTES, BYTES) + "]";`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
> Backos off Typo
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
> Backos off Typo
This should only be done in close()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think it would be better to do something like `return "[" + new BytesRef(ranges, 0, BYTES) + " TO " + new BytesRef(ranges, BYTES, BYTES) + "]";`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
Yeah, let's do that (expand the range to the entire valid port range, and add assertions etc.). Thanks @jaymode.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
From the spec, it appears that action could potentially be a high cardinality tag: ![image](https://user-images.githubusercontent.com/1697736/40988408-96a7bae0-68b0-11e8-91e7-dd24f5108dcc.png)
From the spec, it appears that action could potentially be a high cardinality tag: ![image](https://user-images.githubusercontent.com/1697736/40988408-96a7bae0-68b0-11e8-91e7-dd24f5108dcc.png)
Nit: `initializing.size()-1` -> `initializing.size() - 1`
sorry, missed the loop
sorry, missed the loop
or just: ``` java if (Objects.equals(similarity(), other.similarity() == false) { conflicts.add("mapper [" + names().fullName() + "] has different similarity"); } ```
or just: ``` java if (Objects.equals(similarity(), other.similarity() == false) { conflicts.add("mapper [" + names().fullName() + "] has different similarity"); } ```
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This should be done in reset()
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
you can make one of them public and call it from both tests, I don't mind
I guess it could be renamed to isFalse() / isTrue() now
I guess it could be renamed to isFalse() / isTrue() now
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
No, you are right, I didn't realize the need for api users before going through the whole changes.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
I think this line fits in the previous one
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
or just: "return ok;"? :)
Maybe we could avoid compressing just to pass to the mapper service? Seems like the api for merge could take non compressed and we can use helpers to wrap a decompressor when we already have compressed? Just a thought for a spinoff issue (Ive had it on my mind for a while).
Maybe we could avoid compressing just to pass to the mapper service? Seems like the api for merge could take non compressed and we can use helpers to wrap a decompressor when we already have compressed? Just a thought for a spinoff issue (Ive had it on my mind for a while).
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
nit - an extra d? release**d**Delayed..
Ok sounds fine then.
It seems that all the implementations of `DisruptableMockTransport` simply have a getter for some constant value for the local node as their implementation. Maybe just move that getter up into `DisruptableMockTransport` and pass it as constructor parameter while we're changing this anyway? (just to save a bit of noise in the concrete tests :))
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
We don't add default values to descriptions.
I would be using a `Set` in this circumstances.
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
yes that would be perfect thanks
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
it would be awesome to have some doc-strings on these settings
it would be awesome to have some doc-strings on these settings
it would be awesome to have some doc-strings on these settings
it would be awesome to have some doc-strings on these settings
it would be awesome to have some doc-strings on these settings
it would be awesome to have some doc-strings on these settings
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
also, please make a note to make this configurable.
offtopic: I'm wondering if we should drop `SubscriptionHelper.isCancelled()`
remove empty line
This should be ``` return new Subscriber<T>(child); ``` to chain the unsubscription properly.
maybe also here `"foo"` -> `{@code foo}`
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
maybe this setting should have a more descriptive name too
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
maybe also rename the setting? (in addition to the constant)
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Maybe the max should be more? Something like 5
Maybe the max should be more? Something like 5
Ah sorry missed that
... so that this doesn't need the `{credentials}` parameter in the URL ...
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
Nit: please add spaces around the `=` sign.
just name it `readSize`
Oh, woops, good :)
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
As far as I can see you did not hence why I am asking here. The code I've referenced makes an explicit setup using `NettyConnectorFactory`. As far as I can see we'd lose that as soon as an url is set.
can we use getters here like `getNode` `isCanceled`
I thought I saw some `List<String>` already but I can't find it anywhere, seems like we will add that when we need it then.
shard can remain
thanks for adding this
Since the `lineinfile` defaults to `-1` for the `lock_timeout`, this conditional is skipped but the next matches and an exception is raised. Since `0` is less than `-1` but `-1` is "truthy", the while loop is skipped, the lockfile is immediately closed, and an exception as raised. I believe setting the default for `lock_timeout` to 0 or possibly a small positive integer in the `argument_spec` would be the best solution. Then, this change would not be necessary.
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
The great irony is that these are really hard to read in the font that chrome uses for plain text files so I have to squint to make sure these are right.....
I honestly don't get it... the way I look at it, we moved from having the `env` "polluting" the `Factory` interface to having it now "pollute" the `Factory.Provider`... why don't we just either wire the concrete factories into a map binder, or, if we don't want to wire them, see if we can pass in the Env. directly to the Module ctor (just like it can accept `Settings`)
Can we fold this into `writeTo` and add a boolean to the signature (maybe `includeRequestHeaders`)? It seems like it just requires adding a if/else block
and remove the below null check
I'd feel better if we had a dedicated method for this called something like `closeAsync` or something like this, I think the logic would be simpler...
You should probably expect unicode strings
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
This function is used to resolve index constraint on field stats. I am not sure if we should implement index constraint on a geopoint field but if we don't then we should throw an exception here.
wonder if we should make these Integer and Boolean just int and boolean primite types.
maybe we implement `Iterable<V>`
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
`of the it's last` -> `of its last`
I think you should just do `instanceof Number` and else call `.toString()`
I was getting confused by invalidateAll - on second inspection you hold both locks when clearing the maps.
I think you should just do `instanceof Number` and else call `.toString()`
I think you should just do `instanceof Number` and else call `.toString()`
update version to beta 1
I see that we need it from another package, I think it's ok.
I think you should just do `instanceof Number` and else call `.toString()`
maybe we implement `Iterable<V>`
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
similarly here I would like it better with a regular for loop and by making fillSegmentInfo take a single segment at a time
similarly here I would like it better with a regular for loop and by making fillSegmentInfo take a single segment at a time
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
similarly here I would like it better with a regular for loop and by making fillSegmentInfo take a single segment at a time
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
We can pass a name in the constructor if need be? On 11 dec. 2015 9:53 AM +0100, Martijn van Groningennotifications@github.com, wrote: > Incore/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java(https://github.com/elastic/elasticsearch/pull/15363#discussion_r47332645): > > > @@ -304,7 +304,27 @@ public void onFailure(Throwable t) {>observer.waitForNextChange(new ClusterStateObserver.Listener() {>@Override>public void onNewClusterState(ClusterState state) {>- threadPool.executor(executor).execute(AsyncReplicaAction.this);>+ transportService.sendRequest(clusterService.localNode(), transportReplicaAction, request, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {>+>+ @Override>+ public void handleResponse(TransportResponse.Empty response) {>+ try {>+ channel.sendResponse(response);>+ } catch (IOException e) {>+ logger.debug("failed to send retry on replica response, action [{}], request [{}]", e, actionName, request); > > got it. btw about the generic helper, we always have a custom log message or want to deal a failure differently in many scenarios, so I think a generic helper isn't going to help much. > > â > Reply to this email directly orview it on GitHub(https://github.com/elastic/elasticsearch/pull/15363/files#r47332645).
I think we can better call this in the Store.OnCloseListener.afterIndexClosed(). Feels cleaner to call this once we think all shards have bee removed.
I think we can better call this in the Store.OnCloseListener.afterIndexClosed(). Feels cleaner to call this once we think all shards have bee removed.
I think we need check whether pipeline has be specified on the bulk request or on any sub requests here. Right now we always delegate to the pipeline execution service that will execute on the ingest thread pool, which we should prevent if no pipeline has been specified.
Do we want to have this as an assertion or as an IllegalStateException or similar? If a user runs this on some weird Linux distribution that has an empty file here they might get odd errors later on, although I suppose you could argue that if they're not running on a supported OS then they're on their own anyway.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think we need check whether pipeline has be specified on the bulk request or on any sub requests here. Right now we always delegate to the pipeline execution service that will execute on the ingest thread pool, which we should prevent if no pipeline has been specified.
well we don't need to extend this anywhere, plus these changes don't have anything to do with this PR at this point, would prefer to leave them out.
you can use `IOUtils.close(processor)` it deals with `null` values...
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
The `isInternal` data member hasn't been removed - is it correct to remove it here? (If it is for some reason then it should also be removed from `hashCode()`.)
Either way is fine. In general `<title>` is better than extracting from embedded data as the former is less likely to change. If there's an example that `<title>` or `settings['title']` is missing, a fallback should be provided, otherwise the extraction should be fatal.
you can use `IOUtils.close(processor)` it deals with `null` values...
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
I think we should leave this method for java api bw comp
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I think we should leave this method for java api bw comp
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I think we should leave this method for java api bw comp
Just dug into it and found we use `TestRuleAssertionsRequired` from the lucene-test-framework jar to do this check
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
can we please unpack the tuple right away instead of using v1 v2? just easier to read
there are too many flavours to set a `WebServiceMessageSender`. Specifying a vararg of instance and a `Class` looks wrong to me. I've removed that in my fork.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
`them` -> `them;`
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
we should totally not have this method, one more reason to not implement the interface.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
I think `Store` and `Started` should not be internal classes, it makes the `AsyncShardFetch` file smaller and easier to digest if they are moved to their own files.
I think you have to sort before shuffling, otherwise it will not be deterministic, cause the order in the list still depends on the order in the set, which depends on the jvm :)
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
I think you have to sort before shuffling, otherwise it will not be deterministic, cause the order in the list still depends on the order in the set, which depends on the jvm :)
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
Clever. Quite timely for you to have fixed this as I came across this problem just last night.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
`them` -> `them;`
we should totally not have this method, one more reason to not implement the interface.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
Here is a quick fix (not elegant): ``` java volatile Scheduler.Inner innerScheduler = null; /** * Try draining the queue on the given scheduler. * The method ensures that only one thread is actively draining the * queue on the given scheduler. * * @param scheduler * the scheduler where the draining should happen * @param cs * the composite subscription to track the schedule */ public void tryDrainAsync(Scheduler scheduler, final CompositeSubscription cs) { if (cs.isUnsubscribed() || wip.incrementAndGet() > 1) { return; } if (innerScheduler == null) { // add tracking subscription only if schedule is run to avoid overfilling cs final MultipleAssignmentSubscription mas = new MultipleAssignmentSubscription(); cs.add(mas); mas.set(scheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { innerScheduler = o; if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } })); } else { innerScheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } }); } } ```
Here is a quick fix (not elegant): ``` java volatile Scheduler.Inner innerScheduler = null; /** * Try draining the queue on the given scheduler. * The method ensures that only one thread is actively draining the * queue on the given scheduler. * * @param scheduler * the scheduler where the draining should happen * @param cs * the composite subscription to track the schedule */ public void tryDrainAsync(Scheduler scheduler, final CompositeSubscription cs) { if (cs.isUnsubscribed() || wip.incrementAndGet() > 1) { return; } if (innerScheduler == null) { // add tracking subscription only if schedule is run to avoid overfilling cs final MultipleAssignmentSubscription mas = new MultipleAssignmentSubscription(); cs.add(mas); mas.set(scheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { innerScheduler = o; if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } })); } else { innerScheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } }); } } ```
Instead of creating the formerParams and replacing them afterwards could we not create a `nextParams` map which is a copy of the params map and pass it into the node.retrieve method? This would save us having to put things back after the method returns
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
This test should assert that the headers are correct.
maybe make this variable final? just better indicate it will never change
This test should assert that the headers are correct.
This test should assert that the headers are correct.
This test should assert that the headers are correct.
I removed the try...except... — Thanks both.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
I had the same thought, but I guess the point is to properly validate things when they get set to the builder, so that non supported values will never be serialized. I assume that we do that already, otherwise we should.
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
I think I'd prefer to have a single `static` block, since it's not easily apparent which would be executed first
This is short and only used in one place, so I think I'd inline it.
I had the same thought, but I guess the point is to properly validate things when they get set to the builder, so that non supported values will never be serialized. I assume that we do that already, otherwise we should.
I think I'd prefer to have a single `static` block, since it's not easily apparent which would be executed first
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
I think I'd prefer to have a single `static` block, since it's not easily apparent which would be executed first
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
If you use ImmutableOpenIntMap instead (as for activeAllocationIds), you get cluster state diffs on it for free.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Maybe we could avoid compressing just to pass to the mapper service? Seems like the api for merge could take non compressed and we can use helpers to wrap a decompressor when we already have compressed? Just a thought for a spinoff issue (Ive had it on my mind for a while).
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
We could add a default value (.i.e. `< 6.1 `) in the parameterized message because > Automatically enabling security for older trial license (null) might be slightly obscure.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
this curly bracket should be on the previous line
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
for some caches it would be nice to make sure to not compute twice the same value
Same here about multi-line toString methods
Here again I think we should use `builder.timeField` to handle this
Here again I think we should use `builder.timeField` to handle this
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
oh yeah I missed that :/
hm, thx! I missed something there, sorry.
I'd like if you could rework the assertion so it always runs. Currently it looks a bit brittle in that if the if condition never evaluates to true, the assertion won't be executed and the test will still pass.
This is logic that I think should go into ReplicatedOperation.
ok...but client depends on the transport service anyway no? I think I don't get it
Ah ok, right. I understand now. Yes, so we should have to consistent indeed but we need to deprecate them.
ok...but client depends on the transport service anyway no? I think I don't get it
good point. I didn't think about that. The value to append can be an json object too, so yes the exception should be replaced with logic to deal with that.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I like this much better!
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
also this class should be final.
also this class should be final.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
hopefully the `System.nanoTime` goes away once you merge master in.
I like it!
I always think of `Iterator` as sitting between two entries rather than on the last entry it returned. But I see your way of thinking and am fine with keeping `current`.
nit: extra newline
I have the same thoughts as above for commit time.
I have the same thoughts as above for commit time.
I have the same thoughts as above for commit time.
I see, I didn't notice that, cool no problem
I see, I didn't notice that, cool no problem
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
can we change this to await busy? then we don't need sleep ...
Yes, I think we should make `Job.Builder::setJobType` `public`. The user could change it if they used the low level REST client.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
nit: maybe call this `awaitSearchActive` (or `markSearchActive` if my other suggestion is accepted to move setting the timer here) ? pending refresh is an internal implementation detail..
Should be `SingleValueMap`
this would make sense especially given that their setters accept primitive types
can be specified as `catch (SnapshotCreationException | RepositoryException ex)` in Java ;-)
can be specified as `catch (SnapshotCreationException | RepositoryException ex)` in Java ;-)
Nit: `[] {` -> `[]{`.
Nit: `[] {` -> `[]{`.
Nit: `[] {` -> `[]{`.
Nit: `[] {` -> `[]{`.
Nit: `[] {` -> `[]{`.
nit - an extra d? release**d**Delayed..
nit - an extra d? release**d**Delayed..
nit - an extra d? release**d**Delayed..
this getClass() test is not necessary, super.equals already takes care of it
fantastic thanks a lot
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
same for here, not sure if the full Objects.equals needs to be called
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
maybe use `indexOf(...)` and then `indexInsert(...)` and `indexGet(...)` respectively to avoid determining what the slot is for a key several times? ```java final int slot = processedSeqNo.indexOf(bitArrayKey); if (processedSeqNo.indexExists(slot) == false) { processedSeqNo.indexInsert(slot, bitArrayKey, new FixedBitSet(bitArraysSize)); } return processedSeqNo.indexGet(slot); ```
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
those are hard to debug I can tell u :dancers:
May as well cull the sysout to reduce test noise
May as well cull the sysout to reduce test noise
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
It seems that all the implementations of `DisruptableMockTransport` simply have a getter for some constant value for the local node as their implementation. Maybe just move that getter up into `DisruptableMockTransport` and pass it as constructor parameter while we're changing this anyway? (just to save a bit of noise in the concrete tests :))
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I find it really confusing to have `footerChecksum` at the top-level that is a byte array and `footerChecksum` here that is a string, with only `this.` to indicate which one is being used.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
We need to cast indeed, but I want to give the compiler opportunities to find errors, which is never possible when one starts definiting methods whose generic parameter is only used in the return value. By the way I'm thinking that we could make casts more safe by making category a class instead of a string, and this class would be the base class of the object that the namedwriteables can deserialize
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
can you just call spliStringToSet with true? why do we need another variant when the method this calls is public
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
save -> safe :tongue:
future note - once refresh mapping is gone, we should inline this with index creation.
+1 then we shouldn't forget about it :)
+1 then we shouldn't forget about it :)
nit: the word "event" is no longer relevant
nit: the word "event" is no longer relevant
can't we just call this feature `trim`? `trim` personally makes more sense to me.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
+1 then we shouldn't forget about it :)
I think you can remove `isSSLPropertyPresent` here, it's always true as it's checked above.
+1 then we shouldn't forget about it :)
OK, thanks for the clarification
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
+1 then we shouldn't forget about it :)
can't we just call this feature `trim`? `trim` personally makes more sense to me.
nit: this is normally called the "short hash" so reversing it sounds very odd. :)
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This should be done in reset()
This should be done in reset()
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
How about the following? ```python mean_k, var_k, beta_k, gamma_k = [k.variable(v) for v in [x, mean, var, beta, gamma]] ```
We should state clearly what to use when deprecation ends, there is a risk that we'll remove logging of suspicious session: ```python def decode(self, session_data): try: return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer) # RemovedInDjango40Warning: when the deprecation ends, replace with: # except signing.BadSignature: # logger = logging.getLogger('django.security.SuspiciousSession') # logger.warning('Session data corrupted') # except Exception: # # ValueError, unpickling exceptions. If any of these happen, # # return an empty dictionary (an empty session). # pass # return {} except Exception: return self._legacy_decode(session_data) ```
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
makes sense to me as well now, sorry for the noise.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
yea, I would at least debug log it..., it shouldn't happen
yea, I would at least debug log it..., it shouldn't happen
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
I just realized this will probably cause problems with the test security manager? It stops anything being written outside where we expect (ie in temp dirs controlled by the test). Right now it lets you write anywhere based on the CWD of the test, but I hope to change that in the future. It would probably be best to create a temp dir? So it won't be any better than what you have here with the UUID as far as knowing which dir to expect, but you can give it a meaningful prefix, and it means it will be cleaned up easily.
I don't think you need to fail always but rather fail randomly. This is important to test failures that can come in any step, not just the first.
this could be static
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I think this should be a ParseException instead of an IllegalArgumentException. This would be in line with what we do elsewhere in the codebase (such as in the mapper parsers where any left over parameters after parsing is done are throw in a MapperParsingException).
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
The important assertions here is that the operation changes were rolledback as well. You want to make sure to call `self.assertTableNotExists('migrations_foo')`.
the AnsibleModule class has a method to find executables. Use that method: kinit_cmd = module.get_bin_path("kinit", required=True)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I suspect that some aggregations could be grouped under the same parsed aggregation implementation, so we won't really have a 1-1 relationship between the internal agg and the parsed agg. Like an aggregation of type "sum" (ie InternalSum) and "min" (ie InternalMin) can be parsed back using a same `LongSingleValueParsedAggregation`. In definitive I'm not sure we should add the getType() here or also in the Aggregation interface.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Written while holding a lock and read without lock.
`IOUtils` can handle null
I'd probably write validate's results to a variable and reuse it.
also this class should be final.
also this class should be final.
I think I'd prefer to have a single `static` block, since it's not easily apparent which would be executed first
Is this new or code that was moved? I was looking for where this came from but couldn't find anything.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
this line can be removed
this line can be removed
this line can be removed
how would you feel about naming this method (and it's counterpart) `activatePrimaryMode` ? I was confused a couple of times as initialize and primary terms already used in the IndexShard context (a primary relocation target is a primary shard and is already initializing long before the method is called) .
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
how would you feel about naming this method (and it's counterpart) `activatePrimaryMode` ? I was confused a couple of times as initialize and primary terms already used in the IndexShard context (a primary relocation target is a primary shard and is already initializing long before the method is called) .
Also, can you add an element to maven enforcer plugin for plugins/pom.xml so it fails build cleanly and early if this property is not set? We should also insert a check in pluginservice, if it differs from the directory name, someone manually meddled
can we do this `for (IndexShard shard : this) {...` not a big deal though
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
It'd be nice if the map were `unmodifiable`.
Ah, okay. Thanks.
can we use the index name first in the log, like `[{}] locking all shards, num_shards [{}], index, numShards`
@akarnokd please correct me if I'm wrong, but on machine (VM) with only one core this won't be async at all because `Schedulers.computation()` has `count of threads == Runtime.getAvailableProcessors()`, I'd replace it with `Schedulers.newThread()`
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
good point.... we should be able to get rid of it.
ok...but client depends on the transport service anyway no? I think I don't get it
The message doesn't really make sense because it's missing the "discovery state" part, right now it says it timed out waiting for initial timeout :)
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
Nit: missing `@Override`
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
why is this public? it's only used internally, right
why is this public? it's only used internally, right
why is this public? it's only used internally, right
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
why is this public? it's only used internally, right
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
this is much better!! ð
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
why is this public? it's only used internally, right
This worked well in my testing. It can be made a bit more resilient in the event a package doesn't split as expected. ```suggestion raw_pkg_details = {'name', package} # or maybe # raw_pkg_details = {'name': package, 'version': '', 'release': ''} nvr = package.rsplit('-', 2) try: return { 'name': nvr[0], 'version': nvr[1], 'release': nvr[2], } except IndexError: return raw_pkg_details ```
This worked well in my testing. It can be made a bit more resilient in the event a package doesn't split as expected. ```suggestion raw_pkg_details = {'name', package} # or maybe # raw_pkg_details = {'name': package, 'version': '', 'release': ''} nvr = package.rsplit('-', 2) try: return { 'name': nvr[0], 'version': nvr[1], 'release': nvr[2], } except IndexError: return raw_pkg_details ```
Can this use `b_output_path` from line 291? ```suggestion b_output_path, ```
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
This worked well in my testing. It can be made a bit more resilient in the event a package doesn't split as expected. ```suggestion raw_pkg_details = {'name', package} # or maybe # raw_pkg_details = {'name': package, 'version': '', 'release': ''} nvr = package.rsplit('-', 2) try: return { 'name': nvr[0], 'version': nvr[1], 'release': nvr[2], } except IndexError: return raw_pkg_details ```
last `%version` should be `%major_minor_version`
I liked generator approach more: it's more readable in terms of separating a distinct logical step from a higher-level flow.
What is this supposed to achieve? Modules are cached on import, they'll be picked up from that cache regardless of the pointers being listed in `sys.modules`.
Is this change intentional? Seems like the metavar should be something like "RELEASE_BRANCH".
In our discussion about semaphores I understood a different model we keep a semaphore per index/shard directory (like the on the disk locks but in memory). That would be pruned when the folders are pruned. I see where you were heading. I'm fine with either way.
You defined this method as a helper, but are calling `shardLock(id, 0)` manually all throughout the code still, it would be good to change all of those instances to `shardLock(id)`
youtube-dl does not use non-browser user agent.
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
please log the exception here as well we really wanna see what was going wrong
I think you should pass in the request here instead of empty params
I realize the example already here used this form, but I think it is clearer to use `== false` for inverted conditions.
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
I think we should fix our datastrucuture first and don't make Path trie super complicated and flexible. This should be fixed first before we make this change here.
you can just use a glob here ie: ``` blobNamePrefix = blobNamePrefix == null ? "" : blobNamePrefix; try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, blobNamePrefix + "*") { //.... } ```
I think the indentation was better before, indicating these lines are a continuation of the try with resources.
I think the indentation was better before, indicating these lines are a continuation of the try with resources.
:heart:, this is one that I've wanted to do for a long time.
@puzan `rabbitmqctl status` doesn't support `vhost`. I run RabbitMQ 3.6.16. As quick fix, I added `add_vhost=True` as default argument to `_exec` to have something like this : ```python def _exec(self, args, run_in_check_mode=False, split_lines=True, add_vhost=True): .... some code here .... if add_vhost: args.insert(1, '-p') args.insert(2, self._vhost) ```
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
I think we should increment the term, and log that we've done so.
you should assign a new list instance (or clear the `abortBenchmarkNodeStatuses` list) to make sure we are not reading an instance that already has some status in the list.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
you should assign a new list instance (or clear the `abortBenchmarkNodeStatuses` list) to make sure we are not reading an instance that already has some status in the list.
> 6 shard copies? That's rather useless in a system like ES We do have people using more then 3 shards so that lead to the idea of having the default scale with it. Thinking about it more I think the main usage for having so many copies is auto-expand-replicas-like usages, where you want to have shard copies available on all active nodes. In those case I think you mostly care about the data being on everything thatâs up and not be bound by durability guarantees. In that case I would be fine with waitForActiveShards default to 1 and allow people to set things differently on the index level if the want different default (when we do that change). > This setting is of limited use anyhow as it does not provide the guarantee that most users are after Correct - this setting is meant to be used to limit the scope of events that will be indexed into less than a given number of shards. It should be coupled with a check of the response of each write operation.
I think we should increment the term, and log that we've done so.
Doesn't actually throw `IOException`.
Isn't it more clear that method names start with a verb? like`evaluatePoolingFailureAnalyzer()`
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
make the error a bit more understandable for users? Like "processor x doesn't support some of the provided configuration parameters" and list them like you do already...
I think when this is rewritten, I would prefer to have an `.isConcreteIndex()` method on `AliasOrIndex` to avoid the double negatives in comparisons, I had to stare at this for a while to validate it is working correctly.
I think this will be clearer if we say - "// precreate incoming indices and popluate them with the relevant types"
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
style wise, I think `getV3Key` reads easier
> probably we should make such constants (e.g. the ones in IMC.java) private in the future. +1
> probably we should make such constants (e.g. the ones in IMC.java) private in the future. +1
Same here for `compareAndSet`
I've never liked using the constants like this here in tests. The reason that I don't like is because if someone has their IDE open and accidentally inserts a character into one of the settings keys (e.g., `indices.memory.index_buffer_size` -> `indices.memory.index_buffer_sizes`) then the tests will continue to pass and so we've silently broken things. I would prefer the string literals just be copied and pasted here: `"indices.memory.index_buffer_size"` instead of `INDEX_BUFFER_SIZE_SETTING.getKey()`. Break the build early and often. :smile: (This applies to other similar uses in these rest of this diff.)
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
Do we need to catch `AttributeError`? It looks unnecessary since d2a26c1a90e837777dabdf3d67ceec4d2a70fb86 :thinking:
It seems nothing is done when `check_mode` is enabled.
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
It could be safer to add vserver to the query
I think the unlock calls should always be in a finally block
I'd rather chose a common unit here instead of converting to nanos. ``` java TimeUnit common = initialDelayUnit.compareTo(periodUnit) < 0 ? initialDelayUnit : periodUnit; final long initial = common.convert(initialDelay, initialDelayUnit); final long period = common.convert(period, periodUnit); ```
nit - an extra d? release**d**Delayed..
I think this results in double logging, we will log this here too, no? https://github.com/elastic/elasticsearch/pull/11545/files#diff-9a7b643d56430763f42de913657ca798R125
good catch on delta > 0
good catch on delta > 0
must be param prefixes now
must be param prefixes now
I think the logging in this class is unneeded. if you debug it you can add it back
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
we should check the exception is what we expect (assert part or all of the message)
Missing a space here after `id`
Missing a space here after `id`
how about `onGet` as a name instead of primer
how about `onGet` as a name instead of primer
can we use a limit variable that looks like `int limit = indexMetaData.numberOfReplicas() + 1; // one for the primary` and then bound the loop with `<` instead of `<=` it took me a while :)
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
should we use a long just to be on the paranoia side of things
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I think the unlock calls should always be in a finally block
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
In general this can be simpliefied to `if info.get('status) == 200`
Sorry, right, I was confused by the child and _child looking similar.
Do we have to keep cutting to `other_length`? ```suggestion joined_column_names, ```
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Sorry, right, I was confused by the child and _child looking similar.
we can't take this one out of the try catch, it protects agains corruption. I think we should rename `buildMetadata` to `loadMetadata` and set both commutUserData and metadata in it.
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
This should be done in reset()
can we use a regular foreach here on dataNodes? I think its cleaner
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
Maybe we could fold primaryTerms and activeAllocationIds into a single object. Both currently store values that are indexed by shard number. Could be sth like IndexShardMetaData.
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
Change "param required" to "parameters are required"
Looks good now!
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
also this class should be final.
also this class should be final.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
also this class should be final.
I wonder how long this would work ;)
s/HashMap<String, Object> expected/Map<String, Object> expected
I wonder how long this would work ;)
can we just do it even for `size == 0`
can we just do it even for `size == 0`
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
no need for this to be public
Nit: missing `@Override`
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
This branch in untested :thinking:
nit: extra line
nit: extra line
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
The first two of these fields are unused. I think that's right, and we should remove them and also `ec2Bucket`, by generating the key and token and then passing them into the bucket's constructor.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
I see that we need it from another package, I think it's ok.
since this is a `FixedBitSet` I wonder why renamed everything to use bitArray? I don't mind. Just curious.
This seems very error prone, since it relies on CPU scheduling, network latency, or even whether the test is using mocked networking...
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
I wonder if we want a trace message here...
I think this is wrong? I this is an indexing request on a replica and we're here, that means that there is already a doc with this id. In this case we want to just ignore the request. +1 on what Simon said regarding not changing this code.
Afraid not, we generally use Spring's `Assert` class. I can change this when we merge it.
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Construction now loses the side effect of a `NullPointerException` when this class is misused by giving `null` values for everything except `sourcePath`, which could lead to new, unexpected `NullPointerException`s upon use.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
this deserves a sep issue I guess but good catch
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
I think it would be valid to fallback to a generated salt if none is set (for other use cases), but it doesn't necessarily need to be part of this PR.
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
yeah, I'm on the fence my self. It's just one (cached) thread we spawn per cluster task (which then executes all of the call backs). Not sure wether you saw this in the profiling as a potential time consumer when it was doing it before. I don't feel too strong about it though.
can we log with a "-->" prefix? i.e., "--> done ... " . Makes it easier to find & grep.
why not native boolean type instead of Boolean object? Also, we use the package names as prefix for modules settings, so I would go with `plugins.isolation` compared to `plugin.isolation`.
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
Got it but I think the reason why a `Supplier` was added is wrong.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
After seeing the mess that these kinds of "constants your children set" have caused in aggregations I'd prefer to have `shouldCancelChildrenOnCancellation` be abstract.
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
This looks not quite right. I'm not 100% sure, but I'd do: ``` + logger.warn("unable to start GCE discovery service", e); ``` and let the logger do its job with the exception. I'm tired though - airplanes. So don't take what I type at face value.
What's the point of this? Remove.
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
I know this is a pattern we use everywhere but I don't like the name `success` to mean "I've forked this request and now it's the listener's problem" but I don't know a better name.
Should be: ```python elif state == 'absent': ``` state is always defined, and can only be "present" or "absent".
Request -> ExplainLifecycleRequest
I think I would still like it better as it avoids reverse-engineering a toString() impl.
See #1353 for concern about the parameter name "time" (similar parameters in other operators are called "timespan", "timeout", "interval", "period", "intervalDuration", etc.; those parameters that have pretty much the same function should have the same name).
See #1353 for concern about the parameter name "time" (similar parameters in other operators are called "timespan", "timeout", "interval", "period", "intervalDuration", etc.; those parameters that have pretty much the same function should have the same name).
Since using casting, why not just use the following code: ``` java return ((Transformer<T, R>) transformer).call(this); ```
Actually, there is no need to add more type parameters but just do an unchecked cast or raw type cast: ``` java @SuppressWarnings("unchecked") //... return (Observable)lift(OperatorIgnoreElements.<T>instance()); ``` Note that `instance()` does this re-cast as well since the operator is stateless.
Since using casting, why not just use the following code: ``` java return ((Transformer<T, R>) transformer).call(this); ```
Since using casting, why not just use the following code: ``` java return ((Transformer<T, R>) transformer).call(this); ```
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
Request -> ExplainLifecycleRequest
Actually, there is no need to add more type parameters but just do an unchecked cast or raw type cast: ``` java @SuppressWarnings("unchecked") //... return (Observable)lift(OperatorIgnoreElements.<T>instance()); ``` Note that `instance()` does this re-cast as well since the operator is stateless.
Actually, there is no need to add more type parameters but just do an unchecked cast or raw type cast: ``` java @SuppressWarnings("unchecked") //... return (Observable)lift(OperatorIgnoreElements.<T>instance()); ``` Note that `instance()` does this re-cast as well since the operator is stateless.
It should always return a list.
Actually, there is no need to add more type parameters but just do an unchecked cast or raw type cast: ``` java @SuppressWarnings("unchecked") //... return (Observable)lift(OperatorIgnoreElements.<T>instance()); ``` Note that `instance()` does this re-cast as well since the operator is stateless.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
That's not going to work. That code expects the String to point to a File. I've opened an issue to get an `InputStream` variant so I'd rather wait for that.
Actually, there is no need to add more type parameters but just do an unchecked cast or raw type cast: ``` java @SuppressWarnings("unchecked") //... return (Observable)lift(OperatorIgnoreElements.<T>instance()); ``` Note that `instance()` does this re-cast as well since the operator is stateless.
Actually, there is no need to add more type parameters but just do an unchecked cast or raw type cast: ``` java @SuppressWarnings("unchecked") //... return (Observable)lift(OperatorIgnoreElements.<T>instance()); ``` Note that `instance()` does this re-cast as well since the operator is stateless.
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
maybe we should have a constant somewhere with _source and _ingest? pretty sure we already use them somewhere else
nit: `an` -> `a`
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
```suggestion - The repository name. ```
use `reverse()` rather than a hard coded URL.
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
This should be done in reset()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
BackpressureUtils didn't exist at that point, so I am considering how to consolidate this type of logic as we keep repeating this type of non-trivial code and it is easy to get wrong. I'm okay with merging ... we really should spend some time figuring out the core patterns so we can encode the state machine, similar to what BackpressureUtils and AbstractOnSubscribe have started formalizing.
I believe this will inject non-determinism ... notifications will be capable of interleaving and being out of order. I think we need to combine this with `ScheduledObserver` which maintains a queue and event loop for handling each notification sequentially on the given scheduler.
This should have a description like the other fields.
++ on debug message
good catch on delta > 0
note that this will make the test below fail because it asserts that an IllegalStateException will be thrown. One workaround is to pack the assertion into a method and override that method in the test with a noop
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
redundant parens `% (names)`
hey can we rename this V1 to ChecksummedTranslogStream
hey can we rename this V1 to ChecksummedTranslogStream
hey can we rename this V1 to ChecksummedTranslogStream
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think we should also check the taskId here
I think we should also check the taskId here
I actually meant to keep this with a range of random value for the frequently branch. Something like ``` long count = frequently() ? randomPositiveLong() : 0; ```
can we make those two constructors call the 3rd one so that we can centralize validation (if we ever add some)
I don't think you need @Before here, the parent method already has it.
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
can we add bogus non relevant settings? Would be good to know they don't mess up with things.
Ok, sounds fine.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
I wonder if using fromSeq and toSeqNo (instead of size) will result in this being less confusing.
I think you should pass the Result here. Maybe also add an assertion in the ctor that the result is either `Result.DELETED` or `Result.NOT_FOUND`.
I think this will result in a double info logging - we already logged at info level when discovering this.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
That is much easier to read!
to make this simpler, I think we should add a method `addCustomFields` to the `AcknowledgedResponse` object instead and just call `response.addCustomFields(builder)` in `AcknowledgedRestListener`. As a follow-up we can then make AcknowledgedResponse implement `StatusToXContent`.
change `duration` to `period`
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I think it might be nice to move this in `TcpHeader`
I think it might be nice to move this in `TcpHeader`
+1 on adding UUID
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
can we add some trace logging here? I can imagine it will save some WTF at some point.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
can we please unpack the tuple right away instead of using v1 v2? just easier to read
can we add some trace logging here? I can imagine it will save some WTF at some point.
This constructor doesn't seem to be necessary.
can we add some trace logging here? I can imagine it will save some WTF at some point.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
can we please unpack the tuple right away instead of using v1 v2? just easier to read
can we please unpack the tuple right away instead of using v1 v2? just easier to read
This constructor doesn't seem to be necessary.
Sure, a separate PR sounds good.
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
Why using StopWatch? this create many short live objects for not resean.
Why using StopWatch? this create many short live objects for not resean.
Why using StopWatch? this create many short live objects for not resean.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
spaces missing after `if` and before `{` ð¡
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
I have seen this comparison in several places. Maybe, it makes sense to move inside Snapshot and have something like `boolean hasName(String repository, String name)` method where it will take place? Not sure if `hasName` is a good name for this method though.
I have seen this comparison in several places. Maybe, it makes sense to move inside Snapshot and have something like `boolean hasName(String repository, String name)` method where it will take place? Not sure if `hasName` is a good name for this method though.
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
Written while holding a lock and read without lock.
maybe update the docs to say this is a terms query rather than a bool
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
Written while holding a lock and read without lock.
True, this message is unused since its introduction in d725cc9734272f867d41f7236235c28b3931a1b2. I think we can remove `_parse_header()` hook, see #15802.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I'm not sure what you're testing here with this assertion. why not just repeatedly call `stopRandomNode()`, and maybe check that the cluster is alive and healthy before shutting down the last node.
This can be `UnaryOperator` instead of `Function`.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
I would add a note saying this does not relate to the partitions file system formatting.
same request for assertion.
same here re enumSet.toString
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
can we order the clients? :) I'm OCDing ..
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
can we use `== false` instead of `!`
alright - lets get this in
I think this test can be moved somewhere else and use the single node base class? this doesn't really have a disruption in it and will be slow...
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
If you do this, you can also simplify things above. ```java Gauge.builder("git.info", () -> 1L) .description("Project Git information").strongReference(true); .tag("branch", getOrDefault(props.getBranch())); .tag("id", getOrDefault(props.getShortCommitId())); .tag("time", getOrDefault(props.getCommitTime())); .register(registry); ```
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Ok, sounds fine.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think you can initialize the capacity.
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
Yeah, I'd make these a hard check and throw a `new IllegalArgumentException("Usage doesn't look like UnifiedHighlighter")`.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
Yes, but we can address this in another release.
Yes, but we can address this in another release.
Yes, but we can address this in another release.
I would assert for memory/time/parallelism here (and also in the other upgrade test) -- so we know that actually the version caused the upgrade. (ie like we do for the other hashers)
I see, thanks for investigating.
A suggestion: '--config' repetition could be avoided using: ``` if self.config: config_param = ''.join(' --config %s=%r' % (key, value) for (key, value) in self.config.items()) else: config_param = '' ``` _DONE_
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
space missing between closing and opening bracket: `false){`
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
This thread can leak and fail the test, I think that you need to clean it up (join on it in tear down).
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
don't prettyprint please we don't test this here
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
can we do this once we check the write is indeed allowed? Also I think it will be clearer if we have this in a dedicated method (`markLastWrite` or something like that)
I think it makes sense to do it here too, especially the need for remove especially should be contained in the utils method I think.
I think it makes sense to do it here too, especially the need for remove especially should be contained in the utils method I think.
I think I've seen this somewhere else today ;-)
In these cases its acceptable to use randomize testing's `rarely()` or its like to cover either branch randomly.
here you can use a `scaledRandomIntBetween` something like ``` Java int length = randomIntBetween(1, scaledRandomIntBetween(PAGE_SIZE * 2, PAGE_SIZE * 20)); ``` this will use the upper bound rather than the lower bound when we run with nightly=true.
Correct me if I am wrong but these filters have to be executed in a serial fashion one after another, right? So you can make this async if you need to on top of the blocking loop? I would like to see an example where this is used to understand the rational please :)
I think this can use the FileSystemUtils method you added to get all paths as an array for a directory, instead of creating the stream here.
+1 to randomize on 1 node cluster as well - wasn't aware of this to be honest...
maybe just catch (Exception)
maybe just catch (Exception)
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think it will be cleaner? not a biggy though
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
`verify(object)` is the same as `verify(object, times(1))`.
The theoretical idea here is to try to move away from overriding methods like crazy at the transport level. So if refactorings need to happen, we can (hopefully) just move the stubs to different locations, opposed to dealing with a billion different tightly couple to the `Transport` interface tests.
I feel like it'd be cleaner to have this be the result of falling off the end of an if statement chain.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
The indentation is off here and the rest of the way through this test.
good catch on delta > 0
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
This could be `Strings.hasLength(tokenizerName)`
maybe just `esVersion()`
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
There could be a number indices on a single remote cluster or several remote clusters `remoteIndices.size()` is not a measure of the number of remote clusters `RemoteClusterLicenseChecker.remoteClusterAliases(remoteIndices).size()` should be used instead.
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
ok can we rename the getter then to `getFailedNodeExceptions()`
nit: maybe call this `awaitSearchActive` (or `markSearchActive` if my other suggestion is accepted to move setting the timer here) ? pending refresh is an internal implementation detail..
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
I've noticed this field isn't in 6.x so please remove from the backport
I'd switch the order of these so it matches the declaration order.
args are not used.. we should either remove those from the method sig (which will be consistent with the `println` methods) or pass `String.format(text, args)` to `doPrint`
args are not used.. we should either remove those from the method sig (which will be consistent with the `println` methods) or pass `String.format(text, args)` to `doPrint`
args are not used.. we should either remove those from the method sig (which will be consistent with the `println` methods) or pass `String.format(text, args)` to `doPrint`
For things like fielddata I think it's an important requirement
For things like fielddata I think it's an important requirement
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
same for functions below
For things like fielddata I think it's an important requirement
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
Instead of using `IndexWriter` here, you could use `DirectoryReader.listCommits` (there should be at most `IndexCommit` returned) and then call `IndexCommit.getUserData()` instead. Seems safer since `DirectoryReader` cannot do any writing on the index, doesn't acquire the write lock, etc.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Instead of using `IndexWriter` here, you could use `DirectoryReader.listCommits` (there should be at most `IndexCommit` returned) and then call `IndexCommit.getUserData()` instead. Seems safer since `DirectoryReader` cannot do any writing on the index, doesn't acquire the write lock, etc.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Instead of using `IndexWriter` here, you could use `DirectoryReader.listCommits` (there should be at most `IndexCommit` returned) and then call `IndexCommit.getUserData()` instead. Seems safer since `DirectoryReader` cannot do any writing on the index, doesn't acquire the write lock, etc.
Instead of using `IndexWriter` here, you could use `DirectoryReader.listCommits` (there should be at most `IndexCommit` returned) and then call `IndexCommit.getUserData()` instead. Seems safer since `DirectoryReader` cannot do any writing on the index, doesn't acquire the write lock, etc.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Instead of using `IndexWriter` here, you could use `DirectoryReader.listCommits` (there should be at most `IndexCommit` returned) and then call `IndexCommit.getUserData()` instead. Seems safer since `DirectoryReader` cannot do any writing on the index, doesn't acquire the write lock, etc.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Why use a static block to initialise this? `Sets.newHashSet` can turn this into a 1 liner, and then you can wrap it in `unmodifiableSet`
Rename `calendar` -> `filter`
You already asserted this 2 lines ago, this is a duplicate.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
I think you should fsync after writing these bytes, e.g. `out.getChannel().force(true)`, like the translog code does? Would be horribly unlucky if the user ran this tool then their box crashed and it left the translog corrupt.
I think you should fsync after writing these bytes, e.g. `out.getChannel().force(true)`, like the translog code does? Would be horribly unlucky if the user ran this tool then their box crashed and it left the translog corrupt.
Yes! Thank you.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
I also need to go back and do this for the PutUserRequest
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
This shouldn't be here. You should use ESLoggerFactory instead.
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should only be done in close()
This should only be done in close()
This should only be done in close()
This should only be done in close()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should only be done in close()
s/HashMap<String, Object> fields/Map<String, Object> fields
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
s/HashMap<String, Object> fields/Map<String, Object> fields
s/HashMap<String, Object> fields/Map<String, Object> fields
This should only be done in close()
You will need to include the OAUTH_TOKEN environment variable also.
```suggestion files = sorted(self.storage_dir.joinpath("dotted.path").iterdir()) self.assertFalse(self.storage_dir.joinpath("dotted_.path").exists()) ```
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
I think you can also replace a switch in toQuery
I think you can also replace a switch in toQuery
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
this getClass() test is not necessary, super.equals already takes care of it
this getClass() test is not necessary, super.equals already takes care of it
yeah, I'm on the fence my self. It's just one (cached) thread we spawn per cluster task (which then executes all of the call backs). Not sure wether you saw this in the profiling as a potential time consumer when it was doing it before. I don't feel too strong about it though.
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
this getClass() test is not necessary, super.equals already takes care of it
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
nit: the word "event" is no longer relevant
just nitpicking, maybe we could change the name of the test method that's left, or even remove it? I don't think we need to explicitly test the serialization here anymore...
That assumes `list` can't contain null..if that is not the case ignore
hopefully the `System.nanoTime` goes away once you merge master in.
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
I think that we need to guard against overflow here!
This can just be `System.out.print(msg)` now I think. Thanks for removing the formatting from these print apis! I think that was the real problem, its trappy for a `printf()` to be named anything other than `*printf()`. And in this case the caller can just always `String.format` themselves.
I don't know that we care about closing the handler. It probably does not matter too much, but there should not be any resources hanging around if we properly consume all the requests.
looks like this condition is only actual for `resubscribeBeforeTimeout` test
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
This docstring can be single-lined.
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I'm not too worried about it. We might try some "extract variable/method" refactoring when we merge.
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
you probably intended to write "alias:id,snapshot".
Drop the string constant. :)
Drop the string constant. :)
oh nevermind, I just found the method that called it with null :)
It would make sense to distinguish between plaintext (`redis://â¦`) and SSL (`rediss://`) connections.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we create the exponential back off here and provide a package protected getter for the `BackoffPolicy`? It avoids to jump to another method just to see what kind of policy is created
This logic tried to enforce a minimum version requirement, which the new code does not. Since it doesn't sound like you have added compatibility with older versions (or have any reason to), why not do something like: ``` min_version = '2.4' if loose_srv_version < LooseVersion(min_version): module.fail_json(msg='MongoDB {0] found, the minimum version supported by this module is {1}'.format(srv_version, min_version)) ```
this should use the config system instead
this deserves a sep issue I guess but good catch
Can we fold this into `writeTo` and add a boolean to the signature (maybe `includeRequestHeaders`)? It seems like it just requires adding a if/else block
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
please add a newline after this
please add a newline after this
`try` and `except` statement seems useless: nothing will raise `KafkaError`.
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
`of the it's last` -> `of its last`
`of the it's last` -> `of its last`
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
sneaky, I missed that :)
yields always true
If the error message is different, maybe you can differentiate between the case where we detect a missing START_OBJECT and the case where the underlying Jackson parser throws.
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
I think with this removal the `requestId` is now no longer used and can be removed.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
or just: "return ok;"? :)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
or just: "return ok;"? :)
Oh nevermind, `CodecUtil.checkHeader` is already doing the real check. You really do not trust anyone ;)
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
This is logic that I think should go into ReplicatedOperation.
Ok, sounds fine.
I suspect that some aggregations could be grouped under the same parsed aggregation implementation, so we won't really have a 1-1 relationship between the internal agg and the parsed agg. Like an aggregation of type "sum" (ie InternalSum) and "min" (ie InternalMin) can be parsed back using a same `LongSingleValueParsedAggregation`. In definitive I'm not sure we should add the getType() here or also in the Aggregation interface.
This will fail if `(int)((end - start)/bucketSpan)` is greater than 10000. A check should be added elsewhere to ensure that the window is small enough that this won't happen.
Ok, sounds fine.
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
should we use a long just to be on the paranoia side of things
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
Boost will be set in BaseQueryTestCase. No harm here, but doppelt gemoppelt (I want to try to gradually introduce this expression into the english vocabulary like Kindergarten and Schadenfreude) ;-)
I think we should test cases with score separately from those without scores and retain both types of test.
`expectedType.cast(e)` should remove the need for the unchecked suppression.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
Didn't know about `dematerialize`, then I guess we stick to that convention. Providing a mapper sounds good. Then maybe we could deprecate the current `dematerialize` in Observable.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
this is not needed. createIndex automatically reroutes.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
look into `StreamInput#readMap`
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
look into `StreamInput#readMap`
look into `StreamInput#readMap`
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
look into `StreamInput#readMap`
Error message could mention the erroneous value (`len(self.topic)`). DONE
Nit: `currentThreadNamme` -> `currentThreadName`
You could add an assert that it's not ES 7.x here so we know to remove it
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
I pushed a commit with some edits, let me know if it looks okay.
I pushed a commit with some edits, let me know if it looks okay.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
Looks like the '--' is not necessary since the variable is not used anymore later on.
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
remove this additional line break? :)
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
remove this additional line break? :)
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
maybe this can be static too, and I would rename to assertDeprecationWarnings or expectDeprecationWarnings
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
just please don't add one. There are too many classes already.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
No, I still think that it should not be a method on the `Strings` class.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
That makes me think that ShardInfo needs a public default constructor.
Nit: `active.size()-1` -> `active.size() - 1`
Nit: `active.size()-1` -> `active.size() - 1`
Nit: `active.size()-1` -> `active.size() - 1`
can we check part of the message so we know we got the right exception? ditto for the other cases like this in this file
can we check part of the message so we know we got the right exception? ditto for the other cases like this in this file
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
open reader doesn't need to check for <0 and throw an exception any more.
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
I'd switch the order of these so it matches the declaration order.
Using the % operator. Like: ``` '%s.%s' % (data.group(1), data.group(2)) ```
space missing between ) and {
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I think we should collapse the two above methods, they are always called in sequence.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
nit: extra line
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
Ok, sounds fine.
I think the length of individual byte[] values should also be encoded using vInt.
Same as the double note above, just for long.
I think I prefer the current logic of this method to relying on the return value of get().
I think I prefer the current logic of this method to relying on the return value of get().
Same as the double note above, just for long.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
```suggestion * Executed when a shard returns a fetch result. ```
cool can you update the title of the PR then? :)
Rename the method to something about captures I think now that the utility is gone.
I am ok with what you propose Nik!
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
cool then we can take those out so it is clearer what we have and don't have to do :)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
oh yeah I missed that :/
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
(Not part of this, just asking hypothetically)
nit: "so we assume"...
since finalizePingCycle will call listener.onPing, I think we shouldn't re-throw the exception but rather let finalizePingCycle do it's thing here: ``` logger.warn("[{}] failed to send pings", t, id); finalizePingCycle(id, listener); ``` at a future change we will do the same with UnicastZenPing
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
since finalizePingCycle will call listener.onPing, I think we shouldn't re-throw the exception but rather let finalizePingCycle do it's thing here: ``` logger.warn("[{}] failed to send pings", t, id); finalizePingCycle(id, listener); ``` at a future change we will do the same with UnicastZenPing
since finalizePingCycle will call listener.onPing, I think we shouldn't re-throw the exception but rather let finalizePingCycle do it's thing here: ``` logger.warn("[{}] failed to send pings", t, id); finalizePingCycle(id, listener); ``` at a future change we will do the same with UnicastZenPing
since finalizePingCycle will call listener.onPing, I think we shouldn't re-throw the exception but rather let finalizePingCycle do it's thing here: ``` logger.warn("[{}] failed to send pings", t, id); finalizePingCycle(id, listener); ``` at a future change we will do the same with UnicastZenPing
My idea was to make the BulkRequestSource hold what it has to hold (the failed items), be able to retrieve them and act accordingly from processBulkIndexRequest, rather than have logic to deal with failures within the BulkRequestSource itself. Exposing different getters might help as well, that's another option. I tend to think that extracting the "processing" part would make things cleaner but I may be wrong.
My idea was to make the BulkRequestSource hold what it has to hold (the failed items), be able to retrieve them and act accordingly from processBulkIndexRequest, rather than have logic to deal with failures within the BulkRequestSource itself. Exposing different getters might help as well, that's another option. I tend to think that extracting the "processing" part would make things cleaner but I may be wrong.
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
I think it makes sense to do it here too, especially the need for remove especially should be contained in the utils method I think.
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
++ plural is good
I like `hasSize` better for this because it gives a nicer error message on failure.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
Please change it to `only one thread should call`, remove `be allowed to`.
Thought so ... thanks for the confirmation.
> However, I am not sure if we should do it. why is that? We're building all this machinery to have search availability during the transition, except for this very short moment? I had the same idea about retrying. An alternative would be to do refcounting for closing the engine, to ensure that we only actually close once all in-flight `acquireSearcher` calls have been completed.
got it thank you.
make this synchronized too. it's safer since you modify both references
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
maybe we implement `Iterable<V>`
Such changes in our own source is a good indication there will be generics issues for the users of the library.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
s/y ou/you Also I think upfront is one word.
maybe we implement `Iterable<V>`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
s/y ou/you Also I think upfront is one word.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
can we move this to our `test` infra? I think we do this in another place in our code (or one of our branches)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
while I get that the preference for a for loop... but the inconsistency of how xcontent is parsed is annoying.. if we do it everywhere using a `while (...)` then we should stick to that... if we want to change to a for loop, then lets do it across the board
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
can we move this to our `test` infra? I think we do this in another place in our code (or one of our branches)
Since this is now a suffix, can you change the constant name to reflect that, eg `CITY_DB_SUFFIX`? And same with country as well.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
maybe we implement `Iterable<V>`
maybe we implement `Iterable<V>`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Ok, sounds fine.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
`ConcurrentLinkedQueue` seems to be expensive for the usage pattern; you could get away with `SpscLinkedQueue` or `SpscLinkedArrayQueue` here (no need for `MpscLinkedQueue` because the offer side is inside a synchronized block).
maybe we implement `Iterable<V>`
same - wdyt about a condition suffix/
maybe we implement `Iterable<V>`
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
same - wdyt about a condition suffix/
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I would make the class `final`, and these members `public final`
maybe we implement `Iterable<V>`
Ok, sounds fine.
you are right, sorry
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
I think the unlock calls should always be in a finally block
I see that we need it from another package, I think it's ok.
This eagerly shuts down the chain and does not wait for the delayed values.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
I see that we need it from another package, I think it's ok.
> nesting several layers of Observables, Observers and Subscriptions. The entire library is based on composition. If we were seeking to avoid that we wouldn't be using a functional style so unless there is a strong performance reason (that isn't a bug with one of the operators themselves) I don't see that as a reason to add a helper operator.
`file reopened` -> `file is reopened`
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
I think you can initialize the capacity.
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
braces please. for the rest of the method too. (I realize you just tweaked this to be a lambda but it would be good to fix this as two line single statement `if`s are dangerous and evil).
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
is this limited to TLDs? it seems all labels are limited to 63 characters.
It should now be possible to make up the `RoleArn` and `SecretAccessKey` using the seeded RNG rather than by concatenating strings like this. They can reasonably be different each call.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
Here again I think we should use `builder.timeField` to handle this
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
Here again I think we should use `builder.timeField` to handle this
Here again I think we should use `builder.timeField` to handle this
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
similarly, equals uses the hash while hashCode doesn't
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
That used to be like one character in the antlr syntax....
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
@jasontedor Thanks. I think `:` is a reserved char on Windows and if used in logging.yml but no node name is configured then it might fail the creation of the log file. But I don't think there's something we can do.
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
These calls need to be wrapped in try/except to handle exceptions, otherwise the exception will just bubble up to the user. We provide a decorator in the EC2 module utils that handles boto3 exceptions and does retries for you. https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ec2.py#L71
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
You might want to have a superclass here just so common stuff is obvious like `source` and (sometimes) `read`.
These calls need to be wrapped in try/except to handle exceptions, otherwise the exception will just bubble up to the user. We provide a decorator in the EC2 module utils that handles boto3 exceptions and does retries for you. https://github.com/ansible/ansible/blob/devel/lib/ansible/module_utils/ec2.py#L71
`Connection` and `ConnectionError` imports seems to be unused.
This isn't thread-safe. To be safe, it shouldn't just be wrapped in a synchronised block. We should avoid calling a health indicator while holding a lock as it's code that we don't control and could result in deadlock if someone does something a bit daft in their indicator and calls back into the registry.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
this could be static
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
would you mind reverting the variable name change, at least temporarily? it confuses the review
Another `_` java 9 will be mad at
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
it's a shame java need this...
I think this the right trade off here.
This is why I do not like `assertEquals`; this is backwards from expected and actual. Instead: `assertThat(t1.v1(), equalTo(2L))`.
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
You are already in `ESRestTestCase` so you don't need the to reference the class.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
You know, we can add a checkstyle check for those....
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
same - wdyt about a condition suffix/
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
In some previous discussion for other builders we tried to set default values for non primitive types that have a default, setting to null effectively means use the default, same as specifying `field: null` in the json query. Maybe we can keep this here (and in the following setters that have default values)
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
you can use Arrays.copyOfRange
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
This lambda does not need to be a statement block.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
Missing a space here after `id`
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
Missing a space here after `id`
This lambda does not need to be a statement block.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
nit: can we move the look up of the primary to the callers that pass null? this method is hairy enough :)
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
These changes should be in a separate test method. Leave the `testOnBackpressureDropSynchronous` as is and introduce `testOnBackpressureDropWithActionSynchronous`.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
instead of this check just override `public void onRejection(Throwable t)`
Why using StopWatch? this create many short live objects for not resean.
Same here with naming, we have `delayedPrepareBulkRequest` and `delayPrepareBulkRequest` which are confusing when vars and functions are named so similarly
Same here with naming, we have `delayedPrepareBulkRequest` and `delayPrepareBulkRequest` which are confusing when vars and functions are named so similarly
I think the indentation was better before, indicating these lines are a continuation of the try with resources.
now that we have `GsubExpression` (hurray!). we should probably define an equals, where the `pattern` field is compared using the `.pattern()` command since that seems to be the proper way to check equivalence between `Pattern` objects. then these assertions would be simplified as well.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think some of them could be private
we decided to live on the edge and have fun. The concern was around non ascii codes breaking tooling but CI seems happy. Let's see how far we get.
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
we decided to live on the edge and have fun. The concern was around non ascii codes breaking tooling but CI seems happy. Let's see how far we get.
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
lets just use IOException that's much better for this purpose and it's checked
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
lets just use IOException that's much better for this purpose and it's checked
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
lets just use IOException that's much better for this purpose and it's checked
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
randomInt cannot be within the loop, otherwise it changes at every iteration...
can this be moved to securityutils please? we don't want to expose a lot of this as public
can this be moved to securityutils please? we don't want to expose a lot of this as public
``` java assertThat(provider.fetchCount, is(1)); ```
nit: extra line
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
nit: extra line
nit: extra line
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
I think we should leave this method for java api bw comp
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
thanks a lot! should we have a test that leverages this extension point for score functions? I thought we had one already but not sure anymore
I see that we need it from another package, I think it's ok.
Additionally, I like calling these `getFinalDecision` in ClusterAllocationExplanation.java because it differentiated it from the node decisions, how do you feel about that? (It would also probably change `getExplanation()` to `getFinalExplanation()`)
I see that we need it from another package, I think it's ok.
Additionally, I like calling these `getFinalDecision` in ClusterAllocationExplanation.java because it differentiated it from the node decisions, how do you feel about that? (It would also probably change `getExplanation()` to `getFinalExplanation()`)
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
As an aside, it's weird that this is a factory and all the others are accessors. Is `TestScheduler`'s constructor `public`? If so we should just remove this static method that implies there's somehow a shared scheduler for tests.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
I don't think you need to this, the internal cluster will call the node settings automatically.
Looks like this should be in `secondJustError()` and vice versa
nit: IOException never thrown
This test should assert that the headers are correct.
This test should assert that the headers are correct.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I had the same thought, but I guess the point is to properly validate things when they get set to the builder, so that non supported values will never be serialized. I assume that we do that already, otherwise we should.
I don't think we need an implementation for this method however I think this could be `RamUsageEstimator.shallowSizeOfInstance(CountedBitSet.class) + (bitset == null ? 0 : bitset.ramBytesUsed());`. You could even fold `RamUsageEstimator.shallowSizeOfInstance(CountedBitSet.class)` into a static final constant.
You need to use `BytesValues.scratch` instead of allocating a spare here in order for `copyShared` or `currentValueHash` to work correctly.
removed? It does not seem to be used.
I'm not sure the length comparison buys you much. I'm fairly sure `String#endsWith` already checks that super duper early.
I guess we should call this method `updateAppliedStates()` and the field should be `appliedStatesByVersion`.
I guess we should call this method `updateAppliedStates()` and the field should be `appliedStatesByVersion`.
I guess we should call this method `updateAppliedStates()` and the field should be `appliedStatesByVersion`.
Did you push the change that added it? I don't see it.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You don't but I certainly did ð
We don't need to delay the error ... just emit it and skip everything else. We confirmed this behavior in `observeOn`: https://github.com/ReactiveX/RxJava/issues/1680
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Similar to above, `new TreeMap` should be wrapped with `Collections.unmodifiableSortedMap()`.
I don't think this line should be modified.
I think you can initialize the capacity.
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
It might be cleaner and create less new-Function objects if you extract this compute block as a new method, say "newIndexFieldDataCache(fieldName)", then just do `fieldDataCaches.computeIfAbsent(fieldName, this::newIndexFieldDataCache)` here.
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
Nit: Almost ;-) To be or not to be, and also where, that is the question.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
also this class should be final.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I wonder if later on we are able to get rid of QueryRegistration and register stuff straight-away rather than when calling buildQueryParserRegistry. we will see later though!
indentation is off after other changes
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
this would make sense especially given that their setters accept primitive types
indentation is off after other changes
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
lets just use IOException that's much better for this purpose and it's checked
Ok, sounds fine.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Those two tests are new right? You could do the same with one that takes a `Duration` and one that takes `null` afteR. No need for the deprecation. Besides, I'd appreciate a separate PR for this as they are unrelated.
This isn't needed client-side.
This isn't needed client-side.
This isn't needed client-side.
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
instead of this check just override `public void onRejection(Throwable t)`
instead of this check just override `public void onRejection(Throwable t)`
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
Should use `{}` logging style instead of string concatenation here
good catch on delta > 0
you can do some streaming java8 magic here.
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
the start cluster does this.
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
I think we don't need the AtomicBoolean here. We should protect from double closing on the level below
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
Yannick and I discussed this option first, but this needs extra care, for instance to not copy the write lock. It's also a bit more involved if we want to track statistics as well for the first source. In the end it's not clear to me which option is better.
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
Sorry, I thought the URL could be used to provide the username and password.
this is much better!! ð
No, I still think that it should not be a method on the `Strings` class.
> Though I do prefer that it fails fast instead of lazily later. ++
> Though I do prefer that it fails fast instead of lazily later. ++
Nit: missing `@Override`
Nit: missing `@Override`
Nit: missing `@Override`
Nit: missing `@Override`
> Though I do prefer that it fails fast instead of lazily later. ++
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
this is much better!! ð
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
this is much better!! ð
this is much better!! ð
I don't think that complexity is warranted. Just keep constructor injection please.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I had not though about option 2 but I really like the fact that it does not require to add a new API. But if this argument does not resonate to you, feel free to push the change as-in, I don't have too strong feelings about it.
s/HashMap<String, Object> expected/Map<String, Object> expected
s/HashMap<String, Object> expected/Map<String, Object> expected
would be great if this logic could be unit tested.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
Nit: " . " -> ". "
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
I think I'd just let deleted and updated come out in the toString rather than worry about that. I think it was a mistake that I did it. I don't think it is worth the complexity of the map. It is just a couple of fields that we can ignore.
Not sure, but maybe we can add null-check for innerQuery here like in other nested query builders (e.g. BoostingQueryBuilder)? That would avoid potential NPEs or null checks in doXContent later.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
If this stays an Object we have a problem with builder equality when we do the roundtrip doXContent->fromXContent that we currently do in the tests. I had similar problems in TermQueryBuilder already. Imagine an Integer (126) that is rendered to JSON (or other XContent) via `writeValue(Object value)` which inspects the class of the Object and then chooses a type-specific method to write it. On the parser side, this is always read back as a String ("126") with `parser.text()`. So if we check those builders for equality we will fail with `126 != "126"`. For the lucene query produced in the end this difference won't matter (we convert all values to String there), but I think it would be great to keep that property that when we have builder A, generate XContent for that and parse it to Builder B, they should be the same. One option would be to push up the String-conversion we later do in `toQuery()` anyway to the constructor. I'm not sure if the java API currently is to lenient here by allowing any `Object` as argument, since parsing only works for object types that correctly parse back as String. Another option might be to allow parsing to numeric values using `objectText()` like in CommonTermsQueryParser. Not sure about which way is better to be honest.
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
`o1 +=8;` <== format this file again :)
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
can you please add the `clusterStateVersion` to the assert message
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
It would be worth requiring that `jobId` and `jobType` are not `null`.
Similar to above, `new TreeMap` should be wrapped with `Collections.unmodifiableSortedMap()`.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
assertBusy uses by default 10 seconds, no need to specify it here again
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
This has to use the new settings API.
you could also use `ElasticsearchAssertions.assertHitCount` here
I think the unlock calls should always be in a finally block
it would be awesome to have some doc-strings on these settings
Given that signaling this failure up the stack would be a mess, I wonder if partial results really bring us any advantage. I suggest we fail (call the listener's failure handle). When we'll move the security searches over a different threadpool, partial results would be even scarier.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
good catch on delta > 0
caller does: ``` if (indexMetaData != null && indicesService.hasIndex(indexMetaData.getIndex()) == false) ``` so it doesn't care if indexMetaData is null...
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
What do you think of: ``` private void handleReadResponse(long from, int maxOperationCount, long maxRequiredSeqNo, ShardChangesAction.Response response) { maybeUpdateMapping(response.getIndexMetadataVersion(), () -> { synchronized (ShardFollowNodeTask.this) { globalCheckpoint = Math.max(globalCheckpoint, response.getGlobalCheckpoint()); final long newMinRequiredSeqNo; if (response.getOperations().length == 0) { newMinRequiredSeqNo = from; } else { assert response.getOperations()[0].seqNo() == from : "first operation is not what we asked for. From is [" + from + "], got " + response.getOperations()[0]; buffer.addAll(Arrays.asList(response.getOperations())); final long maxSeqNo = response.getOperations()[response.getOperations().length - 1].seqNo(); assert maxSeqNo== Arrays.stream(response.getOperations()).mapToLong(Translog.Operation::seqNo).max().getAsLong(); newMinRequiredSeqNo = maxSeqNo + 1; // update last requested seq no as we may have gotten more than we asked for and we don't want to ask it again. lastRequestedSeqno = Math.max(lastRequestedSeqno, maxSeqNo); assert lastRequestedSeqno <= globalCheckpoint: "lastRequestedSeqno [" + lastRequestedSeqno + "] is larger than the global checkpoint [" + globalCheckpoint + "]"; coordinateWrites(); } if (newMinRequiredSeqNo < maxRequiredSeqNo) { int newSize = (int) (maxRequiredSeqNo - newMinRequiredSeqNo) + 1; LOGGER.trace("{} received [{}] ops, still missing [{}/{}], continuing to read...", params.getFollowShardId(), response.getOperations().length, newMinRequiredSeqNo, maxRequiredSeqNo); sendShardChangesRequest(newMinRequiredSeqNo, newSize, maxRequiredSeqNo); } else { // read is completed, decrement numConcurrentReads--; if (response.getOperations().length == 0 && globalCheckpoint == lastRequestedSeqno) { // we got nothing and we have no reason to believe asking again well get us more, treat shard as idle and delay // future requests LOGGER.trace("{} received no ops and no known ops to fetch, scheduling to coordinate reads", params.getFollowShardId()); scheduler.accept(idleShardChangesRequestDelay, this::coordinateReads); } else { coordinateReads(); } } } }); } ``` PS - note the difference in handling of `lastRequestedSeqno` - I think the way you had it had a bug.
this deserves a sep issue I guess but good catch
we can't take this one out of the try catch, it protects agains corruption. I think we should rename `buildMetadata` to `loadMetadata` and set both commutUserData and metadata in it.
alright I can't see a reason why one would have the two clients using different protocols. Then reading from settings becomes overkill. I am sorry, I think I'd go back to the method that you had before then. It was a good one, I just needed to see it gone to realize that :)
I also think that this should log the input instead of the normalized input.
Nitpick - the term `The value` is used twice here with different meanings each time. I suggest changing `...if IE changes the values...` to something like `...if the IE configuration changes...` to resolve the ambiguity.
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
This shouldn't be here. You should use ESLoggerFactory instead.
I'd rather have a different parameter there. However, that would add complexity. It might be better to not handle missing field or NaN and Inf at all and let the user sort it out with range filters.
I spoke to @rmuir and this is enabled 99% of the time in master (file leak detection) we can just remove this layer.
IMO this is useless since it will throw an NPE anyway the check is obsolet
not sure if we should make such a big deal out of it
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
just name it `read`
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
good that you added this assertion :)
good that you added this assertion :)
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
Can we fold this into `writeTo` and add a boolean to the signature (maybe `includeRequestHeaders`)? It seems like it just requires adding a if/else block
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
`file reopened` -> `file is reopened`
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
same here re iterator.remove()
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
minor nit: "int he" -> "in the"
Can you add an assertion post `super` call that the ssl handler is still first? That way a future change does not accidentally mess up necessary ordering on handlers.
Can you add an assertion post `super` call that the ssl handler is still first? That way a future change does not accidentally mess up necessary ordering on handlers.
Can you add an assertion post `super` call that the ssl handler is still first? That way a future change does not accidentally mess up necessary ordering on handlers.
It feels squicky to ignore the exception. Personally I'd `assert false : "Exceptions not expected here."` and `logger.error` about it.
It feels squicky to ignore the exception. Personally I'd `assert false : "Exceptions not expected here."` and `logger.error` about it.
Please fix identation.
canceled -> cancelled
I would give this method the same name as the method above: `enoughShardsActive`. One operates at index, the other at the shard level. To make things even more explicit, the above method could have parameters (IndexRoutingTable, IndexMetaData) and this one (IndexShardRoutingTable, IndexMetaData). This would also leave it up to the caller to deal with `indexMetaData == null`.
I think it would be clearer if `_get_view_func` did the exception handling and returned `None` for this case.
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
oh yeah I missed that :/
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
this looks a bit odd of a toString() implementation as it's very much targeted towards that one logging call site. Maybe change it to be more generic.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
But even if we don't rename, users who implement the interface will have to adapt their code due to the method signature change? So I think we could break this too? I don't expect many users, if any, to implement this interface at the moment.
The aim is to ensure `switchIfEmpty` returns `Single`. This fluent writing works if `switchIfEmpty` returned any other type.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
look into `StreamInput#readMap`
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
I think s/lang/defaultLang/
> We should never rely on the ordinal for any enum anywhere We've been relying on ordinals for serialization for a while, asserting that the ordinals do not change in the tests.
You could combine "errors" and content of `pofile` in a file. Here is a untested approach: ``` py logfile_format = """\ Invalid input: %s ----- Output of %r: %s """ pofile_log = '%s.log' % pofile with open(pofile_log, "w") as fobj, open(pofile) as fpofile: fobj.write(logfile_format % (errors, pofile, fpofile.read())) ```
Done. I would prefer using `action` as a parameter of `get` instead of being an attribute of `KafkaTopics`.
Done. I would prefer using `action` as a parameter of `get` instead of being an attribute of `KafkaTopics`.
For consistency with other `org.springframework.boot.actuate.autoconfigure.*` packages, this should probably be something like "Auto-configuration for Micrometer Tracing".
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Nit: `reject` -> `rejected`
that's just a suggestion, I tend to do thsi this way: ```Java Runnable toRelease = () -> {}; //... semaphore.acquire(); toRelease = semaphore:release ``` that way you don't need to check any boolean logic and can just call the runnable
that's just a suggestion, I tend to do thsi this way: ```Java Runnable toRelease = () -> {}; //... semaphore.acquire(); toRelease = semaphore:release ``` that way you don't need to check any boolean logic and can just call the runnable
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
`if (serializedStates != null) {` is no longer needed
can we get away with passing `null` instead of `TrustSelfSignedStrategy`? I'd prefer to have the certificates we trust only stored in the truststore
something is wrong in this sentence :)
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
something is wrong in this sentence :)
`if (serializedStates != null) {` is no longer needed
`if (serializedStates != null) {` is no longer needed
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
can't we just call this feature `trim`? `trim` personally makes more sense to me.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
It looks like with the latest changes serializedStates can no longer be null, so we should probably remove `Nullable` here.
oh sorry, I had missed that you used the filtered collection below
`if (serializedStates != null) {` is no longer needed
thanks for adding this
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
`them` -> `them;`
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
`if (serializedStates != null) {` is no longer needed
It looks like with the latest changes serializedStates can no longer be null, so we should probably remove `Nullable` here.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
`them` -> `them;`
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I would probably throw an exception instead of accepting null here.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
master_election.filter_data [{}] is a leftover I think
I think this assert in particular (the timestamp one) could be greatly simplified by asserting inside of the script itself instead of setting a new field value.
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
I think we want to test index level blocks too here
I think we want to test index level blocks too here
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
braces please. for the rest of the method too. (I realize you just tweaked this to be a lambda but it would be good to fix this as two line single statement `if`s are dangerous and evil).
Exactly, or in that particular case, from their child since constant-score queries can only have one child.
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
Ok, just checking.
Can we fold all these assertions into a single one? I think this should cover enough. ``` assertThat(shardChangesRequests, contains(new long[][]{ {0L, 8L}, {9L, 8L}, {18L, 8L}, {27L, 8L}, {36L, 8L}, {45L, 8L}, {54L, 8L}, {63L, 8L} })); ``` Moreover, the leader should not return more than the requesting batch size. Here, we request 8 operations, but it returns 9 operations.
For python 2.6 compatibility, this and the following four strings have to look like `cmd = "ping {0} {1}".format(vrf, dest)`
maybe make this variable final? just better indicate it will never change
Did you push the change that added it? I don't see it.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I think it'd be nice to have an assertion on the text of one description just so we can look at it.
These changes should be in a separate test method. Leave the `testOnBackpressureDropSynchronous` as is and introduce `testOnBackpressureDropWithActionSynchronous`.
It seems that all the implementations of `DisruptableMockTransport` simply have a getter for some constant value for the local node as their implementation. Maybe just move that getter up into `DisruptableMockTransport` and pass it as constructor parameter while we're changing this anyway? (just to save a bit of noise in the concrete tests :))
Originally, it was a description. I don't see much point keeping duplicate data. So `origin` and `zh-CN` should be enough.
Can we avoid using camel_case here? I think `testMaxConcurrentReads` should be good.
Fix test: ```suggestion 'ext': 'mp4', ```
we should totally not have this method, one more reason to not implement the interface.
For python 2.6 compatibility, this and the following four strings have to look like `cmd = "ping {0} {1}".format(vrf, dest)`
not sure if we should make such a big deal out of it
can we have a shorter name here maybe `forceReadFromFileChannel`
A problem for another PR, I assume.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
I don't like the fact these aren't snake_case, surely we can convert
nit: "so we assume"...
just a little hint, there is a cloudstack optimized fail_json `self.fail_json` which would also return the zone on failure as return value. But this is fine as well
Minor typo of `local` instead of `locale` in the exception message.
I wonder if we should void this check if indexUUID or that.indexUUID is IndexMetaData#INDEX_UUID_NA_VALUE . We can still run into this value when reading existing state files.
+1 on adding UUID
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
I think you can initialize the capacity.
Minor typo of `local` instead of `locale` in the exception message.
Counters, including `FunctionCounter`, in Micrometer are expected to be monotonically increasing, which is not the case with these rates, I believe. If you were to convert these, they would be gauges in Micrometer.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I wonder if we should void this check if indexUUID or that.indexUUID is IndexMetaData#INDEX_UUID_NA_VALUE . We can still run into this value when reading existing state files.
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
Yeah I was thinking that. Should return a `Subscription` that closes the subject and removes the internal listener. Would be good to have unit tests too. Have a look at the existing Android specific classes to see how we use Robolectric to test them. I'm also getting a weird compilation error in IntelliJ (it says `PublishSubject<float[]>` is not a subtype of `Observable<float[]>`, but it builds fine using Gradle, so that might be an issue with my IDE setup? Apart from that looks good to me. @benjchristensen I was wondering though, in what way does this not merge cleanly? I don't see with what this would conflict and GH isn't reporting merge conflicts for me.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
nit: extra plus in `+ 5 * + 3600000L`
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
+1 on adding UUID
I think we can remove this sentence.
Is there really no alternative to a plain except? This would even catch KeyboardInterupt etc which we surely don't want. Which exceptions can occur here? As a last resort you can use except Exception, but I'd prefer it explicit.
can be specified as `catch (SnapshotCreationException | RepositoryException ex)` in Java ;-)
can be specified as `catch (SnapshotCreationException | RepositoryException ex)` in Java ;-)
This should have a @DeprecatedConfigurationProperty with the replacement key
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
If it is not required, you don't have to add `'required: False`.
If it is not required, you don't have to add `'required: False`.
Minor typo of `local` instead of `locale` in the exception message.
spaces missing after `if` and before `{` ð¡
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
You should catch the error twice to produce an error message suitable for each query
Another `-1l` I'd consider replacing with the field [proposed previously](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
chop blank line
You should catch the error twice to produce an error message suitable for each query
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
Please add `type='str'`
can we change this to await busy? then we don't need sleep ...
This should only be done in close()
This should only be done in close()
I'd switch the order of these so it matches the declaration order.
I'd switch the order of these so it matches the declaration order.
I'd switch the order of these so it matches the declaration order.
This is great! No more @Inject!
oh right sorry I keep missing that.
Oh I see. I like it better the current way better then. I was confused by the fact that you could have both ALWAYS and PARTIAL in the same doc, maybe we could add an assertion that it never happers.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think this can move to before the threads start - will be nastier
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
I think this should happen first to make this PR less complex
I think we want to test index level blocks too here
I'm not sure if it's worth the complexity of this code here just to provide a better message as to why an index service got removed. If you think it's useful, maybe factor the logic of determining the `AllocatedIndices.IndexRemovalReason` based on currentState and newState into a helper method so it can be reused by removeIndices
can we make this an enumSet called writeAllowedStateForReplica (and the same for primary). It's getting out of hand :) also please right them in order recovering, post_recovery, started, relocated
since this is all for dealing with a TaskResult._result, move the _result processing code to it's own method and call from here? ``` python def _clean_result(self, result, ignore): <...> ``` It could even be staticmethod or module scope method ``` python def clean_result_dict(result_dict, ignore): <..> return result_dict ``` so, clean_result() could: ``` python if self._result: result._result = clean_result(result._result, ignore) return result ```
I think we want to test index level blocks too here
Maybe change to `AtomicLong`? Took me awhile to get it :thought_balloon:
I think we want to test index level blocks too here
I think this should happen first to make this PR less complex
Here again I think we should use `builder.timeField` to handle this
I think we can clean up the http/transport/gatway settings here
Those two tests are new right? You could do the same with one that takes a `Duration` and one that takes `null` afteR. No need for the deprecation. Besides, I'd appreciate a separate PR for this as they are unrelated.
spaces missing after `if` and before `{` ð¡
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
I think we can clean up the http/transport/gatway settings here
I think we want to test index level blocks too here
can we make this an enumSet called writeAllowedStateForReplica (and the same for primary). It's getting out of hand :) also please right them in order recovering, post_recovery, started, relocated
strictly speaking I think we need to read this from disk after the flush - i.e., make sure that what's on disk is OK.
Fine with me, just a thought :)
Just discussed it with Robert and indeed this fsync is not necessary.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
No need for quotes here.
if we do what I suggested aboce this can go away
if we do what I suggested aboce this can go away
I'd just leave the ternary operation there.
I think it's always a single node cluster, but I'm good to keep it like this.
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
This constructor doesn't seem to be necessary.
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
there are more similar problems below
we can randomly use a different cluster? or maybe downsize the global cluster to 1 node for this test? I also wonder if we should consider to run tests with one node as well? the minNode=2 was only convenience...
s/HashMap<String, Object> fields/Map<String, Object> fields
s/HashMap<String, Object> fields/Map<String, Object> fields
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
```suggestion if isinstance(e.cause, compat_HTTPError) and e.cause.code == 403: ```
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
s/HashMap<String, Object> fields/Map<String, Object> fields
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
s/HashMap<String, Object> fields/Map<String, Object> fields
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
You can use a for-each syntax here: `for (ObjectCursor<byte[]> cursor : bytesList)`
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can use a for-each syntax here: `for (ObjectCursor<byte[]> cursor : bytesList)`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
By restoring the code as it was before in my polish, this test fails. The replicat set is erased by the connection URI. I don't know if that's a new behaviour of the driver or if I messed up the change but I'd appreciate some help there.
By restoring the code as it was before in my polish, this test fails. The replicat set is erased by the connection URI. I don't know if that's a new behaviour of the driver or if I messed up the change but I'd appreciate some help there.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
please - I can help if you want
please - I can help if you want
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Maybe catch `Exception` instead. If there is a jvm error (out of memory and such) then we should just bail and not try to execute the onfailure processors.
I think that we can do without this flag, it could be a util method that returns a boolean depending on whether values are set or lookup details are.
Maybe catch `Exception` instead. If there is a jvm error (out of memory and such) then we should just bail and not try to execute the onfailure processors.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
For backwards compatibility reasons, we must also read the old file.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This problem would go away entirely if the registry wasn't also responsible for calling the indicators.
This isn't thread-safe. To be safe, it shouldn't just be wrapped in a synchronised block. We should avoid calling a health indicator while holding a lock as it's code that we don't control and could result in deadlock if someone does something a bit daft in their indicator and calls back into the registry.
Can `schema_editor.quote_name` be used here instead? ```suggestion schema_editor.quote_name(value) if isinstance(value, str) else value ```
It would work but it would be a kind of implementation detail abuse since `value` is not an SQL identifier but an expression. This whole method should likely live on `connection.ops` instead.
I like the level of detail in these tests, the degree of splitting them in into so many test methods and helpers is maybe a little bit hard to read. The following are just some suggestions of how to maybe group some of the tests. e.g the null, true and false test could be grouped into one case that checks allowed fields fort the allowMalformed field.
I like the level of detail in these tests, the degree of splitting them in into so many test methods and helpers is maybe a little bit hard to read. The following are just some suggestions of how to maybe group some of the tests. e.g the null, true and false test could be grouped into one case that checks allowed fields fort the allowMalformed field.
I'd switch the order of these so it matches the declaration order.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
since this is done once. should we be more restrictive here to actually have a proper path format? just a `.` is pretty flexible and would allow ``` hello. .hello ```
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I find this API very awkward since it's available on every type but should only be used on `Single<Notification<T>>`. I don't have a better suggestion though. Except defining it yourself and using a Kotlin extension function.
I find this API very awkward since it's available on every type but should only be used on `Single<Notification<T>>`. I don't have a better suggestion though. Except defining it yourself and using a Kotlin extension function.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
I don't think that complexity is warranted. Just keep constructor injection please.
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
Use `==` to compare booleans. The `is` test should *only* be used when you really want to compare identities of objects! Finally, there's no need to compare a boolean to `True` or `False` explicitly; simply write `elif self._has_migs(local):`.
This can all fit on one line.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
This can all fit on one line.
This can all fit on one line.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
could be a instance variable, as used in all tests
This can all fit on one line.
This can all fit on one line.
This can all fit on one line.
could be a instance variable, as used in all tests
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
I think that rather than copying this code from FixedExecutorBuilder, this logic should be pushed up to a package-private static method in the super class.
could be a instance variable, as used in all tests
could be a instance variable, as used in all tests
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
This can all fit on one line.
randomInt cannot be within the loop, otherwise it changes at every iteration...
This can all fit on one line.
I think this is a left over.
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
can you please add the `clusterStateVersion` to the assert message
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
If we assume that all surrogate pairs need encoding, I think we can make this simpler? ``` int startIndex = i; for (i++;i< s.length() && doesNotNeedEncoding.get(s.charAt(i)) == false; i++) { assert Character.isSurrogate(s.charAt(i)) == false || doesNotNeedEncoding.get(s.charAt(i)) == false; } final byte[] bytes = s.substring(startIndex, i).getBytes(UTF_8); ```
If we assume that all surrogate pairs need encoding, I think we can make this simpler? ``` int startIndex = i; for (i++;i< s.length() && doesNotNeedEncoding.get(s.charAt(i)) == false; i++) { assert Character.isSurrogate(s.charAt(i)) == false || doesNotNeedEncoding.get(s.charAt(i)) == false; } final byte[] bytes = s.substring(startIndex, i).getBytes(UTF_8); ```
If we assume that all surrogate pairs need encoding, I think we can make this simpler? ``` int startIndex = i; for (i++;i< s.length() && doesNotNeedEncoding.get(s.charAt(i)) == false; i++) { assert Character.isSurrogate(s.charAt(i)) == false || doesNotNeedEncoding.get(s.charAt(i)) == false; } final byte[] bytes = s.substring(startIndex, i).getBytes(UTF_8); ```
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
this should be `public static final Setting<TimeValue> INDICES_CACHE_REQUEST_CLEAN_INTERVAL = Setting.positiveTimeSetting("indices.requests.cache.clean_interval", TimeValue.timeValueSeconds(60), false, Setting.Scope.CLUSTER);`
Can you fix the indentation
maybe tell the engine of a global checkpoint and see that it is persisted? now we don't test this as global checkpoint stays the same.
Why all these extra levels of indirection? I think this addSupplier, and the other one added here could just be implemented inside `keystore` that takes a FileSupplier, and the File variant calls that method instead of this indirection.
This enforce that the exception is thrown, but the current code doesn't *always* throw one.
just fix a number, I don't think randomizing this adds much.
It would be worth requiring that `jobId` and `jobType` are not `null`.
Yes, I think we should make `Job.Builder::setJobType` `public`. The user could change it if they used the low level REST client.
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
Actually it needs to be `AttributeError` to keep everything happy (which the import machinery will turn into an `ImportError` if it was sourced by an import)
What uses this? And why is forbidden APIs not angry about passing in String,int here... i feel like i banned that method. I dont like it as its wired to 127.0.0.1 in non-test code.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Got it...sounds weird though that you use your own `FetchSubPhase` which depends on a custom `HighlighterContext`, as the context is pretty much bound to our `HighlightPhase`. I wonder now if its constructor should have been package private from the beginning too :) Anyways, I think a `protected` constructor would do the trick for you instead of `public`, I'd prefer that so it's clear that people are not supposed to instantiate a `HighlightQuery` in the ordinary usecase.
maybe s/VS/?/ since we don't know yet if the valuessource is applicable
good point.... we should be able to get rid of it.
can we pass empty string and empty bytes ref to this so it's a valid ctor? we should fail if these args are null
on second thought, this might be easier after adding proper settings (with defaults).
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
on second thought, this might be easier after adding proper settings (with defaults).
on second thought, this might be easier after adding proper settings (with defaults).
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
on second thought, this might be easier after adding proper settings (with defaults).
on second thought, this might be easier after adding proper settings (with defaults).
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
in this case is it worth peaking at the file again and check if the first byte is valid even for version 0? maybe we should do that check first and then move to V1 and fail hard if we see a CorruptIndexExp
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
can this be in try-with logic.... you are not closing this input stream at all
Missing a space here after `id`
Missing a space here after `id`
oh nevermind, I just found the method that called it with null :)
Nit: `candidate` -> `candidates`
Nit: `candidate` -> `candidates`
oh nevermind, I just found the method that called it with null :)
we could pass a glob with regex:xxx to newDirectoryStream if we want
@JakeWharton well, it depends on use case, I guess somebody who wants to use `await(time)` on `TestSubscriber` either wants it to be: - "max timeout to fail the test instead of looping infinitely", like @Timeout in JUnit. so in that case value will be someting like `1, MINUTE` while actually data will arrive much faster. - "precise value to check some concurrency algorithm with expected timeouts" so in that case "success" long (relatively) after actual timeout can be considered as a bug. I'd be ok with something like this: ``` java while (true) { if (valueCount >= expected) { return true; } if (System.nanoTime() - start > timeoutNano) { return false; } Thread.sleep(1); } ``` So that only flakiness of last `sleep()` will be amortized. Current implementation increments `timeout` after each `sleep(1)` and may collect some relatively big error, like you had 150 `sleep(1)` but actually spent `200ms` which is ~25% error and seems possible in real life.
Similar to above, `new TreeMap` should be wrapped with `Collections.unmodifiableSortedMap()`.
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
did you plan to add here the list of nodes or something? looks like there is a missing argument.
this is not concurrency-safe. Closing can be happening concurrently to this.
this is not concurrency-safe. Closing can be happening concurrently to this.
this is not concurrency-safe. Closing can be happening concurrently to this.
this is not concurrency-safe. Closing can be happening concurrently to this.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
I think this check comes too early. Templates have not been applied yet. I suggest doing this once IndexMetadata has been created.
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
We will need stronger assertions here too.
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
can we replace the Math.max with an assertion? it should never happen and we shouldn't protect for it.
This should be done in reset()
No, that allows `0`, `off`, and `no` for `false`, and `1`, `on`, and `yes` for `true`.
Given what we are doing below I think we should declare the `ValueType` as `ValueType.VALUE` here because otherwise its confusing when reading the code to see INT here and then the fact that we might expect a String that isn't just an int value below. We should then add an else to the below method to throw an exception if anything other than int or String is supplied.
I guess it's because the async shard fetch logic - the shards are not assigned when the call returns.
This should be done in reset()
This should be done in reset()
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
Nit: `automattic` -> `automatic`
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
This should be done in reset()
This should be done in reset()
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
This should be done in reset()
This should be done in reset()
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
Nit: `automattic` -> `automatic`
Thinking about this more, I wonder if we should have this run-even-if-there-is-nothing-to-do complexity. I'll reach out to discuss.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
This should be done in reset()
This should be done in reset()
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
Nit: `automattic` -> `automatic`
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
I wonder if we should extend `ChannelReference` to implement `Closeable` and have the `.close()` method decrement the ref and throw an error if it's not now at 0 (which it should be since it's being closed in this case). That way we error immediately if the translog is closed but something incremented the channel ref. What do you think of this? Dunno if you think it might make ChannelReference too complex.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
Maybe it's too verbose, but I suggest to rephrase to `apply filtering on the argument of the grouping function instead`, as `grouped field` maybe be confusing.
we should never have an iterable here, right? it should all be "raw" values, I think calling extractRawValues in fetchPhase when from source will fix it.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
I think it is fine: we only build one search context per request per shard.
I would be using a `Set` in this circumstances.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I don't think it's important for now
I don't think it's important for now
can't we just call this feature `trim`? `trim` personally makes more sense to me.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I am glad we simplified things by just renaming id to tag, that's a good choice
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
can't we just call this feature `trim`? `trim` personally makes more sense to me.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
I think this can move to before the threads start - will be nastier
can't we just call this feature `trim`? `trim` personally makes more sense to me.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
can't we just call this feature `trim`? `trim` personally makes more sense to me.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
add action name pls.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
No need to be fancy here, just: `logger.debug("got exception", throwable);`.
Ah, ok. As I said, I've never used docker-machine, so I assumed that it actually connects to the machine (using that shell) and exports the environment from there. If that's just the format, then yes, it really doesn't matter (as long as it is a format you can parse :) ). Both `bash` and `sh` are fine for me, use whatever you want then.
Done. I would prefer using `action` as a parameter of `get` instead of being an attribute of `KafkaTopics`.
Can you issue a `RuntimeWarning` here telling the user that Django falls back and it might be time to clean up using `squashmigrations` and link to https://docs.djangoproject.com/en/dev/topics/migrations/#squashing-migrations.
Ah, ok. As I said, I've never used docker-machine, so I assumed that it actually connects to the machine (using that shell) and exports the environment from there. If that's just the format, then yes, it really doesn't matter (as long as it is a format you can parse :) ). Both `bash` and `sh` are fine for me, use whatever you want then.
Done. I would prefer using `action` as a parameter of `get` instead of being an attribute of `KafkaTopics`.
We can't use hardcoded ports.
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
can we add some trace logging here? I can imagine it will save some WTF at some point.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Ah sorry missed that
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
I am ok with what you propose Nik!
you can do some streaming java8 magic here.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
+1 lets get rid of it! If we don't use it there is no need for the complexity!
you can omit `ElasticsearchException` here it's unchecked
`of the it's last` -> `of its last`
@mikewiebe this will only work if command_timeout/connect_timeout is set as ENV var, but won't work if someone sets the timeout in ansible.cfg within `persistent_connection` section. You can do the following instead. ``` + +from ansible import constants as C from ansible.module_utils.network.nxos.nxos import load_config, run_commands from ansible.module_utils.network.nxos.nxos import nxos_argument_spec, check_args from ansible.module_utils.basic import AnsibleModule @@ -131,6 +133,8 @@ from ansible.module_utils.basic import AnsibleModule def check_ansible_timer(module): '''Check Ansible Timer Values''' + command_timer = C.PERSISTENT_COMMAND_TIMEOUT + connect_timer = C.PERSISTENT_CONNECT_TIMEOUT ``` This takes care of both the scenarios.
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
We don't need any of these `build*Properties()` methods; all the kafka specific properties are already handled by parts of `KafkaProperties`.
I'd put the method taking `Duration` above the deprecated one, not below.
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
nit: "so we assume"...
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
good point.... we should be able to get rid of it.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
```suggestion out = run_gluster(['volume', 'heal', name, 'info'], environ_update=dict(LANG='C', LC_ALL='C', LC_MESSAGES='C')) ```
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
`of the it's last` -> `of its last`
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
oh yeah I missed that :/
Got it but I think the reason why a `Supplier` was added is wrong.
can we make that -1 a constant and use it in all the relevant places? it would be easier to remove it once we go to 4.0
I think that `node);` fits in the previous line
(Not part of this, just asking hypothetically)
this needs a message
can we use different ids for the different indices? I find this super confusing to reason about. Maybe also add the routing value you expect to be used to the id.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
Nit: `reject` -> `rejected`
the reason why I suggested to make it configurable is that we could pass in our own values in tests that's all... not a big deal
or rather pass it to `spawnNativePluginControllers` and change it's signature to `spawnNativePluginControllers(Path pluginPath, Map<String,String> env)` I don't think we need to depend on `Environment`
why not native boolean type instead of Boolean object? Also, we use the package names as prefix for modules settings, so I would go with `plugins.isolation` compared to `plugin.isolation`.
`application` needs to be null/empty
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
the reason why I suggested to make it configurable is that we could pass in our own values in tests that's all... not a big deal
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
the reason why I suggested to make it configurable is that we could pass in our own values in tests that's all... not a big deal
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Good for me, I didn't have a strong feeling about it.
I think we can simplify this and make sure we have 1 shard, no replicas.
why not native boolean type instead of Boolean object? Also, we use the package names as prefix for modules settings, so I would go with `plugins.isolation` compared to `plugin.isolation`.
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
This was not a typo
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
These look like leftovers.
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
As far as I can see you did not hence why I am asking here. The code I've referenced makes an explicit setup using `NettyConnectorFactory`. As far as I can see we'd lose that as soon as an url is set.
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
Somehow we need to distinguish "background" tasks for the cluster from those started by rest actions.
you can just use a glob here ie: ``` blobNamePrefix = blobNamePrefix == null ? "" : blobNamePrefix; try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, blobNamePrefix + "*") { //.... } ```
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
s/The tasks has/In case the task has/
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
s/The tasks has/In case the task has/
++ . I like this better then the listener.
++ . I like this better then the listener.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
dunder dun dunnnnn
dunder dun dunnnnn
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
this is the default..
You should also test `nextUp(-0f)` ?: ```` assertEquals( NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", -0f, null, false, false), NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", +0f, null, true, false)); ````
You should also test `nextUp(-0f)` ?: ```` assertEquals( NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", -0f, null, false, false), NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", +0f, null, true, false)); ````
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
No, you are right, I didn't realize the need for api users before going through the whole changes.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
You could use `map.computeIfAbsent()`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Oh I thought it aleardy did! Then maybe a better way would be to make this method pkg-private? (I'm just trying to keep the API to a bare minimum)
Oh I thought it aleardy did! Then maybe a better way would be to make this method pkg-private? (I'm just trying to keep the API to a bare minimum)
Oh I thought it aleardy did! Then maybe a better way would be to make this method pkg-private? (I'm just trying to keep the API to a bare minimum)
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
looks like a left-over
Can you change this assertion to match the whole error string? It might be a bit fragile to future changes in tests, but since we don't randomize anything here the error should stay stable for a bit and this makes it easiert to understand the whole error structure from reading the test.
I like the level of detail in these tests, the degree of splitting them in into so many test methods and helpers is maybe a little bit hard to read. The following are just some suggestions of how to maybe group some of the tests. e.g the null, true and false test could be grouped into one case that checks allowed fields fort the allowMalformed field.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
Trailing zeros are stripped on PostgreSQL, so I changed to ```suggestion self.assertRegex(now_string, rf"^.*\.\d{{1,{precision}}}") ```
Trailing zeros are stripped on PostgreSQL, so I changed to ```suggestion self.assertRegex(now_string, rf"^.*\.\d{{1,{precision}}}") ```
I think this should throw IAE if you pass null - that's 100% of the time a bug
Oops, sorry, brain fart. :)
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Why use a static block to initialise this? `Sets.newHashSet` can turn this into a 1 liner, and then you can wrap it in `unmodifiableSet`
I think this should throw IAE if you pass null - that's 100% of the time a bug
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
I think an absurdly high limit could still be helpful? (in a follow-up PR)
I think an absurdly high limit could still be helpful? (in a follow-up PR)
I think an absurdly high limit could still be helpful? (in a follow-up PR)
I think an absurdly high limit could still be helpful? (in a follow-up PR)
I think an absurdly high limit could still be helpful? (in a follow-up PR)
I would add a note saying this does not relate to the partitions file system formatting.
I would add a note saying this does not relate to the partitions file system formatting.
Nit: Almost ;-) To be or not to be, and also where, that is the question.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
maybe reverse this check? (`expected.equals(map) == false`)
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
alright - didn't see it immeditately
we can randomly use a different cluster? or maybe downsize the global cluster to 1 node for this test? I also wonder if we should consider to run tests with one node as well? the minNode=2 was only convenience...
alright - didn't see it immeditately
it seems that the latch is useless? or maybe you wanted to enable the recovery half way through the "indexing operations"? Also, this suffers from the same racing condition - if the ops that are now in flight when the relocation comes in are not first in the onLockAcquiredActions list, we will have a deadlock.
we can randomly use a different cluster? or maybe downsize the global cluster to 1 node for this test? I also wonder if we should consider to run tests with one node as well? the minNode=2 was only convenience...
I think it might makes sense to split this into `initalPosition` and `initialState`.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I know we already checked it but I think it's important to make sure all data deletion goes through the same place where we do (and will extend) all the required safety checks. We might even want to restrict access to the delete methods in NodeEnv via forbidden API.
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
I know we already checked it but I think it's important to make sure all data deletion goes through the same place where we do (and will extend) all the required safety checks. We might even want to restrict access to the delete methods in NodeEnv via forbidden API.
I know we already checked it but I think it's important to make sure all data deletion goes through the same place where we do (and will extend) all the required safety checks. We might even want to restrict access to the delete methods in NodeEnv via forbidden API.
And so does my proposal, by typing `existing` more strongly than the compiler can do (because of erasure) but is clearly correct and eliminates the suspicious call inspection.
We don't format method name that way. Please look at the rest of the codebase for inspiration.
update java docs
I know we already checked it but I think it's important to make sure all data deletion goes through the same place where we do (and will extend) all the required safety checks. We might even want to restrict access to the delete methods in NodeEnv via forbidden API.
Great. I now wonder if this whole block can move into the `JoinHelper`. If the code above returned its `mode` and called `becomeLeader()` then the `JoinHelper` should be able to work out the right things to do with the join.
also, please make a note to make this configurable.
its not clear to me when `listener` could ever be null here (and also below in `clusterStateProcessed`)? if it is possible, then the method should have @Nullable annotation for listener
I think this can all fit on one line more cleanly if you break after the equal sign.
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
sneaky :D, throwing from the `finally` block to supercede the possibly thrown exception from `grok.captures`
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
General thought for these various `Double.NaN`'s .. should we be returning `null` instead (and subsequently returning a `Double` instead of `double`)? E.g. because some fields may actually have `NaN`'s as real values, and lacking a field isn't quite the same as not-a-number? Not sure, probably needs several more opinions :)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
sneaky :D, throwing from the `finally` block to supercede the possibly thrown exception from `grok.captures`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think it should be a LinkedHashSet since we rely on doc ID order for tie-breaking.
Ok, sounds fine.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Should use `Timer.start(meterRegistry)` so that you are using the registry's clock for this sample.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we can now remove this condition as the client can not be null because we throw now `new ElasticsearchException("Unable to configure Azure compute service", e);` in the CTOR
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
yields always true
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
This can be updated to return `maxHttpFormPostSize`.
This can be updated to return `maxHttpFormPostSize`.
You can drop `final` from here, we generally don't use it for local variables.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I wonder whether we should use `unicastConnectExecutor` for this and keep it contained (and throttled).
I wonder whether we should use `unicastConnectExecutor` for this and keep it contained (and throttled).
I wonder whether we should use `unicastConnectExecutor` for this and keep it contained (and throttled).
Group names are supposed to be named similar to variables, i.e. alphanumeric and underscore. So at least the prefix should adhere to that. Besides that, look at this PR: https://github.com/ansible/ansible/pull/52748
Super tiny nit: could we wrap the `SUPPORTED_DATE_METRICS` with brackets (`[...]`)? Makes it easier for the user to see the difference in message and dynamic values. Ditto to below with `unsupportedMetrics`
I like `hasSize` better for this because it gives a nicer error message on failure.
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
take out boost and queryname once you rebased
oh yeah I missed that :/
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
I just saw @s1monw replacing `Lists.newArrayList` with `new ArrayList<>()` a few days ago. Maybe that way is out preferred way now? +1 on removing the warning though.
If `resumeFunctionInCaseOfError` returns something like `Observable.never.toSingle`, we should still `unsubscribe` the original one.
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
last `%version` should be `%major_minor_version`
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
We used dd rather than cat in the jail, chroot, and zone plugins. Can use similar code here. I believe that code also does this without a shell which could be nice for making this more generic (not that most installs will be lacking bash but it's always nice to avoid) and potentially avoiding shell quoting issues.
What does qubes do if the file already exists in QubesIncoming? If it overwrites, I think this code will work. If it errors, we'd have to deal with the error here.
I am not sure about this one. I feel like if it's part of `RepositoryData` it needs to be in json. Otherwise it cause things like `fromXContent` with additional parameters. Would it be a huge deal to pass gen id alone as an additional parameter instead of adding it to `RepositoryData` itself. I feel like it's not really a repositories concern, if you see what I mean.
Can use the '{}' syntax here for `DATA_BLOB_PREFIX`
We could add a default value (.i.e. `< 6.1 `) in the parameterized message because > Automatically enabling security for older trial license (null) might be slightly obscure.
We could add a default value (.i.e. `< 6.1 `) in the parameterized message because > Automatically enabling security for older trial license (null) might be slightly obscure.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
I find it really confusing to have `footerChecksum` at the top-level that is a byte array and `footerChecksum` here that is a string, with only `this.` to indicate which one is being used.
don't drink and code ð» (same line twice)
Same here. The origin of the issue is in `lift`: https://github.com/ReactiveX/RxJava/blob/1.x/src/main/java/rx/Observable.java#L144
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
Same here. The origin of the issue is in `lift`: https://github.com/ReactiveX/RxJava/blob/1.x/src/main/java/rx/Observable.java#L144
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
What do you think about using `argparse.SUPPRESS` instead (as suggested in the previous patch)? e.g. ```suggestion parser.add_argument( '-v', '--verbosity', default=1, type=int, choices=[0, 1, 2, 3], help=argparse.SUPPRESS if 'verbosity' in self.suppressed_arguments else ( 'Verbosity level; 0=minimal output, 1=normal output, ' '2=verbose output, 3=very verbose output' ), ) ``` This way the list of options will not be misleading anymore and at the same time default values will be available for subcommands :thinking: This should increase backward compatibility.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
oh nevermind, I just found the method that called it with null :)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Can you explain what moving out the call to splitAndValidatePath() from getMapper() saves here? As far as I understand it it seems better to centralize this in getMapper, but I might miss something here.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
This condition will never evaluate to `true` as we'll get an NPE when dereferencing a `null` instance of type `ExecutorHolder` in the line above.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
We tend to make these static.
remove this additional line break? :)
`o1 +=8;` <== format this file again :)
`o1 +=8;` <== format this file again :)
oh nevermind, I just found the method that called it with null :)
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
If we went for one suggestion that I left above, on filtering the list rather than the current per host predicate, the selector could decide what to do directly. Either go for another node, or return an empty list, and we would always throw whenever we get an empty list (after also trying to resurrect nodes). The current extension point seems a bit limited in that it doesn't give context on the set of nodes that are to be tried.
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
Nit: space between the cast operator and the target.
Randomized runner should not need these @Test annotations.
can we add bogus non relevant settings? Would be good to know they don't mess up with things.
I think we can add here the loading for the simple id cache, if that is used. (gettable from: indexService.cache().idCache())
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
this check is not needed, the default is `False` if you should never get a `None` at this point
Yes, but we can address this in another release.
Yes, but we can address this in another release.
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
Would be removed if `get_bin_path` used.
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
+1 this really cleans up code in several places
Note for anyone else: this is just copied from SuggestSearchTests which was removed below. It looks right to me.
I see that we need it from another package, I think it's ok.
"should is allowed" doesn't seem to be grammatically correct
Got it but I think the reason why a `Supplier` was added is wrong.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Not sure if we need to do that it's just one entry per field though.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
:+1: I like how this method abstracts the way sub aggregators should be collected and how you can mix deferred aggregation with sorting.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Ok, sounds fine.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
also, I think the opened channel needs to be closed at one point
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
A description here on why someone would want a custom name resolve would be nice.
I see, bummer, I guess we can't do much about it ;)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
```suggestion * Executed when a shard returns a fetch result. ```
`file reopened` -> `file is reopened`
It should say greater than zero, 0 is not permitted.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You already asserted this 2 lines ago, this is a duplicate.
You already asserted this 2 lines ago, this is a duplicate.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
just beware that Long.compare is Java 1.7 only, you might want to use Longs.compare from Guava instead when merging to 1.x
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
look into `StreamInput#readMap`
look into `StreamInput#readMap`
look into `StreamInput#readMap`
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
s/payload is/payloads are
Indeed merge is the main reason, however every time people use split-merge and **don't find out** about this behavior they introduce a potential hard-to-find bug. It still seems to me that `merge` should by default behave like `mergeFirstErrorOnly` from #5779 discussion, but I'm definitely not pushing.
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you should replace the curly bracket with a square bracket here.... :D
`file reopened` -> `file is reopened`
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
maybe we implement `Iterable<V>`
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
maybe add which type of section it was, so that it's even safer to get rid of the double exception? That is the only useful bit I find in the original stacktrace that would otherwise get lost.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
ah ok I misunderstood what this was doing, I'm +1 on it working as you describe to match keyword fields
This isn't the right fix, it's not a response parameter (it controls the request that the node client sends). Rather, this parameter needs to be consumed (and parsed as a boolean).
You could add an assert that it's not ES 7.x here so we know to remove it
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
I think we should also check the taskId here
I just fiddled around with it some more and see what you mean about periodically checking. Your arguments sounds good to me.
I just fiddled around with it some more and see what you mean about periodically checking. Your arguments sounds good to me.
`replayObserverFromIndex` always access `index` first. Actually, if I swap these two statement, ``` java int index = h.index.get(); int size = h.list.size(); ``` I can pass this test. I think `index` can guarantee "l < index.get() <= list.size()". So I feel this is not the cause of the concurrency issue.
This logging statement has a `[{}]` but no argument to fill it
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
I'd switch the order of these so it matches the declaration order.
I'd switch the order of these so it matches the declaration order.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I'd switch the order of these so it matches the declaration order.
Right - RollupIT is the right place
Can you name this something more descriptive? maybe `shardIdToRouting` instead of just `map`
Can you name this something more descriptive? maybe `shardIdToRouting` instead of just `map`
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
Right - RollupIT is the right place
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
Lets please not do that. The thing is it would break: the codebase of the utility class itself would screw everything up. To me, the right answer is not to make these acc blocks easier: its to have less of them, by fixing the actual problems so the blocks are not needed :)
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
I'd switch the order of these so it matches the declaration order.
I think using a `LongAdder` would probably be more efficient than `AtomicLong`, since the value is not going to be inspected as often as its incremented
I'd switch the order of these so it matches the declaration order.
I your reply got busted.... lemme reread
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
here you may be able to use copyCurrentStructure
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
Can you name this something more descriptive? maybe `shardIdToRouting` instead of just `map`
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
Can you name this something more descriptive? maybe `shardIdToRouting` instead of just `map`
You should catch the error twice to produce an error message suitable for each query
don't try to fix it, you just moved code around, but this catch block worries me :(
maybe reverse this check? (`expected.equals(map) == false`)
the start cluster does this.
is it necessary to mock the rescorer builder, seems like an easy object to create manually, unless I am missing something. In general, I tend to use mockito only as a last-resort, when things are really hard to reconstruct, that's why I'm asking.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
for code cleanup: ``` if(! StringUtils.hasText(prefix)){ return null; } String trimmedPrefix =prefix; while (trimmedPrefix.endsWith(".")) { trimmedPrefix = trimmedPrefix.substring(0, trimmedPrefix.length() - 1); } return trimmedPrefix; ```
I second this, other than this, the PR looks good. Will approve when changed.
Based on the discussion above (whether we need to account for the "has no results" case at all after "reduce", I would opt for at least testing it less frequent, and thest the "result" case mostly.
I think you can initialize the capacity.
I think you can initialize the capacity.
Based on the discussion above (whether we need to account for the "has no results" case at all after "reduce", I would opt for at least testing it less frequent, and thest the "result" case mostly.
Based on the discussion above (whether we need to account for the "has no results" case at all after "reduce", I would opt for at least testing it less frequent, and thest the "result" case mostly.
I think you can initialize the capacity.
I think you can initialize the capacity.
I think you can initialize the capacity.
oh right sorry I keep missing that.
maybe ${stashedKey} alone should return an object then? Does that complicate things? Calling toString makes sense when the stashed thing is part of a string, otherwise returning the object sounds better.
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
maybe ${stashedKey} alone should return an object then? Does that complicate things? Calling toString makes sense when the stashed thing is part of a string, otherwise returning the object sounds better.
oh right sorry I keep missing that.
is this needed here? I think it does something only when the current token is start array or start object.
This does not necessarily need to be within a static initialization block.
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Use generators to avoid massive memory consumption when huge lists are being used: ``` for batch in (objs[i:i + batch_size] for i in xrange(0, len(objs), batch_size)): ```
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
I actually meant an error (http 400)? Messages can be ignored. This is just an invalid configuration.
I actually meant an error (http 400)? Messages can be ignored. This is just an invalid configuration.
can we make this an enumSet called writeAllowedStateForReplica (and the same for primary). It's getting out of hand :) also please right them in order recovering, post_recovery, started, relocated
Similar to above, `new TreeMap` should be wrapped with `Collections.unmodifiableSortedMap()`.
I also think it'd be good to have `HeapBufferedAsyncResponseConsumer` take a `ByteSizeValue` instead of an `int` of bytes, much less chance of misinterpretation.
Please could you assert that the content of the message is correct? (`expectThrows` returns the exception thrown, so you just need to assign it to a variable and check its message.)
I see. Could we just open all the directories up-front and then clean them all up at the end? If possible I think it's clearer that there are no leaks if you can see acquisition and release of resources to be paired up in a single method. It's not always possible, but here I think it is.
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
Personally repetition makes me blind to any small changes but I can live with that.
Small typo here: Guage -> Gauge.
Can you add the `<String, Object>` (@nik9000 style) or `<?, ?>` (@jpountz style) to the map? Again, I don't know if you should have a default here.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
I think the length of individual byte[] values should also be encoded using vInt.
oh yeah I missed that :/
Doesn't actually throw `IOException`.
good catch on delta > 0
... and this doesn't need to know it either.
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
good that you added this assertion :)
I think we can just access the member directly.
nit: read lock -> just lock.
you can omit `ElasticsearchException` here it's unchecked
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
If we don't count token with 0-increment this should be equal to 2
we decided to live on the edge and have fun. The concern was around non ascii codes breaking tooling but CI seems happy. Let's see how far we get.
nit: ditto for `final` method args here
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I think they can stay here, until we start using them in other places.. but I'm good with moving if people want to
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
Ah, okay. Thanks.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
`expectedType.cast(e)` should remove the need for the unchecked suppression.
you can use `IOUtils.close(processor)` it deals with `null` values...
I think we can move this under `try ... except`, e.g. ```python try: token, rest = parser.get_mailbox(addr) if rest: # The entire address must be parsed. raise ValueError nm = token.display_name or '' localpart = token.local_part domain = token.domain or '' except (HeaderParseError, ValueError, IndexError): raise ValueError("Invalid address '{}'".format(addr)) ```
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
This should only be done in close()
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
s/HashMap<String, Object> fields/Map<String, Object> fields
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
maybe we implement `Iterable<V>`
Nit: missing `@Override`
We could fall back to `__file__` or something in that case at minimum. Could be useful to include that regardless.
cool stuff - I wonder if we should only add fields to the multimap that are explicitly added like via `add(IndexableField field, String key)` for the most of the field this is not needed at all though.
cool looks good!
cool looks good!
cool looks good!
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
cool stuff - I wonder if we should only add fields to the multimap that are explicitly added like via `add(IndexableField field, String key)` for the most of the field this is not needed at all though.
cool stuff - I wonder if we should only add fields to the multimap that are explicitly added like via `add(IndexableField field, String key)` for the most of the field this is not needed at all though.
cool looks good!
I like the level of detail in these tests, the degree of splitting them in into so many test methods and helpers is maybe a little bit hard to read. The following are just some suggestions of how to maybe group some of the tests. e.g the null, true and false test could be grouped into one case that checks allowed fields fort the allowMalformed field.
can we use an iterator here instead? it would be more clear to me if we'd do that..
nit: space after the second percent sign (on all these lines)
can we use `== false`
Nit: missing `@Override`
and remove the below null check
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
This isn't needed client-side.
This isn't needed client-side.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
I think this assertion should be in `getAnyNodeExcept()` - it's ok to return an empty list here.
should we move the `configureSocketChannel` call into the try block as well here? seems cleaner
no need to implement/override this method if no validation is required
use AbstractRunnable? Then you don't need the try catch :)
Can we make this 1 hour? If it times out it's nice to get thread dump
Can we make this 1 hour? If it times out it's nice to get thread dump
Can we make this 1 hour? If it times out it's nice to get thread dump
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
Yup, exactly, deserves a `throw` in my opinion, to prevent leaking that `null` into user's code. Also ![1454550686518](https://cloud.githubusercontent.com/assets/967132/12830813/453683d8-cba2-11e5-97f8-b820117907e1.jpg)
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think we should try to do it in an atomic way? ``` java if (queryFetchResults.compareAndSet(shardIndex, null, result) == false) { throw new Exception(); } ```
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Since the account settings are supplied by user, I would feels better if we used URI to build this string. This way we will have at least some basic validation of the things that go into this URL.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
yea, I would at least debug log it..., it shouldn't happen
yea, I would at least debug log it..., it shouldn't happen
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
yea, I would at least debug log it..., it shouldn't happen
this should happen after we update `isSecurityEnabledByTrialVersion`
The list reference is already final in the class so this isnât really needed
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
Is there really no alternative to a plain except? This would even catch KeyboardInterupt etc which we surely don't want. Which exceptions can occur here? As a last resort you can use except Exception, but I'd prefer it explicit.
Is there really no alternative to a plain except? This would even catch KeyboardInterupt etc which we surely don't want. Which exceptions can occur here? As a last resort you can use except Exception, but I'd prefer it explicit.
A suggestion: '--config' repetition could be avoided using: ``` if self.config: config_param = ''.join(' --config %s=%r' % (key, value) for (key, value) in self.config.items()) else: config_param = '' ``` _DONE_
Can you issue a `RuntimeWarning` here telling the user that Django falls back and it might be time to clean up using `squashmigrations` and link to https://docs.djangoproject.com/en/dev/topics/migrations/#squashing-migrations.
this could be static
would you mind adding `<>` after `new PriorityQueue` ? otherwise this is an unchecked assignment.
afaics kb is not supported for SizeValue. it is "k" or "K"? Same for the other entries.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
this might be called by `scheduledRefresh`, which can happen at any time
sneaky, I missed that :)
This wasn't aligned correctly before but we may as well fix it up now we're changing it.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I'm not a huge fan of this, we should be able to build the result set from module.params and the response.
The repeatedly printed stacktrace is not relevant if you want to fail the test. The uncaught handlers are thread-local and you only need to get past the catch around the onError handler. They are invoked together on the same thread.
we may need to go over all the callers of the new NamedWriteableRegistry#register and see whether they are compliant to the decision that we have yet to make in #17458 :)
spaces missing after `if` and before `{` ð¡
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
Think this is just `publicationInProgress()` again now.
Nit: `active.size()-1` -> `active.size() - 1`
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
spaces missing after `if` and before `{` ð¡
can you just leave the constant in this class? There isn't a need to put it in realm imo
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
could be `final`
weird to declare vars after the constructor
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
weird to declare vars after the constructor
++ on debug message
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
we do this so often. I wonder if it's time for a utility method.
Think this is just `publicationInProgress()` again now.
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Can we fold all these assertions into a single one? I think this should cover enough. ``` assertThat(shardChangesRequests, contains(new long[][]{ {0L, 8L}, {9L, 8L}, {18L, 8L}, {27L, 8L}, {36L, 8L}, {45L, 8L}, {54L, 8L}, {63L, 8L} })); ``` Moreover, the leader should not return more than the requesting batch size. Here, we request 8 operations, but it returns 9 operations.
I am confused. Is that streams specific? Yet this property doesn't indicate that's the case.
I am confused. Is that streams specific? Yet this property doesn't indicate that's the case.
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
canceled -> cancelled
We have to be sure that a real setting has been accessed at least once before. After checking some code paths, I think it is the case and this should be safe to do.
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
Can you fix the indentation
nit: please use lowercase start for variable names
`} catch(IllegalArgumentException e) {`
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
`while(ChronoUnit.MILLIS.between(started, Instant.now()) < TIMEOUT)` looks more sensible to me.
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
I think we might miss some responses in case of onFailure() because it will be using responses created [here](https://github.com/s1monw/elasticsearch/blob/issues/5766/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java#L94)
Not sure if this already includes the shard context, but if it doesn't can you change it to: ``` logger.debug("{} found local translog with id [{}]", this.shardId, id); ```
I wonder if you want a CyclicBarrier here.
You are already in `ESRestTestCase` so you don't need the to reference the class.
You are already in `ESRestTestCase` so you don't need the to reference the class.
Could you indent this one more time? I'd probably also add the line break before `implements` rather than after the `,` so it is more obvious what is up when you scan file.
can you rename `k` to something a bit more meaningful? :)
can you rename `k` to something a bit more meaningful? :)
can you rename `k` to something a bit more meaningful? :)
This isn't thread-safe
This isn't thread-safe
Ah ok, right. I understand now. Yes, so we should have to consistent indeed but we need to deprecate them.
Ah ok, right. I understand now. Yes, so we should have to consistent indeed but we need to deprecate them.
I guess it is "these" marked consumers now.
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
Written while holding a lock and read without lock.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
Why all these extra levels of indirection? I think this addSupplier, and the other one added here could just be implemented inside `keystore` that takes a FileSupplier, and the File variant calls that method instead of this indirection.
we need these only in IndicesClient, so that users can do client.indices().openIndex() . No need to add them here too.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
Can we move these up at the top of the class with the other object variable declarations? I think it is more readable than having them 300 lines down into the class.
As it's a new major release, I think we can just break this without deprecation.
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
interesting, what is the reason for this funny upper bound? :)
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
Is white box a recognised Wavefront term? We try to avoid white box and black box if we can as they're jargon that can confuse people, particularly those with English as a second language.
As it's a new major release, I think we can just break this without deprecation.
maybe `Objects.equal` could make it easier to read
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
Can use the '{}' syntax here for `DATA_BLOB_PREFIX`
This exception will be treated as ignore replica exception. :wink:
Thought so ... thanks for the confirmation.
Thought so ... thanks for the confirmation.
Thought so ... thanks for the confirmation.
Nit: space between the cast operator and the target.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
oh right sorry I keep missing that.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
it's a shame java need this...
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
for some caches it would be nice to make sure to not compute twice the same value
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
I think I preferred the `DataOrMasterNodePredicate`.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
`of the it's last` -> `of its last`
I can confirm that changing the name of the template (but not the index pattern it matches) will not break the Logstash Management UI in Kibana. As long as the logstash management index name remains `.logstash`, everything in the Kibana Logstash Management UI should continue to work.
I think it would be good to be consistent and always throw
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
`of the it's last` -> `of its last`
`of the it's last` -> `of its last`
`of the it's last` -> `of its last`
`of the it's last` -> `of its last`
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
do we need == true ? :)
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
this is much better!! ð
It'd be nice to be sure it contained that `not_found` wasn't found.
It'd be nice to be sure it contained that `not_found` wasn't found.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
OK. I'm good with fixing this inconsistency by throwing an InterruptedException (and catching it up just like we do with LockObtainFailedException
1s should be enough.
1s should be enough.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
We do not want to lock for `onNext` calls. That is against Rx Design Guideline 6.8: ``` 6.8. Avoid serializing operators As all Rx operators are bound to guideline 6.7, operators can safely assume that their inputs are serialized. Adding too much synchronization would clutter the code and can lead to performance degradation. If an observable sequence is not following the Rx contract (see chapter 0), it is up to the developer writing the end-user application to fix the observable sequence by calling the Synchronize operator at the first place the developer gets a hold of the observable sequence. This way the scope of additional synchronization is limited to where it is needed. ```
The first two of these fields are unused. I think that's right, and we should remove them and also `ec2Bucket`, by generating the key and token and then passing them into the bucket's constructor.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
cool stuff - I wonder if we should only add fields to the multimap that are explicitly added like via `add(IndexableField field, String key)` for the most of the field this is not needed at all though.
ok...but client depends on the transport service anyway no? I think I don't get it
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
cool stuff - I wonder if we should only add fields to the multimap that are explicitly added like via `add(IndexableField field, String key)` for the most of the field this is not needed at all though.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
one too many whitespace between List<C> and the method name
cool stuff - I wonder if we should only add fields to the multimap that are explicitly added like via `add(IndexableField field, String key)` for the most of the field this is not needed at all though.
ok...but client depends on the transport service anyway no? I think I don't get it
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
we should totally not have this method, one more reason to not implement the interface.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Not sure we want to use `settings.CSRF_COOKIE_NAME` for this. What about `CSRF_SESSION_KEY = '_csrf_token'` just like we do with `LANGUAGE_SESSION_KEY`.
not sure if this should be pretty printed as we put in the exception message. we'll have to see an example to be sure. Alternatively we can log a warning line like we do in ensure green. Also, you can consider using Strings.toString().
not sure if this should be pretty printed as we put in the exception message. we'll have to see an example to be sure. Alternatively we can log a warning line like we do in ensure green. Also, you can consider using Strings.toString().
not sure if this should be pretty printed as we put in the exception message. we'll have to see an example to be sure. Alternatively we can log a warning line like we do in ensure green. Also, you can consider using Strings.toString().
not sure if this should be pretty printed as we put in the exception message. we'll have to see an example to be sure. Alternatively we can log a warning line like we do in ensure green. Also, you can consider using Strings.toString().
It feels squicky to ignore the exception. Personally I'd `assert false : "Exceptions not expected here."` and `logger.error` about it.
same here - just pass a new instance
same here - just pass a new instance
same here - just pass a new instance
No need to talk to a mocked observer, TestObserver.assertEmpty() already verifies these.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Here again I think we should use `builder.timeField` to handle this
For human readable-ness, an additional field should be added, we shouldn't replace the field with a human readable version. You should be able to do ```java builder.timeField("modified_millis", "modified", modifiedDate); ``` (replacing the field names with the fields we want to use) and then you don't have to check the human readable flag yourself
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
Can we keep the line numbers in the test assertions? I think they are important to maintain.
For human readable-ness, an additional field should be added, we shouldn't replace the field with a human readable version. You should be able to do ```java builder.timeField("modified_millis", "modified", modifiedDate); ``` (replacing the field names with the fields we want to use) and then you don't have to check the human readable flag yourself
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
For human readable-ness, an additional field should be added, we shouldn't replace the field with a human readable version. You should be able to do ```java builder.timeField("modified_millis", "modified", modifiedDate); ``` (replacing the field names with the fields we want to use) and then you don't have to check the human readable flag yourself
Nit: `initializing.size()-1` -> `initializing.size() - 1`
also this class should be final.
Should this be 6 instead of 9? When I try `Instant instant = Instant.from(formatter.parse("0.0000001"));` in the tests I get an `java.lang.ArithmeticException: Rounding necessary`
Ok, sounds fine.
also this class should be final.
also this class should be final.
I can confirm that changing the name of the template (but not the index pattern it matches) will not break the Logstash Management UI in Kibana. As long as the logstash management index name remains `.logstash`, everything in the Kibana Logstash Management UI should continue to work.
I'm not sure this is the right fix. If you pull a reference to the values, add values and then pull an iterator, the iterator will not see the values that have just been added. I think it should rather be: ``` java return new Iterable<V>() { @Override public Iterator<V> iterator() { final ImmutableOpenMap<K, V> immutableMap = UpdateInPlaceMap.this.immutableMap; final ConcurrentMap<K, V> concurrentMap = UpdateInPlaceMap.this.concurrentMap; if (immutableMap != null) { return immutableMap.valuesIt(); } else { return Iterables.unmodifiableIterable(concurrentMap.values()).iterator(); } } } ``` So that the iterator to use is decided at the time when it is requested instead of ahead of time.
Such changes in our own source is a good indication there will be generics issues for the users of the library.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I guess, are any of the other assertions necessary given that we are checking that source has not changed at all in this case (and no metadata was added).
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
maybe fold this if-else into the next one.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
`Description` -> `Descriptor`
Ah sorry missed that
Once we have a `running` flag, we can check on it and not on `isAlive`.
`application` needs to be null/empty
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
What do you think of: ``` private void handleReadResponse(long from, int maxOperationCount, long maxRequiredSeqNo, ShardChangesAction.Response response) { maybeUpdateMapping(response.getIndexMetadataVersion(), () -> { synchronized (ShardFollowNodeTask.this) { globalCheckpoint = Math.max(globalCheckpoint, response.getGlobalCheckpoint()); final long newMinRequiredSeqNo; if (response.getOperations().length == 0) { newMinRequiredSeqNo = from; } else { assert response.getOperations()[0].seqNo() == from : "first operation is not what we asked for. From is [" + from + "], got " + response.getOperations()[0]; buffer.addAll(Arrays.asList(response.getOperations())); final long maxSeqNo = response.getOperations()[response.getOperations().length - 1].seqNo(); assert maxSeqNo== Arrays.stream(response.getOperations()).mapToLong(Translog.Operation::seqNo).max().getAsLong(); newMinRequiredSeqNo = maxSeqNo + 1; // update last requested seq no as we may have gotten more than we asked for and we don't want to ask it again. lastRequestedSeqno = Math.max(lastRequestedSeqno, maxSeqNo); assert lastRequestedSeqno <= globalCheckpoint: "lastRequestedSeqno [" + lastRequestedSeqno + "] is larger than the global checkpoint [" + globalCheckpoint + "]"; coordinateWrites(); } if (newMinRequiredSeqNo < maxRequiredSeqNo) { int newSize = (int) (maxRequiredSeqNo - newMinRequiredSeqNo) + 1; LOGGER.trace("{} received [{}] ops, still missing [{}/{}], continuing to read...", params.getFollowShardId(), response.getOperations().length, newMinRequiredSeqNo, maxRequiredSeqNo); sendShardChangesRequest(newMinRequiredSeqNo, newSize, maxRequiredSeqNo); } else { // read is completed, decrement numConcurrentReads--; if (response.getOperations().length == 0 && globalCheckpoint == lastRequestedSeqno) { // we got nothing and we have no reason to believe asking again well get us more, treat shard as idle and delay // future requests LOGGER.trace("{} received no ops and no known ops to fetch, scheduling to coordinate reads", params.getFollowShardId()); scheduler.accept(idleShardChangesRequestDelay, this::coordinateReads); } else { coordinateReads(); } } } }); } ``` PS - note the difference in handling of `lastRequestedSeqno` - I think the way you had it had a bug.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Looks like you have already done this TODO
Same here with line breaks. Usually I see this as `} else {` in our code.
yeah, that was what I meant
same for here, not sure if the full Objects.equals needs to be called
I think we can clean up the http/transport/gatway settings here
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
I think that we can do without this flag, it could be a util method that returns a boolean depending on whether values are set or lookup details are.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
This might cause a port clash if something else is used port 9001. It would be safer if the customizer didn't do anything to the connector.
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
It would be worth requiring that `jobId` and `jobType` are not `null`.
`like` -> `likely`
This can all fit on one line.
This can all fit on one line.
I think that rather than copying this code from FixedExecutorBuilder, this logic should be pushed up to a package-private static method in the super class.
This can all fit on one line.
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
Also extract title from `<title>(.+)</title>` in case current extraction fails
We should debug log here the number of times that we have retried up to here.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
here you may be able to use copyCurrentStructure
Remove and create again is not needed I think
I think we should increment the term, and log that we've done so.
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
Remove and create again is not needed I think
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
what are testing here? sounds like primaryPhaseExecutesRequest
Remove and create again is not needed I think
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
The linger time for a socket is very different to the time it'll wait for a connection before being closed. When the socket is closed, the linger time causes the socket to block waiting for acknowledgement of the close from its peer.
same - please name it something like `explainOrThrowRejectedCommand`
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
++ on debug message
We no longer support `aggregations_binary` (already listed as removed in the release notes for 5.0) so we can just remove the `aggregation_binary` code below which should solve this issue? (it looks like I missed this bit whilst doing the aggregation refactoring before.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
I think this should be a mandatory option when creating a disk and we don't randomly choose one.
no need to set timeout, the default is good enough
Just about code style, I would prefer ``` if (iterator.hasNext()) { continue; } ``` rather than the short form. But I would indeed keep the `continue` to avoid starting one retry thread per type not found. One is enough.
Just about code style, I would prefer ``` if (iterator.hasNext()) { continue; } ``` rather than the short form. But I would indeed keep the `continue` to avoid starting one retry thread per type not found. One is enough.
I still feel like there ought to be a way to make these methods look less copy-and-paste-ish. They just set off my copy-and-paste blindness even though they aren't copied and pasted.
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
You know, we can add a checkstyle check for those....
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think it's good to reuse this threadpool, but it implies that the analytics process is a "job" from the point of view of deciding how many jobs can run on each node. We definitely need to hook these processes into a unified allocation framework. Also, maybe rename the threadpool to `JOB_PROCESS_THREAD_POOL_NAME` or similar.
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
minor nit: s/currently in a/in/
Not a bad approach :). LGTM then
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
this could be static
I don't know how sane the data you're reading in is but this might be a little safer: ``` python lines = (line for line in out.split('\n') if ':' in line and line.split(':')[1] == instance)
I think @bizybot is correct - we probably need some of the failure cases in `ApiKeyService.authenticateWithApiKeyIfPresent` to have a `terminate` status instead of `continue`. If I'm passing an API Key over TLS, then it would be very strange (and hard to debug) if the authentication use the API Key right up until it expired and then suddenly switched to PKI auth.
this could be static
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
The theoretical idea here is to try to move away from overriding methods like crazy at the transport level. So if refactorings need to happen, we can (hopefully) just move the stubs to different locations, opposed to dealing with a billion different tightly couple to the `Transport` interface tests.
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I think we want to test index level blocks too here
don't drink and code ð» (same line twice)
Isn't this cheating? You're modifying behavior in the compliance tests but the runtime actually behaves differently.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
nit: can you use assertEquals rather than `assertThat(..., equalTo())` ? I know we do that in quite some places in our codebase but we seem to be preferring the former over the latter nowadays.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
minor note: we consider shards inactive until the first indexing operation has happen, so I think this part is OK regardless of the change.
This test should assert that the headers are correct.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
This does not do anything. The listener takes `Void`. `v` will always be null.
These changes should be in a separate test method. Leave the `testOnBackpressureDropSynchronous` as is and introduce `testOnBackpressureDropWithActionSynchronous`.
I was only talking about the context _path_. But what you have is fine for now, the entire class really needs a rethink. :)
This does not do anything. The listener takes `Void`. `v` will always be null.
We could probably replace the filter with `hasLength` from `org.springframework.util.StringUtils`. A `forEach` might also be a bit more concise than the collector: ```java Arrays.stream(args).filter(StringUtils::hasLength).forEach(this.args::add); ```
s/The tasks has/In case the task has/
It would be worth requiring that `jobId` and `jobType` are not `null`.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Ok, sounds fine.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
How about building a set of invalid keys and adding them all to the exception? This would be a little friendlier to a user with multiple secure settings
We should debug log here the number of times that we have retried up to here.
We should debug log here the number of times that we have retried up to here.
I don't think it's important for now
did you plan to add here the list of nodes or something? looks like there is a missing argument.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Personally I prefer `is_ansible` or `is_ansible_install` as it makes it more obvious the `is_install` is referring to Ansible's install location and not the collection path. I'm not married to it but I definitely had to look at the code to make sure that is correct.
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
ok...but client depends on the transport service anyway no? I think I don't get it
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
oh yeah I missed that :/
Again, it would be cleaner to init `i` to `offset + 1` so that you don't have to add `offset` in every iteration.
++ on debug message
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
No need to be fancy here, just: `logger.debug("got exception", throwable);`.
Would be better to put this as a module constant to avoid compiling it over and over.
if we reduce the publish timeout to 0 (which will make the test faster), we need to use the same assertBusy technique on masterNode2 to make sure it has process the change as well.
I spoke to @rmuir and this is enabled 99% of the time in master (file leak detection) we can just remove this layer.
Would be better to put this as a module constant to avoid compiling it over and over.
Would be better to put this as a module constant to avoid compiling it over and over.
:+1: I like how this method abstracts the way sub aggregators should be collected and how you can mix deferred aggregation with sorting.
this is usually a bad sign. We should use sleep anywhere. Sometimes it's needed but we try give all the utilities to make sure no one used it explicitly. In this case we have assert busy: ``` assertBusy(() -> { final ClusterState currState = internalCluster().clusterService(masterNode1).state(); assertTrue("index not deleted", currState.metaData().hasIndex("test") == false && currState.status() == ClusterState.ClusterStateStatus.APPLIED); }); ```
:+1: I like how this method abstracts the way sub aggregators should be collected and how you can mix deferred aggregation with sorting.
I think you should just do `instanceof Number` and else call `.toString()`
I think we shouldn't call the error handler if the error can be delivered or replaced on the normal path.
s/y ou/you Also I think upfront is one word.
this is usually a bad sign. We should use sleep anywhere. Sometimes it's needed but we try give all the utilities to make sure no one used it explicitly. In this case we have assert busy: ``` assertBusy(() -> { final ClusterState currState = internalCluster().clusterService(masterNode1).state(); assertTrue("index not deleted", currState.metaData().hasIndex("test") == false && currState.status() == ClusterState.ClusterStateStatus.APPLIED); }); ```
I'm doing buffer now and they all emit buffered data in case of onError.
Two tests are missing here. One that assert what happens when the library is not on the classpath, as I've indicated in [my previous review](https://github.com/spring-projects/spring-boot/pull/24340#discussion_r546777503). One that assert that a custom `Sniffer` instance is used rather creating one here. This custom instance should probably have a dependency on the high level client we auto-configure to make this a bit more realistic.
Two tests are missing here. One that assert what happens when the library is not on the classpath, as I've indicated in [my previous review](https://github.com/spring-projects/spring-boot/pull/24340#discussion_r546777503). One that assert that a custom `Sniffer` instance is used rather creating one here. This custom instance should probably have a dependency on the high level client we auto-configure to make this a bit more realistic.
May as well cull the sysout to reduce test noise
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
this should look like this instead: ``` result = super(ActionModule, self).run(tmp, task_vars) if result.get('skipped', False) or result.get('failed', False): return result ```
we throw the exception and thus take care of the interrupt. We don't need to set it...
I think you can initialize the capacity.
maybe add the set of wrappers to the message so taht it would be easier to debug
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Maybe call this `HighlightersExtensionPoint`? Also the type could be moved here? ``` public class HighlightersExtensionPoint extends ExtensionPoint<Highlighter> { ```
Maybe call this `HighlightersExtensionPoint`? Also the type could be moved here? ``` public class HighlightersExtensionPoint extends ExtensionPoint<Highlighter> { ```
Nit: Almost ;-) To be or not to be, and also where, that is the question.
Probably it would be worth implementing AbstractStreamableTestCase#getMutateFunction in this case, so that the equals/hashCode tests are more complete. I think without it a part of them is skipped.
I think we can drop the benchmark.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
`file reopened` -> `file is reopened`
For backporting to 6.3, I think this needs to be changed to 7.
please give us messages for the assertions
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
It might be a good idea to store a version of elasticsearch that generated the task somewhere on the top level. So, we could filter out incompatible versions in the future and don't have to support old persistence formats forever.
cool thanks for clarifying!
can we please unpack the tuple right away instead of using v1 v2? just easier to read
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
I think a better name would be `acknowledgeResponseReceipt` or something similar
the suppress warnings could be right on the line of code doing the cast instead of the whole method
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
the suppress warnings could be right on the line of code doing the cast instead of the whole method
I suspect that having to pass the next interval which differs from the usual interval is the reason why this was not async in the first place :) we need to find a way to do that though, we currently lose that behaviour with this change. Another idea, maybe overkill, could be to change the hosts sniffer API to be async and accept a listener as an argument.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
can this see `unregister task for id: [{}]`
Should really ask for `toString()`s on these handlers too, although this adds noise.
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
can we make this ret val unmodifiable please
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
Since the time unit is ms, we should remove this conversion.
can we make a constant out of the -1L it's easier to see where it's used :)
Oh, never mind, I misread. Sorry for that. ð
Nit: `if(` -> `if (` (add space)
remove this additional line break? :)
No, I still think that it should not be a method on the `Strings` class.
I've removed the Supplier in my polish commit. I didn't found a single use of it and would argue that it is something you can determine when you build the template
Like, just for checking that assertions are enabled.
Needs a guard.
Yeah, I'd make these a hard check and throw a `new IllegalArgumentException("Usage doesn't look like UnifiedHighlighter")`.
Yeah, I'd make these a hard check and throw a `new IllegalArgumentException("Usage doesn't look like UnifiedHighlighter")`.
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
Nit: `getNumConnection` -> `getNumConnections`.
does this work? it works for percentiles, but with percentiles rank it's reversed
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I am ok with what you propose Nik!
same 1+ randomInt
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
same 1+ randomInt
This lambda does not need to be a statement block.
I think this should be a separate file so things like snapshot & restore can re-use it in the case the state is corrupted, it's easy to miss down here all alone
same 1+ randomInt
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
You can use `UncheckedIOException`
It'd be nice if the map were `unmodifiable`.
The compiler uses `MustacheResourceTemplateLoader` internally and that one is configured to use the configured charset.
I'd switch the order of these so it matches the declaration order.
I like `hasSize` better for this because it gives a nicer error message on failure.
I like `hasSize` better for this because it gives a nicer error message on failure.
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
(we just load all files in the `ES_HOME/config/ingest/grok` directory)
(we just load all files in the `ES_HOME/config/ingest/grok` directory)
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
nit: extra empty line
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Missing a space here after `id`
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Please do not drop stack traces; `Throwable#getMessage` is an abomination.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
I've removed the Supplier in my polish commit. I didn't found a single use of it and would argue that it is something you can determine when you build the template
Yes, I think we should make `Job.Builder::setJobType` `public`. The user could change it if they used the low level REST client.
maybe add an explicit `continue;` here to indicate that it's being skipped
nit: extra line
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
`application` needs to be null/empty
`application` needs to be null/empty
`application` needs to be null/empty
`application` needs to be null/empty
Probably a good call. I try to always keep them totally 1.0 for my sanity.
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
I think it was better when this was passed into the constructor of the exception. The thrower knows the type so thereâs no need to make the analysis figure it out.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
I think it was better when this was passed into the constructor of the exception. The thrower knows the type so thereâs no need to make the analysis figure it out.
The `<=` will need to be escaped.
The `<=` will need to be escaped.
The `<=` will need to be escaped.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
nevermind I was confused... all is good
nevermind I was confused... all is good
nevermind I was confused... all is good
I think we want to test index level blocks too here
nevermind I was confused... all is good
nevermind I was confused... all is good
I think we want to test index level blocks too here
nevermind I was confused... all is good
Same suggestion here for `assertNotEquals`.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think I saw this in Christoph's PR too. Hopefully you don't need it.
I would be using a `Set` in this circumstances.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
this can be collapsed into `assertTrue(foundTerms.add(bucket.getKeyAsNumber()))`
is it necessary to parse everything into a map in the first place? At some point later on we do need a map, but I wonder if we can postpone calling parser.map till then.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
I think java 9 is going to choke on `_` here, if I recall correctly
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
nit: extra line
This isn't needed client-side.
doc level failure (normal failures are OK from an algorithmic perspective).
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
did you plan to add here the list of nodes or something? looks like there is a missing argument.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Same suggestion here for `assertNotEquals`.
I would be using a `Set` in this circumstances.
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
we could pass a glob with regex:xxx to newDirectoryStream if we want
we could pass a glob with regex:xxx to newDirectoryStream if we want
The theoretical idea here is to try to move away from overriding methods like crazy at the transport level. So if refactorings need to happen, we can (hopefully) just move the stubs to different locations, opposed to dealing with a billion different tightly couple to the `Transport` interface tests.
This lambda does not need to be a statement block.
We will need stronger assertions here too.
This lambda does not need to be a statement block.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
Never mind. I just found `SafeSubscriber` will do it.
ok...but client depends on the transport service anyway no? I think I don't get it
We don't need to use this local ref
We don't need to use this local ref
nit: extra empty line
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
can this see `unregister task for id: [{}]`
There is no reason to test this unwanted behavior.
same here - just pass a new instance
What uses this? And why is forbidden APIs not angry about passing in String,int here... i feel like i banned that method. I dont like it as its wired to 127.0.0.1 in non-test code.
can this see `unregister task for id: [{}]`
Same question here about closing.
I don't think we are perf critical here of any sort, can you just use the constants where they are used? I think they are only used in one place and these Field classes are really unnecessary
I wonder how long this would work ;)
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
This code doesn't is not equivalent right? `RabbitListenerRetryTemplateConfigurer()` does more than what you removed as far as I see.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
I see, ok
I see, ok
how about introducing a writeable object that holds the lookup info? then to determine if it's a lookup or not would be checking if that object is null or not. we could have a new setter for that new object, and also keep the existing setters that create a new instance if null (for bw comp).
What uses this? And why is forbidden APIs not angry about passing in String,int here... i feel like i banned that method. I dont like it as its wired to 127.0.0.1 in non-test code.
at this point you don't need the restClient variable anymore
also, I think the opened channel needs to be closed at one point
This isn't needed client-side.
weird to declare vars after the constructor
I c... ok
last parameter can be set to from.
we need to find a way to keep the headers and context of the original benchmark requests here, when executing the "internal" ones. That might involve recreating the `SearchRequest` via copy constructor passing in the original benchmark request where the headers and context would get copied from.
last parameter can be set to from.
last parameter can be set to from.
last parameter can be set to from.
last parameter can be set to from.
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
This does not compile; `FakeRestRequest` does not have a constructor with two arguments. This is a recent change and I think you just missed it when you rebased.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I am leaning towards 2. it's much cleaner
Missing a space here after `id`
nit: extra empty line
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
Missing a space here after `id`
Missing a space here after `id`
Missing a space here after `id`
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Missing a space here after `id`
Missing a space here after `id`
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Missing a space here after `id`
Missing a space here after `id`
nit: extra empty line
This could return an immutable list
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
now that it doesn't return a value, maybe rename in to loadIntoContext , or add something to the java docs to indicate where the output is put.
now that it doesn't return a value, maybe rename in to loadIntoContext , or add something to the java docs to indicate where the output is put.
I think you can remove `isSSLPropertyPresent` here, it's always true as it's checked above.
I think you can remove `isSSLPropertyPresent` here, it's always true as it's checked above.
I think we cannot (yet) do this with auth tokens received externally because they need to be passed to the test suite as well as this fixture, so we've had to settle on just using the same (long) string in both places. It would indeed be nicer if there were no magic strings in the fixture at all. For deterministic testing, maybe you can pass a seed in from Gradle somehow? Or just hard-code them, it's not that important. I'd rather they weren't synthesised as they are now.
Sure, good plan.
Typo, "Trasnlog" -> "Translog"
I think it'd be useful to see the filenames in the exception message.
Typo, "Trasnlog" -> "Translog"
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
oh right sorry I keep missing that.
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
I think this should be a trace log with "[{}] trying to delete store (reason: [{}})" (note the index name as well) and log the info after successful deletion. We already log a debug message (or higher) in all callers of this method and it will not result in an info message saying "deleting" when we actually failed. ``` logger.trace("{} trying to deleting store (reason [{}]}", index, reason); nodeEnv.deleteIndexDirectorySafe(index, 0, indexSettings); logger.info("{} store deleted (reason [{}]}", index, reason); } catch (LockObtainFailedException ex) { logger.debug("{} failed to delete index store - at least one shards is still locked", ex, index); ```
++ to this pattern
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
hooray for try-with-resources!
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
++ to this pattern
nit: read lock -> just lock.
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
++ to this pattern
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
nit: read lock -> just lock.
++ to this pattern
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
space missing between `)` and `{`
space missing between `)` and `{`
I wonder if we should extend `ChannelReference` to implement `Closeable` and have the `.close()` method decrement the ref and throw an error if it's not now at 0 (which it should be since it's being closed in this case). That way we error immediately if the translog is closed but something incremented the channel ref. What do you think of this? Dunno if you think it might make ChannelReference too complex.
Missing a space here after `id`
Read the warning 2 lines above :-)
I wonder if you want a CyclicBarrier here.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
It seems that all the implementations of `DisruptableMockTransport` simply have a getter for some constant value for the local node as their implementation. Maybe just move that getter up into `DisruptableMockTransport` and pass it as constructor parameter while we're changing this anyway? (just to save a bit of noise in the concrete tests :))
can we move this to ShardRecoveryContext and pass request and shard to addNewRecovery ? this way won't need all the supplier fun. Might as well rename the add method here to addNewRecovery too? or maybe `registerRecovery`? (I don't mind much about the names, just a suggestion)
this is already done by argspec when param is defined as boolean, all redundant
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
We should debug log here the number of times that we have retried up to here.
We should debug log here the number of times that we have retried up to here.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
I have seen this comparison in several places. Maybe, it makes sense to move inside Snapshot and have something like `boolean hasName(String repository, String name)` method where it will take place? Not sure if `hasName` is a good name for this method though.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
nit: maybe call this `awaitSearchActive` (or `markSearchActive` if my other suggestion is accepted to move setting the timer here) ? pending refresh is an internal implementation detail..
Ahh okay, that makes sense, I missed that
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
Out of curiosity, why create a class for this instead of an anonymous class in `IndexService` capturing the local `shardId`? There are no other instantiations of this class other than the single one
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
For the record, I'm asking because I expect the setter to be called once while these create methods can be called _many_ times
would be nice to allow to configure it to a percentage of the heap size
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
For the record, I'm asking because I expect the setter to be called once while these create methods can be called _many_ times
Ahh okay, that makes sense, I missed that
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
We can reuse an existing migration: ```suggestion call_command("sqlmigrate", "migrations", "0002", stdout=out) ```
Sorry ... I'm not shipping code with `Thread.stop` in it.
`"auto_expand_replicas": 2` instead? That way you don't end up with a yellow cluster on one node and you end up with a fairly large amount of paranoia if you have three nodes? I'm ambivalent for the 2 vs 1 replica thing but I like `auto_expand_replicas` here.
I think it might makes sense to split this into `initalPosition` and `initialState`.
maybe `clauses` can directly store Integers.
I also think we should not catch the excep here.
nit: `>=` -> `>` (equality is not an option :))
Lifecycle component is not concurrency-aware, and not all methods that create the blobstore etc. are guarded by "if-not-closed" checks. We need to guard against creating a blobstore / container after the closing has started
Lifecycle component is not concurrency-aware, and not all methods that create the blobstore etc. are guarded by "if-not-closed" checks. We need to guard against creating a blobstore / container after the closing has started
super minor, but indentation is off here
super minor, but indentation is off here
No need to specify the `'introspection'` prefix here.
can we try turning those into constants? I think we should try doing this all the time though.
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
This is where I was a bit uncomfortable with requiring the underlying stream to have an unbound support for mark. If I read things correctly we end up with a stream that just wraps a byte reference and we therefore don't care. If you're comfortable relying on that behavior, then I'm good but then I also think we don't need to allocate a growing size of `firstBytes` but rather read byte by byte until we find the first non-white space.
Question - why not just get the connection from the transport service right here? does the supplier buy as something? maybe we can even try to get it first and create a new temporary only if it fails ``` Transport.Connection existingConnection = null; if (transportService.nodeConnected(nodeToSend)) { try { existingConnection = transportService.getConnection(nodeToSend); } catch (NodeNotConnectedException e) { // it's ok we'll create a temp connection } } if (existingConnection != null) { sendPingRequestToNode(existingConnection, sendPingsHandler.id(), timeout, pingRequest, latch, node, nodeToSend); } else { ```
I think these should get taken care of by `uninstallService`? Or is the point here that we want to assert exit code 0 when uninstalling it in these tests
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
This line does not need quotes. (nitpick)
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
space missing between ) and {
maybe just extend the note to say: doesn't check docsWithField since we replace missing values in select() ? Took me a while to figure out why this was safe
Chop blank line.
same here - I think it's better to log the info message if the deletion was successful.
I expanded your assertions a bit if you are ok with them: ``` public void testRoundsUpperBoundCorrectly() { ScaledFloatFieldMapper.ScaledFloatFieldType ft = new ScaledFloatFieldMapper.ScaledFloatFieldType(); ft.setName("scaled_float"); ft.setScalingFactor(100.0); Query scaledFloatQ = ft.rangeQuery(null, 0.1, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.1, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.095, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.095, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.105, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.105, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); } public void testRoundsLowerBoundCorrectly() { ScaledFloatFieldMapper.ScaledFloatFieldType ft = new ScaledFloatFieldMapper.ScaledFloatFieldType(); ft.setName("scaled_float"); ft.setScalingFactor(100.0); Query scaledFloatQ = ft.rangeQuery(-0.1, null, false, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.1, null, true, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.095, null, false, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.095, null, true, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.105, null, false, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.105, null, true, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); } ```
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
`tests_require` is deprecated in [setuptools](https://setuptools.readthedocs.io/en/latest/setuptools.html#new-and-changed-setup-keywords) since [41.5.0](https://setuptools.readthedocs.io/en/latest/history.html#v41-5-0) (27 Oct 2019). (It is also being unused by Django anyway.)
randomInt cannot be within the loop, otherwise it changes at every iteration...
randomInt cannot be within the loop, otherwise it changes at every iteration...
randomInt cannot be within the loop, otherwise it changes at every iteration...
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
or N times
I think the fact that a list with the key name of `fields` is hard-coded here, maybe we should give a more specific name to this? should we call this `AbstractStringsFieldProcessor`? or we can force the factory to implement a `getStringsFieldName` or something of the sort to make the `fields` name to be required to be defined by each implementing processor factory. I understand that there are no other users of this whose field name is not `fields`, so I am also OK with leaving it as is.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
I think the fact that a list with the key name of `fields` is hard-coded here, maybe we should give a more specific name to this? should we call this `AbstractStringsFieldProcessor`? or we can force the factory to implement a `getStringsFieldName` or something of the sort to make the `fields` name to be required to be defined by each implementing processor factory. I understand that there are no other users of this whose field name is not `fields`, so I am also OK with leaving it as is.
or N times
I think the fact that a list with the key name of `fields` is hard-coded here, maybe we should give a more specific name to this? should we call this `AbstractStringsFieldProcessor`? or we can force the factory to implement a `getStringsFieldName` or something of the sort to make the `fields` name to be required to be defined by each implementing processor factory. I understand that there are no other users of this whose field name is not `fields`, so I am also OK with leaving it as is.
This test should be kept and should continue to pass.
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
Same here, we need j<= numReplicas, which also makes me wonder if we want to validate in shardCanBeDeleted that the total number of shards in the routing table is what we expect it to be (we now only check for no shards at all)
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
No need to talk to a mocked observer, TestObserver.assertEmpty() already verifies these.
This is just a log message. I think we want all the details.
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
Maybe rename `myself` this to _local_ like in `network.host` setting? At some point we should support port ranges too, but it can be done in a follow up PR.
that `!` fucked me up can we have `== false`? ð
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
I see that `ScrollHelper.fetchAllByEntity` already wraps the listener inside a `ContextPreservingActionListener`.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
This check is pointless.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
right, I had totally misunderstood how the test works
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
Same here, with `CLUSTER_ROUTING_REBALANCE_ENABLE`
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think you can initialize the capacity.
I think you can initialize the capacity.
I think you can initialize the capacity.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
Nit: spacing between `while` and `(`.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
In case of LOCAL_SHARDS/RESTORE, we could again call activatePrimary here.
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
Configuration properties must be JavaBean properties (the type must match) and we don't support `Optional` here.
one assert per member is better then you see what's not null :0
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
one assert per member is better then you see what's not null :0
For readability, could we have ``` java List<SortBuilder<?>> sorts = mainRequest.getSearchRequest().source().sorts(); if (sorts == null || sorts.isEmpty()) { mainRequest.getSearchRequest().source().sort(fieldSort("_doc")); } ```
This test should assert that the headers are correct.
you should assign a new list instance (or clear the `abortBenchmarkNodeStatuses` list) to make sure we are not reading an instance that already has some status in the list.
It seems that all the implementations of `DisruptableMockTransport` simply have a getter for some constant value for the local node as their implementation. Maybe just move that getter up into `DisruptableMockTransport` and pass it as constructor parameter while we're changing this anyway? (just to save a bit of noise in the concrete tests :))
This test should assert that the headers are correct.
shard can remain
shard can remain
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
Can you move the global declarations to one place? Easy for the future maintainer.
[run_command](https://github.com/gdelpierre/ansible/blob/a6742ea78fba6b8206eaef61c6410e985a9a61f7/lib/ansible/module_utils/basic.py#L2558) won't raise an error and `rc` will not be zero.
Can you move the global declarations to one place? Easy for the future maintainer.
Can you move the global declarations to one place? Easy for the future maintainer.
"will lazily allocated" -> "lazily allocates"
"will lazily allocated" -> "lazily allocates"
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
I think it's always a single node cluster, but I'm good to keep it like this.
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
I think it's always a single node cluster, but I'm good to keep it like this.
I think it's always a single node cluster, but I'm good to keep it like this.
This branch in untested :thinking:
I think it's always a single node cluster, but I'm good to keep it like this.
This is already covered by `ParseHeaderParameterTests.test_basic()`.
This is already covered by `ParseHeaderParameterTests.test_basic()`.
I think it's always a single node cluster, but I'm good to keep it like this.
I think we could leave this called `simpleString`. The convention seems to be not to call out the existence of the Validator explicitly in other calls. I see that this might cause some issues with overloading but I think they're surmountable.
I think it's always a single node cluster, but I'm good to keep it like this.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
just please don't add one. There are too many classes already.
We can't really do that as the sole purpose of the field init is to express a default value that isn't dependant of the environment. I'll remove that as part of the polish.
Typo: "se" -> "so"
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
I think there is a bug here. What is `\\`? I guess Windows? You need to take caution for different filesystems.
can we add some trace logging here? I can imagine it will save some WTF at some point.
I find personally the previous version more readable: nesting the method call in the constructor parameter makes it harder to read.
No really necessary but if you want to keep it I would capitalise it and add a full stop.
No really necessary but if you want to keep it I would capitalise it and add a full stop.
shouldn't this line and the one below just not be here, and the loop be `for arg, version in self.DEFAULT_DEPRECATED_ARGS` (though those aren't really a default either, so `DEFAULT` is a bit of a misnomer)
nit: `an` -> `a`
nit: `an` -> `a`
nit: `an` -> `a`
ok let me know if I have to look into that or you can manage.
this is the default..
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
oh oh I hadn't read your reply when I replied ;)
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
maybe just catch (Exception)
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
can we also step out if `matchedDocId < DocIdSetIterator.NO_MORE_DOC`
can we also step out if `matchedDocId < DocIdSetIterator.NO_MORE_DOC`
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
nit: please use lowercase start for variable names
We have other analysis components that also use Java regexps, I don't think we need to block this one.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
I see that we need it from another package, I think it's ok.
I see that we need it from another package, I think it's ok.
could be just `if (ancestors.add(value) == false)` when moving to a set
could be just `if (ancestors.add(value) == false)` when moving to a set
could be just `if (ancestors.add(value) == false)` when moving to a set
could be just `if (ancestors.add(value) == false)` when moving to a set
could be just `if (ancestors.add(value) == false)` when moving to a set
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
also use the constant here
Thanks for this, David
we discussed this and we decided to leave it for ease of use, just keeping only the most common (required) arguments, index, type, id and path
we discussed this and we decided to leave it for ease of use, just keeping only the most common (required) arguments, index, type, id and path
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
It's irrelevant to log the message ,e.getMessage(), because he will be logged by passing the entire exception to the logger. Instead you could log a more specific message for this case
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
Can you call this something other than `total`? It's really hard to read things like `total.total, total.total, total.total + total.total`.
Two tests are missing here. One that assert what happens when the library is not on the classpath, as I've indicated in [my previous review](https://github.com/spring-projects/spring-boot/pull/24340#discussion_r546777503). One that assert that a custom `Sniffer` instance is used rather creating one here. This custom instance should probably have a dependency on the high level client we auto-configure to make this a bit more realistic.
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
We also need a simple rest test, testing integration like we have for the other processors
We also need a simple rest test, testing integration like we have for the other processors
tokeinzer -> tokenizer
tokeinzer -> tokenizer
Can we keep the line numbers in the test assertions? I think they are important to maintain.
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
Can we do this instead (throw an exception)? And just tell the user to use a cidr mask? Supporting "fuzzy" queries on ip addresses seems crazy, and I don't think we should continue this.
super nit: I tend to like validation to be first
super nit: I tend to like validation to be first
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
We prefer forward merges to back-ports, however, if switching the base branch to 2.7.x is proving tricky, please leave it as main and switch to Spring Retry 1.3.3-SNAPSHOT in your PR. We can then take care of getting the changes based on top of 2.7.x as part of merging the contribution.
TIL about the `|=` operator. For others reviewing: this will replace changed with True iff changed is not True already and a function evaluates to True. Once True, one of these updated returning False won't switch the changed status.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
TIL about the `|=` operator. For others reviewing: this will replace changed with True iff changed is not True already and a function evaluates to True. Once True, one of these updated returning False won't switch the changed status.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
don't drink and code ð» (same line twice)
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
`Arrays.asStream(response.pingResponses)` would not materialize it
We prefer forward merges to back-ports, however, if switching the base branch to 2.7.x is proving tricky, please leave it as main and switch to Spring Retry 1.3.3-SNAPSHOT in your PR. We can then take care of getting the changes based on top of 2.7.x as part of merging the contribution.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
We prefer forward merges to back-ports, however, if switching the base branch to 2.7.x is proving tricky, please leave it as main and switch to Spring Retry 1.3.3-SNAPSHOT in your PR. We can then take care of getting the changes based on top of 2.7.x as part of merging the contribution.
remove this additional line break? :)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
I think I prefer the current logic of this method to relying on the return value of get().
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
remove this additional line break? :)
remove this additional line break? :)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
remove this additional line break? :)
I wonder about the cases where this can happen as the `close` method on `InternalTestCluster` that calls `shutdown` on the executor is synchronized (same as this method). Have you observed this exception being thrown? If we don't expect this to occur under normal operations, I would prefer not to swallow the exception here.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I think using a `LongAdder` would probably be more efficient than `AtomicLong`, since the value is not going to be inspected as often as its incremented
I think using a `LongAdder` would probably be more efficient than `AtomicLong`, since the value is not going to be inspected as often as its incremented
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
Here's Python: ``` >>> ', '.join('(byte) 0x%x' % x for x in cbor.dumps({'foo': 5})) '(byte) 0xa1, (byte) 0x63, (byte) 0x66, (byte) 0x6f, (byte) 0x6f, (byte) 0x5' ```
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
This should be done in reset()
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
or N times
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
`describe` and `get` methods are almost the same: a refactor is possible.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
Users won't be able to use `--disable-rack-aware`.
It seems nothing is done when `check_mode` is enabled.
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
Fine with me :) I'm already wiping the repository itself after each test, so this shouldn't have much effect (I don't think).
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
`of the it's last` -> `of its last`
It would be worth requiring that `jobId` and `jobType` are not `null`.
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
It would be worth requiring that `jobId` and `jobType` are not `null`.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
It would be worth requiring that `jobId` and `jobType` are not `null`.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
This seems very error prone, since it relies on CPU scheduling, network latency, or even whether the test is using mocked networking...
This seems very error prone, since it relies on CPU scheduling, network latency, or even whether the test is using mocked networking...
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
`thread_pools_patterns` does not match the name of the parameter registered in the RestController
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
don't drink and code ð» (same line twice)
don't drink and code ð» (same line twice)
don't drink and code ð» (same line twice)
you can do some streaming java8 magic here.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
could be a instance variable, as used in all tests
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
I think this needs to be `Version.V_6_0_0_alpha3` now.
I think this needs to be `Version.V_6_0_0_alpha3` now.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
Nit: `who's the a better` -> `which is the better`
Nit: `who's the a better` -> `which is the better`
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
spaces missing after `if` and before `{` ð¡
If we don't count token with 0-increment this should be equal to 2
spaces missing after `if` and before `{` ð¡
This is why I do not like `assertEquals`; this is backwards from expected and actual. Instead: `assertThat(t1.v1(), equalTo(2L))`.
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
maybe mention that it is important to remove entries that have a value of zero to avoid memory leaks
could be just `if (ancestors.add(value) == false)` when moving to a set
This should be an issue only when `migration_name` is passed, so I would move it to the `if options['app_label'] and options['migration_name']` branch, e.g. ```diff diff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py index 9ad1854a2d..aa1a41e78c 100644 --- a/django/core/management/commands/migrate.py +++ b/django/core/management/commands/migrate.py @@ -140,18 +140,20 @@ class Command(BaseCommand): except KeyError: raise CommandError("Cannot find a migration matching '%s' from app '%s'." % ( migration_name, app_label)) - targets = [(app_label, migration.name)] + target = (app_label, migration.name) + if ( + target not in executor.loader.graph.nodes and + target in executor.loader.replacements + ): + incomplete_migration = executor.loader.replacements[target] + target = incomplete_migration.replaces[-1] + targets = [target] ```
This should be an issue only when `migration_name` is passed, so I would move it to the `if options['app_label'] and options['migration_name']` branch, e.g. ```diff diff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py index 9ad1854a2d..aa1a41e78c 100644 --- a/django/core/management/commands/migrate.py +++ b/django/core/management/commands/migrate.py @@ -140,18 +140,20 @@ class Command(BaseCommand): except KeyError: raise CommandError("Cannot find a migration matching '%s' from app '%s'." % ( migration_name, app_label)) - targets = [(app_label, migration.name)] + target = (app_label, migration.name) + if ( + target not in executor.loader.graph.nodes and + target in executor.loader.replacements + ): + incomplete_migration = executor.loader.replacements[target] + target = incomplete_migration.replaces[-1] + targets = [target] ```
spaces missing after `if` and before `{` ð¡
we should also have messages here in this assert
This should be an issue only when `migration_name` is passed, so I would move it to the `if options['app_label'] and options['migration_name']` branch, e.g. ```diff diff --git a/django/core/management/commands/migrate.py b/django/core/management/commands/migrate.py index 9ad1854a2d..aa1a41e78c 100644 --- a/django/core/management/commands/migrate.py +++ b/django/core/management/commands/migrate.py @@ -140,18 +140,20 @@ class Command(BaseCommand): except KeyError: raise CommandError("Cannot find a migration matching '%s' from app '%s'." % ( migration_name, app_label)) - targets = [(app_label, migration.name)] + target = (app_label, migration.name) + if ( + target not in executor.loader.graph.nodes and + target in executor.loader.replacements + ): + incomplete_migration = executor.loader.replacements[target] + target = incomplete_migration.replaces[-1] + targets = [target] ```
If we don't count token with 0-increment this should be equal to 2
spaces missing after `if` and before `{` ð¡
spaces missing after `if` and before `{` ð¡
we should also have messages here in this assert
I think this is a tricky place to put this - it doesn't really know what the retry semantics are (that we always retry a full batch). This is why we had the BatchOperationException. If we want to remove it from the "official exception list" (+1 on that), we can still make BatchOperationException dedicated non ElasticsearchException by always rethrowing it's cause.
I think this is a tricky place to put this - it doesn't really know what the retry semantics are (that we always retry a full batch). This is why we had the BatchOperationException. If we want to remove it from the "official exception list" (+1 on that), we can still make BatchOperationException dedicated non ElasticsearchException by always rethrowing it's cause.
I think we don't need this line or the following two, since they duplicate docs found elsewhere.
I think we don't need this line or the following two, since they duplicate docs found elsewhere.
I think this is a tricky place to put this - it doesn't really know what the retry semantics are (that we always retry a full batch). This is why we had the BatchOperationException. If we want to remove it from the "official exception list" (+1 on that), we can still make BatchOperationException dedicated non ElasticsearchException by always rethrowing it's cause.
I think this is a tricky place to put this - it doesn't really know what the retry semantics are (that we always retry a full batch). This is why we had the BatchOperationException. If we want to remove it from the "official exception list" (+1 on that), we can still make BatchOperationException dedicated non ElasticsearchException by always rethrowing it's cause.
I see. Could we just open all the directories up-front and then clean them all up at the end? If possible I think it's clearer that there are no leaks if you can see acquisition and release of resources to be paired up in a single method. It's not always possible, but here I think it is.
I see. Could we just open all the directories up-front and then clean them all up at the end? If possible I think it's clearer that there are no leaks if you can see acquisition and release of resources to be paired up in a single method. It's not always possible, but here I think it is.
I think this is a tricky place to put this - it doesn't really know what the retry semantics are (that we always retry a full batch). This is why we had the BatchOperationException. If we want to remove it from the "official exception list" (+1 on that), we can still make BatchOperationException dedicated non ElasticsearchException by always rethrowing it's cause.
what I mean is just do it at the end of the method so waiting for refresh will be concurrent to the fsync (just a minor optimization - not really something worth complicating flow paths)
I think this is a tricky place to put this - it doesn't really know what the retry semantics are (that we always retry a full batch). This is why we had the BatchOperationException. If we want to remove it from the "official exception list" (+1 on that), we can still make BatchOperationException dedicated non ElasticsearchException by always rethrowing it's cause.
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
I think we can just access the member directly.
I really don't think we should capture assertions and rethrow, it leaves us really open to typoing and swallowing test failures because we accidentally forgot to rethrow. I assume your intent here was to give more info if one of them failed? In that case, I think ordering them by most to least information would be better (though optional, I mostly care about removing anything catching asserts): ``` java assertThat(e.getMessage(), containsString("Remote responded with a chunk that was too large. Use a smaller batch size.")); assertSame(tooLong, e.getCause()); assertFalse(called.get()); ``` And then removing the try/catch altogether.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
should we think about the fact that flush might not be allowed since a recovery is happening (that will eventually get cancelled since we are closing the engine)
canceled -> cancelled
It should read `d is null`.
This doesn't look correct to me: `of course` would be analyzer as a single token `course` at position 0 while it should be at position 1. I think the right fix is to put back `tokens.add` where it was before and instead to initialize `position` at -1.
It should read `d is null`.
nit: read lock -> just lock.
minor detail: I think currentState instead of newState will better communicate that the state was already applied.
maybe it's nicer to just capture the `DiscoveryNode` object here and use `equals` on that (internally it will use the ephemeral id for comparison anyhow).
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
This doesn't look correct to me: `of course` would be analyzer as a single token `course` at position 0 while it should be at position 1. I think the right fix is to put back `tokens.add` where it was before and instead to initialize `position` at -1.
Checkstyle is unhappy with this.
nit: move this to the line above.
This should only be done in close()
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
This should only be done in close()
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
This lambda does not need to be a statement block.
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
Can you call this something other than `total`? It's really hard to read things like `total.total, total.total, total.total + total.total`.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
formatting should be fixed like the rest in these three lines
one assert per member is better then you see what's not null :0
I have a similar concern here for when entry.getValue is not a Map
nit: `>=` -> `>` (equality is not an option :))
I think we want to test index level blocks too here
do we need the version check here? it's folded into allocatedPostIndexCreate() ? I think it will be simpler to read if we remove this from the if and add an assert on this, explaining why we expect it like that. Something like: ``` if (lastActiveAllocationIds.isEmpty()) { assert indexSettings.getIndexVersionCreated().before(Version.V_3_0_0) : "trying to allocated a primary with an empty allocation id set, but index is new"; ```
do we need the version check here? it's folded into allocatedPostIndexCreate() ? I think it will be simpler to read if we remove this from the if and add an assert on this, explaining why we expect it like that. Something like: ``` if (lastActiveAllocationIds.isEmpty()) { assert indexSettings.getIndexVersionCreated().before(Version.V_3_0_0) : "trying to allocated a primary with an empty allocation id set, but index is new"; ```
Missing a space here after `id`
nit: `>=` -> `>` (equality is not an option :))
Missing a space here after `id`
I think we want to test index level blocks too here
I won't mind, but I don't know Spring Boot development process in details, so I'll defer a decision for a proper validation and its place to respective Spring Boot team members. Thanks
I won't mind, but I don't know Spring Boot development process in details, so I'll defer a decision for a proper validation and its place to respective Spring Boot team members. Thanks
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I would be using a `Set` in this circumstances.
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
I wonder if we should just fold this into a single iteration: ``` for (final DiscoveryNode node : currentNodes) { if (discoveryNodes.contains(node) == false) { <-- probably should rename discoveryNodes to nodesToKeep or something like it) // remove logic } } ```
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
can we just do it even for `size == 0`
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
oh nevermind, I just found the method that called it with null :)
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
ok let me know if I have to look into that or you can manage.
I guess it is "these" marked consumers now.
ok let me know if I have to look into that or you can manage.
I guess it is "these" marked consumers now.
I think we need to throw an exception here, just as we do above with the currentFlushing check.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
I think we need to throw an exception here, just as we do above with the currentFlushing check.
Imho, the interruption is dealt with here. We don't need to bother the code higher up with it.
Imho, the interruption is dealt with here. We don't need to bother the code higher up with it.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
this could be replaced with Objects.requireNotNull
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
ta -> to
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Sorry, I wasn't explicit, but you're missing "term" everywhere except for the ones that you just fixed.
Sorry, I wasn't explicit, but you're missing "term" everywhere except for the ones that you just fixed.
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
Just thinking about diagnosing possible future failures, I think it would be useful to `logger.info()` any non-matching states so we can see if something weird was going on.
If we separate `updateNodes(state, clusterStateServiceMap);` out of `randomInitialClusterState`, there is no need to have a `clusterStateServiceMap` in this test.
If we separate `updateNodes(state, clusterStateServiceMap);` out of `randomInitialClusterState`, there is no need to have a `clusterStateServiceMap` in this test.
nit: "so we assume"...
long live java 8
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
trace logging here as well
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
I think you can remove the whole override.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
I think a better name would be `acknowledgeResponseReceipt` or something similar
I think a better name would be `acknowledgeResponseReceipt` or something similar
I think a better name would be `acknowledgeResponseReceipt` or something similar
the suppress warnings could be right on the line of code doing the cast instead of the whole method
nit: `>=` -> `>` (equality is not an option :))
This sucks.. I want to see how big of a deal it is to keep things as they were. Indeed snapshotting a commit will keep it's translog around but I'm not sure anymore it's worth this kind of wrapping layers. Maybe we should invest in faster clean up on those snapshotted commits. I'll reach out to discuss.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
Also good. :)
nit: `>=` -> `>` (equality is not an option :))
here a dict could be stored instead of both `self.jaas_auth_file` and `self.kafka_env_opts`. if module.params['jaas_auth_file']: self.kafka_env_opts = {'KAFKA_OPTS': module.params['jaas_auth_file']} else: self.kafka_env_opts = {}
You would have to remove the type if you donât want int32. We deal with unsigned ints that are 64 bits in length in win_regedit and have to rely on the manual parsing.
I think I'd prefer two tests to test these two paths.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
can this see `unregister task for id: [{}]`
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
This message probably made sense once but it doesn't anymore. I'd suggest `Cannot update the job config because job...`
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
Sorry, I'd missed that there are two URIs being configured, one with credentials and one without.
Is this clearer? ```diff diff --git a/core/src/main/java/org/elasticsearch/node/AdaptiveSelectionStats.java b/core/src/main/java/org/elasticsearch/node/AdaptiveSelectionStats.java index bed282b899..787fa1e9d1 100644 --- a/core/src/main/java/org/elasticsearch/node/AdaptiveSelectionStats.java +++ b/core/src/main/java/org/elasticsearch/node/AdaptiveSelectionStats.java @@ -33,6 +33,7 @@ import java.util.Locale; import java.util.Map; import java.util.Set; import java.util.concurrent.TimeUnit; +import java.util.stream.Collectors; /** * Class representing statistics about adaptive replica selection. This includes @@ -102,10 +103,12 @@ public class AdaptiveSelectionStats implements Writeable, ToXContentFragment { * Returns a map of node id to the ranking of the nodes based on the adaptive replica formula */ public Map<String, Double> getRanks() { - Map<String, Double> ranks = new HashMap<>(nodeComputedStats.size()); - nodeComputedStats.forEach((k, v) -> { - ranks.put(k, v.rank(clientOutgoingConnections.getOrDefault(k, 0L))); - }); - return ranks; + return + nodeComputedStats + .entrySet() + .stream() + .collect(Collectors.toMap( + Map.Entry::getKey, + e -> e.getValue().rank(clientOutgoingConnections.getOrDefault(e.getKey(), 0L)))); } } ```
`metric1` first? you have `metric2` twice.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
This description seems redundant to me.
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
I think it might makes sense to split this into `initalPosition` and `initialState`.
we decided to live on the edge and have fun. The concern was around non ascii codes breaking tooling but CI seems happy. Let's see how far we get.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
I think that we can save the instanceof checks, builder.value(Object) does it already
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
I think that it's cleaner to write this as: ``` ElasticsearchParseException ex = (ElasticsearchParseException)ExceptionsHelper.unwrap(e, ElasticsearchParseException.class); assertNotNull(ex); assertThat(ex.getMessage(), equalTo("processor [test] doesn't support one or more provided configuration parameters [unused]")); ```
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Same here about multi-line toString methods
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
Like, just for checking that assertions are enabled.
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
Same here about multi-line toString methods
I think it'd be nice to have an assertion on the text of one description just so we can look at it.
I like `hasSize` better for this because it gives a nicer error message on failure.
I think that we need to guard against overflow here!
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
`Description` -> `Descriptor`
you should assign a new list instance (or clear the `abortBenchmarkNodeStatuses` list) to make sure we are not reading an instance that already has some status in the list.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
Another `_` java 9 will be mad at
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
Another `_` java 9 will be mad at
Nit: `initializing.size()-1` -> `initializing.size() - 1`
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Nit: `initializing.size()-1` -> `initializing.size() - 1`
I think it's always a single node cluster, but I'm good to keep it like this.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
This is fine as is.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
Nit: `initializing.size()-1` -> `initializing.size() - 1`
This should be: ``` ^(?:[-\\w]+[.])+$ ``` This assumes that (a) at least one level is required and (b) there is nothing after the group key (so it is anchored to the end of the string)
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
As suggested by Tobias, it should be: ``` class MyEmailBackend(EmailBackend): def __init__(*args, **kwargs): kwargs['timeout'] = 60 super(MyEmailBackend, self).__init__(*args, **kwargs) ```
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
minor formatting issue
cool can you update the title of the PR then? :)
What about something like ``` p = nextBufferPos(p); int sequence = 0xFF & sequenceBuffer[p]; p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); p = nextBufferPos(p); sequence = sequence << 8 | (0xFF & sequenceBuffer[p]); node.add(sequence << 8); ``` No byte array required.
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
I think we should leave this method for java api bw comp
I think this check does not add much (I would skip it)
maybe rename those methods to assert\* as this is what they do... same with the next one
`Weight weight = searcher.createNormalizedWeight(filtersFunctionScoreQuery, true)` would be better I think as it will include weight normalization
`Weight weight = searcher.createNormalizedWeight(filtersFunctionScoreQuery, true)` would be better I think as it will include weight normalization
maybe rename those methods to assert\* as this is what they do... same with the next one
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
maybe rename those methods to assert\* as this is what they do... same with the next one
maybe rename those methods to assert\* as this is what they do... same with the next one
maybe rename those methods to assert\* as this is what they do... same with the next one
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
maybe rename those methods to assert\* as this is what they do... same with the next one
maybe rename those methods to assert\* as this is what they do... same with the next one
maybe rename those methods to assert\* as this is what they do... same with the next one
Ah yes, thanks!
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
Is that supposed to be SpEL? I'd prefer if we perform that detection elsewhere (in the caller with access to the `Environment`).
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
the start cluster does this.
We don't do property placeholder in properties. Yes please.
Key descriptions do not start with "The", "A", etc.
I wonder how long this would work ;)
fine with me as well. go ahead and push!
can we move this part to the setRefreshPending method? this will come at the expense of a dedicated listener but all the code that changes pendingRefreshLocation will be in one place making it easier figure out.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I think this is a mistake here you didn't want to pull in some guice class here right? `+import org.elasticsearch.common.inject.Provider;` Can't we just make the privder be a string instead? and if necessary it should be a `Supplier`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
I think it might makes sense to split this into `initalPosition` and `initialState`.
doing this via reflection would be nice too :)
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can use a for-each syntax here: `for (ObjectCursor<byte[]> cursor : bytesList)`
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
I think the unlock calls should always be in a finally block
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
here you may be able to use copyCurrentStructure
here you may be able to use copyCurrentStructure
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
here you may be able to use copyCurrentStructure
here you may be able to use copyCurrentStructure
this deserves a sep issue I guess but good catch
here you may be able to use copyCurrentStructure
I think we want to test index level blocks too here
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
It seems nothing is done when `check_mode` is enabled.
It seems nothing is done when `check_mode` is enabled.
:+1: (I added the same method here locally (differently implemented) )
I think this needs a bit more explanation, as well as what null means. Honestly it'd be best if we could avoid it being part of script altogether because most scripts don't have a content type.
should be action
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I doubt this util from spring-kafka is acceptable in Spring Boot code. See other similar auto-configuration classes which use something like this: `PropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull();` The `IntegrationAutoConfiguration` is good one to look into.
TIL about the `|=` operator. For others reviewing: this will replace changed with True iff changed is not True already and a function evaluates to True. Once True, one of these updated returning False won't switch the changed status.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
Typo: "Dynamics" -> "Dynamic"
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
Or not. It looks like you are allowed to modify the segment's innards while you have this lock.
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
also this class should be final.
also this class should be final.
`try / finally`
for some caches it would be nice to make sure to not compute twice the same value
This will fail if `(int)((end - start)/bucketSpan)` is greater than 10000. A check should be added elsewhere to ensure that the window is small enough that this won't happen.
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
Maybe `SystemUser.NAME`? I worry that in the future when we do object level security using a username that doesnât correspond to a real user may be a security hole.
Nit: please add spaces around the `=` sign.
Maybe `SystemUser.NAME`? I worry that in the future when we do object level security using a username that doesnât correspond to a real user may be a security hole.
also this class should be final.
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
nit: indenting should be only 4 extra spaces
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
That assumes `list` can't contain null..if that is not the case ignore
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
This will fail if `(int)((end - start)/bucketSpan)` is greater than 10000. A check should be added elsewhere to ensure that the window is small enough that this won't happen.
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
This will fail if `(int)((end - start)/bucketSpan)` is greater than 10000. A check should be added elsewhere to ensure that the window is small enough that this won't happen.
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
Can't recovery -> Can't recover
Why do we need this? The public ctor is used for new types, when intializing all the metadata fields. But in that case, there is nothing shared so no need to initialize the join fieldtype (it should not be used unless/until _parent is set on the new type, in which case it will be parsed and the protected ctor will be used).
I wonder if the entire function could be simplified to the form: ``` current = min while (current <= max && iter.hasNext()) { // get next bucket // loop current up to nextBucket // set current to nextBucket rounded } while (current <= max) { // handles both empty case and trailing case } ```
Typo: "Dynamics" -> "Dynamic"
The sizes are `long`s so I think `randomLongBetween()` would be better.
The sizes are `long`s so I think `randomLongBetween()` would be better.
Maybe `SystemUser.NAME`? I worry that in the future when we do object level security using a username that doesnât correspond to a real user may be a security hole.
There is no state `get`.
Nit: please add spaces around the `=` sign.
Nit: please add spaces around the `=` sign.
It's better to mark parentSubscription final
It's better to mark parentSubscription final
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
It's better to mark parentSubscription final
It's better to mark parentSubscription final
Nit: please add spaces around the `=` sign.
Typo: "Dynamics" -> "Dynamic"
Typo: "Dynamics" -> "Dynamic"
Nit: please add spaces around the `=` sign.
I would also test the direct retrieval of a file (not relevant to this change but we miss that one now and it will be good to have)
I think we should leave this method for java api bw comp
I think we should leave this method for java api bw comp
I think we should leave this method for java api bw comp
I think we should leave this method for java api bw comp
I guess it could be renamed to isFalse() / isTrue() now
can we move this part to the setRefreshPending method? this will come at the expense of a dedicated listener but all the code that changes pendingRefreshLocation will be in one place making it easier figure out.
I think `value.length() == 0` here should be `String.hasText(value)`, so it checks for `" "` and uses the default value for it.
I guess it could be renamed to isFalse() / isTrue() now
I think `value.length() == 0` here should be `String.hasText(value)`, so it checks for `" "` and uses the default value for it.
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
do we need ordered things? does order help anywhere? If not I would just use HashMap
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
Such a loop in a test is not acceptable. You could send a message and wait a bit. There are similar samples in the JMS area you can reuse.
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
I think we can go with a higher bulk size, because we only do deletes. Something like 5000 or even 10000.
I think we can go with a higher bulk size, because we only do deletes. Something like 5000 or even 10000.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
do we want to check that the shards were actually failed? Ideally we would just check that the allocation service was asked to fail them. Mockito maybe helpful? I don't want to hold you back for this though...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Once we have a `running` flag, we can check on it and not on `isAlive`.
can we replace these test with a simpler to understand test, paying the price of things being less targeted? experience have shown that this type of tests are very hard to maintain and often don't reproduce exactly what was intended anyway (because it's so hard)..
Such a loop in a test is not acceptable. You could send a message and wait a bit. There are similar samples in the JMS area you can reuse.
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
Such a loop in a test is not acceptable. You could send a message and wait a bit. There are similar samples in the JMS area you can reuse.
do we want to check that the shards were actually failed? Ideally we would just check that the allocation service was asked to fail them. Mockito maybe helpful? I don't want to hold you back for this though...
randomInt cannot be within the loop, otherwise it changes at every iteration...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
sorry, I missed the ping here. I think that 1 is ok too, but then we should in general change the terminology in `IndexShardOperationPermits` to move from the notion of blocking operations to running exclusive operations (similar to a read/write lock).
do we want to check that the shards were actually failed? Ideally we would just check that the allocation service was asked to fail them. Mockito maybe helpful? I don't want to hold you back for this though...
do we want to check that the shards were actually failed? Ideally we would just check that the allocation service was asked to fail them. Mockito maybe helpful? I don't want to hold you back for this though...
we end up supporting both `$stashedKey` and `foo${stashedKey}bar` ? we may want to move to the latter once all the clients runners implement this feature, to have a single way to get stashed values.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
This should be done in reset()
Yea, I can see that... . The problem though is that it might create a lot of warn messages... . People can always decide to dynamically enable debug logging here to see whats going on. We do not allocate shards on other deciders, and never warn because of it... One of the things we were thinking about is that potentially part of the reroute call, we will give back a full explanation on what was allocated and what was not, so people can see it as part of an API call about why things were rejected.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
Yea, I can see that... . The problem though is that it might create a lot of warn messages... . People can always decide to dynamically enable debug logging here to see whats going on. We do not allocate shards on other deciders, and never warn because of it... One of the things we were thinking about is that potentially part of the reroute call, we will give back a full explanation on what was allocated and what was not, so people can see it as part of an API call about why things were rejected.
This has the same issue where multiple threads could wind up âfinishingâ this since done is not rechecked within the synchronized block.
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
maybe ${stashedKey} alone should return an object then? Does that complicate things? Calling toString makes sense when the stashed thing is part of a string, otherwise returning the object sounds better.
can you just leave the constant in this class? There isn't a need to put it in realm imo
can you just leave the constant in this class? There isn't a need to put it in realm imo
Ah yes, thanks!
Ah! I was blind to the line with the white background.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
I think this name should align more closely with the setting that it maps to. Something like `timeBetweenEvictionRuns`, perhaps.
I think this name should align more closely with the setting that it maps to. Something like `timeBetweenEvictionRuns`, perhaps.
Ok sounds fine then.
Ok sounds fine then.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Ok sounds fine then.
thank you for renaming this.
thank you for renaming this.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
I think this is fine for now. While I do think expert users will want to tweak exactly which metric they use for evaluation, I guess it's ok to not make this plug-able right from the start.
Please change it to `only one thread should call`, remove `be allowed to`.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
maybe `Objects.equal` could make it easier to read
Doh! the recommendation is forbidden API ..never mind.
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
You can use a for-each syntax here: `for (ObjectCursor<byte[]> cursor : bytesList)`
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
these ElasticsaerchExceptions are bogus remove them
++ on debug message
Since "version" and "primary" are used not only here, but below in the `fromXContent`, they may go better in a static `Fields` encapsulation so if they are changed in the future they only have to be changed in one place.
same here - I think it's better to log the info message if the deletion was successful.
Since "version" and "primary" are used not only here, but below in the `fromXContent`, they may go better in a static `Fields` encapsulation so if they are changed in the future they only have to be changed in one place.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
++ on debug message
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
same here - just pass a new instance
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
lets just use IOException that's much better for this purpose and it's checked
lets just use IOException that's much better for this purpose and it's checked
no, the existing TermsLookup shall remain, but we have to add serialization etc. to it.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
No, I still think that it should not be a method on the `Strings` class.
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
I'd deliver to current thread uncaught exception handler similarly how this method worked before This change can also end up violating Reactive Streams in some cases
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
This is especially important in the case of `TransportReplicationAction` where the request sizes can get big. So we definitely want to count those bytes, but still exclude these requests from the checks.
I'd deliver to current thread uncaught exception handler similarly how this method worked before This change can also end up violating Reactive Streams in some cases
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
Can we remove `throws IOException` and write: ``` java try { if (!Files.exists(initialSettings.v2().pluginsFile())) { Files.createDirectories(initialSettings.v2().pluginsFile()); } } catch (IOException e) { displayHelp("Unable to create plugins dir: " + initialSettings.v2().pluginsFile()); System.exit(EXIT_CODE_ERROR); } ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
ok I am fine with that, not a huge deal
By moving this inside the `for` loop it throws after the first IOException, so it would be better to throw inside the `catch` block (unless moving it inside was not intended)
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
I'd deliver to current thread uncaught exception handler similarly how this method worked before This change can also end up violating Reactive Streams in some cases
I see that we need it from another package, I think it's ok.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
The repeatedly printed stacktrace is not relevant if you want to fail the test. The uncaught handlers are thread-local and you only need to get past the catch around the onError handler. They are invoked together on the same thread.
No, I still think that it should not be a method on the `Strings` class.
> Though I do prefer that it fails fast instead of lazily later. ++
should be ThreadedActionListener<>
should be ThreadedActionListener<>
s/The tasks has/In case the task has/
yea I was looking at the stacktrace and wondering what is important in there, not sure.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Can we remove `throws IOException` and write: ``` java try { if (!Files.exists(initialSettings.v2().pluginsFile())) { Files.createDirectories(initialSettings.v2().pluginsFile()); } } catch (IOException e) { displayHelp("Unable to create plugins dir: " + initialSettings.v2().pluginsFile()); System.exit(EXIT_CODE_ERROR); } ```
Nah, if it hasn't hit yet we'll handle it if it does in the future, don't worry about it.
Unfortunately these overloaded method signatures have the same arity and will cause problems with Groovy/Clojure/JRuby etc as they can't determine the difference between `Func0` vs `Func1` at runtime. We should either eliminate unnecessary overloads, change signatures or have more descriptive names instead of overloads.
I think there is a bug here. What is `\\`? I guess Windows? You need to take caution for different filesystems.
I think there is a bug here. What is `\\`? I guess Windows? You need to take caution for different filesystems.
I think there is a bug here. What is `\\`? I guess Windows? You need to take caution for different filesystems.
Don't shadow built-in names.
Hmm, good point.
I wonder how long this would work ;)
Hmm, good point.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
Can this be "metadata"? We don't hyphenate anywhere else in the code.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
make this Error? we alway want to use this.
nit: `>=` -> `>` (equality is not an option :))
This should say `higher cluster state version` instead of `higher id`.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
Oh, I'm fine with symmetry, I just wanted to make sure that I was reading it correctly.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
Another personal preference, but we should be able to avoid empty opening `(` here
Another personal preference, but we should be able to avoid empty opening `(` here
This should say `higher cluster state version` instead of `higher id`.
Another personal preference, but we should be able to avoid empty opening `(` here
same here, all retry logic should be removed
I think this has to happen before you start the cluster, or else the cluster will start with full knowledge.
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
I have the same thoughts as above for commit time.
Small typo: `s/affective/effective/`
I think the unlock calls should always be in a finally block
at this point you don't need the restClient variable anymore
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
nit - an extra d? release**d**Delayed..
I think its worth it? most of the time the response handle is SAME, so its not a big problem, but it allows to not overflow the same thread pool if it happens
you should assign a new list instance (or clear the `abortBenchmarkNodeStatuses` list) to make sure we are not reading an instance that already has some status in the list.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
newQueue -> newTombstone
newQueue -> newTombstone
It seems nothing is done when `check_mode` is enabled.
Maybe warp the listener using ActionListener#wrap which does the write things and will simplify the code here too.
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
why do we need to read the checkpoint again? I think we need to be consistent here - either with throw the underlying exception (and thus not protect about FileNotFoundException) or catch everything and rethrow a corruption exception. I tend toward the later..
Left over Note
> We should never rely on the ordinal for any enum anywhere We've been relying on ordinals for serialization for a while, asserting that the ordinals do not change in the tests.
> We should never rely on the ordinal for any enum anywhere We've been relying on ordinals for serialization for a while, asserting that the ordinals do not change in the tests.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I've tried http://mediadownloads.mlb.com/mlbam/2014/07/12/ in a browser and it takes more than 50 seconds to download. We should use a faster method, for example looking into: http://m.mlb.com/gen/multimedia/detail/6/6/3/34496663.xml
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
typo - failIfCancled -> failIfCanceled
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
I think "Have you added" or "Did you add" might sound a bit better here... We could also change it to something less accusative :smile: like "If this is a newly added aggregation, please open..."
Doesn't actually throw `IOException`.
please - I can help if you want
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
should be ThreadedActionListener<>
can you add more rolling while adding? Also *sometimes* increment the primary term
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
Hmm good point, I had forgotten that this class could actually be returned to the user (masked behind an API interface).
no need to make this public; package-visible is good enough.
Plz also use `match` arg here
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
just use the public one with one less parameter...
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
`\s` not ` `.
Could initialize this with the size of the hits list to prevent resizing
I am ok with what you propose Nik!
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
I'm not certain this requirement is enough because if a source doesn't deliver the requested amount, it will keep the client hanging which may not request a new batch. There is also the problem if the first observable delivers less than requested, the missing amount is not replenished/considered by the second Observable and thus the client may starve. This is why `concat` uses the `SubscriptionArbiter` so that if an Observable didn't deliver enough, the next is requested for the missed amount. Similar measures might be required with this `AsyncOnSubscribe`.
Nit: drop the `,` here.
Nit: drop the `,` here.
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
I don't see much value in check that bad representation doesn't exists. I moved the entire row to a single assertion.
This can just be `System.out.print(msg)` now I think. Thanks for removing the formatting from these print apis! I think that was the real problem, its trappy for a `printf()` to be named anything other than `*printf()`. And in this case the caller can just always `String.format` themselves.
can be specified as `catch (SnapshotCreationException | RepositoryException ex)` in Java ;-)
assertBusy uses by default 10 seconds, no need to specify it here again
ah ok I misunderstood what this was doing, I'm +1 on it working as you describe to match keyword fields
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
This always scheduled in the future with `timeout`. Shouldn't it be the time until next timeout? Let's say timeout is 1000ms and I get an onNext call every 50ms. This code seems to schedule each action to execute 1000ms in the future even if it comes in 950ms since the last onNext was permitted through.
oh yeah I missed that :/
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
nit - we flush also it will reduce the size of uncommitted gens but strictly speaking it doesn't mean it will be below the threshold
can we use an iterator here instead? it would be more clear to me if we'd do that..
I don't grok this method yet as it is rather complicated so I'm going to have to come back to this another time ...
`s/step/cluster state step/`
I am good
does it make sense to put the "fail a shard" logic under a method? to make sure we don't forget to put it in failedShards etc.
does it make sense to put the "fail a shard" logic under a method? to make sure we don't forget to put it in failedShards etc.
`file reopened` -> `file is reopened`
I think it's good to reuse this threadpool, but it implies that the analytics process is a "job" from the point of view of deciding how many jobs can run on each node. We definitely need to hook these processes into a unified allocation framework. Also, maybe rename the threadpool to `JOB_PROCESS_THREAD_POOL_NAME` or similar.
So what does this _look_ like? I imagine it doesn't look any different unless you set the logging level to something lower-than-default.
please log the exception here as well we really wanna see what was going wrong
Although this is some kind of hidden feature, there might be people relying on us following links here... I'd open a separate issue if we want to remove it to give people the chance to speak up if they need it.
I don't think this needs "WithAlphas", because the unstable branch always has alphas (when we switch to beta, we cut a new stable branch).
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
use assertBusy instead.
use assertBusy instead.
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
use assertBusy instead.
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
I think we can just access the member directly.
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
I think we can drop the benchmark.
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
Same here with line breaks. Usually I see this as `} else {` in our code.
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
even though this is just `debug`, logging an encryption key is worrisome
simpler: datetime.now().strftime(''%B %d, %Y - %X')
I think this needs to be `Version.V_6_0_0_alpha3` now.
This method is only used in applyDeletedShards to iterate over the shards... That method is called every cluster state update for each IndexService, which might be wasteful in terms of resources. We can simply use iterator instead.
I don't think this indenting is intended.
I wonder if we should just fold this into a single iteration: ``` for (final DiscoveryNode node : currentNodes) { if (discoveryNodes.contains(node) == false) { <-- probably should rename discoveryNodes to nodesToKeep or something like it) // remove logic } } ```
I don't think this indenting is intended.
I wonder if we should just fold this into a single iteration: ``` for (final DiscoveryNode node : currentNodes) { if (discoveryNodes.contains(node) == false) { <-- probably should rename discoveryNodes to nodesToKeep or something like it) // remove logic } } ```
I think "Have you added" or "Did you add" might sound a bit better here... We could also change it to something less accusative :smile: like "If this is a newly added aggregation, please open..."
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
I think that it's worth logging the index metadata version here too (and the mapping metadata version in the future).
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
nevermind I was confused... all is good
If this stays an error or maybe gets converted to a log message, the line number would be a helpful debugging information for the user the file.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
I am ok with what you propose Nik!
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
can we rename this to `sortedShardDocs`
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
This isn't needed client-side.
good that you added this assertion :)
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
this can be collapsed into `assertTrue(foundTerms.add(bucket.getKeyAsNumber()))`
The message doesn't really make sense because it's missing the "discovery state" part, right now it says it timed out waiting for initial timeout :)
nit - an extra d? release**d**Delayed..
nit: can we move the look up of the primary to the callers that pass null? this method is hairy enough :)
I think we should still wrap this in a doPriviledged block same asn the entire thread creation and set* below. It will allow us and other users to give fine granular security permissions
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
also, the setting should be using `componentSettings.get("page.limit", ...)`, so it will resolve to `cache.recycler.page.limit` (and I think the in_bytes usage here is not needed).
nit: can we move the look up of the primary to the callers that pass null? this method is hairy enough :)
nit: can we move the look up of the primary to the callers that pass null? this method is hairy enough :)
nit: can we move the look up of the primary to the callers that pass null? this method is hairy enough :)
I think we should still wrap this in a doPriviledged block same asn the entire thread creation and set* below. It will allow us and other users to give fine granular security permissions
Another `_` java 9 will be mad at
role_name can be lower case as well. For example, user can provide admin for `Admin` value, then this function will return None.
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Needs a guard.
Needs a guard.
Ah, nope, I'm just bad at Java. `[Metric1, Metric2]` is exactly what I was wanting. :)
I suggest `for x_shape, y_shape, axes, z_shape in test_cases:` to improve readability.
for style can we maybe invert the if statements here ie `if (!masterCopy.isEmpty)` and `if (!success)`? I like to have only one return statement at the end of the method
for style can we maybe invert the if statements here ie `if (!masterCopy.isEmpty)` and `if (!success)`? I like to have only one return statement at the end of the method
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
> while in this case we only make a copy if maxBatchSizeInBytes limit has been reached. he - I'm pretty I saw we did in some previous iterations. And yes - it must allow reads because we block reads when we don't consume the write buffer. In a sense the right moment is when you coordinate writes and you consumed some buffer elements. Both are fine with me
no need to make this public; package-visible is good enough.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
Why do we need this? The public ctor is used for new types, when intializing all the metadata fields. But in that case, there is nothing shared so no need to initialize the join fieldtype (it should not be used unless/until _parent is set on the new type, in which case it will be parsed and the protected ctor will be used).
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
Why do we need this? The public ctor is used for new types, when intializing all the metadata fields. But in that case, there is nothing shared so no need to initialize the join fieldtype (it should not be used unless/until _parent is set on the new type, in which case it will be parsed and the protected ctor will be used).
Key descriptions do not start with "The", "A", etc.
> Is there a different way we can handle this altogether? That's what I'm going to be thinking about.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think we could persist a time-to-live in the cluster state, and on each cluster state update the current master can subtract the offset between the current `System#nanoTime` and the `System#nanoTime` from the last time the master updated its local cluster state and persist the maximum of the new time remaining and zero. Now the tombstone will live exactly as long as there has been an active master and we do not have to worry about any crazy time issues.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
`try / finally`
hmm can't we use `State.values()` and if this is only used for `fromId` I think we can just do this: ``` Java switch(id) { case RUNNING.id: return RUNNING; //... } ```
I am good
this method can the max size and min expiration window as parameters, which will make it easier to test and have those be settings,
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
"new" -> "now"
I meant `node` from the for loop.
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
I meant `node` from the for loop.
this method can the max size and min expiration window as parameters, which will make it easier to test and have those be settings,
ok...but client depends on the transport service anyway no? I think I don't get it
I am good
I think we could persist a time-to-live in the cluster state, and on each cluster state update the current master can subtract the offset between the current `System#nanoTime` and the `System#nanoTime` from the last time the master updated its local cluster state and persist the maximum of the new time remaining and zero. Now the tombstone will live exactly as long as there has been an active master and we do not have to worry about any crazy time issues.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
Nit: space between the cast operator and the target.
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
why do we need assertBusy here? I rather use two signaling methods - the one you have now and the one signaling the some/all the threads have acquired the ops lock. Note that now I think you have a race condition with the recovery thread can sneak in first.
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
You could add an assert that it's not ES 7.x here so we know to remove it
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Name an example URL where `og:description` has HTML tags.
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
This changes behaviour as any exception from the `close()` call will no longer be caught and logged as a warning.
I meant the listener we pass to the transport
I think if you add this below then that will work too and it is shorter: ``` (actual instanceof NodeNotConnectedException && actual.getMessage().contains("TransportService is closed")) ```
Can you reverse this, the negative makes it harder to read
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
I meant the listener we pass to the transport
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
I think it's simpler to just keep equality, but I'm good with you prefer it this way.
this means the mutable ShardRouting will have their hashes re-calculated every time . Can you double check the impact this have on a huge routing nodes and the balancer (your favorite code :)).
use Model.objects.create() rather than `save()`? I don't think manually specifying an id is needed (or a best practice)
yea, I would at least debug log it..., it shouldn't happen
use Model.objects.create() rather than `save()`? I don't think manually specifying an id is needed (or a best practice)
this line can be removed
use Model.objects.create() rather than `save()`? I don't think manually specifying an id is needed (or a best practice)
Technically since we're doing this in a fixture, either `monkeypatch` should be used to insert these into `globals()`, or you should return `mod`, and then just use `mod.Template` and `mod.AnsibleNativeEnvironment` in your tests.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
I like `hasSize` better for this because it gives a nicer error message on failure.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
as I said above, that makes sense, I adjusted it on our branch that way.
`Exception as e`
`Exception as e`
check listener.isDone() as we don't expect a retry here I think
`Exception as e`
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
why do we need assertBusy here? I rather use two signaling methods - the one you have now and the one signaling the some/all the threads have acquired the ops lock. Note that now I think you have a race condition with the recovery thread can sneak in first.
we don't need this anymore mockFs takes care of all this. /cc @rmuir
strictly speaking, we can log the reason here as we don't know why people called us. We need to either pass a parameter (reason) or remove the last part.
Nit: `reject` -> `rejected`
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
Can we fold all these assertions into a single one? I think this should cover enough. ``` assertThat(shardChangesRequests, contains(new long[][]{ {0L, 8L}, {9L, 8L}, {18L, 8L}, {27L, 8L}, {36L, 8L}, {45L, 8L}, {54L, 8L}, {63L, 8L} })); ``` Moreover, the leader should not return more than the requesting batch size. Here, we request 8 operations, but it returns 9 operations.
Minor typo of `local` instead of `locale` in the exception message.
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
typo: direct**or** -> direct
This was missing a re-throw of the exception anyway!
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
shall we check what the current token is? if it is a field_name we could use a while instead of a do while? that would be a bit more readable I think.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
How about you install a custom hook to the current thread from the `onError` handler that will rethrow the original exception: ```java import java.io.IOException; import java.lang.Thread.UncaughtExceptionHandler; import org.junit.*; import io.reactivex.Observable; import io.reactivex.plugins.RxJavaPlugins; public class HookThrowing { @Before public void before() { RxJavaPlugins.setErrorHandler(ex -> { UncaughtExceptionHandler h = Thread.currentThread().getUncaughtExceptionHandler(); Thread.currentThread().setUncaughtExceptionHandler((t, e) -> { Thread.currentThread().setUncaughtExceptionHandler(h); HookThrowing.sneakyThrow(ex); }); throw new RuntimeException("Fail up"); }); } @SuppressWarnings("unchecked") static <E extends Throwable> void sneakyThrow(Throwable ex) throws E { throw (E)ex; } @After public void after() { RxJavaPlugins.reset(); } @Test public void test() { Observable.error(new IOException()) .subscribe(); } } ```
There is an `empty()` matcher - `org.hamcrest.Matchers.empty`
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
also this class should be final.
I'd switch the order of these so it matches the declaration order.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
we can use assertThat(translog.currentId(), isGreaterThan(currentTranslogId) and get nice messages automatically.
just name it `readSize`
I think this assert in particular (the timestamp one) could be greatly simplified by asserting inside of the script itself instead of setting a new field value.
no test annotation (not needed, but for consistency)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
no test annotation (not needed, but for consistency)
no test annotation (not needed, but for consistency)
no test annotation (not needed, but for consistency)
oh I see. I missed it.
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
Such changes in our own source is a good indication there will be generics issues for the users of the library.
What do you think of this? ``` public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Iterable<Entry<K1, V1>> entries) { CopyOnWriteHashMap<K, V> result = this; for (Entry<K1, V1> entry : entries) { result = result.copyAndPut(entry.getKey(), entry.getValue()); } return result; } public <K1 extends K, V1 extends V> CopyOnWriteHashMap<K, V> copyAndPutAll(Stream<Entry<K1, V1>> entries) { return copyAndPutAll(entries::iterator); } ``` It's not necessary but the call site on line [519](https://github.com/elastic/elasticsearch/pull/13533/files#diff-80e3b9bf08264f2b719b2f8ce044ae80R519) can then change to not call `Collection#stream` but the rest of the call sites can remain as is.
Such changes in our own source is a good indication there will be generics issues for the users of the library.
Such changes in our own source is a good indication there will be generics issues for the users of the library.
Such changes in our own source is a good indication there will be generics issues for the users of the library.
Despite the name (comes from the C API unfortunately), set_range() only locates the key or the next greatest key, it does not otherwise constrain the results produced by the cursor :) It needs to be something like: ````python prefix = term[:-1] # strip asterisk cursor.set_range(prefix) while cursor.key().startswith(prefix): ret.append(cursor.item()) cursor.next() ````
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
I don't think this is worth the inconsistency. Please remove that and make it camel cased
```suggestion - There is a small delay (typically about 5 seconds, but can be as long as 60 seconds) before obtaining the random values when requesting a validation ```
Nit: Almost ;-) To be or not to be, and also where, that is the question.
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I think we should leave this method for java api bw comp
253, can go, this one... ``` print (' export S3_BUCKET_SYNC_FROM="%s"' % (s3_bucket_sync_to)) ```
I think we should leave this method for java api bw comp
I think we should leave this method for java api bw comp
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
left over reference to a countdown latch
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Right. I figure we should have a test for it or explicitly make the min for that parameter `1`. We have other ways to turn off dynamic scripts if we want so maybe it'd be better not to have two ways to do it.
I'd use an enum with `Jedis` and `Lettuce` here rather than a raw string. This also improves the developer experience in the IDE.
it would be awesome to have some doc-strings on these settings
Sure I was just wondering if there is a use case for this.
Sorry, I am not sure why but my mind inserted a `static` into that field definition. That's clearly not there so of course what you have is fine.
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
we should validate we started on a start array
we should validate we started on a start array
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
Opinionated, but I would just remove the null values. Some combination of return input.stream.filter.collect(toMap) would also be more succinct IMO.
I am not sure about this one. I feel like if it's part of `RepositoryData` it needs to be in json. Otherwise it cause things like `fromXContent` with additional parameters. Would it be a huge deal to pass gen id alone as an additional parameter instead of adding it to `RepositoryData` itself. I feel like it's not really a repositories concern, if you see what I mean.
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
I am not sure about this one. I feel like if it's part of `RepositoryData` it needs to be in json. Otherwise it cause things like `fromXContent` with additional parameters. Would it be a huge deal to pass gen id alone as an additional parameter instead of adding it to `RepositoryData` itself. I feel like it's not really a repositories concern, if you see what I mean.
let's see if we get objections on that PR or not
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
If you prefer, in the indexing method we can do tryAcquire first out of lock and go under lock and try again, if failed.
I like this much better!
I like this much better!
I like this much better!
I think you can initialize the capacity.
I think you can initialize the capacity.
I think you can initialize the capacity.
seems like we use field or fieldName throughout the different processors. Can we settle on the same name for all processors? I think field is enough.
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
nit: extra line
same note as in the json processor PR.
same note as in the json processor PR.
Rename the method to something about captures I think now that the utility is gone.
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
can we please not use `forEach` I think we should stick to for loops it just makes the code more readable and consistent
You could add an assert that it's not ES 7.x here so we know to remove it
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
Oh. You need to explicitly close the op.
Oh. You need to explicitly close the op.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
If we separate `updateNodes(state, clusterStateServiceMap);` out of `randomInitialClusterState`, there is no need to have a `clusterStateServiceMap` in this test.
You can use `assertAcked` here and just wrap the above line... one line saved ;)
can this see `unregister task for id: [{}]`
could be `final`
could be `final`
maybe just start a unicast cluster for now
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
nit: space before brackets
we can't take this one out of the try catch, it protects agains corruption. I think we should rename `buildMetadata` to `loadMetadata` and set both commutUserData and metadata in it.
maybe a regex would be more readable here :)
maybe we implement `Iterable<V>`
see above about abstract runnable
Could you have a syntax close to : ``` if not re.match(): raise ... ``` That we don't have as much indentation levels.
This method is only used in applyDeletedShards to iterate over the shards... That method is called every cluster state update for each IndexService, which might be wasteful in terms of resources. We can simply use iterator instead.
I feel like the summary here should be a bit more descriptive. Perhaps "There are enough master-eligible instances to form a quorum."
This method is only used in applyDeletedShards to iterate over the shards... That method is called every cluster state update for each IndexService, which might be wasteful in terms of resources. We can simply use iterator instead.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
does it need to be protected? Also maybe rename to something like collectValue ? I find it weird to call add against the script itself
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
This should be named `Ansi256PropertySourceTests`
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
I had not though about option 2 but I really like the fact that it does not require to add a new API. But if this argument does not resonate to you, feel free to push the change as-in, I don't have too strong feelings about it.
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
I had not though about option 2 but I really like the fact that it does not require to add a new API. But if this argument does not resonate to you, feel free to push the change as-in, I don't have too strong feelings about it.
I had not though about option 2 but I really like the fact that it does not require to add a new API. But if this argument does not resonate to you, feel free to push the change as-in, I don't have too strong feelings about it.
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
The dangling else make the code very easy to confuse with ``` java if (outputFused) { runBackfused(); } if (sourceModel == SYNC) { runSync(); } else { runAsync(); } ```
I had not though about option 2 but I really like the fact that it does not require to add a new API. But if this argument does not resonate to you, feel free to push the change as-in, I don't have too strong feelings about it.
I had not though about option 2 but I really like the fact that it does not require to add a new API. But if this argument does not resonate to you, feel free to push the change as-in, I don't have too strong feelings about it.
I think we want to test index level blocks too here
I think we want to test index level blocks too here
I think we want to test index level blocks too here
this method can be private now
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
I had not though about option 2 but I really like the fact that it does not require to add a new API. But if this argument does not resonate to you, feel free to push the change as-in, I don't have too strong feelings about it.
I think we want to test index level blocks too here
It would be worth requiring that `jobId` and `jobType` are not `null`.
I think this assertion should be in `getAnyNodeExcept()` - it's ok to return an empty list here.
nit: extra line
nit: extra line
we can just call `terminate(threadPool)` here
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
nit: extra line
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
what happens when indexing completes, relocation happens and then (and only then) the global updater kicks in. I _think_ we still have an issue, if true, let's just relax global checkpoint for now. I'm good with doing all of that as a separate fix in the interest of getting this in.
Ah, okay. Thanks.
I like the level of detail in these tests, the degree of splitting them in into so many test methods and helpers is maybe a little bit hard to read. The following are just some suggestions of how to maybe group some of the tests. e.g the null, true and false test could be grouped into one case that checks allowed fields fort the allowMalformed field.
Nit: this could be on the previous line.
`NewThreadScheduler` uses `executor.shutdown()` which allows already submitted tasks to run but prevents new tasks being scheduled. I think this is the wrong behavior there and I should have used `executor.shutdownNow()` instead; a fix is underway. Since the Handler scheduler can't be stopped and thus stopping all tasks, you need to keep track of the worker's submitted tasks.
can we give that a better name that describes what the function does? something like `checkCommittedAndSendCommitIfSo()`.
I think that we can do without this flag, it could be a util method that returns a boolean depending on whether values are set or lookup details are.
I think that we can do without this flag, it could be a util method that returns a boolean depending on whether values are set or lookup details are.
I think that we can do without this flag, it could be a util method that returns a boolean depending on whether values are set or lookup details are.
It's a sample application so I don't think the performance argument applies here.
I think that we can do without this flag, it could be a util method that returns a boolean depending on whether values are set or lookup details are.
We don't format method name that way. Please look at the rest of the codebase for inspiration.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
super nit: I tend to like validation to be first
We don't format method name that way. Please look at the rest of the codebase for inspiration.
formatting, 1 line instead of 2
There's an extraneous blank line here.
I expanded your assertions a bit if you are ok with them: ``` public void testRoundsUpperBoundCorrectly() { ScaledFloatFieldMapper.ScaledFloatFieldType ft = new ScaledFloatFieldMapper.ScaledFloatFieldType(); ft.setName("scaled_float"); ft.setScalingFactor(100.0); Query scaledFloatQ = ft.rangeQuery(null, 0.1, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.1, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.095, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.095, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.105, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.105, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); } public void testRoundsLowerBoundCorrectly() { ScaledFloatFieldMapper.ScaledFloatFieldType ft = new ScaledFloatFieldMapper.ScaledFloatFieldType(); ft.setName("scaled_float"); ft.setScalingFactor(100.0); Query scaledFloatQ = ft.rangeQuery(-0.1, null, false, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.1, null, true, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.095, null, false, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.095, null, true, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.105, null, false, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.105, null, true, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); } ```
I am ok with what you propose Nik!
I am ok with what you propose Nik!
I am ok with what you propose Nik!
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
I think after closing #19917 we can remove this todo
I think after closing #19917 we can remove this todo
I think the test should fail. We don't know what else have happened due to this interrupt nor whether the node is ready.
@jasontedor Thanks. I think `:` is a reserved char on Windows and if used in logging.yml but no node name is configured then it might fail the creation of the log file. But I don't think there's something we can do.
Needs a guard.
Needs a guard.
Needs a guard.
Needs a guard.
I think you can initialize the capacity.
I think you can initialize the capacity.
remove this additional line break? :)
I think we can just access the member directly.
Oh, never mind, I misread. Sorry for that. ð
remove this additional line break? :)
are we sure we want to silently go ahead this way when templateService is null? Maybe we should fail so that we find out when it happens, unless it's situation that is actually expected to happen.
Could you please update the PR to use commons-logging rather than SLF4J
I think you should pass in the request here instead of empty params
remove this additional line break? :)
remove this additional line break? :)
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
I meant `node` from the for loop.
do we really need to extend this class? I wanna get rid of it? We should set things up in a ctor and impl. Closeable IMO
I meant `node` from the for loop.
I meant `node` from the for loop.
I meant `node` from the for loop.
should this check be in the same place where we make the actual transition? then it doesn't look a `LIFECYCLE_FORCED_PHASE` would have to be set as a signal back to this execution.
If you prefer, in the indexing method we can do tryAcquire first out of lock and go under lock and try again, if failed.
I meant `node` from the for loop.
do we really need to extend this class? I wanna get rid of it? We should set things up in a ctor and impl. Closeable IMO
do we really need to extend this class? I wanna get rid of it? We should set things up in a ctor and impl. Closeable IMO
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
that's just a suggestion, I tend to do thsi this way: ```Java Runnable toRelease = () -> {}; //... semaphore.acquire(); toRelease = semaphore:release ``` that way you don't need to check any boolean logic and can just call the runnable
I meant `node` from the for loop.
I meant `node` from the for loop.
nit: can we add the timeout value here.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
How do you feel about always emitting a `profiles` map, that map just be empty? I think it's a cleaner implementation than a key that sometimes can be missing depending on the profile map, it makes client diagnostics easier also (ie, you know where to look, even if there isn't anything there yet)
How do you feel about always emitting a `profiles` map, that map just be empty? I think it's a cleaner implementation than a key that sometimes can be missing depending on the profile map, it makes client diagnostics easier also (ie, you know where to look, even if there isn't anything there yet)
I'd feel better if we had a dedicated method for this called something like `closeAsync` or something like this, I think the logic would be simpler...
There's not much use in having four tests that check that the four value are set in the right place.
It looks ok to me
Looks like the '--' is not necessary since the variable is not used anymore later on.
Fair enough. We can also maybe just have a something we can drain and let it be a final field.
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
This should be done in reset()
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
It seems to me that this belongs to BenchmarkExecutorService. The rest of the methods can be moved into an utility class and then we can get rid of AbstractBenchmarkService.
I think the logging in this class is unneeded. if you debug it you can add it back
I think the logging in this class is unneeded. if you debug it you can add it back
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
I'm not sure about this test. I think it's confusing if ``` { "obj" : { "f": 1 } } ``` returns `{}` but ``` { "obj" : { } } ``` returns `{ "obj": {}}`
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Same here with line breaks. Usually I see this as `} else {` in our code.
@jasontedor Thanks. I think `:` is a reserved char on Windows and if used in logging.yml but no node name is configured then it might fail the creation of the log file. But I don't think there's something we can do.
This can just be a plain old logging statement `logger.debug("[discovery-file] using dynamic discovery nodes {}", discoNodes);`.
Somehow we need to distinguish "background" tasks for the cluster from those started by rest actions.
Written while holding a lock and read without lock.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
canceled -> cancelled
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
Written while holding a lock and read without lock.
you should use the `awaitBusy` method here which doesn't have a fixed sleep but increase the sleep interval in quadratic steps...
maybe, to be more precise, it would be good to check the partition that included the new primary.
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
s/y ou/you Also I think upfront is one word.
This should only be done in close()
all I want here is a mechanism that always works. I think if we rely on a backgroud task our system is broken and we have to fix it.
all I want here is a mechanism that always works. I think if we rely on a backgroud task our system is broken and we have to fix it.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
all I want here is a mechanism that always works. I think if we rely on a backgroud task our system is broken and we have to fix it.
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
nit: extra line
(Not part of this, just asking hypothetically)
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
Maybe change to `AtomicLong`? Took me awhile to get it :thought_balloon:
I don't think it's important for now
The sizes are `long`s so I think `randomLongBetween()` would be better.
I don't think it's important for now
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
No need to talk to a mocked observer, TestObserver.assertEmpty() already verifies these.
You can drop `final` from here, we generally don't use it for local variables.
Ok, just checking.
I like the type safety!
Exactly, or in that particular case, from their child since constant-score queries can only have one child.
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
that looks good, thanks
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
this check is obsolet - we can just remove it
If you change the previous method, you can make this return `void` because it doesn't need to return the string
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
this check is obsolet - we can just remove it
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Rather that parsing the json yourself, it would be nice to configure Kafka to do that for us automatically.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
I think it will be cleaner? not a biggy though
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
If you change the previous method, you can make this return `void` because it doesn't need to return the string
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
yea, in that case, let's not add the addition message, and solve it on the logging side m
quote names of objects (`'CREATE INDEX "%(index)s"...'` etc). These parameters are spliced into the statement, not passed as arguments.
I think this will throw a NPE if you create an iterator, then the class switches to CHM, and then you iterate on the iterator since `immutableMap` will be null.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
`file reopened` -> `file is reopened`
I know we already checked it but I think it's important to make sure all data deletion goes through the same place where we do (and will extend) all the required safety checks. We might even want to restrict access to the delete methods in NodeEnv via forbidden API.
confuses the shit out of me everytime :)
confuses the shit out of me everytime :)
confuses the shit out of me everytime :)
confuses the shit out of me everytime :)
`describe` and `get` methods are almost the same: a refactor is possible.
`describe` and `get` methods are almost the same: a refactor is possible.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
No need to be fancy here, just: `logger.debug("got exception", throwable);`.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
another option here is to remove the `success` and just call `translogs.clear()` once you are done and simply close the lists elements all the time
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
`of the it's last` -> `of its last`
`of the it's last` -> `of its last`
oh i see, the JsonStreamContext now doesn't implement `writeValue()`.
`of the it's last` -> `of its last`
This seems wrong to me: this class is abstract and contains tests that should work with any type of repository. We should not force the repository type to `fs` but rely on the `createTestRepository(repoName)` method instead like it is done in the other test.
or N times
grr nevermind I didn't see the last line pfff...
I spoke to @rmuir and this is enabled 99% of the time in master (file leak detection) we can just remove this layer.
I spoke to @rmuir and this is enabled 99% of the time in master (file leak detection) we can just remove this layer.
Any interest in implementing `Accountable`? Accounting for caches is a thing we like.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I was just trying to see how we could make some variables final so that the compiler ca help us. In addition this one variable looked to me like you would almost always want o use a custom weigher.
Not sure if we need to do that it's just one entry per field though.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
That'd be a "no" then.
Any interest in implementing `Accountable`? Accounting for caches is a thing we like.
Any interest in implementing `Accountable`? Accounting for caches is a thing we like.
Any interest in implementing `Accountable`? Accounting for caches is a thing we like.
NO unfortunately there is no `Property.ClusterScope` so I think it makes it more important to have the setting resolved on the coordinating node so that all shards use the same value.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
That requires Kafka streams to be on the classpath and, as I understand, this is an optional dependency on top of Kafka
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
I am glad we simplified things by just renaming id to tag, that's a good choice
Not sure you need to initialize the factory every time there.
we should totally not have this method, one more reason to not implement the interface.
What if we make `level` default to "info" or "debug" instead? That way if you call `log_response` on a non-error response you'd just get an info/debug log, instead of getting a confusing "module logger has no attribute None" error (or whatever the wording actually would be)
thanks @nik9000 ! @elastic/es-clients is this ok? I guess all the client runners will have to be changed accordingly.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
you can use Arrays.copyOfRange
It's super minor, but I think we usually don't include punctuation at the end of exception messages (the `.`)
It's super minor, but I think we usually don't include punctuation at the end of exception messages (the `.`)
It's super minor, but I think we usually don't include punctuation at the end of exception messages (the `.`)
This seems like it should be handled in the `JobConfigProvider` so that any callers don't have to deal with the same error handling.
I think you can initialize the capacity.
It'd be fine with me if it were one of the random options for `createSearchSourceBuilder`, yeah. We'd want to make sure we kept the assertion that the deserialized copy's bytes match the original's bytes which I don't think is an assertion we normally have in these round trip tests.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
Any interest in implementing `Accountable`? Accounting for caches is a thing we like.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
I meant empty as in the settings are empty.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Do these really have to be test instance fields? Can they be passed around? They are easy enough to construct.
This should be done in reset()
I'd switch the order of these so it matches the declaration order.
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
I'd switch the order of these so it matches the declaration order.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
I wonder how long this would work ;)
We tend to start the messages with the job_id. So, this could become: `logger.error("[" + jobId + "] Failed to clear finished_time; source [" + source + "]", e);`
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
here you may be able to use copyCurrentStructure
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
here you may be able to use copyCurrentStructure
Nit: `active.size()-1` -> `active.size() - 1`
oh oh I hadn't read your reply when I replied ;)
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
It would be great, if this is to be migrated to 2.x, that user-supplied functions are called in try-catch. Perhaps not here but in call().
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
Hmm, not sure how I feel about that.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
typo - failIfCancled -> failIfCanceled
typo - failIfCancled -> failIfCanceled
typo - failIfCancled -> failIfCanceled
You can remove the `hasResponseFromRequest` method - it is not needed anymore.
`force` parameter: use boolean type
```suggestion str(ErrorList(['Grace is not a Zombie'], error_class='nonform')) ```
Such a loop in a test is not acceptable. You could send a message and wait a bit. There are similar samples in the JMS area you can reuse.
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
A bit odd. I'd rather have two separate tests (and the one using the deprecated form should be marked as deprecated so that we can clean things up once we remove the deprecated feature that it tests.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
maybe add an explicit `continue;` here to indicate that it's being skipped
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
`try / finally`
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
I think it would be valid to fallback to a generated salt if none is set (for other use cases), but it doesn't necessarily need to be part of this PR.
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
I'd switch the order of these so it matches the declaration order.
cool thanks :)
I think you are missing a `\n` here.
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
Are we sure we can use lessThanOrEqualTo here? we can also just assert that time() > 0 imho.
left over reference to a countdown latch
OK, did not know this :-)
OK, did not know this :-)
The assert message should be `https` not `http`!
one assert per member is better then you see what's not null :0
doc level failure (normal failures are OK from an algorithmic perspective).
doc level failure (normal failures are OK from an algorithmic perspective).
I expanded your assertions a bit if you are ok with them: ``` public void testRoundsUpperBoundCorrectly() { ScaledFloatFieldMapper.ScaledFloatFieldType ft = new ScaledFloatFieldMapper.ScaledFloatFieldType(); ft.setName("scaled_float"); ft.setScalingFactor(100.0); Query scaledFloatQ = ft.rangeQuery(null, 0.1, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.1, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.095, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.095, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 9]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.105, true, false, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(null, 0.105, true, true, null); assertEquals("scaled_float:[-9223372036854775808 TO 10]", scaledFloatQ.toString()); } public void testRoundsLowerBoundCorrectly() { ScaledFloatFieldMapper.ScaledFloatFieldType ft = new ScaledFloatFieldMapper.ScaledFloatFieldType(); ft.setName("scaled_float"); ft.setScalingFactor(100.0); Query scaledFloatQ = ft.rangeQuery(-0.1, null, false, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.1, null, true, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.095, null, false, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.095, null, true, true, null); assertEquals("scaled_float:[-9 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.105, null, false, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); scaledFloatQ = ft.rangeQuery(-0.105, null, true, true, null); assertEquals("scaled_float:[-10 TO 9223372036854775807]", scaledFloatQ.toString()); } ```
doc level failure (normal failures are OK from an algorithmic perspective).
Same here, with `CLUSTER_ROUTING_REBALANCE_ENABLE`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
oh right sorry I keep missing that.
oh right sorry I keep missing that.
not a big deal but maybe phrase it `remove() is not supported on GeoHashPathIterator`
Sorry, right, I was confused by the child and _child looking similar.
would be great if this logic could be unit tested.
can we have some messages for these asserts, they are a pain if they trip without a message
same here, this might be called by a user-invoked force-merge
same here, this might be called by a user-invoked force-merge
This function is used to resolve index constraint on field stats. I am not sure if we should implement index constraint on a geopoint field but if we don't then we should throw an exception here.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
It is in.
maybe mention that it is important to remove entries that have a value of zero to avoid memory leaks
Looks like this should be in `secondJustError()` and vice versa
Was this test not useful anymore? Maybe just test the builder here.
This doesn't look correct to me: `of course` would be analyzer as a single token `course` at position 0 while it should be at position 1. I think the right fix is to put back `tokens.add` where it was before and instead to initialize `position` at -1.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
`o1 +=8;` <== format this file again :)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
can we make sure not to delete a file that wasn't created and hide the original exception? we typically do this: ``` bool success = false; try { do something success = true; } finally { if (success) { clean up } } ```
I think it's always a single node cluster, but I'm good to keep it like this.
if we'd make the `2` a double I would sleep much better at night ;) same below :)
if we'd make the `2` a double I would sleep much better at night ;) same below :)
We prefer forward merges to back-ports, however, if switching the base branch to 2.7.x is proving tricky, please leave it as main and switch to Spring Retry 1.3.3-SNAPSHOT in your PR. We can then take care of getting the changes based on top of 2.7.x as part of merging the contribution.
We prefer forward merges to back-ports, however, if switching the base branch to 2.7.x is proving tricky, please leave it as main and switch to Spring Retry 1.3.3-SNAPSHOT in your PR. We can then take care of getting the changes based on top of 2.7.x as part of merging the contribution.
`module.param['executable']` could be a non executable file. [`ansible.module_utils.basic.is_executable`](https://github.com/ansible/ansible/blob/68aeaa5/lib/ansible/module_utils/basic.py#L657) should be used in order to check that. Moving all these checks in specific method would make unit tests easier.
nit: ditto for `final` method args here
nit: ditto for `final` method args here
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
canceled -> cancelled
nit: ditto for `final` method args here
+1, rather catch them early than with transport weirdness later on
nit: ditto for `final` method args here
nit: ditto for `final` method args here
nit: ditto for `final` method args here
That assumes `list` can't contain null..if that is not the case ignore
Or not. It looks like you are allowed to modify the segment's innards while you have this lock.
+1, rather catch them early than with transport weirdness later on
+1, rather catch them early than with transport weirdness later on
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
By the way should we throw an error if the loader generates a null value? I'm unsure if we need it and it makes the cache harder to manage (or just bad if we keep on regenerating null values)
That assumes `list` can't contain null..if that is not the case ignore
nit: ditto for `final` method args here
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
does this work? it works for percentiles, but with percentiles rank it's reversed
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
nit: ditto for `final` method args here
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
nit: ditto for `final` method args here
This seems quite sneaky that you modify the lists returned by `getGetMethods()` and `getGetReturns()`. Additionally, I'm not sure how it actually works since you increment `get`, but then but remove, so the size is changing. Can you instead create a copy of the lists in SSource ctor and use those local versions? I think you could then just create the lists on SSource only containing variables contained in `reserved.getUsedVariables()`? Then just iterate the member lists here to add to the `mainMethod`.
look into `StreamInput#readMap`
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
minor nit: for readability, I would rather do ``` if (leader.skipDuplicates == false || seenSurfaceForms.add(current.getText().toString())) { options.add(current); if (options.size() >= size) { break; } } ``` That makes the if with continue not needed as we are at the end of the while block.
@jkakavas - thanks for the thoughtful reply. I don't want to derail this PR and will open an issue for further discussion. EDIT: Issue logged: https://github.com/elastic/elasticsearch/issues/31692
maybe, to be more precise, it would be good to check the partition that included the new primary.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
now that we have `GsubExpression` (hurray!). we should probably define an equals, where the `pattern` field is compared using the `.pattern()` command since that seems to be the proper way to check equivalence between `Pattern` objects. then these assertions would be simplified as well.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
I double checked and this has changed with this PR, we used to return 404 before.
I think this is ok, the isFilter() flag should be set when parent queries that are already using toQuery() produce some inner query in a filter context.
maybe update the docs to say this is a terms query rather than a bool
Well that's the problem, we don't know what's important for a custom rescorer. `SearchContext` is mutable which is why I think it's too sensitive but the same applies to `SearchSourceBuilder` so you're probably right. We can find ways to pass more information in the `RescoreContext` anyways so +1 to keep this simplification.
Well that's the problem, we don't know what's important for a custom rescorer. `SearchContext` is mutable which is why I think it's too sensitive but the same applies to `SearchSourceBuilder` so you're probably right. We can find ways to pass more information in the `RescoreContext` anyways so +1 to keep this simplification.
no need to set timeout, the default is good enough
This seems a little strange, so multiple threads can read the same operation twice and then advance into the middle (or over) a subsequent operation? I think the `AtomicLong` gives the impression of thread safety but we should clearly mark that this class is not thread-safe.
one more line break? :)
one more line break? :)
`file reopened` -> `file is reopened`
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I think I've seen this somewhere else today ;-)
I think it might be nice to move this in `TcpHeader`
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
I think it might be nice to move this in `TcpHeader`
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
cool lets move on with this.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
Please test this in a dedicated test. I'd like also to see a test that checks what happens if the MBean has already been registered (using the `<jmxConfigurator />` option).
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
lower cased now...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should say `higher cluster state version` instead of `higher id`.
If it is not required, you don't have to add `'required: False`.
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
Please don't use Commons Lang. Spring's `ReflectionUtils` or `DirectFieldAccessor` are our preferred alternatives.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
`try / finally`
Missing space. Should be: `String publicKeyBase64 = getValue`
You can make the whole PR a lot simpler by using: `for fname in sorted(files)[start : stop]` Remember: this feature should only total a few lines of change. The only "logic" required by this PR is the computation of `start` and `stop` above given the `validation_split` passed by the user (if any).
Ok sounds fine then.
No need to be fancy here, just: `logger.debug("got exception", throwable);`.
can we make the environment variables passed on to this configurable ie. as ctor arguments? I also wonder if the variable should be prefixed with `ES_`
do we need ordered things? does order help anywhere? If not I would just use HashMap
Full default value handling story here: https://github.com/elastic/dev/blob/master/design/queries/general-guidelines.md#default-handling
ah I get the difference now. then maybe say "if either inner query buider returns null" null-query makes me think of the empty-query, maybe it's me
the exception is completely swallowed... we should at least log something
the exception is completely swallowed... we should at least log something
same should be done for minChildren and maxChildren too. Wondering now if it makes sense to move to `int` rather than `Integer` for all three fields
the exception is completely swallowed... we should at least log something
the exception is completely swallowed... we should at least log something
the exception is completely swallowed... we should at least log something
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
maybe `Objects.equal` could make it easier to read
the node where the shard should move to
the node where the shard should move to
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
If you do this, you can also simplify things above. ```java Gauge.builder("git.info", () -> 1L) .description("Project Git information").strongReference(true); .tag("branch", getOrDefault(props.getBranch())); .tag("id", getOrDefault(props.getShortCommitId())); .tag("time", getOrDefault(props.getCommitTime())); .register(registry); ```
if we change this to never be null, I think we can share the logic here and make it simpler. Something like: 1) Add everything we get to the buffer 2) coordinatewrites (always) 3) If max retrieved seq!= requiredMaxSeq, send another request 4) else if ops.length == 0 schedule a future coordinate read 5) else if coordinate read now.
maybe, to be more precise, it would be good to check the partition that included the new primary.
right, I forgot about the exception.. let's keep it, but private ;)
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
for style can we maybe invert the if statements here ie `if (!masterCopy.isEmpty)` and `if (!success)`? I like to have only one return statement at the end of the method
Please add `type='str'`
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
Revert all noop changes.
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
What if we make `level` default to "info" or "debug" instead? That way if you call `log_response` on a non-error response you'd just get an info/debug log, instead of getting a confusing "module logger has no attribute None" error (or whatever the wording actually would be)
neat picky - formatting. (add {} )
neat picky - formatting. (add {} )
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
This should be done in reset()
60s is way too much for a single test in my opinion. I think we should either make the test faster or mark it as @Nightly.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be done in reset()
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
As the alternative is to change the mock maker for the whole project, I'd prefer to load an actual `KeyStore`.
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
at that point you want have a read budget, which I mentioned above.
I think the add and set methods for those lists here are too complex. I think we should only have setters and the setters should make an unmodifiable list out of the values as well as copy them.
at that point you want have a read budget, which I mentioned above.
:+1: I like how this method abstracts the way sub aggregators should be collected and how you can mix deferred aggregation with sorting.
Sorry, I'd missed that there are two URIs being configured, one with credentials and one without.
also use the constant here
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
Sorry, I'd missed that there are two URIs being configured, one with credentials and one without.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
this check is obsolet - we can just remove it
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
This logging statement has a `[{}]` but no argument to fill it
waitForMappingUpdatePostRecovery defaults to 30s, give that the timeout now results in a failed shard (good!) I think we should be more lenient. Especially given the fact that local gateway recovery runs on full cluster restart where the master might be overloaded by things to do. How about something very conservative like 15m (which is what we use for the same update mapping - see RecoverySourceHandler#updateMappingOnMaster)
can we call this initializePrimaryTerms ? I find allocate confusing here
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
instead of this check just override `public void onRejection(Throwable t)`
You could add an assert that it's not ES 7.x here so we know to remove it
This could be deleteIfExists
I don't think that a security exception should be re-thrown as an `IOException`.
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
I think I'd prefer to have a single `static` block, since it's not easily apparent which would be executed first
Since the account settings are supplied by user, I would feels better if we used URI to build this string. This way we will have at least some basic validation of the things that go into this URL.
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
Oops must have accidentally pull this code over from 6.x. Thanks for removing
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
It would be useful to have access to these in `-o` and even in --match-filter (https://github.com/yt-dlp/yt-dlp/issues/1309)
nit: extra plus in `+ 5 * + 3600000L`
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I see what you mean, that we somehow break bw comp but I would leave only the lowercase variants to make this consistent with other places where we load files e.g. we would never load `elasticsearch.YML` . I think this change is acceptable and in the scope of the PR since we are in fact limiting the files that are getting loaded as logging configuration.
Yes, I think the builder should operate on the field type.
Yes, I think the builder should operate on the field type.
just fix a number, I don't think randomizing this adds much.
we should totally not have this method, one more reason to not implement the interface.
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
Perhaps add the duplicate size to the assert message here
Perhaps add the duplicate size to the assert message here
Perhaps add the duplicate size to the assert message here
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Perhaps add the duplicate size to the assert message here
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
would be nice to allow to configure it to a percentage of the heap size
nit: extra line
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
if you get merge conflicts on these MetaData calls that should have been static, don't worry, I think I recently merged a PR from a contributor that fixed just that.
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
There is a default value for `executable` module parameter: then `get_bin_path` will never be called.
This constructor doesn't seem to be necessary.
Minor typo of `local` instead of `locale` in the exception message.
Minor typo of `local` instead of `locale` in the exception message.
I don't think you need to divide at all - randomDouble is between 0 and 1, I believe.
Can we move these up at the top of the class with the other object variable declarations? I think it is more readable than having them 300 lines down into the class.
same for functions below
it seems that the latch is useless? or maybe you wanted to enable the recovery half way through the "indexing operations"? Also, this suffers from the same racing condition - if the ops that are now in flight when the relocation comes in are not first in the onLockAcquiredActions list, we will have a deadlock.
oh, multi-bucket comparisons are ready already? :)
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
oh nevermind, I just found the method that called it with null :)
You can simplify your code a lot by simply updating your boolean, instead of using a list of booleans.
I would probably go for "Exit" here, but that's more cosmetic than functional.
This line is too long to pass the lint test
This line is too long to pass the lint test
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
To keep things simple, I would not support null values for now.
Nit: `initializing.size()-1` -> `initializing.size() - 1`
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
would be great if this logic could be unit tested.
would be great if this logic could be unit tested.
would be great if this logic could be unit tested.
thanks a lot! should we have a test that leverages this extension point for score functions? I thought we had one already but not sure anymore
I'm fine with it, given the explanation. I only saw that it seemed to be a variable name change that was unnecessary.
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
I see that we need it from another package, I think it's ok.
this needs a message
this needs a message
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
you can use `IOUtils.close(processor)` it deals with `null` values...
I don't think you need to this, the internal cluster will call the node settings automatically.
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
Since we have used `EDITOR` historically, we should not change the default and need to start with `EDITOR` as the default. This precedence may not make sense, though, and we may need to add a config option to control this. ```suggestion env_editor = os.environ.get('EDITOR', os.environ.get('VISUAL', 'vi')) ```
good catch on delta > 0
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
I think it'd be useful to see the filenames in the exception message.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think s/lang/defaultLang/
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
This is called from inside the lock being held which means that replaying all historical values to a new Observer will block all existing Observers and new values from proceeding.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
Why do we need this leniency? The semantics should be either no qualifier is null, or empty string, but not either.
No "unsupported HTTP method" message? :)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
Lucene has a FilterFileSystemProvider which allows mocking of various file system calls (for example the VirusCheckingFS class in the lucene test-framework which throws AccessDeniedExceptions on delete)
I think you should fsync after writing these bytes, e.g. `out.getChannel().force(true)`, like the translog code does? Would be horribly unlucky if the user ran this tool then their box crashed and it left the translog corrupt.
I think you should fsync after writing these bytes, e.g. `out.getChannel().force(true)`, like the translog code does? Would be horribly unlucky if the user ran this tool then their box crashed and it left the translog corrupt.
Can we have a `ssl` namespace for these (see `RabbitProperties` for instance)
No "unsupported HTTP method" message? :)
This also seems like the kind of leniency that we'd want to remove in the future.
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
This also seems like the kind of leniency that we'd want to remove in the future.
This also seems like the kind of leniency that we'd want to remove in the future.
This also seems like the kind of leniency that we'd want to remove in the future.
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
I think "from" should be "from2" here. Also I would make the calculation simpler here as well, I think otherwise min might be smaller than max in the calls to "randomIntBetween"
Nice, I just figured out how you check the response by preparing it here.
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
maybe reverse this check? (`expected.equals(map) == false`)
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
I don't think you should catch this here! this must not be null at all just let it run into NPE
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
lets just use IOException that's much better for this purpose and it's checked
I think you want to use `notVisitedTasks` here instead of `runningTasks`
Default isn't specified in argspec.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
these unit tests are great! We are going to need more of them :)
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
I think you want to use `notVisitedTasks` here instead of `runningTasks`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
I think you want to use `notVisitedTasks` here instead of `runningTasks`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I think you want to use `notVisitedTasks` here instead of `runningTasks`
I think you want to use `notVisitedTasks` here instead of `runningTasks`
I think you want to use `notVisitedTasks` here instead of `runningTasks`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I'm wondering if we need to use `Objects.equals` here which would be quite heavy-weight on the entire CockroachTasksInProgress... in this case, for example, all we care about is if there are new task entries whose executor is the local node id... in that case, maybe we can have a method on `CockroachTasksInProgress` such as `hasNewEntriesForExecutor(localNodeId)`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I think you want to use `notVisitedTasks` here instead of `runningTasks`
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I think you want to use `notVisitedTasks` here instead of `runningTasks`
Not a big deal, I'm fine without it
minor nit: "int he" -> "in the"
minor nit: "int he" -> "in the"
minor nit: "int he" -> "in the"
interesting, what is the reason for this funny upper bound? :)
interesting, what is the reason for this funny upper bound? :)
we could pass a glob with regex:xxx to newDirectoryStream if we want
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
I am ok with what you propose Nik!
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
is this needed? as far as I can tell, the implementation does nothing?: ``` try { if (lock != null) { <-- **lock is null** try { lock.release(); lock = null; } finally { clearLockHeld(path); } } } finally { IOUtils.close(channel); <-- channel is null channel = null; } ```
would be great if this logic could be unit tested.
Such changes in our own source is a good indication there will be generics issues for the users of the library.
Such changes in our own source is a good indication there will be generics issues for the users of the library.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
nit: extra newline
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
I wonder if we should do this with no timeout at all. Potentially log warning after 30s and retry.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
oh boy I was hoping we would not need this sort of stuff, but I guess we do? I mean the instanceof as well as the cast to double array
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Again, need to figure out what to do if ATOMIC_MOVE is not supported
just name it `read`
Another `_` java 9 will be mad at
Another `_` java 9 will be mad at
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
this only verifies the repo on the master, not the other nodes...
this only verifies the repo on the master, not the other nodes...
Before calling this, we should probably add a check that the `batchedIterator.hasNext()` and throw if not. It might make our future life easier when trying to debug stuff :-)
I think you can initialize the capacity.
This isn't needed client-side.
maybe add which type of section it was, so that it's even safer to get rid of the double exception? That is the only useful bit I find in the original stacktrace that would otherwise get lost.
This should be a call to `setIdleTimeout` instead. It is described as "sets the maximum Idle time for a connection, which roughly translates to the `Socket.setSoTimeout(int)` call.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should be a call to `setIdleTimeout` instead. It is described as "sets the maximum Idle time for a connection, which roughly translates to the `Socket.setSoTimeout(int)` call.
This whole loop reads fairly low-level. If config files can be considered small, we could just read them much more concisely with the Stream API (untested): ``` java String rules = Files.readAllLines(path) .stream() .filter((v) -> v.startsWith("#") == false) .collect(Collectors.joining("\n")); ``` All the low-level stuff is gone. But this relies on Java 8 features and will only work on master.
ok now i can see that it is null when removing the task, sorry for the noise
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Such a loop in a test is not acceptable. You could send a message and wait a bit. There are similar samples in the JMS area you can reuse.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
shard can remain
I see that we need it from another package, I think it's ok.
I wonder if this new method/accessing the char[] is something we should just deprecate immediately? Long term I don't think eg we should not be using the keystore to store a password for another keystore; the contents of the other keystore should be moved into the elasticsearch keystore.
Now I wonder if you should make readFrom/writeTo final and make an abstract method that is just responsible for reading the response. That pattern was used by the query builders until they switched to constructor based reading and it seems fairly a appropriate. I don't think it should block the PR though. It isn't really important I think.
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
Missing a `@since`. I wonder if that wouldn't be something of interest for the library (ping @jkschneider)
Minor typo of `local` instead of `locale` in the exception message.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
I still feel like there ought to be a way to make these methods look less copy-and-paste-ish. They just set off my copy-and-paste blindness even though they aren't copied and pasted.
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
As per #1353 I recommend something other than "selector" for the parameter name (here and elsewhere) "since these functions aren't really 'selecting' items so much as changing them."
It should be noted that this is an optional epoch break point if your `data/epoch_generator` does not stop.
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
also, please make a note to make this configurable.
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
Correct me if I am wrong but these filters have to be executed in a serial fashion one after another, right? So you can make this async if you need to on top of the blocking loop? I would like to see an example where this is used to understand the rational please :)
also this class should be final.
also this class should be final.
Again, not monotonically increasing (except for max) so should not be a FunctionCounter.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
the enum values make no sense in the context of the name. I wonder if we should call it `OperationAge` or something like this.
Changing the names of variables which is not necessary for this patch makes it harder to review, can we revert them? e.g. `total_seconds_since -> since`, or ``` for index, (seconds_per_chunk, chunk_name) in enumerate(TIMESINCE_CHUNKS): ``` -> ``` for i, (seconds, name) in enumerate(TIMESINCE_CHUNKS): ```
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
remove empty line
remove empty line
remove empty line
remove empty line
remove empty line
I think it might be nice to move this in `TcpHeader`
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
Nit: Almost ;-) To be or not to be, and also where, that is the question.
we should start thinking about testing the parsing phase for things that we never output from doXContent.... :)
I think it might be nice to move this in `TcpHeader`
Changing the names of variables which is not necessary for this patch makes it harder to review, can we revert them? e.g. `total_seconds_since -> since`, or ``` for index, (seconds_per_chunk, chunk_name) in enumerate(TIMESINCE_CHUNKS): ``` -> ``` for i, (seconds, name) in enumerate(TIMESINCE_CHUNKS): ```
I think it might be nice to move this in `TcpHeader`
This will fail if `(int)((end - start)/bucketSpan)` is greater than 10000. A check should be added elsewhere to ensure that the window is small enough that this won't happen.
I think it might be nice to move this in `TcpHeader`
I think this needs to be `Version.V_6_0_0_alpha3` now.
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
I think this needs to be `Version.V_6_0_0_alpha3` now.
I see now that MoveAllocationCommand is not touched by the PR. I think moving to NamedWriteableRegistry is a good idea, but I'm fine with putting it out of scope for this PR
I think this needs to be `Version.V_6_0_0_alpha3` now.
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Need to import reduce from ansible.module_utils.six.moves.
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Nit: you could use `Collections.emptyList()` instead of `new ArrayList<>()`
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should only be done in close()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
super nit: I tend to like validation to be first
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I think `writeGenericValue` handles null values, so you could omitt the surrounding check.
pageParams is missing from the equality check
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
I think `writeGenericValue` handles null values, so you could omitt the surrounding check.
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
Use double quote docstrtings.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
I don't think we should be making that change as part of the upgrade to the new driver unless this use case is no longer supported.
I don't think we should be making that change as part of the upgrade to the new driver unless this use case is no longer supported.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
I think you can initialize the capacity.
I think you can initialize the capacity.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
I think you can initialize the capacity.
One thing to note, merge_type might not work with apply, we might hard code the apply merge strategy to merge (since strategic merge patch would need to know the merge key to intelligently generate the patch)
Sorry, I thought the URL could be used to provide the username and password.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
I think this is a sign that `getActionFilters` maybe should take `ThreadPool` as an argument.
ok...but client depends on the transport service anyway no? I think I don't get it
That's very minor but you can use `assertIn` here.
`Arrays.asStream(response.pingResponses)` would not materialize it
indentation is off after other changes
I don't think it's important for now
do we have a todo to extend this to the new setup (in a follow up)? There's much more that should go here.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
I opened: #23338
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
I opened: #23338
I'nm still missing the buffer size, the max requested seq no, leader global checkpoint , follower global checkpoint etc. I'm fine with a follow up for those, but that's what I meant.
Does this mean the module version is only the "major" version within a semver denoted jar filename? It might be useful to note that, or even link to any Java spec docs that describe this version extraction for automatic modules.
I am not sure RestoreService would be the right place for it since addBlock would need to be moved to the same place and it's currently used all over the place. I don't have an issue with renaming it to `addIndexMedataBlocks` but since IndexMetadata is the only parameter, repeating IndexMetadata in the name might be redundant.
Fall back to _old_ behavior
Fall back to _old_ behavior
+1 to randomize on 1 node cluster as well - wasn't aware of this to be honest...
Let's replace the `assertTrue` and `assertFalse` by more effective matchers.
Can you rewrite these to use `assertThat(..., equalTo(...))`. I prefer this form because it's clearer which is the expectation and which is the value under test whereas with `assertEquals` it often gets confused.
Fall back to _old_ behavior
oh oh I hadn't read your reply when I replied ;)
oh oh I hadn't read your reply when I replied ;)
oh oh I hadn't read your reply when I replied ;)
oh oh I hadn't read your reply when I replied ;)
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
oh oh I hadn't read your reply when I replied ;)
> It sounds like I'm going to shift to List from arrays anyway, and thereby drop these methods altogether. +1, that should shrink the added code in this PR by a lot.
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
@jborean93 My preference here would be to allow to put the unit as part of the value (which obviously means we ought to have helper-functions to translate the values to the needed format). If the unit is missing, I would assume it is in bytes. But I can see how that could be difficult in cases where values in bytes make little sense. So maybe the module could provide a different default unit (and specify it in the parameter docs). I am not a big fan for having the unit in the parameter name, or having a separate parameter that stores the unit (usually done to avoid the need for parsing). The unit as part of the value is definitely the most user-friendly and concise option.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
I'm not convinced in th soundness of the bookkeeping here. I think that `totalNanos` can include the total task time for more than `tasksPerWindow` tasks.
There is no need in excessive verbosity.
this line should be: `def __init__(self, *args, **kwargs):`
it doesn't reset the ignored list..
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
oh, multi-bucket comparisons are ready already? :)
oh, multi-bucket comparisons are ready already? :)
oh, multi-bucket comparisons are ready already? :)
I'm not sure it is ever good for this to be a global default. Haven't we learned that it causes nasty issues in places like event loops? It seems only appropriate for separate threads, like the IO or NewThread schedulers.
I'm not sure it is ever good for this to be a global default. Haven't we learned that it causes nasty issues in places like event loops? It seems only appropriate for separate threads, like the IO or NewThread schedulers.
I'm not sure it is ever good for this to be a global default. Haven't we learned that it causes nasty issues in places like event loops? It seems only appropriate for separate threads, like the IO or NewThread schedulers.
It's good like it is , it's more civilized, otherwise it would indeed indeed violate the scope of this PR. I think I see the privilege code as new code where creative destruction is more loosely permitted. But I still think it would be nice to do this change in a follow-up. I am happy to pick it up if you wish.
I think that's a great idea as it'll avoid any drift between the two projects with how the four settings are mapping to a policy. Let's wait for that API to appear in Spring Kafka and then we can update the proposal here to use it.
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
I believe you can remove the todo here, since you set it to true in the unit test
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
ok...but client depends on the transport service anyway no? I think I don't get it
isn't this the default? just omit in that case.
We also need a simple rest test, testing integration like we have for the other processors
maybe update the docs to say this is a terms query rather than a bool
did you plan to add here the list of nodes or something? looks like there is a missing argument.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
... and this doesn't need to know it either.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
We should also remove the other builders to be consistent. WDYT @polyfractal ? I can do that in a follow up.
maybe just simplify these by setting it to the value of the `randomBoolean()` and using `Boolean.valueOf`? Not super necessary, just a nit.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
I think this will be clearer if we say - "// precreate incoming indices and popluate them with the relevant types"
can you move this up to fail before we assign
cool thanks for clarifying!
Should use `{}` logging style instead of string concatenation here
Should use `{}` logging style instead of string concatenation here
did you plan to add here the list of nodes or something? looks like there is a missing argument.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
remove this part which doesn't apply anymore
Just an idea how about making rerouting an AtomicReference<String> where a non null value signals the currently next reroute task name? this way we can log here logger.trace("already has pending reroute due to [{}]. ignoring [{}]")/
`file reopened` -> `file is reopened`
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
Rename the method to something about captures I think now that the utility is gone.
use `Objects.equals` for all once changed to potentially null references.
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Ok sounds fine then.
use `Objects.equals` for all once changed to potentially null references.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
I wonder if we should make these Map<Index, IndexService> - it will remove all these index.getUUID() calls..
It's not 100% mandatory but I liked your idea of having a POJO using JSON to serialize its content. Spring Kafka has actually support for that and you can configure the `JsonSerializer` in Spring Boot (even though I don't expect this to be required).
randomInt cannot be within the loop, otherwise it changes at every iteration...
randomInt cannot be within the loop, otherwise it changes at every iteration...
We can't use hardcoded ports.
Ah, okay. Thanks.
I meant the listener we pass to the transport
I meant the listener we pass to the transport
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
Can't recovery -> Can't recover
nit: a space before `else`.
I would move that to the assertion rather than creating a variable for that.
Can't recovery -> Can't recover
Can't recovery -> Can't recover
can `aliases` be final as well
I your reply got busted.... lemme reread
`try / finally`
actually I think would simplify things as we don't even have to wonder whether we need to retry or throw exception. If the selector doesn't return any host we just throw, it is responsibility of the selector to return at least one host given one or more hosts. Knowing that, a selector can fall back to some backup plan in case e.g. it doesn't find any non master only node.
This isn't the right fix, it's not a response parameter (it controls the request that the node client sends). Rather, this parameter needs to be consumed (and parsed as a boolean).
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
Did you confirm we sometimes hit this and not just ACE? (The "indexed" CountDownLatch should make it likely...)
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
randomInt cannot be within the loop, otherwise it changes at every iteration...
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
randomInt cannot be within the loop, otherwise it changes at every iteration...
maybe just `esVersion()`
randomInt cannot be within the loop, otherwise it changes at every iteration...
randomInt cannot be within the loop, otherwise it changes at every iteration...
this deserves a sep issue I guess but good catch
randomInt cannot be within the loop, otherwise it changes at every iteration...
When `onError` occurs it immediately emits and does not work any further work. We had this discussion a while back when debating `delay` I think. Rx Design Guideline 6.6 > 6.6. OnError messages should have abort semantics > > As normal control flow in .NET uses abort semantics for exceptions (the stack is unwound, current code path is interrupted), Rx mimics this behavior. To ensure this behavior, no messages should be sent out by an operator once one of it sources has an error message or an exception is thrown within the operator. ... > In this sample, a buffering operator will abandon the observable sequence as soon as the subscription to source encounters an error. The current buffer is not sent to any subscribers, maintain abort semantics.
remove this part which doesn't apply anymore
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
I think that these log parameters are backwards.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
spaces missing after `if` and before `{` ð¡
Can we keep the line numbers in the test assertions? I think they are important to maintain.
can be specified as `catch (SnapshotCreationException | RepositoryException ex)` in Java ;-)
We should fail if the put replaced an existing entry? Or rather, not replace if the mapping already exists (ie where a 2 different whiteslists are whitelisting methods on the same class). But surely they can't be allowed to have different names in painless for the same java class (one would overwrite the other here).
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Note that you can use Objects.hashCode(function) directly which will make sure to return 0 if the value is null.
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
nit: IOException never thrown
Ok sounds fine then.
nit: IOException never thrown
maybe make this a parameter on `randomInitialClusterState` (i.e. `Supplier<MockIndicesService>`)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Yes, I think we should make `Job.Builder::setJobType` `public`. The user could change it if they used the low level REST client.
I was a bit confused by that. The `waitStrategy` runs some CQL requests as well, doesn't it? That makes this test a bit fragile IMO.
neat picky - formatting. (add {} )
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
The rate is per second; not counting seconds, which is what this ends up seeming like - a count of seconds.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
same 1+ randomInt
LUNs 1-4095 for private or shared connections
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
can you add more rolling while adding? Also *sometimes* increment the primary term
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
just fix a number, I don't think randomizing this adds much.
Oops, sorry, brain fart. :)
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
It would make sense to refactor this into `private Settings newNodeEnvSettings()` since every test requires it, in case it ever has to be changed in the future.
just fix a number, I don't think randomizing this adds much.
make this an atomicreference to throwable so we can see what it was in the failure message? (use assertNull)
I think the unlock calls should always be in a finally block
This could race with the emission of `run()`.
ð much cleaner. There was no need to stop a node inside the callback.
Same here for `compareAndSet`
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
Randomized runner should not need these @Test annotations.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
This does not necessarily need to be within a static initialization block.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
this breaks backwards compatibility, you will need if based on version in both `readFrom` and `writeTo`
can we move this part to the setRefreshPending method? this will come at the expense of a dedicated listener but all the code that changes pendingRefreshLocation will be in one place making it easier figure out.
can we move this part to the setRefreshPending method? this will come at the expense of a dedicated listener but all the code that changes pendingRefreshLocation will be in one place making it easier figure out.
nit: "so we assume"...
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
It would be good to have some context as to where the filter appeared. I would at least word it a little differently: `"Missing [type] setting for anonymous char filter: " + charFilterName`
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
I would use `sys.stderr.write(msg + os.linesep)` for each result instead of `print()` with joined results.
This is why I said moving to compute instead of computeIfPresent so that we could assert that we do have a mapping for nodeId in that map at that point. To be clear I think that what you did is correct, I'd just like to add assertions to it to make sure the invariant is respected.
nit: please use lowercase start for variable names
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
I think checking for newline is better than relying on pretty printing having space between key/object...
thanks for killing this IllegalAccessError: i added this on accident when debugging long ago!
thanks for killing this IllegalAccessError: i added this on accident when debugging long ago!
`Matchers.equalTo` or `equalTo` with a static import is more normal for this sort of thing I think.
here you may be able to use copyCurrentStructure
I think we might miss some responses in case of onFailure() because it will be using responses created [here](https://github.com/s1monw/elasticsearch/blob/issues/5766/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java#L94)
Minor typo of `local` instead of `locale` in the exception message.
You could avoid this one off method by using a `List<String> lines` instead of a StringBuilder, then returning `String.join(System.lineSeparator(), lines);`
please log the exception here as well we really wanna see what was going wrong
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
To keep things simple, I would not support null values for now.
same note as in the json processor PR.
This also seems like the kind of leniency that we'd want to remove in the future.
how do you feel about renaming this "force merge" instead of "optimize"? (may be out of scope, just curious)
I think it's simpler to just keep equality, but I'm good with you prefer it this way.
We also need a simple rest test, testing integration like we have for the other processors
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
what are testing here? sounds like primaryPhaseExecutesRequest
getDelayCalculationTimestampInNanos -> getLastComputedLeftDelayNanos
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
you can do some streaming java8 magic here.
When I see this, I am now happy that wait is a forbidden API. :-)
I would be using a `Set` in this circumstances.
I would be using a `Set` in this circumstances.
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
`file reopened` -> `file is reopened`
ok, it didn't have any meaning...
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
If we call `start()` and `stop()` in a time frame that is below the resolution of `System.nanoTime()` (at best ~ 30 ns) then we will have also significant skew here (assuming 1 ns between consecutive calls).
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
What uses this? And why is forbidden APIs not angry about passing in String,int here... i feel like i banned that method. I dont like it as its wired to 127.0.0.1 in non-test code.
`file reopened` -> `file is reopened`
I guess it would be good to assert that the returned delegate is not another instance of `JsonGeneratorDelegate`
`them` -> `them;`
not used (I was so much looking forward to more usages of this)
no need to implement/override this method if no validation is required
Here is a quick fix (not elegant): ``` java volatile Scheduler.Inner innerScheduler = null; /** * Try draining the queue on the given scheduler. * The method ensures that only one thread is actively draining the * queue on the given scheduler. * * @param scheduler * the scheduler where the draining should happen * @param cs * the composite subscription to track the schedule */ public void tryDrainAsync(Scheduler scheduler, final CompositeSubscription cs) { if (cs.isUnsubscribed() || wip.incrementAndGet() > 1) { return; } if (innerScheduler == null) { // add tracking subscription only if schedule is run to avoid overfilling cs final MultipleAssignmentSubscription mas = new MultipleAssignmentSubscription(); cs.add(mas); mas.set(scheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { innerScheduler = o; if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } })); } else { innerScheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } }); } } ```
Here is a quick fix (not elegant): ``` java volatile Scheduler.Inner innerScheduler = null; /** * Try draining the queue on the given scheduler. * The method ensures that only one thread is actively draining the * queue on the given scheduler. * * @param scheduler * the scheduler where the draining should happen * @param cs * the composite subscription to track the schedule */ public void tryDrainAsync(Scheduler scheduler, final CompositeSubscription cs) { if (cs.isUnsubscribed() || wip.incrementAndGet() > 1) { return; } if (innerScheduler == null) { // add tracking subscription only if schedule is run to avoid overfilling cs final MultipleAssignmentSubscription mas = new MultipleAssignmentSubscription(); cs.add(mas); mas.set(scheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { innerScheduler = o; if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } })); } else { innerScheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } }); } } ```
Here is a quick fix (not elegant): ``` java volatile Scheduler.Inner innerScheduler = null; /** * Try draining the queue on the given scheduler. * The method ensures that only one thread is actively draining the * queue on the given scheduler. * * @param scheduler * the scheduler where the draining should happen * @param cs * the composite subscription to track the schedule */ public void tryDrainAsync(Scheduler scheduler, final CompositeSubscription cs) { if (cs.isUnsubscribed() || wip.incrementAndGet() > 1) { return; } if (innerScheduler == null) { // add tracking subscription only if schedule is run to avoid overfilling cs final MultipleAssignmentSubscription mas = new MultipleAssignmentSubscription(); cs.add(mas); mas.set(scheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { innerScheduler = o; if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } })); } else { innerScheduler.schedule(new Action1<Scheduler.Inner>() { @Override public void call(Scheduler.Inner o) { if (!cs.isUnsubscribed()) { do { queue.poll().call(); } while (wip.decrementAndGet() > 0 && !cs.isUnsubscribed()); } } }); } } ```
I think we should collapse the two above methods, they are always called in sequence.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
maybe `Objects.equal` could make it easier to read
Whoa this is even stranger to read since it spans 3 lines
can we call these indices "short_delay" and "long_delay" ? I think it will be easier to read.
Pick node with THE primary shard
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
I wonder how long this would work ;)
I guess the bird has already flown with this one but the operator `take` refers to `onNext` events and we are more or less using it for all event types (take till terminates or the other thing terminates). I'm not suggesting a change perhaps a naming review for 3.x.
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
I think the length of individual byte[] values should also be encoded using vInt.
nit: extra newline
We don't need any of these `build*Properties()` methods; all the kafka specific properties are already handled by parts of `KafkaProperties`.
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
I think it's simpler to just keep equality, but I'm good with you prefer it this way.
I think it's simpler to just keep equality, but I'm good with you prefer it this way.
We should debug log here the number of times that we have retried up to here.
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
This function does not have a properly formatted dosctring (see other dosctrings for reference)
I don't think this is worth the inconsistency. Please remove that and make it camel cased
Same here, with `CLUSTER_ROUTING_REBALANCE_ENABLE`
Same here, with `CLUSTER_ROUTING_REBALANCE_ENABLE`
I think we want to test index level blocks too here
Can this use `b_output_path` from line 291? ```suggestion b_output_path, ```
now that we have `GsubExpression` (hurray!). we should probably define an equals, where the `pattern` field is compared using the `.pattern()` command since that seems to be the proper way to check equivalence between `Pattern` objects. then these assertions would be simplified as well.
Technically, you don't have to start the job if you just want to make sure the task is running. We start the persistent task when the job is created in the CreateRollupJob API. Although I wonder if there might be a potentially rare timing issue here? The CreateRollupJob API returns when the persistent task framework acknowledges that task was created. But I believe there might be a lag between that and when the allocated task is actually created on the target node? So it might be possible for the StartJob API (or `assertRollupJob()` if starting is skipped) to fail because the allocated task hasn't started yet? Maybe we need an `assertBusy` checking for the job, like below? I may be wrong about that though, you're much more familiar with how the persistent tasks work :)
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
A description for these configuration properties must be as short as possible: https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#appendix.configuration-metadata.format.property
The `<=` will need to be escaped.
now that we have `GsubExpression` (hurray!). we should probably define an equals, where the `pattern` field is compared using the `.pattern()` command since that seems to be the proper way to check equivalence between `Pattern` objects. then these assertions would be simplified as well.
now that we have `GsubExpression` (hurray!). we should probably define an equals, where the `pattern` field is compared using the `.pattern()` command since that seems to be the proper way to check equivalence between `Pattern` objects. then these assertions would be simplified as well.
I mean: I saw that `kafka-topics` has a `--disable-rack-aware` parameter, I don't known if the module should allow user to use it or not.
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
You could add an assert that it's not ES 7.x here so we know to remove it
The indentation is off here and the rest of the way through this test.
I guess the bird has already flown with this one but the operator `take` refers to `onNext` events and we are more or less using it for all event types (take till terminates or the other thing terminates). I'm not suggesting a change perhaps a naming review for 3.x.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
Strings.EMPTY_ARRAY could be used too (if you want)
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
I think the `&` needs to be `&amp;`
`foo`-> `{@code foo}`
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think it is fine: we only build one search context per request per shard.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
perhaps a different name for this listener, as it doesn't only handle failures but also successful response publishing
This lambda does not need to be a statement block.
Randomized runner should not need these @Test annotations.
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
you can do some streaming java8 magic here.
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
None of the other stores have such a variant and I am not keen to introduce it as part of the upgrade. We can reconsider once the upgrade is done of course.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
Please change it to `only one thread should call`, remove `be allowed to`.
Traditional how? That it's in 1.x? I don't see why that should stop us from removing it. Doing something like this is wrong: ``` java timer(1, SECONDS, Schedulers.test()) ``` yet it's how you'd use every other static method in this class.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Maybe the max should be more? Something like 5
nit: can you use assertThat or expose the actual values in the message.
I wonder if those should all be sets? and must be non-null
save -> safe
I was hesitant in the beginning due to the need for the additional class, but this looks great, it simplifies also concurrency as we read only once per node from the blacklist, so from then on we don't even have to retry as we kind of act based on the previous view of the blacklist. Not only does it allow us to remove the max_attempt, but also to remove retries due to the concurrent changes as a whole!
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
I think this can all fit on one line more cleanly if you break after the equal sign.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
is this correct? don't we want the maxrequired to be global checkpoint (i.e., from - 1 )? now it seem you have to bring at least on seq# back.
It's super minor, but our log standardization is usually all lowercase
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
(Not part of this, just asking hypothetically)
good catch on delta > 0
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Could you have the score scripts as separate scripts rather than repurposing the existing ones? I think its important that we continue testing scripts that don't use score as well as scripts that do.
nit - an extra d? release**d**Delayed..
Please revert this change.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
+1 to clone()
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
you need to wrap that in a new `ArrayList` otherwise access by key won't work (the initial collection is immutable).
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
You already asserted this 2 lines ago, this is a duplicate.
I think this check should go into initializeSnapshot or repository.
can we remove this default ctor and pass the non-recycling closure in the test directly. I think it's just one place.
good catch on delta > 0
Oh, I assumed so, thanks for fixing!
please don't use two letter variables names for acronyms.
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
The theoretical idea here is to try to move away from overriding methods like crazy at the transport level. So if refactorings need to happen, we can (hopefully) just move the stubs to different locations, opposed to dealing with a billion different tightly couple to the `Transport` interface tests.
Same here about `Exception` catching
Same here about `Exception` catching
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
new lines missing. Also we should assert this is never called. Also no need for `throws EngineException`
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
derives -> derived
also this class should be final.
Could be a bug with IntelliJ as javac and Eclipse was fine with the original.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
See #1353 for concern about the parameter name "time" (similar parameters in other operators are called "timespan", "timeout", "interval", "period", "intervalDuration", etc.; those parameters that have pretty much the same function should have the same name).
So the net effect of UnsafeFunc0 is that it forces us to catch the declared Exception on resourceFactory.call() and think about what might happen. I'm not sure it's worth it.
So the net effect of UnsafeFunc0 is that it forces us to catch the declared Exception on resourceFactory.call() and think about what might happen. I'm not sure it's worth it.
nit: extra line
I think it would be valid to fallback to a generated salt if none is set (for other use cases), but it doesn't necessarily need to be part of this PR.
I think it's always a single node cluster, but I'm good to keep it like this.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
good catch on delta > 0
For human readable-ness, an additional field should be added, we shouldn't replace the field with a human readable version. You should be able to do ```java builder.timeField("modified_millis", "modified", modifiedDate); ``` (replacing the field names with the fields we want to use) and then you don't have to check the human readable flag yourself
I think this should be an `AbstractRunnable`, so it can either set `isForcedExecution` to true, or handle rejections gracefully, in the event the executor is ever set to a threadpool other than the generic one, or if we limit the queue_size for the generic threadpool (which we have discussed doing)
It would be nice to have test coverage of this. There is a `JobProviderIT` class could you index some forecast stats in that and assert this method.
Should this be 6 instead of 9? When I try `Instant instant = Instant.from(formatter.parse("0.0000001"));` in the tests I get an `java.lang.ArithmeticException: Rounding necessary`
I think I would still like it better as it avoids reverse-engineering a toString() impl.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
nit: extra line
I think we should leave this method for java api bw comp
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
I might have missed something here. I don't see that the UnsafeFunc0 adds much. After all every Func0 is potentially unsafe inasmuch as it can throw a RuntimeException for instance.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
So the net effect of UnsafeFunc0 is that it forces us to catch the declared Exception on resourceFactory.call() and think about what might happen. I'm not sure it's worth it.
`Description` -> `Descriptor`
As what we're actually storing is the list, I would make this constructor the leaf one. Then the varargs one can just call `this(Arrays.asList(jobIds))`.
I think we want to test index level blocks too here
nevermind I was confused... all is good
You need to close the `Connection`.
relativize can be tricky if paths have different roots. is siteFile really guaranteed to be absolute too? In lucene i coded this "minimal path" with the following idiom: ``` root = root.toAbsolutePath().normalize(); path = root.relativize(path.toAbsolutePath().normalize()); ```
relativize can be tricky if paths have different roots. is siteFile really guaranteed to be absolute too? In lucene i coded this "minimal path" with the following idiom: ``` root = root.toAbsolutePath().normalize(); path = root.relativize(path.toAbsolutePath().normalize()); ```
nit: the map can be `PluginBundle::plugin`
nevermind I was confused... all is good
Why use a static block to initialise this? `Sets.newHashSet` can turn this into a 1 liner, and then you can wrap it in `unmodifiableSet`
I'd just remove this and change standard types to explicitly list the types. `Collections.unmodifiableSet(NativeRealmSettings.TYPE, FileRealmSettings.TYPE, LdapRealmSettings.AD_TYPE, LdapRealmSettings.LDAP_TYPE, PkiRealmSettings.TYPE);`
Given what we are doing below I think we should declare the `ValueType` as `ValueType.VALUE` here because otherwise its confusing when reading the code to see INT here and then the fact that we might expect a String that isn't just an int value below. We should then add an else to the below method to throw an exception if anything other than int or String is supplied.
Given what we are doing below I think we should declare the `ValueType` as `ValueType.VALUE` here because otherwise its confusing when reading the code to see INT here and then the fact that we might expect a String that isn't just an int value below. We should then add an else to the below method to throw an exception if anything other than int or String is supplied.
(Not part of this, just asking hypothetically)
(Not part of this, just asking hypothetically)
(Not part of this, just asking hypothetically)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
All these methods can have package protected visibility.
We can't use hardcoded ports.
Yes I think so.
I was confused with the StringBuilder here, as you later on `insert(0` for the prefix of the message. You could use an ArrayList for the `type.getKey()` and a StringJoiner to append them to the StringBuilder. Really minor, just a suggestion.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
that's just a suggestion, I tend to do thsi this way: ```Java Runnable toRelease = () -> {}; //... semaphore.acquire(); toRelease = semaphore:release ``` that way you don't need to check any boolean logic and can just call the runnable
I don't think we should have this constructor on the client side, as there's no way to sensibly add the missing values (and no sensible reason why the user would need to).
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
By removing the `not` and turning the conditions around, this code can be simplified.
By removing the `not` and turning the conditions around, this code can be simplified.
here you may be able to use copyCurrentStructure
This lambda does not need to be a statement block.
this name is not good. there is no *error* involved. I think you should maybe name it `generateFailureXContent` or somethign like this
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
nit: shard routing already has [] in it's toString
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
Seems strange to split the string here rather than moving `Mapper.etc` to a new line
I wasn't entirely sure either but good to know! :)
oh I see what you meant now in the other PR :) if Tuples don't pollute the method arguments, I am ok with this, actually it simplifies synchronization issues between the two maps otherwise, I will update my PR to do the same.
maybe just use `IOUtils` here they handle null values as well
or N times
this file can go back to 140 chars as well...
maybe just use `IOUtils` here they handle null values as well
or N times
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
super nit: I tend to like validation to be first
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
+1 then we shouldn't forget about it :)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
super nit: I tend to like validation to be first
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
maybe a custom junit rule would be good here? I see that scheme a lot in tests to reset the plugin system once the test is done
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
On reflection I think this means we don't need `lastCommittedState` any more.
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
this made me worry we don't log these failures anymore.. In this specific case I think we are best to just let the exception bubble up, but it does raise a more general issue - if people put exceptions in the builder, it's their responsiblity to report it. we should probably add something to the internal cluster service to auto log it.
Sorry, I'd missed that there are two URIs being configured, one with credentials and one without.
Let's maybe call it `preCollect`? (symetric with `postCollect`)
The factory is what holds onto the params, so that they can be passed to the constructor. Think of the factory as the signature for the constructor. It's not boilerplate; it is actually needed based on current uses of scripts throughout the system. Also note that the factory signature is what allows the script instance to have arbitrary objects passed in. If `ScriptService.compile` were to return an instance directly, instead of a factory, we would need some way to pass in this information in a generic way, which would probably mean duck typing through a String->Object map and then require casts. With the factory, we get static type checking of the arguments a script needs to be constructed.
I wonder how long this would work ;)
This can be `final`.
I don't get it sorry :)
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
We could add a default value (.i.e. `< 6.1 `) in the parameterized message because > Automatically enabling security for older trial license (null) might be slightly obscure.
ok as a follow-up
Can we keep the line numbers in the test assertions? I think they are important to maintain.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
This should be `Type.FS.match(` instead of `Type.FS.name().equals`
It might be cleaner and create less new-Function objects if you extract this compute block as a new method, say "newIndexFieldDataCache(fieldName)", then just do `fieldDataCaches.computeIfAbsent(fieldName, this::newIndexFieldDataCache)` here.
the node where the shard should move to
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Use bullet points
Use bullet points
Use bullet points
Use bullet points
Since the time unit is ms, we should remove this conversion.
Use bullet points
Typo, "Trasnlog" -> "Translog"
Use bullet points
Typo, "Trasnlog" -> "Translog"
I still find the line break between `else` and `if` really weird... although you don't even need the `else` after `return`.
I still find the line break between `else` and `if` really weird... although you don't even need the `else` after `return`.
Not sure about this. We're making a string of the form: ```threadName > ... > threadName > lockOwnerName``` This change removes the last `>` between the final `threadName` and the `lockOwnerName`. I think the original _behaviour_ looks right, although the condition was always true so the `if` could be simply unwrapped.
perhaps a different name for this listener, as it doesn't only handle failures but also successful response publishing
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
This isn't needed client-side.
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
Usually we also make a few API calls to the server, e.g. https://github.com/elastic/elasticsearch/blob/2aba52de8f9315b0e384e1c657d7b0401d26a1b0/qa/vagrant/src/main/java/org/elasticsearch/packaging/test/PackageTestCase.java#L121-L122 I'm not completely sold on the value of those though
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
should be cached thread pool, the default constructor does the right thing here
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
good catch on delta > 0
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
sure, nothing bad happens, but it might still be a user configuration error (user configured initalTimeout, but forgot to set maxTimeout). I think it's nicer to just throw an exception and report it.
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
It would be worth requiring that `jobId` and `jobType` are not `null`.
Looks like this should be in `secondJustError()` and vice versa
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should only be done in close()
This should only be done in close()
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
Again, it looks like you need to pass the level.
make the error a bit more understandable for users? Like "processor x doesn't support some of the provided configuration parameters" and list them like you do already...
This should be done in reset()
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
Could you add a short description here? Something like `Add a byte to the sequence.` would make it so you could skip the `@param` bit and still keep the `@return` which is so nicely descriptive.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
see above - I think you should add it though
Could you add a short description here? Something like `Add a byte to the sequence.` would make it so you could skip the `@param` bit and still keep the `@return` which is so nicely descriptive.
Typo, "Trasnlog" -> "Translog"
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
I call those "leftovers".
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
same here re iterator.remove()
Please revert this change.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
Same here for `compareAndSet`
Same here for `compareAndSet`
Same here for `compareAndSet`
use `terminate(threadPool);` (this method is in ESTestCase)
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
I'd prefer warning :smile: Mentally I reserve error for issues like "oh no I'm going to lose data" or "oh boy I have to crash now" rather than "sorry, I'm busted and can't do what you wanted". That feels like solid warning territory for me.
I would probably throw an exception instead of accepting null here.
It might be worth adding a default implementation of it to whatever interface declares it. The vast majority of the time its a noop.
I would probably throw an exception instead of accepting null here.
typo? oracle corp isn't the jvm version..
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
or just: ``` java if (Objects.equals(similarity(), other.similarity() == false) { conflicts.add("mapper [" + names().fullName() + "] has different similarity"); } ```
Ah, you have enough in CustomUnifiedHighlighterTests, I think.
or just: ``` java if (Objects.equals(similarity(), other.similarity() == false) { conflicts.add("mapper [" + names().fullName() + "] has different similarity"); } ```
Ah, you have enough in CustomUnifiedHighlighterTests, I think.
Below there are more like this, if you'd care :-)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
shard can remain
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
Most of the time `onNext` would emit without contention if the consumer is fast. Does lock elision remove the performance impediment of a `synchronized` on every single `onNext` attempt? Just thinking through the fact that this is a bunch of machinery for something that will typically be put in for dropping data when backpressure happens but should otherwise add negligible overhead.
this could be static
open reader doesn't need to check for <0 and throw an exception any more.
I'd expect the set to be done after mangers & admins are added
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
connec to to -> connect to
Thanks. Perhaps I've misread the change, but won't this warn if your app uses `application.properties` at all? For example, if there's one in `BOOT-INF/classes` in the jar that's configuring properties that don't affect `PropertiesLauncher`? I think we need to warn only if `application.properties` is found and it's used to configure one of the launcher's properties.
This is great! No more @Inject!
I think we should do this in such a way that we can log a warning that `application.properties` is deprecated and that `loader.properties` should be used instead. We can then remove support for `application.properties` in 2.0.
I think the old indentation was a bit better than this.
Hmm, why did we need to fork this class from Lucene? Is it only for the added `getBufferSize` public API? If so, I think we can make this change directly in Lucene. I'll do that ...
Ok, just checking.
there is a bunch of duplication here so I guess we could at least put the `recycler != null` case in a a single method like ``` Java private <T> T registerNewPage(Recycler.V<T> v, int expectedSize) { cache = grow(cache, page + 1); assert cache[page] == null; cache[page] = v; assert v.v().length == expectedSize return v.v(); } ```
Why do we need both? Is it because there are so many things going on in this file? I don't understand why we wouldnt just need the CompiledAutomaton for the terms.intersect operation, why do we need a ByteRunAutomaton too? Having both seems silly anyway, but if we must do it, try to assign the ByteRunAutomaton from the CompiledAutomaton. The majority of the time it will be non-null: ``` /** * Matcher for quickly determining if a byte[] is accepted. * only valid for {@link AUTOMATON_TYPE#NORMAL}. */ public final ByteRunAutomaton runAutomaton; ```
makes sense - treat whatever I wrote as a draft that can be adjusted as more metrics are added
Worth putting the different mapping as first in the List as a second test? `(EsIndex("diff"...), EsIndex("same"..), EsIndex("one"))`
